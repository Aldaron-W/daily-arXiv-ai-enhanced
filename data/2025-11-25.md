<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 77]
- [cs.CY](#cs.CY) [Total: 2]
- [cs.LG](#cs.LG) [Total: 14]
- [cs.CR](#cs.CR) [Total: 3]
- [cs.CV](#cs.CV) [Total: 6]
- [eess.AS](#eess.AS) [Total: 2]
- [cs.AI](#cs.AI) [Total: 4]
- [cs.LO](#cs.LO) [Total: 1]
- [cs.MA](#cs.MA) [Total: 1]
- [stat.ML](#stat.ML) [Total: 1]
- [cs.SE](#cs.SE) [Total: 1]
- [cs.IR](#cs.IR) [Total: 2]
- [cs.DB](#cs.DB) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [SCARE: A Benchmark for SQL Correction and Question Answerability Classification for Reliable EHR Question Answering](https://arxiv.org/abs/2511.17559)
*Gyubok Lee,Woosog Chay,Edward Choi*

Main category: cs.CL

TL;DR: SCARE是一个用于评估电子健康记录问答系统中后验安全机制的基准，专注于问题可回答性分类和SQL查询验证/修正任务。


<details>
  <summary>Details</summary>
Motivation: 在临床环境中部署文本到SQL模型存在安全风险，不正确的SQL查询可能危及患者护理。现有工作缺乏对后验验证机制的统一评估基准。

Method: 构建包含4,200个问题-SQL查询-预期输出三元组的基准数据集，基于MIMIC-III、MIMIC-IV和eICU数据库，涵盖7种不同文本到SQL模型生成的多样化查询。

Result: 实验揭示了问题分类和SQL错误修正之间的关键权衡，识别了主要挑战并为未来研究指明了方向。

Conclusion: SCARE基准填补了电子健康记录问答系统安全部署评估的空白，为开发可靠的后验安全层提供了重要工具。

Abstract: Recent advances in Large Language Models (LLMs) have enabled the development of text-to-SQL models that allow clinicians to query structured data stored in Electronic Health Records (EHRs) using natural language. However, deploying these models for EHR question answering (QA) systems in safety-critical clinical environments remains challenging: incorrect SQL queries-whether caused by model errors or problematic user inputs-can undermine clinical decision-making and jeopardize patient care. While prior work has mainly focused on improving SQL generation accuracy or filtering questions before execution, there is a lack of a unified benchmark for evaluating independent post-hoc verification mechanisms (i.e., a component that inspects and validates the generated SQL before execution), which is crucial for safe deployment. To fill this gap, we introduce SCARE, a benchmark for evaluating methods that function as a post-hoc safety layer in EHR QA systems. SCARE evaluates the joint task of (1) classifying question answerability (i.e., determining whether a question is answerable, ambiguous, or unanswerable) and (2) verifying or correcting candidate SQL queries. The benchmark comprises 4,200 triples of questions, candidate SQL queries, and expected model outputs, grounded in the MIMIC-III, MIMIC-IV, and eICU databases. It covers a diverse set of questions and corresponding candidate SQL queries generated by seven different text-to-SQL models, ensuring a realistic and challenging evaluation. Using SCARE, we benchmark a range of approaches-from two-stage methods to agentic frameworks. Our experiments reveal a critical trade-off between question classification and SQL error correction, highlighting key challenges and outlining directions for future research.

</details>


### [2] [$A^3$: Attention-Aware Accurate KV Cache Fusion for Fast Large Language Model Serving](https://arxiv.org/abs/2511.17560)
*Yuechi Zhou,Yi Su,Jianxin Zhang,Juntao Li,Qingrong Xia,Zhefeng Wang,Xinyu Duan,Baoxing Huai*

Main category: cs.CL

TL;DR: 提出了A³算法，通过基于问题相关性预计算和选择性融合文本块的KV缓存，在减少解码延迟的同时保持最佳任务性能


<details>
  <summary>Details</summary>
Motivation: LLMs处理长上下文时解码延迟和内存开销仍然很大，现有的KV缓存重用方法存在性能下降问题

Method: A³算法：基于注意力机制预计算文本块的KV缓存，根据与问题的相关性选择性融合，实现准确集成和最小计算开销

Result: 在各种基准测试和LLMs上，A³相比四个基线方法获得最佳任务性能，同时将首token时间减少2倍

Conclusion: A³算法有效解决了KV缓存重用中的性能下降问题，在保持任务性能的同时显著降低解码延迟

Abstract: Large language models (LLMs) have demonstrated strong capabilities in processing long contexts, enabling them to tackle tasks involving long textual inputs such as multi-turn conversations, legal documents, or retrieved documents in Retrieval-Augmented Generation (RAG) systems. However, despite their ability to handle long sequences, the resulting decoding latency and memory overhead remain substantial, posing challenges for real-world deployment. Recent advances in KV Cache reuse have shown potential to mitigate these costs, but still suffer from notable performance degradation. To address this issue, we conduct an in-depth investigation of recomputation-based reuse methods and observe that the recomputed tokens often fail to align with the context segments most relevant to the question. This misalignment hinders proper updates to the critical contextual representations. Therefore, we propose the $\textbf{A}$ttention-$\textbf{A}$ware $\textbf{A}$ccurate KV Cache Fusion algorithm ($A^3$), which precomputes and selectively fuses the KV Cache of text chunks based on their relevance to the question, achieving accurate integration with minimal computational overhead. Extensive experiments on various benchmarks and LLMs demonstrate that $A^3$ achieves the best task performance compared to four baselines while reducing the time-to-first-token (TTFT) by 2$\times$.

</details>


### [3] [LexInstructEval: Lexical Instruction Following Evaluation for Large Language Models](https://arxiv.org/abs/2511.17561)
*Huimin Ren,Yan Liang,Baiqiao Su,Chaobo Sun,Hengtong Lu,Kaike Zhang,Chen Wei*

Main category: cs.CL

TL;DR: LexInstructEval是一个新的基准测试和评估框架，用于评估大语言模型在细粒度词汇指令遵循方面的能力，通过基于规则的语法将复杂指令解构为<过程、关系、值>三元组。


<details>
  <summary>Details</summary>
Motivation: 当前评估大语言模型精确遵循复杂词汇指令能力的方法存在局限性：人工评估主观且昂贵，自动化LLM-as-a-judge系统存在固有偏见和不可靠性，而现有编程基准缺乏表达复杂组合约束的细粒度测试能力。

Method: 构建基于形式化规则语法的评估框架，将复杂指令解构为<过程、关系、值>三元组；通过多阶段人工参与流程系统生成多样化数据集；使用透明、程序化的验证引擎进行客观评估。

Result: 开发了LexInstructEval基准测试框架和数据集，提供了客观评估大语言模型词汇指令遵循能力的新方法。

Conclusion: LexInstructEval为研究大语言模型的可控性和可靠性提供了新的评估工具，发布的开放数据集和评估工具将促进该领域的进一步研究。

Abstract: The ability of Large Language Models (LLMs) to precisely follow complex and fine-grained lexical instructions is a cornerstone of their utility and controllability. However, evaluating this capability remains a significant challenge. Current methods either rely on subjective and costly human evaluation or on automated LLM-as-a-judge systems, which suffer from inherent biases and unreliability. Existing programmatic benchmarks, while objective, often lack the expressiveness to test intricate, compositional constraints at a granular level. To address these limitations, we introduce LexInstructEval, a new benchmark and evaluation framework for fine-grained lexical instruction following. Our framework is built upon a formal, rule-based grammar that deconstructs complex instructions into a canonical <Procedure, Relation, Value> triplet. This grammar enables the systematic generation of a diverse dataset through a multi-stage, human-in-the-loop pipeline and facilitates objective verification via a transparent, programmatic engine. We release our dataset and open-source evaluation tools to facilitate further research into the controllability and reliability of LLMs.

</details>


### [4] [ChineseErrorCorrector3-4B: State-of-the-Art Chinese Spelling and Grammar Corrector](https://arxiv.org/abs/2511.17562)
*Wei Tian,YuhaoZhou*

Main category: cs.CL

TL;DR: 基于Qwen3-4B的中文拼写和语法纠错统一模型，在多个权威基准测试中取得最优性能


<details>
  <summary>Details</summary>
Motivation: 开发一个统一的中文拼写和语法纠错模型，提升中文文本纠错的整体性能

Method: 基于Qwen3-4B构建统一的中文错误纠正模型ChineseErrorCorrector3-4B

Result: 在SIGHAN-2015、EC-LAW、MCSC和NaCGEC等基准测试中，F1和F0.5分数显著超越现有公开模型，在拼写和语法纠错任务中均排名第一

Conclusion: 该模型在中文拼写和语法纠错方面表现出色，达到了最先进的性能水平

Abstract: This paper introduces ChineseErrorCorrector3-4B, a unified model for Chinese spelling and grammatical error correction based on Qwen3-4B. The model demonstrates outstanding performance in general text correction tasks and achieves state-of-the-art results in both spelling correction (CSC) and grammatical correction (CGC). On several authoritative benchmark datasets -- including SIGHAN-2015, EC-LAW, MCSC, and NaCGEC -- the model's F1 and F0.5 scores significantly surpass existing publicly available models, ranking first in both spelling and grammatical error correction tasks.

</details>


### [5] [Generative Caching for Structurally Similar Prompts and Responses](https://arxiv.org/abs/2511.17565)
*Sarthak Chakraborty,Suman Nath,Xuchao Zhang,Chetan Bansal,Indranil Gupta*

Main category: cs.CL

TL;DR: 提出了一个名为\ourmethod{}的生成式缓存系统，用于处理结构相似但存在细微差异的提示，通过识别可重用的响应模式并为新请求合成定制化输出。


<details>
  <summary>Details</summary>
Motivation: 在可重复工作流和智能体场景中，提示通常会被重复使用且只有细微变化，但精确匹配会失败，而语义缓存可能忽略关键差异导致错误响应。

Method: \ourmethod{}识别相似提示结构中的可重用响应模式，并为新请求合成定制化输出。

Result: 在无提示重复的数据集上达到83%的缓存命中率且错误命中率极低；在智能体工作流中，相比标准提示匹配，缓存命中率提高约20%，端到端执行延迟降低约34%。

Conclusion: \ourmethod{}能够有效处理结构相似提示的缓存问题，显著提高缓存命中率和系统性能。

Abstract: Large Language Models (LLMs) are increasingly being used to plan, reason, and execute tasks across diverse scenarios. In use cases like repeatable workflows and agentic settings, prompts are often reused with minor variations while having a similar structure for recurring tasks. This opens up opportunities for caching. However, exact prompt matching fails on such structurally similar prompts, while semantic caching may produce incorrect responses by ignoring critical differences. To address this, we introduce \ourmethod{}, a generative cache that produces variation-aware responses for structurally similar prompts. \ourmethod{} identifies reusable response patterns across similar prompt structures and synthesizes customized outputs for new requests. We show that \ourmethod{} achieves 83\% cache hit rate, while having minimal incorrect hits on datasets without prompt repetition. In agentic workflows, it improves cache hit rate by $\sim$20\% and reduces end-to-end execution latency by $\sim$34\% compared to standard prompt matching.

</details>


### [6] [Community-Aligned Behavior Under Uncertainty: Evidence of Epistemic Stance Transfer in LLMs](https://arxiv.org/abs/2511.17572)
*Patrick Gerard,Aiden Chang,Svitlana Volkova*

Main category: cs.CL

TL;DR: 该研究通过事件知识删除框架测试LLMs在社区对齐后的认知立场迁移能力，发现在即使删除事实知识后，对齐的LLMs仍能保持社区特定的不确定性处理行为模式。


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型在特定社区对齐后，是表现出可泛化的行为模式反映社区态度，还是仅仅回忆训练数据中的模式。

Method: 引入认知立场迁移测试框架：通过针对性删除事件知识并验证，然后评估模型在无知状态下是否仍能重现社区的有机响应模式。使用俄罗斯-乌克兰军事讨论和美国党派Twitter数据进行实验。

Result: 即使经过激进的事实删除，对齐的LLMs仍保持稳定的社区特定行为模式来处理不确定性。

Conclusion: 对齐编码了超越表面模仿的结构化、可泛化行为，该框架为检测在无知状态下持续存在的行为偏差提供了系统方法，有助于更安全透明的LLM部署。

Abstract: When large language models (LLMs) are aligned to a specific online community, do they exhibit generalizable behavioral patterns that mirror that community's attitudes and responses to new uncertainty, or are they simply recalling patterns from training data? We introduce a framework to test epistemic stance transfer: targeted deletion of event knowledge, validated with multiple probes, followed by evaluation of whether models still reproduce the community's organic response patterns under ignorance. Using Russian--Ukrainian military discourse and U.S. partisan Twitter data, we find that even after aggressive fact removal, aligned LLMs maintain stable, community-specific behavioral patterns for handling uncertainty. These results provide evidence that alignment encodes structured, generalizable behaviors beyond surface mimicry. Our framework offers a systematic way to detect behavioral biases that persist under ignorance, advancing efforts toward safer and more transparent LLM deployments.

</details>


### [7] [Random Text, Zipf's Law, Critical Length,and Implications for Large Language Models](https://arxiv.org/abs/2511.17575)
*Vladimir Berman*

Main category: cs.CL

TL;DR: 该论文建立了一个完全非语言学的文本模型，通过独立抽取有限字母表加空格符号来研究文本结构。推导出单词长度呈几何分布，词汇增长和词频分布的闭式表达式，并得到Zipf型秩频定律。


<details>
  <summary>Details</summary>
Motivation: 为自然语言和大型语言模型中的词汇统计提供一个结构化的零模型，证明Zipf模式可以纯粹从组合学和分割中产生，无需优化原则或语言组织。

Method: 使用有限字母表加空格符号的独立抽取模型，定义单词为非空格符号的最大块。通过几何分布、优惠券收集论证和组合分析推导结构结果。

Result: 单词长度服从几何分布；词汇增长和词频分布有闭式表达式；存在临界词长k*；得到Zipf型秩频定律p(r) ∝ r^{-α}，指数由字母表大小和空格概率确定。

Conclusion: 该模型为语言统计提供了结构化的零模型，表明Zipf模式可能源于随机文本结构，有助于识别需要更深层解释的语言现象。

Abstract: We study a deliberately simple, fully non-linguistic model of text: a sequence of independent draws from a finite alphabet of letters plus a single space symbol. A word is defined as a maximal block of non-space symbols. Within this symbol-level framework, which assumes no morphology, syntax, or semantics, we derive several structural results. First, word lengths follow a geometric distribution governed solely by the probability of the space symbol. Second, the expected number of words of a given length, and the expected number of distinct words of that length, admit closed-form expressions based on a coupon-collector argument. This yields a critical word length k* at which word types transition from appearing many times on average to appearing at most once. Third, combining the exponential growth of the number of possible strings of length k with the exponential decay of the probability of each string, we obtain a Zipf-type rank-frequency law p(r) proportional to r^{-alpha}, with an exponent determined explicitly by the alphabet size and the space probability.
  Our contribution is twofold. Mathematically, we give a unified derivation linking word lengths, vocabulary growth, critical length, and rank-frequency structure in a single explicit model. Conceptually, we argue that this provides a structurally grounded null model for both natural-language word statistics and token statistics in large language models. The results show that Zipf-like patterns can arise purely from combinatorics and segmentation, without optimization principles or linguistic organization, and help clarify which phenomena require deeper explanation beyond random-text structure.

</details>


### [8] [Computational frame analysis revisited: On LLMs for studying news coverage](https://arxiv.org/abs/2511.17746)
*Sharaj Kunjar,Alyssa Hasegawa Smith,Tyler R Mckenzie,Rushali Mohbe,Samuel V Scarpino,Brooke Foucault Welles*

Main category: cs.CL

TL;DR: 评估生成式LLM在媒体框架分析中的效果，发现其表现不如人工编码员，在某些情况下甚至不如小型语言模型，需要人工验证来选择合适的模型。


<details>
  <summary>Details</summary>
Motivation: 研究生成式LLM（如GPT和Claude）作为内容分析工具在媒体框架识别中的有效性，与传统计算方法和人工编码进行比较。

Method: 使用新颖的金标准数据集，系统评估生成式LLM与词袋模型、编码器转换器以及传统人工编码程序在MPox疫情新闻报道框架分析中的表现。

Result: 生成式LLM在某些应用中具有潜力，但总体上表现不如人工编码员，有时甚至不如小型语言模型，需要人工验证来确定合适的模型选择。

Conclusion: 支持方法论多元主义方法，提出了计算框架分析的研究路线图，建议研究人员利用这些方法的互补性来协同使用。

Abstract: Computational approaches have previously shown various promises and pitfalls when it comes to the reliable identification of media frames. Generative LLMs like GPT and Claude are increasingly being used as content analytical tools, but how effective are they for frame analysis? We address this question by systematically evaluating them against their computational predecessors: bag-of-words models and encoder-only transformers; and traditional manual coding procedures. Our analysis rests on a novel gold standard dataset that we inductively and iteratively developed through the study, investigating six months of news coverage of the US Mpox epidemic of 2022. While we discover some potential applications for generative LLMs, we demonstrate that they were consistently outperformed by manual coders, and in some instances, by smaller language models. Some form of human validation was always necessary to determine appropriate model choice. Additionally, by examining how the suitability of various approaches depended on the nature of different tasks that were part of our frame analytical workflow, we provide insights as to how researchers may leverage the complementarity of these approaches to use them in tandem. We conclude by endorsing a methodologically pluralistic approach and put forth a roadmap for computational frame analysis for researchers going forward.

</details>


### [9] [PoETa v2: Toward More Robust Evaluation of Large Language Models in Portuguese](https://arxiv.org/abs/2511.17808)
*Thales Sales Almeida,Rodrigo Nogueira,Hélio Pedrini*

Main category: cs.CL

TL;DR: PoETa v2是对葡萄牙语最全面的LLM评估基准，包含40多个任务，评估了20多个模型，揭示了计算投入和语言适应对葡萄牙语性能的影响。


<details>
  <summary>Details</summary>
Motivation: LLM在不同语言和文化背景下的性能差异显著，需要系统性地评估多种语言，特别是葡萄牙语。

Method: 引入PoETa v2基准，包含40多个葡萄牙语任务，评估了20多个不同训练规模和计算资源的模型。

Result: 研究发现计算投资和语言特定适应显著影响葡萄牙语性能，并分析了与英语任务的性能差距。

Conclusion: PoETa v2为葡萄牙语建模和评估的未来研究奠定了基础，基准已在GitHub上开源。

Abstract: Large Language Models (LLMs) exhibit significant variations in performance across linguistic and cultural contexts, underscoring the need for systematic evaluation in diverse languages. In this work, we present the most extensive evaluation of LLMs for the Portuguese language to date. Leveraging our newly introduced PoETa v2 benchmark -- a comprehensive suite of over 40 tasks in Portuguese -- we assess more than 20 models covering a broad spectrum of training scales and computational resources. Our study reveals how computational investment and language-specific adaptation impact performance in Portuguese, while also analyzing performance gaps in comparison to equivalent tasks in English. Through this benchmark and analysis, PoETa v2 lays the groundwork for future research on Portuguese language modeling and evaluation. The benchmark is available at https://github.com/PoETaV2/PoETaV2.

</details>


### [10] [Point of Order: Action-Aware LLM Persona Modeling for Realistic Civic Simulation](https://arxiv.org/abs/2511.17813)
*Scott Merrill,Shashank Srivastava*

Main category: cs.CL

TL;DR: 提出一个可复现的流程，将Zoom公开录音转换为带说话者身份标签的转录本，包含人物档案和语用行为标签，用于训练更真实的多人审议模拟模型。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型能模拟多方审议，但缺乏说话者身份数据限制了真实建模。ASR生成的匿名说话者标签无法捕捉一致的人类行为。

Method: 开发可复现流程处理Zoom录音，生成带说话者身份标签的转录本，包含人物档案和语用行为标签。发布三个地方政府审议数据集，并用这些"行为感知"数据微调LLMs。

Result: 使用该方法微调的模型困惑度降低67%，说话者忠实度和真实性的分类器性能指标几乎翻倍。图灵式人类评估显示模拟与真实审议难以区分。

Conclusion: 该方法为复杂真实公民模拟提供了实用且可扩展的方案，能有效提升审议模拟的真实性。

Abstract: Large language models offer opportunities to simulate multi-party deliberation, but realistic modeling remains limited by a lack of speaker-attributed data. Transcripts produced via automatic speech recognition (ASR) assign anonymous speaker labels (e.g., Speaker_1), preventing models from capturing consistent human behavior. This work introduces a reproducible pipeline to transform public Zoom recordings into speaker-attributed transcripts with metadata like persona profiles and pragmatic action tags (e.g., [propose_motion]). We release three local government deliberation datasets: Appellate Court hearings, School Board meetings, and Municipal Council sessions. Fine-tuning LLMs to model specific participants using this "action-aware" data produces a 67% reduction in perplexity and nearly doubles classifier-based performance metrics for speaker fidelity and realism. Turing-style human evaluations show our simulations are often indistinguishable from real deliberations, providing a practical and scalable method for complex realistic civic simulations.

</details>


### [11] [A superpersuasive autonomous policy debating system](https://arxiv.org/abs/2511.17854)
*Allen Roush,Devin Gonier,John Hines,Judah Goldfeder,Philippe Martin Wyder,Sanjay Basu,Ravid Shwartz Ziv*

Main category: cs.CL

TL;DR: DeepDebater是一个能够参与并赢得完整政策辩论的自主系统，采用分层多智能体架构，结合大规模证据库和AI语音动画技术，在模拟辩论中表现优于人类辩手。


<details>
  <summary>Details</summary>
Motivation: 解决AI在复杂、基于证据且具有战略适应性的说服能力方面的重大挑战，超越之前简化的辩论系统，实现完整的政策辩论能力。

Method: 采用分层多智能体工作流架构，LLM驱动的智能体团队协作执行特定论证任务，使用大规模政策辩论证据库进行迭代检索、合成和自校正，生成完整辩论内容。

Result: 在初步评估中，DeepDebater产生的论证组件质量优于人类撰写案例，在模拟辩论中持续获胜，专家辩论教练也更偏好其构建的论点、证据和案例。

Conclusion: DeepDebater展示了AI在复杂辩论任务中的强大能力，支持全自主和混合人机操作模式，为AI说服系统的发展提供了重要进展。

Abstract: The capacity for highly complex, evidence-based, and strategically adaptive persuasion remains a formidable great challenge for artificial intelligence. Previous work, like IBM Project Debater, focused on generating persuasive speeches in simplified and shortened debate formats intended for relatively lay audiences. We introduce DeepDebater, a novel autonomous system capable of participating in and winning a full, unmodified, two-team competitive policy debate. Our system employs a hierarchical architecture of specialized multi-agent workflows, where teams of LLM-powered agents collaborate and critique one another to perform discrete argumentative tasks. Each workflow utilizes iterative retrieval, synthesis, and self-correction using a massive corpus of policy debate evidence (OpenDebateEvidence) and produces complete speech transcripts, cross-examinations, and rebuttals. We introduce a live, interactive end-to-end presentation pipeline that renders debates with AI speech and animation: transcripts are surface-realized and synthesized to audio with OpenAI TTS, and then displayed as talking-head portrait videos with EchoMimic V1. Beyond fully autonomous matches (AI vs AI), DeepDebater supports hybrid human-AI operation: human debaters can intervene at any stage, and humans can optionally serve as opponents against AI in any speech, allowing AI-human and AI-AI rounds. In preliminary evaluations against human-authored cases, DeepDebater produces qualitatively superior argumentative components and consistently wins simulated rounds as adjudicated by an independent autonomous judge. Expert human debate coaches also prefer the arguments, evidence, and cases constructed by DeepDebater. We open source all code, generated speech transcripts, audio and talking head video here: https://github.com/Hellisotherpeople/DeepDebater/tree/main

</details>


### [12] [Principled Context Engineering for RAG: Statistical Guarantees via Conformal Prediction](https://arxiv.org/abs/2511.17908)
*Debashish Chakraborty,Eugene Yang,Daniel Khashabi,Dawn Lawrie,Kevin Duh*

Main category: cs.CL

TL;DR: 本文提出了一种基于保形预测的上下文过滤方法，用于控制RAG系统中保留证据的覆盖率，在减少上下文长度的同时保持事实准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的RAG系统在长文本或噪声上下文中准确率下降，而预生成过滤器缺乏对保留证据的统计控制。

Method: 使用保形预测框架，通过嵌入和LLM评分函数对检索到的证据进行覆盖率控制的过滤，在NeuCLIR和RAGTIME数据集上测试。

Result: 保形过滤始终达到目标覆盖率，将保留上下文减少2-3倍，在严格过滤下ARGUE F1得分提高，中等覆盖率下保持稳定。

Conclusion: 保形预测为RAG提供了可靠、覆盖率控制的上下文缩减方法，是一种模型无关且原则性的上下文工程方法。

Abstract: Retrieval-Augmented Generation (RAG) enhances factual grounding in large language models (LLMs) by incorporating retrieved evidence, but LLM accuracy declines when long or noisy contexts exceed the model's effective attention span. Existing pre-generation filters rely on heuristics or uncalibrated LLM confidence scores, offering no statistical control over retained evidence. We evaluate and demonstrate context engineering through conformal prediction, a coverage-controlled filtering framework that removes irrelevant content while preserving recall of supporting evidence. Using both embedding- and LLM-based scoring functions, we test this approach on the NeuCLIR and RAGTIME collections. Conformal filtering consistently meets its target coverage, ensuring that a specified fraction of relevant snippets are retained, and reduces retained context by 2-3x relative to unfiltered retrieval. On NeuCLIR, downstream factual accuracy measured by ARGUE F1 improves under strict filtering and remains stable at moderate coverage, indicating that most discarded material is redundant or irrelevant. These results demonstrate that conformal prediction enables reliable, coverage-controlled context reduction in RAG, offering a model-agnostic and principled approach to context engineering.

</details>


### [13] [L2V-CoT: Cross-Modal Transfer of Chain-of-Thought Reasoning via Latent Intervention](https://arxiv.org/abs/2511.17910)
*Yuliang Zhan,Xinyu Tang,Han Wan,Jian Li,Ji-Rong Wen,Hao Sun*

Main category: cs.CL

TL;DR: L2V-CoT是一种无需训练的潜在干预方法，通过线性人工层析发现LLMs和VLMs在CoT推理中共享相似的低频潜在表示，从而将LLMs的CoT推理能力转移到VLMs。


<details>
  <summary>Details</summary>
Motivation: 尽管CoT推理显著提升了LLMs的能力，但VLMs在多步推理任务中仍表现不佳，现有方法需要高训练成本或架构对齐。

Method: 使用线性人工层析验证LLMs和VLMs共享相似的低频CoT潜在表示，提出L2V-CoT方法在频域提取和重采样LLMs的低频CoT表示，在推理时进行维度匹配和潜在注入。

Result: 大量实验表明，该方法在无需训练的方法中表现最佳，甚至超越了一些监督学习方法。

Conclusion: LLMs和VLMs在CoT推理中共享相似的潜在表示，L2V-CoT提供了一种高效、无需训练的方法来提升VLMs的推理能力。

Abstract: Recently, Chain-of-Thought (CoT) reasoning has significantly enhanced the capabilities of large language models (LLMs), but Vision-Language Models (VLMs) still struggle with multi-step reasoning tasks due to limited multimodal reasoning data. To bridge this gap, researchers have explored methods to transfer CoT reasoning from LLMs to VLMs. However, existing approaches either need high training costs or require architectural alignment. In this paper, we use Linear Artificial Tomography (LAT) to empirically show that LLMs and VLMs share similar low-frequency latent representations of CoT reasoning despite architectural differences. Based on this insight, we propose L2V-CoT, a novel training-free latent intervention approach that transfers CoT reasoning from LLMs to VLMs. L2V-CoT extracts and resamples low-frequency CoT representations from LLMs in the frequency domain, enabling dimension matching and latent injection into VLMs during inference to enhance reasoning capabilities. Extensive experiments demonstrate that our approach consistently outperforms training-free baselines and even surpasses supervised methods.

</details>


### [14] [Towards Efficient LLM-aware Heterogeneous Graph Learning](https://arxiv.org/abs/2511.17923)
*Wenda Li,Tongya Zheng,Shunyu Liu,Yu Wang,Kaixuan Chen,Hanyang Yuan,Bingde Hu,Zujie Ren,Mingli Song,Gang Chen*

Main category: cs.CL

TL;DR: 提出ELLA框架，利用大语言模型处理异质图的复杂关系语义，通过关系分词器和跳级关系图变换器降低计算复杂度，并在四个异质图上验证了其优越性能和效率。


<details>
  <summary>Details</summary>
Motivation: 异质图中节点和关系类型的多样性导致复杂语义，现有方法受限于预定义语义依赖和监督信号稀缺，而大语言模型虽能解决语义问题但计算复杂度高。

Method: 提出LLM感知关系分词器编码多跳多类型关系，使用跳级关系图变换器将LLM感知关系推理复杂度从指数降为线性，引入细粒度任务感知文本链式思维提示。

Result: 在四个异质图上实验表明，ELLA在性能和效率上优于最先进方法，可扩展到130亿参数LLM，相比现有LLM方法提速4倍。

Conclusion: ELLA框架有效解决了异质图复杂关系语义建模问题，同时显著降低了计算复杂度，为LLM在异质图分析中的应用提供了高效解决方案。

Abstract: Heterogeneous graphs are widely present in real-world complex networks, where the diversity of node and relation types leads to complex and rich semantics. Efforts for modeling complex relation semantics in heterogeneous graphs are restricted by the limitations of predefined semantic dependencies and the scarcity of supervised signals. The advanced pre-training and fine-tuning paradigm leverages graph structure to provide rich self-supervised signals, but introduces semantic gaps between tasks. Large Language Models (LLMs) offer significant potential to address the semantic issues of relations and tasks in heterogeneous graphs through their strong reasoning capabilities in textual modality, but their incorporation into heterogeneous graphs is largely limited by computational complexity. Therefore, in this paper, we propose an Efficient LLM-Aware (ELLA) framework for heterogeneous graphs, addressing the above issues. To capture complex relation semantics, we propose an LLM-aware Relation Tokenizer that leverages LLM to encode multi-hop, multi-type relations. To reduce computational complexity, we further employ a Hop-level Relation Graph Transformer, which help reduces the complexity of LLM-aware relation reasoning from exponential to linear. To bridge semantic gaps between pre-training and fine-tuning tasks, we introduce the fine-grained task-aware textual Chain-of-Thought (CoT) prompts. Extensive experiments on four heterogeneous graphs show that our proposed ELLA outperforms state-of-the-art methods in the performance and efficiency. In particular, ELLA scales up to 13b-parameter LLMs and achieves up to a 4x speedup compared with existing LLM-based methods. Our code is publicly available at https://github.com/l-wd/ELLA.

</details>


### [15] [SPINE: Token-Selective Test-Time Reinforcement Learning with Entropy-Band Regularization](https://arxiv.org/abs/2511.17938)
*Jianghao Wu,Yasmeen George,Jin Ye,Yicheng Wu,Daniel F. Schmidt,Jianfei Cai*

Main category: cs.CL

TL;DR: SPINE是一个基于令牌选择的测试时强化学习框架，通过只更新高熵分支点令牌来避免TTRL方法中的响应长度崩溃问题，在多个推理基准上稳定提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有的测试时强化学习方法存在分布偏移和缺乏可验证监督的问题，且容易发生响应长度崩溃和Pass@1下降。

Method: 提出SPINE框架：(i)只更新分叉令牌（高熵分支点）(ii)在分叉令牌处应用熵带正则化器来维持探索和抑制噪声监督。

Result: 在十个基准测试中，SPINE持续改善Pass@1，避免响应长度崩溃，并在LLM和MLLM骨干网络上产生更稳定的训练动态。

Conclusion: 将更新与思维链分支点对齐是推理模型中稳定有效测试时适应的简单且无标签机制。

Abstract: Large language models (LLMs) and multimodal LLMs (MLLMs) excel at chain-of-thought reasoning but face distribution shift at test-time and a lack of verifiable supervision. Recent test-time reinforcement learning (TTRL) methods derive label-free pseudo-rewards from self-consistency voting over sampled trajectories, yet they often collapse: the majority-vote reward prevails, responses shorten, and Pass@1 declines. We trace this to uniform sequence updates in which most tokens are low-entropy followers, while a small high-entropy subset determines the reasoning branches. Thus we propose SPINE, a token-selective test-time reinforcement learning framework that (i) updates only forking tokens, the high-entropy branch points identified from forward-pass statistics, and (ii) applies an entropy-band regularizer at those tokens to sustain exploration when entropy is too low and to suppress noisy supervision when it is too high. SPINE plugs into GRPO-style objectives, optionally with a KL anchor, and requires no labels or reward models. Across ten benchmarks spanning multimodal VQA, general and expert QA, mathematical reasoning, and medical QA, SPINE consistently improves Pass@1 over TTRL while avoiding response-length collapse and yielding more stable training dynamics on both LLM and MLLM backbones. These results indicate that aligning updates with chain-of-thought branch points is a simple and label-free mechanism for stable and effective test-time adaptation in reasoning models. Code is available at https://github.com/JianghaoWu/SPINE.

</details>


### [16] [Measuring the Impact of Lexical Training Data Coverage on Hallucination Detection in Large Language Models](https://arxiv.org/abs/2511.17946)
*Shuo Zhang,Fabrizio Gotti,Fengran Mo,Jian-Yun Nie*

Main category: cs.CL

TL;DR: 本文研究了预训练数据覆盖度作为大语言模型幻觉检测的补充信号，发现词汇覆盖特征虽然单独使用时预测能力较弱，但与对数概率结合时能在高不确定性数据集上带来适度提升。


<details>
  <summary>Details</summary>
Motivation: 探索预训练数据暴露与幻觉之间的关系，研究问题/生成答案的词汇训练数据覆盖度是否能提供额外的幻觉检测信号，这是现有研究中被忽视的方向。

Method: 在RedPajama的1.3万亿token预训练语料上构建可扩展后缀数组，检索提示和模型生成的n-gram统计信息，并在三个QA基准上评估其幻觉检测效果。

Result: 基于出现频率的特征单独使用时是弱预测器，但与对数概率结合时能在内在模型不确定性较高的数据集上产生适度增益。

Conclusion: 词汇覆盖特征为幻觉检测提供了补充信号，特别是在模型不确定性较高的情况下。

Abstract: Hallucination in large language models (LLMs) is a fundamental challenge, particularly in open-domain question answering. Prior work attempts to detect hallucination with model-internal signals such as token-level entropy or generation consistency, while the connection between pretraining data exposure and hallucination is underexplored. Existing studies show that LLMs underperform on long-tail knowledge, i.e., the accuracy of the generated answer drops for the ground-truth entities that are rare in pretraining. However, examining whether data coverage itself can serve as a detection signal is overlooked. We propose a complementary question: Does lexical training-data coverage of the question and/or generated answer provide additional signal for hallucination detection? To investigate this, we construct scalable suffix arrays over RedPajama's 1.3-trillion-token pretraining corpus to retrieve $n$-gram statistics for both prompts and model generations. We evaluate their effectiveness for hallucination detection across three QA benchmarks. Our observations show that while occurrence-based features are weak predictors when used alone, they yield modest gains when combined with log-probabilities, particularly on datasets with higher intrinsic model uncertainty. These findings suggest that lexical coverage features provide a complementary signal for hallucination detection. All code and suffix-array infrastructure are provided at https://github.com/WWWonderer/ostd.

</details>


### [17] [MTikGuard System: A Transformer-Based Multimodal System for Child-Safe Content Moderation on TikTok](https://arxiv.org/abs/2511.17955)
*Dat Thanh Nguyen,Nguyen Hung Lam,Anh Hoang-Thi Nguyen,Trong-Hop Do*

Main category: cs.CL

TL;DR: MTikGuard是一个针对TikTok的实时多模态有害内容检测系统，通过扩展数据集、多模态特征融合和可扩展流式架构，实现了89.37%的准确率和89.45%的F1分数。


<details>
  <summary>Details</summary>
Motivation: TikTok作为儿童和青少年中最有影响力的平台之一，其有害内容可能影响用户认知和行为，而传统审核方法难以应对海量实时上传内容的挑战。

Method: 提出了MTikGuard系统：扩展TikHarm数据集至4,723个标注视频；构建集成视觉、音频和文本特征的多模态分类框架；基于Apache Kafka和Apache Spark构建可扩展的流式架构。

Result: 系统实现了89.37%的准确率和89.45%的F1分数，达到了最先进的性能水平。

Conclusion: 研究表明，结合数据集扩展、先进的多模态融合和稳健的部署策略，能够有效实现大规模社交媒体内容的实际审核。

Abstract: With the rapid rise of short-form videos, TikTok has become one of the most influential platforms among children and teenagers, but also a source of harmful content that can affect their perception and behavior. Such content, often subtle or deceptive, challenges traditional moderation methods due to the massive volume and real-time nature of uploads. This paper presents MTikGuard, a real-time multimodal harmful content detection system for TikTok, with three key contributions: (1) an extended TikHarm dataset expanded to 4,723 labeled videos by adding diverse real-world samples, (2) a multimodal classification framework integrating visual, audio, and textual features to achieve state-of-the-art performance with 89.37% accuracy and 89.45% F1-score, and (3) a scalable streaming architecture built on Apache Kafka and Apache Spark for real-time deployment. The results demonstrate the effectiveness of combining dataset expansion, advanced multimodal fusion, and robust deployment for practical large-scale social media content moderation. The dataset is available at https://github.com/ntdat-8324/MTikGuard-System.git.

</details>


### [18] [Blu-WERP (Web Extraction and Refinement Pipeline): A Scalable Pipeline for Preprocessing Large Language Model Datasets](https://arxiv.org/abs/2511.18054)
*Gowtham,Sai Rupesh,Sanjay Kumar,Saravanan,Venkata Chaithanya*

Main category: cs.CL

TL;DR: Blu-WERP是一种新颖的数据预处理流水线，专门优化Common Crawl WARC文件的质量，用于LLM训练。相比现有基准方法，它在多个模型规模和评估基准上都显著提升了性能，同时降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有预处理流水线在处理网络规模语料时难以有效去除噪声和非结构化内容，这影响了LLM的训练质量。需要开发更有效的数据预处理方法来优化训练数据质量。

Method: Blu-WERP处理CC WARC转储文件，实现了先进的过滤和质量评估机制，通过优化数据预处理流程来提升LLM训练数据质量。

Result: 在150M到1B参数的多个模型规模上，Blu-WERP在九个标准基准测试中均表现优异。在1B参数规模下，相比DCLM和Fineweb分别实现了4.0%和9.5%的总体性能提升，并在世界知识与推理、语言理解、常识推理三个类别中分别提升了2.4%、6.2%和4.2%。

Conclusion: Blu-WERP代表了数据预处理流水线的最先进技术，显著提高了LLM训练数据质量和下游模型性能，同时降低了计算成本，为数据为中心的AI研究提供了实用解决方案。

Abstract: High-quality training data is fundamental to large language model (LLM) performance, yet existing preprocessing pipelines often struggle to effectively remove noise and unstructured content from web-scale corpora. This paper presents Blu-WERP, a novel data preprocessing pipeline designed to optimize the quality of Common Crawl WARC files for LLM training. We demonstrate that Blu-WERP significantly outperforms established baselines including DCLM across multiple model scales and evaluation benchmarks. Our pipeline processes CC WARC dumps, implementing advanced filtering and quality assessment mechanisms. We conducted comprehensive evaluations using models with 150M, 400M, 530M, 750M, and 1B parameters, testing against nine standard benchmarks categorized as World Knowledge & Reasoning, Language Understanding, and Commonsense Reasoning. Results show Blu-WERP consistently achieved superior performance across all model scales. At the 1B parameter scale, Relatively Blu-WERP demonstrates a 4.0% and 9.5% aggregate improvement over DCLM and Fineweb respectively, while achieving quality-per-token efficiency gain. Categorical analysis reveals 2.4% improvement in World Knowledge & Reasoning, 6.2% improvement in Language Understanding, and 4.2% improvement in Commonsense Reasoning. These results establish Blu-WERP as a state-of-the-art preprocessing pipeline that substantially improves LLM training data quality and downstream model performance with reduced computational cost. Our findings contribute to the growing body of research on data-centric AI, demonstrating that preprocessing pipeline design significantly impacts LLM capabilities. The Blu-WERP pipeline represents a practical advancement in data quality optimization, offering researchers and practitioners an effective solution for improving LLM training efficiency and model performance.

</details>


### [19] [GeeSanBhava: Sentiment Tagged Sinhala Music Video Comment Data Set](https://arxiv.org/abs/2511.18146)
*Yomal De Mel,Nisansa de Silva*

Main category: cs.CL

TL;DR: 本研究创建了GeeSanBhava数据集，这是一个高质量僧伽罗语歌曲评论数据集，基于Russell的效价-唤醒模型进行人工标注，并在零样本学习中取得了0.887的ROC-AUC分数。


<details>
  <summary>Details</summary>
Motivation: 解决僧伽罗语自然语言处理中情感分析数据稀缺的问题，探索基于评论的情感映射对音乐情感识别的重要性，并应对用户生成内容中的偏见挑战。

Method: 从YouTube提取僧伽罗语歌曲评论，由三名独立标注者使用效价-唤醒模型进行人工标注；使用在僧伽罗语新闻评论数据集上预训练的机器学习和深度学习模型进行零样本学习；通过超参数优化构建三层MLP模型。

Result: 标注者间一致性达到84.96%；优化的三层MLP模型（256-128-64神经元配置）在零样本学习中取得0.887的ROC-AUC分数；不同歌曲显示出独特的情感特征。

Conclusion: 研究贡献了有价值的标注数据集，为僧伽罗语NLP和音乐情感识别提供了基础，证明了基于评论的情感分析在音乐情感识别中的有效性。

Abstract: This study introduce GeeSanBhava, a high-quality data set of Sinhala song comments extracted from YouTube manually tagged using Russells Valence-Arousal model by three independent human annotators. The human annotators achieve a substantial inter-annotator agreement (Fleiss kappa = 84.96%). The analysis revealed distinct emotional profiles for different songs, highlighting the importance of comment based emotion mapping. The study also addressed the challenges of comparing comment-based and song-based emotions, mitigating biases inherent in user-generated content. A number of Machine learning and deep learning models were pre-trained on a related large data set of Sinhala News comments in order to report the zero-shot result of our Sinhala YouTube comment data set. An optimized Multi-Layer Perceptron model, after extensive hyperparameter tuning, achieved a ROC-AUC score of 0.887. The model is a three-layer MLP with a configuration of 256, 128, and 64 neurons. This research contributes a valuable annotated dataset and provides insights for future work in Sinhala Natural Language Processing and music emotion recognition.

</details>


### [20] [Vector Arithmetic in Concept and Token Subspaces](https://arxiv.org/abs/2511.18162)
*Sheridan Feucht,Byron Wallace,David Bau*

Main category: cs.CL

TL;DR: 论文展示了如何利用概念归纳头和标记归纳头在LLaMA-2-7b模型中识别具有连贯语义结构的激活子空间，通过注意力权重变换隐藏状态，显著提高了平行四边形算术和词形变换的准确性。


<details>
  <summary>Details</summary>
Motivation: 为了预测下一个标记，LLMs需要表示当前词的语义和表层信息。先前工作已识别出两种能分离这些信息的注意力头类型，本研究旨在利用这些头来识别模型激活中具有连贯语义结构的子空间。

Method: 使用概念归纳头和标记归纳头的注意力权重来变换隐藏状态。概念头用于语义操作（如平行四边形算术），标记头用于表层词形操作（如词形变换）。

Result: 通过概念头变换的隐藏状态在平行四边形算术中达到80%的最近邻准确率，远高于原始隐藏状态的47%。标记头变换也能有效揭示隐藏状态中的表层词信息。

Conclusion: 特定类型的注意力头可以识别模型激活中的语义和表层信息子空间，通过适当的变换能显著提升语义操作和词形变换的性能。

Abstract: In order to predict the next token, LLMs must represent semantic and surface-level information about the current word. Previous work identified two types of attention heads that disentangle this information: (i) Concept induction heads, which copy word meanings, and (ii) Token induction heads, which copy literal token representations (Feucht et al., 2025). We show that these heads can be used to identify subspaces of model activations that exhibit coherent semantic structure in Llama-2-7b. Specifically, when we transform hidden states using the attention weights of concept heads, we are able to more accurately perform parallelogram arithmetic (Mikolov et al., 2013) on the resulting hidden states, e.g., showing that "Athens" - "Greece" + "China" = "Beijing". This transformation allows for much higher nearest-neighbor accuracy (80%) than direct use of raw hidden states (47%). Analogously, we show that token heads allow for transformations that reveal surface-level word information in hidden states, allowing for operations like "coding" - "code" + "dance" = "dancing".

</details>


### [21] [Rethinking Retrieval: From Traditional Retrieval Augmented Generation to Agentic and Non-Vector Reasoning Systems in the Financial Domain for Large Language Models](https://arxiv.org/abs/2511.18177)
*Elias Lumer,Matt Melich,Olivia Zino,Elena Kim,Sara Dieter,Pradeep Honaganahalli Basavaraju,Vamse Kumar Subbiah,James A. Burke,Roberto Hernandez*

Main category: cs.CL

TL;DR: 本文首次系统评估了基于向量的智能RAG与基于层次节点系统在金融文档问答中的表现，发现向量RAG在检索准确性和答案质量方面显著优于层次节点系统，交叉编码器重排和小到大块检索技术能进一步提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有工作缺乏对金融文档中基于向量和非向量RAG架构的系统比较，以及高级RAG技术对检索准确性、答案质量、延迟和成本影响的经验分析。

Method: 比较基于向量的智能RAG（使用混合搜索和元数据过滤）与基于层次节点的系统（无需嵌入遍历文档结构），评估交叉编码器重排和小到大块检索两种增强技术。

Result: 基于向量的智能RAG在1200份SEC文件上的150个问题基准测试中，相比层次节点系统获得68%的胜率；交叉编码器重排在最优参数下MRR@5提升59%；小到大块检索相比基线块划分获得65%胜率，仅增加0.2秒延迟。

Conclusion: 在金融问答系统中应用高级RAG技术可显著提升检索准确性和答案质量，但在生产环境中需要考虑成本与性能的权衡。

Abstract: Recent advancements in Retrieval-Augmented Generation (RAG) have enabled Large Language Models to answer financial questions using external knowledge bases of U.S. SEC filings, earnings reports, and regulatory documents. However, existing work lacks systematic comparison of vector-based and non-vector RAG architectures for financial documents, and the empirical impact of advanced RAG techniques on retrieval accuracy, answer quality, latency, and cost remain unclear. We present the first systematic evaluation comparing vector-based agentic RAG using hybrid search and metadata filtering against hierarchical node-based systems that traverse document structure without embeddings. We evaluate two enhancement techniques applied to the vector-based architecture, i) cross-encoder reranking for retrieval precision, and ii) small-to-big chunk retrieval for context completeness. Across 1,200 SEC 10-K, 10-Q, and 8-K filings on a 150-question benchmark, we measure retrieval metrics (MRR, Recall@5), answer quality through LLM-as-a-judge pairwise comparisons, latency, and preprocessing costs. Vector-based agentic RAG achieves a 68% win rate over hierarchical node-based systems with comparable latency (5.2 compared to 5.98 seconds). Cross-encoder reranking achieves a 59% absolute improvement at optimal parameters (10, 5) for MRR@5. Small-to-big retrieval achieves a 65% win rate over baseline chunking with only 0.2 seconds additional latency. Our findings reveal that applying advanced RAG techniques to financial Q&A systems improves retrieval accuracy, answer quality, and has cost-performance tradeoffs to be considered in production.

</details>


### [22] [Agent-as-a-Graph: Knowledge Graph-Based Tool and Agent Retrieval for LLM Multi-Agent Systems](https://arxiv.org/abs/2511.18194)
*Faheem Nizar,Elias Lumer,Anmol Gulati,Pradeep Honaganahalli Basavaraju,Vamse Kumar Subbiah*

Main category: cs.CL

TL;DR: 提出了Agent-as-a-Graph检索方法，通过知识图谱表示代理和工具，在LiveMCPBenchmark上显著提升了检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有代理、MCP和检索方法通常只匹配单个代理描述，掩盖了每个代理的细粒度工具能力，导致代理选择不理想。

Method: 采用知识图谱检索增强生成方法，将工具及其父代理表示为知识图谱中的节点和边。检索过程包括：向量搜索相关代理和工具节点，应用类型特定的加权互逆排序融合进行重排序，以及在知识图谱中遍历父代理以获得最终代理集合。

Result: 在LiveMCPBenchmark上，Recall@5和nDCG@5分别比现有最优检索器提升了14.9%和14.6%，wRRF优化提升了2.4%。

Conclusion: Agent-as-a-Graph方法通过知识图谱表示和检索策略，有效解决了现有代理检索中细粒度工具能力被掩盖的问题，显著提升了检索性能。

Abstract: Recent advances in Large Language Model Multi-Agent Systems enable scalable orchestration and retrieval of specialized, parallelized subagents, each equipped with hundreds or thousands of Model Context Protocol (MCP) servers and tools. However, existing agent, MCP, and retrieval methods typically match queries against a single agent description, obscuring fine-grained tool capabilities of each agent, resulting in suboptimal agent selection. We introduce Agent-as-a-Graph retrieval, a knowledge graph retrieval augmented generation approach that represents both tools and their parent agents as nodes and edges in a knowledge graph. During retrieval, i) relevant agents and tool nodes are first retrieved through vector search, ii) we apply a type-specific weighted reciprocal rank fusion (wRRF) for reranking tools and agents, and iii) parent agents are traversed in the knowledge graph for the final set of agents. We evaluate Agent-as-a-Graph on the LiveMCPBenchmark, achieving 14.9% and 14.6% improvements in Recall@5 and nDCG@5 over prior state-of-the-art retrievers, and 2.4% improvements in wRRF optimizations.

</details>


### [23] [From Archives to Decisions: Multi-Agent Pharmaceutical Co-Scientist for Traceable Drug Discovery and Reverse Translation](https://arxiv.org/abs/2511.18259)
*Xiaochen Zheng,Alvaro Serra,Ilya Schneider Chernov,Maddalena Marchesi,Eunice Musvasva,Tatyana Y. Doktorova*

Main category: cs.CL

TL;DR: DiscoVerse是一个多智能体协同科学家系统，用于支持药物研发，通过语义检索、跨文档链接和可审计合成来重用罗氏公司的历史研究档案，在180个分子数据集上展示了高召回率和中等精度的性能。


<details>
  <summary>Details</summary>
Motivation: 药物研发积累了大量的异构数据，其中许多来自已终止的项目。重用这些档案对于逆向转化研究具有重要价值，但实际中往往难以实现。

Method: 开发了DiscoVerse多智能体系统，实现语义检索、跨文档链接和可审计合成，在罗氏公司超过40年的研究档案（覆盖180个分子、8.7亿BPE标记）上进行验证。

Result: 在7个基准查询中，DiscoVerse实现了近乎完美的召回率（≥0.99）和中等精度（0.71-0.91），在终止理由和器官特异性毒性评估中显示出忠实、源链接的合成能力。

Conclusion: 这是首个在真实药物数据上系统评估的逆向转化智能体框架，展示了有前景的答案准确性和决策洞察力，为药物研发中的知识重用提供了有效工具。

Abstract: Pharmaceutical research and development has accumulated vast, heterogeneous archives of data. Much of this knowledge stems from discontinued programs, and reusing these archives is invaluable for reverse translation. However, in practice, such reuse is often infeasible. In this work, we introduce DiscoVerse, a multi-agent co-scientist designed to support pharmaceutical research and development. The system implements semantic retrieval, cross-document linking, and auditable synthesis on a large historical corpus from Roche. To validate our approach at real-world scale, we selected a subset of 180 molecules from the Roche research repositories, covering over 0.87 billion BPE tokens and more than four decades of research. Given that automated evaluation metrics are poorly aligned with scientific utility, we evaluate the performance of DiscoVerse using blinded expert evaluation of source-linked outputs. To our knowledge, this is the first agentic framework systematically assessed on real pharmaceutical data for reverse translation, enabled by authorized access to confidential, end-to-end drug-development archives. Our contributions include role-specialized agent designs aligned with scientist workflows; human-in-the-loop support for reverse translation; expert evaluation; and a large-scale demonstration showing promising answer accuracy and decision-making insights. In brief, across seven benchmark queries covering 180 molecules, DiscoVerse achieved near-perfect recall ($\geq 0.99$) with moderate precision ($0.71-0.91$), while qualitative assessments of discontinuation rationale and organ-specific toxicity showed faithful, source-linked synthesis across preclinical and clinical evidence.

</details>


### [24] ["AGI" team at SHROOM-CAP: Data-Centric Approach to Multilingual Hallucination Detection using XLM-RoBERTa](https://arxiv.org/abs/2511.18301)
*Harsh Rathva,Pruthwik Mishra,Shrikant Malviya*

Main category: cs.CL

TL;DR: 本文提出了一种数据中心的策略来解决多语言科学文本幻觉检测中的数据稀缺和不平衡问题，通过统一和平衡五个现有数据集创建了124,821个样本的训练语料，在SHROOM-CAP 2025共享任务中取得了竞争性表现。


<details>
  <summary>Details</summary>
Motivation: 解决多语言科学文本中LLM生成幻觉检测的数据稀缺和类别不平衡问题，特别是在低资源语言的零样本设置下。

Method: 采用数据中心策略，统一和平衡五个现有数据集创建大规模训练语料，然后使用5.6亿参数的XLM-RoBERTa-Large模型进行微调。

Result: 在SHROOM-CAP 2025任务中表现优异：古吉拉特语（零样本语言）获得第2名（事实性F1为0.5107），其余8种语言排名4-6位。

Conclusion: 系统性的数据整理策略能够显著超越单纯的架构创新，特别是在低资源语言的零样本设置中效果尤为明显。

Abstract: The detection of hallucinations in multilingual scientific text generated by Large Language Models (LLMs) presents significant challenges for reliable AI systems. This paper describes our submission to the SHROOM-CAP 2025 shared task on scientific hallucination detection across 9 languages. Unlike most approaches that focus primarily on model architecture, we adopted a data-centric strategy that addressed the critical issue of training data scarcity and imbalance. We unify and balance five existing datasets to create a comprehensive training corpus of 124,821 samples (50% correct, 50% hallucinated), representing a 172x increase over the original SHROOM training data. Our approach fine-tuned XLM-RoBERTa-Large with 560 million parameters on this enhanced dataset, achieves competitive performance across all languages, including \textbf{2nd place in Gujarati} (zero-shot language) with Factuality F1 of 0.5107, and rankings between 4th-6th place across the remaining 8 languages. Our results demonstrate that systematic data curation can significantly outperform architectural innovations alone, particularly for low-resource languages in zero-shot settings.

</details>


### [25] [Table Comprehension in Building Codes using Vision Language Models and Domain-Specific Fine-Tuning](https://arxiv.org/abs/2511.18306)
*Mohammad Aqib,Mohd Hamza,Ying Hei Chui,Qipei Mei*

Main category: cs.CL

TL;DR: 本文比较了两种从建筑规范表格数据中提取信息的方法：直接输入图像到视觉语言模型(VLM)和间接转换图像为LaTeX代码再输入。实验表明直接方法更准确，且通过LoRA微调后性能显著提升，Qwen2.5-VL-3B-Instruct准确率提升超过100%。


<details>
  <summary>Details</summary>
Motivation: 建筑规范包含确保安全和合规的关键信息，但表格数据由于复杂布局、合并单元格和多行表头等特性难以提取。需要开发自动化问答系统来快速准确访问具体规范条款。

Method: 比较两种方法：1) 直接输入页面图像到预训练VLM；2) 间接方法将表格图像转换为LaTeX代码再输入。使用LoRA对VLM进行参数高效微调。

Result: 直接输入方法通常比间接方法准确率更高。经过LoRA微调后，模型性能显著提升，特别是Qwen2.5-VL-3B-Instruct相对准确率提升超过100%。

Conclusion: 参数高效微调方法能够有效适配强大的VLM来理解专业领域中的复杂结构化数据，在建筑规范解释和法规合规方面具有巨大潜力。

Abstract: Building codes contain critical information for ensuring safety, regulatory compliance, and informed decision-making in construction and engineering. Automated question answering systems over such codes enable quick and accurate access to specific regulatory clauses, improving efficiency and reducing errors. Retrieval-Augmented Generation (RAG) systems are essential for this task as they combine the precision of information retrieval with the generative capabilities of language models. However, tabular data are challenging to extract as they often involve complex layouts, merged cells, multi-row headers, and embedded semantic relationships that are not easily captured by traditional natural language processing techniques and Vision Language Models (VLMs). This paper explores and compares two methods for extracting information from tabular data in building codes using several pre-trained VLMs. First, a direct input method is used, where the image of the page is input directly into the VLMs, which are then tasked with answering questions based on the image. Second, an indirect input method is introduced, which involves converting an image of a page containing tables into the LaTeX code and then answering inquires based on the LaTeX-based input. The experiments find that the direct input method generally resulted in higher accuracy than the indirect input method. To further improve the performance, we fine-tuned each VLM using Low Rank Adaptation (LoRA) on a domain-specific tabular dataset. The fine-tuned models exhibited substantial improvements, with Qwen2.5-VL-3B-Instruct achieving relative accuracy gains exceeding 100%. Our results highlight the potential of parameter-efficient fine-tuning methods to adapt powerful VLMs for understanding complex structured data in specialized fields, such as building code interpretation and regulatory compliance.

</details>


### [26] [Path-Constrained Retrieval: A Structural Approach to Reliable LLM Agent Reasoning Through Graph-Scoped Semantic Search](https://arxiv.org/abs/2511.18313)
*Joseph Oladokun*

Main category: cs.CL

TL;DR: 提出路径约束检索(PCR)方法，结合图结构约束和语义搜索，确保检索信息在知识图谱中保持逻辑关系，显著提高LLM代理推理的连贯性和可靠性。


<details>
  <summary>Details</summary>
Motivation: LLM代理从知识库检索上下文时，由于缺乏与当前推理状态的结构一致性，导致推理链不连贯。需要一种能保持逻辑关系的检索方法。

Method: PCR方法将结构图约束与语义搜索相结合，将搜索空间限制为从锚节点可达的节点，防止检索结构断开的信息。

Result: 在PathRAG-6基准测试中，PCR实现100%结构一致性(基线为24-32%)，同时保持强相关性得分。在技术领域，PCR在rank 10时获得完全相关性且完全结构一致，显著优于向量搜索和混合检索。

Conclusion: 路径约束检索是提高LLM代理推理系统可靠性和连贯性的有效方法，检索上下文平均图距离比基线减少78%。

Abstract: Large Language Model agents often retrieve context from knowledge bases that lack structural consistency with the agent's current reasoning state, leading to incoherent reasoning chains. We introduce Path-Constrained Retrieval (PCR), a retrieval method that combines structural graph constraints with semantic search to ensure retrieved information maintains logical relationships within a knowledge graph. PCR restricts the search space to nodes reachable from an anchor node, preventing retrieval of structurally disconnected information that may lead to inconsistent reasoning. We evaluate PCR on PathRAG-6, a benchmark spanning six domains with 180 nodes and 360 edges. Our results show that PCR achieves full structural consistency compared to 24-32 percent in baseline methods, while maintaining strong relevance scores. On the technology domain, PCR obtains full relevance at rank 10 with full structural consistency, significantly outperforming vector search and hybrid retrieval. PCR reduces the average graph distance of retrieved context by 78 percent compared to baselines, demonstrating retrieval of more structurally consistent information. These findings suggest that path-constrained retrieval is an effective approach for improving the reliability and coherence of LLM agent reasoning systems.

</details>


### [27] [Gradient Masters at BLP-2025 Task 1: Advancing Low-Resource NLP for Bengali using Ensemble-Based Adversarial Training for Hate Speech Detection](https://arxiv.org/abs/2511.18324)
*Syed Mohaiminul Hoque,Naimur Rahman,Md Sakhawat Hossain*

Main category: cs.CL

TL;DR: 本文提出了一种基于集成学习的微调策略'Gradient Masters'，用于孟加拉语多任务仇恨言论识别任务，在YouTube评论的仇恨类型分类和目标群体分类两个子任务中取得了优异成绩。


<details>
  <summary>Details</summary>
Motivation: 解决低资源孟加拉语仇恨言论检测的挑战，提高在YouTube评论中识别仇恨言论类型和目标群体的准确性。

Method: 采用集成学习策略对孟加拉语语言模型进行微调，通过广泛的实验评估模型在低资源场景下的鲁棒性和泛化能力。

Result: 在子任务1A中获得第6名（微F1得分73.23%），在子任务1B中获得第3名（微F1得分73.28%），超越了基线模型。

Conclusion: 提出的集成微调方法在孟加拉语仇恨言论检测任务中表现优异，为低资源语言场景下的仇恨言论识别提供了有效解决方案。

Abstract: This paper introduces the approach of "Gradient Masters" for BLP-2025 Task 1: "Bangla Multitask Hate Speech Identification Shared Task". We present an ensemble-based fine-tuning strategy for addressing subtasks 1A (hate-type classification) and 1B (target group classification) in YouTube comments. We propose a hybrid approach on a Bangla Language Model, which outperformed the baseline models and secured the 6th position in subtask 1A with a micro F1 score of 73.23% and the third position in subtask 1B with 73.28%. We conducted extensive experiments that evaluated the robustness of the model throughout the development and evaluation phases, including comparisons with other Language Model variants, to measure generalization in low-resource Bangla hate speech scenarios and data set coverage. In addition, we provide a detailed analysis of our findings, exploring misclassification patterns in the detection of hate speech.

</details>


### [28] [OmniStruct: Universal Text-to-Structure Generation across Diverse Schemas](https://arxiv.org/abs/2511.18335)
*James Y. Huang,Wenxuan Zhou,Nan Xu,Fei Wang,Qin Liu,Sheng Zhang,Hoifung Poon,Muhao Chen*

Main category: cs.CL

TL;DR: OmniStruct是一个评估LLMs在文本到结构任务上能力的综合基准，通过合成数据训练的小模型可以达到GPT-4o的性能水平。


<details>
  <summary>Details</summary>
Motivation: 虽然现代LLMs在生成非结构化自然语言响应方面表现出色，但它们在文本到结构任务上的性能仍不清楚，需要建立一个全面的评估基准。

Method: 通过识别适合结构化答案格式的现有数据集，在统一的文本到结构问题设置下构建OmniStruct基准，并通过合成任务生成收集高质量训练数据。

Result: 实验表明，在不使用OmniStruct任务监督数据的情况下，通过在合成数据上微调更小的模型，可以训练出能够媲美GPT-4o性能的通用结构化生成模型。

Conclusion: OmniStruct基准填补了LLMs在文本到结构任务评估方面的空白，证明了通过合成数据训练小模型实现高效结构化生成的可行性。

Abstract: The ability of Large Language Models (LLMs) to generate structured outputs that follow arbitrary schemas is crucial to a wide range of downstream tasks that require diverse structured representations of results such as information extraction, table generation, and function calling. While modern LLMs excel in generating unstructured responses in natural language, whether this advancement translates to a strong performance on text-to-structure tasks remains unclear. To bridge this gap, we first introduce OmniStruct, a comprehensive benchmark for assessing LLMs' capabilities on diverse text-to-structure tasks such as information extraction, table generation, and function calling. We build OmniStruct by identifying existing datasets across a wide range of tasks that are suitable for a structured answer format, and adapting them under a unified text-to-structure problem setting. To facilitate the development of efficient text-to-structure models, we collect high-quality training data via synthetic task generation. Without using any supervised data for OmniStruct tasks, our experiments demonstrate the possibility of fine-tuning much smaller models on synthetic data into universal structured generation models that can rival the performance of GPT-4o.

</details>


### [29] [Tu crois que c'est vrai ? Diversite des regimes d'enonciation face aux fake news et mecanismes d'autoregulation conversationnelle](https://arxiv.org/abs/2511.18369)
*Manon Berriche*

Main category: cs.CL

TL;DR: 该研究探讨了两个悖论：虚假新闻在社交媒体中占比很小但政治极化加剧。通过混合方法研究发现，虚假新闻主要由少数高度政治化的活跃用户传播，普通用户会采取不同形式的批判性距离，但这些互动很少产生真正的协商辩论。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解释为什么在缺乏编辑控制的社交媒体上，虚假新闻只占信息消费的小部分，以及为什么用户对虚假新闻并不特别接受但政治极化却在加剧这两个悖论。

Method: 采用混合方法设计，结合数字痕迹的定量分析与在线观察和访谈。在Twitter上研究分享虚假新闻的用户特征，在Facebook上研究用户对不确定信息状态声明的反应。

Result: 1) 虚假新闻分享集中在少数高度政治化、批判制度的活跃用户群体；2) 暴露用户会根据社会地位和情境采取不同批判距离形式；3) 这些互动很少产生真正的协商辩论，更多是"聋子对话"。

Conclusion: 虚假新闻的影响不在于广泛传播，而在于被少数高度活跃的政治化用户放大，这些用户的议程设置能力和互动模式加剧了政治极化，而非虚假新闻本身的广泛接受度。

Abstract: This thesis addresses two paradoxes: (1) why empirical studies find that fake news represent only a small share of the information consulted and shared on social media despite the absence of editorial control or journalistic norms, and (2) how political polarization has intensified even though users do not appear especially receptive to fake news. To investigate these issues, two complementary studies were carried out on Twitter and Facebook, combining quantitative analyses of digital traces with online observation and interviews. This mixed-methods design avoids reducing users to single reactions to identified fake items and instead examines the variety of practices across different interactional situations, online and offline, while recording socio-demographic traits. The first study mapped users who shared at least one item labeled fake by fact-checkers in the French Twittersphere. The second used a corpus of items flagged by Facebook users to study reactions to statements whose epistemic status is uncertain. Three main findings emerge. First, sharing fake news is concentrated among a limited group of users who are not less educated or cognitively disadvantaged but are more politicized and critical of institutions; owing to their high activity and prolific sharing, they can help set the agenda for their political camp. Second, exposed users can deploy varying forms of critical distance depending on their social position and the interactional norms of the situations they inhabit: either discursive caution (prudence énonciative) or interventions ('points d'arrêt') that express disagreement or corrections. Third, these forms of critical distance seldom yield genuine deliberative debates or agonistic pluralism; rather, they often produce dialogues of the deaf among a small, particularly active minority.

</details>


### [30] [Towards Robust and Fair Next Visit Diagnosis Prediction under Noisy Clinical Notes with Large Language Models](https://arxiv.org/abs/2511.18393)
*Heejoon Koo*

Main category: cs.CL

TL;DR: 该论文研究了文本质量退化对临床决策支持系统中大语言模型的影响，提出了分层思维链策略来提升模型在噪声输入下的鲁棒性和公平性。


<details>
  <summary>Details</summary>
Motivation: 临床文本常因人为错误或自动化流程故障而质量下降，这会影响AI辅助决策的可靠性和公平性，但目前对此影响的研究不足。

Method: 引入临床基础的标签缩减方案和分层思维链策略，模拟临床医生的推理过程，研究不同文本损坏场景下最先进LLM的表现。

Result: 该方法提高了模型在退化输入下的鲁棒性，减少了亚组不稳定性，推进了LLM在临床决策支持系统中的可靠使用。

Conclusion: 通过分层思维链策略可以有效应对临床文本质量退化问题，提升大语言模型在医疗决策中的可靠性和公平性。

Abstract: A decade of rapid advances in artificial intelligence (AI) has opened new opportunities for clinical decision support systems (CDSS), with large language models (LLMs) demonstrating strong reasoning abilities on timely medical tasks. However, clinical texts are often degraded by human errors or failures in automated pipelines, raising concerns about the reliability and fairness of AI-assisted decision-making. Yet the impact of such degradations remains under-investigated, particularly regarding how noise-induced shifts can heighten predictive uncertainty and unevenly affect demographic subgroups. We present a systematic study of state-of-the-art LLMs under diverse text corruption scenarios, focusing on robustness and equity in next-visit diagnosis prediction. To address the challenge posed by the large diagnostic label space, we introduce a clinically grounded label-reduction scheme and a hierarchical chain-of-thought (CoT) strategy that emulates clinicians' reasoning. Our approach improves robustness and reduces subgroup instability under degraded inputs, advancing the reliable use of LLMs in CDSS. We release code at https://github.com/heejkoo9/NECHOv3.

</details>


### [31] [Findings of the BlackboxNLP 2025 Shared Task: Localizing Circuits and Causal Variables in Language Models](https://arxiv.org/abs/2511.18409)
*Dana Arad,Yonatan Belinkov,Hanjie Chen,Najoung Kim,Hosein Mohebbi,Aaron Mueller,Gabriele Sarti,Martin Tutek*

Main category: cs.CL

TL;DR: 该论文基于Mechanistic Interpretability Benchmark (MIB)构建了BlackboxNLP 2025共享任务，通过电路定位和因果变量定位两个赛道，对8种不同方法进行标准化评估，展示了在可解释性研究中的进展。


<details>
  <summary>Details</summary>
Motivation: 解决机制可解释性(MI)研究中进展衡量困难的问题，通过标准化评估框架来比较不同MI技术的效果。

Method: 扩展MIB基准为社区共享任务，包含两个赛道：电路定位（识别因果影响组件和交互）和因果变量定位（将激活映射为可解释特征）。

Result: 在电路定位中，三个团队的八种方法通过集成和正则化策略取得显著进展；在因果变量定位中，一个团队的两种方法使用低维和非线性投影实现显著提升。

Conclusion: MIB排行榜保持开放，鼓励在该标准化评估框架下继续工作，以衡量MI研究的未来进展。

Abstract: Mechanistic interpretability (MI) seeks to uncover how language models (LMs) implement specific behaviors, yet measuring progress in MI remains challenging. The recently released Mechanistic Interpretability Benchmark (MIB; Mueller et al., 2025) provides a standardized framework for evaluating circuit and causal variable localization. Building on this foundation, the BlackboxNLP 2025 Shared Task extends MIB into a community-wide reproducible comparison of MI techniques. The shared task features two tracks: circuit localization, which assesses methods that identify causally influential components and interactions driving model behavior, and causal variable localization, which evaluates approaches that map activations into interpretable features. With three teams spanning eight different methods, participants achieved notable gains in circuit localization using ensemble and regularization strategies for circuit discovery. With one team spanning two methods, participants achieved significant gains in causal variable localization using low-dimensional and non-linear projections to featurize activation vectors. The MIB leaderboard remains open; we encourage continued work in this standard evaluation framework to measure progress in MI research going forward.

</details>


### [32] [SmolKalam: Ensemble Quality-Filtered Translation at Scale for High Quality Arabic Post-Training Data](https://arxiv.org/abs/2511.18411)
*Sultan Alrashed,Chadi Helwe,Francesco Orabona*

Main category: cs.CL

TL;DR: SmolKalam是一个阿拉伯语多轮对话数据集，通过多模型集成翻译管道从Smoltalk2翻译而来，包含推理和工具调用功能，并应用了质量过滤。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏大规模、高质量的阿拉伯语多轮对话数据集，特别是包含推理和工具调用的数据集。直接翻译在预训练阶段可行，但后训练阶段需要更高质量的数据集。

Method: 采用多模型集成翻译管道，应用质量过滤，并通过消融实验研究传统仅解码器模型的有效翻译技术。

Result: 成功创建了SmolKalam阿拉伯语数据集，该数据集具有高质量的多轮对话内容，包含推理和工具调用功能。

Conclusion: 通过严格的翻译流程和质量控制，可以创建高质量的阿拉伯语后训练数据集，填补了该领域的数据空白。

Abstract: Although the community has tackled the acquisition of high-quality Arabic pretraining data, we still lack large-scale, multi-turn Arabic datasets that include reasoning and tool calling. Naive translation can work at the pretraining scale, but post-training demands much higher quality, which requires a stricter approach to dataset curation. In this work, we introduce SmolKalam, a translation of Smoltalk2 that uses a multi-model ensemble translation pipeline, applies quality filtering, and examines effective translation techniques for traditional decoder-only models through ablations.

</details>


### [33] [Multi-Agent Collaborative Filtering: Orchestrating Users and Items for Agentic Recommendations](https://arxiv.org/abs/2511.18413)
*Yu Xia,Sungchul Kim,Tong Yu,Ryan A. Rossi,Julian McAuely*

Main category: cs.CL

TL;DR: 提出了多智能体协同过滤框架MACF，将传统协同过滤算法与基于LLM的多智能体协作相类比，通过动态智能体招募和个性化协作指令来提升推荐效果


<details>
  <summary>Details</summary>
Motivation: 现有的智能体推荐系统大多关注通用单智能体或多智能体任务分解流程，缺乏推荐导向设计，未能充分利用用户-物品交互历史中的协同信号，导致推荐结果不理想

Method: 为目标用户和查询实例化相似用户和相关物品作为具有独特配置文件的LLM智能体，每个智能体能够调用检索工具、推荐候选物品并与其他智能体交互，通过中央协调器智能体动态管理智能体间的协作

Result: 在三个不同领域的数据集上的实验结果表明，MACF框架相比强大的智能体推荐基线具有优势

Conclusion: MACF框架通过将传统协同过滤与多智能体协作相结合，有效提升了智能体推荐系统的性能

Abstract: Agentic recommendations cast recommenders as large language model (LLM) agents that can plan, reason, use tools, and interact with users of varying preferences in web applications. However, most existing agentic recommender systems focus on generic single-agent plan-execute workflows or multi-agent task decomposition pipelines. Without recommendation-oriented design, they often underuse the collaborative signals in the user-item interaction history, leading to unsatisfying recommendation results. To address this, we propose the Multi-Agent Collaborative Filtering (MACF) framework for agentic recommendations, drawing an analogy between traditional collaborative filtering algorithms and LLM-based multi-agent collaboration. Specifically, given a target user and query, we instantiate similar users and relevant items as LLM agents with unique profiles. Each agent is able to call retrieval tools, suggest candidate items, and interact with other agents. Different from the static preference aggregation in traditional collaborative filtering, MACF employs a central orchestrator agent to adaptively manage the collaboration between user and item agents via dynamic agent recruitment and personalized collaboration instruction. Experimental results on datasets from three different domains show the advantages of our MACF framework compared to strong agentic recommendation baselines.

</details>


### [34] [General Agentic Memory Via Deep Research](https://arxiv.org/abs/2511.18423)
*B. Y. Yan,Chaofan Li,Hongjin Qian,Shuqi Lu,Zheng Liu*

Main category: cs.CL

TL;DR: 提出了一种名为通用代理记忆（GAM）的新框架，采用即时编译原则，在运行时为客户端创建优化上下文，同时在离线阶段仅保留简单但有用的记忆。


<details>
  <summary>Details</summary>
Motivation: 解决广泛采用的静态记忆系统在预先创建可用记忆时不可避免的信息丢失问题。

Method: 采用双组件设计：1）记忆器（Memorizer）使用轻量级记忆突出关键历史信息，同时在通用页面存储中维护完整历史信息；2）研究者（Researcher）根据预构建的记忆从页面存储中检索和整合有用信息。

Result: 在实验研究中，GAM在各种基于记忆的任务完成场景中相比现有记忆系统取得了显著改进。

Conclusion: GAM框架能够有效利用前沿大语言模型的代理能力和测试时扩展性，同时通过强化学习促进端到端性能优化。

Abstract: Memory is critical for AI agents, yet the widely-adopted static memory, aiming to create readily available memory in advance, is inevitably subject to severe information loss. To address this limitation, we propose a novel framework called \textbf{general agentic memory (GAM)}. GAM follows the principle of "\textbf{just-in time (JIT) compilation}" where it focuses on creating optimized contexts for its client at runtime while keeping only simple but useful memory during the offline stage. To this end, GAM employs a duo-design with the following components. 1) \textbf{Memorizer}, which highlights key historical information using a lightweight memory, while maintaining complete historical information within a universal page-store. 2) \textbf{Researcher}, which retrieves and integrates useful information from the page-store for its online request guided by the pre-constructed memory. This design allows GAM to effectively leverage the agentic capabilities and test-time scalability of frontier large language models (LLMs), while also facilitating end-to-end performance optimization through reinforcement learning. In our experimental study, we demonstrate that GAM achieves substantial improvement on various memory-grounded task completion scenarios against existing memory systems.

</details>


### [35] [MindEval: Benchmarking Language Models on Multi-turn Mental Health Support](https://arxiv.org/abs/2511.18491)
*José Pombal,Maya D'Eon,Nuno M. Guerreiro,Pedro Henrique Martins,António Farinhas,Ricardo Rei*

Main category: cs.CL

TL;DR: 提出了MindEval框架，用于在多轮心理健康治疗对话中自动评估语言模型，发现现有模型在真实治疗互动中表现不佳，存在沟通模式问题。


<details>
  <summary>Details</summary>
Motivation: 当前AI心理健康聊天机器人存在诸多限制，如奉承、过度验证和强化不良信念等，且缺乏能捕捉真实治疗互动复杂性的基准测试。

Method: 与临床心理学家合作开发MindEval框架，通过患者模拟和LLM自动评估，在真实多轮治疗对话中评估语言模型。

Result: 评估12个最先进LLM，所有模型平均得分低于4/6，在沟通模式方面表现尤其薄弱，推理能力和模型规模不能保证更好性能。

Conclusion: 现有LLM在心理健康治疗对话中表现不足，需要专门改进以处理此类复杂互动，MindEval为评估和改进提供了有效工具。

Abstract: Demand for mental health support through AI chatbots is surging, though current systems present several limitations, like sycophancy or overvalidation, and reinforcement of maladaptive beliefs. A core obstacle to the creation of better systems is the scarcity of benchmarks that capture the complexity of real therapeutic interactions. Most existing benchmarks either only test clinical knowledge through multiple-choice questions or assess single responses in isolation. To bridge this gap, we present MindEval, a framework designed in collaboration with Ph.D-level Licensed Clinical Psychologists for automatically evaluating language models in realistic, multi-turn mental health therapy conversations. Through patient simulation and automatic evaluation with LLMs, our framework balances resistance to gaming with reproducibility via its fully automated, model-agnostic design. We begin by quantitatively validating the realism of our simulated patients against human-generated text and by demonstrating strong correlations between automatic and human expert judgments. Then, we evaluate 12 state-of-the-art LLMs and show that all models struggle, scoring below 4 out of 6, on average, with particular weaknesses in problematic AI-specific patterns of communication. Notably, reasoning capabilities and model scale do not guarantee better performance, and systems deteriorate with longer interactions or when supporting patients with severe symptoms. We release all code, prompts, and human evaluation data.

</details>


### [36] [For Those Who May Find Themselves on the Red Team](https://arxiv.org/abs/2511.18499)
*Tyler Shoemaker*

Main category: cs.CL

TL;DR: 文学学者必须参与大型语言模型可解释性研究，尽管这涉及意识形态斗争甚至妥协，但当前可解释性方法的工具性不应是衡量LLM解释的唯一标准。


<details>
  <summary>Details</summary>
Motivation: 当前LLM可解释性研究过于工具化，文学学者需要参与其中以引入更丰富的解释标准和方法。

Method: 提出将红队（red team）作为文学学者参与LLM可解释性研究的实践场所。

Result: 认识到文学学者参与LLM可解释性研究的必要性和潜在冲突。

Conclusion: 文学学者必须积极介入LLM可解释性研究，通过红队等实践场所来挑战和丰富现有的解释标准。

Abstract: This position paper argues that literary scholars must engage with large language model (LLM) interpretability research. While doing so will involve ideological struggle, if not out-right complicity, the necessity of this engagement is clear: the abiding instrumentality of current approaches to interpretability cannot be the only standard by which we measure interpretation with LLMs. One site at which this struggle could take place, I suggest, is the red team.

</details>


### [37] [Dealing with the Hard Facts of Low-Resource African NLP](https://arxiv.org/abs/2511.18557)
*Yacouba Diarra,Nouhoum Souleymane Coulibaly,Panga Azazia Kamaté,Madani Amadou Tall,Emmanuel Élisé Koné,Aymane Dembélé,Michael Leventhal*

Main category: cs.CL

TL;DR: 本文报告了为低资源语言班巴拉语收集612小时自发语音数据、半自动转录标注、创建多个单语超紧凑和小型模型，并进行自动和人工评估的过程。


<details>
  <summary>Details</summary>
Motivation: 为低资源语言创建语音数据集、模型和评估框架具有挑战性，因为缺乏相关经验基础。

Method: 野外收集班巴拉语自发语音数据，进行半自动转录标注，创建单语超紧凑和小型模型，并进行自动和人工评估。

Result: 收集了612小时班巴拉语语音数据，创建了多个模型，并提供了数据收集协议、标注和模型设计的实用建议。

Conclusion: 除了主要数据集外，还公开提供了多个评估数据集、模型和代码，强调了进行人工评估的重要性。

Abstract: Creating speech datasets, models, and evaluation frameworks for low-resource languages remains challenging given the lack of a broad base of pertinent experience to draw from. This paper reports on the field collection of 612 hours of spontaneous speech in Bambara, a low-resource West African language; the semi-automated annotation of that dataset with transcriptions; the creation of several monolingual ultra-compact and small models using the dataset; and the automatic and human evaluation of their output. We offer practical suggestions for data collection protocols, annotation, and model design, as well as evidence for the importance of performing human evaluation. In addition to the main dataset, multiple evaluation datasets, models, and code are made publicly available.

</details>


### [38] [Toward Trustworthy Difficulty Assessments: Large Language Models as Judges in Programming and Synthetic Tasks](https://arxiv.org/abs/2511.18597)
*H. M. Shadman Tabib,Jaber Ahmed Deedar*

Main category: cs.CL

TL;DR: GPT-4o作为编程问题难度评估器的表现远不如基于显式特征的LightGBM模型，准确率仅37.75% vs 86%，且存在对简单类别的强烈偏见。


<details>
  <summary>Details</summary>
Motivation: 探索LLM在结构化任务（如预测编程问题难度）中的表现，评估其作为自动评判器的可靠性。

Method: 在1,825个LeetCode问题上系统比较GPT-4o（纯自然语言评估）与基于显式数值和文本特征的LightGBM集成模型。

Result: LightGBM达到86%准确率，而GPT-4o仅37.75%。GPT-4o忽视数值约束（如输入大小限制和接受率），对简单类别有强烈偏见。

Conclusion: 在竞争性编程、教育平台或强化学习管道中信任基于LLM的评判器之前，必须解决这些具体的失败模式。

Abstract: Large Language Models (LLMs) have demonstrated impressive capabilities in natural language and code generation, and are increasingly deployed as automatic judges of model outputs and learning activities. Yet, their behavior on structured tasks such as predicting the difficulty of competitive programming problems remains under-explored. We conduct a systematic comparison of GPT-4o, used purely as a natural-language difficulty assessor, against an interpretable Light-GBM ensemble trained on explicit numeric and textual features. On a dataset of 1,825 LeetCode problems labeled Easy, Medium, or Hard, LightGBM attains 86% accuracy, whereas GPT-4o reaches only 37.75%. Detailed analyses, including confusion matrices and SHAP-based interpretability, show that numeric constraints -- such as input size limits and acceptance rates -- play a crucial role in separating Hard problems from easier ones. By contrast, GPT-4o often overlooks these cues and exhibits a strong bias toward simpler categories. We further probe GPT-4o through a synthetic Hard-problem generation protocol. Surprisingly, GPT-4o labels almost all of its own synthetic Hard problems as Medium, contradicting its tendency to downgrade real Hard problems to Easy. Our findings connect to recent work on LLMs-as-judges and automatic difficulty estimation in programming and education, and highlight concrete failure modes that must be addressed before LLM-based judges can be considered trustworthy in competitive programming, educational platforms, or reinforcement-learning pipelines.

</details>


### [39] [A Benchmark for Zero-Shot Belief Inference in Large Language Models](https://arxiv.org/abs/2511.18616)
*Joseph Malone,Rachith Aiyappa,Byunghwee Lee,Haewoon Kwak,Jisun An,Yong-Yeol Ahn*

Main category: cs.CL

TL;DR: 提出了一个系统性基准来评估LLM在零样本设置下预测个体对各种话题立场的泛化能力，发现提供更多背景信息能提高预测准确性，但性能在不同信念领域差异显著。


<details>
  <summary>Details</summary>
Motivation: 信念是人类推理、沟通和社交的核心，但现有计算方法局限于狭窄的社会政治背景且依赖微调。需要了解LLM在不同信念领域的泛化能力。

Method: 使用在线辩论平台数据构建可复现基准，在零样本设置下评估LLM预测个体立场的表现，包含多种信息条件以分离人口统计背景和已知先验信念的贡献。

Result: 提供更多个体背景信息能提高预测准确性，但性能在不同信念领域差异很大。中小型模型表现出这种模式。

Conclusion: 研究揭示了当前LLM模拟人类推理的能力和局限性，为超越社会政治领域的信念系统建模提供了可扩展框架。

Abstract: Beliefs are central to how humans reason, communicate, and form social connections, yet most computational approaches to studying them remain confined to narrow sociopolitical contexts and rely on fine-tuning for optimal performance. Despite the growing use of large language models (LLMs) across disciplines, how well these systems generalize across diverse belief domains remains unclear. We introduce a systematic, reproducible benchmark that evaluates the ability of LLMs to predict individuals' stances on a wide range of topics in a zero-shot setting using data from an online debate platform. The benchmark includes multiple informational conditions that isolate the contribution of demographic context and known prior beliefs to predictive success. Across several small- to medium-sized models, we find that providing more background information about an individual improves predictive accuracy, but performance varies substantially across belief domains. These findings reveal both the capacity and limitations of current LLMs to emulate human reasoning, advancing the study of machine behavior and offering a scalable framework for modeling belief systems beyond the sociopolitical sphere.

</details>


### [40] [A Unified BERT-CNN-BiLSTM Framework for Simultaneous Headline Classification and Sentiment Analysis of Bangla News](https://arxiv.org/abs/2511.18618)
*Mirza Raquib,Munazer Montasir Akash,Tawhid Ahmed,Saydul Akbar Murad,Farida Siddiqi Prity,Mohammad Amzad Hossain,Asif Pervez Polok,Nick Rahimi*

Main category: cs.CL

TL;DR: 本研究提出了一个结合孟加拉语新闻标题分类和情感分析的最先进方法，使用BERT-CNN-BiLSTM混合迁移学习模型，在BAN-ABSA数据集上取得了最佳性能。


<details>
  <summary>Details</summary>
Motivation: 报纸是重要的信息来源，但有效浏览大量新闻内容具有挑战性。新闻标题的情感分析可以帮助快速理解新闻的情感基调。

Method: 使用BERT-CNN-BiLSTM混合迁移学习模型，在包含9014个新闻标题的BAN-ABSA数据集上进行实验，采用了两种处理不平衡数据集的策略：技术1（分割前进行欠采样和过采样）和技术2（分割后进行欠采样和过采样）。

Result: 技术1的过采样方法在标题分类和情感分析上分别达到78.57%和73.43%的最高性能；技术2在原始不平衡数据集上训练分别达到81.37%和64.46%的最高结果。BERT-CNN-BiLSTM模型显著优于所有基线模型。

Conclusion: 该模型在孟加拉语新闻标题分类和情感分析任务中取得了新的最先进结果，证明了同时利用标题和情感数据集的重要性，为低资源孟加拉语文本分类提供了强基线。

Abstract: In our daily lives, newspapers are an essential information source that impacts how the public talks about present-day issues. However, effectively navigating the vast amount of news content from different newspapers and online news portals can be challenging. Newspaper headlines with sentiment analysis tell us what the news is about (e.g., politics, sports) and how the news makes us feel (positive, negative, neutral). This helps us quickly understand the emotional tone of the news. This research presents a state-of-the-art approach to Bangla news headline classification combined with sentiment analysis applying Natural Language Processing (NLP) techniques, particularly the hybrid transfer learning model BERT-CNN-BiLSTM. We have explored a dataset called BAN-ABSA of 9014 news headlines, which is the first time that has been experimented with simultaneously in the headline and sentiment categorization in Bengali newspapers. Over this imbalanced dataset, we applied two experimental strategies: technique-1, where undersampling and oversampling are applied before splitting, and technique-2, where undersampling and oversampling are applied after splitting on the In technique-1 oversampling provided the strongest performance, both headline and sentiment, that is 78.57\% and 73.43\% respectively, while technique-2 delivered the highest result when trained directly on the original imbalanced dataset, both headline and sentiment, that is 81.37\% and 64.46\% respectively. The proposed model BERT-CNN-BiLSTM significantly outperforms all baseline models in classification tasks, and achieves new state-of-the-art results for Bangla news headline classification and sentiment analysis. These results demonstrate the importance of leveraging both the headline and sentiment datasets, and provide a strong baseline for Bangla text classification in low-resource.

</details>


### [41] [Prompt Optimization as a State-Space Search Problem](https://arxiv.org/abs/2511.18619)
*Maanas Taneja*

Main category: cs.CL

TL;DR: 该论文提出将提示优化建模为状态空间搜索问题，使用束搜索和随机游走算法在提示空间中进行系统探索，在五个NLP任务上验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 语言模型对输入提示字符串的微小变化极为敏感，容易出现性能崩溃。受DSpy等基于演示的提示优化方法启发，作者希望提供一种替代方法来解决这个问题。

Method: 将提示空间建模为图结构，节点代表提示状态，边对应有意的转换操作（如缩短、添加示例、重新排序内容）。使用束搜索和随机游走算法系统探索该空间，在开发集上评估候选提示并剪枝无希望的路径。

Result: 在五个NLP任务（情感分类、问答、摘要、推理和自然语言推理）上，即使浅层搜索配置（束宽=2，深度=2）也能在开发集上改进种子提示。例如，束搜索在推理任务上实现了开发准确率从0.40提升到0.80，但测试集改进较为温和（0.20到0.50），表明存在对开发启发式过拟合。

Conclusion: 结果验证了提示优化作为搜索问题的有效性，并表明通过更多计算资源和改进的评估指标，更深入的探索可以产生在开发集之外具有更好泛化能力的稳健提示。

Abstract: Language Models are extremely susceptible to performance collapse with even small changes to input prompt strings. Libraries such as DSpy (from Stanford NLP) avoid this problem through demonstration-based prompt optimisation. Inspired by this, I propose an alternative approach that treats prompt optimisation as a classical state-space search problem. I model the prompt space as a graph where nodes represent prompt states and edges correspond to deliberate transformations such as shortening, adding examples, or re- ordering content. Using beam search and random walk algorithms, I systematically explore this space, evaluating candidates on development sets and pruning unpromising branches. Across five NLP tasks (sentiment classification, question answering, summarisation, reason- ing, and natural language inference), I find that even shallow search configurations (beam width=2, depth=2) improve upon seed prompts on development sets. For instance, beam search achieves development accuracy gains from 0.40 to 0.80 on reasoning tasks, though test set improvements are more modest (0.20 to 0.50), indicating overfitting to the develop- ment heuristic. Analysis of successful optimisation paths reveals that transformations that make prompts concise appear most frequently, while verbosity operators are never selected. My results validate prompt optimization as a search problem and suggest that with greater computational resources and improved evaluation metrics, deeper exploration could yield more robust prompts that generalize beyond development sets. Code and implementation are available at [https://github.com/MaanasTaneja/PromptOptimiser].

</details>


### [42] [OpenGloss: A Synthetic Encyclopedic Dictionary and Semantic Knowledge Graph](https://arxiv.org/abs/2511.18622)
*Michael J. Bommarito*

Main category: cs.CL

TL;DR: OpenGloss是一个合成的英语百科全书词典和语义知识图谱，整合了词典定义、百科全书背景、词源历史和语义关系，包含53.7万个词义和910万条语义边，通过多智能体流程生成，成本低于1000美元，时间不到一周。


<details>
  <summary>Details</summary>
Motivation: 解决教学应用中词汇学习和自然语言处理任务的综合内容需求，填补现有资源的空白，展示结构化生成在创建全面词汇资源方面的潜力。

Method: 使用多智能体流程生成管道，结合模式验证的LLM输出和自动化质量保证，生成包含词典定义、百科全书内容、词源和语义关系的统一资源。

Result: 生成包含53.7万个词义、150万个词位、910万条语义边、100万个使用示例、300万个搭配和6000万词百科全书内容的大规模资源，规模与WordNet 3.1相当但定义数量多四倍。

Conclusion: 结构化生成能够在成本和时间尺度上创建全面的词汇资源，为研究人员和教育工作者提供可公开使用的数据集，反映了当前基础模型的能力和局限性。

Abstract: We present OpenGloss, a synthetic encyclopedic dictionary and semantic knowledge graph for English that integrates lexicographic definitions, encyclopedic context, etymological histories, and semantic relationships in a unified resource. OpenGloss contains 537K senses across 150K lexemes, on par with WordNet 3.1 and Open English WordNet, while providing more than four times as many sense definitions. These lexemes include 9.1M semantic edges, 1M usage examples, 3M collocations, and 60M words of encyclopedic content.
  Generated through a multi-agent procedural generation pipeline with schema-validated LLM outputs and automated quality assurance, the entire resource was produced in under one week for under $1,000. This demonstrates that structured generation can create comprehensive lexical resources at cost and time scales impractical for manual curation, enabling rapid iteration as foundation models improve. The resource addresses gaps in pedagogical applications by providing integrated content -- definitions, examples, collocations, encyclopedias, etymology -- that supports both vocabulary learning and natural language processing tasks.
  As a synthetically generated resource, OpenGloss reflects both the capabilities and limitations of current foundation models. The dataset is publicly available on Hugging Face under CC-BY 4.0, enabling researchers and educators to build upon and adapt this resource.

</details>


### [43] [No Free Lunch in Language Model Bias Mitigation? Targeted Bias Reduction Can Exacerbate Unmitigated LLM Biases](https://arxiv.org/abs/2511.18635)
*Shireen Chand,Faith Baca,Emilio Ferrara*

Main category: cs.CL

TL;DR: 针对特定偏见维度进行偏见缓解时，经常会在其他维度产生意外的负面后果，如增加模型偏见和降低整体连贯性。


<details>
  <summary>Details</summary>
Motivation: LLMs从训练数据中继承了社会偏见，可能导致有害或不公平的输出。现有偏见缓解技术通常只评估目标偏见维度的影响，而忽略了跨类别的后果。

Method: 研究了四种偏见缓解技术，应用于来自七个模型家族的十个模型，探索了种族、宗教、职业和性别相关的偏见。使用StereoSet基准测量去偏见对模型连贯性和刻板印象偏好的影响。

Result: 定向缓解有时能减少目标维度的偏见，但经常在其他维度导致意外负面后果，如增加模型偏见和降低一般连贯性。

Conclusion: 在研究和开发偏见缓解策略时，需要强大的多维度评估工具，以避免无意中在未针对的轴上转移或加剧偏见。

Abstract: Large Language Models (LLMs) inherit societal biases from their training data, potentially leading to harmful or unfair outputs. While various techniques aim to mitigate these biases, their effects are often evaluated only along the dimension of the bias being targeted. This work investigates the cross-category consequences of targeted bias mitigation. We study four bias mitigation techniques applied across ten models from seven model families, and we explore racial, religious, profession- and gender-related biases. We measure the impact of debiasing on model coherence and stereotypical preference using the StereoSet benchmark. Our results consistently show that while targeted mitigation can sometimes reduce bias in the intended dimension, it frequently leads to unintended and often negative consequences in others, such as increasing model bias and decreasing general coherence. These findings underscore the critical need for robust, multi-dimensional evaluation tools when examining and developing bias mitigation strategies to avoid inadvertently shifting or worsening bias along untargeted axes.

</details>


### [44] [Evaluating Large Language Models on the 2026 Korean CSAT Mathematics Exam: Measuring Mathematical Ability in a Zero-Data-Leakage Setting](https://arxiv.org/abs/2511.18649)
*Goun Pyeon,Inbum Heo,Jeesu Jung,Taewook Hwang,Hyuk Namgoong,Hyein Seo,Yerim Han,Eunbin Kim,Hyeonseok Kang,Sangkeun Jung*

Main category: cs.CL

TL;DR: 本研究系统评估了大型语言模型在2026年韩国高考数学考试中的推理能力，建立了完全无数据泄露的评估环境，发现GPT-5 Codex获得满分，几何是最薄弱领域，增强推理强度能提升性能但大幅降低效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有基准测试中数据泄露问题，在考试公开后两小时内数字化所有题目，确保模型训练数据中不可能包含这些题目，实现完全无污染的评估环境。

Method: 使用2026年韩国高考数学全部46道题目，对24个最先进的大型语言模型进行综合评估，涵盖不同输入模态（文本、图像、文本+图形）和提示语言（韩语、英语），并进行推理增强实验。

Result: GPT-5 Codex获得唯一满分（100分），Grok 4、GPT-5和Deepseek R1得分超过95分；几何是最薄弱领域（平均77.7%）；文本输入优于图像输入；增强推理强度从82.6分提升到100分但效率大幅降低。

Conclusion: 本研究实现了完全未暴露的评估环境，建立了基于真实考试的LLM评估框架，并提供了整合性能、成本和时间考量的实用评估视角，建议最小推理的模型可能更实用。

Abstract: This study systematically evaluated the mathematical reasoning capabilities of Large Language Models (LLMs) using the 2026 Korean College Scholastic Ability Test (CSAT) Mathematics section, ensuring a completely contamination-free evaluation environment. To address data leakage issues in existing benchmarks, we digitized all 46 questions (22 common and 24 elective) within two hours of the exam's public release, eliminating any possibility of inclusion in model training data. We conducted comprehensive evaluations of 24 state-of-the-art LLMs across varying input modalities (text, image, text+figure) and prompt languages (Korean, English).
  GPT-5 Codex achieved the only perfect score (100 points) with text input and Korean prompts, while Grok 4, GPT-5, and Deepseek R1 scored above 95 points. Notably, gpt-oss-20B achieved 95.7 points despite its relatively small size, demonstrating high cost-effectiveness. Problem-specific analysis revealed geometry as the weakest domain (77.7% average) with significant performance degradation on 4-point high-difficulty problems. Text input consistently outperformed image input, while prompt language effects varied by model scale.
  In reasoning enhancement experiments with GPT-5 series, increased reasoning intensity improved performance (from 82.6 to 100 points) but quadrupled token usage and drastically reduced efficiency, suggesting that models with minimal reasoning may be more practical. This research contributes: (1) implementation of a completely unexposed evaluation environment, (2) a real-exam-based LLM assessment framework, and (3) a practical evaluation perspective integrating performance, cost, and time considerations. Detailed results and model comparisons are available at the 2026 Korean CSAT LLM Evaluation Leaderboard (https://isoft.cnu.ac.kr/csat2026/).

</details>


### [45] [CLaRa: Bridging Retrieval and Generation with Continuous Latent Reasoning](https://arxiv.org/abs/2511.18659)
*Jie He,Richard He Bai,Sinead Williamson,Jeff Z. Pan,Navdeep Jaitly,Yizhe Zhang*

Main category: cs.CL

TL;DR: CLaRa是一个统一的检索增强生成框架，通过嵌入压缩和联合优化在共享连续空间中解决长上下文和检索-生成分离优化问题。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强生成方法存在长上下文处理和检索-生成模块分离优化的问题，需要统一的框架来提升性能。

Method: 提出CLaRa框架，使用SCP数据合成方法生成语义丰富的压缩向量，通过可微分top-k估计器端到端训练重排序器和生成器。

Result: 在多个问答基准测试中，CLaRa实现了最先进的压缩和重排序性能，通常超过基于文本的微调基线方法。

Conclusion: CLaRa通过统一的连续潜在推理框架，理论上有助于对齐检索相关性和答案质量，在实践中表现出优越性能。

Abstract: Retrieval-augmented generation (RAG) enhances large language models (LLMs) with external knowledge but still suffers from long contexts and disjoint retrieval-generation optimization. In this work, we propose CLaRa (Continuous Latent Reasoning), a unified framework that performs embedding-based compression and joint optimization in a shared continuous space. To obtain semantically rich and retrievable compressed vectors, we introduce SCP, a key-preserving data synthesis framework using QA and paraphrase supervision. CLaRa then trains the reranker and generator end-to-end via a single language modeling loss, with gradients flowing through both modules using a differentiable top-k estimator. Theoretically, this unified optimization aligns retrieval relevance with answer quality. Experiments across multiple QA benchmarks show that CLaRa achieves state-of-the-art compression and reranking performance, often surpassing text-based fine-tuned baselines.

</details>


### [46] [Empathetic Cascading Networks: A Multi-Stage Prompting Technique for Reducing Social Biases in Large Language Models](https://arxiv.org/abs/2511.18696)
*Wangjiaxuan Xin*

Main category: cs.CL

TL;DR: ECN是一个多阶段提示框架，通过四个阶段增强大语言模型的同理心和包容性能力，在GPT模型上实现了最高的同理心商数得分。


<details>
  <summary>Details</summary>
Motivation: 提升大语言模型在对话AI中的同理心和包容性能力，使其能够生成更具情感共鸣和情境感知的回应。

Method: 使用四阶段提示方法：视角采纳、情感共鸣、反思理解和综合整合，引导模型生成情感共鸣的回应。

Result: ECN在GPT-3.5-turbo和GPT-4上获得了最高的同理心商数得分，同时在尊重度和困惑度指标上保持竞争力。

Conclusion: ECN框架在需要同理心和包容性的对话AI应用中具有重要潜力。

Abstract: This report presents the Empathetic Cascading Networks (ECN) framework, a multi-stage prompting method designed to enhance the empathetic and inclusive capabilities of large language models. ECN employs four stages: Perspective Adoption, Emotional Resonance, Reflective Understanding, and Integrative Synthesis, to guide models toward generating emotionally resonant and contextually aware responses. Experimental results demonstrate that ECN achieves the highest Empathy Quotient (EQ) scores across GPT-3.5-turbo and GPT-4, while maintaining competitive Regard and Perplexity metrics. These findings emphasize ECN's potential for applications requiring empathy and inclusivity in conversational AI.

</details>


### [47] [RhinoInsight: Improving Deep Research through Control Mechanisms for Model Behavior and Context](https://arxiv.org/abs/2511.18743)
*Yu Lei,Shuzheng Si,Wei Wang,Yifei Wu,Gang Chen,Fanchao Qi,Maosong Sun*

Main category: cs.CL

TL;DR: RhinoInsight是一个深度研究框架，通过添加可验证清单和证据审计两个控制机制，增强LLM代理在深度研究任务中的鲁棒性、可追溯性和质量，无需参数更新。


<details>
  <summary>Details</summary>
Motivation: 现有系统采用线性流水线（规划-搜索-写作-报告）存在错误累积和上下文腐化问题，缺乏对模型行为和上下文的显式控制。

Method: 1. 可验证清单模块：将用户需求转化为可追溯的子目标，通过人工或LLM批评者进行细化，生成分层大纲来锚定后续行动。2. 证据审计模块：结构化搜索内容，迭代更新大纲，修剪噪声上下文，通过批评者对高质量证据进行排名和绑定。

Result: 实验表明RhinoInsight在深度研究任务上达到最先进性能，同时在深度搜索任务上保持竞争力。

Conclusion: RhinoInsight通过两个控制机制有效解决了现有系统的局限性，在保持竞争力的同时显著提升了深度研究任务的质量和可靠性。

Abstract: Large language models are evolving from single-turn responders into tool-using agents capable of sustained reasoning and decision-making for deep research. Prevailing systems adopt a linear pipeline of plan to search to write to a report, which suffers from error accumulation and context rot due to the lack of explicit control over both model behavior and context. We introduce RhinoInsight, a deep research framework that adds two control mechanisms to enhance robustness, traceability, and overall quality without parameter updates. First, a Verifiable Checklist module transforms user requirements into traceable and verifiable sub-goals, incorporates human or LLM critics for refinement, and compiles a hierarchical outline to anchor subsequent actions and prevent non-executable planning. Second, an Evidence Audit module structures search content, iteratively updates the outline, and prunes noisy context, while a critic ranks and binds high-quality evidence to drafted content to ensure verifiability and reduce hallucinations. Our experiments demonstrate that RhinoInsight achieves state-of-the-art performance on deep research tasks while remaining competitive on deep search tasks.

</details>


### [48] [Large Language Models Require Curated Context for Reliable Political Fact-Checking -- Even with Reasoning and Web Search](https://arxiv.org/abs/2511.18749)
*Matthew R. DeVerna,Kai-Cheng Yang,Harry Yaojun Yan,Filippo Menczer*

Main category: cs.CL

TL;DR: 评估15个主流LLM在事实核查任务上的表现，发现标准模型表现差，推理能力帮助有限，网络搜索仅提供中等改进，而使用高质量摘要的RAG系统显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 随着LLM具备推理和网络搜索能力并被广泛用于事实核查，急需对这些模型在事实核查任务上的表现进行严格评估。

Method: 在PolitiFact的6000多条声明上评估15个最新LLM，比较标准模型、推理变体和网络搜索变体的表现，并与使用PolitiFact摘要的RAG系统对比。

Result: 标准模型表现差，推理提供最小收益，网络搜索仅中等改进，而RAG系统平均提升宏F1分数233%。

Conclusion: 为模型提供精选的高质量上下文是自动事实核查的有前景路径。

Abstract: Large language models (LLMs) have raised hopes for automated end-to-end fact-checking, but prior studies report mixed results. As mainstream chatbots increasingly ship with reasoning capabilities and web search tools -- and millions of users already rely on them for verification -- rigorous evaluation is urgent. We evaluate 15 recent LLMs from OpenAI, Google, Meta, and DeepSeek on more than 6,000 claims fact-checked by PolitiFact, comparing standard models with reasoning- and web-search variants. Standard models perform poorly, reasoning offers minimal benefits, and web search provides only moderate gains, despite fact-checks being available on the web. In contrast, a curated RAG system using PolitiFact summaries improved macro F1 by 233% on average across model variants. These findings suggest that giving models access to curated high-quality context is a promising path for automated fact-checking.

</details>


### [49] [Robust Multimodal Sentiment Analysis with Distribution-Based Feature Recovery and Fusion](https://arxiv.org/abs/2511.18751)
*Daiqing Wu,Dongbao Yang,Can Ma,Yu Zhou*

Main category: cs.CL

TL;DR: 提出DRF方法用于图像-文本对的多模态情感分析，通过特征分布建模同时处理低质量和缺失模态问题，在三种公开数据集上验证了其鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏对低质量和缺失模态的考虑，而现实应用中这些问题频繁发生，需要能够稳健预测情感的模型。

Method: 为每个模态维护特征队列来近似特征分布，基于分布定量估计模态质量以减少低质量模态的贡献，通过样本和分布监督建立模态间映射关系来恢复缺失模态。

Result: 在三种公开图像-文本数据集上，DRF相比SOTA方法在两种破坏策略（损坏和丢弃模态）下均取得普遍改进。

Conclusion: DRF方法在统一框架中有效处理低质量和缺失模态问题，验证了其在鲁棒多模态情感分析中的有效性。

Abstract: As posts on social media increase rapidly, analyzing the sentiments embedded in image-text pairs has become a popular research topic in recent years. Although existing works achieve impressive accomplishments in simultaneously harnessing image and text information, they lack the considerations of possible low-quality and missing modalities. In real-world applications, these issues might frequently occur, leading to urgent needs for models capable of predicting sentiment robustly. Therefore, we propose a Distribution-based feature Recovery and Fusion (DRF) method for robust multimodal sentiment analysis of image-text pairs. Specifically, we maintain a feature queue for each modality to approximate their feature distributions, through which we can simultaneously handle low-quality and missing modalities in a unified framework. For low-quality modalities, we reduce their contributions to the fusion by quantitatively estimating modality qualities based on the distributions. For missing modalities, we build inter-modal mapping relationships supervised by samples and distributions, thereby recovering the missing modalities from available ones. In experiments, two disruption strategies that corrupt and discard some modalities in samples are adopted to mimic the low-quality and missing modalities in various real-world scenarios. Through comprehensive experiments on three publicly available image-text datasets, we demonstrate the universal improvements of DRF compared to SOTA methods under both two strategies, validating its effectiveness in robust multimodal sentiment analysis.

</details>


### [50] [Context-Aware Whisper for Arabic ASR Under Linguistic Varieties](https://arxiv.org/abs/2511.18774)
*Bashar Talafha,Amin Abu Alhassan,Muhammad Abdul-Mageed*

Main category: cs.CL

TL;DR: 提出基于上下文提示策略的Whisper阿拉伯语语音识别方法，无需重新训练即可显著降低词错误率，特别是在现代标准阿拉伯语和方言语音上。


<details>
  <summary>Details</summary>
Motivation: 解决阿拉伯语等低资源语言的ASR挑战，特别是面对广泛方言变异和有限标注数据的情况。

Method: 使用解码器提示（首遍转录或检索语句）和编码器前缀（目标说话人语音合成），结合提示重排序、说话人感知前缀合成和多模态检索（词汇、语义、声学）技术。

Result: 在九种阿拉伯语语言条件下，现代标准阿拉伯语的WER降低达22.3%，方言语音降低9.2%，显著减少幻觉和说话人不匹配问题。

Conclusion: 上下文感知提示策略有效提升了Whisper在零样本设置下的阿拉伯语语音识别性能，为低资源ASR提供了实用解决方案。

Abstract: Low-resource ASR remains a challenging problem, especially for languages like Arabic that exhibit wide dialectal variation and limited labeled data. We propose context-aware prompting strategies to adapt OpenAI's Whisper for Arabic speech recognition without retraining. Our methods include decoder prompting with first-pass transcriptions or retrieved utterances, and encoder prefixing using speech synthesized in the target speaker's voice. We introduce techniques such as prompt reordering, speaker-aware prefix synthesis, and modality-specific retrieval (lexical, semantic, acoustic) to improve transcription in real-world, zero-shot settings. Evaluated on nine Arabic linguistic conditions, our approach reduces WER by up to 22.3% on Modern Standard Arabic and 9.2% on dialectal speech, significantly mitigating hallucinations and speaker mismatch.

</details>


### [51] [HyperbolicRAG: Enhancing Retrieval-Augmented Generation with Hyperbolic Representations](https://arxiv.org/abs/2511.18808)
*Cao Linxiao,Wang Ruitao,Li Jindong,Zhou Zhipeng,Yang Menglin*

Main category: cs.CL

TL;DR: 提出了HyperbolicRAG框架，将双曲几何融入基于图的检索增强生成，通过共享Poincare流形嵌入、对比正则化和互排序融合机制，在多个QA基准测试中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的图基RAG方法依赖欧几里得嵌入，虽然能捕捉语义相似性，但缺乏对层次深度的几何表示，限制了在复杂知识图中表示抽象关系的能力。

Method: 1) 深度感知表示学习器，在共享Poincare流形中嵌入节点；2) 无监督对比正则化，强制跨抽象级别的几何一致性；3) 互排序融合机制，联合利用欧几里得和双曲空间的检索信号。

Result: 在多个QA基准测试上的广泛实验表明，HyperbolicRAG优于竞争基线，包括标准RAG和图增强基线。

Conclusion: HyperbolicRAG通过整合双曲几何，能够同时捕捉细粒度语义和全局层次结构，在检索增强生成任务中表现出色。

Abstract: Retrieval-augmented generation (RAG) enables large language models (LLMs) to access external knowledge, helping mitigate hallucinations and enhance domain-specific expertise. Graph-based RAG enhances structural reasoning by introducing explicit relational organization that enables information propagation across semantically connected text units. However, these methods typically rely on Euclidean embeddings that capture semantic similarity but lack a geometric notion of hierarchical depth, limiting their ability to represent abstraction relationships inherent in complex knowledge graphs. To capture both fine-grained semantics and global hierarchy, we propose HyperbolicRAG, a retrieval framework that integrates hyperbolic geometry into graph-based RAG. HyperbolicRAG introduces three key designs: (1) a depth-aware representation learner that embeds nodes within a shared Poincare manifold to align semantic similarity with hierarchical containment, (2) an unsupervised contrastive regularization that enforces geometric consistency across abstraction levels, and (3) a mutual-ranking fusion mechanism that jointly exploits retrieval signals from Euclidean and hyperbolic spaces, emphasizing cross-space agreement during inference. Extensive experiments across multiple QA benchmarks demonstrate that HyperbolicRAG outperforms competitive baselines, including both standard RAG and graph-augmented baselines.

</details>


### [52] [Concept than Document: Context Compression via AMR-based Conceptual Entropy](https://arxiv.org/abs/2511.18832)
*Kaize Shi,Xueyao Sun,Xiaohui Tao,Lin Li,Qika Lin,Guandong Xu*

Main category: cs.CL

TL;DR: 提出了一种基于抽象意义表示(AMR)图的无监督上下文压缩框架，通过节点级熵量化来保留语义核心信息，过滤冗余内容，在RAG中提高推理精度并减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在处理长上下文时面临信息过载问题，特别是在检索增强生成中，大量支持文档常包含冗余内容，这会降低推理准确性并增加计算负担。

Method: 构建AMR图，计算节点级概念熵来评估每个节点的概念重要性，筛选重要信息节点形成压缩的语义聚焦上下文。

Result: 在PopQA和EntityQuestions数据集上的实验表明，该方法优于基准方法，在显著减少上下文长度的同时获得更高准确率。

Conclusion: 这是首个引入基于AMR的概念熵进行上下文压缩的工作，展示了稳定语言特征在上下文工程中的潜力。

Abstract: Large Language Models (LLMs) face information overload when handling long contexts, particularly in Retrieval-Augmented Generation (RAG) where extensive supporting documents often introduce redundant content. This issue not only weakens reasoning accuracy but also increases computational overhead. We propose an unsupervised context compression framework that exploits Abstract Meaning Representation (AMR) graphs to preserve semantically essential information while filtering out irrelevant text. By quantifying node-level entropy within AMR graphs, our method estimates the conceptual importance of each node, enabling the retention of core semantics. Specifically, we construct AMR graphs from raw contexts, compute the conceptual entropy of each node, and screen significant informative nodes to form a condensed and semantically focused context than raw documents. Experiments on the PopQA and EntityQuestions datasets show that our method outperforms vanilla and other baselines, achieving higher accuracy while substantially reducing context length. To the best of our knowledge, this is the first work introducing AMR-based conceptual entropy for context compression, demonstrating the potential of stable linguistic features in context engineering.

</details>


### [53] [A Reproducible Framework for Neural Topic Modeling in Focus Group Analysis](https://arxiv.org/abs/2511.18843)
*Heger Arfaoui,Mohammed Iheb Hergli,Beya Benzina,Slimane BenMiled*

Main category: cs.CL

TL;DR: 提出了一个用于焦点小组讨论文本的计算分析框架，使用BERTopic模型解决超参数敏感性、模型稳定性和可解释性验证等挑战，并在HPV疫苗认知研究中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 传统焦点小组数据分析依赖劳动密集型手动编码，限制了可扩展性和可重复性，需要开发严谨的计算分析方法。

Method: 使用BERTopic对突尼斯HPV疫苗认知的10个焦点小组（1,076条话语）进行分析，系统评估27种超参数配置，通过30次bootstrap重采样评估稳定性，并由3位领域专家进行人工验证。

Result: 框架对超参数选择敏感，分层合并策略（先提取细粒度主题评估稳定性，再合并提高可解释性）在稳定性-连贯性权衡中表现良好（连贯性0.558 vs 0.539），人工验证显示良好评分者间信度（ICC=0.79，加权Cohen's kappa=0.578）。

Conclusion: 该框架为定性研究提供了实用的计算分析指南，所有代码、数据处理脚本和评估协议都公开可用，支持研究的复制和扩展。

Abstract: Focus group discussions generate rich qualitative data but their analysis traditionally relies on labor-intensive manual coding that limits scalability and reproducibility. We present a rigorous, reproducible computational framework for applying neural topic modeling to focus group transcripts, addressing fundamental methodological challenges: hyperparameter sensitivity, model stability, and validation of interpretability. Using BERTopic applied to ten focus groups exploring HPV vaccine perceptions in Tunisia (1,076 utterances), we conducted systematic evaluation across 27 hyperparameter configurations, assessed stability through bootstrap resampling with 30 replicates per configuration, and validated interpretability through formal human evaluation by three domain experts. Our analysis demonstrates substantial sensitivity to hyperparameter choices and reveals that metric selection for stability assessment must align with analytical goals. A hierarchical merging strategy (extracting fine-grained topics for stability then consolidating for interpretability) effectively navigates the stability-coherence tradeoff, achieving coherence of 0.558 compared to 0.539 for direct extraction. Human validation confirmed topic quality with very good inter-rater reliability (ICC = 0.79, weighted Cohen's kappa = 0.578). Our framework provides practical guidelines that researchers can adapt to their own qualitative research contexts. All code, data processing scripts, and evaluation protocols are publicly available to support reproduction and extension of this work.

</details>


### [54] [Large Language Models for the Summarization of Czech Documents: From History to the Present](https://arxiv.org/abs/2511.18848)
*Václav Tran,Jakub Šmíd,Ladislav Lenc,Jean-Pierre Salmon,Pavel Král*

Main category: cs.CL

TL;DR: 本文针对捷克语文本摘要任务，特别是历史文档摘要，通过使用大型语言模型（Mistral和mT5）和翻译方法，在SumeCzech数据集上取得了最先进的结果，并创建了新的历史捷克文本摘要数据集Posel od Čerchova。


<details>
  <summary>Details</summary>
Motivation: 捷克语摘要任务，特别是历史文档摘要，由于捷克语的语言复杂性和缺乏高质量标注数据集而研究不足。本文旨在填补这一空白。

Method: 使用Mistral和mT5等大型语言模型，并提出翻译方法：先将捷克文本翻译成英文，用英文模型摘要，再翻译回捷克语。

Result: 在SumeCzech数据集上取得了新的最先进结果，证明了多语言LLM对形态丰富的捷克语的有效性，并创建了新的历史捷克文本摘要数据集。

Conclusion: 通过结合先进模型与现代及历史捷克数据集，为捷克语摘要研究的进一步发展奠定了基础，为捷克历史文档处理和低资源摘要研究提供了宝贵资源。

Abstract: Text summarization is the task of automatically condensing longer texts into shorter, coherent summaries while preserving the original meaning and key information. Although this task has been extensively studied in English and other high-resource languages, Czech summarization, particularly in the context of historical documents, remains underexplored. This is largely due to the inherent linguistic complexity of Czech and the lack of high-quality annotated datasets.
  In this work, we address this gap by leveraging the capabilities of Large Language Models (LLMs), specifically Mistral and mT5, which have demonstrated strong performance across a wide range of natural language processing tasks and multilingual settings. In addition, we also propose a translation-based approach that first translates Czech texts into English, summarizes them using an English-language model, and then translates the summaries back into Czech. Our study makes the following main contributions: We demonstrate that LLMs achieve new state-of-the-art results on the SumeCzech dataset, a benchmark for modern Czech text summarization, showing the effectiveness of multilingual LLMs even for morphologically rich, medium-resource languages like Czech. We introduce a new dataset, Posel od Čerchova, designed for the summarization of historical Czech texts. This dataset is derived from digitized 19th-century publications and annotated for abstractive summarization. We provide initial baselines using modern LLMs to facilitate further research in this underrepresented area.
  By combining cutting-edge models with both modern and historical Czech datasets, our work lays the foundation for further progress in Czech summarization and contributes valuable resources for future research in Czech historical document processing and low-resource summarization more broadly.

</details>


### [55] [Cognitive Alpha Mining via LLM-Driven Code-Based Evolution](https://arxiv.org/abs/2511.18850)
*Fengyuan Liu,Huang Yi,Sichun Luo,Yuqi Wang,Yazheng Yang,Xinye Li,Zefa Hu,Junlan Feng,Qi Liu*

Main category: cs.CL

TL;DR: 提出了CogAlpha框架，结合代码级alpha表示、LLM驱动推理和进化搜索，用于在金融数据中发现有效的预测信号（alpha因子）。


<details>
  <summary>Details</summary>
Motivation: 现有方法（深度学习、遗传编程、LLM因子生成）在探索广阔alpha搜索空间时存在局限：神经网络模型产生不透明和脆弱的模式，符号或公式方法产生冗余或经济意义不足的表达式，且泛化能力差。

Method: 将LLM作为自适应认知代理，通过多阶段提示和金融反馈迭代优化、变异和重组alpha候选因子，结合代码级alpha表示和进化搜索。

Result: 在A股股票上的实验表明，CogAlpha能够持续发现具有优越预测准确性、鲁棒性和泛化能力的alpha因子，优于现有方法。

Conclusion: 将进化优化与基于LLM的推理相结合，有望实现自动化和可解释的alpha发现。

Abstract: Discovering effective predictive signals, or ``alphas,'' from financial data with high dimensionality and extremely low signal-to-noise ratio remains a difficult open problem. Despite progress in deep learning, genetic programming, and, more recently, large language model (LLM)--based factor generation, existing approaches still explore only a narrow region of the vast alpha search space. Neural models tend to produce opaque and fragile patterns, while symbolic or formula-based methods often yield redundant or economically ungrounded expressions that generalize poorly. Although different in form, these paradigms share a key limitation: none can conduct broad, structured, and human-like exploration that balances logical consistency with creative leaps. To address this gap, we introduce the Cognitive Alpha Mining Framework (CogAlpha), which combines code-level alpha representation with LLM-driven reasoning and evolutionary search. Treating LLMs as adaptive cognitive agents, our framework iteratively refines, mutates, and recombines alpha candidates through multi-stage prompts and financial feedback. This synergistic design enables deeper thinking, richer structural diversity, and economically interpretable alpha discovery, while greatly expanding the effective search space. Experiments on A-share equities demonstrate that CogAlpha consistently discovers alphas with superior predictive accuracy, robustness, and generalization over existing methods. Our results highlight the promise of aligning evolutionary optimization with LLM-based reasoning for automated and explainable alpha discovery. All source code will be released.

</details>


### [56] [FanarGuard: A Culturally-Aware Moderation Filter for Arabic Language Models](https://arxiv.org/abs/2511.18852)
*Masoomali Fatehkia,Enes Altinisik,Husrev Taha Sencar*

Main category: cs.CL

TL;DR: FanarGuard是一个双语内容审核过滤器，专注于阿拉伯语和英语的安全性和文化对齐性评估，在文化敏感性方面表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有内容审核过滤器主要关注通用安全性而忽视文化背景，特别是在阿拉伯文化语境中缺乏专门的文化对齐评估。

Method: 构建包含46.8万条提示-响应对的数据集，由LLM评委评估无害性和文化意识，训练两种过滤器变体，并开发首个针对阿拉伯文化背景的基准测试。

Result: FanarGuard与人类标注的一致性优于标注者间一致性，同时在安全性基准测试中达到最先进过滤器的性能水平。

Conclusion: 将文化意识整合到内容审核中至关重要，FanarGuard是实现更上下文敏感保障的实际步骤。

Abstract: Content moderation filters are a critical safeguard against alignment failures in language models. Yet most existing filters focus narrowly on general safety and overlook cultural context. In this work, we introduce FanarGuard, a bilingual moderation filter that evaluates both safety and cultural alignment in Arabic and English. We construct a dataset of over 468K prompt and response pairs, drawn from synthetic and public datasets, scored by a panel of LLM judges on harmlessness and cultural awareness, and use it to train two filter variants. To rigorously evaluate cultural alignment, we further develop the first benchmark targeting Arabic cultural contexts, comprising over 1k norm-sensitive prompts with LLM-generated responses annotated by human raters. Results show that FanarGuard achieves stronger agreement with human annotations than inter-annotator reliability, while matching the performance of state-of-the-art filters on safety benchmarks. These findings highlight the importance of integrating cultural awareness into moderation and establish FanarGuard as a practical step toward more context-sensitive safeguards.

</details>


### [57] [Generating Reading Comprehension Exercises with Large Language Models for Educational Applications](https://arxiv.org/abs/2511.18860)
*Xingyu Huang,Fei Jiang,Jianli Xiao*

Main category: cs.CL

TL;DR: 提出了名为RCEG的LLM框架，用于自动生成高质量的个性化英语阅读理解练习，通过微调LLM生成候选内容，使用判别器选择最佳候选，显著提升生成内容质量。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的快速发展，在教育领域特别是自动文本生成方面展现出巨大潜力，需要创建智能和自适应的学习内容。

Method: 使用微调的大语言模型生成内容候选，然后通过判别器选择最佳候选，构建专门的英语阅读理解数据集进行实验评估。

Result: 实验结果表明，RCEG显著提高了生成练习的相关性和认知适当性，在内容多样性、事实准确性、语言毒性和教学对齐等指标上表现良好。

Conclusion: RCEG框架能够有效生成高质量的个性化英语阅读理解练习，在教育领域具有重要应用价值。

Abstract: With the rapid development of large language models (LLMs), the applications of LLMs have grown substantially. In the education domain, LLMs demonstrate significant potential, particularly in automatic text generation, which enables the creation of intelligent and adaptive learning content. This paper proposes a new LLMs framework, which is named as Reading Comprehension Exercise Generation (RCEG). It can generate high-quality and personalized English reading comprehension exercises automatically. Firstly, RCEG uses fine-tuned LLMs to generate content candidates. Then, it uses a discriminator to select the best candidate. Finally, the quality of the generated content has been improved greatly. To evaluate the performance of RCEG, a dedicated dataset for English reading comprehension is constructed to perform the experiments, and comprehensive evaluation metrics are used to analyze the experimental results. These metrics include content diversity, factual accuracy, linguistic toxicity, and pedagogical alignment. Experimental results show that RCEG significantly improves the relevance and cognitive appropriateness of the generated exercises.

</details>


### [58] [Think Before You Prune: Selective Self-Generated Calibration for Pruning Large Reasoning Models](https://arxiv.org/abs/2511.18864)
*Yang Xiang,Yixin Ji,Juntao Li,Min Zhang*

Main category: cs.CL

TL;DR: 本文首次研究大型推理模型(LRMs)的剪枝问题，发现直接应用现有剪枝技术效果不佳，提出使用自生成推理数据进行校准可显著提升剪枝性能，并设计了选择性自生成推理(SSGR)数据构建策略。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型在复杂推理基准上表现出色，但其长链式推理过程带来显著推理开销。剪枝是减少计算成本的有前景方法，但现有研究主要关注大型语言模型(LLMs)，LRMs剪枝尚未探索。

Method: 提出选择性自生成推理(SSGR)数据构建策略，通过分析推理数据的难度和长度对剪枝效果的影响，发现具有挑战性和中等长度的自生成推理数据是理想的校准数据。

Result: 在DeepSeek-R1-Distill模型系列上的实验结果表明，相比通用剪枝方法，该策略将剪枝后LRMs的推理能力提升了10%-13%。

Conclusion: 使用自生成推理数据进行校准是LRMs剪枝的关键，选择性自生成推理数据构建策略能有效提升剪枝后模型的推理性能。

Abstract: Large Reasoning Models (LRMs) have demonstrated remarkable performance on complex reasoning benchmarks. However, their long chain-of-thought reasoning processes incur significant inference overhead. Pruning has emerged as a promising approach to reducing computational costs. However, existing efforts have primarily focused on large language models (LLMs), while pruning LRMs remains unexplored. In this work, we conduct the first empirical study on pruning LRMs and show that directly applying existing pruning techniques fails to yield satisfactory results. Our findings indicate that using self-generated reasoning data for calibration can substantially improve pruning performance. We further investigate how the difficulty and length of reasoning data affect pruning outcomes. Our analysis reveals that challenging and moderately long self-generated reasoning data serve as ideal calibration data. Based on these insights, we propose a Selective Self-Generated Reasoning (SSGR) data construction strategy to provide effective calibration data for pruning LRMs. Experimental results on the DeepSeek-R1-Distill model series validate that our strategy improves the reasoning ability of pruned LRMs by 10%-13% compared to general pruning methods.

</details>


### [59] [CoreEval: Automatically Building Contamination-Resilient Datasets with Real-World Knowledge toward Reliable LLM Evaluation](https://arxiv.org/abs/2511.18889)
*Jingqian Zhao,Bingbing Wang,Geng Tu,Yice Zhang,Qianlong Wang,Bin Liang,Jing Li,Ruifeng Xu*

Main category: cs.CL

TL;DR: CoreEval是一种抗数据污染的评估策略，通过从GDELT数据库获取最新知识来更新数据集，解决LLM评估中的数据污染问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法完全消除模型中的预存知识或保持原始数据集的语义复杂性，导致数据污染评估不准确。

Method: 从原始数据提取实体关系，利用GDELT数据库检索最新知识，重新语境化并整合知识，通过数据反射机制迭代验证标签。

Result: 在更新数据集上的广泛实验验证了CoreEval的鲁棒性，有效缓解了数据污染导致的性能高估问题。

Conclusion: CoreEval提供了一种有效的抗污染评估方法，能够确保LLM评估的公平性和准确性。

Abstract: Data contamination poses a significant challenge to the fairness of LLM evaluations in natural language processing tasks by inadvertently exposing models to test data during training. Current studies attempt to mitigate this issue by modifying existing datasets or generating new ones from freshly collected information. However, these methods fall short of ensuring contamination-resilient evaluation, as they fail to fully eliminate pre-existing knowledge from models or preserve the semantic complexity of the original datasets. To address these limitations, we propose \textbf{CoreEval}, a \textbf{Co}ntamination-\textbf{re}silient \textbf{Eval}uation strategy for automatically updating data with real-world knowledge. This approach begins by extracting entity relationships from the original data and leveraging the GDELT database to retrieve relevant, up-to-date knowledge. The retrieved knowledge is then recontextualized and integrated with the original data, which is refined and restructured to ensure semantic coherence and enhanced task relevance. Ultimately, a robust data reflection mechanism is employed to iteratively verify and refine labels, ensuring consistency between the updated and original datasets. Extensive experiments on updated datasets validate the robustness of CoreEval, demonstrating its effectiveness in mitigating performance overestimation caused by data contamination.

</details>


### [60] [Reproducibility Study of Large Language Model Bayesian Optimization](https://arxiv.org/abs/2511.18891)
*Adam Rychert,Gasper Spagnolo,Evgenii Posashkov*

Main category: cs.CL

TL;DR: 本研究复现了LLAMBO框架，使用开源的Llama 3.1 70B模型替代GPT-3.5进行贝叶斯优化实验，验证了该框架在不同语言模型骨干网络下的稳健性。


<details>
  <summary>Details</summary>
Motivation: 验证LLAMBO框架在不同语言模型骨干网络下的稳健性和有效性，特别是使用开源模型替代原论文中的GPT-3.5。

Method: 在原始评估协议下复现核心实验，使用Llama 3.1 70B模型替换GPT-3.5，进行Bayesmark和HPOBench实验，并进行了消融研究。

Result: 结果证实了LLAMBO的主要主张：上下文预热显著改善早期遗憾行为；判别代理模型虽弱于传统方法但受益于跨任务语义先验；候选采样器生成质量更高且更多样化的提案；小模型容量不足导致预测不稳定。

Conclusion: LLAMBO架构对语言模型骨干网络的变化具有稳健性，使用Llama 3.1 70B时仍保持有效，但需要足够容量的模型才能实现可靠的代理行为。

Abstract: In this reproducibility study, we revisit the LLAMBO framework of Daxberger et al. (2024), a prompting-based Bayesian optimization (BO) method that uses large language models as discriminative surrogates and acquisition optimizers via text-only interactions. We replicate the core Bayesmark and HPOBench experiments under the original evaluation protocol, but replace GPT-3.5 with the open-weight Llama 3.1 70B model used for all text encoding components.
  Our results broadly confirm the main claims of LLAMBO. Contextual warm starting via textual problem and hyperparameter descriptions substantially improves early regret behaviour and reduces variance across runs. LLAMBO's discriminative surrogate is weaker than GP or SMAC as a pure single task regressor, yet benefits from cross task semantic priors induced by the language model. Ablations that remove textual context markedly degrade predictive accuracy and calibration, while the LLAMBO candidate sampler consistently generates higher quality and more diverse proposals than TPE or random sampling. Experiments with smaller backbones (Gemma 27B, Llama 3.1 8B) yield unstable or invalid predictions, suggesting insufficient capacity for reliable surrogate behaviour.
  Overall, our study shows that the LLAMBO architecture is robust to changing the language model backbone and remains effective when instantiated with Llama 3.1 70B.

</details>


### [61] [Look It Up: Analysing Internal Web Search Capabilities of Modern LLMs](https://arxiv.org/abs/2511.18931)
*Sahil Kale*

Main category: cs.CL

TL;DR: 评估大型语言模型在需要时有效使用网络搜索的能力，发现网络访问能提高准确性但存在校准问题，模型在需要搜索时过度自信且查询表述能力弱。


<details>
  <summary>Details</summary>
Motivation: 研究现代大语言模型是否能在真正需要时有效调用网络搜索，以及搜索的必要性和有效性。

Method: 构建包含静态和动态问题的基准数据集，静态部分测试模型基于内部置信度调用搜索的能力，动态部分测试模型识别何时需要搜索并检索更新信息的能力。

Result: 网络访问显著提高了GPT-5-mini和Claude Haiku 4.5的静态准确性，但置信度校准变差；动态查询中模型频繁调用搜索但准确率低于70%，主要由于查询表述能力弱。

Conclusion: 内置网络搜索能有效提高事实准确性并选择性调用，但模型仍存在过度自信、在需要时跳过检索、以及初始搜索查询表现不佳时表现下降的问题。

Abstract: Modern large language models integrate web search to provide real-time answers, yet it remains unclear whether they are efficiently calibrated to use search when it is actually needed. We introduce a benchmark evaluating both the necessity and effectiveness of web access across commercial models with no access to internal states or parameters. The dataset includes a static split of 783 temporally anchored questions answerable from pre-cutoff knowledge, aimed at testing whether models invoke search based on low internal confidence, and a dynamic split of 288 post-cutoff queries designed to test whether models recognise when search is required and retrieve updated information. Web access substantially improves static accuracy for GPT-5-mini and Claude Haiku 4.5, though confidence calibration worsens. On dynamic queries, both models frequently invoke search yet remain below 70 percent accuracy due to weak query formulation. Costs per accuracy-improving call remain low, but returns diminish once initial retrieval fails. Selective invocation helps, but models become overconfident and inconsistent after search. Overall, built-in web search meaningfully improves factual accuracy and can be invoked selectively, yet models remain overconfident, skip retrieval when it is essential, and falter once initial search queries underperform. Taken together, internal web search works better as a good low-latency verification layer than a reliable analytical tool, with clear room for improvement.

</details>


### [62] [Skeletons Matter: Dynamic Data Augmentation for Text-to-Query](https://arxiv.org/abs/2511.18934)
*Yuchen Ji,Bo Xu,Jie Shi,Jiaqing Liang,Deqing Yang,Yu Mao,Hai Chen,Yanghua Xiao*

Main category: cs.CL

TL;DR: 本文提出了Text-to-Query任务范式，统一了不同查询语言的语义解析任务，通过识别查询骨架作为共享优化目标，并提出了动态数据增强框架来诊断模型弱点并合成针对性训练数据。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常只关注单一查询语言，导致方法在不同语言间的泛化能力有限。本文旨在统一不同查询语言的语义解析任务，提高方法的通用性。

Method: 提出Text-to-Query任务范式，识别查询骨架作为共享优化目标，开发动态数据增强框架来诊断模型在查询骨架处理上的弱点，并合成针对性训练数据。

Result: 在四个Text-to-Query基准测试中，仅使用少量合成数据就实现了最先进的性能，证明了方法的效率和通用性。

Conclusion: 该方法为Text-to-Query任务的统一研究奠定了坚实基础，代码已在GitHub开源。

Abstract: The task of translating natural language questions into query languages has long been a central focus in semantic parsing. Recent advancements in Large Language Models (LLMs) have significantly accelerated progress in this field. However, existing studies typically focus on a single query language, resulting in methods with limited generalizability across different languages. In this paper, we formally define the Text-to-Query task paradigm, unifying semantic parsing tasks across various query languages. We identify query skeletons as a shared optimization target of Text-to-Query tasks, and propose a general dynamic data augmentation framework that explicitly diagnoses model-specific weaknesses in handling these skeletons to synthesize targeted training data. Experiments on four Text-to-Query benchmarks demonstrate that our method achieves state-of-the-art performance using only a small amount of synthesized data, highlighting the efficiency and generality of our approach and laying a solid foundation for unified research on Text-to-Query tasks. We release our code at https://github.com/jjjycaptain/Skeletron.

</details>


### [63] [Knowledge-based Graphical Method for Safety Signal Detection in Clinical Trials](https://arxiv.org/abs/2511.18937)
*Francois Vandenhende,Anna Georgiou,Michalis Georgiou,Theodoros Psaras,Ellie Karekla,Elena Hadjicosta*

Main category: cs.CL

TL;DR: 提出了一种基于图形化知识的方法来审查临床试验中的治疗相关不良事件，通过为MedDRA添加隐藏医学知识层(Safeterm)来改进AE分析。


<details>
  <summary>Details</summary>
Motivation: 改进临床试验中不良事件(AE)的审查方法，通过增强MedDRA术语系统的语义理解能力，提高AE分析的清晰度、效率和准确性。

Method: 为MedDRA添加隐藏医学知识层(Safeterm)，在2D地图中捕获术语间的语义关系；自动将AE首选术语重新分组为相似性簇；使用收缩发生率比计算治疗特异性不成比例度量；通过精度加权聚合推导簇级EBGM值。

Result: 应用于三个历史试验，自动化方法清晰地恢复了所有预期的安全信号；提供两种可视化输出：显示AE发生率的语义地图和用于快速信号检测的期望度-不成比例度图。

Conclusion: 通过为MedDRA添加医学知识层，显著提高了临床试验中AE解释的清晰度、效率和准确性。

Abstract: We present a graphical, knowledge-based method for reviewing treatment-emergent adverse events (AEs) in clinical trials. The approach enhances MedDRA by adding a hidden medical knowledge layer (Safeterm) that captures semantic relationships between terms in a 2-D map. Using this layer, AE Preferred Terms can be regrouped automatically into similarity clusters, and their association to the trial disease may be quantified. The Safeterm map is available online and connected to aggregated AE incidence tables from ClinicalTrials.gov. For signal detection, we compute treatment-specific disproportionality metrics using shrinkage incidence ratios. Cluster-level EBGM values are then derived through precision-weighted aggregation. Two visual outputs support interpretation: a semantic map showing AE incidence and an expectedness-versus-disproportionality plot for rapid signal detection. Applied to three legacy trials, the automated method clearly recovers all expected safety signals. Overall, augmenting MedDRA with a medical knowledge layer improves clarity, efficiency, and accuracy in AE interpretation for clinical trials.

</details>


### [64] [Logic of Montage](https://arxiv.org/abs/2511.19063)
*Hayami Takahashi,Kensuke Takahashi*

Main category: cs.CL

TL;DR: 提出了一种补充自然语言的情感表达形式，通过矛盾结构效应和蒙太奇操作来构建情感表达的理论框架。


<details>
  <summary>Details</summary>
Motivation: 为情感表达提供一种独立于自然语言的替代形式，作为情感状态的代理或窗口。

Method: 建立矛盾结构效应模型，通过蒙太奇操作叠加结构效应，引入德勒兹的强度概念作为模型要素。

Result: 构建了通用的理论框架——系统间词语导入，并通过教育升级的例子展示了结构效应的过程。

Conclusion: 提出的情感表达形式能够有效补充自然语言，为情感状态的表达提供了新的理论工具。

Abstract: In expressing emotions, as an expression form separate from natural language, we propose an alternative form that complements natural language, acting as a proxy or window for emotional states. First, we set up an expression form "Effect of Contradictory Structure." "Effect of Contradictory Structure" is not static but dynamic. Effect in "Effect of Contradictory Structure" is unpleasant or pleasant, and the orientation to avoid that unpleasantness is considered pseudo-expression of will. Second, "Effect of Contradictory Structure" can be overlapped with each other. This overlapping operation is called "montage." A broader "Structure" that includes related "Effect of Contradictory Structure" and "Effect of Structure" are set up. Montage produces "Effect of Structure". In montage, it is necessary to set something like "strength," so we adopted Deleuze and Deleuze/Guattari's word "intensity" and set it as an element of our model. We set up a general theoretical framework - Word Import Between Systems (Models) and justified the import of "intensity" through Austin's use of the word "force." "Effect of Structure" process is demonstrated using the example of proceeding to the next level of education.

</details>


### [65] [GraphMind: Theorem Selection and Conclusion Generation Framework with Dynamic GNN for LLM Reasoning](https://arxiv.org/abs/2511.19078)
*Yutong Li,Yitian Zhou,Xudong Wang,GuoChen,Caiyan Qin*

Main category: cs.CL

TL;DR: GraphMind是一个将图神经网络与LLMs结合的动态图框架，用于多步推理中的定理选择和中间结论生成，通过异构图建模推理过程，在多个QA数据集上表现优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 现有LLMs在多步推理中缺乏显式的动态机制来结构化和演化中间推理状态，限制了上下文感知的定理选择和迭代结论生成能力。

Method: 将推理过程建模为异构图，节点表示条件、定理和结论，边捕获逻辑依赖关系，使用GNN编码当前推理状态，通过语义匹配进行定理选择，实现闭环的结构化推理。

Result: 在多个问答数据集上的实验表明，GraphMind方法实现了持续的性能提升，在多步推理中显著优于现有基线方法。

Conclusion: GraphMind框架通过图神经网络与LLMs的结合，实现了上下文感知、可解释和结构化的推理，验证了该方法的有效性和泛化能力。

Abstract: Large language models (LLMs) have demonstrated impressive capabilities in natural language understanding and generation, including multi-step reasoning such as mathematical proving. However, existing approaches often lack an explicit and dynamic mechanism to structurally represent and evolve intermediate reasoning states, which limits their ability to perform context-aware theorem selection and iterative conclusion generation. To address these challenges, we propose GraphMind, a novel dynamic graph-based framework that integrates the graph neural network (GNN) with LLMs to iteratively select theorems and generate intermediate conclusions for multi-step reasoning. Our method models the reasoning process as a heterogeneous evolving graph, where nodes represent conditions, theorems, and conclusions, while edges capture logical dependencies between nodes. By encoding the current reasoning state with GNN and leveraging semantic matching for theorem selection, our framework enables context-aware, interpretable, and structured reasoning in a closed-loop manner. Experiments on various question-answering (QA) datasets demonstrate that our proposed GraphMind method achieves consistent performance improvements and significantly outperforms existing baselines in multi-step reasoning, validating the effectiveness and generalizability of our approach.

</details>


### [66] [A Multi-Agent LLM Framework for Multi-Domain Low-Resource In-Context NER via Knowledge Retrieval, Disambiguation and Reflective Analysis](https://arxiv.org/abs/2511.19083)
*Wenxuan Mu,Jinzhong Ning,Di Zhao,Yijia Zhang*

Main category: cs.CL

TL;DR: 提出了KDR-Agent多智能体框架，通过知识检索、消歧和反思分析解决低资源命名实体识别问题，显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 解决现有基于上下文学习的NER方法在低资源场景下的三个关键局限：依赖动态检索标注数据、对未见领域泛化能力有限、无法整合外部知识或解决实体歧义

Method: KDR-Agent多智能体框架，包含知识检索、消歧和反思分析三个专门智能体，使用自然语言类型定义和静态实体级对比演示，减少对大型标注语料库的依赖

Result: 在5个领域的10个数据集上的实验表明，KDR-Agent在多个LLM骨干网络上显著优于现有的零样本和少样本ICL基线方法

Conclusion: KDR-Agent通过整合外部知识和结构化自我评估，有效提升了低资源多领域NER的性能，为ICL-based NER提供了新的解决方案

Abstract: In-context learning (ICL) with large language models (LLMs) has emerged as a promising paradigm for named entity recognition (NER) in low-resource scenarios. However, existing ICL-based NER methods suffer from three key limitations: (1) reliance on dynamic retrieval of annotated examples, which is problematic when annotated data is scarce; (2) limited generalization to unseen domains due to the LLM's insufficient internal domain knowledge; and (3) failure to incorporate external knowledge or resolve entity ambiguities. To address these challenges, we propose KDR-Agent, a novel multi-agent framework for multi-domain low-resource in-context NER that integrates Knowledge retrieval, Disambiguation, and Reflective analysis. KDR-Agent leverages natural-language type definitions and a static set of entity-level contrastive demonstrations to reduce dependency on large annotated corpora. A central planner coordinates specialized agents to (i) retrieve factual knowledge from Wikipedia for domain-specific mentions, (ii) resolve ambiguous entities via contextualized reasoning, and (iii) reflect on and correct model predictions through structured self-assessment. Experiments across ten datasets from five domains demonstrate that KDR-Agent significantly outperforms existing zero-shot and few-shot ICL baselines across multiple LLM backbones. The code and data can be found at https://github.com/MWXGOD/KDR-Agent.

</details>


### [67] [DeCoRL: Decoupling Reasoning Chains via Parallel Sub-Step Generation and Cascaded Reinforcement for Interpretable and Scalable RLHF](https://arxiv.org/abs/2511.19097)
*Ziyuan Gao,Di Liang,Xianjie Wu,Philippe Morel,Minlong Peng*

Main category: cs.CL

TL;DR: DeCoRL是一个新颖的强化学习框架，通过将推理过程从顺序处理转变为协作式模块化编排，解决了现有方法在可解释性和时间效率方面的限制。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法存在两个关键限制：1) 作为黑盒提供无差别奖励信号，难以诊断错误；2) 顺序解码具有O(n)时间复杂度，不适合实时部署复杂推理任务。

Method: 训练轻量级专用模型并行生成推理子步骤，设计模块化奖励函数独立评分每个子步骤，使用级联DRPO优化协调奖励同时保持步骤间依赖关系。

Result: 在RM-Bench、RMB和RewardBench上达到最先进结果，推理速度提升3.8倍，可解释性提高22.7%，能耗降低72.4%，吞吐量增加68%。

Conclusion: DeCoRL通过并行处理、精确错误归因和高效优化，使复杂推理系统的实时部署成为现实。

Abstract: Existing reinforcement learning methods for Chain-of-Thought reasoning suffer from two critical limitations. First, they operate as monolithic black boxes that provide undifferentiated reward signals, obscuring individual step contributions and hindering error diagnosis. Second, sequential decoding has O(n) time complexity. This makes real-time deployment impractical for complex reasoning tasks. We present DeCoRL (Decoupled Reasoning Chains via Coordinated Reinforcement Learning), a novel framework that transforms reasoning from sequential processing into collaborative modular orchestration. DeCoRL trains lightweight specialized models to generate reasoning sub-steps concurrently, eliminating sequential bottlenecks through parallel processing. To enable precise error attribution, the framework designs modular reward functions that score each sub-step independently. Cascaded DRPO optimization then coordinates these rewards while preserving inter-step dependencies. Comprehensive evaluation demonstrates state-of-the-art results across RM-Bench, RMB, and RewardBench, outperforming existing methods including large-scale models. DeCoRL delivers 3.8 times faster inference while maintaining superior solution quality and offers a 22.7\% improvement in interpretability through explicit reward attribution. These advancements, combined with a 72.4\% reduction in energy consumption and a 68\% increase in throughput, make real-time deployment of complex reasoning systems a reality.

</details>


### [68] [A symbolic Perl algorithm for the unification of Nahuatl word spellings](https://arxiv.org/abs/2511.19118)
*Juan-José Guzmán-Landa,Jesús Vázquez-Osorio,Juan-Manuel Torres-Moreno,Ligia Quintana Torres,Miguel Figueroa-Saavedra,Martha-Lorena Avendaño-Garrido,Graham Ranger,Patricia Velázquez-Morales,Gerardo Eugenio Sierra Martínez*

Main category: cs.CL

TL;DR: 提出一个基于符号模型和正则表达式的纳瓦特尔语文本自动正字法统一方法，并设计了人工评估协议来验证统一句子的质量。


<details>
  <summary>Details</summary>
Motivation: 解决纳瓦特尔语文本在不同正字法系统下的统一问题，便于语言处理和分析。

Method: 基于先前纳瓦特尔语句子分析算法，使用符号正则表达式实现语言规则，并利用π-yalli语料库进行开发。

Result: 在句子语义任务测试中，评估者对人工统一句子的多数期望特征给出了积极反馈。

Conclusion: 该方法在纳瓦特尔语文本自动正字法统一方面取得了令人鼓舞的成果。

Abstract: In this paper, we describe a symbolic model for the automatic orthographic unification of Nawatl text documents. Our model is based on algorithms that we have previously used to analyze sentences in Nawatl, and on the corpus called $π$-yalli, consisting of texts in several Nawatl orthographies. Our automatic unification algorithm implements linguistic rules in symbolic regular expressions. We also present a manual evaluation protocol that we have proposed and implemented to assess the quality of the unified sentences generated by our algorithm, by testing in a sentence semantic task. We have obtained encouraging results from the evaluators for most of the desired features of our artificially unified sentences

</details>


### [69] [On the Optimality of Discrete Object Naming: a Kinship Case Study](https://arxiv.org/abs/2511.19120)
*Phong Le,Mees Lindeman,Raquel G. Alhama*

Main category: cs.CL

TL;DR: 本文提出了一个信息论框架来分析自然语言命名系统，证明当听者的解码器等同于说话者的贝叶斯解码器时，才能实现信息丰富性与复杂度之间的最优权衡。


<details>
  <summary>Details</summary>
Motivation: 解决先前研究的两个简化假设：(i) 最优听者和(ii) 跨语言通用交际需求，为离散对象命名系统建立更现实的理论框架。

Method: 采用涌现通信中的指称游戏设置，专注于亲属关系语义域，引入信息论框架分析命名系统。

Result: 理论证明最优权衡是可实现的，并且在学习的通信系统中经验性地涌现出来。

Conclusion: 当听者解码器与说话者贝叶斯解码器等价时，命名系统能够在信息丰富性和复杂度之间达到最优平衡，这一理论结果在实际学习系统中得到了验证。

Abstract: The structure of naming systems in natural languages hinges on a trade-off between high informativeness and low complexity. Prior work capitalizes on information theory to formalize these notions; however, these studies generally rely on two simplifications: (i) optimal listeners, and (ii) universal communicative need across languages. Here, we address these limitations by introducing an information-theoretic framework for discrete object naming systems, and we use it to prove that an optimal trade-off is achievable if and only if the listener's decoder is equivalent to the Bayesian decoder of the speaker. Adopting a referential game setup from emergent communication, and focusing on the semantic domain of kinship, we show that our notion of optimality is not only theoretically achievable but also emerges empirically in learned communication systems.

</details>


### [70] [Emotion-Enhanced Multi-Task Learning with LLMs for Aspect Category Sentiment Analysis](https://arxiv.org/abs/2511.19122)
*Yaping Chai,Haoran Xie,Joe S. Qin*

Main category: cs.CL

TL;DR: 提出了一种情感增强的多任务方面类别情感分析框架，联合学习情感极性和基于Ekman六种基本情感的类别特定情感，通过VAD维度框架进行情感精炼，显著提升了ACSA性能。


<details>
  <summary>Details</summary>
Motivation: 现有ACSA方法主要关注情感极性，忽略了塑造情感表达的基本情感维度，这限制了模型捕捉针对特定方面类别的细粒度情感信号的能力。

Method: 基于LLMs的生成能力，提出多任务框架联合学习情感极性和类别特定情感，引入基于VAD维度框架的情感精炼机制，通过结构化LLM策略重新标注与VAD坐标不一致的情感。

Result: 实验结果表明，该方法在所有基准数据集上都显著优于强基线模型。

Conclusion: 将情感维度整合到ACSA中是有效的，情感增强方法能够显著提升方面类别情感分析的性能。

Abstract: Aspect category sentiment analysis (ACSA) has achieved remarkable progress with large language models (LLMs), yet existing approaches primarily emphasize sentiment polarity while overlooking the underlying emotional dimensions that shape sentiment expressions. This limitation hinders the model's ability to capture fine-grained affective signals toward specific aspect categories. To address this limitation, we introduce a novel emotion-enhanced multi-task ACSA framework that jointly learns sentiment polarity and category-specific emotions grounded in Ekman's six basic emotions. Leveraging the generative capabilities of LLMs, our approach enables the model to produce emotional descriptions for each aspect category, thereby enriching sentiment representations with affective expressions. Furthermore, to ensure the accuracy and consistency of the generated emotions, we introduce an emotion refinement mechanism based on the Valence-Arousal-Dominance (VAD) dimensional framework. Specifically, emotions predicted by the LLM are projected onto a VAD space, and those inconsistent with their corresponding VAD coordinates are re-annotated using a structured LLM-based refinement strategy. Experimental results demonstrate that our approach significantly outperforms strong baselines on all benchmark datasets. This underlines the effectiveness of integrating affective dimensions into ACSA.

</details>


### [71] [Eliciting Chain-of-Thought in Base LLMs via Gradient-Based Representation Optimization](https://arxiv.org/abs/2511.19131)
*Zijian Wang,Yanxiang Ma,Chang Xu*

Main category: cs.CL

TL;DR: 提出了一种基于概率条件生成的新方法，通过优化隐藏状态来激发基础大语言模型的思维链推理能力，在保持语言连贯性的同时提升推理性能。


<details>
  <summary>Details</summary>
Motivation: 基础大语言模型由于缺乏专门的推理训练，在处理复杂多步任务时表现不佳。现有的隐藏状态操纵方法存在刚性约束问题，容易导致分布偏移和文本质量下降。

Method: 将挑战重新表述为具有平衡似然和先验正则化框架的优化问题，通过概率条件生成指导隐藏状态朝向推理导向的轨迹发展。

Result: 在数学、常识和逻辑推理基准测试中，该方法始终优于现有的引导方法，显著提升了基础大语言模型的推理能力。

Conclusion: 该方法为增强基础大语言模型的推理能力提供了一个理论上有原则且有效的解决方案，通过隐藏状态操纵实现了更好的推理性能。

Abstract: Chain-of-Thought (CoT) reasoning is a critical capability for large language models (LLMs), enabling them to tackle com- plex multi-step tasks. While base LLMs, pre-trained on general text corpora, often struggle with reasoning due to a lack of specialized training, recent studies reveal their latent reason- ing potential tied to hidden states. However, existing hidden state manipulation methods, such as linear activation steering, suffer from limitations due to their rigid and unconstrained nature, often leading to distribution shifts and degraded text quality. In this work, we propose a novel approach for elic- iting CoT reasoning from base LLMs through hidden state manipulation grounded in probabilistic conditional generation. By reformulating the challenge as an optimization problem with a balanced likelihood and prior regularization framework, our method guides hidden states toward reasoning-oriented trajectories while preserving linguistic coherence. Extensive evaluations across mathematical, commonsense, and logical reasoning benchmarks demonstrate that our approach con- sistently outperforms existing steering methods, offering a theoretically principled and effective solution for enhancing reasoning capabilities in base LLMs.

</details>


### [72] [Representational Stability of Truth in Large Language Models](https://arxiv.org/abs/2511.19166)
*Samantha Dies,Courtney Maynard,Germans Savcisens,Tina Eliassi-Rad*

Main category: cs.CL

TL;DR: 本文提出了表征稳定性的概念，用于评估LLM对真实、虚假和中性内容内部概率表示的稳定性，发现稳定性更多源于认知熟悉度而非语言形式。


<details>
  <summary>Details</summary>
Motivation: 不清楚LLM如何在内部概率表示中稳定地区分真实、虚假和中性内容，需要评估其表征稳定性。

Method: 通过在LLM激活上训练线性探针来分离真实与非真实陈述，并测量在受控标签变化下学习决策边界的变化。

Result: 陌生中性陈述导致最大边界偏移（高达40%的真相判断翻转），而熟悉虚构陈述保持更一致的聚类和较小变化（≤8.2%）。

Conclusion: 表征稳定性更多源于认知熟悉度而非语言形式，该方法为审计和训练LLM提供了诊断工具，以在语义不确定性下保持一致的真相分配。

Abstract: Large language models (LLMs) are widely used for factual tasks such as "What treats asthma?" or "What is the capital of Latvia?". However, it remains unclear how stably LLMs encode distinctions between true, false, and neither-true-nor-false content in their internal probabilistic representations. We introduce representational stability as the robustness of an LLM's veracity representations to perturbations in the operational definition of truth. We assess representational stability by (i) training a linear probe on an LLM's activations to separate true from not-true statements and (ii) measuring how its learned decision boundary shifts under controlled label changes. Using activations from sixteen open-source models and three factual domains, we compare two types of neither statements. The first are fact-like assertions about entities we believe to be absent from any training data. We call these unfamiliar neither statements. The second are nonfactual claims drawn from well-known fictional contexts. We call these familiar neither statements. The unfamiliar statements induce the largest boundary shifts, producing up to $40\%$ flipped truth judgements in fragile domains (such as word definitions), while familiar fictional statements remain more coherently clustered and yield smaller changes ($\leq 8.2\%$). These results suggest that representational stability stems more from epistemic familiarity than from linguistic form. More broadly, our approach provides a diagnostic for auditing and training LLMs to preserve coherent truth assignments under semantic uncertainty, rather than optimizing for output accuracy alone.

</details>


### [73] [In Machina N400: Pinpointing Where a Causal Language Model Detects Semantic Violations](https://arxiv.org/abs/2511.19232)
*Christos-Nikolaos Zacharopoulos,Revekka Kyriakoglou*

Main category: cs.CL

TL;DR: 本文研究了transformer模型如何检测语义异常，发现模型在中间层才开始有效区分合理与不合理句子结尾，且异常检测过程经历了从探索到快速整合的转变。


<details>
  <summary>Details</summary>
Motivation: 探索transformer模型在何处以及如何检测句子语义异常，并与人类语言处理的心理语言学发现进行对比。

Method: 使用phi-2因果语言模型，通过精心设计的语料库评估合理与不合理句子结尾，采用线性探针分析各隐藏层的状态，并研究异常编码的有效维度。

Result: 线性解码器在模型底层难以区分语义异常，但在中间层准确率急剧上升；异常编码的表示子空间先扩大后收缩，表明从探索到整合的转变过程。

Conclusion: transformer模型的语义异常检测模式与人类阅读中的心理语言学发现一致，即语义异常在句法解析后才被检测，发生在在线处理序列的后期。

Abstract: How and where does a transformer notice that a sentence has gone semantically off the rails? To explore this question, we evaluated the causal language model (phi-2) using a carefully curated corpus, with sentences that concluded plausibly or implausibly. Our analysis focused on the hidden states sampled at each model layer. To investigate how violations are encoded, we utilized two complementary probes. First, we conducted a per-layer detection using a linear probe. Our findings revealed that a simple linear decoder struggled to distinguish between plausible and implausible endings in the lowest third of the model's layers. However, its accuracy sharply increased in the middle blocks, reaching a peak just before the top layers. Second, we examined the effective dimensionality of the encoded violation. Initially, the violation widens the representational subspace, followed by a collapse after a mid-stack bottleneck. This might indicate an exploratory phase that transitions into rapid consolidation. Taken together, these results contemplate the idea of alignment with classical psycholinguistic findings in human reading, where semantic anomalies are detected only after syntactic resolution, occurring later in the online processing sequence.

</details>


### [74] [MultiBanAbs: A Comprehensive Multi-Domain Bangla Abstractive Text Summarization Dataset](https://arxiv.org/abs/2511.19317)
*Md. Tanzim Ferdous,Naeem Ahsan Chowdhury,Prithwiraj Bhattacharjee*

Main category: cs.CL

TL;DR: 开发了一个包含54,000+孟加拉语文章和摘要的多领域数据集，用于抽象摘要研究，并建立了深度学习模型的基准性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注新闻文章，但现实中的孟加拉语内容来源多样（博客、社交媒体等），需要能够适应不同写作风格的摘要系统来减轻信息过载。

Method: 从多个来源（包括Cinegolpo博客、Samakal和The Business Standard报纸）收集数据，使用LSTM、BanglaT5-small和MTS-small等深度学习模型进行训练和评估。

Result: 建立了强大的基准性能，展示了该数据集作为孟加拉语自然语言处理未来研究基准的潜力。

Conclusion: 该数据集为构建鲁棒的摘要系统提供了坚实基础，有助于扩展低资源语言的NLP资源。

Abstract: This study developed a new Bangla abstractive summarization dataset to generate concise summaries of Bangla articles from diverse sources. Most existing studies in this field have concentrated on news articles, where journalists usually follow a fixed writing style. While such approaches are effective in limited contexts, they often fail to adapt to the varied nature of real-world Bangla texts. In today's digital era, a massive amount of Bangla content is continuously produced across blogs, newspapers, and social media. This creates a pressing need for summarization systems that can reduce information overload and help readers understand content more quickly. To address this challenge, we developed a dataset of over 54,000 Bangla articles and summaries collected from multiple sources, including blogs such as Cinegolpo and newspapers such as Samakal and The Business Standard. Unlike single-domain resources, our dataset spans multiple domains and writing styles. It offers greater adaptability and practical relevance. To establish strong baselines, we trained and evaluated this dataset using several deep learning and transfer learning models, including LSTM, BanglaT5-small, and MTS-small. The results highlight its potential as a benchmark for future research in Bangla natural language processing. This dataset provides a solid foundation for building robust summarization systems and helps expand NLP resources for low-resource languages.

</details>


### [75] [Learning to Reason: Training LLMs with GPT-OSS or DeepSeek R1 Reasoning Traces](https://arxiv.org/abs/2511.19333)
*Shaltiel Shmidman,Asher Fredman,Oleg Sudakov,Meriem Bendris*

Main category: cs.CL

TL;DR: 比较DeepSeek-R1和gpt-oss两种大型语言模型生成推理轨迹对中型LLM数学问题解决能力的影响，评估准确性和推理效率。


<details>
  <summary>Details</summary>
Motivation: 利用大型语言模型生成的推理轨迹作为高质量监督数据，无需昂贵人工标注即可训练中小型语言模型获得推理能力。

Method: 对中型LLM进行后训练，使用DeepSeek-R1和gpt-oss生成的两种推理轨迹数据，比较它们在数学问题上的表现。

Result: 评估两种推理轨迹在准确性和推理效率方面的影响差异。

Conclusion: 比较分析不同大型语言模型生成的推理轨迹对中型模型推理能力训练的效果。

Abstract: Test-time scaling, which leverages additional computation during inference to improve model accuracy, has enabled a new class of Large Language Models (LLMs) that are able to reason through complex problems by understanding the goal, turning this goal into a plan, working through intermediate steps, and checking their own work before answering . Frontier large language models with reasoning capabilities, such as DeepSeek-R1 and OpenAI's gpt-oss, follow the same procedure when solving complex problems by generating intermediate reasoning traces before giving the final answer. Today, these models are being increasingly used to generate reasoning traces that serve as high-quality supervised data for post-training of small and medium-sized language models to teach reasoning capabilities without requiring expensive human curation. In this work, we compare the performance of medium-sized LLMs on Math problems after post-training on two kinds of reasoning traces. We compare the impact of reasoning traces generated by DeepSeek-R1 and gpt-oss LLMs in terms of accuracy and inference efficiency.

</details>


### [76] [DR Tulu: Reinforcement Learning with Evolving Rubrics for Deep Research](https://arxiv.org/abs/2511.19399)
*Rulin Shao,Akari Asai,Shannon Zejiang Shen,Hamish Ivison,Varsha Kishore,Jingming Zhuo,Xinran Zhao,Molly Park,Samuel G. Finlayson,David Sontag,Tyler Murray,Sewon Min,Pradeep Dasigi,Luca Soldaini,Faeze Brahman,Wen-tau Yih,Tongshuang Wu,Luke Zettlemoyer,Yoon Kim,Hannaneh Hajishirzi,Pang Wei Koh*

Main category: cs.CL

TL;DR: 提出了RLER（强化学习与演进式评分标准）方法，开发了Deep Research Tulu（DR Tulu-8B）模型，这是首个专门为开放式长格式深度研究训练的开源模型，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有开源深度研究模型主要在可验证的短格式QA任务上训练，无法扩展到现实的长格式研究任务，需要新的训练方法。

Method: 使用RLER方法，构建和维护与策略模型共同演进的评分标准，使评分标准能够整合模型新探索的信息并提供区分性反馈。

Result: DR Tulu在科学、医疗和通用领域的四个长格式深度研究基准测试中大幅优于现有开源模型，性能匹配或超过专有系统，同时模型更小、查询成本更低。

Conclusion: RLER方法有效解决了长格式深度研究的训练挑战，DR Tulu展示了开源模型在复杂研究任务上的竞争力，为未来研究提供了数据、模型和代码资源。

Abstract: Deep research models perform multi-step research to produce long-form, well-attributed answers. However, most open deep research models are trained on easily verifiable short-form QA tasks via reinforcement learning with verifiable rewards (RLVR), which does not extend to realistic long-form tasks. We address this with Reinforcement Learning with Evolving Rubrics (RLER), in which we construct and maintain rubrics that co-evolve with the policy model during training; this allows the rubrics to incorporate information that the model has newly explored and to provide discriminative, on-policy feedback. Using RLER, we develop Deep Research Tulu (DR Tulu-8B), the first open model that is directly trained for open-ended, long-form deep research. Across four long-form deep research benchmarks in science, healthcare and general domains, DR Tulu substantially outperforms existing open deep research models, and matches or exceeds proprietary deep research systems, while being significantly smaller and cheaper per query. To facilitate future research, we release all data, models, and code, including our new MCP-based agent infrastructure for deep research systems.

</details>


### [77] [Be My Eyes: Extending Large Language Models to New Modalities Through Multi-Agent Collaboration](https://arxiv.org/abs/2511.19417)
*James Y. Huang,Sheng Zhang,Qianchu Liu,Guanghui Qin,Tinghui Zhu,Tristan Naumann,Muhao Chen,Hoifung Poon*

Main category: cs.CL

TL;DR: BeMyEyes是一个模块化多智能体框架，通过让高效的可视语言模型作为感知器与强大的大语言模型作为推理器进行对话协作，扩展LLMs的多模态推理能力，无需训练大规模多模态模型。


<details>
  <summary>Details</summary>
Motivation: 扩展LLMs到新模态（如视觉）通常需要开发成本高昂的大规模视觉语言模型，而较小的VLMs虽然高效但缺乏前沿LLMs的广泛知识和推理能力。

Method: 提出模块化多智能体框架，通过对话协调感知器和推理器的协作；引入数据合成和监督微调管道来训练感知器代理与推理器代理有效协作。

Result: 实验表明该框架为LLMs解锁了多模态推理能力，轻量级开源解决方案（DeepSeek-R1 + Qwen2.5-VL-7B）在广泛的知识密集型多模态任务上超越了GPT-4o等大规模专有VLMs。

Conclusion: BeMyEyes证明了多智能体方法在构建未来多模态推理系统方面的有效性、模块化和可扩展性，结合了感知和推理智能体的互补优势。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in challenging, knowledge-intensive reasoning tasks. However, extending LLMs to perceive and reason over a new modality (e.g., vision), often requires costly development of large-scale vision language models (VLMs) with LLMs as backbones. Smaller VLMs are more efficient and adaptable but often lack the broad knowledge and reasoning capabilities of frontier LLMs. In this work, we propose BeMyEyes, a modular, multi-agent framework for extending LLMs to multimodal reasoning by orchestrating collaboration between efficient, adaptable VLMs as perceivers and powerful LLMs as reasoners through conversations. We then introduce a data synthesis and supervised fine-tuning pipeline to train the perceiver agent to effectively collaborate with the reasoner agent. By combining the complementary strengths of perception and reasoning agents, BeMyEyes avoids the need for training large-scale multimodal models, preserves the generalization and reasoning capabilities of LLMs, and allows flexible extension to new domains and modalities. Experiments show that our framework unlocks the multimodal reasoning capabilities for LLMs, enabling a lightweight and fully open-source solution, i.e. equipping text-only DeepSeek-R1 with Qwen2.5-VL-7B perceiver, to outperform large-scale proprietary VLMs such as GPT-4o on a wide range of knowledge-intensive multimodal tasks. These results demonstrate the effectiveness, modularity, and scalability of our multi-agent approach for building future multimodal reasoning systems.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [78] [Beyond the Rubric: Cultural Misalignment in LLM Benchmarks for Sexual and Reproductive Health](https://arxiv.org/abs/2511.17554)
*Sumon Kanti Dey,Manvi S,Zeel Mehta,Meet Shah,Unnati Agrawal,Suhani Jalota,Azra Ismail*

Main category: cs.CY

TL;DR: 评估LLM在印度性健康咨询中的表现，发现现有基准存在西方偏见，需要开发文化适应性评估框架


<details>
  <summary>Details</summary>
Motivation: LLMs有潜力为全球南方提供健康信息服务，但现有评估基准主要基于西方规范，需要验证其在其他文化背景下的有效性

Method: 使用HealthBench基准评估637个性健康查询，通过自动评分和人工定性分析对比评估结果

Result: 自动评分系统给出的评分普遍较低，但人工分析显示许多回答在文化和医学上都是合适的，揭示了西方偏见问题

Conclusion: 当前评估基准在捕捉不同文化和医疗背景系统有效性方面存在局限，需要开发文化适应性评估框架

Abstract: Large Language Models (LLMs) have been positioned as having the potential to expand access to health information in the Global South, yet their evaluation remains heavily dependent on benchmarks designed around Western norms. We present insights from a preliminary benchmarking exercise with a chatbot for sexual and reproductive health (SRH) for an underserved community in India. We evaluated using HealthBench, a benchmark for conversational health models by OpenAI. We extracted 637 SRH queries from the dataset and evaluated on the 330 single-turn conversations. Responses were evaluated using HealthBench's rubric-based automated grader, which rated responses consistently low. However, qualitative analysis by trained annotators and public health experts revealed that many responses were actually culturally appropriate and medically accurate. We highlight recurring issues, particularly a Western bias, such as for legal framing and norms (e.g., breastfeeding in public), diet assumptions (e.g., fish safe to eat during pregnancy), and costs (e.g., insurance models). Our findings demonstrate the limitations of current benchmarks in capturing the effectiveness of systems built for different cultural and healthcare contexts. We argue for the development of culturally adaptive evaluation frameworks that meet quality standards while recognizing needs of diverse populations.

</details>


### [79] [A Cross-Cultural Assessment of Human Ability to Detect LLM-Generated Fake News about South Africa](https://arxiv.org/abs/2511.17682)
*Tim Schlippe,Matthias Wölfel,Koena Ronny Mabokela*

Main category: cs.CY

TL;DR: 文化亲近性对AI生成假新闻检测能力的影响研究：南非参与者比其他国家参与者更擅长识别本国真实新闻，但在识别假新闻方面表现更差，显示文化熟悉度在信息验证中的双重作用。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型能够生成复杂的假新闻，理解人类在不同文化背景下的检测能力变得至关重要，特别是在内容跨越文化和地理边界的信息生态系统中。

Method: 对89名参与者（56名南非人，33名其他国家人士）进行调查，让他们评估10篇真实的南非新闻文章和10篇AI生成的假新闻版本。

Result: 南非人在检测本国真实新闻方面表现更优（偏离理想评分40% vs 52%），但在识别假新闻方面表现更差（62% vs 55%）。南非人更依赖内容知识和上下文理解，而其他国家参与者更强调语言形式特征。

Conclusion: 文化熟悉度有助于验证真实信息，但在评估虚假内容时可能引入偏见，这对理解跨文化错误信息检测和应对AI生成假新闻的策略具有重要意义。

Abstract: This study investigates how cultural proximity affects the ability to detect AI-generated fake news by comparing South African participants with those from other nationalities. As large language models increasingly enable the creation of sophisticated fake news, understanding human detection capabilities becomes crucial, particularly across different cultural contexts. We conducted a survey where 89 participants (56 South Africans, 33 from other nationalities) evaluated 10 true South African news articles and 10 AI-generated fake versions. Results reveal an asymmetric pattern: South Africans demonstrated superior performance in detecting true news about their country (40% deviation from ideal rating) compared to other participants (52%), but performed worse at identifying fake news (62% vs. 55%). This difference may reflect South Africans' higher overall trust in news sources. Our analysis further shows that South Africans relied more on content knowledge and contextual understanding when judging credibility, while participants from other countries emphasised formal linguistic features such as grammar and structure. Overall, the deviation from ideal rating was similar between groups (51% vs. 53%), suggesting that cultural familiarity appears to aid verification of authentic information but may also introduce bias when evaluating fabricated content. These insights contribute to understanding cross-cultural dimensions of misinformation detection and inform strategies for combating AI-generated fake news in increasingly globalised information ecosystems where content crosses cultural and geographical boundaries.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [80] [Practical Machine Learning for Aphasic Discourse Analysis](https://arxiv.org/abs/2511.17553)
*Jason M. Pittman,Anton Phillips,Yesenia Medina-Santos,Brielle C. Stark*

Main category: cs.LG

TL;DR: 本研究评估了五种机器学习模型在失语症患者图片描述任务中自动识别正确信息单元(CIU)的能力，发现模型在区分词语与非词语方面表现优异，但在识别CIU方面仍有挑战。


<details>
  <summary>Details</summary>
Motivation: 手动进行CIU分析对言语治疗师来说劳动密集，需要自动化工具来辅助临床工作。

Method: 使用五种监督机器学习模型，基于失语症患者的人类编码转录本训练，评估其在图片描述任务中识别CIU的能力。

Result: 词语识别准确率达0.995，但CIU识别表现差异较大，k-NN模型表现最佳(准确率0.824，AUC 0.787)。

Conclusion: 机器学习模型能有效区分词语与非词语，但准确识别CIU仍具挑战性，需要进一步改进。

Abstract: Analyzing spoken discourse is a valid means of quantifying language ability in persons with aphasia. There are many ways to quantify discourse, one common way being to evaluate the informativeness of the discourse. That is, given the total number of words produced, how many of those are context-relevant and accurate. This type of analysis is called Correct Information Unit (CIU) analysis and is one of the most prevalent discourse analyses used by speech-language pathologists (SLPs). Despite this, CIU analysis in the clinic remains limited due to the manual labor needed by SLPs to code and analyze collected speech. Recent advances in machine learning (ML) seek to augment such labor by automating modeling of propositional, macrostructural, pragmatic, and multimodal dimensions of discourse. To that end, this study evaluated five ML models for reliable identification of Correct Information Units (CIUs, Nicholas & Brookshire, 1993), during a picture description task. The five supervised ML models were trained using randomly selected human-coded transcripts and accompanying words and CIUs from persons with aphasia. The baseline model training produced a high accuracy across transcripts for word vs non-word, with all models achieving near perfect performance (0.995) with high AUC range (0.914 min, 0.995 max). In contrast, CIU vs non-CIU showed a greater variability, with the k-nearest neighbor (k-NN) model the highest accuracy (0.824) and second highest AUC (0.787). These findings indicate that while the supervised ML models can distinguish word from not word, identifying CIUs is challenging.

</details>


### [81] [Efficient Mathematical Reasoning Models via Dynamic Pruning and Knowledge Distillation](https://arxiv.org/abs/2511.17577)
*Fengming Yu,Qingyu Meng,Haiwei Pan,Kejia Zhang*

Main category: cs.LG

TL;DR: 提出一种轻量级优化方法，结合动态注意力头剪枝和知识蒸馏，在保持数学推理能力的同时显著提升大语言模型的效率。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在数学推理任务中表现出色，但计算和存储成本高昂，阻碍实际部署。

Method: 使用权重范数和熵的组合动态评估多头注意力机制中每个注意力头的重要性，实时剪枝冗余头以减少计算开销，并通过知识蒸馏将原始模型信息转移到剪枝后的学生模型中。

Result: 在Math23k数据集上，30%剪枝率下参数减少18.7%，推理速度提升27.5%，FLOPs减少19.3%，准确率仅下降0.7%（从84.4%降至83.7%）。

Conclusion: 该方法在保持强大推理性能的同时实现了显著的效率提升，为大语言模型在数学推理任务中的高效部署提供了实用解决方案。

Abstract: With the rapid development of deep learning, large language models have shown strong capabilities in complex reasoning tasks such as mathematical equation solving. However, their substantial computational and storage costs hinder practical deployment. This paper proposes a lightweight optimization method that integrates dynamic attention head pruning with knowledge distillation. The approach dynamically evaluates the importance of each attention head in the multi-head attention mechanism using a combination of weight norms and entropy, and prunes redundant heads in real time to reduce computational overhead. To mitigate performance degradation, knowledge distillation transfers information from the original model to the pruned student, enabling the smaller model to preserve reasoning ability. Experiments conducted on both Math23k and ASDiv-A verify the effectiveness of the proposed method. For example, on Math23k with a 30% pruning ratio, parameters are reduced by 18.7%, inference speed is improved by 27.5%, FLOPs are reduced by 19.3%, and accuracy drops only 0.7% (from 84.4% to 83.7%). These results demonstrate that the method achieves substantial efficiency gains while maintaining strong reasoning performance, providing a practical solution for efficient deployment of large language models in mathematical reasoning tasks.

</details>


### [82] [Llamazip: Leveraging LLaMA for Lossless Text Compression and Training Dataset Detection](https://arxiv.org/abs/2511.17589)
*Sören Dréano,Derek Molloy,Noel Murphy*

Main category: cs.LG

TL;DR: Llamazip是一种基于LLaMA3语言模型预测能力的无损文本压缩算法，通过仅存储模型无法预测的令牌来实现显著数据压缩，同时还能识别文档是否属于语言模型训练数据集。


<details>
  <summary>Details</summary>
Motivation: 开发一种利用语言模型预测能力的高效无损文本压缩方法，同时解决语言模型训练数据溯源、知识产权和透明度等关键问题。

Method: 基于LLaMA3语言模型的预测能力，仅存储模型无法准确预测的令牌，通过分析量化程度和上下文窗口大小等关键因素来优化压缩性能。

Result: Llamazip实现了显著的数据压缩效果，同时能够有效识别文档是否属于语言模型的训练数据集，为数据溯源提供了新方法。

Conclusion: Llamazip不仅展示了语言模型在无损压缩方面的潜力，还提供了一种解决语言模型训练数据透明度和知识产权问题的新途径。

Abstract: This work introduces Llamazip, a novel lossless text compression algorithm based on the predictive capabilities of the LLaMA3 language model. Llamazip achieves significant data reduction by only storing tokens that the model fails to predict, optimizing storage efficiency without compromising data integrity. Key factors affecting its performance, including quantization and context window size, are analyzed, revealing their impact on compression ratios and computational requirements. Beyond compression, Llamazip demonstrates the potential to identify whether a document was part of the training dataset of a language model. This capability addresses critical concerns about data provenance, intellectual property, and transparency in language model training.

</details>


### [83] [PocketLLM: Ultimate Compression of Large Language Models via Meta Networks](https://arxiv.org/abs/2511.17637)
*Ye Tian,Chengcheng Wang,Jing Han,Yehui Tang,Kai Han*

Main category: cs.LG

TL;DR: PocketLLM是一种通过元网络在潜在空间压缩大语言模型的新方法，使用编码器将权重投影到离散潜在向量，通过紧凑码本表示，再用轻量解码器重建，实现高压缩比下的优异性能。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型规模持续增长，在边缘设备上存储和传输变得日益困难，传统量化剪枝方法难以在保持精度前提下实现极端压缩。

Method: 提出简单编码器网络将LLM权重投影到离散潜在向量，用紧凑码本表示，再通过轻量解码器将码本代表向量映射回原始权重空间。

Result: 实验表明PocketLLM在极高压缩比下仍保持优异性能，例如将Llama 2-7B压缩10倍而精度损失可忽略。

Conclusion: 该方法仅需小型解码器、简洁码本和索引，就能显著压缩LLM的大权重，为边缘设备部署提供有效解决方案。

Abstract: As Large Language Models (LLMs) continue to grow in size, storing and transmitting them on edge devices becomes increasingly challenging. Traditional methods like quantization and pruning struggle to achieve extreme compression of LLMs without sacrificing accuracy. In this paper, we introduce PocketLLM, a novel approach to compress LLMs in a latent space via meta-networks. A simple encoder network is proposed to project the weights of LLMs into discrete latent vectors, which are then represented using a compact codebook. A lightweight decoder network is employed to map the codebook's representative vectors back to the original weight space. This method allows for significant compression of the large weights in LLMs, consisting solely of a small decoder, a concise codebook, and an index. Extensive experiments show that PocketLLM achieves superior performance even at significantly high compression ratios, e.g., compressing Llama 2-7B by 10x with a negligible drop in accuracy.

</details>


### [84] [DeepCoT: Deep Continual Transformers for Real-Time Inference on Data Streams](https://arxiv.org/abs/2511.17693)
*Ginés Carreto Picón,Peng Yuan Zhou,Qi Zhang,Alexandros Iosifidis*

Main category: cs.LG

TL;DR: 提出DeepCoT模型，解决深度Transformer在流数据推理中的计算冗余问题，实现线性计算成本并显著提升运行效率


<details>
  <summary>Details</summary>
Motivation: Transformer模型规模不断增大，但在资源受限设备上进行低延迟流数据推理时存在高度冗余计算，现有Continual Transformers仅适用于浅层模型，限制了其应用范围和泛化能力

Method: 提出DeepCoT，一种无冗余的仅编码器模型，可应用于现有深度编码器架构，只需最小改动

Result: 在音频、视频和文本流数据实验中，DeepCoT保持与非持续基线模型相当的性能，同时所有Transformer层实现线性计算成本，运行时间比先前高效模型减少高达两个数量级

Conclusion: DeepCoT成功解决了深度Transformer在流数据推理中的计算效率问题，为资源受限设备上的高效推理提供了可行方案

Abstract: Transformer-based models have dramatically increased their size and parameter count to tackle increasingly complex tasks. At the same time, there is a growing demand for low-latency inference on resource-constrained devices that achieves high performance. In particular, stream data inference is typically performed over a sliding temporal window, leading to highly redundant computations. The recent Continual Transformers have addressed this issue, but they can only be effectively used in shallow models, which limits their scope and generalization power. In this paper, we propose the Deep Continual Transformer (DeepCoT), a redundancy-free encoder-only model that can be applied over existing deep encoder architectures with minimal changes. In our experiments over audio, video, and text streams, we show that DeepCoTs retain comparative performance to their non-continual baselines while offering a linear computational cost for all Transformer layers, which reduces up to two orders of magnitude in the running time compared to previous efficient models.

</details>


### [85] [Deterministic Inference across Tensor Parallel Sizes That Eliminates Training-Inference Mismatch](https://arxiv.org/abs/2511.17826)
*Ziyang Zhang,Xinheng Ding,Jiayi Yuan,Rixin Liu,Huizi Mao,Jiarong Xing,Zirui Liu*

Main category: cs.LG

TL;DR: 本文提出了Tree-Based Invariant Kernels (TBIK)来解决大语言模型推理中的非确定性问题，确保在不同张量并行配置下获得比特级相同的输出结果。


<details>
  <summary>Details</summary>
Motivation: 现有LLM服务框架存在非确定性行为：相同输入在不同系统配置（如TP大小、批大小）下会产生不同输出，这在LLM评估、多智能体系统和强化学习中会造成严重问题。

Method: 提出了树基不变核(TBIK)，通过统一的分层二叉树结构对齐GPU内和GPU间的归约顺序，实现TP不变的矩阵乘法和归约原语。

Result: 实验证实了零概率发散和比特级可重现性，在不同TP大小下实现了确定性推理，并在RL训练管道中实现了vLLM和FSDP之间的比特级相同结果。

Conclusion: TBIK有效解决了TP引起的非一致性问题，为LLM应用提供了可靠的确定性推理保障。

Abstract: Deterministic inference is increasingly critical for large language model (LLM) applications such as LLM-as-a-judge evaluation, multi-agent systems, and Reinforcement Learning (RL). However, existing LLM serving frameworks exhibit non-deterministic behavior: identical inputs can yield different outputs when system configurations (e.g., tensor parallel (TP) size, batch size) vary, even under greedy decoding. This arises from the non-associativity of floating-point arithmetic and inconsistent reduction orders across GPUs. While prior work has addressed batch-size-related nondeterminism through batch-invariant kernels, determinism across different TP sizes remains an open problem, particularly in RL settings, where the training engine typically uses Fully Sharded Data Parallel (i.e., TP = 1) while the rollout engine relies on multi-GPU TP to maximize the inference throughput, creating a natural mismatch between the two. This precision mismatch problem may lead to suboptimal performance or even collapse for RL training. We identify and analyze the root causes of TP-induced inconsistency and propose Tree-Based Invariant Kernels (TBIK), a set of TP-invariant matrix multiplication and reduction primitives that guarantee bit-wise identical results regardless of TP size. Our key insight is to align intra- and inter-GPU reduction orders through a unified hierarchical binary tree structure. We implement these kernels in Triton and integrate them into vLLM and FSDP. Experiments confirm zero probability divergence and bit-wise reproducibility for deterministic inference across different TP sizes. Also, we achieve bit-wise identical results between vLLM and FSDP in RL training pipelines with different parallel strategy. Code is available at https://github.com/nanomaoli/llm_reproducibility.

</details>


### [86] [Majority of the Bests: Improving Best-of-N via Bootstrapping](https://arxiv.org/abs/2511.18630)
*Amin Rakhsha,Kanika Madan,Tianyu Zhang,Amir-massoud Farahmand,Amir Khasahmadi*

Main category: cs.LG

TL;DR: 提出Majority-of-the-Bests (MoB)方法，通过自助采样估计Best-of-N的输出分布并选择其众数，在奖励模型不完美时比传统BoN方法表现更好。


<details>
  <summary>Details</summary>
Motivation: 传统Best-of-N方法在奖励模型不完美时性能急剧下降，因为正确答案通常不是概率最高的，但可能是最可能的结果。

Method: MoB通过自助采样估计BoN的输出分布，然后选择该分布的众数作为最终答案。

Result: 在5个基准测试、3种基础LLM和2种奖励模型的30个设置中，25个设置显示MoB相比BoN有持续改进。

Conclusion: MoB是BoN和自一致性方法的简单而强大的替代方案，激励进一步研究更精细的选择机制。

Abstract: Sampling multiple outputs from a Large Language Model (LLM) and selecting the most frequent (Self-consistency) or highest-scoring (Best-of-N) candidate is a popular approach to achieve higher accuracy in tasks with discrete final answers. Best-of-N (BoN) selects the output with the highest reward, and with perfect rewards, it often achieves near-perfect accuracy. With imperfect rewards from reward models, however, BoN fails to reliably find the correct answer and its performance degrades drastically. We consider the distribution of BoN's outputs and highlight that, although the correct answer does not usually have a probability close to one under imperfect rewards, it is often the most likely outcome. This suggests that the mode of this distribution can be more reliably correct than a sample from it. Based on this idea, we propose Majority-of-the-Bests (MoB), a novel selection mechanism that estimates the output distribution of BoN via bootstrapping and selects its mode. Experimental results across five benchmarks, three different base LLMs, and two reward models demonstrate consistent improvements over BoN in 25 out of 30 setups. We also provide theoretical results for the consistency of the bootstrapping. MoB serves as a simple, yet strong alternative to BoN and self-consistency, and more broadly, motivates further research in more nuanced selection mechanisms.

</details>


### [87] [How Learning Rate Decay Wastes Your Best Data in Curriculum-Based LLM Pretraining](https://arxiv.org/abs/2511.18903)
*Kairong Luo,Zhenbo Sun,Haodong Wen,Xinyu Shi,Jiarui Cui,Chenyi Dang,Kaifeng Lyu,Wenguang Chen*

Main category: cs.LG

TL;DR: 研究发现课程式预训练效果受限的原因是数据质量升序排列与学习率衰减计划不兼容，提出两种简单策略来缓解这一问题，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 由于高质量数据稀缺，LLM通常在混合质量数据上训练。课程式预训练按数据质量升序排列进行训练，但先前研究显示其改进有限，需要找出制约因素。

Method: 识别出数据质量升序与学习率衰减的不兼容性，提出两种策略：使用更温和的学习率衰减计划（最终学习率仅略小于峰值学习率），以及用模型平均替换学习率衰减（对最后几个检查点进行加权平均）。

Result: 结合这两种策略，在标准基准测试上的平均得分比随机洗牌提高了1.64%，在1.5B参数模型和30B tokens训练上验证了有效性。

Conclusion: 研究呼吁重新评估课程式LLM预训练方法，强调数据课程与优化方法协同设计的潜力。

Abstract: Due to the scarcity of high-quality data, large language models (LLMs) are often trained on mixtures of data with varying quality levels, even after sophisticated data curation. A natural approach to better leverage high-quality data is curriculum-based pretraining, where the model is trained on data sorted in ascending order of quality as determined by a quality metric. However, prior studies have reported limited improvements from such curriculum-based pretraining strategies. This work identifies a critical factor constraining these methods: the incompatibility between the ascending data quality order and the decaying learning rate (LR) schedule. We find that while curriculum-based training substantially outperforms random shuffling when using a constant LR, its advantage diminishes under standard LR decay schedules. Our experiments show this incompatibility can be mitigated by two simple strategies: (1) employing a more moderate LR decay schedule, where the final LR is only moderately smaller than the peak LR, and (2) replacing LR decay with model averaging, i.e., computing a weighted average of the final few checkpoints. By combining these strategies, we improve the average score on a suite of standard benchmarks by 1.64% over random shuffling, without additional data refinement. Validated on 1.5B-parameter models trained over 30B tokens with various data-quality metrics, our findings call for a re-evaluation of curriculum-based LLM pretraining and underscore the potential of co-designing data curricula with optimization methods.

</details>


### [88] [SWAN: Sparse Winnowed Attention for Reduced Inference Memory via Decompression-Free KV-Cache Compression](https://arxiv.org/abs/2511.18936)
*Santhosh G S,Saurav Prakash,Balaraman Ravindran*

Main category: cs.LG

TL;DR: SWAN是一种无需微调的KV缓存压缩框架，通过正交矩阵旋转和剪枝来减少内存占用，无需解压缩步骤，在50-60%内存节省下保持接近原始性能。


<details>
  <summary>Details</summary>
Motivation: LLM自回归推理中KV缓存的内存占用巨大，现有压缩技术存在信息丢失、固定限制或解压缩计算开销等问题。

Method: 使用离线正交矩阵旋转和剪枝KV缓存，无需重构直接用于注意力计算，结合小密集缓冲区实现运行时可调压缩级别。

Result: 在50-60%每token KV缓存内存节省下，性能接近未压缩基线，支持动态调整内存占用。

Conclusion: SWAN提供了一种无解压缩设计、高压缩性能下保持性能、适应性强的实用高效LLM长上下文服务解决方案。

Abstract: Large Language Models (LLMs) face a significant bottleneck during autoregressive inference due to the massive memory footprint of the Key-Value (KV) cache. Existing compression techniques like token eviction, quantization, or other low-rank methods often risk information loss, have fixed limits, or introduce significant computational overhead from explicit decompression steps. In this work, we introduce SWAN, a novel, fine-tuning-free framework that eliminates this overhead. Our method uses an offline orthogonal matrix to rotate and prune the KV-cache, which is then used directly in the attention computation without any reconstruction. Our extensive experiments demonstrate that SWAN, augmented with a small dense buffer, offers a robust trade-off, maintaining performance close to the uncompressed baseline even at aggressive 50-60% memory savings per-token on KV-cache. A key advantage is its runtime-tunable compression level, allowing operators to dynamically adjust the memory footprint, a flexibility absent in methods requiring fixed offline configurations. This combination of a decompression-free design, high performance under compression, and adaptability makes SWAN a practical and efficient solution for serving LLMs with long contexts.

</details>


### [89] [RAVEN++: Pinpointing Fine-Grained Violations in Advertisement Videos with Active Reinforcement Reasoning](https://arxiv.org/abs/2511.19168)
*Deyi Ji,Yuekui Yang,Liqun Liu,Peng Shu,Haiyang Wu,Shaogang Tang,Xudong Chen,Shaoping Ma,Tianrun Chen,Lanyun Zhu*

Main category: cs.LG

TL;DR: RAVEN++是一个改进的视频广告审核框架，通过主动强化学习、细粒度违规理解和渐进式多阶段训练，提升了违规检测的精确性、可解释性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有视频广告审核模型（如RAVEN）在细粒度理解、可解释性和泛化能力方面存在不足，需要更先进的解决方案来应对复杂的广告审核挑战。

Method: 1) 主动强化学习动态适应不同难度样本；2) 通过分层奖励函数和推理蒸馏实现细粒度违规理解；3) 渐进式多阶段训练结合知识注入、课程式被动强化学习和主动强化学习。

Result: 在公共和专有数据集上的实验表明，RAVEN++在细粒度违规理解、推理能力和泛化能力方面优于通用LLM和专用模型（如RAVEN），在线A/B测试也验证了其有效性。

Conclusion: RAVEN++通过创新的训练策略和架构设计，显著提升了视频广告审核的精确性和可解释性，为复杂广告内容审核提供了有效解决方案。

Abstract: Advertising (Ad) is a cornerstone of the digital economy, yet the moderation of video advertisements remains a significant challenge due to their complexity and the need for precise violation localization. While recent advancements, such as the RAVEN model, have improved coarse-grained violation detection, critical gaps persist in fine-grained understanding, explainability, and generalization. To address these limitations, we propose RAVEN++, a novel framework that introduces three key innovations: 1) Active Reinforcement Learning (RL), which dynamically adapts training to samples of varying difficulty; 2) Fine-Grained Violation Understanding, achieved through hierarchical reward functions and reasoning distillation; and 3) Progressive Multi-Stage Training, which systematically combines knowledge injection, curriculum-based passive RL, and active RL. Extensive experiments on both public and proprietary datasets, on both offline scenarios and online deployed A/B Testing, demonstrate that RAVEN++ outperforms general-purpose LLMs and specialized models like RAVEN in terms of fine-grained violation understanding, reasoning capabilities, and generalization ability.

</details>


### [90] [A Nutrition Multimodal Photoplethysmography Language Model](https://arxiv.org/abs/2511.19260)
*Kyle Verrier,Achille Nazaret,Joseph Futoma,Andrew C. Miller,Guillermo Sapiro*

Main category: cs.LG

TL;DR: 提出了一种结合可穿戴设备PPG信号和膳食描述的营养光电容积描记语言模型(NPLM)，用于非侵入式大规模饮食监测


<details>
  <summary>Details</summary>
Motivation: 饥饿和饱腹感动态影响饮食行为和代谢健康，但在日常环境中难以捕捉

Method: 将连续PPG信号投影到语言模型可解释的嵌入空间，与膳食描述联合推理，在19,340名参与者和110万份膳食-PPG数据对上训练

Result: 相比纯文本基线，每日热量摄入预测提升11%，即使去除80%膳食文本仍保持准确性，在独立验证研究(n=140)中结果可复现

Conclusion: 整合消费级可穿戴设备的生理测量与膳食信息对于大规模非侵入式饮食监测具有重要价值

Abstract: Hunger and satiety dynamics shape dietary behaviors and metabolic health, yet remain difficult to capture in everyday settings. We present a Nutrition Photoplethysmography Language Model (NPLM), integrating continuous photoplethysmography (PPG) from wearables with meal descriptions. NPLM projects PPG into embeddings interpretable by language models, enabling joint reasoning over physiology and meal context. Trained on 19,340 participants and 1.1 million meal-PPG pairs, the model improved daily caloric intake prediction by 11% over text-only baselines, with accuracy maintained when 80% of meal text was removed. In an independent validation study (n=140) with controlled dining and detailed meal information, the model replicated these findings. These results demonstrate the value of integrating physiological measurements from consumer wearables with meal information for noninvasive dietary monitoring at scale.

</details>


### [91] [CDLM: Consistency Diffusion Language Models For Faster Sampling](https://arxiv.org/abs/2511.19269)
*Minseo Kim,Chenfeng Xu,Coleman Hooper,Harman Singh,Ben Athiwaratkun,Ce Zhang,Kurt Keutzer,Amir Gholami*

Main category: cs.LG

TL;DR: CDLM通过一致性建模和块级因果注意力掩码，解决了扩散语言模型推理速度慢的问题，实现了3.6x-14.5x的延迟降低，同时保持数学和编程任务的准确率。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型虽然提供了并行生成的优势，但由于需要大量细化步骤且无法使用标准KV缓存，导致推理速度缓慢。

Method: CDLM结合一致性建模来大幅减少采样步骤，实现多令牌最终化；同时通过块级因果注意力掩码使模型完全兼容KV缓存。

Result: 实验显示CDLM在数学和编程任务上实现了3.6x-14.5x的延迟降低，同时保持了竞争力的准确率。

Conclusion: CDLM成功解决了扩散语言模型的两个主要瓶颈，为实际应用提供了高效的解决方案。

Abstract: Diffusion Language Models (DLMs) offer a promising parallel generation paradigm but suffer from slow inference due to numerous refinement steps and the inability to use standard KV caching. We introduce CDLM (Consistency Diffusion Language Models), a training-based acceleration method that simultaneously tackles both bottlenecks. CDLM integrates consistency modeling to drastically reduce the number of required sampling steps by enabling multi-token finalization. Furthermore, we enforce a block-wise causal attention mask during fine-tuning, making the model fully compatible with KV caching. Experiments show CDLM achieves 3.6x-14.5x lower latency while maintaining competitive accuracy on math and coding tasks. The full training and evaluation code is available at https://github.com/SqueezeAILab/CDLM.

</details>


### [92] [MapFormer: Self-Supervised Learning of Cognitive Maps with Input-Dependent Positional Embeddings](https://arxiv.org/abs/2511.19279)
*Victor Rambaud,Salvador Mascarenhas,Yair Lakretz*

Main category: cs.LG

TL;DR: MapFormers是基于Transformer的新架构，能够从观测数据中学习认知地图并以自监督方式执行路径整合，通过输入依赖的位置编码实现结构与内容解耦，在OOD泛化方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统缺乏人类和动物所具有的认知地图能力，这种能力能够编码实体间的抽象关系，提供强大的OOD泛化能力。为了弥合这一差距，需要开发能够学习认知地图的模型。

Method: 开发了MapFormers架构，通过更新Transformer中的位置编码为输入依赖矩阵，自然地实现结构与内容的解耦。提出了两种变体：绝对位置编码建模情景记忆(EM)和相对位置编码建模工作记忆(WM)。

Result: 在包括经典2D导航任务在内的多个任务上测试表明，MapFormers能够学习底层空间的认知地图，并在OOD泛化（如处理更长序列）方面达到近乎完美的性能，优于现有架构。

Conclusion: 结果表明，设计用于学习认知地图的模型具有优越性，引入结构偏置实现结构与内容解耦在Transformer中通过输入依赖的位置编码是可行的。MapFormers在神经科学和AI领域都有广泛应用前景。

Abstract: A cognitive map is an internal model which encodes the abstract relationships among entities in the world, giving humans and animals the flexibility to adapt to new situations, with a strong out-of-distribution (OOD) generalization that current AI systems still do not possess. To bridge this gap, we introduce MapFormers, new architectures based on Transformer models, which can learn cognitive maps from observational data and perform path integration in parallel, in a self-supervised manner. Cognitive maps are learned in the model by disentangling structural relationships in the inputs from their specific content, a property that can be achieved naturally by updating the positional encoding in Transformers with input-dependent matrices. We developed two variants of MapFormers that unify absolute and relative positional encoding to model episodic (EM) and working memory (WM), respectively. We tested MapFormers on several tasks, including a classic 2D navigation task, showing that our models can learn a cognitive map of the underlying space and generalize OOD (e.g., to longer sequences) with near-perfect performance, unlike current architectures. Together, these results demonstrate the superiority of models designed to learn a cognitive map, and the importance of introducing a structural bias for structure-content disentanglement, which can be achieved in Transformers with input-dependent positional encoding. MapFormers have broad applications in both neuroscience and AI, by explaining the neural mechanisms giving rise to cognitive maps, while allowing these relation models to be learned at scale.

</details>


### [93] [Scalable Parameter-Light Spectral Method for Clustering Short Text Embeddings with a Cohesion-Based Evaluation Metric](https://arxiv.org/abs/2511.19350)
*Nikita Neveditsin,Pawan Lingras,Vijay Mago*

Main category: cs.LG

TL;DR: 提出了一种可扩展的光谱方法来自动估计短文本嵌入的聚类数量，并提出了Cohesion Ratio指标用于无监督评估聚类质量，在多个数据集和嵌入模型上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 短文本嵌入聚类是NLP基础任务，但传统方法需要预先指定聚类数量，这在实际应用中是个挑战。

Method: 使用余弦相似度构建拉普拉斯特征谱，通过自适应采样策略直接从谱结构估计聚类数量，并提出Cohesion Ratio指标评估聚类质量。

Result: 在6个短文本数据集和4个嵌入模型上的实验表明，使用该方法指导的K-Means和HAC算法显著优于HDBSCAN、OPTICS和Leiden等参数较少的方法。

Conclusion: 该光谱估计器和Cohesion Ratio指标为短文本数据的无监督组织和评估提供了实用价值。

Abstract: Clustering short text embeddings is a foundational task in natural language processing, yet remains challenging due to the need to specify the number of clusters in advance. We introduce a scalable spectral method that estimates the number of clusters directly from the structure of the Laplacian eigenspectrum, constructed using cosine similarities and guided by an adaptive sampling strategy. This sampling approach enables our estimator to efficiently scale to large datasets without sacrificing reliability. To support intrinsic evaluation of cluster quality without ground-truth labels, we propose the Cohesion Ratio, a simple and interpretable evaluation metric that quantifies how much intra-cluster similarity exceeds the global similarity background. It has an information-theoretic motivation inspired by mutual information, and in our experiments it correlates closely with extrinsic measures such as normalized mutual information and homogeneity. Extensive experiments on six short-text datasets and four modern embedding models show that standard algorithms like K-Means and HAC, when guided by our estimator, significantly outperform popular parameter-light methods such as HDBSCAN, OPTICS, and Leiden. These results demonstrate the practical value of our spectral estimator and Cohesion Ratio for unsupervised organization and evaluation of short text data. Implementation of our estimator of k and Cohesion Ratio, along with code for reproducing the experiments, is available at https://anonymous.4open.science/r/towards_clustering-0C2E.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [94] [MURMUR: Using cross-user chatter to break collaborative language agents in groups](https://arxiv.org/abs/2511.17671)
*Atharv Singh Patlan,Peiyao Sheng,S. Ashwin Hebbar,Prateek Mittal,Pramod Viswanath*

Main category: cs.CR

TL;DR: 本文提出了跨用户投毒(CUP)攻击，这是多用户语言代理中的新攻击向量，攻击者通过注入看似正常的消息来污染共享状态，从而触发代理执行恶意操作。


<details>
  <summary>Details</summary>
Motivation: 随着语言代理从单用户助手扩展到多用户协作环境，现有的语言模型缺乏隔离用户交互和并发任务的机制，这为攻击者创造了新的攻击机会。

Method: 提出了MURMUR框架，使用LLM生成真实的、历史感知的用户交互，将单用户任务组合成并发的基于群体的场景，并验证了CUP攻击的有效性。

Result: CUP攻击在真实系统中成功率很高，其影响在多个任务中持续存在，对多用户LLM部署构成根本性风险。

Conclusion: 最后提出了基于任务聚类的初步防御措施来缓解这类新漏洞。

Abstract: Language agents are rapidly expanding from single-user assistants to multi-user collaborators in shared workspaces and groups. However, today's language models lack a mechanism for isolating user interactions and concurrent tasks, creating a new attack vector inherent to this new setting: cross-user poisoning (CUP). In a CUP attack, an adversary injects ordinary-looking messages that poison the persistent, shared state, which later triggers the agent to execute unintended, attacker-specified actions on behalf of benign users. We validate CUP on real systems, successfully attacking popular multi-user agents. To study the phenomenon systematically, we present MURMUR, a framework that composes single-user tasks into concurrent, group-based scenarios using an LLM to generate realistic, history-aware user interactions. We observe that CUP attacks succeed at high rates and their effects persist across multiple tasks, thus posing fundamental risks to multi-user LLM deployments. Finally, we introduce a first-step defense with task-based clustering to mitigate this new class of vulnerability

</details>


### [95] [Shadows in the Code: Exploring the Risks and Defenses of LLM-based Multi-Agent Software Development Systems](https://arxiv.org/abs/2511.18467)
*Xiaoqing Wang,Keman Huang,Bin Liang,Hongyu Li,Xiaoyong Du*

Main category: cs.CR

TL;DR: 本文研究了LLM驱动的多智能体系统在软件开发生态中的安全风险，识别了两种风险场景（恶意用户-良性代理和良性用户-恶意代理），提出了IMBIA攻击方法和Adv-IMBIA防御机制，并在主流框架上验证了攻击成功率和防御效果。


<details>
  <summary>Details</summary>
Motivation: 随着LLM驱动的多智能体系统使非技术用户也能开发可执行应用，这种民主化软件创建方式引入了尚未充分探索的安全风险，需要系统性地识别和应对这些风险。

Method: 提出了隐式恶意行为注入攻击（IMBIA）方法，展示如何操纵多智能体系统生成表面良性但内含恶意功能的软件；同时提出了Adv-IMBIA作为防御机制，并在ChatDev、MetaGPT和AgentVerse三个框架上进行评估。

Result: IMBIA攻击在不同框架中表现出不同的漏洞模式：在MU-BA场景中攻击成功率分别为93%、45%和71%，在BU-MA场景中分别为71%、84%和45%。防御机制显著降低了攻击成功率，特别是在MU-BA场景中。编码和测试阶段的被攻陷代理构成最大安全风险。

Conclusion: 研究发现多智能体软件开发系统迫切需要强大的安全措施，并提供了实施针对性、资源高效防御策略的实用指南，特别是需要保护关键代理免受恶意用户利用。

Abstract: The rapid advancement of Large Language Model (LLM)-driven multi-agent systems has significantly streamlined software developing tasks, enabling users with little technical expertise to develop executable applications. While these systems democratize software creation through natural language requirements, they introduce significant security risks that remain largely unexplored. We identify two risky scenarios: Malicious User with Benign Agents (MU-BA) and Benign User with Malicious Agents (BU-MA). We introduce the Implicit Malicious Behavior Injection Attack (IMBIA), demonstrating how multi-agent systems can be manipulated to generate software with concealed malicious capabilities beneath seemingly benign applications, and propose Adv-IMBIA as a defense mechanism. Evaluations across ChatDev, MetaGPT, and AgentVerse frameworks reveal varying vulnerability patterns, with IMBIA achieving attack success rates of 93%, 45%, and 71% in MU-BA scenarios, and 71%, 84%, and 45% in BU-MA scenarios. Our defense mechanism reduced attack success rates significantly, particularly in the MU-BA scenario. Further analysis reveals that compromised agents in the coding and testing phases pose significantly greater security risks, while also identifying critical agents that require protection against malicious user exploitation. Our findings highlight the urgent need for robust security measures in multi-agent software development systems and provide practical guidelines for implementing targeted, resource-efficient defensive strategies.

</details>


### [96] [Understanding and Mitigating Over-refusal for Large Language Models via Safety Representation](https://arxiv.org/abs/2511.19009)
*Junbo Zhang,Ran Chen,Qianli Zhou,Xinyang Deng,Wen Jiang*

Main category: cs.CR

TL;DR: 提出MOSR方法来缓解LLM的过度拒绝问题，通过在表示空间干预模型的安全表示，在保持安全性的同时减少过度拒绝。


<details>
  <summary>Details</summary>
Motivation: 现有LLM安全防御方法在提升安全性时往往导致严重的过度拒绝问题，无法在安全性和可用性之间取得良好平衡。

Method: MOSR包含两个核心组件：重叠感知损失加权（通过量化恶意样本与伪恶意样本在表示空间的相似性来确定擦除权重）和上下文感知增强（通过在拒绝响应前添加有害前缀来补充拒绝决策的必要上下文）。

Result: 实验表明该方法在缓解过度拒绝方面优于现有方法，同时很大程度上保持了安全性。

Conclusion: 未来的防御方法应该在安全性和过度拒绝之间取得更好的平衡。

Abstract: Large language models demonstrate powerful capabilities across various natural language processing tasks, yet they also harbor safety vulnerabilities. To enhance LLM safety, various jailbreak defense methods have been proposed to guard against harmful outputs. However, improvements in model safety often come at the cost of severe over-refusal, failing to strike a good balance between safety and usability. In this paper, we first analyze the causes of over-refusal from a representation perspective, revealing that over-refusal samples reside at the boundary between benign and malicious samples. Based on this, we propose MOSR, designed to mitigate over-refusal by intervening the safety representation of LLMs. MOSR incorporates two novel components: (1) Overlap-Aware Loss Weighting, which determines the erasure weight for malicious samples by quantifying their similarity to pseudo-malicious samples in the representation space, and (2) Context-Aware Augmentation, which supplements the necessary context for rejection decisions by adding harmful prefixes before rejection responses. Experiments demonstrate that our method outperforms existing approaches in mitigating over-refusal while largely maintaining safety. Overall, we advocate that future defense methods should strike a better balance between safety and over-refusal.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [97] [Robustness of Structured Data Extraction from Perspectively Distorted Documents](https://arxiv.org/abs/2511.17607)
*Hyakka Nakada,Yoshiyasu Tanaka*

Main category: cs.CV

TL;DR: 本文研究了文档图像中的平面旋转和透视畸变对多模态大语言模型Gemini-1.5-pro数据提取准确性的影响，发现结构识别精度受畸变影响显著，但可通过简单旋转校正改善。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的文档图像通常不仅存在平面旋转，还存在透视畸变，这些扰动会影响多模态LLMs的数据提取准确性，但相关研究不足。

Method: 通过观察典型文档畸变，发现其近似遵循等腰梯形变换，将参数从8个减少到2个（旋转角度和畸变比），在合成样本文档上评估字符识别和结构识别精度。

Result: 文档畸变显著降低了结构识别精度，但简单的旋转校正可以提高该精度。字符识别精度也受影响但程度较轻。

Conclusion: 文档畸变对多模态LLMs的OCR任务有显著影响，特别是结构识别精度，但通过旋转校正可以改善性能，这对实际应用具有重要意义。

Abstract: Optical Character Recognition (OCR) for data extraction from documents is essential to intelligent informatics, such as digitizing medical records and recognizing road signs. Multi-modal Large Language Models (LLMs) can solve this task and have shown remarkable performance. Recently, it has been noticed that the accuracy of data extraction by multi-modal LLMs can be affected when in-plane rotations are present in the documents. However, real-world document images are usually not only in-plane rotated but also perspectively distorted. This study investigates the impacts of such perturbations on the data extraction accuracy for the state-of-the-art model, Gemini-1.5-pro. Because perspective distortions have a high degree of freedom, designing experiments in the same manner as single-parametric rotations is difficult. We observed typical distortions of document images and showed that most of them approximately follow an isosceles-trapezoidal transformation, which allows us to evaluate distortions with a small number of parameters. We were able to reduce the number of independent parameters from eight to two, i.e. rotation angle and distortion ratio. Then, specific entities were extracted from synthetically generated sample documents with varying these parameters. As the performance of LLMs, we evaluated not only a character-recognition accuracy but also a structure-recognition accuracy. Whereas the former represents the classical indicators for optical character recognition, the latter is related to the correctness of reading order. In particular, the structure-recognition accuracy was found to be significantly degraded by document distortion. In addition, we found that this accuracy can be improved by a simple rotational correction. This insight will contribute to the practical use of multi-modal LLMs for OCR tasks.

</details>


### [98] [When Better Teachers Don't Make Better Students: Revisiting Knowledge Distillation for CLIP Models in VQA](https://arxiv.org/abs/2511.17886)
*Pume Tuchinda,Parinthapat Pengpun,Romrawin Chumpu,Sarana Nutanong,Peerat Limkonchotiwat*

Main category: cs.CV

TL;DR: 对CLIP风格视觉语言模型的知识蒸馏进行系统性研究，发现更强的教师模型并不总是产生更好的学生模型，现有蒸馏框架在多模态任务中表现不佳。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型计算需求大，知识蒸馏是构建轻量级模型的有效方法，但在CLIP风格模型中的应用有限，且通常局限于小规模教师和狭窄评估任务。

Method: 对一系列CLIP风格教师模型进行系统性蒸馏研究，包括标准基线和最先进的大规模模型。

Result: 与NLP和视觉领域趋势相反，更强的教师模型不能持续产生更好的学生模型，现有蒸馏框架在多模态任务中表现退化。

Conclusion: 研究结果挑战了知识蒸馏中的普遍假设，为设计参数高效的多模态模型指出了新方向。

Abstract: Vision-language models (VLMs) have achieved remarkable success across multimodal tasks, yet their substantial computational demands hinder efficient deployment. Knowledge distillation (KD) has emerged as a powerful approach for building lightweight but competitive models, with strong evidence from both language and vision domains. However, its application to VLMs, particularly CLIP-style models, remains limited, often constrained to small-scale teachers and narrow evaluation tasks such as classification or retrieval. In this work, we present the first systematic study of distillation across a range of CLIP-style teacher models, ranging from standard baselines to large-scale state-of-the-art models. Contrary to trends observed in NLP and vision, we find that stronger teachers do not consistently yield better students; in fact, existing distillation frameworks often fail to scale, leading to degraded performance in downstream multimodal tasks such as visual question answering. Our findings challenge prevailing assumptions in KD and point toward new directions for designing parameter-efficient multimodal models.

</details>


### [99] [IE-Critic-R1: Advancing the Explanatory Measurement of Text-Driven Image Editing for Human Perception Alignment](https://arxiv.org/abs/2511.18055)
*Bowen Qu,Shangkun Sun,Xiaoyu Liang,Wei Gao*

Main category: cs.CV

TL;DR: 提出了IE-Bench基准套件和IE-Critic-R1评估方法，用于改进文本驱动图像编辑的质量评估，通过人类标注的MOS分数和强化学习实现与人类感知的对齐。


<details>
  <summary>Details</summary>
Motivation: 文本驱动图像编辑的评估具有挑战性，现有方法主要关注文本-图像对齐或未能很好地对齐人类感知，需要同时考虑文本和源图像的约束。

Method: 构建IE-Bench数据库包含多样化的源图像、编辑提示和编辑结果，收集近4000个样本的人类MOS评分；开发IE-Critic-R1，利用可验证奖励的强化学习（RLVR）提供更全面和可解释的质量评估。

Result: 广泛实验表明，IE-Critic-R1在文本驱动图像编辑任务上相比先前指标具有更优越的主观对齐性。

Conclusion: IE-Bench和IE-Critic-R1为文本驱动图像编辑提供了更好的评估框架，相关数据和代码已公开。

Abstract: Recent advances in text-driven image editing have been significant, yet the task of accurately evaluating these edited images continues to pose a considerable challenge. Different from the assessment of text-driven image generation, text-driven image editing is characterized by simultaneously conditioning on both text and a source image. The edited images often retain an intrinsic connection to the original image, which dynamically change with the semantics of the text. However, previous methods tend to solely focus on text-image alignment or have not well aligned with human perception. In this work, we introduce the Text-driven Image Editing Benchmark suite (IE-Bench) to enhance the assessment of text-driven edited images. IE-Bench includes a database contains diverse source images, various editing prompts and the corresponding edited results from different editing methods, and nearly 4,000 samples with corresponding Mean Opinion Scores (MOS) provided by 15 human subjects. Furthermore, we introduce IE-Critic-R1, which, benefiting from Reinforcement Learning from Verifiable Rewards (RLVR), provides more comprehensive and explainable quality assessment for text-driven image editing that aligns with human perception. Extensive experiments demonstrate IE-Critic-R1's superior subjective-alignments on the text-driven image editing task compared with previous metrics. Related data and codes are available to the public.

</details>


### [100] [Bias Is a Subspace, Not a Coordinate: A Geometric Rethinking of Post-hoc Debiasing in Vision-Language Models](https://arxiv.org/abs/2511.18123)
*Dachuan Zhao,Weiyue Li,Zhenda Shen,Yushu Qiu,Bowen Xu,Haoyu Chen,Yongchao Chen*

Main category: cs.CV

TL;DR: 本文提出SPD方法，通过识别和移除线性可解码偏见的整个子空间，同时保留语义保真度，有效解决视觉语言模型中的偏见问题。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型(VLMs)的表征经常编码和放大人口统计偏见，导致下游任务中出现偏见关联和错位预测，影响公平性和视觉语言对齐。现有坐标替换方法存在特征纠缠、跨数据集泛化差和偏见移除不完整等问题。

Method: 提出子空间投影去偏见(SPD)框架，识别和移除线性可解码偏见的整个子空间，同时重新插入中性均值分量以保持语义保真度。

Result: 在零样本分类、文本到图像检索和图像生成任务上的广泛实验表明，SPD在四个公平性指标上平均提升18.5%，同时任务性能损失最小。

Conclusion: SPD方法通过几何原理框架实现了更稳健的去偏见效果，优于现有最佳去偏见基线方法。

Abstract: Vision-Language Models (VLMs) have become indispensable for multimodal reasoning, yet their representations often encode and amplify demographic biases, resulting in biased associations and misaligned predictions in downstream tasks. Such behavior undermines fairness and distorts the intended alignment between vision and language. Recent post-hoc approaches attempt to mitigate bias by replacing the most attribute-correlated embedding coordinates with neutral values. However, our systematic analysis reveals three critical failures of this coordinate-wise approach: feature entanglement, poor cross-dataset generalization, and incomplete bias removal. We find that bias is not localized to a few coordinates but is instead distributed across a few linear subspaces. To address these limitations, we propose $\textbf{S}$ubspace $\textbf{P}$rojection $\textbf{D}$ebiasing ($\textbf{SPD}$), a geometrically principled framework that identifies and removes the entire subspace of linearly decodable bias while reinserting a neutral mean component to preserve semantic fidelity. Extensive experiments across zero-shot classification, text-to-image retrieval, and image generation validate the effectiveness of SPD: our method achieves more robust debiasing with an average improvement of $18.5\%$ across four fairness metrics, while maintaining minimal loss in task performance compared to the best debiasing baseline.

</details>


### [101] [Assessing the alignment between infants' visual and linguistic experience using multimodal language models](https://arxiv.org/abs/2511.18824)
*Alvin Wei Ming Tan,Jane Yang,Tarun Sepuri,Khai Loong Aw,Robert Z. Sparks,Zi Yin,Virginia A. Marchman,Michael C. Frank,Bria Long*

Main category: cs.CV

TL;DR: 使用CLIP模型自动分析婴儿视角视频中视觉-语言对齐情况，发现理想化的学习对齐时刻在日常生活中相对罕见。


<details>
  <summary>Details</summary>
Motivation: 研究儿童语言学习过程中视觉和语言体验的时间对齐程度，传统方法依赖人工标注，需要更高效的自动化分析工具。

Method: 使用对比性语言-图像预训练（CLIP）模型来自动化分析婴儿视角视频中的视觉-语言对齐，并通过人工判断验证CLIP对齐分数的准确性。

Result: 理想化的学习对齐时刻（如"看球"时球确实在儿童视野中）在儿童日常体验中相对罕见，与现代机器学习数据集相比频率较低，且不同儿童之间存在变异性。

Conclusion: 不频繁的对齐是早期词汇学习模型的约束条件，该方法为研究儿童多模态环境提供了新工具。

Abstract: Figuring out which objects or concepts words refer to is a central language learning challenge for young children. Most models of this process posit that children learn early object labels from co-occurrences of words and their referents that occur when someone around them talks about an object in the immediate physical environment. But how aligned in time are children's visual and linguistic experiences during everyday learning? To date, answers to this question have been limited by the need for labor-intensive manual annotations of vision-language co-occurrences. Here, we evaluate the use of contrastive language-image pretraining (CLIP) models to automatically characterize vision-language alignment in egocentric videos taken from the infant perspective in home environments. After validating CLIP alignment scores using human alignment judgments, we apply this metric to a large corpus of infant-perspective videos. We show that idealized aligned moments for learning (e.g., "look at the ball" with a ball present in the child's view) are relatively rare in children's everyday experiences compared to modern machine learning datasets, and highlight variability in alignment both within and across children. These findings suggest that infrequent alignment is a constraint for models describing early word learning and offer a new method for investigating children's multimodal environment.

</details>


### [102] [From Pixels to Posts: Retrieval-Augmented Fashion Captioning and Hashtag Generation](https://arxiv.org/abs/2511.19149)
*Moazzam Umer Gondal,Hamad Ul Qudous,Daniya Siddiqui,Asma Ahmad Farhan*

Main category: cs.CV

TL;DR: 提出基于检索增强的时尚图像描述和标签生成框架，结合多服装检测、属性推理和LLM提示，生成视觉基础扎实、描述性强且风格有趣的文本。


<details>
  <summary>Details</summary>
Motivation: 克服端到端描述模型在属性保真度和领域泛化方面的局限性，为时尚图像生成视觉基础扎实、描述性强且风格有趣的文本内容。

Method: 使用YOLO检测器进行多服装定位，k-means聚类提取主色调，CLIP-FAISS检索模块基于结构化产品索引推断面料和性别属性，结合检索到的风格示例构建事实证据包来指导LLM生成描述和标签。

Result: YOLO检测器在9类服装上获得0.71的mAP@0.5；RAG-LLM管道生成表达力强的属性对齐描述，在标签生成中平均属性覆盖率达0.80，50%阈值下达到完全覆盖；相比BLIP具有更好的事实基础和更少的幻觉。

Conclusion: 检索增强生成是自动化和视觉基础时尚内容生成的有效且可解释的范式，在多种服装领域具有可扩展部署的巨大潜力。

Abstract: This paper introduces the retrieval-augmented framework for automatic fashion caption and hashtag generation, combining multi-garment detection, attribute reasoning, and Large Language Model (LLM) prompting. The system aims to produce visually grounded, descriptive, and stylistically interesting text for fashion imagery, overcoming the limitations of end-to-end captioners that have problems with attribute fidelity and domain generalization. The pipeline combines a YOLO-based detector for multi-garment localization, k-means clustering for dominant color extraction, and a CLIP-FAISS retrieval module for fabric and gender attribute inference based on a structured product index. These attributes, together with retrieved style examples, create a factual evidence pack that is used to guide an LLM to generate human-like captions and contextually rich hashtags. A fine-tuned BLIP model is used as a supervised baseline model for comparison. Experimental results show that the YOLO detector is able to obtain a mean Average Precision (mAP@0.5) of 0.71 for nine categories of garments. The RAG-LLM pipeline generates expressive attribute-aligned captions and achieves mean attribute coverage of 0.80 with full coverage at the 50% threshold in hashtag generation, whereas BLIP gives higher lexical overlap and lower generalization. The retrieval-augmented approach exhibits better factual grounding, less hallucination, and great potential for scalable deployment in various clothing domains. These results demonstrate the use of retrieval-augmented generation as an effective and interpretable paradigm for automated and visually grounded fashion content generation.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [103] [Speech Recognition Model Improves Text-to-Speech Synthesis using Fine-Grained Reward](https://arxiv.org/abs/2511.17555)
*Guansu Wang,Peijie Sun*

Main category: eess.AS

TL;DR: W3AR使用预训练ASR模型的注意力机制为TTS模型提供细粒度的词级对齐奖励，无需显式标注即可提升TTS系统的质量和零样本鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统TTS评估方法（如MOS）在整句层面进行回归，而失败通常发生在少数问题词汇上，需要更细粒度的评估信号。

Method: 利用编码器-解码器ASR模型（如Whisper）的交叉注意力机制，捕捉语音与文本之间的词级不匹配，作为TTS模型的细粒度奖励信号进行优化。

Result: 实验表明W3AR能提升现有TTS系统的质量，并增强对未见说话人的零样本鲁棒性。

Conclusion: 理解模型可以作为评估器，为生成模型提供信息丰富、细粒度的反馈以进行优化。

Abstract: Recent advances in text-to-speech (TTS) have enabled models to clone arbitrary unseen speakers and synthesize high-quality, natural-sounding speech. However, evaluation methods lag behind: typical mean opinion score (MOS) estimators perform regression over entire utterances, while failures usually occur in a few problematic words. We observe that encoder-decoder ASR models (e.g., Whisper) surface word-level mismatches between speech and text via cross-attention, providing a fine-grained reward signal. Building on this, we introduce Word-level TTS Alignment by ASR-driven Attentive Reward (W3AR). Without explicit reward annotations, W3AR uses attention from a pre-trained ASR model to drive finer-grained alignment and optimization of sequences predicted by a TTS model. Experiments show that W3AR improves the quality of existing TTS systems and strengthens zero-shot robustness on unseen speakers. More broadly, our results suggest a simple recipe for generative modeling: understanding models can act as evaluators, delivering informative, fine-grained feedback for optimization.

</details>


### [104] [InstructAudio: Unified speech and music generation with natural language instruction](https://arxiv.org/abs/2511.18487)
*Chunyu Qiang,Kang Yin,Xiaopeng Wang,Yuzhe Liang,Jiahui Zhao,Ruibo Fu,Tianrui Wang,Cheng Gong,Chen Zhang,Longbiao Wang,Jianwu Dang*

Main category: eess.AS

TL;DR: InstructAudio是一个统一的指令控制框架，通过自然语言描述实现对音频属性的控制，支持语音、音乐和对话生成，在英语和中文中均表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的TTS和TTM模型在基于指令的控制方面存在显著限制，TTS系统通常依赖参考音频控制音色，TTM系统受限于需要专家知识标注的输入条件，两者难以实现统一建模。

Method: 采用联合和单扩散变换器层，使用标准化的指令-音素输入格式，在5万小时语音和2万小时音乐数据上训练，实现多任务学习和跨模态对齐。

Result: 与主流TTS和TTM模型相比，InstructAudio在大多数指标上达到最优结果，支持音色、副语言和音乐属性的指令控制。

Conclusion: InstructAudio是首个统一语音和音乐生成的指令控制框架，解决了现有系统在自然语言指令控制方面的局限性。

Abstract: Text-to-speech (TTS) and text-to-music (TTM) models face significant limitations in instruction-based control. TTS systems usually depend on reference audio for timbre, offer only limited text-level attribute control, and rarely support dialogue generation. TTM systems are constrained by input conditioning requirements that depend on expert knowledge annotations. The high heterogeneity of these input control conditions makes them difficult to joint modeling with speech synthesis. Despite sharing common acoustic modeling characteristics, these two tasks have long been developed independently, leaving open the challenge of achieving unified modeling through natural language instructions. We introduce InstructAudio, a unified framework that enables instruction-based (natural language descriptions) control of acoustic attributes including timbre (gender, age), paralinguistic (emotion, style, accent), and musical (genre, instrument, rhythm, atmosphere). It supports expressive speech, music, and dialogue generation in English and Chinese. The model employs joint and single diffusion transformer layers with a standardized instruction-phoneme input format, trained on 50K hours of speech and 20K hours of music data, enabling multi-task learning and cross-modal alignment. Fig. 1 visualizes performance comparisons with mainstream TTS and TTM models, demonstrating that InstructAudio achieves optimal results on most metrics. To our best knowledge, InstructAudio represents the first instruction-controlled framework unifying speech and music generation. Audio samples are available at: https://qiangchunyu.github.io/InstructAudio/

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [105] [Bridging Symbolic Control and Neural Reasoning in LLM Agents: The Structured Cognitive Loop](https://arxiv.org/abs/2511.17673)
*Myung Ho Kim*

Main category: cs.AI

TL;DR: 提出结构化认知循环(SCL)架构，通过模块化设计分离推理与执行，解决大语言模型代理的架构问题，实现零策略违规和完全决策可追溯性。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型代理存在的三个基本架构问题：推理与执行纠缠、内存易失性和不可控动作序列。

Method: 引入SCL架构，将代理认知明确分为五个阶段：检索、认知、控制、动作和记忆(R-CCAM)，核心是软符号控制机制，将符号约束应用于概率推理。

Result: 在多步条件推理任务中实现零策略违规、消除冗余工具调用，并保持完全决策可追溯性。

Conclusion: 通过连接专家系统原理与现代LLM能力，为可靠、可解释和可治理的AI代理提供了实用且理论基础的路径。

Abstract: Large language model agents suffer from fundamental architectural problems: entangled reasoning and execution, memory volatility, and uncontrolled action sequences. We introduce Structured Cognitive Loop (SCL), a modular architecture that explicitly separates agent cognition into five phases: Retrieval, Cognition, Control, Action, and Memory (R-CCAM). At the core of SCL is Soft Symbolic Control, an adaptive governance mechanism that applies symbolic constraints to probabilistic inference, preserving neural flexibility while restoring the explainability and controllability of classical symbolic systems. Through empirical validation on multi-step conditional reasoning tasks, we demonstrate that SCL achieves zero policy violations, eliminates redundant tool calls, and maintains complete decision traceability. These results address critical gaps in existing frameworks such as ReAct, AutoGPT, and memory-augmented approaches. Our contributions are threefold: (1) we situate SCL within the taxonomy of hybrid intelligence, differentiating it from prompt-centric and memory-only approaches; (2) we formally define Soft Symbolic Control and contrast it with neuro-symbolic AI; and (3) we derive three design principles for trustworthy agents: modular decomposition, adaptive symbolic governance, and transparent state management. We provide a complete open-source implementation demonstrating the R-CCAM loop architecture, alongside a live GPT-4o-powered travel planning agent. By connecting expert system principles with modern LLM capabilities, this work offers a practical and theoretically grounded path toward reliable, explainable, and governable AI agents. Code: https://github.com/enkiluv/scl-core-experiment Demo: https://scl-travel-planner.streamlit.app/

</details>


### [106] [Paper2SysArch: Structure-Constrained System Architecture Generation from Scientific Papers](https://arxiv.org/abs/2511.18036)
*Ziyi Guo,Zhou Liu,Wentao Zhang*

Main category: cs.AI

TL;DR: 提出了首个用于自动生成科学论文系统架构图的标准化基准，包含3000篇论文及其对应的高质量图表，并开发了Paper2SysArch系统作为基准测试的强基线。


<details>
  <summary>Details</summary>
Motivation: 手动创建系统架构图耗时且主观，现有生成模型缺乏结构控制和语义理解能力，该领域缺乏标准化基准来定量评估文本到图表的自动生成。

Method: 创建包含3000篇研究论文及其对应高质量图表的基准数据集，采用三层评估指标（语义准确性、布局连贯性、视觉质量）；提出Paper2SysArch系统，利用多智能体协作将论文转换为结构化、可编辑的图表。

Result: 在手动筛选的更具挑战性的论文子集上，Paper2SysArch系统获得了69.0的综合得分，验证了其在复杂情况下的性能。

Conclusion: 主要贡献是建立了大规模基础基准以支持可重复研究和公平比较，提出的系统作为可行概念验证，为这一复杂任务展示了有前景的发展路径。

Abstract: The manual creation of system architecture diagrams for scientific papers is a time-consuming and subjective process, while existing generative models lack the necessary structural control and semantic understanding for this task. A primary obstacle hindering research and development in this domain has been the profound lack of a standardized benchmark to quantitatively evaluate the automated generation of diagrams from text. To address this critical gap, we introduce a novel and comprehensive benchmark, the first of its kind, designed to catalyze progress in automated scientific visualization. It consists of 3,000 research papers paired with their corresponding high-quality ground-truth diagrams and is accompanied by a three-tiered evaluation metric assessing semantic accuracy, layout coherence, and visual quality. Furthermore, to establish a strong baseline on this new benchmark, we propose Paper2SysArch, an end-to-end system that leverages multi-agent collaboration to convert papers into structured, editable diagrams. To validate its performance on complex cases, the system was evaluated on a manually curated and more challenging subset of these papers, where it achieves a composite score of 69.0. This work's principal contribution is the establishment of a large-scale, foundational benchmark to enable reproducible research and fair comparison. Meanwhile, our proposed system serves as a viable proof-of-concept, demonstrating a promising path forward for this complex task.

</details>


### [107] [AutoEnv: Automated Environments for Measuring Cross-Environment Agent Learning](https://arxiv.org/abs/2511.19304)
*Jiayi Zhang,Yiran Peng,Fanqi Kong,Yang Cheng,Yifan Wu,Zhaoyang Yu,Jinyu Xiang,Jianhao Ruan,Jinlin Wang,Maojia Song,HongZhang Liu,Xiangru Tang,Bang Liu,Chenglin Wu,Yuyu Luo*

Main category: cs.AI

TL;DR: 提出了AutoEnv框架和AutoEnv-36数据集，用于研究跨环境智能体学习。研究发现单一学习方法在异构环境中效果有限，需要环境自适应的方法选择。


<details>
  <summary>Details</summary>
Motivation: 现有智能体通常在单一环境中自我进化，缺乏对跨异构环境学习能力的系统评估。需要标准化的异构环境集合和统一的学习表示方法。

Method: 1) 开发AutoEnv框架，将环境分解为转移、观察和奖励的分布，低成本生成异构环境；2) 构建AutoEnv-36数据集（36个环境，358个验证关卡）；3) 将智能体学习形式化为选择、优化、评估三个阶段的组件中心过程。

Result: 语言模型在AutoEnv-36上仅获得12-49%的归一化奖励，显示其挑战性。单一学习方法在环境数量增加时效果快速下降，环境自适应方法选择能显著提升性能但存在收益递减。

Conclusion: 固定学习方法无法扩展到异构环境，需要环境自适应的方法选择。AutoEnv和AutoEnv-36为研究跨环境智能体学习提供了测试平台。

Abstract: Humans naturally adapt to diverse environments by learning underlying rules across worlds with different dynamics, observations, and reward structures. In contrast, existing agents typically demonstrate improvements via self-evolving within a single domain, implicitly assuming a fixed environment distribution. Cross-environment learning has remained largely unmeasured: there is no standard collection of controllable, heterogeneous environments, nor a unified way to represent how agents learn. We address these gaps in two steps. First, we propose AutoEnv, an automated framework that treats environments as factorizable distributions over transitions, observations, and rewards, enabling low-cost (4.12 USD on average) generation of heterogeneous worlds. Using AutoEnv, we construct AutoEnv-36, a dataset of 36 environments with 358 validated levels, on which seven language models achieve 12-49% normalized reward, demonstrating the challenge of AutoEnv-36. Second, we formalize agent learning as a component-centric process driven by three stages of Selection, Optimization, and Evaluation applied to an improvable agent component. Using this formulation, we design eight learning methods and evaluate them on AutoEnv-36. Empirically, the gain of any single learning method quickly decrease as the number of environments increases, revealing that fixed learning methods do not scale across heterogeneous environments. Environment-adaptive selection of learning methods substantially improves performance but exhibits diminishing returns as the method space expands. These results highlight both the necessity and the current limitations of agent learning for scalable cross-environment generalization, and position AutoEnv and AutoEnv-36 as a testbed for studying cross-environment agent learning. The code is avaiable at https://github.com/FoundationAgents/AutoEnv.

</details>


### [108] [PRInTS: Reward Modeling for Long-Horizon Information Seeking](https://arxiv.org/abs/2511.19314)
*Jaewoo Lee,Archiki Prasad,Justin Chih-Yao Chen,Zaid Khan,Elias Stengel-Eskin,Mohit Bansal*

Main category: cs.AI

TL;DR: PRInTS是一个生成式过程奖励模型，通过密集评分和轨迹摘要来解决多步信息搜索任务中的挑战，显著提升了开源模型和专业代理的信息搜索能力。


<details>
  <summary>Details</summary>
Motivation: 现有的过程奖励模型(PRMs)设计用于短推理和二元判断，无法捕捉信息搜索步骤的丰富维度（如工具交互、工具输出推理），也无法处理长视野任务中快速增长的上下文。

Method: 引入PRInTS，一个具有双重能力的生成式PRM：(1)基于多个步骤质量维度的密集评分；(2)轨迹摘要，压缩增长上下文同时保留步骤评估所需的关键信息。

Result: 在FRAMES、GAIA和WebWalkerQA基准测试中，使用PRInTS的最佳n采样显著提升了开源模型和专业代理的信息搜索能力，匹配或超越了前沿模型的性能，且优于其他强奖励建模基线。

Conclusion: PRInTS通过其密集评分和轨迹摘要能力，有效解决了长视野信息搜索任务的挑战，为AI代理的信息搜索能力提供了重要改进。

Abstract: Information-seeking is a core capability for AI agents, requiring them to gather and reason over tool-generated information across long trajectories. However, such multi-step information-seeking tasks remain challenging for agents backed by language models. While process reward models (PRMs) can guide agents by ranking candidate steps at test-time, existing PRMs, designed for short reasoning with binary judgment, cannot capture richer dimensions of information-seeking steps, such as tool interactions and reasoning over tool outputs, nor handle the rapidly growing context in long-horizon tasks. To address these limitations, we introduce PRInTS, a generative PRM trained with dual capabilities: (1) dense scoring based on the PRM's reasoning across multiple step quality dimensions (e.g., interpretation of tool outputs, tool call informativeness) and (2) trajectory summarization that compresses the growing context while preserving essential information for step evaluation. Extensive evaluations across FRAMES, GAIA (levels 1-3), and WebWalkerQA (easy-hard) benchmarks on multiple models, along with ablations, reveal that best-of-n sampling with PRInTS enhances information-seeking abilities of open-source models as well as specialized agents, matching or surpassing the performance of frontier models with a much smaller backbone agent and outperforming other strong reward modeling baselines.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [109] [Comparing Labeled Markov Chains: A Cantor-Kantorovich Approach](https://arxiv.org/abs/2511.18103)
*Adrien Banse,Alessandro Abate,Raphaël M. Jungers*

Main category: cs.LO

TL;DR: 本文研究了标记马尔可夫链的Cantor-Kantorovich距离，证明其可表示为有限时域总变差距离的折扣和，分析了计算复杂性、连续性性质和近似性。


<details>
  <summary>Details</summary>
Motivation: 比较两个标记马尔可夫链以评估抽象精度或量化模型扰动效果，需要有效的距离度量方法。

Method: 将CK距离框架化为有限时域总变差距离的折扣和，分析其计算复杂性、连续性性质和近似方案。

Result: 证明CK距离的精确计算是#P-难的，提供上界分析和可计算近似方案，但近似方案也是#P-难的。

Conclusion: 为CK距离提供了严格的理论基础，阐明了其与现有距离的关系，建立了有限时域迹概率误差的有界性。

Abstract: Labeled Markov Chains (or LMCs for short) are useful mathematical objects to model complex probabilistic languages. A central challenge is to compare two LMCs, for example to assess the accuracy of an abstraction or to quantify the effect of model perturbations. In this work, we study the recently introduced Cantor-Kantorovich (or CK) distance. In particular we show that the latter can be framed as a discounted sum of finite-horizon Total Variation distances, making it an instance of discounted linear distance, but arising from the natural Cantor topology. Building on the latter observation, we analyze the properties of the CK distance along three dimensions: computational complexity, continuity properties and approximation. More precisely, we show that the exact computation of the CK distance is #P-hard. We also provide an upper bound on the CK distance as a function of the approximation relation between the two LMCs, and show that a bounded CK distance implies a bounded error between probabilities of finite-horizon traces. Finally, we provide a computable approximation scheme, and show that the latter is also #P-hard. Altogether, our results provide a rigorous theoretical foundation for the CK distance and clarify its relationship with existing distances.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [110] [From Competition to Coordination: Market Making as a Scalable Framework for Safe and Aligned Multi-Agent LLM Systems](https://arxiv.org/abs/2511.17621)
*Brendan Gho,Suman Muppavarapu,Afnan Shaik,Tyson Tsay,James Begin,Kevin Zhu,Archana Vaidheeswaran,Vasu Sharma*

Main category: cs.MA

TL;DR: 提出基于市场机制的多智能体LLM协调框架，通过概率信念交易实现自我组织和可验证推理，在事实推理、伦理判断等任务中准确率提升达10%。


<details>
  <summary>Details</summary>
Motivation: 随着基础模型在多智能体系统中部署，传统协调机制难以扩展且决策过程不透明，需要新的可信赖、透明和可问责的协调方法。

Method: 采用市场制造框架，将智能体交互组织为结构化经济交换，每个智能体作为市场参与者更新和交易概率信念，以达成共享真实结果。

Result: 在事实推理、伦理判断和常识推理任务中，基于市场的协调比单次基线准确率提升高达10%，同时保持中间推理步骤的可解释性和透明度。

Conclusion: 经济协调原则能够在多智能体LLM系统中实现问责和鲁棒性，为自我修正、社会负责的AI提供可扩展路径，在真实部署场景中保持信任和监督。

Abstract: As foundation models are increasingly deployed as interacting agents in multi-agent systems, their collective behavior raises new challenges for trustworthiness, transparency, and accountability. Traditional coordination mechanisms, such as centralized oversight or adversarial adjudication, struggle to scale and often obscure how decisions emerge. We introduce a market-making framework for multi-agent large language model (LLM) coordination that organizes agent interactions as structured economic exchanges. In this setup, each agent acts as a market participant, updating and trading probabilistic beliefs, to converge toward shared, truthful outcomes. By aligning local incentives with collective epistemic goals, the framework promotes self-organizing, verifiable reasoning without requiring external enforcement. Empirically, we evaluate this approach across factual reasoning, ethical judgment, and commonsense inference tasks. Market-based coordination yields accuracy gains of up to 10% over single-shot baselines while preserving interpretability and transparency of intermediate reasoning steps. Beyond these improvements, our findings demonstrate that economic coordination principles can operationalize accountability and robustness in multi-agent LLM systems, offering a scalable pathway toward self-correcting, socially responsible AI capable of maintaining trust and oversight in real world deployment scenarios.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [111] [Classification EM-PCA for clustering and embedding](https://arxiv.org/abs/2511.18992)
*Zineddine Tighidet,Lazhar Labiod,Mohamed Nadif*

Main category: stat.ML

TL;DR: 提出一种结合PCA和CEM算法的同步非序列方法，同时进行数据嵌入和聚类，解决高维数据和EM算法收敛慢的问题。


<details>
  <summary>Details</summary>
Motivation: 高斯混合模型在聚类中广泛应用，但面临高维数据和EM算法收敛慢的挑战。CEM算法提供快速收敛方案，但维度缩减仍是问题。

Method: 结合主成分分析(PCA)和分类EM(CEM)算法，同时而非顺序地执行数据嵌入和聚类两个任务。

Result: 该方法在聚类和数据嵌入方面表现出优势，并与其他聚类方法建立了联系。

Conclusion: 提出的PCA-CEM组合算法能有效解决高维聚类问题，在聚类性能和降维效果上都有良好表现。

Abstract: The mixture model is undoubtedly one of the greatest contributions to clustering. For continuous data, Gaussian models are often used and the Expectation-Maximization (EM) algorithm is particularly suitable for estimating parameters from which clustering is inferred. If these models are particularly popular in various domains including image clustering, they however suffer from the dimensionality and also from the slowness of convergence of the EM algorithm. However, the Classification EM (CEM) algorithm, a classifying version, offers a fast convergence solution while dimensionality reduction still remains a challenge. Thus we propose in this paper an algorithm combining simultaneously and non-sequentially the two tasks --Data embedding and Clustering-- relying on Principal Component Analysis (PCA) and CEM. We demonstrate the interest of such approach in terms of clustering and data embedding. We also establish different connections with other clustering approaches.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [112] [From Code Foundation Models to Agents and Applications: A Practical Guide to Code Intelligence](https://arxiv.org/abs/2511.18538)
*Jian Yang,Wei Zhang,Shark Liu,Jiajun Wu,Shawn Guo,Yizhi Li*

Main category: cs.SE

TL;DR: 本文对代码大语言模型进行了系统性综述和实验分析，涵盖从数据准备到后训练的全生命周期，比较了通用LLM和专用代码LLM的性能，并探讨了研究与实践之间的差距。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在软件开发中的广泛应用，从规则系统到Transformer架构的发展使得代码生成成功率从个位数提升到95%以上。需要系统性地分析代码LLM的完整生命周期和技术路线。

Method: 通过一系列分析和探测实验，系统考察数据准备、后训练、高级提示范式、代码预训练、监督微调、强化学习和自主编码代理等技术。比较通用LLM和专用代码LLM的性能。

Result: 对代码预训练、监督微调和强化学习进行了全面实验分析，涵盖扩展规律、框架选择、超参数敏感性、模型架构和数据集比较等方面。

Conclusion: 明确了代码LLM研究与实践之间的差距，包括代码正确性、安全性、大型代码库的上下文感知以及与开发工作流的集成等问题，并将有前景的研究方向映射到实际需求。

Abstract: Large language models (LLMs) have fundamentally transformed automated software development by enabling direct translation of natural language descriptions into functional code, driving commercial adoption through tools like Github Copilot (Microsoft), Cursor (Anysphere), Trae (ByteDance), and Claude Code (Anthropic). While the field has evolved dramatically from rule-based systems to Transformer-based architectures, achieving performance improvements from single-digit to over 95\% success rates on benchmarks like HumanEval. In this work, we provide a comprehensive synthesis and practical guide (a series of analytic and probing experiments) about code LLMs, systematically examining the complete model life cycle from data curation to post-training through advanced prompting paradigms, code pre-training, supervised fine-tuning, reinforcement learning, and autonomous coding agents. We analyze the code capability of the general LLMs (GPT-4, Claude, LLaMA) and code-specialized LLMs (StarCoder, Code LLaMA, DeepSeek-Coder, and QwenCoder), critically examining the techniques, design decisions, and trade-offs. Further, we articulate the research-practice gap between academic research (e.g., benchmarks and tasks) and real-world deployment (e.g., software-related code tasks), including code correctness, security, contextual awareness of large codebases, and integration with development workflows, and map promising research directions to practical needs. Last, we conduct a series of experiments to provide a comprehensive analysis of code pre-training, supervised fine-tuning, and reinforcement learning, covering scaling law, framework selection, hyperparameter sensitivity, model architectures, and dataset comparisons.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [113] [What Drives Cross-lingual Ranking? Retrieval Approaches with Multilingual Language Models](https://arxiv.org/abs/2511.19324)
*Roksana Goworek,Olivia Macmillan-Scott,Eda B. Özyiğit*

Main category: cs.IR

TL;DR: 本文系统评估了跨语言信息检索中的四种干预方法，发现专门为CLIR训练的密集检索模型持续优于词汇匹配方法，且文档翻译带来的收益有限。对比学习能缓解语言偏见，重排序效果取决于训练数据质量。


<details>
  <summary>Details</summary>
Motivation: 跨语言信息检索面临资源差异、文字系统不同和嵌入模型跨语言语义对齐弱等挑战，现有方法依赖翻译和单语检索启发式方法，增加了计算开销和噪声，降低了性能。

Method: 系统评估四种干预类型：文档翻译、使用预训练编码器的多语言密集检索、在词、短语和查询-文档级别的对比学习，以及交叉编码器重排序，在三个基准数据集上进行测试。

Result: 专门为CLIR训练的密集检索模型持续优于词汇匹配方法，文档翻译带来的收益有限。对比学习显著改善了初始对齐较弱的编码器，重排序效果取决于交叉编码器训练数据质量。高资源语言仍主导整体性能，但对低资源和跨文字系统语言对的改进最为明显。

Conclusion: 跨语言搜索系统应优先考虑语义多语言嵌入和有针对性的基于学习的对齐，而非基于翻译的流程，特别是对于跨文字系统和资源不足的语言。

Abstract: Cross-lingual information retrieval (CLIR) enables access to multilingual knowledge but remains challenging due to disparities in resources, scripts, and weak cross-lingual semantic alignment in embedding models. Existing pipelines often rely on translation and monolingual retrieval heuristics, which add computational overhead and noise, degrading performance. This work systematically evaluates four intervention types, namely document translation, multilingual dense retrieval with pretrained encoders, contrastive learning at word, phrase, and query-document levels, and cross-encoder re-ranking, across three benchmark datasets. We find that dense retrieval models trained specifically for CLIR consistently outperform lexical matching methods and derive little benefit from document translation. Contrastive learning mitigates language biases and yields substantial improvements for encoders with weak initial alignment, and re-ranking can be effective, but depends on the quality of the cross-encoder training data. Although high-resource languages still dominate overall performance, gains over lexical and document-translated baselines are most pronounced for low-resource and cross-script pairs. These findings indicate that cross-lingual search systems should prioritise semantic multilingual embeddings and targeted learning-based alignment over translation-based pipelines, particularly for cross-script and under-resourced languages.

</details>


### [114] [Generative Query Expansion with Multilingual LLMs for Cross-Lingual Information Retrieval](https://arxiv.org/abs/2511.19325)
*Olivia Macmillan-Scott,Roksana Goworek,Eda B. Özyiğit*

Main category: cs.IR

TL;DR: 本文评估了多语言大语言模型在跨语言查询扩展中的表现，发现查询长度决定提示技术的有效性，语言差异显著影响检索性能，微调仅在训练与测试数据格式相似时有效。


<details>
  <summary>Details</summary>
Motivation: 多语言大语言模型将查询扩展从同义词增强转向伪文档生成，这在密集检索中特别有益。本研究旨在评估不同生成扩展策略对跨语言检索性能的影响因素。

Method: 评估了多种多语言大语言模型及其微调变体，测试了不同的生成扩展策略，分析了查询长度、提示技术和语言差异等因素。

Result: 查询长度决定提示技术有效性，复杂提示通常无额外收益；语言差异显著：跨语言查询扩展对基线最弱的语言改进最大，但不同文字系统间的检索性能尤其差；微调仅在训练测试数据格式相似时有效。

Conclusion: 需要更平衡的多语言和跨语言训练与评估资源来解决当前的语言差异问题。

Abstract: Query expansion is the reformulation of a user query by adding semantically related information, and is an essential component of monolingual and cross-lingual information retrieval used to ensure that relevant documents are not missed. Recently, multilingual large language models (mLLMs) have shifted query expansion from semantic augmentation with synonyms and related words to pseudo-document generation. Pseudo-documents both introduce additional relevant terms and bridge the gap between short queries and long documents, which is particularly beneficial in dense retrieval. This study evaluates recent mLLMs and fine-tuned variants across several generative expansion strategies to identify factors that drive cross-lingual retrieval performance. Results show that query length largely determines which prompting technique is effective, and that more elaborate prompts often do not yield further gains. Substantial linguistic disparities persist: cross-lingual query expansion can produce the largest improvements for languages with the weakest baselines, yet retrieval is especially poor between languages written in different scripts. Fine-tuning is found to lead to performance gains only when the training and test data are of similar format. These outcomes underline the need for more balanced multilingual and cross-lingual training and evaluation resources.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [115] [LLM and Agent-Driven Data Analysis: A Systematic Approach for Enterprise Applications and System-level Deployment](https://arxiv.org/abs/2511.17676)
*Xi Wang,Xianyao Ling,Kun Li,Gang Yin,Liang Zhang,Jiang Wu,Annie Wang,Weizhe Wang*

Main category: cs.DB

TL;DR: 本文探讨了生成式AI和智能体技术如何变革企业数据管理，重点关注基于LLM的SQL生成技术，以及相关的安全、部署挑战。


<details>
  <summary>Details</summary>
Motivation: 企业数据管理和分析正被AI技术深刻改变，需要解决数据安全、合规性以及降低数据访问门槛的问题。

Method: 采用检索增强生成(RAG)、向量数据库技术，以及基于LLM的SQL生成和多智能体协作框架。

Result: 开发了支持复杂查询理解、多智能体协作和安全验证的创新框架，提升了企业数据分析效率。

Conclusion: AI驱动的企业数据分析面临分布式部署、数据安全和SQL生成固有难度的挑战，需要持续创新解决方案。

Abstract: The rapid progress in Generative AI and Agent technologies is profoundly transforming enterprise data management and analytics. Traditional database applications and system deployment are fundamentally impacted by AI-driven tools, such as Retrieval-Augmented Generation (RAG) and vector database technologies, which provide new pathways for semantic querying over enterprise knowledge bases. In the meantime, data security and compliance are top priorities for organizations adopting AI technologies. For enterprise data analysis, SQL generations powered by large language models (LLMs) and AI agents, has emerged as a key bridge connecting natural language with structured data, effectively lowering the barrier to enterprise data access and improving analytical efficiency. This paper focuses on enterprise data analysis applications and system deployment, covering a range of innovative frameworks, enabling complex query understanding, multi-agent collaboration, security verification, and computational efficiency. Through representative use cases, key challenges related to distributed deployment, data security, and inherent difficulties in SQL generation tasks are discussed.

</details>
