<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 60]
- [cs.LG](#cs.LG) [Total: 4]
- [cs.SD](#cs.SD) [Total: 2]
- [cs.CV](#cs.CV) [Total: 6]
- [cs.AI](#cs.AI) [Total: 3]
- [cs.IR](#cs.IR) [Total: 1]
- [eess.AS](#eess.AS) [Total: 3]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Dynamic Prompt Fusion for Multi-Task and Cross-Domain Adaptation in LLMs](https://arxiv.org/abs/2509.18113)
*Xin Hu,Yue Kang,Guanzi Yao,Tianze Kang,Mengjie Wang,Heyao Liu*

Main category: cs.CL

TL;DR: 本研究提出了一种统一的多任务学习框架，通过动态提示调度机制解决大语言模型在多任务和跨域设置下的泛化限制问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法如SPoT依赖固定提示模板，存在泛化能力不足的问题，需要开发更灵活的多任务学习框架来提升模型跨任务和跨域的适应能力。

Method: 采用动态提示调度机制，包括提示池和任务感知调度策略，通过任务嵌入和门控机制精细控制提示信号，结合联合多任务学习优化目标和自动学习调度权重策略。

Result: 实验结果表明该方法在语言理解和知识推理任务上显著提升性能，有效维持模型稳定性并增强可迁移性。

Conclusion: 提出的动态提示调度方法在多任务建模和跨域适应方面具有显著优势和应用价值。

Abstract: This study addresses the generalization limitations commonly observed in
large language models under multi-task and cross-domain settings. Unlike prior
methods such as SPoT, which depends on fixed prompt templates, our study
introduces a unified multi-task learning framework with dynamic prompt
scheduling mechanism. By introducing a prompt pool and a task-aware scheduling
strategy, the method dynamically combines and aligns prompts for different
tasks. This enhances the model's ability to capture semantic differences across
tasks. During prompt fusion, the model uses task embeddings and a gating
mechanism to finely control the prompt signals. This ensures alignment between
prompt content and task-specific demands. At the same time, it builds flexible
sharing pathways across tasks. In addition, the proposed optimization objective
centers on joint multi-task learning. It incorporates an automatic learning
strategy for scheduling weights, which effectively mitigates task interference
and negative transfer. To evaluate the effectiveness of the method, a series of
sensitivity experiments were conducted. These experiments examined the impact
of prompt temperature parameters and task number variation. The results confirm
the advantages of the proposed mechanism in maintaining model stability and
enhancing transferability. Experimental findings show that the prompt
scheduling method significantly improves performance on a range of language
understanding and knowledge reasoning tasks. These results fully demonstrate
its applicability and effectiveness in unified multi-task modeling and
cross-domain adaptation.

</details>


### [2] [GAUSS: Benchmarking Structured Mathematical Skills for Large Language Models](https://arxiv.org/abs/2509.18122)
*Yue Zhang,Jiaxin Zhang,Qiuyu Ren,Tahsin Saffat,Xiaoxuan Liu,Zitong Yang,Banghua Zhu,Yi Ma*

Main category: cs.CL

TL;DR: GAUSS是一个评估LLMs数学能力的基准测试，涵盖12个核心技能维度，分为三个领域：知识与理解、问题解决与沟通、元技能与创造力。通过按认知技能分类问题并设计隔离特定能力的任务，GAUSS构建了全面、细粒度且可解释的模型数学能力画像。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏能够全面评估LLMs数学能力多维度的基准测试，现有评估往往过于关注最终答案而忽略了底层的认知技能。GAUSS旨在填补这一空白，提供更深入理解模型数学智能的评估框架。

Method: 将数学问题按12个核心技能维度分类，设计能够隔离特定认知能力的任务，构建综合的技能画像来评估模型的数学能力。

Result: 通过GAUSS基准测试，成功揭示了GPT-5-thinking的数学技能画像，显示了其优势、弱点以及与o4-mini-high的差异。

Conclusion: GAUSS基准测试提供了多维度的、基于技能的评估方法，能够更准确地反映LLMs的底层数学智能，为模型能力评估提供了有价值的工具。

Abstract: We introduce \textbf{GAUSS} (\textbf{G}eneral \textbf{A}ssessment of
\textbf{U}nderlying \textbf{S}tructured \textbf{S}kills in Mathematics), a
benchmark that evaluates LLMs' mathematical abilities across twelve core skill
dimensions, grouped into three domains: knowledge and understanding, problem
solving and communication, and meta-skills and creativity. By categorizing
problems according to cognitive skills and designing tasks that isolate
specific abilities, GAUSS constructs comprehensive, fine-grained, and
interpretable profiles of models' mathematical abilities. These profiles
faithfully represent their underlying mathematical intelligence. To exemplify
how to use the \textsc{GAUSS} benchmark, we have derived the skill profile of
\textsc{GPT-5-thinking}, revealing its strengths and weaknesses as well as its
differences relative to \textsc{o4-mini-high}, thereby underscoring the value
of multidimensional, skill-based evaluation.

</details>


### [3] [Event Causality Identification with Synthetic Control](https://arxiv.org/abs/2509.18156)
*Haoyu Wang,Fengze Liu,Jiayao Zhang,Dan Roth,Kyle Richardson*

Main category: cs.CL

TL;DR: 本文提出了一种基于Rubin因果模型的事件因果关系识别方法，通过将第一个事件视为治疗、第二个事件视为结果，利用合成控制方法生成虚拟双胞胎来估计因果效应。


<details>
  <summary>Details</summary>
Motivation: 传统的事件因果关系识别方法主要依赖语言模式和多跳关系推理，容易因因果关系的非正式使用和虚假的图形推理而导致错误识别。需要更稳健的方法来区分因果关系和相关关系。

Method: 采用Rubin因果模型框架，将事件对视为治疗-结果关系。使用合成控制方法从相关历史数据中生成虚拟双胞胎，利用文本嵌入合成和反演技术来估计治疗干预对结果可能性的影响。

Result: 该方法在因果关系基准测试COPES-hard上表现出色，识别效果优于包括GPT-4在内的先前方法，能够更稳健地识别事件间的因果关系。

Conclusion: 基于因果推断理论的事件因果关系识别方法能够有效克服传统方法的局限性，通过合成控制技术实现了在文本领域中更可靠的因果效应估计。

Abstract: Event causality identification (ECI), a process that extracts causal
relations between events from text, is crucial for distinguishing causation
from correlation. Traditional approaches to ECI have primarily utilized
linguistic patterns and multi-hop relational inference, risking false causality
identification due to informal usage of causality and specious graphical
inference. In this paper, we adopt the Rubin Causal Model to identify event
causality: given two temporally ordered events, we see the first event as the
treatment and the second one as the observed outcome. Determining their
causality involves manipulating the treatment and estimating the resultant
change in the likelihood of the outcome. Given that it is only possible to
implement manipulation conceptually in the text domain, as a work-around, we
try to find a twin for the protagonist from existing corpora. This twin should
have identical life experiences with the protagonist before the treatment but
undergoes an intervention of treatment. However, the practical difficulty of
locating such a match limits its feasibility. Addressing this issue, we use the
synthetic control method to generate such a twin' from relevant historical
data, leveraging text embedding synthesis and inversion techniques. This
approach allows us to identify causal relations more robustly than previous
methods, including GPT-4, which is demonstrated on a causality benchmark,
COPES-hard.

</details>


### [4] [ZERA: Zero-init Instruction Evolving Refinement Agent - From Zero Instructions to Structured Prompts via Principle-based Optimization](https://arxiv.org/abs/2509.18158)
*Seungyoun Yi,Minsoo Khang,Sungrae Park*

Main category: cs.CL

TL;DR: ZERA是一个自动提示优化框架，通过联合优化系统提示和用户提示，使用结构化评分标准和快速迭代，在少量样本下实现高效提示优化。


<details>
  <summary>Details</summary>
Motivation: 现有的自动提示优化方法通常只关注用户提示，依赖非结构化反馈，需要大量样本和长迭代周期，导致成本高且脆弱。

Method: ZERA使用八个可泛化标准对提示进行评分，并基于结构化批评修订提示，实现快速收敛到高质量提示。

Result: 在五个LLM和九个不同数据集上的实验结果显示，ZERA相比强基线方法有持续改进，消融研究验证了各组件对提示构建的有效贡献。

Conclusion: ZERA通过结构化、低开销的优化方法，实现了更高效的提示优化，代码和所有提示已开源。

Abstract: Automatic Prompt Optimization (APO) improves large language model (LLM)
performance by refining prompts for specific tasks. However, prior APO methods
typically focus only on user prompts, rely on unstructured feedback, and
require large sample sizes and long iteration cycles-making them costly and
brittle. We propose ZERA (Zero-init Instruction Evolving Refinement Agent), a
novel framework that jointly optimizes both system and user prompts through
principled, low-overhead refinement. ZERA scores prompts using eight
generalizable criteria with automatically inferred weights, and revises prompts
based on these structured critiques. This enables fast convergence to
high-quality prompts using minimal examples and short iteration cycles. We
evaluate ZERA across five LLMs and nine diverse datasets spanning reasoning,
summarization, and code generation tasks. Experimental results demonstrate
consistent improvements over strong baselines. Further ablation studies
highlight the contribution of each component to more effective prompt
construction. Our implementation including all prompts is publicly available at
https://github.com/younatics/zera-agent.

</details>


### [5] [Thinking in a Crowd: How Auxiliary Information Shapes LLM Reasoning](https://arxiv.org/abs/2509.18163)
*Haodong Zhao,Chenyan Zhao,Yansi Li,Zhuosheng Zhang,Gongshen Liu*

Main category: cs.CL

TL;DR: 这篇论文研究了外部信息对具有逐步推理能力的大语言模型的影响，发现模型的思考模式是一把双刃剑：有帮助的信息能提高准确性，但误导性信息会导致性能灾难性下降，且思考过程会放大错误。


<details>
  <summary>Details</summary>
Motivation: 在现实场景中，LLMs经常需要处理外部信息，这些信息可能是有帮助的、无关的甚至是误导性的。论文旨在系统研究这些辅助信息对LLMs推理过程的因果影响。

Method: 作者引入了SciAux数据集（基于ScienceQA），用于系统测试模型对不同类型信息的鲁棒性，特别关注具有逐步思考能力的模型。

Result: 研究发现模型的有意识"思考模式"存在关键漏洞：有帮助的上下文能提高准确性，但误导性信息会导致性能灾难性下降，且思考过程会放大错误程度。

Conclusion: 挑战不仅在于让模型"思考"，更重要的是赋予它们评估推理所依赖信息的批判能力。SciAux数据集已公开可用。

Abstract: The capacity of Large Language Models (LLMs) to reason is fundamental to
their application in complex, knowledge-intensive domains. In real-world
scenarios, LLMs are often augmented with external information that can be
helpful, irrelevant, or even misleading. This paper investigates the causal
impact of such auxiliary information on the reasoning process of LLMs with
explicit step-by-step thinking capabilities. We introduce SciAux, a new dataset
derived from ScienceQA, to systematically test the robustness of the model
against these types of information. Our findings reveal a critical
vulnerability: the model's deliberative "thinking mode" is a double-edged
sword. While helpful context improves accuracy, misleading information causes a
catastrophic drop in performance, which is amplified by the thinking process.
Instead of conferring robustness, thinking reinforces the degree of error when
provided with misinformation. This highlights that the challenge is not merely
to make models "think", but to endow them with the critical faculty to evaluate
the information upon which their reasoning is based. The SciAux dataset is
available at https://huggingface.co/datasets/billhdzhao/SciAux.

</details>


### [6] [SIRAG: Towards Stable and Interpretable RAG with A Process-Supervised Multi-Agent Framework](https://arxiv.org/abs/2509.18167)
*Junlin Wang,Zehao Wu,Shaowei Lu,Yanlan Li,Xinghao Huang*

Main category: cs.CL

TL;DR: 提出了一个过程监督的多智能体框架来优化检索增强生成（RAG）中检索器与生成器的协调问题，通过决策制定器和知识选择器两个轻量级智能体，结合过程级奖励和树状探索策略，提升问答任务的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统RAG系统中检索器和生成器独立开发导致交互不理想，检索器可能返回不相关文档，生成器未能充分利用检索证据，需要更好的协调机制。

Method: 使用过程监督的多智能体框架，包含决策制定器（控制检索时机）和知识选择器（筛选有用文档），采用LLM作为评判者提供过程级奖励，通过树状展开策略探索推理路径，使用PPO进行端到端训练。

Result: 在单跳和多跳问答基准测试中，该方法相比标准RAG基线实现了更高准确性、更稳定收敛，并产生更可解释的推理轨迹。

Conclusion: 该框架具有模块化和即插即用特性，无需修改现有检索器或生成器，适用于实际RAG应用场景。

Abstract: Retrieval-Augmented Generation (RAG) enables large language models (LLMs) to
access external knowledge sources, but the effectiveness of RAG relies on the
coordination between the retriever and the generator. Since these components
are developed independently, their interaction is often suboptimal: the
retriever may return irrelevant or redundant documents, while the generator may
fail to fully leverage retrieved evidence. In this work, we propose a
process-supervised multi-agent framework to bridge the gap between retriever
and generator. The framework introduces two lightweight agents: a Decision
Maker, which determines when to continue retrieval or stop for answer
generation, and a Knowledge Selector, which filters retrieved documents to
retain only the most useful evidence. To provide fine-grained supervision, we
employ an LLM-as-a-Judge that evaluates each intermediate action with
process-level rewards, ensuring more accurate credit assignment than relying
solely on final answer correctness. We further adopt a tree-structured rollout
strategy to explore diverse reasoning paths, and train both agents with
Proximal Policy Optimization (PPO) in an end-to-end manner. Experiments on
single-hop and multi-hop question answering benchmarks show that our approach
achieves higher accuracy, more stable convergence, and produces more
interpretable reasoning trajectories compared with standard RAG baselines.
Importantly, the proposed framework is modular and plug-and-play, requiring no
modification to the retriever or generator, making it practical for real-world
RAG applications.

</details>


### [7] [ERFC: Happy Customers with Emotion Recognition and Forecasting in Conversation in Call Centers](https://arxiv.org/abs/2509.18175)
*Aditi Debsharma,Bhushan Jagyasi,Surajit Sen,Priyanka Pandey,Devicharith Dovari,Yuvaraj V. C,Rosalin Parida,Gopali Contractor*

Main category: cs.CL

TL;DR: 提出了一种新的情感识别和预测架构ERFC，用于对话中的情感识别和未来话语情感预测，特别适用于呼叫中心等场景。


<details>
  <summary>Details</summary>
Motivation: 在呼叫中心等对话场景中，了解客户当前和未来情感状态对提升客户体验至关重要，通过预测未来话语情感可以帮助客服人员及时采取正确应对措施。

Method: ERFC架构考虑了多模态、情感的不同属性、上下文以及对话中说话者话语之间的相互依赖关系。

Result: 在IEMOCAP数据集上的实验证明了ERFC的可行性。

Conclusion: 该方法在呼叫中心等重视客户满意度的应用中具有重要的商业价值。

Abstract: Emotion Recognition in Conversation has been seen to be widely applicable in
call center analytics, opinion mining, finance, retail, healthcare, and other
industries. In a call center scenario, the role of the call center agent is not
just confined to receiving calls but to also provide good customer experience
by pacifying the frustration or anger of the customers. This can be achieved by
maintaining neutral and positive emotion from the agent. As in any
conversation, the emotion of one speaker is usually dependent on the emotion of
other speaker. Hence the positive emotion of an agent, accompanied with the
right resolution will help in enhancing customer experience. This can change an
unhappy customer to a happy one. Imparting the right resolution at right time
becomes easier if the agent has the insight of the emotion of future
utterances. To predict the emotions of the future utterances we propose a novel
architecture, Emotion Recognition and Forecasting in Conversation. Our proposed
ERFC architecture considers multi modalities, different attributes of emotion,
context and the interdependencies of the utterances of the speakers in the
conversation. Our intensive experiments on the IEMOCAP dataset have shown the
feasibility of the proposed ERFC. This approach can provide a tremendous
business value for the applications like call center, where the happiness of
customer is utmost important.

</details>


### [8] [Evaluating Large Language Models for Detecting Antisemitism](https://arxiv.org/abs/2509.18293)
*Jay Patel,Hrudayangam Mehta,Jeremy Blackburn*

Main category: cs.CL

TL;DR: 本文评估了8个开源LLM检测反犹内容的能力，提出了一种新的Guided-CoT提示方法，该方法显著提升了模型性能，Llama 3.1 70B甚至超过了微调的GPT-3.5。


<details>
  <summary>Details</summary>
Motivation: 仇恨内容检测是一个重要但具有挑战性的问题，需要持续训练来适应社交媒体的快速变化。本文旨在评估开源LLM在检测反犹内容方面的能力。

Method: 使用上下文定义作为政策指南，探索多种提示技术，设计了新的Guided-CoT提示方法，并引入指标来量化模型生成理由的语义差异。

Result: Guided-CoT在所有评估模型中都提高了性能，不受解码配置、模型大小或推理能力的影响。Llama 3.1 70B表现优于微调的GPT-3.5。

Conclusion: 实验揭示了不同LLM在实用性、可解释性和可靠性方面的差异，为仇恨内容检测提供了新的方法学见解。

Abstract: Detecting hateful content is a challenging and important problem. Automated
tools, like machine-learning models, can help, but they require continuous
training to adapt to the ever-changing landscape of social media. In this work,
we evaluate eight open-source LLMs' capability to detect antisemitic content,
specifically leveraging in-context definition as a policy guideline. We explore
various prompting techniques and design a new CoT-like prompt, Guided-CoT.
Guided-CoT handles the in-context policy well, increasing performance across
all evaluated models, regardless of decoding configuration, model sizes, or
reasoning capability. Notably, Llama 3.1 70B outperforms fine-tuned GPT-3.5.
Additionally, we examine LLM errors and introduce metrics to quantify semantic
divergence in model-generated rationales, revealing notable differences and
paradoxical behaviors among LLMs. Our experiments highlight the differences
observed across LLMs' utility, explainability, and reliability.

</details>


### [9] [Exploiting Tree Structure for Credit Assignment in RL Training of LLMs](https://arxiv.org/abs/2509.18314)
*Hieu Tran,Zonghai Yao,Hong Yu*

Main category: cs.CL

TL;DR: 本文提出TEMPO算法，通过前缀树结构进行非参数化信用分配，解决了LLM推理中稀疏延迟奖励的信用分配瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 强化学习能提升LLM推理能力，但长序列中的稀疏延迟奖励使得token级别的信用分配成为关键瓶颈。数学和医疗QA等推理任务中，只有少数决策token对结果有显著影响。

Method: 提出Prefix-to-Tree(P2T)方法将响应组转换为前缀树，计算非参数化前缀值。基于P2T开发TEMPO算法，在GRPO基础上加入分支门控的时序差分修正，在分支token处提供精确的token级信用分配。

Result: 在Qwen3-1.7B/4B模型上，TEMPO在分布内(MATH、MedQA)和分布外(GSM-HARD、AMC23等)基准测试中均优于PPO和GRPO，在相同训练时间内达到更高验证准确率。

Conclusion: TEMPO提供了一种无需学习价值网络或额外评判者的简单有效方法，解决了token级信用分配问题，在推理任务中表现出色。

Abstract: Reinforcement learning improves LLM reasoning, yet sparse delayed reward over
long sequences makes token-level credit assignment the key bottleneck. We study
the verifiable-reward setting, where the final answer is checkable and multiple
responses can be drawn per prompt. Reasoning tasks in math and medical QA align
with this setup, where only a few decision tokens significantly impact the
outcome. PPO offers token-level advantages with a learned value model, but it
is complex to train both the actor and critic models simultaneously, and it is
not easily generalizable, as the token-level values from the critic model can
make training prone to overfitting. GRPO is critic-free and supports verifiable
rewards, but spreads a single sequence-level return across tokens and ignores
branching. We introduce \textbf{Prefix-to-Tree (P2T)}, a simple procedure that
converts a group of responses into a prefix tree and computes
\emph{nonparametric} prefix values \(V(s)\) by aggregating descendant outcomes.
Built on P2T, we propose \textbf{TEMPO} (\emph{\textbf{T}ree-\textbf{E}stimated
\textbf{M}ean Prefix Value for \textbf{P}olicy \textbf{O}ptimization}), a
critic-free algorithm that augments the group-relative outcome signal of GRPO
with \emph{branch-gated} temporal-difference corrections derived from the tree.
At non-branch tokens, the temporal-difference (TD) term is zero, so TEMPO
reduces to GRPO; at branching tokens, it supplies precise token-level credit
without a learned value network or extra judges/teachers. On Qwen3-1.7B/4B,
TEMPO outperforms PPO and GRPO on in-distribution (MATH, MedQA) and
out-of-distribution (GSM-HARD, AMC23, MedMCQA, MMLU-Medical) benchmarks, and
reaches higher validation accuracy with roughly the same wall-clock time.

</details>


### [10] [Brittleness and Promise: Knowledge Graph Based Reward Modeling for Diagnostic Reasoning](https://arxiv.org/abs/2509.18316)
*Saksham Khatwani,He Cheng,Majid Afshar,Dmitriy Dligach,Yanjun Gao*

Main category: cs.CL

TL;DR: 该研究探索将LLM作为知识图谱推理路径的奖励模型，通过判断候选路径是否能正确诊断患者病情，而非传统的检索增强生成或微调方法。


<details>
  <summary>Details</summary>
Motivation: LLMs在诊断推理中缺乏可靠的知识基础推理能力，而知识图谱（如UMLS）提供结构化生物医学知识支持可信推理。受医生诊断评估过程启发，验证解决方案比从头生成更容易。

Method: 系统评估了5种知识路径判断任务制定方法和8种训练范式，测试路径判断能力是否能泛化到下游诊断任务（诊断总结和医学问答）。使用3个开源指令调优LLMs进行实验。

Result: 特定奖励优化和蒸馏方法能实现强大的路径判断性能，但向下游任务的迁移能力仍然较弱。

Conclusion: 这是对临床知识图谱进行"奖励模型风格"推理的首次系统评估，为结构化、基于奖励的监督如何影响医疗GenAI系统的诊断推理提供了见解。

Abstract: Large language models (LLMs) show promise for diagnostic reasoning but often
lack reliable, knowledge grounded inference. Knowledge graphs (KGs), such as
the Unified Medical Language System (UMLS), offer structured biomedical
knowledge that can support trustworthy reasoning. Prior approaches typically
integrate KGs via retrieval augmented generation or fine tuning, inserting KG
content into prompts rather than enabling structured reasoning. We explore an
alternative paradigm: treating the LLM as a reward model of KG reasoning paths,
where the model learns to judge whether a candidate path leads to correct
diagnosis for a given patient input. This approach is inspired by recent work
that leverages reward training to enhance model reasoning abilities, and
grounded in computational theory, which suggests that verifying a solution is
often easier than generating one from scratch. It also parallels physicians'
diagnostic assessment, where they judge which sequences of findings and
intermediate conditions most plausibly support a diagnosis. We first
systematically evaluate five task formulation for knowledge path judging and
eight training paradigm. Second, we test whether the path judging abilities
generalize to downstream diagnostic tasks, including diagnosis summarization
and medical question answering. Experiments with three open source
instruct-tuned LLMs reveal both promise and brittleness: while specific reward
optimization and distillation lead to strong path-judging performance, the
transferability to downstream tasks remain weak. Our finding provides the first
systematic assessment of "reward model style" reasoning over clinical KGs,
offering insights into how structured, reward-based supervision influences
diagnostic reasoning in GenAI systems for healthcare.

</details>


### [11] [Speculate Deep and Accurate: Lossless and Training-Free Acceleration for Offloaded LLMs via Substitute Speculative Decoding](https://arxiv.org/abs/2509.18344)
*Pei-Shuo Wang,Jian-Jia Chen,Chun-Che Yang,Chi-Chih Chang,Ning-Chi Huang,Mohamed S. Abdelfattah,Kai-Chiang Wu*

Main category: cs.CL

TL;DR: SubSpec是一种无需训练的即插即用方法，通过构建高度对齐的草稿模型来加速参数卸载，在内存受限的GPU上实现无损的LLM推理加速。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在内存受限GPU上部署的挑战，现有方法存在质量下降或推理速度慢的问题，需要一种既能保持质量又能显著加速的方法。

Method: 通过生成低比特量化替代层构建高度对齐的草稿模型，共享GPU驻留层和KV-Cache，减少内存开销并增强对齐度。

Result: 在8GB VRAM限制下为Qwen2.5 7B实现9.1倍加速，在24GB VRAM限制下为Qwen2.5 32B实现平均12.5倍加速。

Conclusion: SubSpec方法有效解决了参数卸载中的推理速度瓶颈，实现了高质量、高效率的LLM部署。

Abstract: The immense model sizes of large language models (LLMs) challenge deployment
on memory-limited consumer GPUs. Although model compression and parameter
offloading are common strategies to address memory limitations, compression can
degrade quality, and offloading maintains quality but suffers from slow
inference. Speculative decoding presents a promising avenue to accelerate
parameter offloading, utilizing a fast draft model to propose multiple draft
tokens, which are then verified by the target LLM in parallel with a single
forward pass. This method reduces the time-consuming data transfers in forward
passes that involve offloaded weight transfers. Existing methods often rely on
pretrained weights of the same family, but require additional training to align
with custom-trained models. Moreover, approaches that involve draft model
training usually yield only modest speedups. This limitation arises from
insufficient alignment with the target model, preventing higher token
acceptance lengths. To address these challenges and achieve greater speedups,
we propose SubSpec, a plug-and-play method to accelerate parameter offloading
that is lossless and training-free. SubSpec constructs a highly aligned draft
model by generating low-bit quantized substitute layers from offloaded target
LLM portions. Additionally, our method shares the remaining GPU-resident layers
and the KV-Cache, further reducing memory overhead and enhance alignment.
SubSpec achieves a high average acceptance length, delivering 9.1x speedup for
Qwen2.5 7B on MT-Bench (8GB VRAM limit) and an average of 12.5x speedup for
Qwen2.5 32B on popular generation benchmarks (24GB VRAM limit).

</details>


### [12] [Speech Vecalign: an Embedding-based Method for Aligning Parallel Speech Documents](https://arxiv.org/abs/2509.18360)
*Chutong Meng,Philipp Koehn*

Main category: cs.CL

TL;DR: Speech Vecalign是一种无需文本转录的并行语音文档对齐方法，通过单调对齐语音片段嵌入，相比基线方法产生更长的语音对齐且噪声更少。


<details>
  <summary>Details</summary>
Motivation: 现有的语音挖掘方法（如Global Mining和Local Mining）在对齐语音文档时存在对齐长度不足和噪声较多的问题，需要一种更鲁棒的对齐方法。

Method: Speech Vecalign基于语音片段嵌入的单调对齐，不依赖文本转录，直接从语音信号中学习对齐关系。

Result: 在3000小时未标记的英德平行语音数据上应用Speech Vecalign，获得了约1000小时高质量对齐数据，训练的语言翻译模型相比Global Mining在英德和德英翻译上分别提升0.37和0.18 ASR-BLEU，且使用8倍少的原始语音文档即可达到或超过SpeechMatrix模型性能。

Conclusion: Speech Vecalign是一种有效的无监督语音文档对齐方法，能够产生高质量的对齐数据，显著提升语音翻译性能，且数据效率更高。

Abstract: We present Speech Vecalign, a parallel speech document alignment method that
monotonically aligns speech segment embeddings and does not depend on text
transcriptions. Compared to the baseline method Global Mining, a variant of
speech mining, Speech Vecalign produces longer speech-to-speech alignments. It
also demonstrates greater robustness than Local Mining, another speech mining
variant, as it produces less noise. We applied Speech Vecalign to 3,000 hours
of unlabeled parallel English-German (En-De) speech documents from VoxPopuli,
yielding about 1,000 hours of high-quality alignments. We then trained En-De
speech-to-speech translation models on the aligned data. Speech Vecalign
improves the En-to-De and De-to-En performance over Global Mining by 0.37 and
0.18 ASR-BLEU, respectively. Moreover, our models match or outperform
SpeechMatrix model performance, despite using 8 times fewer raw speech
documents.

</details>


### [13] [Interactive Real-Time Speaker Diarization Correction with Human Feedback](https://arxiv.org/abs/2509.18377)
*Xinlu He,Yiwen Guan,Badrivishal Paurana,Zilin Dai,Jacob Whitehill*

Main category: cs.CL

TL;DR: 提出了一种基于LLM的说话人日志校正系统，通过实时用户反馈来修正说话人归属错误，显著降低了说话人日志错误率。


<details>
  <summary>Details</summary>
Motivation: 大多数自动语音处理系统在无用户反馈的"开环"模式下运行，而人机协作工作流可以显著提高准确率。

Method: 系统执行流式ASR和说话人日志，使用LLM生成简洁摘要，接受简短语音反馈并即时整合。开发了合并时分割(SWM)技术检测和分割被错误归因的单说话人段，以及基于用户校正的在线说话人注册。

Result: 在AMI测试集上的LLM驱动模拟显示，系统显著降低DER 9.92%，说话人混淆错误降低44.23%。

Conclusion: 该系统通过人机协作有效提升了说话人日志的准确性，为实时语音处理系统提供了实用的校正机制。

Abstract: Most automatic speech processing systems operate in "open loop" mode without
user feedback about who said what; yet, human-in-the-loop workflows can
potentially enable higher accuracy. We propose an LLM-assisted speaker
diarization correction system that lets users fix speaker attribution errors in
real time. The pipeline performs streaming ASR and diarization, uses an LLM to
deliver concise summaries to the users, and accepts brief verbal feedback that
is immediately incorporated without disrupting interactions. Moreover, we
develop techniques to make the workflow more effective: First, a
split-when-merged (SWM) technique detects and splits multi-speaker segments
that the ASR erroneously attributes to just a single speaker. Second, online
speaker enrollments are collected based on users' diarization corrections, thus
helping to prevent speaker diarization errors from occurring in the future.
LLM-driven simulations on the AMI test set indicate that our system
substantially reduces DER by 9.92% and speaker confusion error by 44.23%. We
further analyze correction efficacy under different settings, including summary
vs full transcript display, the number of online enrollments limitation, and
correction frequency.

</details>


### [14] [NormGenesis: Multicultural Dialogue Generation via Exemplar-Guided Social Norm Modeling and Violation Recovery](https://arxiv.org/abs/2509.18395)
*Minki Hong,Jangho Choi,Jihie Kim*

Main category: cs.CL

TL;DR: NormGenesis是一个多文化对话生成框架，通过Violation-to-Resolution对话类型建模社会规范违反到修复的过程，提升对话系统的社会适应性。


<details>
  <summary>Details</summary>
Motivation: 社会规范在沟通中确保文化适宜性，但现有对话系统缺乏对社会规范动态交互的建模能力，特别是在多语言环境下的文化适应性。

Method: 提出Violation-to-Resolution对话类型，采用基于范例的迭代精炼方法，在对话合成早期引入语言、情感和社会文化期望的对齐。构建包含10,800个多轮对话的数据集，标注规范遵守、说话者意图和情感响应。

Result: 人类和LLM评估显示NormGenesis在精炼质量、对话自然度和泛化性能上显著优于现有数据集。使用V2R增强数据训练的模型在伦理敏感情境下表现出更好的语用能力。

Conclusion: 该工作为文化自适应对话建模建立了新基准，提供了跨语言和文化多样化语言的规范感知生成的可扩展方法。

Abstract: Social norms govern culturally appropriate behavior in communication,
enabling dialogue systems to produce responses that are not only coherent but
also socially acceptable. We present NormGenesis, a multicultural framework for
generating and annotating socially grounded dialogues across English, Chinese,
and Korean. To model the dynamics of social interaction beyond static norm
classification, we propose a novel dialogue type, Violation-to-Resolution
(V2R), which models the progression of conversations following norm violations
through recognition and socially appropriate repair. To improve pragmatic
consistency in underrepresented languages, we implement an exemplar-based
iterative refinement early in the dialogue synthesis process. This design
introduces alignment with linguistic, emotional, and sociocultural expectations
before full dialogue generation begins. Using this framework, we construct a
dataset of 10,800 multi-turn dialogues annotated at the turn level for norm
adherence, speaker intent, and emotional response. Human and LLM-based
evaluations demonstrate that NormGenesis significantly outperforms existing
datasets in refinement quality, dialogue naturalness, and generalization
performance. We show that models trained on our V2R-augmented data exhibit
improved pragmatic competence in ethically sensitive contexts. Our work
establishes a new benchmark for culturally adaptive dialogue modeling and
provides a scalable methodology for norm-aware generation across linguistically
and culturally diverse languages.

</details>


### [15] [Evaluating the Creativity of LLMs in Persian Literary Text Generation](https://arxiv.org/abs/2509.18401)
*Armin Tourajmehr,Mohammad Reza Modarres,Yadollah Yaghoobzadeh*

Main category: cs.CL

TL;DR: 本文评估了大型语言模型生成波斯文学文本的能力，重点关注文化相关表达和创造力维度，并采用自动化评估方法验证结果。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中于英语文学创作，缺乏对非英语文学传统（如波斯文学）的系统评估，且缺乏标准化的创造力评估方法。

Method: 构建包含20个主题的波斯文学数据集，采用托兰斯创造力测试的四个维度（原创性、流畅性、灵活性、精细度）进行评估，使用LLM作为自动评分工具并与人工评分进行对比验证。

Result: LLM在波斯文学文本生成中表现出一定能力，但在文化相关表达和文学手法运用方面存在局限性；自动化评估与人工评估具有强一致性。

Conclusion: LLMs在波斯文学创作方面具有潜力但需要进一步改进，特别是在文化适应性和文学技巧掌握方面。

Abstract: Large language models (LLMs) have demonstrated notable creative abilities in
generating literary texts, including poetry and short stories. However, prior
research has primarily centered on English, with limited exploration of
non-English literary traditions and without standardized methods for assessing
creativity. In this paper, we evaluate the capacity of LLMs to generate Persian
literary text enriched with culturally relevant expressions. We build a dataset
of user-generated Persian literary spanning 20 diverse topics and assess model
outputs along four creativity dimensions-originality, fluency, flexibility, and
elaboration-by adapting the Torrance Tests of Creative Thinking. To reduce
evaluation costs, we adopt an LLM as a judge for automated scoring and validate
its reliability against human judgments using intraclass correlation
coefficients, observing strong agreement. In addition, we analyze the models'
ability to understand and employ four core literary devices: simile, metaphor,
hyperbole, and antithesis. Our results highlight both the strengths and
limitations of LLMs in Persian literary text generation, underscoring the need
for further refinement.

</details>


### [16] [Developing an AI framework to automatically detect shared decision-making in patient-doctor conversations](https://arxiv.org/abs/2509.18439)
*Oscar J. Ponce-Ponte,David Toro-Tobon,Luis F. Figueroa,Michael Gionfriddo,Megan Branda,Victor M. Montori,Saturnino Luz,Juan P. Brito*

Main category: cs.CL

TL;DR: 本研究开发了一种使用语言建模和对话对齐(CA)评分来自动测量医患共享决策(SDM)的方法，通过深度学习模型和微调BERT模型计算CA分数，并与SDM结果关联分析。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏自动测量医患共享决策(SDM)的方法，需要开发可扩展的自动化评估工具来促进以患者为中心的医疗服务。

Method: 使用157个医患对话视频的42,559个句子，通过上下文-响应对和负采样训练深度学习模型和微调BERT模型，利用下一句预测任务计算四种CA分数，并与SDM结果进行关联分析。

Result: DL模型和微调BERTbase模型分别达到0.227和0.640的召回率，某些CA分数与OPTION12和DCS评分显著相关，表明CA分数可以有效衡量SDM质量。

Conclusion: 本研究首次提出了通过可解释的CA分数自动、可扩展地测量医患共享决策的方法，具有大规模评估SDM策略的潜力。

Abstract: Shared decision-making (SDM) is necessary to achieve patient-centred care.
Currently no methodology exists to automatically measure SDM at scale. This
study aimed to develop an automated approach to measure SDM by using language
modelling and the conversational alignment (CA) score. A total of 157
video-recorded patient-doctor conversations from a randomized multi-centre
trial evaluating SDM decision aids for anticoagulation in atrial fibrillations
were transcribed and segmented into 42,559 sentences. Context-response pairs
and negative sampling were employed to train deep learning (DL) models and
fine-tuned BERT models via the next sentence prediction (NSP) task. Each
top-performing model was used to calculate four types of CA scores. A
random-effects analysis by clinician, adjusting for age, sex, race, and trial
arm, assessed the association between CA scores and SDM outcomes: the
Decisional Conflict Scale (DCS) and the Observing Patient Involvement in
Decision-Making 12 (OPTION12) scores. p-values were corrected for multiple
comparisons with the Benjamini-Hochberg method. Among 157 patients (34% female,
mean age 70 SD 10.8), clinicians on average spoke more words than patients
(1911 vs 773). The DL model without the stylebook strategy achieved a recall@1
of 0.227, while the fine-tuned BERTbase (110M) achieved the highest recall@1
with 0.640. The AbsMax (18.36 SE7.74 p=0.025) and Max CA (21.02 SE7.63 p=0.012)
scores generated with the DL without stylebook were associated with OPTION12.
The Max CA score generated with the fine-tuned BERTbase (110M) was associated
with the DCS score (-27.61 SE12.63 p=0.037). BERT model sizes did not have an
impact the association between CA scores and SDM. This study introduces an
automated, scalable methodology to measure SDM in patient-doctor conversations
through explainable CA scores, with potential to evaluate SDM strategies at
scale.

</details>


### [17] [CogniLoad: A Synthetic Natural Language Reasoning Benchmark With Tunable Length, Intrinsic Difficulty, and Distractor Density](https://arxiv.org/abs/2509.18458)
*Daniel Kaiser,Arnoldo Frigessi,Ali Ramezani-Kebrya,Benjamin Ricaud*

Main category: cs.CL

TL;DR: CogniLoad是一个基于认知负荷理论(CLT)的合成基准测试，通过独立可调参数来精确分析LLM长上下文推理中的失败原因，包括内在难度、干扰因素和任务长度三个维度。


<details>
  <summary>Details</summary>
Motivation: 当前的长上下文推理基准测试往往模糊了关键因素，如内在任务复杂性、干扰因素影响和任务长度，无法进行精确的失败分析。

Method: 基于认知负荷理论，设计自然语言逻辑谜题，通过三个独立可调参数：内在难度(d)控制内在负荷，干扰信号比(ρ)调节外在负荷，任务长度(N)作为相关负荷的代理指标。

Result: 评估22个最先进的推理LLM，发现任务长度是主要约束因素，模型对内在复杂性有不同容忍度，对干扰比呈现U型响应模式。

Conclusion: CogniLoad通过系统控制认知负荷维度，为分析LLM推理局限性和指导未来模型开发提供了可重现、可扩展且诊断性强的工具。

Abstract: Current benchmarks for long-context reasoning in Large Language Models (LLMs)
often blur critical factors like intrinsic task complexity, distractor
interference, and task length. To enable more precise failure analysis, we
introduce CogniLoad, a novel synthetic benchmark grounded in Cognitive Load
Theory (CLT). CogniLoad generates natural-language logic puzzles with
independently tunable parameters that reflect CLT's core dimensions: intrinsic
difficulty ($d$) controls intrinsic load; distractor-to-signal ratio ($\rho$)
regulates extraneous load; and task length ($N$) serves as an operational proxy
for conditions demanding germane load. Evaluating 22 SotA reasoning LLMs,
CogniLoad reveals distinct performance sensitivities, identifying task length
as a dominant constraint and uncovering varied tolerances to intrinsic
complexity and U-shaped responses to distractor ratios. By offering systematic,
factorial control over these cognitive load dimensions, CogniLoad provides a
reproducible, scalable, and diagnostically rich tool for dissecting LLM
reasoning limitations and guiding future model development.

</details>


### [18] [LAWCAT: Efficient Distillation from Quadratic to Linear Attention with Convolution across Tokens for Long Context Modeling](https://arxiv.org/abs/2509.18467)
*Zeyu Liu,Souvik Kundu,Lianghao Jiang,Anni Li,Srikanth Ronanki,Sravan Bodapati,Gourav Datta,Peter A. Beerel*

Main category: cs.CL

TL;DR: LAWCAT提出了一种线性注意力框架，可将预训练Transformer高效转换为高性能线性注意力架构，显著降低长上下文应用的计算复杂度


<details>
  <summary>Details</summary>
Motivation: 传统Transformer的二次计算复杂度成为长上下文应用的瓶颈，而从头训练线性复杂度模型资源消耗大，需要一种高效迁移预训练模型能力的方法

Method: LAWCAT集成了因果Conv1D层增强局部依赖建模，采用归一化门控线性注意力提升不同上下文长度的泛化能力，通过知识蒸馏将预训练模型转换为线性架构

Result: 仅用1K长度序列蒸馏Mistral-7B，在22K tokens内实现90%以上passkey检索准确率；Llama3.2-1B变体在多个长上下文基准测试中表现优异，预训练token量不到0.1%

Conclusion: LAWCAT为高性能长上下文线性模型提供了高效路径，适合边缘部署，减少了对大量长序列训练数据和计算资源的依赖

Abstract: Although transformer architectures have achieved state-of-the-art performance
across diverse domains, their quadratic computational complexity with respect
to sequence length remains a significant bottleneck, particularly for
latency-sensitive long-context applications. While recent linear-complexity
alternatives are increasingly powerful, effectively training them from scratch
is still resource-intensive. To overcome these limitations, we propose LAWCAT
(Linear Attention with Convolution Across Time), a novel linearization
framework designed to efficiently transfer the capabilities of pre-trained
transformers into a performant linear attention architecture. LAWCAT integrates
causal Conv1D layers to enhance local dependency modeling and employs
normalized gated linear attention to improve generalization across varying
context lengths. Our comprehensive evaluations demonstrate that, distilling
Mistral-7B with only 1K-length sequences yields over 90\% passkey retrieval
accuracy up to 22K tokens, significantly extending its effective context
window. Similarly, Llama3.2-1B LAWCAT variant achieves competitive performance
on S-NIAH 1\&2\&3 tasks (1K-8K context length) and BABILong benchmark
(QA2\&QA3, 0K-16K context length), requiring less than 0.1\% pre-training
tokens compared with pre-training models. Furthermore, LAWCAT exhibits faster
prefill speeds than FlashAttention-2 for sequences exceeding 8K tokens. LAWCAT
thus provides an efficient pathway to high-performance, long-context linear
models suitable for edge deployment, reducing reliance on extensive
long-sequence training data and computational resources.

</details>


### [19] [Actions Speak Louder than Prompts: A Large-Scale Study of LLMs for Graph Inference](https://arxiv.org/abs/2509.18487)
*Ben Finkelshtein,Silviu Cucerzan,Sujay Kumar Jauhar,Ryen White*

Main category: cs.CL

TL;DR: 本文通过大规模系统评估，研究了LLM在图数据上的能力，发现代码生成方法在图形任务中表现最佳，特别是在长文本或高密度图中，且所有交互策略在异质图中都有效。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在文本丰富的图机器学习任务中应用日益广泛，但缺乏对其与图数据交互能力的系统性理解，需要评估不同交互模式在不同图结构下的表现。

Method: 通过大规模控制实验，评估了LLM-图交互的多个关键变量轴：交互模式（提示、工具使用、代码生成）、数据集领域、结构机制、特征特性和模型配置，并分析了输入类型的依赖性。

Result: 代码生成方法在图形数据上表现最强，特别是在长文本或高密度图中；所有交互策略在异质图中都有效；代码生成能灵活调整对结构、特征或标签的依赖。

Conclusion: 研究为当前LLM-图交互模式提供了全面的优劣势分析，并为未来方法设计提供了关键原则指导。

Abstract: Large language models (LLMs) are increasingly used for text-rich graph
machine learning tasks such as node classification in high-impact domains like
fraud detection and recommendation systems. Yet, despite a surge of interest,
the field lacks a principled understanding of the capabilities of LLMs in their
interaction with graph data. In this work, we conduct a large-scale, controlled
evaluation across several key axes of variability to systematically assess the
strengths and weaknesses of LLM-based graph reasoning methods in text-based
applications. The axes include the LLM-graph interaction mode, comparing
prompting, tool-use, and code generation; dataset domains, spanning citation,
web-link, e-commerce, and social networks; structural regimes contrasting
homophilic and heterophilic graphs; feature characteristics involving both
short- and long-text node attributes; and model configurations with varying LLM
sizes and reasoning capabilities. We further analyze dependencies by
methodically truncating features, deleting edges, and removing labels to
quantify reliance on input types. Our findings provide practical and actionable
guidance. (1) LLMs as code generators achieve the strongest overall performance
on graph data, with especially large gains on long-text or high-degree graphs
where prompting quickly exceeds the token budget. (2) All interaction
strategies remain effective on heterophilic graphs, challenging the assumption
that LLM-based methods collapse under low homophily. (3) Code generation is
able to flexibly adapt its reliance between structure, features, or labels to
leverage the most informative input type. Together, these findings provide a
comprehensive view of the strengths and limitations of current LLM-graph
interaction modes and highlight key design principles for future approaches.

</details>


### [20] [A Rhythm-Aware Phrase Insertion for Classical Arabic Poetry Composition](https://arxiv.org/abs/2509.18514)
*Mohamad Elzohbi,Richard Zhao*

Main category: cs.CL

TL;DR: 提出了一种基于ByT5的方法，用于在阿拉伯诗歌中插入短语以符合特定韵律，通过规则化的字形到节拍转换和条件去噪目标进行微调。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够自动生成符合古典阿拉伯诗歌韵律的短语插入方法，以支持诗歌创作的协同应用。

Method: 使用ByT5模型，采用基于规则的grapheme-to-beat转换提取韵律，通过条件去噪目标进行微调，并采用课程学习策略（先在通用阿拉伯语数据集上预训练，再在诗歌数据集上微调），探索从英语到阿拉伯语的跨语言迁移。

Result: 实验结果表明，所提出的模型在保持语义连贯性的同时，实现了高度的韵律对齐。

Conclusion: 该方法在古典阿拉伯诗歌创作过程中具有协同创作的潜力。

Abstract: This paper presents a methodology for inserting phrases in Arabic poems to
conform to a specific rhythm using ByT5, a byte-level multilingual
transformer-based model. Our work discusses a rule-based grapheme-to-beat
transformation tailored for extracting the rhythm from fully diacritized Arabic
script. Our approach employs a conditional denoising objective to fine-tune
ByT5, where the model reconstructs masked words to match a target rhythm. We
adopt a curriculum learning strategy, pre-training on a general Arabic dataset
before fine-tuning on poetic dataset, and explore cross-lingual transfer from
English to Arabic. Experimental results demonstrate that our models achieve
high rhythmic alignment while maintaining semantic coherence. The proposed
model has the potential to be used in co-creative applications in the process
of composing classical Arabic poems.

</details>


### [21] [Trace Is In Sentences: Unbiased Lightweight ChatGPT-Generated Text Detector](https://arxiv.org/abs/2509.18535)
*Mo Mu,Dianqiao Lei,Chang Li*

Main category: cs.CL

TL;DR: 提出了一种轻量级框架，通过分析文本内部结构来检测原始和PSP修改的AI生成文本，解决了现有词级检测器的局限性。


<details>
  <summary>Details</summary>
Motivation: ChatGPT的广泛使用引发了对AI生成文本检测的需求，现有词级检测器存在对改写敏感、存在偏见、对修改文本性能下降等问题。

Method: 使用预训练语言模型编码句子嵌入，通过注意力机制建模关系，采用对比学习减轻自回归生成偏见，结合因果图和反事实方法分离结构特征与主题相关偏见。

Result: 在两个精心策划的数据集（包括摘要比较和修订的生活FAQ）上的实验验证了方法的有效性。

Conclusion: 该方法通过关注文本内部结构特征，能够有效检测AI生成文本，且对词级修改具有鲁棒性。

Abstract: The widespread adoption of ChatGPT has raised concerns about its misuse,
highlighting the need for robust detection of AI-generated text. Current
word-level detectors are vulnerable to paraphrasing or simple prompts (PSP),
suffer from biases induced by ChatGPT's word-level patterns (CWP) and training
data content, degrade on modified text, and often require large models or
online LLM interaction. To tackle these issues, we introduce a novel task to
detect both original and PSP-modified AI-generated texts, and propose a
lightweight framework that classifies texts based on their internal structure,
which remains invariant under word-level changes. Our approach encodes sentence
embeddings from pre-trained language models and models their relationships via
attention. We employ contrastive learning to mitigate embedding biases from
autoregressive generation and incorporate a causal graph with counterfactual
methods to isolate structural features from topic-related biases. Experiments
on two curated datasets, including abstract comparisons and revised life FAQs,
validate the effectiveness of our method.

</details>


### [22] [CCQA: Generating Question from Solution Can Improve Inference-Time Reasoning in SLMs](https://arxiv.org/abs/2509.18536)
*Jin Young Kim,Ji Won Yoon*

Main category: cs.CL

TL;DR: CCQA是一种针对小型语言模型的新型推理方法，通过循环一致性机制生成问题并评估相似度来选择最佳答案


<details>
  <summary>Details</summary>
Motivation: 现有的推理策略在大型语言模型上效果显著，但在小型模型上表现不佳，需要开发专门适用于小型模型的有效推理方法

Method: 基于循环一致性原理，从每个推理路径和答案生成问题，评估其与原问题的相似度，选择相似度最高的候选解作为最终答案。使用专门的轻量级Flan-T5模型支持问题生成

Result: 在数学和常识推理基准测试中，CCQA在八个模型上一致优于现有最先进方法

Conclusion: 该方法为小型语言模型的高效推理建立了新的实用基准

Abstract: Recently, inference-time reasoning strategies have further improved the
accuracy of large language models (LLMs), but their effectiveness on smaller
models remains unclear. Based on the observation that conventional approaches
often fail to improve performance in this context, we propose
\textbf{C}ycle-\textbf{C}onsistency in \textbf{Q}uestion \textbf{A}nswering
(CCQA), a novel reasoning method that can be effectively applied to SLMs.
Inspired by cycle consistency, CCQA generates a question from each reasoning
path and answer, evaluates each by its similarity to the original question, and
then selects the candidate solution with the highest similarity score as the
final response. Since conventional SLMs struggle to generate accurate questions
from their own reasoning paths and answers, we employ a lightweight Flan-T5
model specialized for question generation to support this process efficiently.
From the experimental results, it is verified that CCQA consistently
outperforms existing state-of-the-art (SOTA) methods across eight models on
mathematical and commonsense reasoning benchmarks. Furthermore, our method
establishes a new practical baseline for efficient reasoning in SLMs. Source
code can be found at https://github.com/scai-research/ccqa_official.

</details>


### [23] [Prior-based Noisy Text Data Filtering: Fast and Strong Alternative For Perplexity](https://arxiv.org/abs/2509.18577)
*Yeongbin Seo,Gayoung Kim,Jaehyung Kim,Jinyoung Yeo*

Main category: cs.CL

TL;DR: 提出了一种基于词频统计的先验数据过滤方法，替代传统的基于困惑度(PPL)的过滤方法，在保持高性能的同时大幅降低时间成本


<details>
  <summary>Details</summary>
Motivation: 传统基于困惑度的数据过滤方法存在时间成本高、对噪声和分布外样本不可靠的问题，需要更高效可靠的替代方案

Method: 使用语料库级别的词频统计估计token先验概率，基于token先验的均值和标准差来过滤文档，无需模型推理

Result: 在20个下游基准测试中取得最高平均性能，同时将时间成本降低1000倍以上，适用于代码、数学等符号语言和多语言语料库

Conclusion: 基于先验的数据过滤方法是一种简单而强大的替代方案，在效率和性能上都优于传统的困惑度过滤方法

Abstract: As large language models (LLMs) are pretrained on massive web corpora,
careful selection of data becomes essential to ensure effective and efficient
learning. While perplexity (PPL)-based filtering has shown strong performance,
it suffers from drawbacks: substantial time costs and inherent unreliability of
the model when handling noisy or out-of-distribution samples. In this work, we
propose a simple yet powerful alternative: a prior-based data filtering method
that estimates token priors using corpus-level term frequency statistics,
inspired by linguistic insights on word roles and lexical density. Our approach
filters documents based on the mean and standard deviation of token priors,
serving as a fast proxy to PPL while requiring no model inference. Despite its
simplicity, the prior-based filter achieves the highest average performance
across 20 downstream benchmarks, while reducing time cost by over 1000x
compared to PPL-based filtering. We further demonstrate its applicability to
symbolic languages such as code and math, and its dynamic adaptability to
multilingual corpora without supervision

</details>


### [24] [TsqLoRA: Towards Sensitivity and Quality Low-Rank Adaptation for Efficient Fine-Tuning](https://arxiv.org/abs/2509.18585)
*Yu Chen,Yifei Han,Long Zhang,Yue Du,Bin Li*

Main category: cs.CL

TL;DR: TsqLoRA是一种新颖的参数高效微调方法，通过数据质量驱动选择和敏感度感知的低秩适应来提高大模型微调效率


<details>
  <summary>Details</summary>
Motivation: 完全微调所有模型参数计算成本高且内存密集，现有参数高效微调方法忽视了不同模型层的敏感度差异和训练数据的重要性

Method: TsqLoRA包含两个主要组件：质量感知采样机制选择最有信息的训练数据，以及动态秩分配模块根据层敏感度调整每层的秩

Result: 实验结果表明TsqLoRA在各种NLP任务上提高了微调效率，同时保持甚至改善了性能

Conclusion: TsqLoRA通过结合数据质量选择和敏感度感知的秩分配，为资源受限环境提供了一种有效的微调解决方案

Abstract: Fine-tuning large pre-trained models for downstream tasks has become a
fundamental approach in natural language processing. Fully fine-tuning all
model parameters is computationally expensive and memory-intensive, especially
in resource-constrained environments. Existing parameter-efficient fine-tuning
methods reduce the number of trainable parameters but typically overlook the
varying sensitivity of different model layers and the importance of training
data. In this work, we propose TsqLoRA, a novel method that integrates
data-quality-driven selection with sensitivity-aware low-rank adaptation,
consisted of two main components: a quality-aware sampling mechanism for
selecting the most informative training data, and a dynamic rank allocation
module that adjusts the rank of each layer based on its sensitivity to
parameter updates. The experimental results demonstrate that TsqLoRA improves
fine-tuning efficiency while maintaining or even improving performance on a
variety of NLP tasks. Our code will be available at
https://github.com/Benjamin-Ricky/TsqLoRA.

</details>


### [25] [UniECG: Understanding and Generating ECG in One Unified Model](https://arxiv.org/abs/2509.18588)
*Jiarui Jin,Haoyu Wang,Xiang Lan,Jun Li,Gaofeng Cheng,Hongyan Li,Shenda Hong*

Main category: cs.CL

TL;DR: UniECG是首个能够同时执行基于证据的心电图解释和文本条件心电图生成任务的统一模型，通过解耦的两阶段训练方法实现。


<details>
  <summary>Details</summary>
Motivation: 当前统一模型如GPT-5在视觉语言任务上取得进展，但无法正确理解心电图信号并提供准确的医疗诊断，也不能正确生成心电图信号。

Method: 采用解耦的两阶段训练方法：首先学习基于证据的解释技能（ECG-to-Text），然后通过潜在空间对齐注入心电图生成能力（Text-to-ECG）。

Result: UniECG能够根据用户输入自主选择解释或生成心电图，显著扩展了当前心电图模型的能力边界。

Conclusion: 该模型解决了现有统一模型在心电图理解和生成方面的局限性，为心电图分析提供了更全面的解决方案。

Abstract: Recent unified models such as GPT-5 have achieved encouraging progress on
vision-language tasks. However, these unified models typically fail to
correctly understand ECG signals and provide accurate medical diagnoses, nor
can they correctly generate ECG signals. To address these limitations, we
propose UniECG, the first unified model for ECG capable of concurrently
performing evidence-based ECG interpretation and text-conditioned ECG
generation tasks. Through a decoupled two-stage training approach, the model
first learns evidence-based interpretation skills (ECG-to-Text), and then
injects ECG generation capabilities (Text-to-ECG) via latent space alignment.
UniECG can autonomously choose to interpret or generate an ECG based on user
input, significantly extending the capability boundaries of current ECG models.
Our code and checkpoints will be made publicly available at
https://github.com/PKUDigitalHealth/UniECG upon acceptance.

</details>


### [26] [A Good Plan is Hard to Find: Aligning Models with Preferences is Misaligned with What Helps Users](https://arxiv.org/abs/2509.18632)
*Nishant Balepur,Matthew Shu,Yoo Yeon Sung,Seraphina Goldfarb-Tarrant,Shi Feng,Fumeng Yang,Rachel Rudinger,Jordan Lee Boyd-Graber*

Main category: cs.CL

TL;DR: 本文研究发现用户偏好和模型偏好并不能准确预测哪些计划真正对用户有帮助，表明常见的对齐方法可能误导LLM的有用性。


<details>
  <summary>Details</summary>
Motivation: 测试LLM生成计划的对齐方法是否真正反映了对用户的帮助性，而非仅仅基于用户偏好。

Method: 使用Planorama界面，让126名用户回答300个多步骤问题，收集4388个计划执行和5584个比较数据，测量计划的有用性和用户偏好。

Result: 1) 用户/模型偏好和代理成功率不能准确预测计划的帮助性；2) 这种差距不是用户特定偏好造成的；3) 表面线索（如简洁性）与偏好相关但无法预测帮助性。

Conclusion: 需要基于真实用户交互的反馈来对齐有用的LLM，而不仅仅是基于看起来有用的偏好。

Abstract: To assist users in complex tasks, LLMs generate plans: step-by-step
instructions towards a goal. While alignment methods aim to ensure LLM plans
are helpful, they train (RLHF) or evaluate (ChatbotArena) on what users prefer,
assuming this reflects what helps them. We test this with Planorama: an
interface where 126 users answer 300 multi-step questions with LLM plans. We
get 4388 plan executions and 5584 comparisons to measure plan helpfulness (QA
success) and user preferences on plans, and recreate the setup in agents and
reward models to see if they simulate or prefer what helps users. We expose: 1)
user/model preferences and agent success do not accurately predict which plans
help users, so common alignment feedback can misalign with helpfulness; 2) this
gap is not due to user-specific preferences, as users are similarly successful
when using plans they prefer/disprefer; 3) surface-level cues like brevity and
question similarity strongly link to preferences, but such biases fail to
predict helpfulness. In all, we argue aligning helpful LLMs needs feedback from
real user interactions, not just preferences of what looks helpful, so we
discuss the plan NLP researchers can execute to solve this problem.

</details>


### [27] [Consistency-Aware Parameter-Preserving Knowledge Editing Framework for Multi-Hop Question Answering](https://arxiv.org/abs/2509.18655)
*Lingwen Deng,Yifei Han,Long Zhang,Yue Du,Bin Li*

Main category: cs.CL

TL;DR: CAPE-KG是一个基于知识图谱的一致性感知参数保留知识编辑框架，用于多跳问答任务，解决了现有方法在知识污染、更新不稳定和检索不一致方面的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的基于知识图谱的参数保留知识编辑方法在多跳问答中存在一致性问题，导致知识污染、更新不稳定和检索行为不符合预期编辑，影响了多跳推理的可靠性。

Method: 提出CAPE-KG框架，确保知识图谱的构建、更新和检索始终与多跳问答任务要求对齐，在未编辑和已编辑知识上保持连贯推理。

Result: 在MQuAKE基准测试上的广泛实验显示，CAPE-KG在多跳问答的PPKE性能上取得了准确率提升。

Conclusion: CAPE-KG通过解决一致性问题，有效提升了参数保留知识编辑在多跳问答中的性能，证明了在PPKE中处理一致性的重要性。

Abstract: Parameter-Preserving Knowledge Editing (PPKE) enables updating models with
new or corrected information without retraining or parameter adjustment. Recent
PPKE approaches based on knowledge graphs (KG) to extend knowledge editing (KE)
capabilities to multi-hop question answering (MHQA). However, these methods
often lack consistency, leading to knowledge contamination, unstable updates,
and retrieval behaviors that fail to reflect the intended edits. Such
inconsistencies undermine the reliability of PPKE in multi- hop reasoning. We
present CAPE-KG, Consistency-Aware Parameter-Preserving Editing with Knowledge
Graphs, a novel consistency-aware framework for PPKE on MHQA. CAPE-KG ensures
KG construction, update, and retrieval are always aligned with the requirements
of the MHQA task, maintaining coherent reasoning over both unedited and edited
knowledge. Extensive experiments on the MQuAKE benchmark show accuracy
improvements in PPKE performance for MHQA, demonstrating the effectiveness of
addressing consistency in PPKE.

</details>


### [28] [Analyzing Uncertainty of LLM-as-a-Judge: Interval Evaluations with Conformal Prediction](https://arxiv.org/abs/2509.18658)
*Huanxin Sheng,Xinyi Liu,Hangfeng He,Jieyu Zhao,Jian Kang*

Main category: cs.CL

TL;DR: 本文提出了首个通过保形预测分析LLM作为评估者不确定性的框架，为LLM评分提供预测区间，并设计了针对离散评分任务的序数边界调整方法。


<details>
  <summary>Details</summary>
Motivation: LLM作为评估者的不确定性尚未充分探索，这种可靠性不足可能限制其在许多应用中的部署。

Method: 使用保形预测构建连续预测区间，设计序数边界调整处理离散评分任务，提出区间中点作为低偏差替代评分方法。

Result: 实验表明保形预测能提供具有覆盖保证的有效预测区间，区间中点和重新提示评估者能改善判断质量。

Conclusion: 该框架为LLM评估提供了不确定性量化方法，提高了评估结果的可靠性。

Abstract: LLM-as-a-judge has become a promising paradigm for using large language
models (LLMs) to evaluate natural language generation (NLG), but the
uncertainty of its evaluation remains underexplored. This lack of reliability
may limit its deployment in many applications. This work presents the first
framework to analyze the uncertainty by offering a prediction interval of
LLM-based scoring via conformal prediction. Conformal prediction constructs
continuous prediction intervals from a single evaluation run, and we design an
ordinal boundary adjustment for discrete rating tasks. We also suggest a
midpoint-based score within the interval as a low-bias alternative to raw model
score and weighted average. We perform extensive experiments and analysis,
which show that conformal prediction can provide valid prediction interval with
coverage guarantees. We also explore the usefulness of interval midpoint and
judge reprompting for better judgment.

</details>


### [29] [MemOrb: A Plug-and-Play Verbal-Reinforcement Memory Layer for E-Commerce Customer Service](https://arxiv.org/abs/2509.18713)
*Yizhe Huang,Yang Liu,Ruiyu Zhao,Xiaolong Zhong,Xingming Yue,Ling Jiang*

Main category: cs.CL

TL;DR: MemOrb是一个轻量级、即插即用的语言强化记忆层，通过将多轮交互提炼为紧凑的策略反思，存储在共享记忆库中，无需微调即可指导决策，显著提升LLM智能体在客服场景中的成功率和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于大语言模型的客服智能体存在跨会话遗忘、重复错误和缺乏持续自我改进机制的问题，在需要稳定性和一致性的动态环境中表现不可靠。

Method: 提出MemOrb方法，通过提取多轮交互的策略反思，存储在共享记忆库中，并在决策时检索这些反思来指导行为，整个过程不需要对模型进行微调。

Result: 实验表明MemOrb显著提高了任务成功率和稳定性，在多轮成功率上最高获得63个百分点的提升，并在重复试验中表现出更一致的性能。

Conclusion: 结构化反思是增强冻结LLM智能体在客服场景中长期可靠性的有效机制。

Abstract: Large Language Model-based agents(LLM-based agents) are increasingly deployed
in customer service, yet they often forget across sessions, repeat errors, and
lack mechanisms for continual self-improvement. This makes them unreliable in
dynamic settings where stability and consistency are critical. To better
evaluate these properties, we emphasize two indicators: task success rate as a
measure of overall effectiveness, and consistency metrics such as Pass$^k$ to
capture reliability across multiple trials. To address the limitations of
existing approaches, we propose MemOrb, a lightweight and plug-and-play verbal
reinforcement memory layer that distills multi-turn interactions into compact
strategy reflections. These reflections are stored in a shared memory bank and
retrieved to guide decision-making, without requiring any fine-tuning.
Experiments show that MemOrb significantly improves both success rate and
stability, achieving up to a 63 percentage-point gain in multi-turn success
rate and delivering more consistent performance across repeated trials. Our
results demonstrate that structured reflection is a powerful mechanism for
enhancing long-term reliability of frozen LLM agents in customer service
scenarios.

</details>


### [30] [LOTUSDIS: A Thai far-field meeting corpus for robust conversational ASR](https://arxiv.org/abs/2509.18722)
*Pattara Tipaksorn,Sumonmas Thatphithakkul,Vataya Chunwijitra,Kwanchiva Thangthai*

Main category: cs.CL

TL;DR: LOTUSDIS是一个公开的泰语会议语料库，包含114小时自发对话，专门用于远场对话语音识别研究。该数据集通过多种麦克风在不同距离下录制，包含重叠语音和真实环境效应。


<details>
  <summary>Details</summary>
Motivation: 现有的预训练模型在泰语远场语音识别上表现不佳，存在数据不匹配问题。需要距离多样化的训练数据来提升ASR系统的鲁棒性。

Method: 收集114小时自发泰语对话，使用9个独立单通道设备在0.12-10米距离范围内同时录制，涵盖6种麦克风类型。提供标准数据集划分和可复现的基线系统。

Result: 零样本Whisper模型在远场条件下WER严重退化（81.6%）。微调后显著改善：总体WER从64.3%降至38.3%，远场WER从81.6%降至49.5%，最远麦克风改善最大。

Conclusion: 距离多样化的训练数据对于鲁棒ASR至关重要。LOTUSDIS语料库和基线系统为远场对话ASR研究提供了重要资源，促进该领域的可复现研究。

Abstract: We present LOTUSDIS, a publicly available Thai meeting corpus designed to
advance far-field conversational ASR. The dataset comprises 114 hours of
spontaneous, unscripted dialogue collected in 15-20 minute sessions with three
participants, where overlapping speech is frequent and natural. Speech was
recorded simultaneously by nine independent single-channel devices spanning six
microphone types at distances from 0.12 m to 10 m, preserving the authentic
effects of reverberation, noise, and device coloration without relying on
microphone arrays. We provide standard train, dev, test splits and release a
reproducible baseline system. We benchmarked several Whisper variants under
zero-shot and fine-tuned conditions. Off-the-shelf models showed strong
degradation with distance, confirming a mismatch between pre-training data and
Thai far-field speech. Fine-tuning on LOTUSDIS dramatically improved
robustness: a Thai Whisper baseline reduced overall WER from 64.3 to 38.3 and
far-field WER from 81.6 to 49.5, with especially large gains on the most
distant microphones. These results underscore the importance of
distance-diverse training data for robust ASR. The corpus is available under
CC-BY-SA 4.0. We also release training and evaluation scripts as a baseline
system to promote reproducible research in this field.

</details>


### [31] [Global-Recent Semantic Reasoning on Dynamic Text-Attributed Graphs with Large Language Models](https://arxiv.org/abs/2509.18742)
*Yunan Wang,Jianxin Li,Ziwei Zhang*

Main category: cs.CL

TL;DR: DyGRASP是一种新颖的动态文本属性图处理方法，通过结合LLM和时序GNN来有效捕捉近期和全局的时序语义，解决了现有方法在处理动态文本属性图时的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的图神经网络和大语言模型主要关注静态文本属性图，难以处理动态文本属性图中随时间演化的图交互和相关文本属性，特别是忽略了近期-全局时序语义和面临效率问题。

Method: 提出DyGRASP方法：1）使用节点中心隐式推理和滑动窗口机制捕捉近期时序语义；2）通过显式推理和类RNN链结构捕获全局语义动态；3）通过更新和合并层整合近期和全局时序语义以及动态图结构信息。

Result: 在DyTAG基准测试中，DyGRASP表现出优越性能，在目标节点检索任务中Hit@10指标提升高达34%，并且在不同时序GNN和LLM上展现出强泛化能力。

Conclusion: DyGRASP通过有效整合近期和全局时序语义，为动态文本属性图的处理提供了高效且有效的解决方案，在多个任务中显著优于现有方法。

Abstract: Dynamic Text-Attribute Graphs (DyTAGs), characterized by time-evolving graph
interactions and associated text attributes, are prevalent in real-world
applications. Existing methods, such as Graph Neural Networks (GNNs) and Large
Language Models (LLMs), mostly focus on static TAGs. Extending these existing
methods to DyTAGs is challenging as they largely neglect the recent-global
temporal semantics: the recent semantic dependencies among interaction texts
and the global semantic evolution of nodes over time. Furthermore, applying
LLMs to the abundant and evolving text in DyTAGs faces efficiency issues. To
tackle these challenges, we propose Dynamic Global-Recent Adaptive Semantic
Processing (DyGRASP), a novel method that leverages LLMs and temporal GNNs to
efficiently and effectively reason on DyTAGs. Specifically, we first design a
node-centric implicit reasoning method together with a sliding window mechanism
to efficiently capture recent temporal semantics. In addition, to capture
global semantic dynamics of nodes, we leverage explicit reasoning with tailored
prompts and an RNN-like chain structure to infer long-term semantics. Lastly,
we intricately integrate the recent and global temporal semantics as well as
the dynamic graph structural information using updating and merging layers.
Extensive experiments on DyTAG benchmarks demonstrate DyGRASP's superiority,
achieving up to 34% improvement in Hit@10 for destination node retrieval task.
Besides, DyGRASP exhibits strong generalization across different temporal GNNs
and LLMs.

</details>


### [32] [False Friends Are Not Foes: Investigating Vocabulary Overlap in Multilingual Language Models](https://arxiv.org/abs/2509.18750)
*Julie Kallini,Dan Jurafsky,Christopher Potts,Martijn Bartelds*

Main category: cs.CL

TL;DR: 本文研究了多语言模型中子词标记重叠对跨语言迁移的影响，通过控制实验发现标记重叠有利于跨语言语义关系的捕获，并能提升跨语言理解任务的性能。


<details>
  <summary>Details</summary>
Motivation: 多语言分词器自然会产生跨语言的重叠标记，但现有研究对标记重叠是否促进跨语言迁移还是引入干扰存在争议，部分原因是实验设置和混杂因素（如标记频率、分词粒度）的差异。

Method: 设计了受控实验，在双语自回归模型上训练多个语言对，系统性地改变词汇重叠设置，并引入新的维度——跨语言共享标记的语义相似性来分析重叠的影响。

Result: 分析模型隐藏表示发现，任何类型的重叠都会创建捕获跨语言语义关系的嵌入空间，而在词汇不相交的模型中这种效应较弱。在XNLI和XQuAD任务上，有重叠的模型表现优于词汇不相交的模型，且迁移性能随重叠增加而提升。

Conclusion: 标记重叠在多语言模型中具有优势，保持大量共享词汇仍然是多语言分词器的有益设计选择。

Abstract: Subword tokenizers trained on multilingual corpora naturally produce
overlapping tokens across languages. Does token overlap facilitate
cross-lingual transfer or instead introduce interference between languages?
Prior work offers mixed evidence, partly due to varied setups and confounders,
such as token frequency or subword segmentation granularity. To address this
question, we devise a controlled experiment where we train bilingual
autoregressive models on multiple language pairs under systematically varied
vocabulary overlap settings. Crucially, we explore a new dimension to
understanding how overlap affects transfer: the semantic similarity of tokens
shared across languages. We first analyze our models' hidden representations
and find that overlap of any kind creates embedding spaces that capture
cross-lingual semantic relationships, while this effect is much weaker in
models with disjoint vocabularies. On XNLI and XQuAD, we find that models with
overlap outperform models with disjoint vocabularies, and that transfer
performance generally improves as overlap increases. Overall, our findings
highlight the advantages of token overlap in multilingual models and show that
substantial shared vocabulary remains a beneficial design choice for
multilingual tokenizers.

</details>


### [33] [When Long Helps Short: How Context Length in Supervised Fine-tuning Affects Behavior of Large Language Models](https://arxiv.org/abs/2509.18762)
*Yingming Zheng,Hanqi Li,Kai Yu,Lu Chen*

Main category: cs.CL

TL;DR: 研究发现长上下文监督微调（SFT）能提升短上下文任务性能，这与长上下文预训练通常导致性能下降的常识相反。通过分析注意力机制和网络组件，揭示了长上下文SFT促进上下文知识偏好，而混合训练可优化这种偏差。


<details>
  <summary>Details</summary>
Motivation: 随着现实应用对长上下文窗口需求增加，长上下文数据上的持续预训练和SFT成为常见方法。虽然预训练中数据长度的影响已有研究，但SFT中数据长度的影响尚不明确。

Method: 系统研究SFT数据长度对LLM短上下文任务行为的影响，解耦分析多头注意力（MHA）和前馈网络（FFN）组件，研究它们的相互作用和知识偏好偏差。

Result: 长上下文SFT能独立提升MHA和FFN的性能，但会促进上下文知识偏好，而短上下文SFT偏好参数知识，单独使用长上下文SFT不是最优选择。

Conclusion: 混合训练可以缓解知识偏好偏差，为LLM微调提供了可解释的指导。

Abstract: Large language models (LLMs) have achieved impressive performance across
natural language processing (NLP) tasks. As real-world applications
increasingly demand longer context windows, continued pretraining and
supervised fine-tuning (SFT) on long-context data has become a common approach.
While the effects of data length in continued pretraining have been extensively
studied, their implications for SFT remain unclear. In this work, we
systematically investigate how SFT data length influences LLM behavior on
short-context tasks. Counterintuitively, we find that long-context SFT improves
short-context performance, contrary to the commonly observed degradation from
long-context pretraining. To uncover the underlying mechanisms of this
phenomenon, we first decouple and analyze two key components, Multi-Head
Attention (MHA) and Feed-Forward Network (FFN), and show that both
independently benefit from long-context SFT. We further study their interaction
and reveal a knowledge preference bias: long-context SFT promotes contextual
knowledge, while short-context SFT favors parametric knowledge, making
exclusive reliance on long-context SFT suboptimal. Finally, we demonstrate that
hybrid training mitigates this bias, offering explainable guidance for
fine-tuning LLMs.

</details>


### [34] [Financial Risk Relation Identification through Dual-view Adaptation](https://arxiv.org/abs/2509.18775)
*Wei-Ning Chiu,Yu-Hsiang Wang,Andy Hsiao,Yu-Shiang Huang,Chuan-Ju Wang*

Main category: cs.CL

TL;DR: 提出了一种基于10-K文件的无监督方法，用于提取企业间风险关系，通过自然语言处理技术捕捉隐含风险联系，优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 传统依赖专家判断和手动分析企业间风险关系的方法主观性强、劳动密集且难以扩展，需要系统化的自动解决方案。

Method: 利用10-K文件作为数据源，基于时间顺序和词汇模式进行无监督微调，开发领域特定的金融编码器，引入定量风险关系评分。

Result: 大量实验表明该方法在多个评估设置下优于强基线方法。

Conclusion: 该方法为投资组合管理和投资策略等应用提供了可扩展、透明且可解释的企业间风险关系分析工具。

Abstract: A multitude of interconnected risk events -- ranging from regulatory changes
to geopolitical tensions -- can trigger ripple effects across firms.
Identifying inter-firm risk relations is thus crucial for applications like
portfolio management and investment strategy. Traditionally, such assessments
rely on expert judgment and manual analysis, which are, however, subjective,
labor-intensive, and difficult to scale. To address this, we propose a
systematic method for extracting inter-firm risk relations using Form 10-K
filings -- authoritative, standardized financial documents -- as our data
source. Leveraging recent advances in natural language processing, our approach
captures implicit and abstract risk connections through unsupervised
fine-tuning based on chronological and lexical patterns in the filings. This
enables the development of a domain-specific financial encoder with a deeper
contextual understanding and introduces a quantitative risk relation score for
transparency, interpretable analysis. Extensive experiments demonstrate that
our method outperforms strong baselines across multiple evaluation settings.

</details>


### [35] [AECBench: A Hierarchical Benchmark for Knowledge Evaluation of Large Language Models in the AEC Field](https://arxiv.org/abs/2509.18776)
*Chen Liang,Zhaoqi Huang,Haofen Wang,Fu Chai,Chunying Yu,Huanhuan Wei,Zhengjie Liu,Yanpeng Li,Hongjun Wang,Ruifeng Luo,Xianzhong Zhao*

Main category: cs.CL

TL;DR: 本文建立了AECBench基准，用于评估大型语言模型在建筑、工程和施工领域的性能，发现模型在复杂推理和计算任务上表现不佳。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在AEC领域的应用增加，需要评估这些模型在专业和安全关键领域的鲁棒性和可靠性。

Method: 创建包含23个代表性任务的五级认知评估框架，构建4800个问题的数据集，并采用LLM-as-a-Judge方法进行评估。

Result: 评估9个LLMs显示，模型在知识记忆和理解层面表现良好，但在表格解释、复杂推理和计算、专业文档生成等方面存在显著性能缺陷。

Conclusion: 该研究为未来在安全关键工程实践中可靠集成LLMs的研究和开发奠定了基础。

Abstract: Large language models (LLMs), as a novel information technology, are seeing
increasing adoption in the Architecture, Engineering, and Construction (AEC)
field. They have shown their potential to streamline processes throughout the
building lifecycle. However, the robustness and reliability of LLMs in such a
specialized and safety-critical domain remain to be evaluated. To address this
challenge, this paper establishes AECBench, a comprehensive benchmark designed
to quantify the strengths and limitations of current LLMs in the AEC domain.
The benchmark defines 23 representative tasks within a five-level
cognition-oriented evaluation framework encompassing Knowledge Memorization,
Understanding, Reasoning, Calculation, and Application. These tasks were
derived from authentic AEC practice, with scope ranging from codes retrieval to
specialized documents generation. Subsequently, a 4,800-question dataset
encompassing diverse formats, including open-ended questions, was crafted
primarily by engineers and validated through a two-round expert review.
Furthermore, an LLM-as-a-Judge approach was introduced to provide a scalable
and consistent methodology for evaluating complex, long-form responses
leveraging expert-derived rubrics. Through the evaluation of nine LLMs, a clear
performance decline across five cognitive levels was revealed. Despite
demonstrating proficiency in foundational tasks at the Knowledge Memorization
and Understanding levels, the models showed significant performance deficits,
particularly in interpreting knowledge from tables in building codes, executing
complex reasoning and calculation, and generating domain-specific documents.
Consequently, this study lays the groundwork for future research and
development aimed at the robust and reliable integration of LLMs into
safety-critical engineering practices.

</details>


### [36] [Beyond the Leaderboard: Understanding Performance Disparities in Large Language Models via Model Diffing](https://arxiv.org/abs/2509.18792)
*Sabri Boughorbel,Fahim Dalvi,Nadir Durrani,Majd Hawasly*

Main category: cs.CL

TL;DR: 本文使用模型差异分析技术对比Gemma-2-9b-it和其SimPO增强版本，发现SimPO主要提升了安全性、多语言能力和指令跟随能力，同时减少了模型自引用和幻觉管理。


<details>
  <summary>Details</summary>
Motivation: 随着微调成为改进大语言模型的主要方法，理解微调过程中模型的具体变化变得日益重要。传统基准测试往往无法解释模型性能差异的原因。

Method: 采用模型差异分析这一机制可解释性方法，使用crosscoders识别和分类两个模型之间的潜在表示差异。

Result: SimPO获得的潜在概念主要增强了安全机制(+32.8%)、多语言能力(+43.8%)和指令跟随(+151.7%)，同时减少了模型自引用(-44.1%)和幻觉管理(-68.5%)。

Conclusion: 模型差异分析能够提供超越排行榜指标的细粒度洞察，将性能差距归因于具体的机制能力，为LLM比较提供了透明和有针对性的框架。

Abstract: As fine-tuning becomes the dominant paradigm for improving large language
models (LLMs), understanding what changes during this process is increasingly
important. Traditional benchmarking often fails to explain why one model
outperforms another. In this work, we use model diffing, a mechanistic
interpretability approach, to analyze the specific capability differences
between Gemma-2-9b-it and a SimPO-enhanced variant. Using crosscoders, we
identify and categorize latent representations that differentiate the two
models. We find that SimPO acquired latent concepts predominantly enhance
safety mechanisms (+32.8%), multilingual capabilities (+43.8%), and
instruction-following (+151.7%), while its additional training also reduces
emphasis on model self-reference (-44.1%) and hallucination management
(-68.5%). Our analysis shows that model diffing can yield fine-grained insights
beyond leaderboard metrics, attributing performance gaps to concrete
mechanistic capabilities. This approach offers a transparent and targeted
framework for comparing LLMs.

</details>


### [37] [MAPEX: A Multi-Agent Pipeline for Keyphrase Extraction](https://arxiv.org/abs/2509.18813)
*Liting Zhang,Shiwan Zhao,Aobo Kong,Qicheng Li*

Main category: cs.CL

TL;DR: MAPEX是一个基于多智能体协作的关键词提取框架，通过动态适应文档长度的双路径策略，在多个基准数据集上显著优于现有无监督方法。


<details>
  <summary>Details</summary>
Motivation: 现有的无监督提示方法通常采用单阶段推理管道和统一提示策略，无法充分利用LLMs的推理和生成能力，特别是在处理不同长度和复杂度的文档时效果受限。

Method: MAPEX引入多智能体协作机制，包含专家招募、候选提取、主题引导、知识增强和后处理模块，采用知识驱动提取（短文本）和主题引导提取（长文本）的双路径策略。

Result: 在6个基准数据集和3种不同LLM上的实验表明，MAPEX在F1@5指标上平均比最先进的无监督方法高出2.44%，比标准LLM基线高出4.01%。

Conclusion: MAPEX框架通过多智能体协作和动态适应策略，显著提升了关键词提取的性能和泛化能力，为复杂场景下的关键词提取提供了有效解决方案。

Abstract: Keyphrase extraction is a fundamental task in natural language processing.
However, existing unsupervised prompt-based methods for Large Language Models
(LLMs) often rely on single-stage inference pipelines with uniform prompting,
regardless of document length or LLM backbone. Such one-size-fits-all designs
hinder the full exploitation of LLMs' reasoning and generation capabilities,
especially given the complexity of keyphrase extraction across diverse
scenarios. To address these challenges, we propose MAPEX, the first framework
that introduces multi-agent collaboration into keyphrase extraction. MAPEX
coordinates LLM-based agents through modules for expert recruitment, candidate
extraction, topic guidance, knowledge augmentation, and post-processing. A
dual-path strategy dynamically adapts to document length: knowledge-driven
extraction for short texts and topic-guided extraction for long texts.
Extensive experiments on six benchmark datasets across three different LLMs
demonstrate its strong generalization and universality, outperforming the
state-of-the-art unsupervised method by 2.44\% and standard LLM baselines by
4.01\% in F1@5 on average. Code is available at
https://github.com/NKU-LITI/MAPEX.

</details>


### [38] [Are Smaller Open-Weight LLMs Closing the Gap to Proprietary Models for Biomedical Question Answering?](https://arxiv.org/abs/2509.18843)
*Damian Stachura,Joanna Konieczna,Artur Nowak*

Main category: cs.CL

TL;DR: 开源大语言模型在生物医学问答任务中与闭源模型表现相当，甚至在某些情况下通过集成策略超越闭源模型


<details>
  <summary>Details</summary>
Motivation: 研究开源大语言模型是否能够有效替代更大的闭源模型，特别是在生物医学问答领域

Method: 使用检索相关片段、上下文学习、结构化输出等技术，并对精确答案问题采用集成方法结合不同模型的输出

Result: 开源大语言模型与专有模型表现相当，在某些情况下应用集成策略时甚至超越了闭源模型

Conclusion: 开源大语言模型在生物医学问答任务中具有与闭源模型相当的竞争力，集成策略可以进一步提升性能

Abstract: Open-weight versions of large language models (LLMs) are rapidly advancing,
with state-of-the-art models like DeepSeek-V3 now performing comparably to
proprietary LLMs. This progression raises the question of whether small
open-weight LLMs are capable of effectively replacing larger closed-source
models. We are particularly interested in the context of biomedical
question-answering, a domain we explored by participating in Task 13B Phase B
of the BioASQ challenge. In this work, we compare several open-weight models
against top-performing systems such as GPT-4o, GPT-4.1, Claude 3.5 Sonnet, and
Claude 3.7 Sonnet. To enhance question answering capabilities, we use various
techniques including retrieving the most relevant snippets based on embedding
distance, in-context learning, and structured outputs. For certain submissions,
we utilize ensemble approaches to leverage the diverse outputs generated by
different models for exact-answer questions. Our results demonstrate that
open-weight LLMs are comparable to proprietary ones. In some instances,
open-weight LLMs even surpassed their closed counterparts, particularly when
ensembling strategies were applied. All code is publicly available at
https://github.com/evidenceprime/BioASQ-13b.

</details>


### [39] [Multi-Hierarchical Feature Detection for Large Language Model Generated Text](https://arxiv.org/abs/2509.18862)
*Luyan Zhang,Xinyu Xie*

Main category: cs.CL

TL;DR: 本文系统研究了多层级特征集成在AI文本检测中的效果，发现尽管理论上多特征应互补，但实际仅带来微小性能提升(0.4-0.5%)且计算成本显著增加(4.2倍)，表明现代神经语言模型可能已高效捕获大部分检测信号。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型技术的快速发展，研究者对多特征方法是否能显著超越单一神经模型在AI文本检测中的表现产生兴趣。虽然直觉上语义、句法和统计特征的结合应提供互补信号，但这一假设尚未在现代LLM生成文本上得到严格验证。

Method: 实现MHFD（多层级特征检测）方法，通过自适应融合集成基于DeBERTa的语义分析、句法解析和统计概率特征。

Result: 在多个基准数据集上的实验结果表明，MHFD方法在域内检测中达到89.7%的准确率，在跨域检测中保持84.2%的稳定性能，相比现有方法有0.4-2.6%的微小提升。

Conclusion: 多特征集成带来的收益有限而计算成本高昂，现代神经语言模型可能已经高效地捕获了大部分相关的检测信号。

Abstract: With the rapid advancement of large language model technology, there is
growing interest in whether multi-feature approaches can significantly improve
AI text detection beyond what single neural models achieve. While intuition
suggests that combining semantic, syntactic, and statistical features should
provide complementary signals, this assumption has not been rigorously tested
with modern LLM-generated text. This paper provides a systematic empirical
investigation of multi-hierarchical feature integration for AI text detection,
specifically testing whether the computational overhead of combining multiple
feature types is justified by performance gains. We implement MHFD
(Multi-Hierarchical Feature Detection), integrating DeBERTa-based semantic
analysis, syntactic parsing, and statistical probability features through
adaptive fusion. Our investigation reveals important negative results: despite
theoretical expectations, multi-feature integration provides minimal benefits
(0.4-0.5% improvement) while incurring substantial computational costs (4.2x
overhead), suggesting that modern neural language models may already capture
most relevant detection signals efficiently. Experimental results on multiple
benchmark datasets demonstrate that the MHFD method achieves 89.7% accuracy in
in-domain detection and maintains 84.2% stable performance in cross-domain
detection, showing modest improvements of 0.4-2.6% over existing methods.

</details>


### [40] [Diversity Boosts AI-Generated Text Detection](https://arxiv.org/abs/2509.18880)
*Advik Raj Basani,Pin-Yu Chen*

Main category: cs.CL

TL;DR: DivEye是一种检测AI生成文本的新框架，通过捕捉文本中不可预测性的波动来区分人类和AI生成内容，在多个基准测试中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在教育、商业合规、新闻和社交媒体中的滥用增加，检测AI生成文本变得日益重要。现有方法依赖标记级似然或不透明的黑盒分类器，难以应对高质量生成内容且缺乏可解释性。

Method: DivEye使用基于惊讶度的特征来捕捉文本中不可预测性的波动，通过一组可解释的统计特征来捕获人类文本在词汇和结构不可预测性上比LLM输出更丰富的变异性。

Result: DivEye在多个基准测试中优于现有零样本检测器达33.2%，与微调基线相比具有竞争力，对改写和对抗攻击具有鲁棒性，跨领域和模型泛化能力强，作为辅助信号可将现有检测器性能提升18.7%。

Conclusion: DivEye不仅提供检测功能，还能提供可解释的洞察，指出节奏不可预测性是LLM检测中一个强大且未被充分探索的信号。

Abstract: Detecting AI-generated text is an increasing necessity to combat misuse of
LLMs in education, business compliance, journalism, and social media, where
synthetic fluency can mask misinformation or deception. While prior detectors
often rely on token-level likelihoods or opaque black-box classifiers, these
approaches struggle against high-quality generations and offer little
interpretability. In this work, we propose DivEye, a novel detection framework
that captures how unpredictability fluctuates across a text using
surprisal-based features. Motivated by the observation that human-authored text
exhibits richer variability in lexical and structural unpredictability than LLM
outputs, DivEye captures this signal through a set of interpretable statistical
features. Our method outperforms existing zero-shot detectors by up to 33.2%
and achieves competitive performance with fine-tuned baselines across multiple
benchmarks. DivEye is robust to paraphrasing and adversarial attacks,
generalizes well across domains and models, and improves the performance of
existing detectors by up to 18.7% when used as an auxiliary signal. Beyond
detection, DivEye provides interpretable insights into why a text is flagged,
pointing to rhythmic unpredictability as a powerful and underexplored signal
for LLM detection.

</details>


### [41] [Extractive Fact Decomposition for Interpretable Natural Language Inference in one Forward Pass](https://arxiv.org/abs/2509.18901)
*Nicholas Popovič,Michael Färber*

Main category: cs.CL

TL;DR: JEDI是一种仅使用编码器架构的联合提取原子事实分解和可解释推理方法，无需生成模型即可实现竞争性准确度和更强的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有NLI任务依赖资源密集型生成式大语言模型进行原子事实分解，需要更高效且可解释的替代方案。

Method: 提出JEDI编码器架构，联合执行提取式原子事实分解和可解释推理，使用合成原理语料库进行训练。

Result: JEDI在分布内达到竞争性准确度，在分布外和对抗性设置中显著提高鲁棒性。

Conclusion: 研究表明仅使用编码器架构和合成原理即可实现NLI的可解释性和鲁棒泛化。

Abstract: Recent works in Natural Language Inference (NLI) and related tasks, such as
automated fact-checking, employ atomic fact decomposition to enhance
interpretability and robustness. For this, existing methods rely on
resource-intensive generative large language models (LLMs) to perform
decomposition. We propose JEDI, an encoder-only architecture that jointly
performs extractive atomic fact decomposition and interpretable inference
without requiring generative models during inference. To facilitate training,
we produce a large corpus of synthetic rationales covering multiple NLI
benchmarks. Experimental results demonstrate that JEDI achieves competitive
accuracy in distribution and significantly improves robustness out of
distribution and in adversarial settings over models based solely on extractive
rationale supervision. Our findings show that interpretability and robust
generalization in NLI can be realized using encoder-only architectures and
synthetic rationales. Code and data available at https://jedi.nicpopovic.com

</details>


### [42] [DTW-Align: Bridging the Modality Gap in End-to-End Speech Translation with Dynamic Time Warping Alignment](https://arxiv.org/abs/2509.18987)
*Abderrahmane Issam,Yusuf Can Semerci,Jan Scholtes,Gerasimos Spanakis*

Main category: cs.CL

TL;DR: 本文提出了一种使用动态时间规整（DTW）对齐语音和文本嵌入的方法，用于端到端语音翻译（E2E-ST）任务，解决了模态差异问题，相比现有方法更准确、更快，在低资源设置下表现更优。


<details>
  <summary>Details</summary>
Motivation: 端到端语音翻译中语音和文本模态之间存在表示差异，现有方法需要依赖对齐工具或使用最近邻相似性搜索，但这些方法要么不适用于所有语言，要么对齐不准确。

Method: 在训练过程中采用动态时间规整（DTW）来对齐语音和文本嵌入，无需额外的对齐工具，能够更准确地建立模态间的对应关系。

Result: 该方法在E2E-ST任务中有效缩小了模态差异，相比之前的工作产生了更准确的对齐结果，在保持可比性能的同时显著提升了速度，在6种语言方向中的5种低资源设置下表现优于现有方法。

Conclusion: DTW对齐方法为端到端语音翻译提供了一种更有效、更通用的模态对齐解决方案，特别是在资源受限的场景下具有明显优势。

Abstract: End-to-End Speech Translation (E2E-ST) is the task of translating source
speech directly into target text bypassing the intermediate transcription step.
The representation discrepancy between the speech and text modalities has
motivated research on what is known as bridging the modality gap.
State-of-the-art methods addressed this by aligning speech and text
representations on the word or token level. Unfortunately, this requires an
alignment tool that is not available for all languages. Although this issue has
been addressed by aligning speech and text embeddings using nearest-neighbor
similarity search, it does not lead to accurate alignments. In this work, we
adapt Dynamic Time Warping (DTW) for aligning speech and text embeddings during
training. Our experiments demonstrate the effectiveness of our method in
bridging the modality gap in E2E-ST. Compared to previous work, our method
produces more accurate alignments and achieves comparable E2E-ST results while
being significantly faster. Furthermore, our method outperforms previous work
in low resource settings on 5 out of 6 language directions.

</details>


### [43] [Investigating Test-Time Scaling with Reranking for Machine Translation](https://arxiv.org/abs/2509.19020)
*Shaomu Tan,Ryosuke Mitani,Ritvik Choudhary,Toshiyuki Sekiya*

Main category: cs.CL

TL;DR: 本文首次系统研究了机器翻译中的测试时缩放（TTS）策略，通过最佳N选择框架在WMT24基准上验证了其有效性。研究发现TTS在高资源语言中能提升翻译质量，小模型通过大N值可媲美大模型，但在低资源语言和固定计算预算下效果有限。


<details>
  <summary>Details</summary>
Motivation: 传统通过增加模型参数规模来提升NLP系统性能的方法计算成本高昂。测试时缩放（TTS）通过在推理时生成多个候选并选择最佳结果来提供替代方案，但该方法在机器翻译领域尚未得到系统研究。

Method: 采用简单实用的最佳N选择框架，在WMT24基准上进行了系统实验，涵盖6个高资源和1个低资源语言对、5种模型规模（3B-72B）以及多种TTS计算预算（N最大达1024）。

Result: 高资源语言中TTS能显著提升翻译质量；小模型配合大N值可达到或超越大模型在N=1时的性能；固定计算预算下大模型更高效，低资源情况下TTS可能因评估指标盲点而降低质量。

Conclusion: TTS为机器翻译提供了一种有效的性能提升策略，特别是在高资源语言场景下，但需要根据语言资源和计算预算进行权衡选择。

Abstract: Scaling model parameters has become the de facto strategy for improving NLP
systems, but it comes with substantial computational costs. Test-Time Scaling
(TTS) offers an alternative by allocating more computation at inference:
generating multiple candidates and selecting the best. While effective in tasks
such as mathematical reasoning, TTS has not been systematically explored for
machine translation (MT). In this paper, we present the first systematic study
of TTS for MT, investigating a simple but practical best-of-N framework on
WMT24 benchmarks. Our experiments cover six high-resource and one low-resource
language pairs, five model sizes (3B-72B), and various TTS compute budget (N up
to 1024). Our results show that a) For high-resource languages, TTS generally
improves translation quality according to multiple neural MT evaluation
metrics, and our human evaluation confirms these gains; b) Augmenting smaller
models with large $N$ can match or surpass larger models at $N{=}1$ with more
compute cost; c) Under fixed compute budgets, larger models are typically more
efficient, and TTS can degrade quality due to metric blind spots in
low-resource cases.

</details>


### [44] [Charting a Decade of Computational Linguistics in Italy: The CLiC-it Corpus](https://arxiv.org/abs/2509.19033)
*Chiara Alzetta,Serena Auriemma,Alessandro Bondielli,Luca Dini,Chiara Fazzone,Alessio Miaschi,Martina Miliani,Marta Sartor*

Main category: cs.CL

TL;DR: 本文通过分析意大利CLiC-it会议10年来的论文，追踪了意大利计算语言学和自然语言处理领域的研究趋势演变，重点关注从词汇语义资源到语言建模和多模态的转变。


<details>
  <summary>Details</summary>
Motivation: 追踪过去十年意大利计算语言学和自然语言处理领域的研究趋势变化，特别是Transformer大语言模型出现后带来的研究目标和优先级的转变。

Method: 将CLiC-it会议前10届（2014-2024）的论文集编译成CLiC-it语料库，对元数据（作者来源、性别、隶属关系等）和论文内容进行综合分析。

Result: 构建了包含10年会议论文的语料库，分析了意大利CL/NLP社区的研究趋势演变，揭示了从传统资源到语言建模和多模态的转变。

Conclusion: 该研究为意大利和国际研究社区提供了对领域新兴趋势和关键发展的宝贵见解，支持该领域的明智决策和未来方向。

Abstract: Over the past decade, Computational Linguistics (CL) and Natural Language
Processing (NLP) have evolved rapidly, especially with the advent of
Transformer-based Large Language Models (LLMs). This shift has transformed
research goals and priorities, from Lexical and Semantic Resources to Language
Modelling and Multimodality. In this study, we track the research trends of the
Italian CL and NLP community through an analysis of the contributions to
CLiC-it, arguably the leading Italian conference in the field. We compile the
proceedings from the first 10 editions of the CLiC-it conference (from 2014 to
2024) into the CLiC-it Corpus, providing a comprehensive analysis of both its
metadata, including author provenance, gender, affiliations, and more, as well
as the content of the papers themselves, which address various topics. Our goal
is to provide the Italian and international research communities with valuable
insights into emerging trends and key developments over time, supporting
informed decisions and future directions in the field.

</details>


### [45] [Pathways of Thoughts: Multi-Directional Thinking for Long-form Personalized Question Answering](https://arxiv.org/abs/2509.19094)
*Alireza Salemi,Cheng Li,Mingyang Zhang,Qiaozhu Mei,Zhuowan Li,Spurthi Amba Hombaiah,Weize Kong,Tao Chen,Hamed Zamani,Michael Bendersky*

Main category: cs.CL

TL;DR: 提出Pathways of Thoughts (PoT)方法，通过建模LLM的推理为迭代决策过程，动态选择认知操作来生成多样化候选响应，然后根据用户偏好聚合得到个性化QA响应。


<details>
  <summary>Details</summary>
Motivation: 个性化QA系统对提高准确性和用户满意度很重要，但面临从长、嘈杂、隐式上下文中推断偏好以及生成同时正确、上下文适当且符合用户期望的响应的挑战。

Method: PoT是一种推理阶段方法，无需任务特定微调，将LLM推理建模为迭代决策过程，动态选择推理、修订、个性化和澄清等认知操作，探索多个推理轨迹生成多样化候选响应，然后根据推断的用户偏好聚合和重新加权。

Result: 在LaMP-QA个性化QA基准测试中，PoT始终优于竞争基线，相对改进高达13.1%。人工评估显示，66%的情况下标注者偏好PoT输出，只有15%的情况下出现平局。

Conclusion: PoT方法通过探索多样化推理路径并基于用户偏好聚合，有效提升了个性化QA的性能，证明了该方法在无需额外训练的情况下改善LLM个性化能力的有效性。

Abstract: Personalization is essential for adapting question answering (QA) systems to
user-specific information needs, thereby improving both accuracy and user
satisfaction. However, personalized QA remains relatively underexplored due to
challenges such as inferring preferences from long, noisy, and implicit
contexts, and generating responses that are simultaneously correct,
contextually appropriate, and aligned with user expectations and background
knowledge. To address these challenges, we propose Pathways of Thoughts (PoT),
an inference-stage method that applies to any large language model (LLM)
without requiring task-specific fine-tuning. The approach models the reasoning
of an LLM as an iterative decision process, where the model dynamically selects
among cognitive operations such as reasoning, revision, personalization, and
clarification. This enables exploration of multiple reasoning trajectories,
producing diverse candidate responses that capture different perspectives. PoT
then aggregates and reweights these candidates according to inferred user
preferences, yielding a final personalized response that benefits from the
complementary strengths of diverse reasoning paths. Experiments on the LaMP-QA
benchmark for personalized QA show that PoT consistently outperforms
competitive baselines, achieving up to a 13.1% relative improvement. Human
evaluation corroborates these results, with annotators preferring outputs from
PoT in 66% of cases and reporting ties in only 15% of cases.

</details>


### [46] [Are most sentences unique? An empirical examination of Chomskyan claims](https://arxiv.org/abs/2509.19108)
*Hiram Ring*

Main category: cs.CL

TL;DR: 使用NLTK库分析不同语料库中的句子重复率，检验语言学中"大多数语言表达都是独特的"这一主张


<details>
  <summary>Details</summary>
Motivation: 验证语言学中关于大多数语言表达都是独特的这一常见主张，利用大型语料库进行实证研究

Method: 使用NLTK Python库解析不同体裁的语料库，统计每个语料库中的完全字符串匹配数量

Result: 虽然完全独特的句子通常是语料库中的大多数，但这高度依赖于体裁，重复句子在任何个体语料库中都不是微不足道的部分

Conclusion: 语言学中关于句子独特性的主张需要根据体裁进行限定，重复句子在语言使用中具有重要地位

Abstract: A repeated claim in linguistics is that the majority of linguistic utterances
are unique. For example, Pinker (1994: 10), summarizing an argument by Noam
Chomsky, states that "virtually every sentence that a person utters or
understands is a brand-new combination of words, appearing for the first time
in the history of the universe." With the increased availability of large
corpora, this is a claim that can be empirically investigated. The current
paper addresses the question by using the NLTK Python library to parse corpora
of different genres, providing counts of exact string matches in each. Results
show that while completely unique sentences are often the majority of corpora,
this is highly constrained by genre, and that duplicate sentences are not an
insignificant part of any individual corpus.

</details>


### [47] [Human-Annotated NER Dataset for the Kyrgyz Language](https://arxiv.org/abs/2509.19109)
*Timur Turatali,Anton Alekseev,Gulira Jumalieva,Gulnara Kabaeva,Sergey Nikolenko*

Main category: cs.CL

TL;DR: 本文介绍了KyrgyzNER，这是首个吉尔吉斯语的手动标注命名实体识别数据集，包含1,499篇新闻文章、10,900个句子和39,075个实体提及，涵盖27个命名实体类别。


<details>
  <summary>Details</summary>
Motivation: 为资源有限的吉尔吉斯语创建首个高质量的命名实体识别数据集，以支持该语言的NLP研究和发展。

Method: 构建包含27个实体类别的标注方案，评估了基于条件随机场的传统序列标注方法和基于多语言transformer的最先进模型。

Result: 所有模型在罕见实体类别上都表现困难，但多语言RoBERTa变体在精确率和召回率之间取得了有希望的平衡，其他多语言模型也获得了可比的结果。

Conclusion: 研究强调了使用多语言预训练模型处理资源有限语言的挑战和机遇，建议未来工作探索更细粒度的标注方案以获得更深入的见解。

Abstract: We introduce KyrgyzNER, the first manually annotated named entity recognition
dataset for the Kyrgyz language. Comprising 1,499 news articles from the 24.KG
news portal, the dataset contains 10,900 sentences and 39,075 entity mentions
across 27 named entity classes. We show our annotation scheme, discuss the
challenges encountered in the annotation process, and present the descriptive
statistics. We also evaluate several named entity recognition models, including
traditional sequence labeling approaches based on conditional random fields and
state-of-the-art multilingual transformer-based models fine-tuned on our
dataset. While all models show difficulties with rare entity categories, models
such as the multilingual RoBERTa variant pretrained on a large corpus across
many languages achieve a promising balance between precision and recall. These
findings emphasize both the challenges and opportunities of using multilingual
pretrained models for processing languages with limited resources. Although the
multilingual RoBERTa model performed best, other multilingual models yielded
comparable results. This suggests that future work exploring more granular
annotation schemes may offer deeper insights for Kyrgyz language processing
pipelines evaluation.

</details>


### [48] [Context-Aware Hierarchical Taxonomy Generation for Scientific Papers via LLM-Guided Multi-Aspect Clustering](https://arxiv.org/abs/2509.19125)
*Kun Zhu,Lizi Liao,Yuxuan Gu,Lei Huang,Xiaocheng Feng,Bing Qin*

Main category: cs.CL

TL;DR: 提出了一种新颖的上下文感知层次化分类生成框架，通过LLM引导的多方面编码和动态聚类，显著提升了科学文献分类的连贯性和粒度。


<details>
  <summary>Details</summary>
Motivation: 科学文献的快速增长需要高效的组织和综合方法，现有基于无监督聚类或直接提示LLM的分类构建方法缺乏连贯性和粒度。

Method: 利用LLM识别论文关键方面（如方法、数据集、评估），生成特定方面的论文摘要，然后进行编码和聚类形成层次化分类。

Result: 在包含11.6k篇论文的156个专家构建分类的新评估基准上，该方法显著优于现有方法，在分类连贯性、粒度和可解释性方面达到最先进性能。

Conclusion: 该框架为科学文献组织提供了有效的解决方案，通过结合LLM的语义理解和聚类技术，实现了更好的分类质量。

Abstract: The rapid growth of scientific literature demands efficient methods to
organize and synthesize research findings. Existing taxonomy construction
methods, leveraging unsupervised clustering or direct prompting of large
language models (LLMs), often lack coherence and granularity. We propose a
novel context-aware hierarchical taxonomy generation framework that integrates
LLM-guided multi-aspect encoding with dynamic clustering. Our method leverages
LLMs to identify key aspects of each paper (e.g., methodology, dataset,
evaluation) and generates aspect-specific paper summaries, which are then
encoded and clustered along each aspect to form a coherent hierarchy. In
addition, we introduce a new evaluation benchmark of 156 expert-crafted
taxonomies encompassing 11.6k papers, providing the first naturally annotated
dataset for this task. Experimental results demonstrate that our method
significantly outperforms prior approaches, achieving state-of-the-art
performance in taxonomy coherence, granularity, and interpretability.

</details>


### [49] [Anecdoctoring: Automated Red-Teaming Across Language and Place](https://arxiv.org/abs/2509.19143)
*Alejandro Cuevas,Saloni Dash,Bharat Kumar Nayak,Dan Vann,Madeleine I. G. Daepp*

Main category: cs.CL

TL;DR: 提出了一种名为"anecdoctoring"的新型红队测试方法，用于自动生成跨语言和跨文化的对抗性提示，以评估生成式AI在虚假信息传播方面的风险。


<details>
  <summary>Details</summary>
Motivation: 生成式AI的全球采用需要能够适应不同语言和文化的红队评估，但现有的红队数据集通常以美国和英语为中心，存在评估空白。

Method: 从三个语言（英语、西班牙语、印地语）和两个地区（美国和印度）的事实核查网站收集虚假信息声明，将其聚类为更广泛的叙事，并使用知识图谱来增强攻击者LLM。

Result: 该方法相比少样本提示具有更高的攻击成功率，并提供了更好的可解释性。

Conclusion: 研究结果强调了需要基于真实世界对抗性滥用的、能够全球扩展的虚假信息缓解措施。

Abstract: Disinformation is among the top risks of generative artificial intelligence
(AI) misuse. Global adoption of generative AI necessitates red-teaming
evaluations (i.e., systematic adversarial probing) that are robust across
diverse languages and cultures, but red-teaming datasets are commonly US- and
English-centric. To address this gap, we propose "anecdoctoring", a novel
red-teaming approach that automatically generates adversarial prompts across
languages and cultures. We collect misinformation claims from fact-checking
websites in three languages (English, Spanish, and Hindi) and two geographies
(US and India). We then cluster individual claims into broader narratives and
characterize the resulting clusters with knowledge graphs, with which we
augment an attacker LLM. Our method produces higher attack success rates and
offers interpretability benefits relative to few-shot prompting. Results
underscore the need for disinformation mitigations that scale globally and are
grounded in real-world adversarial misuse.

</details>


### [50] [Measuring AI "Slop" in Text](https://arxiv.org/abs/2509.19163)
*Chantal Shaib,Tuhin Chakrabarty,Diego Garcia-Olano,Byron C. Wallace*

Main category: cs.CL

TL;DR: 本文开发了一个AI生成文本'垃圾内容'的分类体系，并通过专家访谈提出了可解释的评估维度，发现二元判断虽然主观但与连贯性、相关性等潜在维度相关。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏对AI生成'垃圾内容'的统一定义和测量方法，需要建立系统的评估框架。

Method: 通过采访NLP、写作和哲学领域的专家，开发'垃圾内容'分类法，并进行跨度级标注分析。

Result: 发现二元'垃圾内容'判断具有一定主观性，但与连贯性、相关性等维度存在相关性。

Conclusion: 该框架可用于AI生成文本的检测和偏好评估，为质量判断提供新的语言学见解。

Abstract: AI "slop" is an increasingly popular term used to describe low-quality
AI-generated text, but there is currently no agreed upon definition of this
term nor a means to measure its occurrence. In this work, we develop a taxonomy
of "slop" through interviews with experts in NLP, writing, and philosophy, and
propose a set of interpretable dimensions for its assessment in text. Through
span-level annotation, we find that binary "slop" judgments are (somewhat)
subjective, but such determinations nonetheless correlate with latent
dimensions such as coherence and relevance. Our framework can be used to
evaluate AI-generated text in both detection and binary preference tasks,
potentially offering new insights into the linguistic and stylistic factors
that contribute to quality judgments.

</details>


### [51] [Soft Tokens, Hard Truths](https://arxiv.org/abs/2509.19170)
*Natasha Butt,Ariel Kwiatkowski,Ismail Labiad,Julia Kempe,Yann Ollivier*

Main category: cs.CL

TL;DR: 本文首次提出通过强化学习训练连续CoT的可扩展方法，无需从离散CoT蒸馏，使用软令牌和输入嵌入噪声实现高效训练。


<details>
  <summary>Details</summary>
Motivation: 连续令牌相比离散令牌在推理过程中具有更强的表达能力，但之前的方法存在训练困难、计算成本高的问题。

Method: 使用软令牌（令牌混合和输入嵌入噪声）结合强化学习训练连续CoT，最小化计算开销，支持数百个令牌的训练。

Result: 在数学推理基准测试中，连续CoT训练在pass@1上匹配离散CoT，在pass@32上超越，显示更强的CoT多样性。最佳方案是训练用连续CoT，推理用离散令牌。

Conclusion: 连续CoT强化学习训练能更好地保留基础模型在域外任务上的预测能力，为基座模型提供更温和的调整。

Abstract: The use of continuous instead of discrete tokens during the Chain-of-Thought
(CoT) phase of reasoning LLMs has garnered attention recently, based on the
intuition that a continuous mixture of discrete tokens could simulate a
superposition of several reasoning paths simultaneously. Theoretical results
have formally proven that continuous tokens have much greater expressivity and
can solve specific problems more efficiently. However, practical use of
continuous tokens has been limited by strong training difficulties: previous
works either just use continuous tokens at inference time on a pre-trained
discrete-token model, or must distill the continuous CoT from ground-truth
discrete CoTs and face computational costs that limit the CoT to very few
tokens.
  This is the first work introducing a scalable method to learn continuous CoTs
via reinforcement learning (RL), without distilling from reference discrete
CoTs. We use "soft" tokens: mixtures of tokens together with noise on the input
embedding to provide RL exploration. Computational overhead is minimal,
enabling us to learn continuous CoTs with hundreds of tokens. On math reasoning
benchmarks with Llama and Qwen models up to 8B, training with continuous CoTs
match discrete-token CoTs for pass@1 and surpass them for pass@32, showing
greater CoT diversity. In systematic comparisons, the best-performing scenario
is to train with continuous CoT tokens then use discrete tokens for inference,
meaning the "soft" models can be deployed in a standard way. Finally, we show
continuous CoT RL training better preserves the predictions of the base model
on out-of-domain tasks, thus providing a softer touch to the base model.

</details>


### [52] [Online Process Reward Leanring for Agentic Reinforcement Learning](https://arxiv.org/abs/2509.19199)
*Xiaoqian Liu,Ke Wang,Yuchuan Wu,Fei Huang,Yongbin Li,Junge Zhang,Jianbin Jiao*

Main category: cs.CL

TL;DR: OPRL是一种用于智能体强化学习的通用信用分配策略，通过交替优化隐式过程奖励模型和智能体策略，将轨迹偏好转化为隐式步骤奖励，解决了稀疏和不可验证奖励环境中的时间信用分配问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型作为自主智能体在交互环境中进行长期推理和行动时，稀疏且有时不可验证的奖励使得时间信用分配极具挑战性。现有方法存在标注偏差、奖励攻击、高方差等问题。

Method: OPRL通过轨迹DPO目标将轨迹偏好转化为隐式步骤奖励，然后结合结果奖励计算步骤级优势，与情节级优势结合进行策略更新，形成自增强循环。理论保证学习到的步骤奖励与轨迹偏好一致，并作为基于势能的塑造奖励。

Result: 在WebShop、VisualSokoban和SOTOPIA等三个不同智能体基准测试中，OPRL表现优于前沿LLM和强RL基线，实现了最先进的结果，具有更高的样本效率和更低的训练方差。

Conclusion: OPRL通过高效探索和更少的动作使用，展示了在现实世界场景中进行智能体学习的潜力，为稀疏奖励环境中的信用分配提供了有效的解决方案。

Abstract: Large language models (LLMs) are increasingly trained with reinforcement
learning (RL) as autonomous agents that reason and act over long horizons in
interactive environments.
  However, sparse and sometimes unverifiable rewards make temporal credit
assignment extremely challenging.
  Recent work attempts to integrate process supervision into agent learning but
suffers from biased annotation, reward hacking, high-variance from overly
fine-grained signals or failtures when state overlap is rare.
  We therefore introduce Online Process Reward Learning (OPRL), a general
credit-assignment strategy for agentic RL that integrates seamlessly with
standard on-policy algorithms without relying on additional rollouts or
explicit step labels.
  In OPRL, we optimize an implicit process reward model (PRM) alternately with
the agent's policy to transform trajectory preferences into implicit step
rewards through a trajectory-based DPO objective.
  These step rewards are then used to compute step-level advantages, which are
combined with episode-level advantages from outcome rewards for policy update,
creating a self-reinforcing loop.
  Theoretical findings guarantee that the learned step rewards are consistent
with trajectory preferences and act as potential-based shaping rewards,
providing bounded gradients to stabilize training.
  Empirically, we evaluate OPRL on three distinct agent benmarks, including
WebShop and VisualSokoban, as well as open-ended social interactions with
unverfiable rewards in SOTOPIA.
  Crucially, OPRL shows superior performance over frontier LLMs and strong RL
baselines across domains, achieving state-of-the-art results with higher
sample-efficiency and lower variance during training.
  Further analysis also demonstrates the efficient exploration by OPRL using
fewer actions, underscoring its potential for agentic learning in real-world
scenarios.

</details>


### [53] [Steering Multimodal Large Language Models Decoding for Context-Aware Safety](https://arxiv.org/abs/2509.19212)
*Zheyuan Liu,Zhangchen Xu,Guangyao Dou,Xiangchi Yuan,Zhaoxuan Tan,Radha Poovendran,Meng Jiang*

Main category: cs.CL

TL;DR: SafeCoDe是一个轻量级、模型无关的解码框架，通过对比解码和全局感知的token调制策略，动态调整多模态大语言模型的安全决策，平衡过度敏感和敏感不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型在安全对齐方面存在平衡问题，要么过度敏感地拒绝良性查询，要么敏感不足而漏检视觉风险。

Method: SafeCoDe采用两阶段方法：1）对比解码机制，通过对比真实图像和高斯噪声图像来突出对视觉上下文敏感的token；2）全局感知token调制策略，将场景级推理与token级调整结合，根据预测的安全判断自适应调整拒绝行为。

Result: 在多种MLLM架构和安全基准测试中，SafeCoDe能持续改进上下文敏感的拒绝行为，同时保持模型的有用性。

Conclusion: SafeCoDe有效解决了多模态大语言模型在安全决策中的平衡问题，提供了一种轻量级且模型无关的解决方案。

Abstract: Multimodal Large Language Models (MLLMs) are increasingly deployed in
real-world applications, yet their ability to make context-aware safety
decisions remains limited. Existing methods often fail to balance
oversensitivity (unjustified refusals of benign queries) and undersensitivity
(missed detection of visually grounded risks), leaving a persistent gap in
safety alignment. To address this issue, we introduce Safety-aware Contrastive
Decoding (SafeCoDe), a lightweight and model-agnostic decoding framework that
dynamically adjusts token generation based on multimodal context. SafeCoDe
operates in two stages: (1) a contrastive decoding mechanism that highlights
tokens sensitive to visual context by contrasting real and Gaussian-noised
images, and (2) a global-aware token modulation strategy that integrates
scene-level reasoning with token-level adjustment to adapt refusals according
to the predicted safety verdict. Extensive experiments across diverse MLLM
architectures and safety benchmarks, covering undersensitivity,
oversensitivity, and general safety evaluations, show that SafeCoDe
consistently improves context-sensitive refusal behaviors while preserving
model helpfulness.

</details>


### [54] [Systematic Comparative Analysis of Large Pretrained Language Models on Contextualized Medication Event Extraction](https://arxiv.org/abs/2509.19224)
*Tariq Abdul-Quddoos,Xishuang Dong,Lijun Qian*

Main category: cs.CL

TL;DR: 该研究比较了多种预训练注意力模型在电子健康记录信息提取任务上的性能，发现临床数据预训练的模型在检测药物和药物事件方面更有效，而通用领域预训练的Bert Base在药物相关事件上下文分类方面表现最佳。


<details>
  <summary>Details</summary>
Motivation: 基于注意力的模型已成为临床笔记自然语言处理的主流方法，但需要比较不同预训练模型在EHR信息提取任务上的性能，以确定最适合临床应用的模型。

Method: 使用Bert Base、BioBert、Bio+Clinical Bert变体、RoBerta和Clinical Longformer等预训练模型，在CMED数据集上进行微调，执行药物提取、医疗事件检测和多维药物事件上下文分类任务。

Result: 临床数据预训练的模型在药物和药物事件检测方面表现更好，而Bert Base在药物事件上下文分类方面表现最优。

Conclusion: 不同预训练模型在不同EHR信息提取任务上各有优势，临床数据预训练对检测任务有益，而通用领域预训练对分类任务更有效。

Abstract: Attention-based models have become the leading approach in modeling medical
language for Natural Language Processing (NLP) in clinical notes. These models
outperform traditional techniques by effectively capturing contextual rep-
resentations of language. In this research a comparative analysis is done
amongst pre- trained attention based models namely Bert Base, BioBert, two
variations of Bio+Clinical Bert, RoBerta, and Clinical Long- former on task
related to Electronic Health Record (EHR) information extraction. The tasks
from Track 1 of Harvard Medical School's 2022 National Clinical NLP Challenges
(n2c2) are considered for this comparison, with the Contextualized Medication
Event Dataset (CMED) given for these task. CMED is a dataset of unstructured
EHRs and annotated notes that contain task relevant information about the EHRs.
The goal of the challenge is to develop effective solutions for extracting
contextual information related to patient medication events from EHRs using
data driven methods. Each pre-trained model is fine-tuned and applied on CMED
to perform medication extraction, medical event detection, and
multi-dimensional medication event context classification. Pro- cessing methods
are also detailed for breaking down EHRs for compatibility with the applied
models. Performance analysis has been carried out using a script based on
constructing medical terms from the evaluation portion of CMED with metrics
including recall, precision, and F1-Score. The results demonstrate that models
pre-trained on clinical data are more effective in detecting medication and
medication events, but Bert Base, pre- trained on general domain data showed to
be the most effective for classifying the context of events related to
medications.

</details>


### [55] [CompLLM: Compression for Long Context Q&A](https://arxiv.org/abs/2509.19228)
*Gabriele Berton,Jayakrishnan Unnikrishnan,Son Tran,Mubarak Shah*

Main category: cs.CL

TL;DR: CompLLM是一种针对长上下文处理的软压缩技术，通过分段独立压缩实现线性复杂度、可扩展性和可重用性，在保持性能的同时显著提升处理效率。


<details>
  <summary>Details</summary>
Motivation: 现有软上下文压缩方法将整个上下文作为单一单元压缩，导致二次压缩复杂度且无法在重叠上下文的查询间重用计算，限制了实际应用。

Method: 将上下文划分为多个段，对每个段独立进行压缩，而不是整体处理。这种设计实现了线性压缩复杂度、从短序列到长序列的良好扩展性，以及压缩段的缓存重用。

Result: 在2倍压缩率下，CompLLM在高上下文长度时将首令牌时间加速最高4倍，KV缓存大小减少50%，且在非常长序列上性能甚至超过未压缩上下文。

Conclusion: CompLLM通过简单的分段压缩设计解决了长上下文处理的关键挑战，展示了高效性和实用性，为大规模语言模型的实际部署提供了可行方案。

Abstract: Large Language Models (LLMs) face significant computational challenges when
processing long contexts due to the quadratic complexity of self-attention.
While soft context compression methods, which map input text to smaller latent
representations, have shown promise, their real-world adoption is limited.
Existing techniques typically compress the context as a single unit, which
leads to quadratic compression complexity and an inability to reuse
computations across queries with overlapping contexts. In this work, we
introduce CompLLM, a soft compression technique designed for practical
deployment. Instead of processing the context holistically, CompLLM divides it
into segments and compresses each one independently. This simple design choice
yields three critical properties: efficiency, as the compression step scales
linearly with the context length; scalability, enabling models trained on short
sequences (e.g., 1k tokens) to generalize to contexts of 100k tokens; and
reusability, allowing compressed segments to be cached and reused across
different queries. Our experiments show that with a 2x compression rate, at
high context lengths CompLLM speeds up Time To First Token (TTFT) by up to 4x
and reduces the KV cache size by 50%. Furthermore, CompLLM achieves performance
comparable to that obtained with the uncompressed context, and even surpasses
it on very long sequences, demonstrating its effectiveness and practical
utility.

</details>


### [56] [Reinforcement Learning on Pre-Training Data](https://arxiv.org/abs/2509.19249)
*Siheng Li,Kejiao Li,Zenan Xu,Guanhua Huang,Evander Yang,Kun Li,Haoyuan Wu,Jiajia Wu,Zihao Zheng,Chenchen Zhang,Kun Shi,Kyrierl Deng,Qi Yi,Ruibin Xiong,Tingqiang Xu,Yuhao Jiang,Jianfeng Yan,Yuyuan Zeng,Guanghui Xu,Jinbao Xue,Zhijiang Xu,Zheng Fang,Shuai Li,Qibin Liu,Xiaoxue Li,Zhuoyu Li,Yangyu Tao,Fei Gao,Cheng Jiang,Bo Chao Wang,Kai Liu,Jianchen Zhu,Wai Lam,Wayyt Wang,Bo Zhou,Di Wang*

Main category: cs.CL

TL;DR: RLPT是一种新的训练时扩展范式，通过强化学习在预训练数据上优化大语言模型，无需人工标注奖励信号，直接在预训练数据上构建奖励机制。


<details>
  <summary>Details</summary>
Motivation: 解决计算资源指数级增长与高质量文本数据有限增长之间的差距，突破传统大语言模型扩展方法的限制。

Method: 采用下一段推理目标，让策略根据前文准确预测后续文本片段来获得奖励，使强化学习能够在预训练数据上扩展。

Result: 在多个模型上的实验显示显著提升，如Qwen3-4B-Base在MMLU、MMLU-Pro等基准上分别提升3.0、5.1、8.1、6.0、6.6和5.3分。

Conclusion: RLPT展示了良好的扩展行为，为大语言模型扩展提供了新范式，增强了推理能力和RLVR性能。

Abstract: The growing disparity between the exponential scaling of computational
resources and the finite growth of high-quality text data now constrains
conventional scaling approaches for large language models (LLMs). To address
this challenge, we introduce Reinforcement Learning on Pre-Training data
(RLPT), a new training-time scaling paradigm for optimizing LLMs. In contrast
to prior approaches that scale training primarily through supervised learning,
RLPT enables the policy to autonomously explore meaningful trajectories to
learn from pre-training data and improve its capability through reinforcement
learning (RL). While existing RL strategies such as reinforcement learning from
human feedback (RLHF) and reinforcement learning with verifiable rewards (RLVR)
rely on human annotation for reward construction, RLPT eliminates this
dependency by deriving reward signals directly from pre-training data.
Specifically, it adopts a next-segment reasoning objective, rewarding the
policy for accurately predicting subsequent text segments conditioned on the
preceding context. This formulation allows RL to be scaled on pre-training
data, encouraging the exploration of richer trajectories across broader
contexts and thereby fostering more generalizable reasoning skills. Extensive
experiments on both general-domain and mathematical reasoning benchmarks across
multiple models validate the effectiveness of RLPT. For example, when applied
to Qwen3-4B-Base, RLPT yields absolute improvements of $3.0$, $5.1$, $8.1$,
$6.0$, $6.6$, and $5.3$ on MMLU, MMLU-Pro, GPQA-Diamond, KOR-Bench, AIME24, and
AIME25, respectively. The results further demonstrate favorable scaling
behavior, suggesting strong potential for continued gains with more compute. In
addition, RLPT provides a solid foundation, extending the reasoning boundaries
of LLMs and enhancing RLVR performance.

</details>


### [57] [Extracting Conceptual Spaces from LLMs Using Prototype Embeddings](https://arxiv.org/abs/2509.19269)
*Nitesh Kumar,Usashi Chatterjee,Steven Schockaert*

Main category: cs.CL

TL;DR: 本文提出了一种从大型语言模型中提取概念空间的方法，通过使用原型描述来编码特征，并对LLM进行微调以对齐原型嵌入与概念空间维度。


<details>
  <summary>Details</summary>
Motivation: 概念空间在认知科学中被广泛使用，并有望成为可解释AI的基石，但目前缺乏从LLM中提取概念空间的实用方法。现有方法主要提取嵌入表示，但概念空间还需要编码底层特征。

Method: 提出一种策略：通过嵌入对应原型的描述来编码特征（如甜度），并对LLM进行微调，使原型嵌入与概念空间维度对齐。

Result: 实证分析表明该方法非常有效。

Conclusion: 该方法成功解决了从LLM中提取概念空间的挑战，为可解释AI提供了实用的概念空间提取方案。

Abstract: Conceptual spaces represent entities and concepts using cognitively
meaningful dimensions, typically referring to perceptual features. Such
representations are widely used in cognitive science and have the potential to
serve as a cornerstone for explainable AI. Unfortunately, they have proven
notoriously difficult to learn, although recent LLMs appear to capture the
required perceptual features to a remarkable extent. Nonetheless, practical
methods for extracting the corresponding conceptual spaces are currently still
lacking. While various methods exist for extracting embeddings from LLMs,
extracting conceptual spaces also requires us to encode the underlying
features. In this paper, we propose a strategy in which features (e.g.
sweetness) are encoded by embedding the description of a corresponding
prototype (e.g. a very sweet food). To improve this strategy, we fine-tune the
LLM to align the prototype embeddings with the corresponding conceptual space
dimensions. Our empirical analysis finds this approach to be highly effective.

</details>


### [58] [SloPalSpeech: A 2,8000-Hour Slovak Speech Corpus from Parliamentary Data](https://arxiv.org/abs/2509.19270)
*Erik Božík,Marek Šuppa*

Main category: cs.CL

TL;DR: 本文介绍了SloPalSpeech，一个包含2,806小时斯洛伐克议会语音的大规模ASR数据集，用于解决低资源语言的语音识别问题。通过微调OpenAI Whisper模型，在斯洛伐克基准测试上显著降低了词错误率。


<details>
  <summary>Details</summary>
Motivation: 斯洛伐克等低资源语言的自动语音识别因训练数据稀缺而受到限制，需要构建大规模高质量数据集来提升模型性能。

Method: 开发了稳健的处理流程，将长格式议会录音对齐和分割成30秒的音频-文本对，并使用该数据集微调多个Whisper模型（small、medium、large-v3和large-v3-turbo）。

Result: 微调后的Whisper-small模型词错误率降低了高达70%，接近更大的Whisper-large-v3模型的基线性能。

Conclusion: SloPalSpeech数据集和微调模型的公开发布将促进低资源语音识别研究的未来发展。

Abstract: Automatic Speech Recognition (ASR) for low-resource languages like Slovak is
hindered by the scarcity of training data. To address this, we introduce
SloPalSpeech, a new, large-scale Slovak ASR dataset containing 2,806 hours of
speech from parliamentary proceedings. We developed a robust processing
pipeline to align and segment long-form recordings into clean, 30-second
audio-transcript pairs suitable for model training. We use this dataset to
fine-tune several OpenAI Whisper models (small, medium, large-v3, and
large-v3-turbo), achieving significant Word Error Rate (WER) reductions on
standard Slovak benchmarks like Common Voice and FLEURS. For instance, the
fine-tuned Whisper-small model's WER dropped by up to 70\%, approaching the
baseline performance of the much larger Whisper-large-v3 model. To foster
future research in low-resource speech recognition, we publicly release the
complete SloPalSpeech dataset, the fully segmented transcripts (60 million
words), and all our fine-tuned models.

</details>


### [59] [WolBanking77: Wolof Banking Speech Intent Classification Dataset](https://arxiv.org/abs/2509.19271)
*Abdou Karim Kandji,Frédéric Precioso,Cheikh Ba,Samba Ndiaye,Augustin Ndione*

Main category: cs.CL

TL;DR: 该论文发布了一个沃洛夫语意图分类数据集WolBanking77，旨在解决低资源语言和文盲率较高地区的意图分类问题，包含9,791条银行领域文本句子和4小时以上的语音数据。


<details>
  <summary>Details</summary>
Motivation: 现有意图分类研究主要关注高资源语言，导致低资源语言和文盲率较高地区（如塞内加尔的沃洛夫语）存在研究空白。沃洛夫语在西非地区有超过1000万使用者，但缺乏相关数据集。

Method: 构建了沃洛夫语意图分类数据集WolBanking77，包含文本和语音数据。在数据集上测试了多种文本和语音的最先进模型作为基线。

Result: 在该数据集上取得了有希望的结果，报告了NLP模型的F1分数和ASR模型的词错误率等基线指标，并进行了模型间比较。

Conclusion: WolBanking77数据集为沃洛夫语意图分类研究提供了重要资源，作者计划持续维护和更新数据集，并发布开源代码。

Abstract: Intent classification models have made a lot of progress in recent years.
However, previous studies primarily focus on high-resource languages datasets,
which results in a gap for low-resource languages and for regions with a high
rate of illiterate people where languages are more spoken than read or written.
This is the case in Senegal, for example, where Wolof is spoken by around 90\%
of the population, with an illiteracy rate of 42\% for the country. Wolof is
actually spoken by more than 10 million people in West African region. To
tackle such limitations, we release a Wolof Intent Classification Dataset
(WolBanking77), for academic research in intent classification. WolBanking77
currently contains 9,791 text sentences in the banking domain and more than 4
hours of spoken sentences. Experiments on various baselines are conducted in
this work, including text and voice state-of-the-art models. The results are
very promising on this current dataset. This paper also provides detailed
analyses of the contents of the data. We report baseline f1-score and word
error rate metrics respectively on NLP and ASR models trained on WolBanking77
dataset and also comparisons between models. We plan to share and conduct
dataset maintenance, updates and to release open-source code.

</details>


### [60] [DRISHTIKON: A Multimodal Multilingual Benchmark for Testing Language Models' Understanding on Indian Culture](https://arxiv.org/abs/2509.19274)
*Arijit Maji,Raghvendra Kumar,Akash Ghosh,Anushka,Nemil Shah,Abhilekh Borah,Vanshika Shah,Nishant Mishra,Sriparna Saha*

Main category: cs.CL

TL;DR: DRISHTIKON是首个专注于印度文化的多模态多语言基准数据集，用于评估生成式AI系统的文化理解能力，涵盖15种语言、所有邦和联邦属地，包含64,000多个对齐的文本-图像对。


<details>
  <summary>Details</summary>
Motivation: 现有基准数据集多为通用或全球范围，缺乏对特定文化（如印度文化）的深度覆盖，需要专门针对印度多样化文化的评估工具来推动包容性AI研究。

Method: 构建包含印度各地区文化主题（节日、服饰、美食、艺术形式、历史遗产等）的多模态数据集，评估各类视觉语言模型在零样本和思维链设置下的表现。

Result: 当前模型在处理文化基础的多模态输入方面存在明显局限，特别是在低资源语言和较少记录的传统方面表现不佳。

Conclusion: DRISHTIKON填补了包容性AI研究的重要空白，为推进具有文化意识和多模态能力的语言技术提供了强大的测试平台。

Abstract: We introduce DRISHTIKON, a first-of-its-kind multimodal and multilingual
benchmark centered exclusively on Indian culture, designed to evaluate the
cultural understanding of generative AI systems. Unlike existing benchmarks
with a generic or global scope, DRISHTIKON offers deep, fine-grained coverage
across India's diverse regions, spanning 15 languages, covering all states and
union territories, and incorporating over 64,000 aligned text-image pairs. The
dataset captures rich cultural themes including festivals, attire, cuisines,
art forms, and historical heritage amongst many more. We evaluate a wide range
of vision-language models (VLMs), including open-source small and large models,
proprietary systems, reasoning-specialized VLMs, and Indic-focused models,
across zero-shot and chain-of-thought settings. Our results expose key
limitations in current models' ability to reason over culturally grounded,
multimodal inputs, particularly for low-resource languages and less-documented
traditions. DRISHTIKON fills a vital gap in inclusive AI research, offering a
robust testbed to advance culturally aware, multimodally competent language
technologies.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [61] [Safe-SAIL: Towards a Fine-grained Safety Landscape of Large Language Models via Sparse Autoencoder Interpretation Framework](https://arxiv.org/abs/2509.18127)
*Jiaqi Weng,Han Zheng,Hanyu Zhang,Qinqin He,Jialing Tao,Hui Xue,Zhixuan Chu,Xiting Wang*

Main category: cs.LG

TL;DR: Safe-SAIL是一个用于解释大语言模型中稀疏自编码器特征的框架，旨在提升对安全相关行为的机制理解。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型安全研究主要关注评估模型输出或特定安全任务，无法有效应对更广泛的未定义风险。稀疏自编码器虽然能解释模型行为，但之前的研究未能将特征与细粒度的安全概念关联起来。

Method: 提出Safe-SAIL框架，系统性地识别具有最佳概念特定可解释性的SAE，解释安全相关神经元，并引入高效策略来扩展解释过程。

Result: 将发布包含SAE检查点和人类可读神经元解释的全面工具包，支持对安全风险的实证分析。

Conclusion: 该框架能够促进大语言模型安全研究，通过提取丰富多样的安全相关特征来有效捕捉高风险行为。

Abstract: Increasing deployment of large language models (LLMs) in real-world
applications raises significant safety concerns. Most existing safety research
focuses on evaluating LLM outputs or specific safety tasks, limiting their
ability to ad- dress broader, undefined risks. Sparse Autoencoders (SAEs)
facilitate interpretability research to clarify model behavior by explaining
single-meaning atomic features decomposed from entangled signals. jHowever,
prior applications on SAEs do not interpret features with fine-grained
safety-related con- cepts, thus inadequately addressing safety-critical
behaviors, such as generating toxic responses and violating safety regu-
lations. For rigorous safety analysis, we must extract a rich and diverse set
of safety-relevant features that effectively capture these high-risk behaviors,
yet face two challenges: identifying SAEs with the greatest potential for
generating safety concept-specific neurons, and the prohibitively high cost of
detailed feature explanation. In this paper, we pro- pose Safe-SAIL, a
framework for interpreting SAE features within LLMs to advance mechanistic
understanding in safety domains. Our approach systematically identifies SAE
with best concept-specific interpretability, explains safety-related neurons,
and introduces efficient strategies to scale up the in- terpretation process.
We will release a comprehensive toolkit including SAE checkpoints and
human-readable neuron ex- planations, which supports empirical analysis of
safety risks to promote research on LLM safety.

</details>


### [62] [PiMoE: Token-Level Routing for Integrating High-Precision Computation and Reasoning](https://arxiv.org/abs/2509.18169)
*Hengbo Xiao,Jingyuan Fan,Xin Tong,Jingzhao Zhang,Chao Lu,Guannan He*

Main category: cs.LG

TL;DR: PiMoE是一种新的训练和推理架构，通过物理隔离的专家混合模型将计算能力内生于神经网络中，实现计算与推理的集成


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型无法将高精度数值计算作为内在可解释能力集成到现有架构中，而主流多智能体方法存在通信开销大、多模态能力效率低和可扩展性有限的问题

Method: 提出PiMoE架构，分别训练专家、文本到计算模块和路由器，在推理时路由器在token级别引导计算和推理，实现单链思维中的迭代交替

Result: 在两个推理-计算任务上的评估显示，PiMoE不仅比直接微调LLM获得更高准确率，而且在响应延迟、token使用和GPU能耗方面相比主流多智能体方法有显著改进

Conclusion: PiMoE为下一代科学或工业智能系统提供了高效、可解释和可扩展的范式

Abstract: Complex systems typically rely on high-precision numerical computation to
support decisions, but current large language models (LLMs) cannot yet
incorporate such computations as an intrinsic and interpretable capability with
existing architectures. Mainstream multi-agent approaches can leverage external
experts, but inevitably introduce communication overhead and suffer from
inefficient multimodal emergent capability and limited scalability. To this
end, we propose PiMoE (Physically-isolated Mixture of Experts), a training and
inference architecture for integrating computation and reasoning. Instead of
the workflow paradigm of tool invocation, PiMoE endogenously integrates
computational capabilities into neural networks after separately training
experts, a text-to-computation module, and a router. At inference, the router
directs computation and reasoning at the token level, thereby enabling
iterative alternation within a single chain of thought. We evaluate PiMoE on
two reasoning-computation tasks against LLM finetuning and the multi-agent
system approaches. Results show that the PiMoE architecture achieves not only
higher accuracy than directly finetuning LLMs but also significant improvements
in response latency, token usage, and GPU energy consumption compared with
mainstream multi-agent approaches. PiMoE offers an efficient, interpretable,
and scalable paradigm for next-generation scientific or industrial intelligent
systems.

</details>


### [63] [TurnBack: A Geospatial Route Cognition Benchmark for Large Language Models through Reverse Route](https://arxiv.org/abs/2509.18173)
*Hongyi Luo,Qing Cheng,Daniel Matos,Hari Krishna Gadi,Yanfeng Zhang,Lu Liu,Yongliang Wang,Niclas Zeller,Daniel Cremers,Liqiu Meng*

Main category: cs.LG

TL;DR: 本文提出了一个大规模基准测试，用于评估大语言模型在地理空间路线认知方面的能力，发现LLMs在路线反转任务中存在显著局限性。


<details>
  <summary>Details</summary>
Motivation: 人类能够通过自然语言理解地理空间信息，但大语言模型的地理空间认知能力尚未得到充分探索。现有研究存在评估指标不可量化、数据集有限和研究层次不清晰等问题。

Method: 创建了包含全球12个大都市36000条路线的大规模评估数据集；开发了PathBuilder工具，用于自然语言指令与导航路线之间的双向转换；提出了新的评估框架和指标对11个SOTA LLMs进行路线反转任务的严格评估。

Result: 基准测试显示LLMs在路线反转任务中存在明显局限：大多数反转路线既未返回起点，也与最优路线不相似。LLMs还面临路线生成鲁棒性低和对错误答案置信度高的问题。

Conclusion: 大语言模型在地理空间路线认知方面仍存在显著挑战，需要进一步改进模型的地理空间理解能力。

Abstract: Humans can interpret geospatial information through natural language, while
the geospatial cognition capabilities of Large Language Models (LLMs) remain
underexplored. Prior research in this domain has been constrained by
non-quantifiable metrics, limited evaluation datasets and unclear research
hierarchies. Therefore, we propose a large-scale benchmark and conduct a
comprehensive evaluation of the geospatial route cognition of LLMs. We create a
large-scale evaluation dataset comprised of 36000 routes from 12 metropolises
worldwide. Then, we introduce PathBuilder, a novel tool for converting natural
language instructions into navigation routes, and vice versa, bridging the gap
between geospatial information and natural language. Finally, we propose a new
evaluation framework and metrics to rigorously assess 11 state-of-the-art
(SOTA) LLMs on the task of route reversal. The benchmark reveals that LLMs
exhibit limitation to reverse routes: most reverse routes neither return to the
starting point nor are similar to the optimal route. Additionally, LLMs face
challenges such as low robustness in route generation and high confidence for
their incorrect answers. Code\ \&\ Data available here:
\href{https://github.com/bghjmn32/EMNLP2025_Turnback}{TurnBack.}

</details>


### [64] [Conversational Orientation Reasoning: Egocentric-to-Allocentric Navigation with Multimodal Chain-of-Thought](https://arxiv.org/abs/2509.18200)
*Yu Ti Huang*

Main category: cs.LG

TL;DR: 本文提出了多模态思维链（MCoT）框架，用于解决对话导航中的自我中心到非自我中心的空间定向问题，在中文对话场景下实现了高精度的方向推理。


<details>
  <summary>Details</summary>
Motivation: 解决室内或复杂设施中GPS信号弱、缺乏详细地图时，对话代理需要将自我中心表达（如"在我右边"）转换为非自我中心方向（N/E/S/W）的挑战。

Method: 提出多模态思维链框架，整合ASR转录语音和地标坐标，通过三步推理过程：提取空间关系、坐标映射到绝对方向、推断用户朝向，并在Taiwan-LLM-13B-v2.0-Chat模型上采用课程学习策略。

Result: MCoT在干净转录本上达到100%方向准确率，在ASR转录本上达到98.1%，显著优于单模态和非结构化基线，且在噪声对话条件下表现出鲁棒性。

Conclusion: 结构化MCoT空间推理为实现可解释和资源高效的具身导航提供了有前景的路径。

Abstract: Conversational agents must translate egocentric utterances (e.g., "on my
right") into allocentric orientations (N/E/S/W). This challenge is particularly
critical in indoor or complex facilities where GPS signals are weak and
detailed maps are unavailable. While chain-of-thought (CoT) prompting has
advanced reasoning in language and vision tasks, its application to multimodal
spatial orientation remains underexplored. We introduce Conversational
Orientation Reasoning (COR), a new benchmark designed for Traditional Chinese
conversational navigation projected from real-world environments, addressing
egocentric-to-allocentric reasoning in non-English and ASR-transcribed
scenarios. We propose a multimodal chain-of-thought (MCoT) framework, which
integrates ASR-transcribed speech with landmark coordinates through a
structured three-step reasoning process: (1) extracting spatial relations, (2)
mapping coordinates to absolute directions, and (3) inferring user orientation.
A curriculum learning strategy progressively builds these capabilities on
Taiwan-LLM-13B-v2.0-Chat, a mid-sized model representative of
resource-constrained settings. Experiments show that MCoT achieves 100%
orientation accuracy on clean transcripts and 98.1% with ASR transcripts,
substantially outperforming unimodal and non-structured baselines. Moreover,
MCoT demonstrates robustness under noisy conversational conditions, including
ASR recognition errors and multilingual code-switching. The model also
maintains high accuracy in cross-domain evaluation and resilience to linguistic
variation, domain shift, and referential ambiguity. These findings highlight
the potential of structured MCoT spatial reasoning as a path toward
interpretable and resource-efficient embodied navigation.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [65] [Pay More Attention To Audio: Mitigating Imbalance of Cross-Modal Attention in Large Audio Language Models](https://arxiv.org/abs/2509.18816)
*Junyu Wang,Ziyang Ma,Zhengding Luo,Tianrui Wang,Meng Ge,Xiaobao Wang,Longbiao Wang*

Main category: cs.SD

TL;DR: MATA是一种无需训练的方法，通过动态调整自注意力机制，让大型音频-语言模型更多地关注音频标记，解决音频-文本注意力不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 大型音频-语言模型在多模态融合层存在音频-文本注意力不平衡问题，过度偏向文本信息而忽视声学线索，导致音频推理任务性能不佳。

Method: MATA在原始注意力评分后介入，仅针对中间层的最后一个标记进行干预，不引入额外参数或计算开销，动态推动模型更多地关注音频标记。

Result: 在MMAU和MMAR基准测试中，MATA实现了持续的性能提升，首次使开源模型在MMAR上超越专有的Gemini 2.0 Flash模型。

Conclusion: MATA为解决注意力偏差提供了高效解决方案，为增强多模态模型的音频处理能力开辟了新的研究方向。

Abstract: Large Audio-Language Models (LALMs) often suffer from audio-textual attention
imbalance, prioritizing text over acoustic information, particularly in the
multi-modal fusion layers of the Transformer architecture. This bias hinders
their ability to fully utilize acoustic cues, causing suboptimal performance on
audio reasoning tasks. To mitigate this, we propose \textbf{MATA}, a novel
training-free method that dynamically pushes LALMs to pay \textbf{M}ore
\textbf{A}ttention \textbf{T}o \textbf{A}udio tokens within the self-attention
mechanism. Specifically, MATA intervenes post raw attention scoring, targeting
only the last token in intermediate layers without introducing additional
parameters or computational overhead. Experiments on the MMAU and MMAR
benchmarks confirm MATA's effectiveness, with consistent performance gains.
Notably, on MMAR, MATA enables an open-source model to surpass the proprietary
Gemini 2.0 Flash for the first time. Our work provides an efficient solution to
mitigate attention bias and opens a new research direction for enhancing the
audio-processing capabilities of multi-modal models.

</details>


### [66] [Finding My Voice: Generative Reconstruction of Disordered Speech for Automated Clinical Evaluation](https://arxiv.org/abs/2509.19231)
*Karen Rosero,Eunjung Yeo,David R. Mortensen,Cortney Van't Slot,Rami R. Hallac,Carlos Busso*

Main category: cs.SD

TL;DR: ChiReSSD是一个语音重建框架，专注于在抑制发音错误的同时保留儿童说话者的身份特征，特别针对有语音障碍的儿童，并能够泛化到成人构音障碍语音。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要基于健康成人语音训练，无法有效处理儿童语音障碍患者的特殊语音特征，特别是音高和韵律方面的问题。

Method: 采用解耦的、基于风格的文本到语音重建方法，适应有语音障碍的儿童语音特征，重点处理音高和韵律。

Result: 在STAR数据集上显著提高了词汇准确性和说话者身份保持度，自动预测与人工专家标注的皮尔逊相关系数达到0.63，在TORGO数据集上也表现出对成人构音障碍语音的有效泛化能力。

Conclusion: 基于风格的解耦TTS重建方法能够为不同临床人群提供身份保持的语音重建，有望减轻人工转录负担。

Abstract: We present ChiReSSD, a speech reconstruction framework that preserves
children speaker's identity while suppressing mispronunciations. Unlike prior
approaches trained on healthy adult speech, ChiReSSD adapts to the voices of
children with speech sound disorders (SSD), with particular emphasis on pitch
and prosody. We evaluate our method on the STAR dataset and report substantial
improvements in lexical accuracy and speaker identity preservation.
Furthermore, we automatically predict the phonetic content in the original and
reconstructed pairs, where the proportion of corrected consonants is comparable
to the percentage of correct consonants (PCC), a clinical speech assessment
metric. Our experiments show Pearson correlation of 0.63 between automatic and
human expert annotations, highlighting the potential to reduce the manual
transcription burden. In addition, experiments on the TORGO dataset demonstrate
effective generalization for reconstructing adult dysarthric speech. Our
results indicate that disentangled, style-based TTS reconstruction can provide
identity-preserving speech across diverse clinical populations.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [67] [Baseer: A Vision-Language Model for Arabic Document-to-Markdown OCR](https://arxiv.org/abs/2509.18174)
*Khalil Hennara,Muhammad Hreden,Mohamed Motasim Hamed,Ahmad Bastati,Zeina Aldallal,Sara Chrouf,Safwan AlModhayan*

Main category: cs.CV

TL;DR: Baseer是一个专门针对阿拉伯语文档OCR的视觉语言模型，通过在大规模合成和真实数据集上进行微调，显著优于现有开源和商业解决方案，WER达到0.25，在阿拉伯语OCR领域创下新纪录。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语文档OCR面临草书字体、多样化字体、变音符号和从右到左书写等挑战，现有多模态大语言模型在阿拉伯语上的性能有限，需要专门针对阿拉伯语进行优化。

Method: 采用解码器专用微调策略，在预训练MLLM基础上进行微调，同时保留通用视觉特征。使用大规模合成和真实文档数据集进行训练，并创建了高质量的专家验证基准Misraj-DocOCR。

Result: Baseer显著优于现有解决方案，WER达到0.25，在阿拉伯语OCR领域建立新的最先进水平。

Conclusion: 特定领域适应通用MLLM具有明显优势，为形态丰富的语言（如阿拉伯语）的高精度OCR建立了强大基准。

Abstract: Arabic document OCR remains a challenging task due to the language's cursive
script, diverse fonts, diacritics, and right-to-left orientation. While modern
Multimodal Large Language Models (MLLMs) have advanced document understanding
for high-resource languages, their performance on Arabic remains limited. In
this work, we introduce Baseer, a vision-language model fine- tuned
specifically for Arabic document OCR. Leveraging a large-scale dataset
combining synthetic and real-world documents, Baseer is trained using a
decoder-only fine-tuning strategy to adapt a pre-trained MLLM while preserving
general visual features. We also present Misraj-DocOCR, a high-quality,
expert-verified benchmark designed for rigorous evaluation of Arabic OCR
systems. Our experiments show that Baseer significantly outperforms existing
open-source and commercial solutions, achieving a WER of 0.25 and establishing
a new state-of-the-art in the domain of Arabic document OCR. Our results
highlight the benefits of domain-specific adaptation of general-purpose MLLMs
and establish a strong baseline for high-accuracy OCR on morphologically rich
languages like Arabic.

</details>


### [68] [OraPO: Oracle-educated Reinforcement Learning for Data-efficient and Factual Radiology Report Generation](https://arxiv.org/abs/2509.18600)
*Zhuoxiao Chen,Hongyang Yu,Ying Xu,Yadan Luo,Long Duong,Yuan-Fang Li*

Main category: cs.CV

TL;DR: 提出OraPO框架和FactS奖励机制，在有限计算资源下实现高效的放射学报告生成，显著减少训练数据需求并达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 解决现有放射学报告生成方法对大规模数据和计算资源的依赖问题，在预算受限条件下实现高效训练

Method: 使用Oracle-educated GRPO (OraPO)框架进行单阶段强化学习训练，结合FactScore奖励机制提取临床事实并与真实标签进行蕴含检查

Result: 在CheXpert Plus数据集上达到0.341 F1分数的新SOTA性能，训练数据减少2-3个数量级，使用小型基础VLM在普通硬件上实现

Conclusion: OraPO和FactS构建了一个紧凑而强大的框架，显著提高了临床挑战性病例的学习效率，为资源受限环境下的放射学报告生成提供了可行方案

Abstract: Radiology report generation (RRG) aims to automatically produce clinically
faithful reports from chest X-ray images. Prevailing work typically follows a
scale-driven paradigm, by multi-stage training over large paired corpora and
oversized backbones, making pipelines highly data- and compute-intensive. In
this paper, we propose Oracle-educated GRPO {OraPO) with a FactScore-based
reward (FactS) to tackle the RRG task under constrained budgets. OraPO enables
single-stage, RL-only training by converting failed GRPO explorations on rare
or difficult studies into direct preference supervision via a lightweight
oracle step. FactS grounds learning in diagnostic evidence by extracting atomic
clinical facts and checking entailment against ground-truth labels, yielding
dense, interpretable sentence-level rewards. Together, OraPO and FactS create a
compact and powerful framework that significantly improves learning efficiency
on clinically challenging cases, setting the new SOTA performance on the
CheXpert Plus dataset (0.341 in F1) with 2--3 orders of magnitude less training
data using a small base VLM on modest hardware.

</details>


### [69] [Failure Makes the Agent Stronger: Enhancing Accuracy through Structured Reflection for Reliable Tool Interactions](https://arxiv.org/abs/2509.18847)
*Junhao Su,Yuanliang Wan,Junwei Yang,Hengyu Shi,Tianyang Han,Junfeng Luo,Yurui Qiu*

Main category: cs.CV

TL;DR: 本文提出结构化反思方法，将错误到修复的路径转化为明确、可控且可训练的动作，通过Reflect-Call-Final策略优化工具调用，显著提升多轮交互的成功率和错误恢复能力。


<details>
  <summary>Details</summary>
Motivation: 当前工具增强的大型语言模型训练方法依赖监督模仿或粗粒度强化学习，自我反思实践通常基于启发式提示或单向推理，在多轮交互中脆弱且容易重复错误。

Method: 提出结构化反思方法，结合DAPO和GSPO目标函数，采用针对工具使用的奖励方案，优化Reflect-Call-Final三步策略。构建Tool-Reflection-Bench基准进行程序化评估。

Result: 在BFCL v3和Tool-Reflection-Bench上的实验显示，多轮工具调用成功率和错误恢复能力大幅提升，冗余调用减少。

Conclusion: 将反思过程显式化并直接优化，能显著提高工具交互的可靠性，为智能体从失败中学习提供了可复现的路径。

Abstract: Tool-augmented large language models (LLMs) are usually trained with
supervised imitation or coarse-grained reinforcement learning that optimizes
single tool calls. Current self-reflection practices rely on heuristic prompts
or one-way reasoning: the model is urged to 'think more' instead of learning
error diagnosis and repair. This is fragile in multi-turn interactions; after a
failure the model often repeats the same mistake. We propose structured
reflection, which turns the path from error to repair into an explicit,
controllable, and trainable action. The agent produces a short yet precise
reflection: it diagnoses the failure using evidence from the previous step and
then proposes a correct, executable follow-up call. For training we combine
DAPO and GSPO objectives with a reward scheme tailored to tool use, optimizing
the stepwise strategy Reflect, then Call, then Final. To evaluate, we introduce
Tool-Reflection-Bench, a lightweight benchmark that programmatically checks
structural validity, executability, parameter correctness, and result
consistency. Tasks are built as mini trajectories of erroneous call,
reflection, and corrected call, with disjoint train and test splits.
Experiments on BFCL v3 and Tool-Reflection-Bench show large gains in multi-turn
tool-call success and error recovery, and a reduction of redundant calls. These
results indicate that making reflection explicit and optimizing it directly
improves the reliability of tool interaction and offers a reproducible path for
agents to learn from failure.

</details>


### [70] [VIR-Bench: Evaluating Geospatial and Temporal Understanding of MLLMs via Travel Video Itinerary Reconstruction](https://arxiv.org/abs/2509.19002)
*Hao Wang,Eiki Murata,Lingfang Zhang,Ayako Sato,So Fukuda,Ziqi Yin,Wentao Hu,Keisuke Nakao,Yusuke Nakamura,Sebastian Zwirner,Yi-Chia Chen,Hiroyuki Otomo,Hiroki Ouchi,Daisuke Kawahara*

Main category: cs.CV

TL;DR: 提出了VIR-Bench基准测试，包含200个旅行视频，用于评估多模态大语言模型在长距离地理时空轨迹理解方面的能力。


<details>
  <summary>Details</summary>
Motivation: 当前视频基准主要关注室内场景或短距离户外活动，缺乏对长距离旅行挑战的探索，而掌握扩展的地理时空轨迹对于下一代MLLMs至关重要。

Method: 构建包含200个旅行视频的VIR-Bench基准，将行程重建作为评估任务，并开发原型旅行规划代理进行案例研究。

Result: 实验表明最先进的MLLMs（包括专有模型）在长时空尺度视频处理上表现不佳，但基于VIR-Bench开发的旅行规划代理显著提升了行程推荐性能。

Conclusion: VIR-Bench不仅能有效评估模型性能，还能转化为用户应用中的具体性能提升，为MLLMs的地理时空智能发展提供重要基准。

Abstract: Recent advances in multimodal large language models (MLLMs) have
significantly enhanced video understanding capabilities, opening new
possibilities for practical applications. Yet current video benchmarks focus
largely on indoor scenes or short-range outdoor activities, leaving the
challenges associated with long-distance travel largely unexplored. Mastering
extended geospatial-temporal trajectories is critical for next-generation
MLLMs, underpinning real-world tasks such as embodied-AI planning and
navigation. To bridge this gap, we present VIR-Bench, a novel benchmark
consisting of 200 travel videos that frames itinerary reconstruction as a
challenging task designed to evaluate and push forward MLLMs'
geospatial-temporal intelligence. Experimental results reveal that
state-of-the-art MLLMs, including proprietary ones, struggle to achieve high
scores, underscoring the difficulty of handling videos that span extended
spatial and temporal scales. Moreover, we conduct an in-depth case study in
which we develop a prototype travel-planning agent that leverages the insights
gained from VIR-Bench. The agent's markedly improved itinerary recommendations
verify that our evaluation protocol not only benchmarks models effectively but
also translates into concrete performance gains in user-facing applications.

</details>


### [71] [ColorBlindnessEval: Can Vision-Language Models Pass Color Blindness Tests?](https://arxiv.org/abs/2509.19070)
*Zijian Ling,Han Zhang,Yazhuo Zhou,Jiahao Cui*

Main category: cs.CV

TL;DR: ColorBlindnessEval是一个新颖的基准测试，用于评估视觉语言模型在受色盲测试启发的视觉对抗场景中的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在复杂视觉环境中的鲁棒性存在不足，特别是在处理对抗性视觉模式时容易产生幻觉问题。

Method: 构建包含500张类似石原色盲测试图像的数据集，包含0-99数字的不同颜色组合，使用是/否和开放式提示评估9个VLMs，并与人类参与者进行对比。

Result: 实验显示模型在对抗性环境中识别数字的能力存在明显局限，普遍存在幻觉问题，表现不如人类参与者。

Conclusion: 该研究强调了改进VLMs在复杂视觉环境中鲁棒性的必要性，ColorBlindnessEval可作为评估和提高VLMs在实际应用中可靠性的重要工具。

Abstract: This paper presents ColorBlindnessEval, a novel benchmark designed to
evaluate the robustness of Vision-Language Models (VLMs) in visually
adversarial scenarios inspired by the Ishihara color blindness test. Our
dataset comprises 500 Ishihara-like images featuring numbers from 0 to 99 with
varying color combinations, challenging VLMs to accurately recognize numerical
information embedded in complex visual patterns. We assess 9 VLMs using Yes/No
and open-ended prompts and compare their performance with human participants.
Our experiments reveal limitations in the models' ability to interpret numbers
in adversarial contexts, highlighting prevalent hallucination issues. These
findings underscore the need to improve the robustness of VLMs in complex
visual environments. ColorBlindnessEval serves as a valuable tool for
benchmarking and improving the reliability of VLMs in real-world applications
where accuracy is critical.

</details>


### [72] [Citrus-V: Advancing Medical Foundation Models with Unified Medical Image Grounding for Clinical Reasoning](https://arxiv.org/abs/2509.19090)
*Guoxin Wang,Jun Zhao,Xinyi Liu,Yanbo Liu,Xuyang Cao,Chao Li,Zhuoyun Liu,Qintian Sun,Fangru Zhou,Haoqiang Xing,Zhenhong Yang*

Main category: cs.CV

TL;DR: Citrus-V是一个多模态医学基础模型，结合图像分析和文本推理，在单一框架中实现病变定位、分割和诊断推理，超越现有医学模型性能


<details>
  <summary>Details</summary>
Motivation: 现有医学影像模型过于专业化且泛化能力有限，而临床应用需要精确的视觉定位、多模态整合和推理能力

Method: 提出新颖的多模态训练方法，整合检测、分割和多模态链式推理，并发布开源数据集

Result: 在多个基准测试中超越现有开源医学模型和专家级影像系统，实现从视觉定位到临床推理的统一流程

Conclusion: Citrus-V支持精确的病变量化、自动化报告生成和可靠的第二意见，为临床诊断提供统一解决方案

Abstract: Medical imaging provides critical evidence for clinical diagnosis, treatment
planning, and surgical decisions, yet most existing imaging models are narrowly
focused and require multiple specialized networks, limiting their
generalization. Although large-scale language and multimodal models exhibit
strong reasoning and multi-task capabilities, real-world clinical applications
demand precise visual grounding, multimodal integration, and chain-of-thought
reasoning. We introduce Citrus-V, a multimodal medical foundation model that
combines image analysis with textual reasoning. The model integrates detection,
segmentation, and multimodal chain-of-thought reasoning, enabling pixel-level
lesion localization, structured report generation, and physician-like
diagnostic inference in a single framework. We propose a novel multimodal
training approach and release a curated open-source data suite covering
reasoning, detection, segmentation, and document understanding tasks.
Evaluations demonstrate that Citrus-V outperforms existing open-source medical
models and expert-level imaging systems across multiple benchmarks, delivering
a unified pipeline from visual grounding to clinical reasoning and supporting
precise lesion quantification, automated reporting, and reliable second
opinions.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [73] [The Illusion of Readiness: Stress Testing Large Frontier Models on Multimodal Medical Benchmarks](https://arxiv.org/abs/2509.18234)
*Yu Gu,Jingjing Fu,Xiaodong Liu,Jeya Maria Jose Valanarasu,Noel Codella,Reuben Tan,Qianchu Liu,Ying Jin,Sheng Zhang,Jinyu Wang,Rui Wang,Lei Song,Guanghui Qin,Naoto Usuyama,Cliff Wong,Cheng Hao,Hohin Lee,Praneeth Sanapathi,Sarah Hilado,Bian Jiang,Javier Alvarez-Valle,Mu Wei,Jianfeng Gao,Eric Horvitz,Matt Lungren,Hoifung Poon,Paul Vozila*

Main category: cs.AI

TL;DR: 论文通过压力测试揭示，大型前沿模型在医学基准测试中的高分可能掩盖了其脆弱性和捷径学习问题，而非真正的医学理解能力。


<details>
  <summary>Details</summary>
Motivation: 当前医学AI基准测试存在缺陷，高分模型在实际应用中可能表现脆弱，需要更严格的评估标准来确保AI在医疗领域的可靠性。

Method: 对六个旗舰模型在六个广泛使用的医学基准上进行评估，包括移除关键输入、改变提示等压力测试，并通过临床医生指导的评分标准进行评估。

Result: 发现领先系统在关键输入被移除时仍能猜对答案，在简单提示变化下会翻转答案，并生成有说服力但有缺陷的推理，表明基准测试奖励的是应试技巧而非真正的医学理解。

Conclusion: 医学基准测试分数不能直接反映实际应用准备度，需要关注模型的鲁棒性、合理推理能力以及与真实医疗需求的对齐，而不仅仅是排行榜胜利。

Abstract: Large frontier models like GPT-5 now achieve top scores on medical
benchmarks. But our stress tests tell a different story. Leading systems often
guess correctly even when key inputs like images are removed, flip answers
under trivial prompt changes, and fabricate convincing yet flawed reasoning.
These aren't glitches; they expose how today's benchmarks reward test-taking
tricks over medical understanding. We evaluate six flagship models across six
widely used benchmarks and find that high leaderboard scores hide brittleness
and shortcut learning. Through clinician-guided rubric evaluation, we show that
benchmarks vary widely in what they truly measure yet are treated
interchangeably, masking failure modes. We caution that medical benchmark
scores do not directly reflect real-world readiness. If we want AI to earn
trust in healthcare, we must demand more than leaderboard wins and must hold
systems accountable for robustness, sound reasoning, and alignment with real
medical demands.

</details>


### [74] [Memory-QA: Answering Recall Questions Based on Multimodal Memories](https://arxiv.org/abs/2509.18436)
*Hongda Jiang,Xinyuan Zhang,Siddhant Garg,Rishab Arora,Shiun-Zu Kuo,Jiayang Xu,Christopher Brossman,Yue Liu,Aaron Colak,Ahmed Aly,Anuj Kumar,Xin Luna Dong*

Main category: cs.AI

TL;DR: Memory-QA是一个新颖的真实世界任务，涉及从先前存储的多模态记忆中回答关于视觉内容的回忆问题。提出的Pensieve管道在QA准确率上比现有最佳解决方案高出14%。


<details>
  <summary>Details</summary>
Motivation: 解决从多模态记忆中回答回忆问题的独特挑战，包括创建任务导向的记忆、有效利用记忆中的时间和位置信息，以及从多个记忆中提取信息来回答问题。

Method: 提出Pensieve综合管道，包括记忆特定增强、时间和位置感知的多信号检索，以及多记忆QA微调。创建了多模态基准来展示任务中的各种真实挑战。

Result: Pensieve在QA准确率上比现有最佳解决方案高出14%，展示了其优越性能。

Conclusion: Memory-QA任务具有重要研究价值，Pensieve管道有效解决了多模态记忆问答的挑战，为未来相关研究提供了基准和解决方案。

Abstract: We introduce Memory-QA, a novel real-world task that involves answering
recall questions about visual content from previously stored multimodal
memories. This task poses unique challenges, including the creation of
task-oriented memories, the effective utilization of temporal and location
information within memories, and the ability to draw upon multiple memories to
answer a recall question. To address these challenges, we propose a
comprehensive pipeline, Pensieve, integrating memory-specific augmentation,
time- and location-aware multi-signal retrieval, and multi-memory QA
fine-tuning. We created a multimodal benchmark to illustrate various real
challenges in this task, and show the superior performance of Pensieve over
state-of-the-art solutions (up to 14% on QA accuracy).

</details>


### [75] [Cross-Cultural Transfer of Commonsense Reasoning in LLMs: Evidence from the Arab World](https://arxiv.org/abs/2509.19265)
*Saeed Almheiri,Rania Hossam,Mena Attia,Chenxi Wang,Preslav Nakov,Timothy Baldwin,Fajri Koto*

Main category: cs.AI

TL;DR: 本文研究了大型语言模型在阿拉伯世界的跨文化常识推理迁移，发现仅需少量文化特定示例即可显著提升模型在其他文化背景下的表现，证明了高效跨文化对齐的可能性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型存在西方中心偏见，限制了其在多元文化环境中的有效性。虽然已有研究探索文化对齐，但跨文化迁移潜力（利用一种文化的对齐来提升其他文化性能）仍未被充分研究。

Method: 使用覆盖13个阿拉伯国家的文化基础常识推理数据集，评估轻量级对齐方法（上下文学习、演示强化DITTO）以及监督微调和直接偏好优化等基线方法。

Result: 仅需12个来自一个国家的文化特定示例即可在多语言模型中平均提升其他国家的性能10%。来自印尼和美国的文化外演示在多项选择推理中能够匹配或超越文化内对齐效果。

Conclusion: 高效的跨文化对齐是可行的，这为将LLMs适配到低资源文化环境提供了一种有前景的方法。

Abstract: Large language models (LLMs) often reflect Western-centric biases, limiting
their effectiveness in diverse cultural contexts. Although some work has
explored cultural alignment, the potential for cross-cultural transfer, using
alignment in one culture to improve performance in others, remains
underexplored. This paper investigates cross-cultural transfer of commonsense
reasoning in the Arab world, where linguistic and historical similarities
coexist with local cultural differences. Using a culturally grounded
commonsense reasoning dataset covering 13 Arab countries, we evaluate
lightweight alignment methods such as in-context learning and
demonstration-based reinforcement (DITTO), alongside baselines like supervised
fine-tuning and direct preference optimization. Our results show that merely 12
culture-specific examples from one country can improve performance in others by
10\% on average, within multilingual models. In addition, we demonstrate that
out-of-culture demonstrations from Indonesia and US contexts can match or
surpass in-culture alignment for MCQ reasoning, highlighting cultural
commonsense transferability beyond the Arab world. These findings demonstrate
that efficient cross-cultural alignment is possible and offer a promising
approach to adapt LLMs to low-resource cultural settings.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [76] [Agentic AutoSurvey: Let LLMs Survey LLMs](https://arxiv.org/abs/2509.18661)
*Yixin Liu,Yonghui Wu,Denghui Zhang,Lichao Sun*

Main category: cs.IR

TL;DR: Agentic AutoSurvey是一个多智能体框架，用于自动生成文献综述，通过四个专业智能体协作，在六个LLM研究主题上显著优于现有基线（8.18/10 vs 4.77/10）。


<details>
  <summary>Details</summary>
Motivation: 科学文献的指数级增长给研究人员综合快速发展的领域知识带来了前所未有的挑战，现有方法存在根本性局限。

Method: 采用四个专业智能体（论文搜索专家、主题挖掘与聚类、学术综述撰写者、质量评估者）协同工作，处理75-443篇论文/主题，通过专业智能体编排实现高引用覆盖率。

Result: 在COLM 2024的六个代表性LLM研究主题上，多智能体方法得分8.18/10，显著优于AutoSurvey的4.77/10，处理了847篇论文，引用覆盖率常≥80%。

Conclusion: 多智能体架构代表了在快速发展的科学领域中自动文献综述生成的有意义进展。

Abstract: The exponential growth of scientific literature poses unprecedented
challenges for researchers attempting to synthesize knowledge across rapidly
evolving fields. We present \textbf{Agentic AutoSurvey}, a multi-agent
framework for automated survey generation that addresses fundamental
limitations in existing approaches. Our system employs four specialized agents
(Paper Search Specialist, Topic Mining \& Clustering, Academic Survey Writer,
and Quality Evaluator) working in concert to generate comprehensive literature
surveys with superior synthesis quality. Through experiments on six
representative LLM research topics from COLM 2024 categories, we demonstrate
that our multi-agent approach achieves significant improvements over existing
baselines, scoring 8.18/10 compared to AutoSurvey's 4.77/10. The multi-agent
architecture processes 75--443 papers per topic (847 total across six topics)
while targeting high citation coverage (often $\geq$80\% on 75--100-paper sets;
lower on very large sets such as RLHF) through specialized agent orchestration.
Our 12-dimension evaluation captures organization, synthesis integration, and
critical analysis beyond basic metrics. These findings demonstrate that
multi-agent architectures represent a meaningful advancement for automated
literature survey generation in rapidly evolving scientific domains.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [77] [No Verifiable Reward for Prosody: Toward Preference-Guided Prosody Learning in TTS](https://arxiv.org/abs/2509.18531)
*Seungyoun Shin,Dongha Ahn,Jiwoo Kim,Sungwook Jeon*

Main category: eess.AS

TL;DR: 本文提出了一种迭代直接偏好优化（DPO）方法，用于解决神经文本转语音（TTS）中韵律自然性问题，通过在韩国呼叫中心数据集上的实验，该方法在人类偏好评估中表现最佳。


<details>
  <summary>Details</summary>
Motivation: 现有GRPO方法虽然能降低转录错误率，但会导致韵律单调不自然，且加入说话人相似性后会进一步恶化性能。需要一种能直接优化韵律自然性的方法。

Method: 使用迭代DPO方案，每轮仅需数百个人类标注的偏好对，直接优化韵律自然性，同时对当前模型进行正则化。

Result: 在KoCC-TTS数据集上，该方法获得了最高的人类偏好评分（ELO），同时保持竞争力的转录错误率，优于GRPO和商业基线。

Conclusion: 当韵律无法自动奖励时，人类偏好优化为自然且鲁棒的TTS提供了一条实用且数据高效的路径。

Abstract: Recent work reports gains in neural text-to-speech (TTS) with Group Relative
Policy Optimization (GRPO). However, in the absence of a verifiable reward for
\textit{prosody}, GRPO trained on transcription-oriented signals (CER/NLL)
lowers error rates yet collapses prosody into monotone, unnatural speech;
adding speaker-similarity further destabilizes training and degrades CER. We
address this with an \textit{iterative Direct Preference Optimization (DPO)}
scheme that uses only a few hundred human-labeled preference pairs per round to
directly optimize prosodic naturalness while regularizing to the current model.
On \textbf{KoCC-TTS}, a curated dataset of authentic Korean call center
interactions capturing task-oriented dialogues, our method attains the highest
human preference (ELO) with competitive CER, outperforming GRPO and strong
commercial baselines. These results suggest that when prosody cannot be
rewarded automatically, \textit{human preference optimization} offers a
practical and data-efficient path to natural and robust TTS. The demo page is
available at \href{https://tts.ch.dev}

</details>


### [78] [HarmoniFuse: A Component-Selective and Prompt-Adaptive Framework for Multi-Task Speech Language Modeling](https://arxiv.org/abs/2509.18570)
*Yuke Si,Runyan Yang,Yingying Gao,Junlan Feng,Chao Deng,Shilei Zhang*

Main category: eess.AS

TL;DR: HarmoniFuse是一个用于多任务语音语言模型的组件选择和提示自适应框架，旨在协调异构任务需求，通过选择并融合任务相关的语音表示组件来提升ASR和SER性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多任务语音语言模型通常采用简单的参数共享或基于提示的调节，没有明确建模每个任务所需信息组成的差异，这可能导致任务干扰和性能下降。ASR主要依赖语言内容，而SER需要整合语言和副语言线索。

Method: HarmoniFuse集成了一个门控语音编码器来提取任务特定的声学特征，以及一个提示自适应动态融合模块来基于任务特性聚合transformer层。此外，采用批量交错训练策略，可以在不需要联合标注的情况下利用单独的ASR和SER数据集。

Result: 实验结果表明，HarmoniFuse提高了ASR和SER的性能，为现实数据约束下的多任务语音理解提供了可扩展且鲁棒的解决方案。

Conclusion: HarmoniFuse通过明确建模任务差异和选择性融合机制，有效解决了多任务语音语言模型中的任务干扰问题，在有限数据条件下实现了更好的性能。

Abstract: Recent advances in large language models have facilitated the development of
unified speech language models (SLMs) capable of supporting multiple speech
tasks within a shared architecture. However, tasks such as automatic speech
recognition (ASR) and speech emotion recognition (SER) rely on distinct types
of information: ASR primarily depends on linguistic content, whereas SER
requires the integration of both linguistic and paralinguistic cues. Existing
multitask SLMs typically adopt naive parameter sharing or prompt-based
conditioning without explicitly modeling the differences in information
composition required by each task. Such designs risk task interference and
performance degradation, especially under limited data conditions. To address
these limitations, we propose HarmoniFuse, a component-selective and
prompt-adaptive framework for multi-task speech language modeling. HarmoniFuse
is designed to harmonize heterogeneous task demands by selecting and fusing
task-relevant components of speech representations. Specifically, it integrates
a gated speech encoder to extract task-specific acoustic features and a
prompt-adaptive dynamic fusion module to aggregate transformer layers based on
task characteristics. In addition, a batch-interleaved training strategy
enables leveraging separate ASR and SER datasets without requiring joint
annotation. Experimental results demonstrate that HarmoniFuse improves both ASR
and SER performance, offering a scalable and robust solution for multitask
speech understanding under realistic data constraints.

</details>


### [79] [Teaching Audio Models to Reason: A Unified Framework for Source- and Layer-wise Distillation](https://arxiv.org/abs/2509.18579)
*Runyan Yang,Yuke Si,Yingying Gao,Junlan Feng,Chao Deng,Shilei Zhang*

Main category: eess.AS

TL;DR: 提出统一知识蒸馏框架，将文本教师模型的推理能力迁移到音频学生模型，同时保持音频处理能力


<details>
  <summary>Details</summary>
Motivation: 解决音频语言模型在复杂推理任务上的困难，主要由于音频与文本之间的模态差异以及缺乏结构化中间监督

Method: 双维度蒸馏框架：源维度蒸馏（利用文本和音频教师提供互补监督）和层维度蒸馏（将教师信号与适当学生层对齐）

Result: 实验结果显示音频推理性能显著提升

Conclusion: 该框架作为音频建模的推理迁移解决方案具有有效性

Abstract: While large audio language models excel at tasks like ASR and emotion
recognition, they still struggle with complex reasoning due to the modality gap
between audio and text as well as the lack of structured intermediate
supervision. To address this, we propose a unified knowledge distillation
framework to transfer reasoning capabilities from a high-capacity textual
teacher model to a student audio models while preserving its acoustic
competence. Our method introduces two key dimensions: source-wise distillation,
which leverages both textual and acoustic teachers to provide complementary
modality-specific supervision; and layer-wise distillation, which aligns
teacher signals with appropriate student layers to improve transfer efficiency.
This dual-dimensional strategy enables fine-grained control over the
distillation process, effectively bridging the gap between symbolic reasoning
and speech representations. Experimental results show significant improvements
in audio reasoning performance, demonstrating the effectiveness of our
framework as a reasoning transfer solution for audio modeling.

</details>
