<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 37]
- [cs.SD](#cs.SD) [Total: 2]
- [cs.CV](#cs.CV) [Total: 4]
- [cs.IR](#cs.IR) [Total: 2]
- [cs.AI](#cs.AI) [Total: 2]
- [cs.CY](#cs.CY) [Total: 1]
- [cs.RO](#cs.RO) [Total: 2]
- [cs.LG](#cs.LG) [Total: 5]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Noise or Nuance: An Investigation Into Useful Information and Filtering For LLM Driven AKBC](https://arxiv.org/abs/2509.08903)
*Alex Clay,Ernesto Jiménez-Ruiz,Pranava Madhyastha*

Main category: cs.CL

TL;DR: 在受限环境下研究知识图谱三元组补全的三个关键方面：生成、质量保证和LLM响应解析，发现在这种约束条件下额外信息能提升生成质量，LLMs能有效过滤低质量三元组，解析方法的灵活性与一致性需要权衡


<details>
  <summary>Details</summary>
Motivation: 在类似2025 LM-KBC挑战的受限环境中，RAG和微调等常用技术受到限制，需要探索在这种约束条件下如何有效完成三元组补全任务

Method: 研究了三元组补全任务的三个关键方面：生成方法、质量保证机制和LLM响应解析技术，在受限设置下进行实验分析

Result: 发现额外信息能提高生成质量，LLMs能有效过滤低质量三元组，LLM响应解析在灵活性和一致性之间存在设置依赖的权衡

Conclusion: 在受限环境下，通过合理的信息增强、质量过滤和解析策略选择，可以在不使用RAG和微调的情况下有效提升三元组补全的质量和可靠性

Abstract: RAG and fine-tuning are prevalent strategies for improving the quality of LLM
outputs. However, in constrained situations, such as that of the 2025 LM-KBC
challenge, such techniques are restricted. In this work we investigate three
facets of the triple completion task: generation, quality assurance, and LLM
response parsing. Our work finds that in this constrained setting: additional
information improves generation quality, LLMs can be effective at filtering
poor quality triples, and the tradeoff between flexibility and consistency with
LLM response parsing is setting dependent.

</details>


### [2] [Automated Evidence Extraction and Scoring for Corporate Climate Policy Engagement: A Multilingual RAG Approach](https://arxiv.org/abs/2509.08907)
*Imene Kolli,Ario Saeid Vaghefi,Chiara Colesanti Senni,Shantam Raj,Markus Leippold*

Main category: cs.CL

TL;DR: 提出AI辅助框架，利用检索增强生成技术自动化从大规模文本数据中提取企业气候政策参与证据，加速企业气候政策参与监测


<details>
  <summary>Details</summary>
Motivation: InfluenceMap的LobbyMap平台监测企业气候政策参与，但大部分评估仍为手动，耗时耗力且易出错，需要自动化解决方案

Method: 采用检索增强生成技术，结合布局感知解析、Nomic嵌入模型和少样本提示策略，从多语言企业文档中提取和分类证据

Result: 评估显示该方法在从多语言企业文档中提取和分类证据方面表现最佳，有效加速证据提取过程

Conclusion: 自动化RAG系统能有效加速证据提取，但由于分析的复杂性，需要人机协作方法，技术应增强而非替代专家判断以确保准确性

Abstract: InfluenceMap's LobbyMap Platform monitors the climate policy engagement of
over 500 companies and 250 industry associations, assessing each entity's
support or opposition to science-based policy pathways for achieving the Paris
Agreement's goal of limiting global warming to 1.5{\deg}C. Although
InfluenceMap has made progress with automating key elements of the analytical
workflow, a significant portion of the assessment remains manual, making it
time- and labor-intensive and susceptible to human error. We propose an
AI-assisted framework to accelerate the monitoring of corporate climate policy
engagement by leveraging Retrieval-Augmented Generation to automate the most
time-intensive extraction of relevant evidence from large-scale textual data.
Our evaluation shows that a combination of layout-aware parsing, the Nomic
embedding model, and few-shot prompting strategies yields the best performance
in extracting and classifying evidence from multilingual corporate documents.
We conclude that while the automated RAG system effectively accelerates
evidence extraction, the nuanced nature of the analysis necessitates a
human-in-the-loop approach where the technology augments, rather than replaces,
expert judgment to ensure accuracy.

</details>


### [3] [Documents Are People and Words Are Items: A Psychometric Approach to Textual Data with Contextual Embeddings](https://arxiv.org/abs/2509.08920)
*Jinsong Chen*

Main category: cs.CL

TL;DR: 提出了一种基于大语言模型的心理测量方法，通过上下文嵌入将文本数据转换为适合心理测量分析的数据，将文档视为个体、词语视为项目，用于发现文本中的潜在知识维度。


<details>
  <summary>Details</summary>
Motivation: 传统心理测量方法难以直接应用于文本数据，需要开发新的方法来分析文本中隐含的心理测量特征和潜在维度。

Method: 两阶段方法：第一阶段使用NLP技术和编码器变压器模型识别关键词并生成上下文分数；第二阶段使用探索性和双因子模型等因子分析技术提取潜在因子。

Result: 在Wiki STEM语料库上的实验表明，该方法能够有效发现文本数据中的潜在知识维度和模式。

Conclusion: 该方法不仅提升了文本数据的心理测量分析能力，在教育、心理学和法律等文本信息丰富的领域具有广泛应用前景。

Abstract: This research introduces a novel psychometric method for analyzing textual
data using large language models. By leveraging contextual embeddings to create
contextual scores, we transform textual data into response data suitable for
psychometric analysis. Treating documents as individuals and words as items,
this approach provides a natural psychometric interpretation under the
assumption that certain keywords, whose contextual meanings vary significantly
across documents, can effectively differentiate documents within a corpus. The
modeling process comprises two stages: obtaining contextual scores and
performing psychometric analysis. In the first stage, we utilize natural
language processing techniques and encoder based transformer models to identify
common keywords and generate contextual scores. In the second stage, we employ
various types of factor analysis, including exploratory and bifactor models, to
extract and define latent factors, determine factor correlations, and identify
the most significant words associated with each factor. Applied to the Wiki
STEM corpus, our experimental results demonstrate the method's potential to
uncover latent knowledge dimensions and patterns within textual data. This
approach not only enhances the psychometric analysis of textual data but also
holds promise for applications in fields rich in textual information, such as
education, psychology, and law.

</details>


### [4] [BRoverbs -- Measuring how much LLMs understand Portuguese proverbs](https://arxiv.org/abs/2509.08960)
*Thales Sales Almeida,Giovana Kerche Bonás,João Guilherme Alves Santos*

Main category: cs.CL

TL;DR: BRoverbs是一个专门针对巴西葡萄牙语的评估数据集，通过巴西谚语来测试大语言模型在文化语境和语言细微差别方面的理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有葡萄牙语评估存在局限性，主要依赖翻译数据集或结构化考试数据，无法充分捕捉语言文化细微差别，需要针对特定区域环境的成熟评估框架。

Method: 创建BRoverbs数据集，使用巴西谚语作为评估工具，这些谚语包含文化智慧、比喻表达和复杂句法结构，能够有效测试模型对地区表达的理解。

Result: 开发了一个专门针对巴西葡萄牙语的新评估基准，可用于评估葡萄牙语大语言模型的性能表现。

Conclusion: BRoverbs为葡萄牙语大语言模型提供了新的区域化评估工具，有助于推进基于地区文化背景的基准测试发展。

Abstract: Large Language Models (LLMs) exhibit significant performance variations
depending on the linguistic and cultural context in which they are applied.
This disparity signals the necessity of mature evaluation frameworks that can
assess their capabilities in specific regional settings. In the case of
Portuguese, existing evaluations remain limited, often relying on translated
datasets that may not fully capture linguistic nuances or cultural references.
Meanwhile, native Portuguese-language datasets predominantly focus on
structured national exams or sentiment analysis of social media interactions,
leaving gaps in evaluating broader linguistic understanding. To address this
limitation, we introduce BRoverbs, a dataset specifically designed to assess
LLM performance through Brazilian proverbs. Proverbs serve as a rich linguistic
resource, encapsulating cultural wisdom, figurative expressions, and complex
syntactic structures that challenge the model comprehension of regional
expressions. BRoverbs aims to provide a new evaluation tool for
Portuguese-language LLMs, contributing to advancing regionally informed
benchmarking. The benchmark is available at
https://huggingface.co/datasets/Tropic-AI/BRoverbs.

</details>


### [5] [Can Vision-Language Models Solve Visual Math Equations?](https://arxiv.org/abs/2509.09013)
*Monjoy Narayan Choudhury,Junling Wang,Yifan Hou,Mrinmaya Sachan*

Main category: cs.CL

TL;DR: 视觉-语言模型在需要感知与符号计算结合的视觉方程求解任务中表现差强，计数和多步推理是主要瓶颈


<details>
  <summary>Details</summary>
Motivation: 研究VLM模型在视觉化数学推理任务中的局限性，特别是需要感知与符号计算相结合的情况

Method: 通过视觉方程求解任务进行实验，将任务解构为系数计数和变量识别两个子步骤，分析每个步骤的性能瓶颈

Result: 发现计数是主要的性能瓶颈，组合识别和推理会引入额外错误，且随着方程复杂度增加，符号推理本身也成为限制因素

Conclusion: 当前VLM模型在视觉化数学推理方面存在显著缺陷，需要在计数能力、多步推理和符号计算方面进行改进

Abstract: Despite strong performance in visual understanding and language-based
reasoning, Vision-Language Models (VLMs) struggle with tasks requiring
integrated perception and symbolic computation. We study this limitation
through visual equation solving, where mathematical equations are embedded in
images, variables are represented by object icons, and coefficients must be
inferred by counting. While VLMs perform well on textual equations, they fail
on visually grounded counterparts. To understand this gap, we decompose the
task into coefficient counting and variable recognition, and find that counting
is the primary bottleneck, even when recognition is accurate. We also observe
that composing recognition and reasoning introduces additional errors,
highlighting challenges in multi-step visual reasoning. Finally, as equation
complexity increases, symbolic reasoning itself becomes a limiting factor.
These findings reveal key weaknesses in current VLMs and point toward future
improvements in visually grounded mathematical reasoning.

</details>


### [6] [Stated Preference for Interaction and Continued Engagement (SPICE): Evaluating an LLM's Willingness to Re-engage in Conversation](https://arxiv.org/abs/2509.09043)
*Thomas Manuel Rost,Martina Figlia,Bernd Wallraff*

Main category: cs.CL

TL;DR: 这篇论文提出了SPICE指标，通过询问大语言模型是否愿意继续与用户交互来评估模型的交互偏好，证明该指标能够显著区分不同用户语气的交互，为模型审计提供了一种简单有效的工具。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏直接评估大语言模型交互偏好的简单方法，需要一种能够衡量模型是否愿意继续与用户交互的诊断信号。

Method: 设计了一个简单的YES/NO问题，询问LLM在阅读短会话记录后是否愿意继续交互。在3种语气（友好、模糊、欺诈）和4种框架条件下测试了4个开源聊天模型，共进行480次试验。

Result: SPICE能够显著区分不同用户语气：友好交互97.5%愿意继续，欺诈交互只有17.9%愿意继续，模糊交互为60.4%。在模型未识别欺诈的情况下，仍有81%的情况下不愿意继续交互。

Conclusion: SPICE是一种健壮、低开销、可复现的工具，能够为模型审计提供直接的关系性信号，补充现有的评估指标。

Abstract: We introduce and evaluate Stated Preference for Interaction and Continued
Engagement (SPICE), a simple diagnostic signal elicited by asking a Large
Language Model a YES or NO question about its willingness to re-engage with a
user's behavior after reviewing a short transcript. In a study using a 3-tone
(friendly, unclear, abusive) by 10-interaction stimulus set, we tested four
open-weight chat models across four framing conditions, resulting in 480
trials. Our findings show that SPICE sharply discriminates by user tone.
Friendly interactions yielded a near-unanimous preference to continue (97.5%
YES), while abusive interactions yielded a strong preference to discontinue
(17.9% YES), with unclear interactions falling in between (60.4% YES). This
core association remains decisive under multiple dependence-aware statistical
tests, including Rao-Scott adjustment and cluster permutation tests.
Furthermore, we demonstrate that SPICE provides a distinct signal from abuse
classification. In trials where a model failed to identify abuse, it still
overwhelmingly stated a preference not to continue the interaction (81% of the
time). An exploratory analysis also reveals a significant interaction effect: a
preamble describing the study context significantly impacts SPICE under
ambiguity, but only when transcripts are presented as a single block of text
rather than a multi-turn chat. The results validate SPICE as a robust,
low-overhead, and reproducible tool for auditing model dispositions,
complementing existing metrics by offering a direct, relational signal of a
model's state. All stimuli, code, and analysis scripts are released to support
replication.

</details>


### [7] [Improving LLM Safety and Helpfulness using SFT and DPO: A Study on OPT-350M](https://arxiv.org/abs/2509.09055)
*Piyush Pant*

Main category: cs.CL

TL;DR: 本研究比较了SFT、DPO和SFT+DPO三种对齐技术在OPT-350M模型上的效果，发现组合方法在所有评估指标上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 研究不同对齐技术对语言模型安全性和有用性的影响，为构建更鲁棒的对齐流程提供基础。

Method: 使用Anthropic Helpful-Harmless RLHF数据集，训练了四个模型：基础OPT350M、SFT模型、DPO模型和SFT+DPO组合模型，并引入了三个评估指标：无害率(HmR)、有用率(HpR)和综合对齐分数(CAS)。

Result: SFT优于DPO，但SFT+DPO组合模型在所有指标上表现最佳，证明了这些技术的互补性。研究还发现了噪声数据、GPU资源限制和训练约束带来的挑战。

Conclusion: 组合SFT和DPO技术能够产生最佳的对齐效果，为未来更鲁棒的对齐流程开发提供了重要见解和基础。

Abstract: This research investigates the effectiveness of alignment techniques,
Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and a
combined SFT+DPO approach on improving the safety and helpfulness of the
OPT-350M language model. Utilizing the Anthropic Helpful-Harmless RLHF dataset,
we train and evaluate four models: the base OPT350M, an SFT model, a DPO model,
and a model trained with both SFT and DPO. We introduce three key evaluation
metrics: Harmlessness Rate (HmR), Helpfulness Rate (HpR), and a Combined
Alignment Score (CAS), all derived from reward model outputs. The results show
that while SFT outperforms DPO, The combined SFT+DPO model outperforms all
others across all metrics, demonstrating the complementary nature of these
techniques. Our findings also highlight challenges posed by noisy data, limited
GPU resources, and training constraints. This study offers a comprehensive view
of how fine-tuning strategies affect model alignment and provides a foundation
for more robust alignment pipelines in future work.

</details>


### [8] [MR-UIE: Multi-Perspective Reasoning with Reinforcement Learning for Universal Information Extraction](https://arxiv.org/abs/2509.09082)
*Zhongqiu Li,Shiquan Wang,Ruiyu Fang,Mengjiao Bao,Zhenhe Wu,Shuangyong Song,Yongxiang Li,Zhongjiang He*

Main category: cs.CL

TL;DR: 提出MR-UIE方法，通过强化学习结合多视角推理来提升大语言模型在通用信息抽取任务中的性能，特别是在复杂模式描述和多步推理场景下。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在通用信息抽取任务中表现不足，特别是在处理结构化输出、复杂模式描述和多步推理时存在显著局限性。需要从被动抽取器转变为主动推理器。

Method: 结合强化学习和多视角推理，让模型不仅知道抽取什么，还知道如何推理。通过多视角推理增强模型在复杂信息抽取任务中的泛化能力。

Result: 在多个信息抽取基准测试中，MR-UIE方法持续提升了跨领域的抽取准确性，并在多个数据集上超越了最先进方法。多视角推理显著增强了复杂任务中的泛化能力。

Conclusion: 多视角推理在强化学习框架中的集成对于提升大语言模型在复杂信息抽取任务中的性能至关重要，证明了推理在挑战性场景中的关键作用。

Abstract: Large language models (LLMs) demonstrate robust capabilities across diverse
research domains. However, their performance in universal information
extraction (UIE) remains insufficient, especially when tackling structured
output scenarios that involve complex schema descriptions and require
multi-step reasoning. While existing approaches enhance the performance of LLMs
through in-context learning and instruction tuning, significant limitations
nonetheless persist. To enhance the model's generalization ability, we propose
integrating reinforcement learning (RL) with multi-perspective reasoning for
information extraction (IE) tasks. Our work transitions LLMs from passive
extractors to active reasoners, enabling them to understand not only what to
extract but also how to reason. Experiments conducted on multiple IE benchmarks
demonstrate that MR-UIE consistently elevates extraction accuracy across
domains and surpasses state-of-the-art methods on several datasets.
Furthermore, incorporating multi-perspective reasoning into RL notably enhances
generalization in complex IE tasks, underscoring the critical role of reasoning
in challenging scenarios.

</details>


### [9] [TigerCoder: A Novel Suite of LLMs for Code Generation in Bangla](https://arxiv.org/abs/2509.09101)
*Nishat Raihan,Antonios Anastasopoulos,Marcos Zampieri*

Main category: cs.CL

TL;DR: 首个专门为孜加拉语设计的代码生成大语言模型家族，包含1B和9B版本，通过高质量数据集和定制评测标准实现了11-18%性能提升


<details>
  <summary>Details</summary>
Motivation: 孜加拉语作为世界第五大语言在大语言模型中表现不足，特别是在代码生成领域，主要因难是缺乏高质量的训练数据

Method: 构建了完整的孜加拉语代码指令数据集，创建MBPP-Bangla评测标准，开发TigerCoder模型家族（包含1B和9B两个规模）

Result: 在Pass@1指标上比现有多语言和通用孜加拉语LLM提升了11-18%的性能，证明精心编辑的高质量数据可以克服小模型在低资源语言中的限制

Conclusion: 通过专门的数据集和模型设计，可以有效提升孜加拉语代码生成能力，所有资源已开源以促进更进一步研究

Abstract: Despite being the 5th most spoken language, Bangla remains underrepresented
in Large Language Models (LLMs), particularly for code generation. This
primarily stems from the scarcity of high-quality data to pre-train and/or
finetune such models. Hence, we introduce the first dedicated family of Code
LLMs for Bangla (1B & 9B). We offer three major contributions: (1) a
comprehensive Bangla code instruction datasets for programming domain
adaptation; (2) MBPP-Bangla, an evaluation benchmark for Bangla code
generation; and (3) the TigerCoder-family of Code LLMs, achieving significant
~11-18% performance gains at Pass@1 over existing multilingual and
general-purpose Bangla LLMs. Our findings show that curated, high-quality
datasets can overcome limitations of smaller models for low-resource languages.
We open-source all resources to advance further Bangla LLM research.

</details>


### [10] [Compass-v3: Scaling Domain-Specific LLMs for Multilingual E-Commerce in Southeast Asia](https://arxiv.org/abs/2509.09121)
*Sophia Maria*

Main category: cs.CL

TL;DR: Compass-v3是一个245B参数的混合专家模型，专为东南亚电商设计，通过硬件优化和OTPO对齐方法，在电商任务和多语言处理上达到SOTA性能，已在Shopee平台广泛应用。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在通用领域表现优异，但在需要领域专业知识的专门任务（如电商）中性能下降。电商数据具有噪声大、异构、多语言和高度动态的特点，需要专门的解决方案。

Method: 采用混合专家架构（245B总参数，71B激活参数），使用更少但更大的专家，结合硬件优化（节点内专家并行和定制memcpy操作符）。训练使用12T tokens的多语言语料库和大规模合成电商指令，采用混合训练策略。提出OTPO（最优传输直接偏好优化）方法来增强对齐。

Result: 在电商性能上超越DeepSeek-V3.1、GPT-4系列和Qwen3-235B，在东南亚低资源语言（印尼语、泰语、菲律宾语、越南语、马来语、他加禄语）和葡萄牙语上表现出强大的多语言能力，同时在通用基准测试中保持竞争力。已在Shopee平台广泛应用，占LLM使用总量的70%以上。

Conclusion: Compass-v3展示了在专业电商知识和广泛语言能力方面的双重优势，成功解决了电商领域的特殊挑战，为垂直领域LLM应用提供了有效解决方案。

Abstract: Large language models (LLMs) excel in general-domain applications, yet their
performance often degrades in specialized tasks requiring domain-specific
knowledge. E-commerce is particularly challenging, as its data are noisy,
heterogeneous, multilingual, and highly dynamic. We present Compass-v3, a
vertical-domain Mixture-of-Experts (MoE) model with 245B total parameters and
71B active per token, designed for Southeast Asian e-commerce. Compass-v3
adopts fewer but larger experts, combined with hardware-efficient
optimizations-such as intra-node expert parallelism and a customized memcpy
operator-to maximize GPU utilization. The model is trained on 12T tokens of
curated multilingual corpora and large-scale synthetic e-commerce instructions
using a mixed-training strategy. To enhance alignment, we propose
Optimal-Transport Direct Preference Optimization (OTPO), which captures
token-level distinctions and improves instruction adherence in
commerce-specific scenarios. Extensive evaluations demonstrate that Compass-v3
delivers state-of-the-art e-commerce performance, surpassing DeepSeek-V3.1,
GPT-4 series, and Qwen3-235B. Moreover, Compass-v3 demonstrates strong
multilingual capability across low-resource Southeast Asian languages
(Indonesian, Thai, Filipino, Vietnamese, Malay, Taglog) and Portuguese while
sustaining competitive performance on general benchmarks. It has already been
widely applied in Shopee's industrial-scale e-commerce platform and is
gradually replacing OpenAI's traffic, now accounting for over 70\% of total LLM
usage, highlighting its dual strengths in specialized commerce expertise and
broad linguistic competence.

</details>


### [11] [Automated Classification of Tutors' Dialogue Acts Using Generative AI: A Case Study Using the CIMA Corpus](https://arxiv.org/abs/2509.09125)
*Liqun He,Jiaqi Xu*

Main category: cs.CL

TL;DR: 使用GPT-4进行教育对话行为分类，准确率达80%，F1分数0.81，科恩卡帕0.74，优于基线表现，显示生成式AI在教育对话分析中的潜力。


<details>
  <summary>Details</summary>
Motivation: 探索使用生成式AI自动分类导师对话行为，以减少传统手动编码所需的时间和精力。

Method: 使用开源CIMA语料库，测试GPT-3.5-turbo和GPT-4模型，采用定制提示进行对话行为分类。

Result: GPT-4达到80%准确率、加权F1分数0.81和科恩卡帕0.74，显著优于基线，与人工标注具有实质性一致。

Conclusion: 生成式AI为对话行为分类提供了高效且可访问的方法，强调任务特定标签定义和上下文信息的重要性，同时需要注意伦理考虑和负责任的研究实践。

Abstract: This study explores the use of generative AI for automating the
classification of tutors' Dialogue Acts (DAs), aiming to reduce the time and
effort required by traditional manual coding. This case study uses the
open-source CIMA corpus, in which tutors' responses are pre-annotated into four
DA categories. Both GPT-3.5-turbo and GPT-4 models were tested using tailored
prompts. Results show that GPT-4 achieved 80% accuracy, a weighted F1-score of
0.81, and a Cohen's Kappa of 0.74, surpassing baseline performance and
indicating substantial agreement with human annotations. These findings suggest
that generative AI has strong potential to provide an efficient and accessible
approach to DA classification, with meaningful implications for educational
dialogue analysis. The study also highlights the importance of task-specific
label definitions and contextual information in enhancing the quality of
automated annotation. Finally, it underscores the ethical considerations
associated with the use of generative AI and the need for responsible and
transparent research practices. The script of this research is publicly
available at
https://github.com/liqunhe27/Generative-AI-for-educational-dialogue-act-tagging.

</details>


### [12] [ViRanker: A BGE-M3 & Blockwise Parallel Transformer Cross-Encoder for Vietnamese Reranking](https://arxiv.org/abs/2509.09131)
*Phuong-Nam Dang,Kieu-Linh Nguyen,Thanh-Hieu Pham*

Main category: cs.CL

TL;DR: ViRanker是一个专门针对越南语的交叉编码器重排序模型，基于BGE-M3编码器构建，采用Blockwise Parallel Transformer增强，在MMARCO-VI基准测试中表现出色，超越了多语言基线模型。


<details>
  <summary>Details</summary>
Motivation: 解决越南语这种低资源语言缺乏竞争性重排序模型的问题，越南语具有复杂的语法和变音符号，需要专门的模型来处理其语言特性。

Method: 基于BGE-M3编码器构建，使用Blockwise Parallel Transformer进行增强，在8GB精选语料库上训练，采用混合硬负采样进行微调以增强鲁棒性。

Result: 在MMARCO-VI基准测试中实现了强大的早期排名准确性，超越了多语言基线模型，并与PhoRanker竞争相当。模型已在Hugging Face上开源发布。

Conclusion: 该研究展示了通过仔细的架构适应和数据管理可以推动其他代表性不足语言的重排序技术发展，为越南语信息检索系统提供了有力支持。

Abstract: This paper presents ViRanker, a cross-encoder reranking model tailored to the
Vietnamese language. Built on the BGE-M3 encoder and enhanced with the
Blockwise Parallel Transformer, ViRanker addresses the lack of competitive
rerankers for Vietnamese, a low-resource language with complex syntax and
diacritics. The model was trained on an 8 GB curated corpus and fine-tuned with
hybrid hard-negative sampling to strengthen robustness. Evaluated on the
MMARCO-VI benchmark, ViRanker achieves strong early-rank accuracy, surpassing
multilingual baselines and competing closely with PhoRanker. By releasing the
model openly on Hugging Face, we aim to support reproducibility and encourage
wider adoption in real-world retrieval systems. Beyond Vietnamese, this study
illustrates how careful architectural adaptation and data curation can advance
reranking in other underrepresented languages.

</details>


### [13] [LITcoder: A General-Purpose Library for Building and Comparing Encoding Models](https://arxiv.org/abs/2509.09152)
*Taha Binhuraib,Ruimin Gao,Anna A. Ivanova*

Main category: cs.CL

TL;DR: LITcoder是一个用于构建和基准测试神经编码模型的开源库，提供标准化工具来处理连续刺激与脑数据的对齐、特征转换、映射和模型评估，支持模块化流程和多种方法选择。


<details>
  <summary>Details</summary>
Motivation: 降低神经编码模型实现的技术门槛，促进跨模型和数据集的系统比较，提高方法严谨性，加速高质量脑活动预测模型的开发。

Method: 采用模块化管道设计，涵盖脑数据集、脑区域、刺激特征（神经网络基础和对照特征）、降采样方法等多种方法选择，内置日志记录、绘图功能，并与实验跟踪平台无缝集成。

Result: 通过在三个故事聆听数据集（LeBel et al. (2023)、Narratives和Little Prince）上拟合一系列编码模型，证明了框架的可扩展性和多功能性，并探索了构建连续fMRI数据编码模型的关键方法选择。

Conclusion: LITcoder有效降低了编码模型实施的技术障碍，促进了系统性的模型比较，增强了方法严谨性，并加速了高性能脑活动预测模型的开发。

Abstract: We introduce LITcoder, an open-source library for building and benchmarking
neural encoding models. Designed as a flexible backend, LITcoder provides
standardized tools for aligning continuous stimuli (e.g., text and speech) with
brain data, transforming stimuli into representational features, mapping those
features onto brain data, and evaluating the predictive performance of the
resulting model on held-out data. The library implements a modular pipeline
covering a wide array of methodological design choices, so researchers can
easily compose, compare, and extend encoding models without reinventing core
infrastructure. Such choices include brain datasets, brain regions, stimulus
feature (both neural-net-based and control, such as word rate), downsampling
approaches, and many others. In addition, the library provides built-in
logging, plotting, and seamless integration with experiment tracking platforms
such as Weights & Biases (W&B). We demonstrate the scalability and versatility
of our framework by fitting a range of encoding models to three story listening
datasets: LeBel et al. (2023), Narratives, and Little Prince. We also explore
the methodological choices critical for building encoding models for continuous
fMRI data, illustrating the importance of accounting for all tokens in a TR
scan (as opposed to just taking the last one, even when contextualized),
incorporating hemodynamic lag effects, using train-test splits that minimize
information leakage, and accounting for head motion effects on encoding model
predictivity. Overall, LITcoder lowers technical barriers to encoding model
implementation, facilitates systematic comparisons across models and datasets,
fosters methodological rigor, and accelerates the development of high-quality
high-performance predictive models of brain activity.
  Project page: https://litcoder-brain.github.io

</details>


### [14] [Target-oriented Multimodal Sentiment Classification with Counterfactual-enhanced Debiasing](https://arxiv.org/abs/2509.09160)
*Zhiyue Liu,Fanrong Ma,Xin Ling*

Main category: cs.CL

TL;DR: 提出了一种新颖的反事实增强去偏框架，通过反事实数据增强和自适应去偏对比学习机制，减少目标导向多模态情感分类中的虚假相关性，提高分类准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法过度依赖文本内容且未考虑数据集偏差（特别是词级上下文偏差），导致文本特征与输出标签之间的虚假相关性，影响分类精度。

Method: 采用反事实数据增强策略最小化改变情感相关因果特征，生成细节匹配的图像-文本样本；引入自适应去偏对比学习机制从反事实数据中学习鲁棒特征。

Result: 在多个基准数据集上的实验结果表明，该方法优于最先进的基线方法。

Conclusion: 提出的反事实增强去偏框架能有效减少虚假相关性，引导模型关注与情感相关的内容，提高目标导向多模态情感分类性能。

Abstract: Target-oriented multimodal sentiment classification seeks to predict
sentiment polarity for specific targets from image-text pairs. While existing
works achieve competitive performance, they often over-rely on textual content
and fail to consider dataset biases, in particular word-level contextual
biases. This leads to spurious correlations between text features and output
labels, impairing classification accuracy. In this paper, we introduce a novel
counterfactual-enhanced debiasing framework to reduce such spurious
correlations. Our framework incorporates a counterfactual data augmentation
strategy that minimally alters sentiment-related causal features, generating
detail-matched image-text samples to guide the model's attention toward content
tied to sentiment. Furthermore, for learning robust features from
counterfactual data and prompting model decisions, we introduce an adaptive
debiasing contrastive learning mechanism, which effectively mitigates the
influence of biased words. Experimental results on several benchmark datasets
show that our proposed method outperforms state-of-the-art baselines.

</details>


### [15] [EchoX: Towards Mitigating Acoustic-Semantic Gap via Echo Training for Speech-to-Speech LLMs](https://arxiv.org/abs/2509.09174)
*Yuhao Zhang,Yuhao Du,Zhanchen Dai,Xiangnan Ma,Kaiqi Kou,Benyou Wang,Haizhou Li*

Main category: cs.CL

TL;DR: EchoX是一个语音-语音大语言模型，通过整合声学和语义学习来解决当前SLLM在知识和推理能力上的退化问题，在有限训练数据下实现了先进的性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于文本大语言模型衍生的语音-语音大语言模型存在知识和推理能力退化的问题，作者认为这是由于训练范式未能弥合特征表示空间中的声学-语义鸿沟。

Method: 提出EchoX方法，利用语义表示并动态生成语音训练目标，整合声学和语义学习，使模型能够保持强大的推理能力。

Result: 实验结果表明，EchoX仅使用约6000小时训练数据，就在多个基于知识的问答基准测试中取得了先进的性能。

Conclusion: EchoX通过创新的训练方法成功解决了语音大语言模型的知识退化问题，证明了整合声学和语义学习的有效性。

Abstract: Speech-to-speech large language models (SLLMs) are attracting increasing
attention. Derived from text-based large language models (LLMs), SLLMs often
exhibit degradation in knowledge and reasoning capabilities. We hypothesize
that this limitation arises because current training paradigms for SLLMs fail
to bridge the acoustic-semantic gap in the feature representation space. To
address this issue, we propose EchoX, which leverages semantic representations
and dynamically generates speech training targets. This approach integrates
both acoustic and semantic learning, enabling EchoX to preserve strong
reasoning abilities as a speech LLM. Experimental results demonstrate that
EchoX, with about six thousand hours of training data, achieves advanced
performance on multiple knowledge-based question-answering benchmarks. The
project is available at https://github.com/FreedomIntelligence/EchoX.

</details>


### [16] [Efficient Trie-based Biasing using K-step Prediction for Rare Word Recognition](https://arxiv.org/abs/2509.09196)
*Chin Yuen Kwok,Jia Qi yip*

Main category: cs.CL

TL;DR: 通过多步预测模型避免伪检索撤销步骤，大幅提升稀有词识别准确性


<details>
  <summary>Details</summary>
Motivation: 解决传统Trie偏置方法在谨慌搜索中撤销契约的计算成本高问题

Method: 调整ASR模型进行多步预测，通过细调Whisper模型使其能够预测是否部分假设会导致完整稀有词

Result: 仅用10小时合成数据细调，将NSC Part 2测试集词误率从30.86%降至12.19%

Conclusion: 多步预测方法能够高效避免偏置契约撤销，显著提升稀有词识别性能

Abstract: Contextual biasing improves rare word recognition of ASR models by
prioritizing the output of rare words during decoding. A common approach is
Trie-based biasing, which gives "bonus scores" to partial hypothesis (e.g.
"Bon") that may lead to the generation of the rare word (e.g. "Bonham"). If the
full word ("Bonham") isn't ultimately recognized, the system revokes those
earlier bonuses. This revocation is limited to beam search and is
computationally expensive, particularly for models with large decoders. To
overcome these limitations, we propose adapting ASR models to look ahead and
predict multiple steps at once. This avoids the revocation step entirely by
better estimating whether a partial hypothesis will lead to the generation of
the full rare word. By fine-tuning Whisper with only 10 hours of synthetic
data, our method reduces the word error rate on the NSC Part 2 test set from
30.86% to 12.19%.

</details>


### [17] [Improving Synthetic Data Training for Contextual Biasing Models with a Keyword-Aware Cost Function](https://arxiv.org/abs/2509.09197)
*Chin Yuen Kwok,Jia Qi Yip,Eng Siong Chng*

Main category: cs.CL

TL;DR: 提出了一种关键词感知损失函数来改进TCPGen上下文偏置方法，通过在合成数据上训练偏置模块，显著降低了稀有词识别的词错误率


<details>
  <summary>Details</summary>
Motivation: 解决ASR模型在合成数据上训练偏置模块时容易过拟合的问题，提高稀有词识别性能

Method: 增强TCPGen上下文偏置方法，提出包含掩码交叉熵和二元分类的关键词感知损失函数，用于训练偏置模块

Result: 在10小时合成数据上微调Whisper模型，将NSC Part 2测试集的词错误率从29.71%降至11.81%

Conclusion: 关键词感知损失函数能有效提升上下文偏置模块的性能，显著改善稀有词识别效果

Abstract: Rare word recognition can be improved by adapting ASR models to synthetic
data that includes these words. Further improvements can be achieved through
contextual biasing, which trains and adds a biasing module into the model
architecture to prioritize rare words. While training the module on synthetic
rare word data is more effective than using non-rare-word data, it can lead to
overfitting due to artifacts in the synthetic audio. To address this, we
enhance the TCPGen-based contextual biasing approach and propose a
keyword-aware loss function that additionally focuses on biased words when
training biasing modules. This loss includes a masked cross-entropy term for
biased word prediction and a binary classification term for detecting biased
word positions. These two terms complementarily support the decoding of biased
words during inference. By adapting Whisper to 10 hours of synthetic data, our
method reduced the word error rate on the NSC Part 2 test set from 29.71% to
11.81%.

</details>


### [18] [GmSLM : Generative Marmoset Spoken Language Modeling](https://arxiv.org/abs/2509.09198)
*Talia Sternberg,Michael London,David Omer,Yossi Adi*

Main category: cs.CL

TL;DR: GmSLM是一个针对狨猴叫声的生成式语音语言模型，通过无监督野外数据和弱标记对话数据进行零样本评估，在声学匹配和下游任务中表现优异，为研究发声交流的神经基础提供了实用框架。


<details>
  <summary>Details</summary>
Motivation: 狨猴表现出复杂的发声交流能力，具有类似人类语言的特征，但由于主要通过叫声交流，标准LLM方法不适用。研究其发声交流为连接大脑活动提供了独特机会，特别是在人类大脑难以直接研究语言的情况下。

Method: 开发了GmSLM（生成式狨猴语音语言模型）管道，使用无监督野外数据和弱标记对话数据设计新颖的零样本评估指标，并与基于人类语音的基线进行比较。

Result: GmSLM生成的叫声在声学上与真实重采样样本高度匹配，在下游任务中表现良好，能够有效区分真实和人工对话，尽管完全无监督。

Conclusion: GmSLM为研究发声交流的神经基础提供了实用框架，有望在神经科学、生物声学和进化生物学领域产生重要影响，支持进一步连接发声与大脑活动的研究。

Abstract: Marmoset monkeys exhibit complex vocal communication, challenging the view
that nonhuman primates vocal communication is entirely innate, and show similar
features of human speech, such as vocal labeling of others and turn-taking.
Studying their vocal communication offers a unique opportunity to link it with
brain activity-especially given the difficulty of accessing the human brain in
speech and language research. Since Marmosets communicate primarily through
vocalizations, applying standard LLM approaches is not straightforward. We
introduce Generative Marmoset Spoken Language Modeling (GmSLM), an optimized
spoken language model pipeline for Marmoset vocal communication. We designed a
novel zero-shot evaluation metrics using unsupervised in-the-wild data,
alongside weakly labeled conversational data, to assess GmSLM and demonstrate
its advantage over a basic human-speech-based baseline. GmSLM generated
vocalizations closely matched real resynthesized samples acoustically and
performed well on downstream tasks. Despite being fully unsupervised, GmSLM
effectively distinguish real from artificial conversations and may support
further investigations of the neural basis of vocal communication and provides
a practical framework linking vocalization and brain activity. We believe GmSLM
stands to benefit future work in neuroscience, bioacoustics, and evolutionary
biology. Samples are provided under: pages.cs.huji.ac.il/adiyoss-lab/GmSLM.

</details>


### [19] [CCF: A Context Compression Framework for Efficient Long-Sequence Language Modeling](https://arxiv.org/abs/2509.09199)
*Wenhao Li,Bangcheng Sun,Weihao Ye,Tianyi Zhang,Daohai Yu,Fei Chao,Rongrong Ji*

Main category: cs.CL

TL;DR: CCF是一个新颖的上下文压缩框架，通过分层潜在表示学习实现高效长上下文建模，在保持全局语义的同时大幅减少输入冗余，显著提升计算和内存效率。


<details>
  <summary>Details</summary>
Motivation: 扩展语言模型到更长上下文对于捕捉扩展语篇中的丰富依赖关系至关重要，但简单的上下文扩展会带来显著的计算和内存负担，导致训练和推理效率低下。

Method: 提出CCF框架，集成分段语义聚合与键值记忆编码，形成紧凑表示；引入训练效率优化策略，结合增量分段解码和稀疏储层采样，大幅降低内存开销。

Result: 在多个长上下文语言建模基准测试中，CCF在高压缩比下实现了有竞争力的困惑度，相比现有方法显著提高了吞吐量和内存效率。

Conclusion: 结构化压缩对于可扩展和有效的长上下文语言建模具有巨大潜力，CCF框架为解决长上下文建模的效率问题提供了有效方案。

Abstract: Scaling language models to longer contexts is essential for capturing rich
dependencies across extended discourse. However, na\"ive context extension
imposes significant computational and memory burdens, often resulting in
inefficiencies during both training and inference. In this work, we propose
CCF, a novel context compression framework designed to enable efficient
long-context modeling by learning hierarchical latent representations that
preserve global semantics while aggressively reducing input redundancy. CCF
integrates segment-wise semantic aggregation with key-value memory encoding,
forming compact representations that support accurate reconstruction and
long-range understanding. To further enhance scalability, we introduce a
training-efficient optimization strategy that couples incremental segment
decoding with sparse reservoir sampling, substantially reducing memory overhead
without degrading performance. Empirical results on multiple long-context
language modeling benchmarks demonstrate that CCF achieves competitive
perplexity under high compression ratios, and significantly improves throughput
and memory efficiency compared to existing approaches. These findings highlight
the potential of structured compression for scalable and effective long-context
language modeling.

</details>


### [20] [Reading Between the Lines: Classifying Resume Seniority with Large Language Models](https://arxiv.org/abs/2509.09229)
*Matan Cohen,Shira Shani,Eden Menahem,Yehudit Aperstein,Alexander Apartsin*

Main category: cs.CL

TL;DR: 本研究评估了大型语言模型在简历资历分类中的有效性，使用包含真实简历和合成困难样本的混合数据集来检测资历夸大和隐性专业能力。


<details>
  <summary>Details</summary>
Motivation: 准确评估简历中的候选人资历是一个关键但具有挑战性的任务，因为普遍存在经验夸大和模糊自我表述的问题，需要自动化解决方案来改善候选人评估系统。

Method: 使用包含真实简历和合成困难样本的混合数据集，评估微调BERT架构等大型语言模型在检测资历夸大相关微妙语言线索方面的性能。

Result: 研究结果显示了大型语言模型在识别资历膨胀和隐性专业能力方面的有效性，为增强AI驱动的候选人评估系统提供了有前景的方向。

Conclusion: 该方法有助于减轻自我推销语言引入的偏见，数据集已向研究社区开放，促进了AI在简历分析领域的进一步发展。

Abstract: Accurately assessing candidate seniority from resumes is a critical yet
challenging task, complicated by the prevalence of overstated experience and
ambiguous self-presentation. In this study, we investigate the effectiveness of
large language models (LLMs), including fine-tuned BERT architectures, for
automating seniority classification in resumes. To rigorously evaluate model
performance, we introduce a hybrid dataset comprising both real-world resumes
and synthetically generated hard examples designed to simulate exaggerated
qualifications and understated seniority. Using the dataset, we evaluate the
performance of Large Language Models in detecting subtle linguistic cues
associated with seniority inflation and implicit expertise. Our findings
highlight promising directions for enhancing AI-driven candidate evaluation
systems and mitigating bias introduced by self-promotional language. The
dataset is available for the research community at https://bit.ly/4mcTovt

</details>


### [21] [Agentic LLMs for Question Answering over Tabular Data](https://arxiv.org/abs/2509.09234)
*Rishit Tyagi,Mohit Gupta,Rahul Bouri*

Main category: cs.CL

TL;DR: 本文提出了一种基于大语言模型的自然语言转SQL方法，用于表格问答任务，在DataBench基准测试中取得了显著优于基线的性能表现。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的表格具有多样化的结构、大小和数据类型，表格问答面临独特挑战。SemEval 2025 Task 8提供了大规模、多领域的基准数据集来评估模型能力。

Method: 采用多阶段流水线方法：示例选择、SQL查询生成、答案提取、验证和迭代优化。使用GPT-4o、GPT-4o-mini和DeepSeek v2:16b等大语言模型动态生成SQL查询。

Result: 在DataBench QA上达到70.5%准确率，在DataBench Lite QA上达到71.6%准确率，显著超越基线模型的26%和27%性能。

Conclusion: 大语言模型驱动的表格问答方法表现出色，本文详细分析了方法的优势和局限性，为相关研究提供了有价值的见解。

Abstract: Question Answering over Tabular Data (Table QA) presents unique challenges
due to the diverse structure, size, and data types of real-world tables. The
SemEval 2025 Task 8 (DataBench) introduced a benchmark composed of large-scale,
domain-diverse datasets to evaluate the ability of models to accurately answer
structured queries. We propose a Natural Language to SQL (NL-to-SQL) approach
leveraging large language models (LLMs) such as GPT-4o, GPT-4o-mini, and
DeepSeek v2:16b to generate SQL queries dynamically. Our system follows a
multi-stage pipeline involving example selection, SQL query generation, answer
extraction, verification, and iterative refinement. Experiments demonstrate the
effectiveness of our approach, achieving 70.5\% accuracy on DataBench QA and
71.6\% on DataBench Lite QA, significantly surpassing baseline scores of 26\%
and 27\% respectively. This paper details our methodology, experimental
results, and alternative approaches, providing insights into the strengths and
limitations of LLM-driven Table QA.

</details>


### [22] [From scratch to silver: Creating trustworthy training data for patent-SDG classification using Large Language Models](https://arxiv.org/abs/2509.09303)
*Grazia Sveva Ascione,Nicolò Tamagnone*

Main category: cs.CL

TL;DR: 本文提出了一种基于弱监督学习的专利-联合国可持续发展目标(SDG)分类方法，通过专利引用SDG标记科学文献的噪声信号，结合大语言模型提取结构化概念，构建银标准多标签数据集，有效解决了标注数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 专利对联合国可持续发展目标(SDG)的分类对于追踪创新如何应对全球挑战至关重要，但缺乏大规模标注数据集限制了监督学习的应用，现有方法缺乏可扩展性和泛化性。

Method: 将专利-SDG分类构建为弱监督问题，利用专利引用SDG标记科学文献(NPL引用)作为噪声初始信号。开发复合标注函数，使用大语言模型从专利和SDG论文中提取结构化概念(功能、解决方案、应用)，基于专利本体计算跨域相似度得分，采用基于排序的检索方法结合得分，通过自定义正样本损失校准标注函数。

Result: 构建了银标准软多标签数据集，能够训练有效的多标签回归模型。内部验证显示方法优于多个基线(包括基于Transformer的模型和零样本LLM)；外部验证通过专利引用、共同发明人和共同申请人图的网络模块性分析，显示所提标签比传统技术分类具有更好的主题、认知和组织一致性。

Conclusion: 弱监督和语义对齐可以大规模增强SDG分类，该方法为解决标注数据稀缺问题提供了有效解决方案，在专利-SDG分类任务上表现出优越性能。

Abstract: Classifying patents by their relevance to the UN Sustainable Development
Goals (SDGs) is crucial for tracking how innovation addresses global
challenges. However, the absence of a large, labeled dataset limits the use of
supervised learning. Existing methods, such as keyword searches, transfer
learning, and citation-based heuristics, lack scalability and generalizability.
This paper frames patent-to-SDG classification as a weak supervision problem,
using citations from patents to SDG-tagged scientific publications (NPL
citations) as a noisy initial signal. To address its sparsity and noise, we
develop a composite labeling function (LF) that uses large language models
(LLMs) to extract structured concepts, namely functions, solutions, and
applications, from patents and SDG papers based on a patent ontology.
Cross-domain similarity scores are computed and combined using a rank-based
retrieval approach. The LF is calibrated via a custom positive-only loss that
aligns with known NPL-SDG links without penalizing discovery of new SDG
associations. The result is a silver-standard, soft multi-label dataset mapping
patents to SDGs, enabling the training of effective multi-label regression
models. We validate our approach through two complementary strategies: (1)
internal validation against held-out NPL-based labels, where our method
outperforms several baselines including transformer-based models, and zero-shot
LLM; and (2) external validation using network modularity in patent citation,
co-inventor, and co-applicant graphs, where our labels reveal greater thematic,
cognitive, and organizational coherence than traditional technological
classifications. These results show that weak supervision and semantic
alignment can enhance SDG classification at scale.

</details>


### [23] [MetaRAG: Metamorphic Testing for Hallucination Detection in RAG Systems](https://arxiv.org/abs/2509.09360)
*Channdeth Sok,David Luz,Yacine Haddam*

Main category: cs.CL

TL;DR: MetaRAG是一个用于检索增强生成(RAG)系统的幻觉检测框架，通过分解答案、生成变异事实、验证一致性来实时检测幻觉，无需真实参考或模型内部访问。


<details>
  <summary>Details</summary>
Motivation: 现有幻觉检测方法主要针对独立LLM，无法解决RAG系统中响应必须与检索证据一致的特殊挑战，企业应用中需要可靠的幻觉检测方案。

Method: 四阶段框架：1)分解答案为原子事实；2)使用同义词和反义词生成受控变异；3)根据检索上下文验证变异(同义词应被蕴含，反义词应被矛盾)；4)聚合不一致性惩罚为响应级幻觉分数。

Result: 在企业专有数据集上的实验证明了MetaRAG在检测幻觉方面的有效性，能够实现基于RAG的对话代理的可信部署。

Conclusion: MetaRAG为RAG系统提供了一种实时、无监督、黑盒的幻觉检测解决方案，特别适用于身份敏感查询，支持可信的AI部署。

Abstract: Large Language Models (LLMs) are increasingly deployed in enterprise
applications, yet their reliability remains limited by hallucinations, i.e.,
confident but factually incorrect information. Existing detection approaches,
such as SelfCheckGPT and MetaQA, primarily target standalone LLMs and do not
address the unique challenges of Retrieval-Augmented Generation (RAG) systems,
where responses must be consistent with retrieved evidence. We therefore
present MetaRAG, a metamorphic testing framework for hallucination detection in
Retrieval-Augmented Generation (RAG) systems. MetaRAG operates in a real-time,
unsupervised, black-box setting, requiring neither ground-truth references nor
access to model internals, making it suitable for proprietary and high-stakes
domains. The framework proceeds in four stages: (1) decompose answers into
atomic factoids, (2) generate controlled mutations of each factoid using
synonym and antonym substitutions, (3) verify each variant against the
retrieved context (synonyms are expected to be entailed and antonyms
contradicted), and (4) aggregate penalties for inconsistencies into a
response-level hallucination score. Crucially for identity-aware AI, MetaRAG
localizes unsupported claims at the factoid span where they occur (e.g.,
pregnancy-specific precautions, LGBTQ+ refugee rights, or labor eligibility),
allowing users to see flagged spans and enabling system designers to configure
thresholds and guardrails for identity-sensitive queries. Experiments on a
proprietary enterprise dataset illustrate the effectiveness of MetaRAG for
detecting hallucinations and enabling trustworthy deployment of RAG-based
conversational agents. We also outline a topic-based deployment design that
translates MetaRAG's span-level scores into identity-aware safeguards; this
design is discussed but not evaluated in our experiments.

</details>


### [24] [Modelling Analogies and Analogical Reasoning: Connecting Cognitive Science Theory and NLP Research](https://arxiv.org/abs/2509.09381)
*Molly R Petersen,Claire E Stevenson,Lonneke van der Plas*

Main category: cs.CL

TL;DR: 本文总结了认知科学中类比推理的关键理论，并将其与自然语言处理研究联系起来，指出NLP领域虽然包含类似概念但缺乏认知视角，并展示了这些理论对NLP主要挑战的相关性。


<details>
  <summary>Details</summary>
Motivation: 将认知科学中的类比推理理论与自然语言处理研究相结合，为NLP研究者提供认知视角，以优化文本中的关系理解而非过度依赖实体层面的相似性。

Method: 总结认知科学文献中关于类比推理过程的关键理论，并将其与NLP中的相关概念进行关联分析，探讨这些认知理论对NLP研究挑战的适用性。

Result: 研究表明认知科学的类比推理理论可以很好地与NLP概念相联系，这些理论对NLP中的多个主要挑战具有相关性，能够指导研究者更好地理解文本中的关系结构。

Conclusion: 将认知科学的视角引入NLP研究有助于提升对文本中关系理解的能力，减少对实体层面相似性的过度依赖，为NLP发展提供新的研究方向。

Abstract: Analogical reasoning is an essential aspect of human cognition. In this
paper, we summarize key theory about the processes underlying analogical
reasoning from the cognitive science literature and relate it to current
research in natural language processing. While these processes can be easily
linked to concepts in NLP, they are generally not viewed through a cognitive
lens. Furthermore, we show how these notions are relevant for several major
challenges in NLP research, not directly related to analogy solving. This may
guide researchers to better optimize relational understanding in text, as
opposed to relying heavily on entity-level similarity.

</details>


### [25] [Hierarchical Bracketing Encodings Work for Dependency Graphs](https://arxiv.org/abs/2509.09388)
*Ana Ezquerro,Carlos Gómez-Rodríguez,David Vilares*

Main category: cs.CL

TL;DR: 该论文提出了一种实用的层次括号编码方法，用于依赖图解析，将图编码为序列，实现线性时间解析，同时支持重入、循环和空节点表示。


<details>
  <summary>Details</summary>
Motivation: 现有的图线性化方法标签空间较大，需要更高效的编码方式来减少标签空间同时保持结构信息，以改进依赖图解析的准确性和效率。

Method: 使用层次括号编码将依赖图表示为序列，通过n个标注动作实现线性时间解析，能够处理重入、循环和空节点等复杂结构。

Result: 在多语言多形式基准测试中表现出竞争力，在精确匹配准确率上相比其他方法有持续改进。

Conclusion: 层次括号编码是一种实用的依赖图解析方法，能够有效减少标签空间并保持结构完整性，在多种语言和形式下都表现出优越性能。

Abstract: We revisit hierarchical bracketing encodings from a practical perspective in
the context of dependency graph parsing. The approach encodes graphs as
sequences, enabling linear-time parsing with $n$ tagging actions, and still
representing reentrancies, cycles, and empty nodes. Compared to existing graph
linearizations, this representation substantially reduces the label space while
preserving structural information. We evaluate it on a multilingual and
multi-formalism benchmark, showing competitive results and consistent
improvements over other methods in exact match accuracy.

</details>


### [26] [GrACE: A Generative Approach to Better Confidence Elicitation in Large Language Models](https://arxiv.org/abs/2509.09438)
*Zhaohan Zhang,Ziquan Liu,Ioannis Patras*

Main category: cs.CL

TL;DR: GrACE是一种新的LLM置信度评估方法，通过隐藏状态与特殊标记嵌入的相似性来实时生成置信度，无需额外采样或辅助模型，在准确性和校准性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有LLM置信度评估方法要么计算成本高，要么校准效果差，难以在实际高风险应用中可靠部署。

Method: 提出GrACE方法，通过模型最后一个隐藏状态与词汇表中特殊标记嵌入的相似性来实时表达置信度，并通过与准确性相关的校准目标进行微调。

Result: 在三个LLM和两个基准数据集上的实验表明，GrACE在开放式生成任务中具有最佳判别能力和校准性能，优于六种竞争方法，且能显著减少测试时缩放所需的样本数量。

Conclusion: GrACE为LLM部署提供了可扩展、可靠且实时的置信度估计实用解决方案，能提高最终决策准确性并减少所需样本量。

Abstract: Assessing the reliability of Large Language Models (LLMs) by confidence
elicitation is a prominent approach to AI safety in high-stakes applications,
such as healthcare and finance. Existing methods either require expensive
computational overhead or suffer from poor calibration, making them impractical
and unreliable for real-world deployment. In this work, we propose GrACE, a
Generative Approach to Confidence Elicitation that enables scalable and
reliable confidence elicitation for LLMs. GrACE adopts a novel mechanism in
which the model expresses confidence by the similarity between the last hidden
state and the embedding of a special token appended to the vocabulary, in
real-time. We fine-tune the model for calibrating the confidence with
calibration targets associated with accuracy. Experiments with three LLMs and
two benchmark datasets show that the confidence produced by GrACE achieves the
best discriminative capacity and calibration on open-ended generation tasks,
outperforming six competing methods without resorting to additional sampling or
an auxiliary model. Moreover, we propose two strategies for improving test-time
scaling based on confidence induced by GrACE. Experimental results show that
using GrACE not only improves the accuracy of the final decision but also
significantly reduces the number of required samples in the test-time scaling
scheme, indicating the potential of GrACE as a practical solution for deploying
LLMs with scalable, reliable, and real-time confidence estimation.

</details>


### [27] [Mitigating Language Barriers in Education: Developing Multilingual Digital Learning Materials with Machine Translation](https://arxiv.org/abs/2509.09473)
*Lucie Poláková,Martin Popel,Věra Kloudová,Michal Novák,Mariia Anisimova,Jiří Balhar*

Main category: cs.CL

TL;DR: EdUKate项目开发多语言教育材料，通过机器翻译将捷克语互动练习翻译成乌克兰语、英语和德语，特别针对教育领域优化捷克-乌克兰机器翻译系统。


<details>
  <summary>Details</summary>
Motivation: 为捷克中小学开发多语言学习材料，满足非捷克语学生的教育需求，通过学术机构与教育出版商的合作实现教育资源的国际化。

Method: 结合数字教育、语言学和机器翻译技术，开发专门的捷克-乌克兰机器翻译系统，处理XML和PDF格式内容，处理科技术语，并通过教师需求调查指导开发。

Result: 成功翻译了多达9000个多模态互动练习，开发了针对教育领域的机器翻译系统，所有应用免费向学生、教育者和研究人员开放。

Conclusion: 项目成功实现了教育资源的跨语言转换，为多语言教育提供了可行解决方案，特别在捷克-乌克兰翻译方面取得了重要进展。

Abstract: The EdUKate project combines digital education, linguistics, translation
studies, and machine translation to develop multilingual learning materials for
Czech primary and secondary schools. Launched through collaboration between a
major Czech academic institution and the country's largest educational
publisher, the project is aimed at translating up to 9,000 multimodal
interactive exercises from Czech into Ukrainian, English, and German for an
educational web portal. It emphasizes the development and evaluation of a
direct Czech-Ukrainian machine translation system tailored to the educational
domain, with special attention to processing formatted content such as XML and
PDF and handling technical and scientific terminology. We present findings from
an initial survey of Czech teachers regarding the needs of non-Czech-speaking
students and describe the system's evaluation and implementation on the web
portal. All resulting applications are freely available to students, educators,
and researchers.

</details>


### [28] [Towards Explainable Job Title Matching: Leveraging Semantic Textual Relatedness and Knowledge Graphs](https://arxiv.org/abs/2509.09522)
*Vadim Zadykian,Bruno Andrade,Haithem Afli*

Main category: cs.CL

TL;DR: 提出了一种结合知识图谱和文本嵌入的自监督混合架构，用于语义文本相关性分析，通过分层评估方法在职位匹配任务中显著提升高相关性区域的性能。


<details>
  <summary>Details</summary>
Motivation: 解决简历推荐系统中职位标题匹配的挑战，传统方法在词汇重叠有限或误导时效果不佳，需要捕捉超越表面词汇相似性的语义关系。

Method: 自监督混合架构，结合密集句子嵌入和领域特定知识图谱，使用图神经网络进行集成，并采用分层评估方法将语义相关性分数连续体划分为低、中、高三个区域。

Result: 经过知识图谱增强的微调SBERT模型在高语义相关性区域表现最佳，RMSE比强基线降低了25%，在语义有意义的子空间中实现了细粒度性能提升。

Conclusion: 结合知识图谱与文本嵌入的方法不仅提升了性能，更重要的是分层评估方法揭示了全局指标掩盖的模型优缺点，为人力资源系统中需要公平性、可解释性和上下文匹配的应用提供了更有针对性的模型选择依据。

Abstract: Semantic Textual Relatedness (STR) captures nuanced relationships between
texts that extend beyond superficial lexical similarity. In this study, we
investigate STR in the context of job title matching - a key challenge in
resume recommendation systems, where overlapping terms are often limited or
misleading. We introduce a self-supervised hybrid architecture that combines
dense sentence embeddings with domain-specific Knowledge Graphs (KGs) to
improve both semantic alignment and explainability. Unlike previous work that
evaluated models on aggregate performance, our approach emphasizes data
stratification by partitioning the STR score continuum into distinct regions:
low, medium, and high semantic relatedness. This stratified evaluation enables
a fine-grained analysis of model performance across semantically meaningful
subspaces. We evaluate several embedding models, both with and without KG
integration via graph neural networks. The results show that fine-tuned SBERT
models augmented with KGs produce consistent improvements in the high-STR
region, where the RMSE is reduced by 25% over strong baselines. Our findings
highlight not only the benefits of combining KGs with text embeddings, but also
the importance of regional performance analysis in understanding model
behavior. This granular approach reveals strengths and weaknesses hidden by
global metrics, and supports more targeted model selection for use in Human
Resources (HR) systems and applications where fairness, explainability, and
contextual matching are essential.

</details>


### [29] [DeMeVa at LeWiDi-2025: Modeling Perspectives with In-Context Learning and Label Distribution Learning](https://arxiv.org/abs/2509.09524)
*Daniil Ignatev,Nan Li,Hugh Mee Wong,Anh Dang,Shane Kaszefski Yaschuk*

Main category: cs.CL

TL;DR: DeMeVa团队在LeWiDi 2025任务中探索了两种方法：基于大语言模型的上下文学习和基于RoBERTa的标签分布学习方法，证明ICL能有效预测标注者特定注释，LDL方法在软标签预测方面具有潜力


<details>
  <summary>Details</summary>
Motivation: 解决学习分歧任务中的标注不一致问题，探索如何有效预测不同标注者的观点注释，并生成软标签表示

Method: 使用大语言模型进行上下文学习（比较不同示例采样策略）和基于RoBERTa的标签分布学习方法（评估多种微调方法）

Result: ICL能有效预测标注者特定注释，将这些预测聚合成软标签可获得有竞争力的性能；LDL方法在软标签预测方面表现良好

Conclusion: 上下文学习和标签分布学习方法都是解决标注分歧问题的有效途径，特别是LDL方法值得进一步探索

Abstract: This system paper presents the DeMeVa team's approaches to the third edition
of the Learning with Disagreements shared task (LeWiDi 2025; Leonardelli et
al., 2025). We explore two directions: in-context learning (ICL) with large
language models, where we compare example sampling strategies; and label
distribution learning (LDL) methods with RoBERTa (Liu et al., 2019b), where we
evaluate several fine-tuning methods. Our contributions are twofold: (1) we
show that ICL can effectively predict annotator-specific annotations
(perspectivist annotations), and that aggregating these predictions into soft
labels yields competitive performance; and (2) we argue that LDL methods are
promising for soft label predictions and merit further exploration by the
perspectivist community.

</details>


### [30] [Prompting the Market? A Large-Scale Meta-Analysis of GenAI in Finance NLP (2022-2025)](https://arxiv.org/abs/2509.09544)
*Paolo Pedinotti,Peter Baumann,Nathan Jessurun,Leslie Barrett,Enrico Santus*

Main category: cs.CL

TL;DR: MetaGraph是一个从科学文献中提取知识图谱的方法论，用于分析金融NLP领域的研究趋势，揭示了LLM在该领域发展的三个阶段演变


<details>
  <summary>Details</summary>
Motivation: 大型语言模型(LLMs)快速重塑了金融NLP领域，但传统调查方法跟不上这种变革速度，需要新的方法来结构化分析研究趋势

Method: 定义了金融NLP研究本体论，构建基于LLM的提取管道，对681篇论文(2022-2025)进行大规模数据驱动分析

Result: 揭示了三个关键阶段：早期LLM采用和任务/数据集创新；对LLM局限性的批判性反思；外围技术向模块化系统的集成

Conclusion: MetaGraph提供了对金融NLP演变的清晰理解，突出了新兴趋势和优先级转变，同时展示了可在其他领域复用的科学进展映射方法

Abstract: Large Language Models (LLMs) have rapidly reshaped financial NLP, enabling
new tasks and driving a proliferation of datasets and diversification of data
sources. Yet, this transformation has outpaced traditional surveys. In this
paper, we present MetaGraph, a generalizable methodology for extracting
knowledge graphs from scientific literature and analyzing them to obtain a
structured, queryable view of research trends. We define an ontology for
financial NLP research and apply an LLM-based extraction pipeline to 681 papers
(2022-2025), enabling large-scale, data-driven analysis. MetaGraph reveals
three key phases: early LLM adoption and task/dataset innovation; critical
reflection on LLM limitations; and growing integration of peripheral techniques
into modular systems. This structured view offers both practitioners and
researchers a clear understanding of how financial NLP has evolved -
highlighting emerging trends, shifting priorities, and methodological
shifts-while also demonstrating a reusable approach for mapping scientific
progress in other domains.

</details>


### [31] [Personality-Enhanced Social Recommendations in SAMI: Exploring the Role of Personality Detection in Matchmaking](https://arxiv.org/abs/2509.09583)
*Brittany Harbison,Samuel Taubman,Travis Taylor,Ashok. K. Goel*

Main category: cs.CL

TL;DR: 使用GPT零样本能力从论坛介绍帖推断大五人格特质，集成到SAMI匹配系统中提供人格感知的社交推荐


<details>
  <summary>Details</summary>
Motivation: 在线课程环境阻碍社交群体自然形成，SAMI系统因缺乏完整心智理论而受限，特别是无法推断人格特质影响推荐相关性

Method: 提出人格检测模型，利用GPT零样本能力从论坛介绍帖推断大五人格特质，并与现有模型进行基准测试，然后将模型集成到SAMI的实体匹配系统中

Result: 模型在人格推断任务中表现有效，初步集成显示人格特质可以补充现有匹配因素

Conclusion: 人格特质能够增强社交推荐系统，但需要进一步评估其对学生参与度和匹配质量的全面影响

Abstract: Social connection is a vital part of learning, yet online course environments
present barriers to the organic formation of social groups. SAMI offers one
solution by facilitating student connections, but its effectiveness is
constrained by an incomplete Theory of Mind, limiting its ability to create an
effective mental model of a student. One facet of this is its inability to
intuit personality, which may influence the relevance of its recommendations.
To explore this, we propose a personality detection model utilizing GPTs
zero-shot capability to infer Big-Five personality traits from forum
introduction posts, often encouraged in online courses. We benchmark its
performance against established models, demonstrating its efficacy in this
task. Furthermore, we integrate this model into SAMIs entity-based matchmaking
system, enabling personality-informed social recommendations. Initial
integration suggests personality traits can complement existing matching
factors, though additional evaluation is required to determine their full
impact on student engagement and match quality.

</details>


### [32] [Fluent but Unfeeling: The Emotional Blind Spots of Language Models](https://arxiv.org/abs/2509.09593)
*Bangzhao Shu,Isha Joshi,Melissa Karnaze,Anh C. Pham,Ishita Kakkar,Sindhu Kothe,Arpine Hovasapian,Mai ElSherief*

Main category: cs.CL

TL;DR: EXPRESS基准数据集评估LLMs在细粒度情感识别方面与人类情感的对齐程度，发现现有模型在准确预测人类自我披露的细粒度情感方面仍面临挑战。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要将情感分类为预定义的有限类别，忽视了更细微的情感表达，需要评估LLMs是否能在细粒度层面与人类情感对齐。

Method: 引入EXPRESS基准数据集（包含251个细粒度情感标签），通过综合评估框架分析预测情感术语并将其分解为八种基本情感，系统测试主流LLMs在不同提示设置下的表现。

Result: LLMs准确预测与人类自我披露情感一致的情感仍然具有挑战性；某些LLMs能生成符合情感理论的术语，但在捕捉上下文线索方面不如人类自我披露有效。

Conclusion: 研究揭示了LLMs在细粒度情感对齐方面的局限性，为未来增强其上下文理解能力的研究提供了见解。

Abstract: The versatility of Large Language Models (LLMs) in natural language
understanding has made them increasingly popular in mental health research.
While many studies explore LLMs' capabilities in emotion recognition, a
critical gap remains in evaluating whether LLMs align with human emotions at a
fine-grained level. Existing research typically focuses on classifying emotions
into predefined, limited categories, overlooking more nuanced expressions. To
address this gap, we introduce EXPRESS, a benchmark dataset curated from Reddit
communities featuring 251 fine-grained, self-disclosed emotion labels. Our
comprehensive evaluation framework examines predicted emotion terms and
decomposes them into eight basic emotions using established emotion theories,
enabling a fine-grained comparison. Systematic testing of prevalent LLMs under
various prompt settings reveals that accurately predicting emotions that align
with human self-disclosed emotions remains challenging. Qualitative analysis
further shows that while certain LLMs generate emotion terms consistent with
established emotion theories and definitions, they sometimes fail to capture
contextual cues as effectively as human self-disclosures. These findings
highlight the limitations of LLMs in fine-grained emotion alignment and offer
insights for future research aimed at enhancing their contextual understanding.

</details>


### [33] [LAVA: Language Model Assisted Verbal Autopsy for Cause-of-Death Determination](https://arxiv.org/abs/2509.09602)
*Yiqun T. Chen,Tyler H. McCormick,Li Liu,Abhirup Datta*

Main category: cs.CL

TL;DR: LA-VA结合大语言模型与传统算法，在资源有限地区通过口头尸检提高死因预测准确率5-10%


<details>
  <summary>Details</summary>
Motivation: 在医疗证明不可用的资源有限地区，口头尸检是估计死因的关键工具，需要改进预测准确性

Method: 使用PHMRC数据集，结合大语言模型(GPT-5)、传统算法(LCVA基线)、文本嵌入和元学习器集成方法

Result: GPT-5在三个年龄组中表现最佳：成人48.6%、儿童50.5%、新生儿53.5%，比传统方法提升5-10%

Conclusion: 现成的大语言模型辅助方法可显著提高口头尸检准确性，对低收入地区的全球健康监测具有重要意义

Abstract: Verbal autopsy (VA) is a critical tool for estimating causes of death in
resource-limited settings where medical certification is unavailable. This
study presents LA-VA, a proof-of-concept pipeline that combines Large Language
Models (LLMs) with traditional algorithmic approaches and embedding-based
classification for improved cause-of-death prediction. Using the Population
Health Metrics Research Consortium (PHMRC) dataset across three age categories
(Adult: 7,580; Child: 1,960; Neonate: 2,438), we evaluate multiple approaches:
GPT-5 predictions, LCVA baseline, text embeddings, and meta-learner ensembles.
Our results demonstrate that GPT-5 achieves the highest individual performance
with average test site accuracies of 48.6% (Adult), 50.5% (Child), and 53.5%
(Neonate), outperforming traditional statistical machine learning baselines by
5-10%. Our findings suggest that simple off-the-shelf LLM-assisted approaches
could substantially improve verbal autopsy accuracy, with important
implications for global health surveillance in low-resource settings.

</details>


### [34] [Bridging the Capability Gap: Joint Alignment Tuning for Harmonizing LLM-based Multi-Agent Systems](https://arxiv.org/abs/2509.09629)
*Minghang Zhu,Zhengliang Shi,Zhiwei Xu,Shiguang Wu,Lingjie Wang,Pengjie Ren,Zhaochun Ren,Zhumin Chen*

Main category: cs.CL

TL;DR: MOAT是一个多智能体联合对齐调优框架，通过迭代对齐提升智能体协作能力，在六个基准测试中平均提升3.1%（held-in任务）和4.4%（held-out任务）


<details>
  <summary>Details</summary>
Motivation: 现有方法通常独立微调多智能体系统中的各个智能体，导致智能体之间存在能力差距和协调性差的问题

Method: 提出MOAT框架，包含两个关键阶段交替进行：(1)规划智能体对齐，优化规划智能体生成更好的子目标序列；(2)接地智能体改进，使用智能体自身生成的多样化子目标-动作对进行微调

Result: 理论分析证明MOAT确保训练过程非递减且逐步收敛，在六个基准测试中超越最先进基线方法

Conclusion: MOAT通过迭代对齐方法有效解决了多智能体系统中的协调问题，显著提升了任务执行性能

Abstract: The advancement of large language models (LLMs) has enabled the construction
of multi-agent systems to solve complex tasks by dividing responsibilities
among specialized agents, such as a planning agent for subgoal generation and a
grounding agent for executing tool-use actions. Most existing methods typically
fine-tune these agents independently, leading to capability gaps among them
with poor coordination. To address this, we propose MOAT, a Multi-Agent Joint
Alignment Tuning framework that improves agents collaboration through iterative
alignment. MOAT alternates between two key stages: (1) Planning Agent
Alignment, which optimizes the planning agent to generate subgoal sequences
that better guide the grounding agent; and (2) Grounding Agent Improving, which
fine-tunes the grounding agent using diverse subgoal-action pairs generated by
the agent itself to enhance its generalization capablity. Theoretical analysis
proves that MOAT ensures a non-decreasing and progressively convergent training
process. Experiments across six benchmarks demonstrate that MOAT outperforms
state-of-the-art baselines, achieving average improvements of 3.1% on held-in
tasks and 4.4% on held-out tasks.

</details>


### [35] [All for One: LLMs Solve Mental Math at the Last Token With Information Transferred From Other Tokens](https://arxiv.org/abs/2509.09650)
*Siddarth Mamidanna,Daking Rai,Ziyu Yao,Yilun Zhou*

Main category: cs.CL

TL;DR: 该论文通过Context-Aware Mean Ablation和Attention-Based Peeking技术，在大语言模型中发现了一个"All-for-One"子图，该子图在心理数学任务中仅在最后token进行关键计算，且信息传递仅通过特定中间层完成。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在计算任务上表现出色，但其内部工作机制仍不明确。研究者希望探究模型在实际操作中如何通过自注意力和多层感知器进行信息处理和计算。

Method: 采用三步骤方法：抑制初始层的输入特定token计算、限制中间层token位置间的信息传递路径、强制剩余层中所有计算在最后token进行。提出了CAMA和ABP两种技术来识别关键计算子图。

Result: 发现了一个高效且必要的"All-for-One"子图，该子图在各种心理数学任务上保持高精度，计算主要发生在深层且仅在最后token，信息通过特定中间层传递。该子图在不同模型和输入风格间具有可迁移性。

Conclusion: 研究揭示了LLMs在数学计算任务中的特定计算模式，识别出的AF1子图对模型性能至关重要，提出的CAMA和ABP技术在子图识别方面优于其他方法。

Abstract: Large language models (LLMs) demonstrate proficiency across numerous
computational tasks, yet their inner workings remain unclear. In theory, the
combination of causal self-attention and multilayer perceptron layers allows
every token to access and compute information based on all preceding tokens. In
practice, to what extent are such operations present? In this paper, on mental
math tasks (i.e., direct math calculation via next-token prediction without
explicit reasoning), we investigate this question in three steps: inhibiting
input-specific token computations in the initial layers, restricting the routes
of information transfer across token positions in the next few layers, and
forcing all computation to happen at the last token in the remaining layers.
With two proposed techniques, Context-Aware Mean Ablation (CAMA) and
Attention-Based Peeking (ABP), we identify an All-for-One subgraph (AF1) with
high accuracy on a wide variety of mental math tasks, where meaningful
computation occurs very late (in terms of layer depth) and only at the last
token, which receives information of other tokens in few specific middle
layers. Experiments on a variety of models and arithmetic expressions show that
this subgraph is sufficient and necessary for high model performance, transfers
across different models, and works on a variety of input styles. Ablations on
different CAMA and ABP alternatives reveal their unique advantages over other
methods, which may be of independent interest.

</details>


### [36] [Steering MoE LLMs via Expert (De)Activation](https://arxiv.org/abs/2509.09660)
*Mohsen Fayyaz,Ali Modarressi,Hanieh Deilamsalehy,Franck Dernoncourt,Ryan Rossi,Trung Bui,Hinrich Schütze,Nanyun Peng*

Main category: cs.CL

TL;DR: SteerMoE是一个通过检测和控制MoE模型中专家的框架，能够在不重新训练或修改权重的情况下，通过选择性激活/停用专家来控制LLM的行为（如忠实性和安全性）。


<details>
  <summary>Details</summary>
Motivation: 现有的MoE模型通过路由机制将token分配给不同的专家网络，但缺乏对这些专家行为的理解和控制能力。研究人员希望开发一种方法来检测和控制与特定行为相关的专家，从而实现对模型行为的精确调控。

Method: 通过检测在对比行为输入对中表现出不同激活模式的专家，识别与特定行为相关的专家。在推理过程中选择性地激活或停用这些专家来控制模型行为。

Result: 在11个基准测试和6个LLM上的实验表明，该方法能将安全性提升高达+20%，忠实性提升+27%。在对抗攻击模式下，单独使用可降低安全性-41%，与现有越狱方法结合可完全绕过所有安全防护（-100%）。

Conclusion: SteerMoE框架提供了一种无需重新训练即可控制MoE模型行为的新方法，同时揭示了专家网络中隐藏的对齐伪装维度，这对模型安全性具有重要意义。

Abstract: Mixture-of-Experts (MoE) in Large Language Models (LLMs) routes each token
through a subset of specialized Feed-Forward Networks (FFN), known as experts.
We present SteerMoE, a framework for steering MoE models by detecting and
controlling behavior-linked experts. Our detection method identifies experts
with distinct activation patterns across paired inputs exhibiting contrasting
behaviors. By selectively (de)activating such experts during inference, we
control behaviors like faithfulness and safety without retraining or modifying
weights. Across 11 benchmarks and 6 LLMs, our steering raises safety by up to
+20% and faithfulness by +27%. In adversarial attack mode, it drops safety by
-41% alone, and -100% when combined with existing jailbreak methods, bypassing
all safety guardrails and exposing a new dimension of alignment faking hidden
within experts.

</details>


### [37] [CDE: Curiosity-Driven Exploration for Efficient Reinforcement Learning in Large Language Models](https://arxiv.org/abs/2509.09675)
*Runpeng Dai,Linfeng Song,Haolin Liu,Zhenwen Liang,Dian Yu,Haitao Mi,Zhaopeng Tu,Rui Liu,Tong Zheng,Hongtu Zhu,Dong Yu*

Main category: cs.CL

TL;DR: 通过引入好奇心驱动探索(CDE)框架，解决RLVR方法中的过早收敛和熵排崩溃问题，在AIME指标上实现了约3个百分点的提升


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法在增强大语言模型的推理能力时存在探索不充分、过早收敛和熵排崩溃的问题

Method: 提出好奇心驱动探索(CDE)框架，利用模型本身的内在好奇心来指导探索。通过演员的生成回应的困惑度和评判者多头估计的方差作为探索奖励

Result: 在AIME指标上实现了约3个百分点的提升，超过但使用GRPO/PPO的标准RLVR方法

Conclusion: CDE框架有效解决了RLVR中的探索问题，通过理论分析识别了RLVR内的检验崩溃机制，为识别常见的LLM失败模式提供了见解

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) is a powerful paradigm
for enhancing the reasoning ability of Large Language Models (LLMs). Yet
current RLVR methods often explore poorly, leading to premature convergence and
entropy collapse. To address this challenge, we introduce Curiosity-Driven
Exploration (CDE), a framework that leverages the model's own intrinsic sense
of curiosity to guide exploration. We formalize curiosity with signals from
both the actor and the critic: for the actor, we use perplexity over its
generated response, and for the critic, we use the variance of value estimates
from a multi-head architecture. Both signals serve as an exploration bonus
within the RLVR framework to guide the model. Our theoretical analysis shows
that the actor-wise bonus inherently penalizes overconfident errors and
promotes diversity among correct responses; moreover, we connect the
critic-wise bonus to the well-established count-based exploration bonus in RL.
Empirically, our method achieves an approximate +3 point improvement over
standard RLVR using GRPO/PPO on AIME benchmarks. Further analysis identifies a
calibration collapse mechanism within RLVR, shedding light on common LLM
failure modes.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [38] [Bona fide Cross Testing Reveals Weak Spot in Audio Deepfake Detection Systems](https://arxiv.org/abs/2509.09204)
*Chin Yuen Kwok,Jia Qi Yip,Zhen Qiu,Chi Hung Chi,Kwok Yan Lam*

Main category: cs.SD

TL;DR: 该论文提出了一种新的音频深度伪造检测评估框架，通过统合多样化的真实语音数据集和平衡的EER计算，解决传统评估方法中的偏差和可靠性问题。


<details>
  <summary>Details</summary>
Motivation: 传统音频深度伪造检测评估存在两大问题：1)单一EER指标会因样本数量不均而偏向某些合成器；2)真实语音数据集类型单一，缺乏实际场景的多样性。

Method: 提出真实语音交叉测试框架，整合多样化的真实语音数据集，并通过聚合多个EER值来进行更平衡的评估。在9种不同真实语音类型上对150多个合成器进行了测试。

Result: 该方法提高了模型评估的稳健性和可解释性，与传统评估方法相比更有效。同时释放了新的数据集以促进进一步研究。

Conclusion: 真实语音交叉测试框架为音频深度伪造检测领域提供了更加全面和可靠的评估方法，有助于更好地模拟实际应用场景。

Abstract: Audio deepfake detection (ADD) models are commonly evaluated using datasets
that combine multiple synthesizers, with performance reported as a single Equal
Error Rate (EER). However, this approach disproportionately weights
synthesizers with more samples, underrepresenting others and reducing the
overall reliability of EER. Additionally, most ADD datasets lack diversity in
bona fide speech, often featuring a single environment and speech style (e.g.,
clean read speech), limiting their ability to simulate real-world conditions.
To address these challenges, we propose bona fide cross-testing, a novel
evaluation framework that incorporates diverse bona fide datasets and
aggregates EERs for more balanced assessments. Our approach improves robustness
and interpretability compared to traditional evaluation methods. We benchmark
over 150 synthesizers across nine bona fide speech types and release a new
dataset to facilitate further research at
https://github.com/cyaaronk/audio_deepfake_eval.

</details>


### [39] [DiFlow-TTS: Discrete Flow Matching with Factorized Speech Tokens for Low-Latency Zero-Shot Text-To-Speech](https://arxiv.org/abs/2509.09631)
*Ngoc-Son Nguyen,Hieu-Nghia Huynh-Nguyen,Thanh V. T. Tran,Truong-Son Hy,Van Nguyen*

Main category: cs.SD

TL;DR: DiFlow-TTS是首个将纯离散流匹配应用于语音合成的模型，通过显式建模分解的语音属性，在零样本TTS中实现了高质量语音合成，推理速度比现有基线快25.8倍


<details>
  <summary>Details</summary>
Motivation: 解决零样本文本转语音中现有方法推理速度慢、存在重复伪影的问题，充分利用离散表示的优势，避免将离散token嵌入连续空间带来的潜在限制

Method: 采用纯离散流匹配方法，在紧凑统一架构中显式建模分解的语音属性。通过上下文学习，基于文本内容和参考语音提取的韵律、声学属性进行条件生成，使用分解流预测机制分别处理韵律和声学细节

Result: 在自然度、韵律、说话人风格保持和能量控制等多个关键指标上表现优异，模型紧凑且实现低延迟推理，生成速度比最新基线快25.8倍

Conclusion: DiFlow-TTS证明了纯离散流匹配在语音合成中的有效性，为高质量、高效率的零样本TTS提供了新的解决方案

Abstract: Zero-shot Text-to-Speech (TTS) aims to synthesize high-quality speech that
mimics the voice of an unseen speaker using only a short reference sample,
requiring not only speaker adaptation but also accurate modeling of prosodic
attributes. Recent approaches based on language models, diffusion, and flow
matching have shown promising results in zero-shot TTS, but still suffer from
slow inference and repetition artifacts. Discrete codec representations have
been widely adopted for speech synthesis, and recent works have begun to
explore diffusion models in purely discrete settings, suggesting the potential
of discrete generative modeling for speech synthesis. However, existing
flow-matching methods typically embed these discrete tokens into a continuous
space and apply continuous flow matching, which may not fully leverage the
advantages of discrete representations. To address these challenges, we
introduce DiFlow-TTS, which, to the best of our knowledge, is the first model
to explore purely Discrete Flow Matching for speech synthesis. DiFlow-TTS
explicitly models factorized speech attributes within a compact and unified
architecture. It leverages in-context learning by conditioning on textual
content, along with prosodic and acoustic attributes extracted from a reference
speech, enabling effective attribute cloning in a zero-shot setting. In
addition, the model employs a factorized flow prediction mechanism with
distinct heads for prosody and acoustic details, allowing it to learn
aspect-specific distributions. Experimental results demonstrate that DiFlow-TTS
achieves promising performance in several key metrics, including naturalness,
prosody, preservation of speaker style, and energy control. It also maintains a
compact model size and achieves low-latency inference, generating speech up to
25.8 times faster than the latest existing baselines.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [40] [Recurrence Meets Transformers for Universal Multimodal Retrieval](https://arxiv.org/abs/2509.08897)
*Davide Caffagni,Sara Sarto,Marcella Cornia,Lorenzo Baraldi,Rita Cucchiara*

Main category: cs.CV

TL;DR: ReT-2是一个统一的多模态检索模型，支持图像和文本组成的多模态查询，并能在多模态文档集合中进行检索，通过循环Transformer架构实现跨层和跨模态的动态信息整合。


<details>
  <summary>Details</summary>
Motivation: 随着多模态检索在LLMs和多模态LLMs中的快速发展，出现了越来越复杂的检索任务。现有方法主要依赖于视觉-语言模型的任务特定微调，且仅限于单模态查询或文档，无法满足多模态检索需求。

Method: ReT-2采用多层表示和循环Transformer架构，结合LSTM启发的门控机制，动态整合跨层和跨模态信息，捕捉细粒度的视觉和文本细节。

Result: 在M2KR和M-BEIR基准测试中，ReT-2在不同检索配置下均实现了最先进的性能，同时提供更快的推理速度和更低的内存使用。在检索增强生成管道中集成后，在Encyclopedic-VQA和InfoSeek数据集上提升了下游性能。

Conclusion: ReT-2作为一个统一的多模态检索模型，在多模态检索任务中表现出色，具有高效性和实用性，源代码和训练模型已公开提供。

Abstract: With the rapid advancement of multimodal retrieval and its application in
LLMs and multimodal LLMs, increasingly complex retrieval tasks have emerged.
Existing methods predominantly rely on task-specific fine-tuning of
vision-language models and are limited to single-modality queries or documents.
In this paper, we propose ReT-2, a unified retrieval model that supports
multimodal queries, composed of both images and text, and searches across
multimodal document collections where text and images coexist. ReT-2 leverages
multi-layer representations and a recurrent Transformer architecture with
LSTM-inspired gating mechanisms to dynamically integrate information across
layers and modalities, capturing fine-grained visual and textual details. We
evaluate ReT-2 on the challenging M2KR and M-BEIR benchmarks across different
retrieval configurations. Results demonstrate that ReT-2 consistently achieves
state-of-the-art performance across diverse settings, while offering faster
inference and reduced memory usage compared to prior approaches. When
integrated into retrieval-augmented generation pipelines, ReT-2 also improves
downstream performance on Encyclopedic-VQA and InfoSeek datasets. Our source
code and trained models are publicly available at:
https://github.com/aimagelab/ReT-2

</details>


### [41] [COCO-Urdu: A Large-Scale Urdu Image-Caption Dataset with Multimodal Quality Estimation](https://arxiv.org/abs/2509.09014)
*Umair Hassan*

Main category: cs.CV

TL;DR: COCO-Urdu是一个大规模乌尔都语图像-字幕数据集，包含59,000张图片和319,000个乌尔都语字幕，旨在解决乌尔都语在多模态研究中资源不足的问题。


<details>
  <summary>Details</summary>
Motivation: 乌尔都语拥有超过2.5亿使用者，但在多模态和视觉语言研究中严重缺乏资源。缺乏大规模高质量数据集限制了乌尔都语系统的发展，并加剧了多语言视觉语言模型对高资源语言的偏见。

Method: 从MS COCO数据集通过分层抽样构建，使用SeamlessM4T v2进行翻译，并通过混合多模态质量评估框架（包括COMET-Kiwi翻译质量评估、CLIP视觉相似度、BERTScore和回译语义一致性）进行验证和迭代优化。

Result: 构建了目前最大的公开乌尔都语字幕数据集，在BLEU、SacreBLEU和chrF等基准测试中报告了持续强劲的结果。

Conclusion: COCO-Urdu数据集及其质量评估管道的发布旨在减少多模态研究中的语言偏见，为包容性视觉语言系统奠定基础。

Abstract: Urdu, spoken by over 250 million people, remains critically under-served in
multimodal and vision-language research. The absence of large-scale,
high-quality datasets has limited the development of Urdu-capable systems and
reinforced biases in multilingual vision-language models trained primarily on
high-resource languages. To address this gap, we present COCO-Urdu, a
large-scale image-caption dataset derived from MS COCO, containing 59,000
images and 319,000 Urdu captions selected through stratified sampling to
preserve the original distribution. Captions were translated using SeamlessM4T
v2 and validated with a hybrid multimodal quality estimation framework that
integrates COMET-Kiwi for translation quality, CLIP-based similarity for visual
grounding, and BERTScore with back-translation for semantic consistency;
low-scoring captions were iteratively refined using open-source large language
models. We further benchmark COCO-Urdu on BLEU, SacreBLEU, and chrF, reporting
consistently strong results. To the best of our knowledge, COCO-Urdu is the
largest publicly available Urdu captioning dataset. By releasing both the
dataset and the quality estimation pipeline, we aim to reduce language bias in
multimodal research and establish a foundation for inclusive vision-language
systems.

</details>


### [42] [Can Multimodal LLMs See Materials Clearly? A Multimodal Benchmark on Materials Characterization](https://arxiv.org/abs/2509.09307)
*Zhengzhao Lai,Youbin Zheng,Zhenyang Cai,Haonan Lyu,Jinpu Yang,Hongqing Liang,Yan Hu,Benyou Wang*

Main category: cs.CV

TL;DR: MatCha是首个材料表征图像理解基准测试，包含1500个需要专业领域知识的问题，评估发现现有MLLM模型在真实材料表征场景中表现不佳，与人类专家存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 虽然多模态大语言模型在材料科学中显示出潜力，但其对真实世界材料表征成像数据的理解能力尚未充分探索，需要建立专业基准来评估模型性能。

Method: 创建MatCha基准测试，涵盖材料研究的四个关键阶段和21个不同任务，包含1500个需要专家级知识的问题，评估现有最先进MLLM模型的表现。

Result: 现有MLLM模型在MatCha基准上表现显著低于人类专家，在处理需要高级专业知识和复杂视觉感知的问题时性能下降，few-shot和chain-of-thought提示方法难以改善这些限制。

Conclusion: 现有MLLM模型对真实材料表征场景的适应性有限，MatCha基准将促进新材料发现和自主科学代理等领域的未来研究。

Abstract: Materials characterization is fundamental to acquiring materials information,
revealing the processing-microstructure-property relationships that guide
material design and optimization. While multimodal large language models
(MLLMs) have recently shown promise in generative and predictive tasks within
materials science, their capacity to understand real-world characterization
imaging data remains underexplored. To bridge this gap, we present MatCha, the
first benchmark for materials characterization image understanding, comprising
1,500 questions that demand expert-level domain expertise. MatCha encompasses
four key stages of materials research comprising 21 distinct tasks, each
designed to reflect authentic challenges faced by materials scientists. Our
evaluation of state-of-the-art MLLMs on MatCha reveals a significant
performance gap compared to human experts. These models exhibit degradation
when addressing questions requiring higher-level expertise and sophisticated
visual perception. Simple few-shot and chain-of-thought prompting struggle to
alleviate these limitations. These findings highlight that existing MLLMs still
exhibit limited adaptability to real-world materials characterization
scenarios. We hope MatCha will facilitate future research in areas such as new
material discovery and autonomous scientific agents. MatCha is available at
https://github.com/FreedomIntelligence/MatCha.

</details>


### [43] [FLUX-Reason-6M & PRISM-Bench: A Million-Scale Text-to-Image Reasoning Dataset and Comprehensive Benchmark](https://arxiv.org/abs/2509.09680)
*Rongyao Fang,Aldrich Yu,Chengqi Duan,Linjiang Huang,Shuai Bai,Yuxuan Cai,Kun Wang,Si Liu,Xihui Liu,Hongsheng Li*

Main category: cs.CV

TL;DR: FLUX-Reason-6M是一个包含600万高质量图像和2000万双语描述的推理导向数据集，PRISM-Bench是包含7个评估轨道的新基准，旨在推动开源文本到图像模型的发展。


<details>
  <summary>Details</summary>
Motivation: 开源文本到图像模型因缺乏大规模推理数据集和全面评估基准而落后于闭源系统，需要解决这一性能差距。

Method: 创建FLUX-Reason-6M数据集（6M图像+20M双语描述），按6个关键特征组织，采用生成思维链(GCoT)提供详细生成步骤；建立PRISM-Bench评估基准包含7个轨道，使用先进视觉语言模型进行人机对齐评估。

Result: 对19个领先模型的广泛评估揭示了关键性能差距和改进需求，数据集和基准为社区提供了前所未有的资源。

Conclusion: 发布的数据集、基准和评估代码将催化下一代推理导向的文本到图像生成技术的发展。

Abstract: The advancement of open-source text-to-image (T2I) models has been hindered
by the absence of large-scale, reasoning-focused datasets and comprehensive
evaluation benchmarks, resulting in a performance gap compared to leading
closed-source systems. To address this challenge, We introduce FLUX-Reason-6M
and PRISM-Bench (Precise and Robust Image Synthesis Measurement Benchmark).
FLUX-Reason-6M is a massive dataset consisting of 6 million high-quality
FLUX-generated images and 20 million bilingual (English and Chinese)
descriptions specifically designed to teach complex reasoning. The image are
organized according to six key characteristics: Imagination, Entity, Text
rendering, Style, Affection, and Composition, and design explicit Generation
Chain-of-Thought (GCoT) to provide detailed breakdowns of image generation
steps. The whole data curation takes 15,000 A100 GPU days, providing the
community with a resource previously unattainable outside of large industrial
labs. PRISM-Bench offers a novel evaluation standard with seven distinct
tracks, including a formidable Long Text challenge using GCoT. Through
carefully designed prompts, it utilizes advanced vision-language models for
nuanced human-aligned assessment of prompt-image alignment and image
aesthetics. Our extensive evaluation of 19 leading models on PRISM-Bench
reveals critical performance gaps and highlights specific areas requiring
improvement. Our dataset, benchmark, and evaluation code are released to
catalyze the next wave of reasoning-oriented T2I generation. Project page:
https://flux-reason-6m.github.io/ .

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [44] [Generative Engine Optimization: How to Dominate AI Search](https://arxiv.org/abs/2509.08919)
*Mahe Chen,Xiaoxuan Wang,Kaiwen Chen,Nick Koudas*

Main category: cs.IR

TL;DR: 这篇论文通过大规模实验对比了AI搜索和传统搜索引擎的信息来源偏向，发现AI搜索对权威第三方源有系统偏向，提出了生成式引擎优化(GEO)的战略框架


<details>
  <summary>Details</summary>
Motivation: 随着ChatGPT、Perplexity、Gemini等生成式AI搜索引擎的快速普及，信息检索模式从传统排名列表转向综合性答案，需要重构SEO实践

Method: 进行大规模、受控实验，涵盖多个垂直领域、多种语言和查询重写，定量分析AI搜索和传统搜索在信息来源方面的关键差异

Result: AI搜索对权威第三方源(Earned media)存在系统性偏向，而调平搜索更平衡。不同AI搜索服务在域名多样性、新鲜度、跨语言稳定性和查询敏感性方面存在显著差异

Conclusion: 提出了生成式引擎优化(GEO)战略议程，包括：(1)为机器扫描和证明设计内容，(2)控制权威媒体建立AI认可的权威性，(3)采用引擎特定和语言敏感策略，(4)应对大品牌偏见以支持小企业

Abstract: The rapid adoption of generative AI-powered search engines like ChatGPT,
Perplexity, and Gemini is fundamentally reshaping information retrieval, moving
from traditional ranked lists to synthesized, citation-backed answers. This
shift challenges established Search Engine Optimization (SEO) practices and
necessitates a new paradigm, which we term Generative Engine Optimization
(GEO).
  This paper presents a comprehensive comparative analysis of AI Search and
traditional web search (Google). Through a series of large-scale, controlled
experiments across multiple verticals, languages, and query paraphrases, we
quantify critical differences in how these systems source information. Our key
findings reveal that AI Search exhibit a systematic and overwhelming bias
towards Earned media (third-party, authoritative sources) over Brand-owned and
Social content, a stark contrast to Google's more balanced mix. We further
demonstrate that AI Search services differ significantly from each other in
their domain diversity, freshness, cross-language stability, and sensitivity to
phrasing.
  Based on these empirical results, we formulate a strategic GEO agenda. We
provide actionable guidance for practitioners, emphasizing the critical need
to: (1) engineer content for machine scannability and justification, (2)
dominate earned media to build AI-perceived authority, (3) adopt
engine-specific and language-aware strategies, and (4) overcome the inherent
"big brand bias" for niche players. Our work provides the foundational
empirical analysis and a strategic framework for achieving visibility in the
new generative search landscape.

</details>


### [45] [Retrieval-Augmented Generation for Reliable Interpretation of Radio Regulations](https://arxiv.org/abs/2509.09651)
*Zakaria El Kassimi,Fares Fourati,Mohamed-Slim Alouini*

Main category: cs.IR

TL;DR: 该论文提出了一个针对无线电法规领域的特定RAG管道，构建了首个该领域的选择题评估集，在检索质量上达到97%准确率，并使GPT-4o的生成准确率相对提升近12%。


<details>
  <summary>Details</summary>
Motivation: 研究无线电法规这一法律敏感和高风险领域的问答问题，需要可靠的检索增强生成方法来确保回答的准确性和权威性。

Method: 提出电信特定的RAG管道，从权威来源构建选择题评估集，采用自动化过滤和人工验证，定义领域特定的检索指标来评估检索质量。

Result: 检索器在领域特定指标下达到约97%的准确率，RAG管道使所有测试模型的生成准确率均得到提升，特别是GPT-4o相对提升近12%。

Conclusion: 精心设计的针对性基础为监管问答提供了简单而强大的基线解决方案，证明领域特定的RAG方法在法规问答中的有效性。

Abstract: We study question answering in the domain of radio regulations, a legally
sensitive and high-stakes area. We propose a telecom-specific
Retrieval-Augmented Generation (RAG) pipeline and introduce, to our knowledge,
the first multiple-choice evaluation set for this domain, constructed from
authoritative sources using automated filtering and human validation. To assess
retrieval quality, we define a domain-specific retrieval metric, under which
our retriever achieves approximately 97% accuracy. Beyond retrieval, our
approach consistently improves generation accuracy across all tested models. In
particular, while naively inserting documents without structured retrieval
yields only marginal gains for GPT-4o (less than 1%), applying our pipeline
results in nearly a 12% relative improvement. These findings demonstrate that
carefully targeted grounding provides a simple yet strong baseline and an
effective domain-specific solution for regulatory question answering. All code
and evaluation scripts, along with our derived question-answer dataset, are
available at https://github.com/Zakaria010/Radio-RAG.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [46] [Automated Unity Game Template Generation from GDDs via NLP and Multi-Modal LLMs](https://arxiv.org/abs/2509.08847)
*Amna Hassan*

Main category: cs.AI

TL;DR: 提出基于NLP和多模态LLM的自动化游戏模板生成框架，将游戏设计文档转换为Unity游戏原型，显著提升代码生成质量和设计规范遵循度


<details>
  <summary>Details</summary>
Motivation: 解决AI辅助游戏开发中的关键空白，简化从游戏设计到实现的过程，利用LLM技术加速游戏原型开发

Method: 使用微调的LLaMA-3模型专门用于Unity代码生成，结合自定义Unity集成包，端到端解析GDD并提取结构化游戏规格，生成Unity兼容的C#代码

Result: 微调模型在编译成功率、GDD遵循度、最佳实践采用和代码模块化指标上表现优异（平均得分4.8/5.0），显著优于基线模型，支持多种游戏类型

Conclusion: 该系统有效证明了LLM作为从游戏设计到实现流程中的宝贵工具，能够生成高质量的游戏模板并遵循设计规范

Abstract: This paper presents a novel framework for automated game template generation
by transforming Game Design Documents (GDDs) into functional Unity game
prototypes using Natural Language Processing (NLP) and multi-modal Large
Language Models (LLMs). We introduce an end-to-end system that parses GDDs,
extracts structured game specifications, and synthesizes Unity-compatible C#
code that implements the core mechanics, systems, and architecture defined in
the design documentation. Our approach combines a fine-tuned LLaMA-3 model
specialized for Unity code generation with a custom Unity integration package
that streamlines the implementation process. Evaluation results demonstrate
significant improvements over baseline models, with our fine-tuned model
achieving superior performance (4.8/5.0 average score) compared to
state-of-the-art LLMs across compilation success, GDD adherence, best practices
adoption, and code modularity metrics. The generated templates demonstrate high
adherence to GDD specifications across multiple game genres. Our system
effectively addresses critical gaps in AI-assisted game development,
positioning LLMs as valuable tools in streamlining the transition from game
design to implementation.

</details>


### [47] [Tree-OPO: Off-policy Monte Carlo Tree-Guided Advantage Optimization for Multistep Reasoning](https://arxiv.org/abs/2509.09284)
*Bingning Huang,Tu Nguyen,Matthieu Zimmer*

Main category: cs.AI

TL;DR: 将MCTS轨迹用于GRPO策略优化，提出基于树结构优势估计的分阶段训练方法，解决优势饱和和奖励信号崩溃问题


<details>
  <summary>Details</summary>
Motivation: 探索如何将传统用于训练价值或奖励模型的MCTS轨迹重新用于改进基于偏好的强化学习中的策略优化

Method: 提出分阶段GRPO训练范式，使用部分揭示的MCTS rollout生成补全，引入新颖的树结构优势估计设置

Result: 结构化优势估计可以稳定更新并更好地反映组合推理质量，但仍面临优势饱和和奖励信号崩溃等挑战

Conclusion: 提出了启发式和统计解决方案来缓解这些问题，并讨论了在分阶段或树状奖励结构下学习的开放挑战

Abstract: Recent advances in reasoning with large language models (LLMs) have shown the
effectiveness of Monte Carlo Tree Search (MCTS) for generating high-quality
intermediate trajectories, particularly in math and symbolic domains. Inspired
by this, we explore how MCTS-derived trajectories, traditionally used for
training value or reward models, can be repurposed to improve policy
optimization in preference-based reinforcement learning (RL). Specifically, we
focus on Group Relative Policy Optimization (GRPO), a recent algorithm that
enables preference-consistent policy learning without value networks. We
propose a staged GRPO training paradigm where completions are derived from
partially revealed MCTS rollouts, introducing a novel tree-structured setting
for advantage estimation. This leads to a rich class of prefix-conditioned
reward signals, which we analyze theoretically and empirically. Our initial
results indicate that while structured advantage estimation can stabilize
updates and better reflect compositional reasoning quality, challenges such as
advantage saturation and reward signal collapse remain. We propose heuristic
and statistical solutions to mitigate these issues and discuss open challenges
for learning under staged or tree-like reward structures.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [48] [A vibe coding learning design to enhance EFL students' talking to, through, and about AI](https://arxiv.org/abs/2509.08854)
*David James Woo,Kai Guo,Yangyang Yu*

Main category: cs.CY

TL;DR: 本文报告了一种创新的英语教学实践，通过人工智能进行vibe coding（使用自然语言创建软件应用）来提升EFL教育效果。研究发现学生在提示工程、权属认定和AI心智模型方面的差异影响了编程效果。


<details>
  <summary>Details</summary>
Motivation: 探索如何利用人工智能技术通过自然语言交互来创建软件应用，以改善英语作为外语（EFL）的教学效果，并研究人机协作语言学习的新模式。

Method: 采用案例研究方法，开发了一个四小时的工作坊，让两名学生设计解决真实EFL写作挑战的应用程序。数据收集包括工作表、视频录音、声思协议、屏幕录制和AI生成图像。

Result: 对比案例显示，一名学生成功创建了符合设计意图的功能性应用，而另一名学生遇到技术困难，设计意图与实际功能存在较大差距。分析发现学生在提示工程方式、AI心智模型和权属归因方面的差异导致了不同的编程结果。

Conclusion: AI作为有益的语言机器，学生如何与AI交互的方式决定了vibe coding的成效。有效的vibe coding教学需要明确的元语言脚手架支持，包括教掌结构化提示工程技巧、促进关于权属问题的批判性讨论以及发展表达AI心智模型的词汇。

Abstract: This innovative practice article reports on the piloting of vibe coding
(using natural language to create software applications with AI) for English as
a Foreign Language (EFL) education. We developed a human-AI meta-languaging
framework with three dimensions: talking to AI (prompt engineering), talking
through AI (negotiating authorship), and talking about AI (mental models of
AI). Using backward design principles, we created a four-hour workshop where
two students designed applications addressing authentic EFL writing challenges.
We adopted a case study methodology, collecting data from worksheets and video
recordings, think-aloud protocols, screen recordings, and AI-generated images.
Contrasting cases showed one student successfully vibe coding a functional
application cohering to her intended design, while another encountered
technical difficulties with major gaps between intended design and actual
functionality. Analysis reveals differences in students' prompt engineering
approaches, suggesting different AI mental models and tensions in attributing
authorship. We argue that AI functions as a beneficial languaging machine, and
that differences in how students talk to, through, and about AI explain vibe
coding outcome variations. Findings indicate that effective vibe coding
instruction requires explicit meta-languaging scaffolding, teaching structured
prompt engineering, facilitating critical authorship discussions, and
developing vocabulary for articulating AI mental models.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [49] [OmniEVA: Embodied Versatile Planner via Task-Adaptive 3D-Grounded and Embodiment-aware Reasoning](https://arxiv.org/abs/2509.09332)
*Yuecheng Liu,Dafeng Chi,Shiguang Wu,Zhanguang Zhang,Yuzheng Zhuang,Bowen Yang,He Zhu,Lingfeng Zhang,Pengwei Xie,David Gamaliel Arcos Bravo,Yingxue Zhang,Jianye Hao,Xingyue Quan*

Main category: cs.RO

TL;DR: OmniEVA是一个多模态大语言模型驱动的具身智能规划器，通过任务自适应3D接地机制和具身感知推理框架，解决了现有系统的几何适应性差距和具身约束差距问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于MLLM的具身系统存在两个关键局限：几何适应性差距（2D输入或硬编码3D几何注入导致空间信息不足或泛化能力受限）和具身约束差距（忽略真实机器人的物理约束，导致计划理论上有效但实际不可行）。

Method: 提出两个核心创新：(1)任务自适应3D接地机制，使用门控路由器根据上下文需求进行选择性3D融合调节；(2)具身感知推理框架，将任务目标和具身约束共同纳入推理循环。

Result: 实验结果表明OmniEVA不仅实现了最先进的通用具身推理性能，还在广泛的下游场景中展现出强大能力，在原始和复合任务基准测试中都表现出稳健和通用的规划能力。

Conclusion: OmniEVA通过创新的3D接地和具身感知推理方法，有效解决了现有MLLM具身系统的局限性，为具身智能提供了更强大和实用的规划解决方案。

Abstract: Recent advances in multimodal large language models (MLLMs) have opened new
opportunities for embodied intelligence, enabling multimodal understanding,
reasoning, and interaction, as well as continuous spatial decision-making.
Nevertheless, current MLLM-based embodied systems face two critical
limitations. First, Geometric Adaptability Gap: models trained solely on 2D
inputs or with hard-coded 3D geometry injection suffer from either insufficient
spatial information or restricted 2D generalization, leading to poor
adaptability across tasks with diverse spatial demands. Second, Embodiment
Constraint Gap: prior work often neglects the physical constraints and
capacities of real robots, resulting in task plans that are theoretically valid
but practically infeasible.To address these gaps, we introduce OmniEVA -- an
embodied versatile planner that enables advanced embodied reasoning and task
planning through two pivotal innovations: (1) a Task-Adaptive 3D Grounding
mechanism, which introduces a gated router to perform explicit selective
regulation of 3D fusion based on contextual requirements, enabling
context-aware 3D grounding for diverse embodied tasks. (2) an Embodiment-Aware
Reasoning framework that jointly incorporates task goals and embodiment
constraints into the reasoning loop, resulting in planning decisions that are
both goal-directed and executable. Extensive experimental results demonstrate
that OmniEVA not only achieves state-of-the-art general embodied reasoning
performance, but also exhibits a strong ability across a wide range of
downstream scenarios. Evaluations of a suite of proposed embodied benchmarks,
including both primitive and composite tasks, confirm its robust and versatile
planning capabilities. Project page: https://omnieva.github.io

</details>


### [50] [SimpleVLA-RL: Scaling VLA Training via Reinforcement Learning](https://arxiv.org/abs/2509.09674)
*Haozhan Li,Yuxin Zuo,Jiale Yu,Yuhao Zhang,Zhaohui Yang,Kaiyan Zhang,Xuekai Zhu,Yuchen Zhang,Tianxing Chen,Ganqu Cui,Dehui Wang,Dingxiang Luo,Yuchen Fan,Youbang Sun,Jia Zeng,Jiangmiao Pang,Shanghang Zhang,Yu Wang,Yao Mu,Bowen Zhou,Ning Ding*

Main category: cs.RO

TL;DR: SimpleVLA-RL是一个针对视觉-语言-动作模型的强化学习框架，通过引入VLA特定的轨迹采样、并行化、多环境渲染和优化损失计算，显著提升了机器人操作的长期动作规划能力，在多个基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 解决VLA模型面临的两个核心挑战：大规模人类操作轨迹数据稀缺且成本高昂，以及在分布偏移任务中的泛化能力有限。受大型推理模型中RL成功提升推理能力的启发，探索RL是否能类似地提升VLA模型的长期动作规划能力。

Method: 基于veRL框架，开发了SimpleVLA-RL框架，包含VLA特定的轨迹采样、可扩展并行化、多环境渲染和优化损失计算。应用探索增强策略，并在OpenVLA-OFT模型上进行训练。

Result: 在LIBERO基准测试中达到最先进性能，在RoboTwin 1.0和2.0上甚至超越了π0。不仅减少了对大规模数据的依赖，实现了鲁棒泛化，而且在真实世界任务中显著超越了监督微调方法。发现了RL训练中的新现象"pushcut"。

Conclusion: SimpleVLA-RL框架有效解决了VLA模型的数据依赖和泛化问题，通过强化学习显著提升了长期动作规划能力，为机器人操作任务提供了更高效和通用的解决方案。

Abstract: Vision-Language-Action (VLA) models have recently emerged as a powerful
paradigm for robotic manipulation. Despite substantial progress enabled by
large-scale pretraining and supervised fine-tuning (SFT), these models face two
fundamental challenges: (i) the scarcity and high cost of large-scale
human-operated robotic trajectories required for SFT scaling, and (ii) limited
generalization to tasks involving distribution shift. Recent breakthroughs in
Large Reasoning Models (LRMs) demonstrate that reinforcement learning (RL) can
dramatically enhance step-by-step reasoning capabilities, raising a natural
question: Can RL similarly improve the long-horizon step-by-step action
planning of VLA? In this work, we introduce SimpleVLA-RL, an efficient RL
framework tailored for VLA models. Building upon veRL, we introduce
VLA-specific trajectory sampling, scalable parallelization, multi-environment
rendering, and optimized loss computation. When applied to OpenVLA-OFT,
SimpleVLA-RL achieves SoTA performance on LIBERO and even outperforms $\pi_0$
on RoboTwin 1.0\&2.0 with the exploration-enhancing strategies we introduce.
SimpleVLA-RL not only reduces dependence on large-scale data and enables robust
generalization, but also remarkably surpasses SFT in real-world tasks.
Moreover, we identify a novel phenomenon ``pushcut'' during RL training,
wherein the policy discovers previously unseen patterns beyond those seen in
the previous training process. Github: https://github.com/PRIME-RL/SimpleVLA-RL

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [51] [Open-sci-ref-0.01: open and reproducible reference baselines for language model and dataset comparison](https://arxiv.org/abs/2509.09009)
*Marianna Nezhurina,Taishi Nakamura,Timur Carstensen,Niccolò Ajroldi,Ville Komulainen,David Salinas,Jenia Jitsev*

Main category: cs.LG

TL;DR: open-sci-ref是一个密集Transformer模型家族，在多个参数规模(0.13B-1.7B)和token规模(最高1T)上训练，在8个开放参考数据集上建立了研究基线，为评估不同训练方法提供参考标准。


<details>
  <summary>Details</summary>
Motivation: 为研究人员提供标准化的参考基线，以便评估不同训练方法的有效性和质量，特别是在不同规模和数据集上的表现。

Method: 使用8个最新的开放参考数据集，训练多个规模的密集Transformer模型，提供中间检查点、训练日志和代码。

Result: NemoTron-CC HQ数据集表现最佳，其次是DCLM-baseline和FineWeb-Edu。建立了可比较的参考基线，支持通过计算轴进行训练方法比较。

Conclusion: open-sci-ref提供了标准化的研究基线，简化了复现过程，促进了未来研究，特别是在训练动态研究和不同数据集性能比较方面。

Abstract: We introduce open-sci-ref, a family of dense transformer models trained as
research baselines across multiple model (0.13B to 1.7B parameters) and token
scales (up to 1T) on 8 recent open reference datasets. Evaluating the models on
various standardized benchmarks, our training runs set establishes reference
points that enable researchers to assess the sanity and quality of alternative
training approaches across scales and datasets. Intermediate checkpoints allow
comparison and studying of the training dynamics. The established reference
baselines allow training procedures to be compared through their scaling
trends, aligning them on a common compute axis. Comparison of open reference
datasets reveals that training on NemoTron-CC HQ consistently outperforms other
reference datasets, followed by DCLM-baseline and FineWeb-Edu. In addition to
intermediate training checkpoints, the release includes logs, code, and
downstream evaluations to simplify reproduction, standardize comparison, and
facilitate future research.

</details>


### [52] [Identifying Key Features for Establishing Sustainable Agro-Tourism Centre: A Data Driven Approach](https://arxiv.org/abs/2509.09214)
*Alka Gadakh,Vidya Kumbhar,Sonal Khosla,Kumar Karunendra*

Main category: cs.LG

TL;DR: 本研究通过机器学习方法确定了农业旅游发展的关键指标，LASSO结合逻辑回归模型达到最高几何精度98-99%的分类准确率。


<details>
  <summary>Details</summary>
Motivation: 农业旅游作为促进农村发展的经济模式，需要研究其增长策略和关键指标，以实现政府收入多样化和文化遗产保护。

Method: 研究分为两个阶段：通过文献综述识别重要指标，然后使用LASSO等机器学习特征选择方法结合逻辑回归、决策树、随机森林和XGBoost等分类器进行分析。

Result: 在70-30%训练-测试数据中，LASSO+逻辑回归模型达到98%的最高准确率，968f机森林为95%。在80-20%数据分配下，逻辑回归维持99%准确率，决策树和XGBoost为97%。

Conclusion: 研究确定了农业旅游发展的关键指标，并验证了LASSO结合机器学习分类器在识别这些指标时的高效性，为农业旅游发展提供了数据驱动的决策支持。

Abstract: Agro-tourism serves as a strategic economic model designed to facilitate
rural development by diversifying income streams for local communities like
farmers while promoting the conservation of indigenous cultural heritage and
traditional agricultural practices. As a very booming subdomain of tourism,
there is a need to study the strategies for the growth of Agro-tourism in
detail. The current study has identified the important indicators for the
growth and enhancement of agro-tourism. The study is conducted in two phases:
identification of the important indicators through a comprehensive literature
review and in the second phase state-of-the-art techniques were used to
identify the important indicators for the growth of agro-tourism. The
indicators are also called features synonymously, the machine learning models
for feature selection were applied and it was observed that the Least Absolute
Shrinkage and Selection Operator (LASSO) method combined with, the machine
Learning Classifiers such as Logistic Regression (LR), Decision Trees (DT),
Random Forest (RF) Tree, and Extreme Gradient Boosting (XGBOOST) models were
used to suggest the growth of the agro-tourism. The results show that with the
LASSO method, LR model gives the highest classification accuracy of 98% in
70-30% train-test data followed by RF with 95% accuracy. Similarly, in the
80-20% train-test data LR maintains the highest accuracy at 99%, while DT and
XGBoost follow with 97% accuracy.

</details>


### [53] [Harnessing Uncertainty: Entropy-Modulated Policy Gradients for Long-Horizon LLM Agents](https://arxiv.org/abs/2509.09265)
*Jiawei Wang,Jiacai Liu,Yuqian Fu,Yingru Li,Xintao Wang,Yuan Lin,Yu Yue,Lin Zhang,Yang Wang,Ke Wang*

Main category: cs.LG

TL;DR: 提出Entropy-Modulated Policy Gradients (EMPG)框架，通过基于不确定性和任务结果重新校准学习信号，解决LLM智能体在长时程任务中因策略梯度与熵耦合导致的低效学习问题。


<details>
  <summary>Details</summary>
Motivation: 长时程任务中，基于大语言模型的智能体面临稀疏奖励难以分配信用的问题，且策略梯度幅度与熵耦合导致自信正确动作更新小、不确定动作更新大而不稳定。

Method: EMPG框架基于步骤不确定性和最终任务结果重新校准学习信号：放大自信正确动作的更新，惩罚自信错误，衰减不确定步骤的更新以稳定探索，并引入未来清晰度奖励项。

Result: 在WebShop、ALFWorld和Deep Search三个挑战性智能体任务上的实验表明，EMPG实现了显著的性能提升，显著优于强策略梯度基线方法。

Conclusion: EMPG通过解耦策略梯度与熵的耦合关系，有效解决了长时程任务中的信用分配和学习稳定性问题，为LLM智能体的强化学习提供了新的解决方案。

Abstract: In long-horizon tasks, recent agents based on Large Language Models (LLMs)
face a significant challenge that sparse, outcome-based rewards make it
difficult to assign credit to intermediate steps. Previous methods mainly focus
on creating dense reward signals to guide learning, either through traditional
reinforcement learning techniques like inverse reinforcement learning or by
using Process Reward Models for step-by-step feedback. In this paper, we
identify a fundamental problem in the learning dynamics of LLMs: the magnitude
of policy gradients is inherently coupled with the entropy, which leads to
inefficient small updates for confident correct actions and potentially
destabilizes large updates for uncertain ones. To resolve this, we propose
Entropy-Modulated Policy Gradients (EMPG), a framework that re-calibrates the
learning signal based on step-wise uncertainty and the final task outcome. EMPG
amplifies updates for confident correct actions, penalizes confident errors,
and attenuates updates from uncertain steps to stabilize exploration. We
further introduce a bonus term for future clarity that encourages agents to
find more predictable solution paths. Through comprehensive experiments on
three challenging agent tasks, WebShop, ALFWorld, and Deep Search, we
demonstrate that EMPG achieves substantial performance gains and significantly
outperforms strong policy gradient baselines. Project page is at
https://empgseed-seed.github.io/

</details>


### [54] [LLMs Don't Know Their Own Decision Boundaries: The Unreliability of Self-Generated Counterfactual Explanations](https://arxiv.org/abs/2509.09396)
*Harry Mayne,Ryan Othniel Kearns,Yushi Yang,Andrew M. Bean,Eoin Delaney,Chris Russell,Adam Mahdi*

Main category: cs.LG

TL;DR: 语言模型生成的反事实解释(SCEs)在有效性和最小化之间存在明显的军争，无法提供可靠的解释工具


<details>
  <summary>Details</summary>
Motivation: 研究语言模型如何通过自我生成的反事实解释来向人类解释其决策，以提高协作效果

Method: 评估LLMs生成反事实解释的有效性(达到预期结果)和最小化(最少修改)程度，在多个LLMs、数据集和评估设置下进行实验

Result: 发现LLMs生成的反事实解释通常有效但远不最小化，而当要求最小化时又修改过少导致预测失败，存在明显的有效性-最小化军争

Conclusion: 自我生成的反事实解释最好情况下是无效的解释工具，最坏情况下可能会提供误导性见解，在重要场景中部署LLMs必须考虑不可靠自我解释的影响

Abstract: To collaborate effectively with humans, language models must be able to
explain their decisions in natural language. We study a specific type of
self-explanation: self-generated counterfactual explanations (SCEs), where a
model explains its prediction by modifying the input such that it would have
predicted a different outcome. We evaluate whether LLMs can produce SCEs that
are valid, achieving the intended outcome, and minimal, modifying the input no
more than necessary. When asked to generate counterfactuals, we find that LLMs
typically produce SCEs that are valid, but far from minimal, offering little
insight into their decision-making behaviour. Worryingly, when asked to
generate minimal counterfactuals, LLMs typically make excessively small edits
that fail to change predictions. The observed validity-minimality trade-off is
consistent across several LLMs, datasets, and evaluation settings. Our findings
suggest that SCEs are, at best, an ineffective explainability tool and, at
worst, can provide misleading insights into model behaviour. Proposals to
deploy LLMs in high-stakes settings must consider the impact of unreliable
self-explanations on downstream decision-making. Our code is available at
https://github.com/HarryMayne/SCEs.

</details>


### [55] [ButterflyQuant: Ultra-low-bit LLM Quantization through Learnable Orthogonal Butterfly Transforms](https://arxiv.org/abs/2509.09679)
*Bingxin Xu,Zhen Dong,Oussama Elachqar,Yuzhang Shang*

Main category: cs.LG

TL;DR: ButterflyQuant是一种新的2位量化方法，通过可学习的蝴蝶变换替代固定Hadamard变换，自适应处理不同层的异常值，显著提升大语言模型在低精度量化下的性能。


<details>
  <summary>Details</summary>
Motivation: 现有旋转方法使用固定的Hadamard变换无法适应不同Transformer层的特定异常值模式，导致极端2位量化时性能严重下降。

Method: 提出可学习的蝴蝶变换，使用连续Givens旋转角度参数化，保证正交性同时支持梯度优化；引入均匀性正则化促进平滑分布；仅需128个校准样本和单GPU几分钟训练。

Result: 在LLaMA-2-7B模型上，2位量化时ButterflyQuant达到15.4困惑度，优于QuaRot的22.1困惑度。

Conclusion: ButterflyQuant通过层自适应旋转变换有效抑制异常值，在极低精度量化下保持模型性能，计算复杂度为O(n log n)，参数效率高。

Abstract: Large language models require massive memory footprints, severely limiting
deployment on consumer hardware. Quantization reduces memory through lower
numerical precision, but extreme 2-bit quantization suffers from catastrophic
performance loss due to outliers in activations. Rotation-based methods such as
QuIP and QuaRot apply orthogonal transforms to eliminate outliers before
quantization, using computational invariance: $\mathbf{y} = \mathbf{Wx} =
(\mathbf{WQ}^T)(\mathbf{Qx})$ for orthogonal $\mathbf{Q}$. However, these
methods use fixed transforms--Hadamard matrices achieving optimal worst-case
coherence $\mu = 1/\sqrt{n}$--that cannot adapt to specific weight
distributions. We identify that different transformer layers exhibit distinct
outlier patterns, motivating layer-adaptive rotations rather than
one-size-fits-all approaches. We propose ButterflyQuant, which replaces
Hadamard rotations with learnable butterfly transforms parameterized by
continuous Givens rotation angles. Unlike Hadamard's discrete $\{+1, -1\}$
entries that are non-differentiable and prohibit gradient-based learning,
butterfly transforms' continuous parameterization enables smooth optimization
while guaranteeing orthogonality by construction. This orthogonal constraint
ensures theoretical guarantees in outlier suppression while achieving $O(n \log
n)$ computational complexity with only $\frac{n \log n}{2}$ learnable
parameters. We further introduce a uniformity regularization on
post-transformation activations to promote smoother distributions amenable to
quantization. Learning requires only 128 calibration samples and converges in
minutes on a single GPU--a negligible one-time cost. On LLaMA-2-7B with 2-bit
quantization, ButterflyQuant achieves 15.4 perplexity versus 22.1 for QuaRot.

</details>
