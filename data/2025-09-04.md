<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 28]
- [cs.LG](#cs.LG) [Total: 1]
- [cs.SD](#cs.SD) [Total: 1]
- [cs.AI](#cs.AI) [Total: 2]
- [cs.CV](#cs.CV) [Total: 1]
- [quant-ph](#quant-ph) [Total: 1]
- [cs.CY](#cs.CY) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [DrDiff: Dynamic Routing Diffusion with Hierarchical Attention for Breaking the Efficiency-Quality Trade-off](https://arxiv.org/abs/2509.02785)
*Jusheng Zhang,Yijia Fan,Kaitong Cai,Zimeng Huang,Xiaofei Sun,Jian Wang,Chengpei Tang,Keze Wang*

Main category: cs.CL

TL;DR: DrDiff是一个新颖的长文本生成框架，通过动态专家调度、分层稀疏注意力和软吸收引导优化三项核心技术，解决了效率与质量之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 解决长文本生成中效率与质量之间的权衡问题，传统方法在处理不同难度和长度的文本时计算效率低下。

Method: 1. 动态专家调度机制：根据文本复杂度智能分配计算资源；2. 分层稀疏注意力机制：将计算复杂度从O(n²)降低到O(n)；3. 软吸收引导优化策略：结合DPM-solver++减少扩散步骤。

Result: 在各种长文本生成基准测试中，DrDiff优于现有的最先进方法，证明了其优越性。

Conclusion: DrDiff框架通过三项创新技术有效解决了长文本生成的效率-质量权衡问题，在保持模型性能的同时显著提高了生成速度。

Abstract: This paper introduces DrDiff, a novel framework for long-text generation that
overcomes the efficiency-quality trade-off through three core technologies.
First, we design a dynamic expert scheduling mechanism that intelligently
allocates computational resources during the diffusion process based on text
complexity, enabling more efficient handling of text generation tasks of
varying difficulty. Second, we introduce a Hierarchical Sparse Attention (HSA)
mechanism that adaptively adjusts attention patterns according to a variety of
input lengths, reducing computational complexity from O($n^2$) to O($n$) while
maintaining model performance. Finally, we propose a soft absorption guidance
optimization strategy that combines with DPM-solver++ to reduce diffusion
steps, significantly improving generation speed. Comprehensive experiments on
various long-text generation benchmarks demonstrate the superiority of our
DrDiff over the existing SOTA methods.

</details>


### [2] [SSVD: Structured SVD for Parameter-Efficient Fine-Tuning and Benchmarking under Domain Shift in ASR](https://arxiv.org/abs/2509.02830)
*Pu Wang,Shinji Watanabe,Hugo Van hamme*

Main category: cs.CL

TL;DR: 本文首次将多种先进的参数高效微调方法（VeRA、DoRA、PiSSA、SVFT）集成到ESPnet中，并针对语音识别任务进行基准测试，同时提出了新的结构化SVD引导微调方法SSVD。


<details>
  <summary>Details</summary>
Motivation: 现有的先进PEFT方法主要针对语言和视觉任务开发，在语音应用中的验证有限，特别是LoRA及其变体在语音任务中的表现需要系统评估。

Method: 提出了结构化SVD引导微调（SSVD），选择性地旋转输入相关的右奇异向量，同时固定输出相关向量以保持语义映射；在ESPnet中集成了多种PEFT方法并进行基准测试。

Result: 在领域偏移的语音识别任务（包括儿童语音和方言变体）上进行了评估，模型规模从0.1B到2B，所有实现已在ESPnet中发布。

Conclusion: SSVD方法能够以最少的可训练参数实现鲁棒的领域适应，提高了效率，为语音任务的参数高效微调提供了全面的基准和工具支持。

Abstract: Parameter-efficient fine-tuning (PEFT) has emerged as a scalable solution for
adapting large foundation models. While low-rank adaptation (LoRA) is widely
used in speech applications, its state-of-the-art variants, e.g., VeRA, DoRA,
PiSSA, and SVFT, are developed mainly for language and vision tasks, with
limited validation in speech. This work presents the first comprehensive
integration and benchmarking of these PEFT methods within ESPnet. We further
introduce structured SVD-guided (SSVD) fine-tuning, which selectively rotates
input-associated right singular vectors while keeping output-associated vectors
fixed to preserve semantic mappings. This design enables robust domain
adaptation with minimal trainable parameters and improved efficiency. We
evaluate all methods on domain-shifted speech recognition tasks, including
child speech and dialectal variation, across model scales from 0.1B to 2B. All
implementations are released in ESPnet to support reproducibility and future
work.

</details>


### [3] [Clustering Discourses: Racial Biases in Short Stories about Women Generated by Large Language Models](https://arxiv.org/abs/2509.02834)
*Gustavo Bonil,João Gondim,Marina dos Santos,Simone Hashiguti,Helena Maia,Nadia Silva,Helio Pedrini,Sandra Avila*

Main category: cs.CL

TL;DR: LLaMA 3.2-3B生成葡萄牙语短篇小说中关于黑人和白人女性的叙事分析，揭示了三种主要话语表征模式，显示看似中立的文本实际上强化了殖民结构化的性别不平等


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型如何构建关于不同种族女性的叙事，特别是LLaMA 3.2-3B在葡萄牙语短篇小说生成中是否存在殖民化、结构化的性别偏见

Method: 从2100篇生成文本中应用计算方法进行语义相似性分组，结合机器学习技术与人工话语分析的整合方法进行定性分析

Result: 识别出三种主要话语表征：社会克服、祖先神话化和主观自我实现，发现语法连贯的文本实际上体现了固化的、殖民结构化的女性身体框架

Conclusion: 研究揭示了看似中立的AI生成文本实际上强化了历史不平等，提出了结合计算方法和定性分析的整合研究框架

Abstract: This study investigates how large language models, in particular LLaMA
3.2-3B, construct narratives about Black and white women in short stories
generated in Portuguese. From 2100 texts, we applied computational methods to
group semantically similar stories, allowing a selection for qualitative
analysis. Three main discursive representations emerge: social overcoming,
ancestral mythification and subjective self-realization. The analysis uncovers
how grammatically coherent, seemingly neutral texts materialize a crystallized,
colonially structured framing of the female body, reinforcing historical
inequalities. The study proposes an integrated approach, that combines machine
learning techniques with qualitative, manual discourse analysis.

</details>


### [4] [IDEAlign: Comparing Large Language Models to Human Experts in Open-ended Interpretive Annotations](https://arxiv.org/abs/2509.02855)
*Hyunji Nam,Lucia Langlois,James Malamut,Mei Tan,Dorottya Demszky*

Main category: cs.CL

TL;DR: 这篇论文提出IDEAlgin方法，通过"选出异类"三元组判断任务来评估LLM生成的解释性注释与人类专家的相似度，解决了开放式注释任务的可扩展评估问题。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在开放式解释性注释任务中的应用增多，需要一种可扩展的方法来评估LLM生成注释与人类专家的相似度，而目前缺乏有效的可扩展测量方法。

Method: 提出IDEAlgin方法，通过"选出异类"三元组判断任务收集人类专家的相似性评分，并评估各种相似性指标（包括矢量基方法和LLM作为判断员）与人类评分的一致性。

Result: 在两个教育数据集上，矢量基方法大多数时无法抓取专家所认为有意义的细致相似性维度。使用IDEAlgin方法的LLM在与人类专家判断的一致性上显著提高（9-30%增长），远超传统词法和矢量基方法。

Conclusion: IDEAlgin作为一种有前景的评估范式，能够在大规模下评估LLM在开放式专家注释任务上的表现，为教育等领域的LLM负责任部署提供指导。

Abstract: Large language models (LLMs) are increasingly applied to open-ended,
interpretive annotation tasks, such as thematic analysis by researchers or
generating feedback on student work by teachers. These tasks involve free-text
annotations requiring expert-level judgments grounded in specific objectives
(e.g., research questions or instructional goals). Evaluating whether
LLM-generated annotations align with those generated by expert humans is
challenging to do at scale, and currently, no validated, scalable measure of
similarity in ideas exists. In this paper, we (i) introduce the scalable
evaluation of interpretive annotation by LLMs as a critical and understudied
task, (ii) propose IDEAlgin, an intuitive benchmarking paradigm for capturing
expert similarity ratings via a "pick-the-odd-one-out" triplet judgment task,
and (iii) evaluate various similarity metrics, including vector-based ones
(topic models, embeddings) and LLM-as-a-judge via IDEAlgin, against these human
benchmarks. Applying this approach to two real-world educational datasets
(interpretive analysis and feedback generation), we find that vector-based
metrics largely fail to capture the nuanced dimensions of similarity meaningful
to experts. Prompting LLMs via IDEAlgin significantly improves alignment with
expert judgments (9-30% increase) compared to traditional lexical and
vector-based metrics. These results establish IDEAlgin as a promising paradigm
for evaluating LLMs against open-ended expert annotations at scale, informing
responsible deployment of LLMs in education and beyond.

</details>


### [5] [A-SEA3L-QA: A Fully Automated Self-Evolving, Adversarial Workflow for Arabic Long-Context Question-Answer Generation](https://arxiv.org/abs/2509.02864)
*Kesen Wang,Daulet Toibazar,Pedro J. Moreno*

Main category: cs.CL

TL;DR: 自动化阻振工作流，通过多个专门的大视觉语言模型协同工作，实现防止汉语长文档QA生成的迭代精炼和持续学习。


<details>
  <summary>Details</summary>
Motivation: 解决防止汉语长文档问答生成中的挑战，需要一种能够自动评估和改进质量的结构化方法。

Method: 使用问题生成器、评估器和答案生成器群组成的巡航式系统，通过闭环循环进行迭代精炼，并将质量指标设置为可调超参数。

Result: 系统显著超越了静态流水线，大大提升了阿拉伯大视觉语言模型的长上下文理解能力，并发布了AraLongBench大规模防止汉諸基准测试集。

Conclusion: 该自成长阻振工作流为阿拉伯语言的长文档理解设置了新标准，并通过完全自动化的文档收集流程强化了其可扩展性。

Abstract: We present an end-to-end, self-evolving adversarial workflow for long-context
Question-Answer (QA) Generation in Arabic. By orchestrating multiple
specialized LVLMs: a question generator, an evaluator, and a swarm of answer
generators, our system iteratively refines its own performance without any
human intervention. Starting from raw, multi-page Arabic documents across
diverse domains, the question generator produces fine-grained, context-aware
queries to be tackled by the answer generator swarm, and the evaluator assesses
and feeds back quality metrics. This closed-loop cycle enables continuous
learning: low-confidence outputs trigger automated re-generation and model
updates, progressively enhancing question difficulty and relevance. Moreover,
we set the quality metrics as a tunable hyperparameter, enabling question
generation at controllable and customizable difficulty levels. We release
AraLongBench, a large-scale Arabic benchmark of single- and multi-page
challenges spanning hundreds of pages, and demonstrate that our self-evolving
workflow substantially outperform static pipelines, markedly boosting the
long-context comprehension capabilities of leading Arabic Large Vision Language
Models (LVLMs). Lastly, we also meticulously architect a fully automated
agentic workflow for long-context Arabic document collection.

</details>


### [6] [Advancing Minority Stress Detection with Transformers: Insights from the Social Media Datasets](https://arxiv.org/abs/2509.02908)
*Santosh Chapagain,Cory J Cascalheira,Shah Muhammad Hamdi,Soukaina Filali Boubrahimi,Jillian R. Scheer*

Main category: cs.CL

TL;DR: 本研究首次全面评估基于Transformer的架构在在线话语中检测少数群体压力的能力，发现图结构增强的Transformer模型在检测性能上表现最佳，优于传统方法和零样本/少样本学习。


<details>
  <summary>Details</summary>
Motivation: 性少数群体因少数群体压力而面临更高的健康问题和心理障碍风险，需要开发有效的方法来在线检测这种压力，为数字健康干预和公共政策提供支持。

Method: 使用ELECTRA、BERT、RoBERTa、BART等Transformer模型与传统机器学习基线及图增强变体进行对比，评估零样本和少样本学习范式，在两个最大的公开Reddit语料库上进行实验。

Result: 图结构整合持续提升Transformer模型的检测性能，有监督微调加关系上下文的方法优于零样本和少样本方法，能够更准确地识别身份隐藏、内化污名和求助等关键语言标记。

Conclusion: 图增强的Transformer模型为数字健康干预和公共健康政策提供了最可靠的基础，通过建模社会连接和对话上下文来提升少数群体压力检测能力。

Abstract: Individuals from sexual and gender minority groups experience
disproportionately high rates of poor health outcomes and mental disorders
compared to their heterosexual and cisgender counterparts, largely as a
consequence of minority stress as described by Meyer's (2003) model. This study
presents the first comprehensive evaluation of transformer-based architectures
for detecting minority stress in online discourse. We benchmark multiple
transformer models including ELECTRA, BERT, RoBERTa, and BART against
traditional machine learning baselines and graph-augmented variants. We further
assess zero-shot and few-shot learning paradigms to assess their applicability
on underrepresented datasets. Experiments are conducted on the two largest
publicly available Reddit corpora for minority stress detection, comprising
12,645 and 5,789 posts, and are repeated over five random seeds to ensure
robustness. Our results demonstrate that integrating graph structure
consistently improves detection performance across transformer-only models and
that supervised fine-tuning with relational context outperforms zero and
few-shot approaches. Theoretical analysis reveals that modeling social
connectivity and conversational context via graph augmentation sharpens the
models' ability to identify key linguistic markers such as identity
concealment, internalized stigma, and calls for support, suggesting that
graph-enhanced transformers offer the most reliable foundation for digital
health interventions and public health policy.

</details>


### [7] [English Pronunciation Evaluation without Complex Joint Training: LoRA Fine-tuned Speech Multimodal LLM](https://arxiv.org/abs/2509.02915)
*Taekyung Ahn,Hosung Nam*

Main category: cs.CL

TL;DR: 使用LoRA微调的多模态大语言模型可同时进行发音自动评估和错误检测诊断，无需复杂架构修改，性能与传统全参数微调相当。


<details>
  <summary>Details</summary>
Motivation: 传统发音评估系统需要为APA和MDD两个不同任务设计复杂架构和单独训练流程，研究旨在开发更简单高效的集成解决方案。

Method: 基于Microsoft Phi-4-multimodal-instruct模型，采用LoRA低秩适应微调方法，在Speechocean762数据集上进行训练，仅微调LoRA层而不修改全部音频层。

Result: 模型预测的发音评分与人工评分具有强相关性(PCC>0.7)，词错误率和音素错误率均低于0.15，LoRA微调性能与全参数微调相当。

Conclusion: LoRA方法为构建集成发音评估系统提供了更简单高效的途径，无需完整微调即可实现多模态大模型的适应，推动了计算机辅助发音训练技术的发展。

Abstract: This study demonstrates that a Multimodal Large Language Model (MLLM) adapted
via Low-Rank Adaptation (LoRA) can perform both Automatic Pronunciation
Assessment (APA) and Mispronunciation Detection and Diagnosis (MDD)
simultaneously. Leveraging Microsoft's Phi-4-multimodal-instruct, our
fine-tuning method eliminates the need for complex architectural changes or
separate training procedures conventionally required for these distinct tasks.
Fine-tuned on the Speechocean762 dataset, the pronunciation evaluation scores
predicted by the model exhibited a strong Pearson Correlation Coefficient (PCC
> 0.7) with human-assigned scores, while achieving low Word Error Rate (WER)
and Phoneme Error Rate (PER) (both < 0.15). Notably, fine-tuning only the LoRA
layers was sufficient to achieve performance levels comparable to those
achieved by fine-tuning all audio layers. This research highlights that an
integrated pronunciation assessment system can be established by adapting large
multimodal models without full fine-tuning, utilizing a significantly simpler
training methodology compared to previous joint models designed for
simultaneous APA and MDD. This efficient LoRA-based approach paves the way for
more accessible, integrated, and effective Computer-Assisted Pronunciation
Training (CAPT) technologies for English L2 learners.

</details>


### [8] [Decoding the Rule Book: Extracting Hidden Moderation Criteria from Reddit Communities](https://arxiv.org/abs/2509.02926)
*Youngwoo Kim,Himanshu Beniwal,Steven L. Johnson,Thomas Hartvigsen*

Main category: cs.CL

TL;DR: 这篇论文提出了一种解释性的语言模型方法，从历史调解数据中提取网络社区的隐式调解标准，通过词汇表现形式实现可解释的内容审查。


<details>
  <summary>Details</summary>
Motivation: 线上社区如subreddits通常使用多样化的隐式标准进行内容调解，缺乏明确的分类标准，需要一种方法来识别和提取这些隐式标准以支持有效的内容审查系统。

Method: 使用解释性架构从历史调解数据中提取隐式标准，将调解标准表示为与内容删除相关联的词汇表达式的分数表，支持不同社区之间的系统性比较。

Result: 实验表明，提取的词汇模式能够有效复现神经网络调解模型的性能，同时提供透明的决策见解。标准矩阵揭示了表面共享规范在不同社区的实际执行差异，发现了以前未文档化的调解模式。

Conclusion: 该方法能够提取网络社区的隐式调解标准，在保持神经网络模型性能的同时提供了解释性和透明度，为跨社区调解实践的研究提供了新的视角和工具。

Abstract: Effective content moderation systems require explicit classification
criteria, yet online communities like subreddits often operate with diverse,
implicit standards. This work introduces a novel approach to identify and
extract these implicit criteria from historical moderation data using an
interpretable architecture. We represent moderation criteria as score tables of
lexical expressions associated with content removal, enabling systematic
comparison across different communities. Our experiments demonstrate that these
extracted lexical patterns effectively replicate the performance of neural
moderation models while providing transparent insights into decision-making
processes. The resulting criteria matrix reveals significant variations in how
seemingly shared norms are actually enforced, uncovering previously
undocumented moderation patterns including community-specific tolerances for
language, features for topical restrictions, and underlying subcategories of
the toxic speech classification.

</details>


### [9] [ProMQA-Assembly: Multimodal Procedural QA Dataset on Assembly](https://arxiv.org/abs/2509.02949)
*Kimihiro Hasegawa,Wiradee Imrattanatrai,Masaki Asada,Susan Holm,Yuran Wang,Vincent Zhou,Ken Fukuda,Teruko Mitamura*

Main category: cs.CL

TL;DR: 提出了一个新的多模态问答数据集ProMQA-Assembly，用于评估装配活动中的助手系统，包含391个QA对，需要理解人类活动记录和说明书。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏支持应用导向系统评估的测试平台，特别是在装配任务中，需要促进相关技术的发展。

Method: 采用半自动QA标注方法，使用LLM生成候选问题并由人工验证，整合细粒度动作标签来多样化问题类型，创建指令任务图来辅助标注和基准测试。

Result: 基准测试显示当前多模态模型仍有很大改进空间，包括竞争性专有模型。

Conclusion: 新的评估数据集可以促进程序性活动助手系统的进一步发展。

Abstract: Assistants on assembly tasks have a large potential to benefit humans from
everyday tasks to industrial settings. However, no testbeds support
application-oriented system evaluation in a practical setting, especially in
assembly. To foster the development, we propose a new multimodal QA dataset on
assembly activities. Our dataset, ProMQA-Assembly, consists of 391 QA pairs
that require the multimodal understanding of human-activity recordings and
their instruction manuals in an online-style manner. In the development, we
adopt a semi-automated QA annotation approach, where LLMs generate candidates
and humans verify them, as a cost-effective method, and further improve it by
integrating fine-grained action labels to diversify question types.
Furthermore, we create instruction task graphs for the target tasks of
assembling toy vehicles. These newly created task graphs are used in our
benchmarking experiment, as well as to facilitate the human verification
process in the QA annotation. Utilizing our dataset, we benchmark models,
including competitive proprietary multimodal models. Our results suggest great
room for improvement for the current models. We believe our new evaluation
dataset can contribute to the further development of procedural-activity
assistants.

</details>


### [10] [DiaCBT: A Long-Periodic Dialogue Corpus Guided by Cognitive Conceptualization Diagram for CBT-based Psychological Counseling](https://arxiv.org/abs/2509.02999)
*Yougen Zhou,Ningning Zhou,Qin Chen,Jie Zhou,Aimin Zhou,Liang He*

Main category: cs.CL

TL;DR: 这篇论文构建了一个基于认知行为疗法(CBT)的长周期心理咨询对话语料库DiaCBT，用于训练更专业的心理咨询模型。


<details>
  <summary>Details</summary>
Motivation: 心理治疗遍及率低，大语言模型有潜力扩大心理健康服务的可及性，但缺乏专业的心理对话数据集。

Method: 构建包含多个咨询会议的长周期对话语料库，结合认知概念图(CCDs)来指导客户模拟，训练深度咨询模型并设计综合评估框架。

Result: DiaCBT有效提升了大语言模型模仿CBT专业心理治疗师的能力，证明了该数据集在训练专业咨询模型方面的潜力。

Conclusion: 该研究为开发更专业的心理咨询对话机器人提供了重要的数据支撑和评估方法，有助于扩大心理健康服务的可及性。

Abstract: Psychotherapy reaches only a small fraction of individuals suffering from
mental disorders due to social stigma and the limited availability of
therapists. Large language models (LLMs), when equipped with professional
psychotherapeutic skills, offer a promising solution to expand access to mental
health services. However, the lack of psychological conversation datasets
presents significant challenges in developing effective psychotherapy-guided
conversational agents. In this paper, we construct a long-periodic dialogue
corpus for counseling based on cognitive behavioral therapy (CBT). Our curated
dataset includes multiple sessions for each counseling and incorporates
cognitive conceptualization diagrams (CCDs) to guide client simulation across
diverse scenarios. To evaluate the utility of our dataset, we train an in-depth
counseling model and present a comprehensive evaluation framework to benchmark
it against established psychological criteria for CBT-based counseling. Results
demonstrate that DiaCBT effectively enhances LLMs' ability to emulate
psychologists with CBT expertise, underscoring its potential for training more
professional counseling agents.

</details>


### [11] [Mitigating Data Imbalance in Automated Speaking Assessment](https://arxiv.org/abs/2509.03010)
*Fong-Chun Tsai,Kuan-Tang Huang,Bi-Cheng Yan,Tien-Hong Lo,Berlin Chen*

Main category: cs.CL

TL;DR: 通过提出新的BLV损失函数，解决自动说话评估中的类别不平衡问题，提升少数类的分类准确性和公平性


<details>
  <summary>Details</summary>
Motivation: 自动说话评估(ASA)模型遇到类别不平衡问题，导致偏见预测，影响对第二语言学习者技能水平的公正评估

Method: 提出平衡逻达变异(BLV)损失函数，通过干扰模型预测来改善少数类的特征表征，无需修改数据集

Result: 在ICNALE标准数据集上，将BLV损失集成到BERT模型中显著提升了分类准确性和公平性

Conclusion: BLV损失函数能够有效解决ASA模型的类别不平衡问题，使自动语音评估更加稳健适用于多样化的学习者

Abstract: Automated Speaking Assessment (ASA) plays a crucial role in evaluating
second-language (L2) learners proficiency. However, ASA models often suffer
from class imbalance, leading to biased predictions. To address this, we
introduce a novel objective for training ASA models, dubbed the Balancing Logit
Variation (BLV) loss, which perturbs model predictions to improve feature
representation for minority classes without modifying the dataset. Evaluations
on the ICNALE benchmark dataset show that integrating the BLV loss into a
celebrated text-based (BERT) model significantly enhances classification
accuracy and fairness, making automated speech evaluation more robust for
diverse learners.

</details>


### [12] [Training LLMs to be Better Text Embedders through Bidirectional Reconstruction](https://arxiv.org/abs/2509.03020)
*Chang Su,Dengliang Shi,Siyuan Huang,Jintao Du,Changhua Meng,Yu Cheng,Weiqiang Wang,Zhouhan Lin*

Main category: cs.CL

TL;DR: 通过新增双向生成重建训练阶段，改善LLM中[EOS]引导的文本嵌入质量，在MTEB基准上创造新的SOTA结果


<details>
  <summary>Details</summary>
Motivation: 现有LLM文本嵌入方法使用末尾特殊标记（如[EOS]）的嵌入，但这些标记未经过敏感训练来捐捕整个上下文的语义，限制了在检索和重排序任务中的性能

Method: 在对比学习前添加新的训练阶段，采用双向生成重建任务（EBQ2D和EBD2Q），通过交替锚定[EOS]嵌入并重建查询-文档对的两端

Result: 这个额外的训练阶段显著提高了LLM在大规模文本嵌入基准（MTEB）上的性能，在不同的LLM基础模型和规模下都达到了新的最高水平

Conclusion: 通过专门的双向生成重建训练，可以有效丰富最终标记嵌入的语义表达能力，从而提升LLM作为文本嵌入器的性能

Abstract: Large language models (LLMs) have increasingly been explored as powerful text
embedders. Existing LLM-based text embedding approaches often leverage the
embedding of the final token, typically a reserved special token such as [EOS].
However, these tokens have not been intentionally trained to capture the
semantics of the whole context, limiting their capacity as text embeddings,
especially for retrieval and re-ranking tasks. We propose to add a new training
stage before contrastive learning to enrich the semantics of the final token
embedding. This stage employs bidirectional generative reconstruction tasks,
namely EBQ2D (Embedding-Based Query-to-Document) and EBD2Q (Embedding-Based
Document-to-Query), which interleave to anchor the [EOS] embedding and
reconstruct either side of Query-Document pairs. Experimental results
demonstrate that our additional training stage significantly improves LLM
performance on the Massive Text Embedding Benchmark (MTEB), achieving new
state-of-the-art results across different LLM base models and scales.

</details>


### [13] [Structure-Learnable Adapter Fine-Tuning for Parameter-Efficient Large Language Models](https://arxiv.org/abs/2509.03057)
*Ming Gong,Yingnan Deng,Nia Qi,Yujun Zou,Zhihao Xue,Yun Zi*

Main category: cs.CL

TL;DR: 提出基于结构可学习机制的自适应适配器微调方法，通过可微分门控函数和结构稀疏性控制变量，自动优化适配器插入点、激活路径和模块组合，在多任务场景下实现灵活结构调节。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型微调中存在的参数冗余、结构僵化和任务适应性有限的问题，提高参数利用效率和表示能力。

Method: 采用适配器微调方法，引入可微分门控函数和结构稀疏性控制变量，通过结构搜索机制动态构建任务特定的高效子结构，同时保持主干参数冻结。

Result: 在多个多任务自然语言理解任务上优于主流参数高效调优技术，在准确性、压缩率以及对噪声和扰动的鲁棒性之间实现了更好的平衡。

Conclusion: 所提出的方法通过结构可学习机制实现了高效的适配器微调，具有优异的性能表现和鲁棒性，为多任务学习提供了有效的解决方案。

Abstract: This paper addresses the issues of parameter redundancy, rigid structure, and
limited task adaptability in the fine-tuning of large language models. It
proposes an adapter-based fine-tuning method built on a structure-learnable
mechanism. By introducing differentiable gating functions and structural
sparsity control variables, the method enables automatic optimization of
adapter insertion points, activation paths, and module combinations. This
allows the model to adjust its structure flexibly in multi-task settings to
match different task characteristics. With the backbone parameters kept frozen,
the method uses a structure search mechanism to guide the dynamic construction
of task-specific efficient substructures during training. This significantly
improves parameter utilization and representational capacity. In addition, the
paper designs a set of sensitivity analysis experiments to systematically
evaluate the effects of sparsity weight, noise injection ratio, and data
perturbation on model performance. These experiments verify the stability and
robustness of the proposed method across various multi-task natural language
understanding tasks. The experimental results show that the proposed method
outperforms mainstream parameter-efficient tuning techniques on multiple tasks.
It achieves a better balance among accuracy, compression rate, and robustness
to noise and perturbation.

</details>


### [14] [A Long Short-Term Memory (LSTM) Model for Business Sentiment Analysis Based on Recurrent Neural Network](https://arxiv.org/abs/2509.03060)
*Md. Jahidul Islam Razin,Md. Abdul Karim,M. F. Mridha,S M Rafiuddin,Tahira Alam*

Main category: cs.CL

TL;DR: 本文应用修改的LSTM模型进行商业情感分析，在产品评论数据集上达到91.33%的准确率，显著超过传统RNN模型。


<details>
  <summary>Details</summary>
Motivation: 商业情感分析在自然语言处理领域具有重要意义，但传统RNN模型存在渐消梯度问题，需要更有效的方法来提升性能。

Method: 采用长短期记忆网络(LSTM)作为修改的递归神经网络模型，使用70%数据进行训练，30%数据进行测试，并与其他传统RNN模型进行比较。

Result: 提出的修改RNN模型达到了91.33%的准确率，表现明显超过传统RNN模型，有效解决了渐消梯度问题。

Conclusion: LSTM模型在商业情感分析中具有良好效果，可以帮助企业根据客户评论评估营销策略，提升业务决策能力。

Abstract: Business sentiment analysis (BSA) is one of the significant and popular
topics of natural language processing. It is one kind of sentiment analysis
techniques for business purposes. Different categories of sentiment analysis
techniques like lexicon-based techniques and different types of machine
learning algorithms are applied for sentiment analysis on different languages
like English, Hindi, Spanish, etc. In this paper, long short-term memory (LSTM)
is applied for business sentiment analysis, where a recurrent neural network is
used. An LSTM model is used in a modified approach to prevent the vanishing
gradient problem rather than applying the conventional recurrent neural network
(RNN). To apply the modified RNN model, product review dataset is used. In this
experiment, 70\% of the data is trained for the LSTM and the rest 30\% of the
data is used for testing. The result of this modified RNN model is compared
with other conventional RNN models, and a comparison is made among the results.
It is noted that the proposed model performs better than the other conventional
RNN models. Here, the proposed model, i.e., the modified RNN model approach has
achieved around 91.33\% of accuracy. By applying this model, any business
company or e-commerce business site can identify the feedback from their
customers about different types of products that customers like or dislike.
Based on the customer reviews, a business company or e-commerce platform can
evaluate its marketing strategy.

</details>


### [15] [Measuring Scalar Constructs in Social Science with LLMs](https://arxiv.org/abs/2509.03116)
*Hauke Licht,Rupak Sarkar,Patrick Y. Wu,Pranav Goel,Niklas Stoehr,Elliott Ash,Alexander Miserlis Hoyle*

Main category: cs.CL

TL;DR: 本文系统评估了LLM在社会科学中测量标量构念的四种方法，发现基于token概率加权的点评分方法效果最佳，小模型微调也能达到或超越提示LLM的性能


<details>
  <summary>Details</summary>
Motivation: 语言构念如复杂性、情感性等具有连续语义结构，LLM虽然适合测量这类标量构念，但其数值输出处理存在特殊性，需要系统评估最佳应用方法

Method: 使用政治科学文献的多个数据集，评估四种方法：未加权直接点评分、成对比较聚合、token概率加权点评分、以及微调方法

Result: 直接提示LLM生成点评分会产生不连续分布；成对比较能改善测量质量；token概率加权点评分效果更好；仅用1000个训练对微调小模型就能匹配或超越提示LLM性能

Conclusion: 为应用研究者提供了实用建议：推荐使用token概率加权点评分方法，小模型微调是经济有效的替代方案，能够产生更高质量的标量构念测量

Abstract: Many constructs that characterize language, like its complexity or
emotionality, have a naturally continuous semantic structure; a public speech
is not just "simple" or "complex," but exists on a continuum between extremes.
Although large language models (LLMs) are an attractive tool for measuring
scalar constructs, their idiosyncratic treatment of numerical outputs raises
questions of how to best apply them. We address these questions with a
comprehensive evaluation of LLM-based approaches to scalar construct
measurement in social science. Using multiple datasets sourced from the
political science literature, we evaluate four approaches: unweighted direct
pointwise scoring, aggregation of pairwise comparisons,
token-probability-weighted pointwise scoring, and finetuning. Our study yields
actionable findings for applied researchers. First, LLMs prompted to generate
pointwise scores directly from texts produce discontinuous distributions with
bunching at arbitrary numbers. The quality of the measurements improves with
pairwise comparisons made by LLMs, but it improves even more by taking
pointwise scores and weighting them by token probability. Finally, finetuning
smaller models with as few as 1,000 training pairs can match or exceed the
performance of prompted LLMs.

</details>


### [16] [From Evaluation to Defense: Constructing Persistent Edit-Based Fingerprints for Large Language Models](https://arxiv.org/abs/2509.03122)
*Yue Li,Xin Yi,Dongsheng Shi,Yongyi Cui,Gerard de Melo,Xiaoling Wang,Linlin Wang*

Main category: cs.CL

TL;DR: 通过知识编辑技术向大语言模型注入指纹定义智能财产保护，提出FSFT方法减少指纹退化，在大规模完调中保持指纹性能


<details>
  <summary>Details</summary>
Motivation: 传统的指令式指纹注入方法对模型性能影响大、计算成本高且在模型修改后持续性差，需要轻量级的替代方案

Method: 采用知识编辑技术进行指纹注入，使用类似乱码的文本作为指纹防止覆盖，提出Fingerprint Subspace-aware Fine-Tuning (FSFT)方法通过限制指纹子空间更新来减少指纹退化

Result: FSFT方法在最坏情况下也能比普通完调提高10%的性能，但发现注入指纹的模型对类似文本区分能力不足

Conclusion: 知识编辑是一种有效的轻量级指纹注入方法，FSFT能够显著减少指纹退化，但仍需要更加稳健和细粒度的指纹注入方法

Abstract: The intellectual property (IP) protection of Large Language Models (LLMs) is
increasingly critical. Injecting specialized fingerprints into LLMs through
instruction tuning is a common IP protection technique. However, this may
significantly degrade model performance, requires substantial computational
resources, and exhibits poor persistence under model modifications. We argue
that knowledge editing offers a lightweight alternative that is more suitable
for fingerprint injection. Accordingly, we apply knowledge editing to
fingerprint injection for the first time and demonstrate its strong capability.
Despite using scrambled text as fingerprints to prevent them from being
overwritten during fine-tuning, degradation still occurs under large-scale
fine-tuning. To address this, we propose Fingerprint Subspace-aware Fine-Tuning
(FSFT), which reduces fingerprint degradation by constraining the update of the
fingerprint subspace. The performance of FSFT exceeds fine-tuning by 10% even
in the worst-case scenario. Additionally, we observe that the
fingerprint-injected models struggle to distinguish between fingerprints and
similar texts due to the high similarity of their features. This finding
underscores the urgent need for more robust and fine-grained fingerprinting
injection methods for LLMs.

</details>


### [17] [An experimental and computational study of an Estonian single-person word naming](https://arxiv.org/abs/2509.03143)
*Kaidi Lõo,Arvi Tavast,Maria Heitmeier,Harald Baayen*

Main category: cs.CL

TL;DR: 本研究通过眼动追踪和命名任务，比较了判别式词典模型(DLM)与传统词汇变量在爱沙尼亚语词汇处理预测中的效果，发现DLM是强有力的预测指标，但深度学习映射并不一定比线性映射更精确，且传统预测因子在某些方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探究计算心理词典模型(DLM)生成的词汇处理测量是否能够预测眼动和命名任务中的反应变量，并与传统的词汇频率、邻域大小等预测因子进行比较。

Method: 采用大规模单被试实验，结合词汇命名任务和眼动追踪技术，分析五个反应变量（首次注视时长、总注视时长、注视次数、命名潜伏期和口语词汇时长），使用广义加性模型进行分析，比较DLM的线性和深度映射模型与传统预测因子的效果。

Result: 主要发现：1) DLM测量是词汇处理的强有力预测指标；2) 深度学习DLM并不比线性映射DLM更精确；3) 传统预测因子在多数情况下拟合精度更高（总注视时长除外）；4) 命名任务中词汇变量对首次注视时长和总注视次数无预测性。

Conclusion: DLM基于形式到意义的映射，其对总注视时长、命名潜伏期和口语时长的预测性表明意义在当前词汇命名任务中起着重要作用，但传统预测因子在某些方面仍具优势。

Abstract: This study investigates lexical processing in Estonian. A large-scale
single-subject experiment is reported that combines the word naming task with
eye-tracking. Five response variables (first fixation duration, total fixation
duration, number of fixations, word naming latency, and spoken word duration)
are analyzed with the generalized additive model. Of central interest is the
question of whether measures for lexical processing generated by a
computational model of the mental lexicon (the Discriminative Lexicon Model,
DLM) are predictive for these response variables, and how they compare to
classical predictors such as word frequency, neighborhood size, and
inflectional paradigm size. Computational models were implemented both with
linear and deep mappings. Central findings are, first, that DLM-based measures
are powerful predictors for lexical processing, second, that DLM-measures using
deep learning are not necessarily more precise predictors of lexical processing
than DLM-measures using linear mappings, third, that classical predictors tend
to provide somewhat more precise fits compared to DLM-based predictors (except
for total fixation duration, where the two provide equivalent goodness of fit),
and fourth, that in the naming task lexical variables are not predictive for
first fixation duration and the total number of fixations. As the DLM works
with mappings from form to meaning, the predictivity of DLM-based measures for
total fixation duration, naming latencies, and spoken word duration indicates
that meaning is heavily involved in the present word naming task.

</details>


### [18] [Expanding the WMT24++ Benchmark with Rumantsch Grischun, Sursilvan, Sutsilvan, Surmiran, Puter, and Vallader](https://arxiv.org/abs/2509.03148)
*Jannis Vamvas,Ignacio Pérez Prat,Not Battesta Soliva,Sandra Baltermia-Guetg,Andrina Beeli,Simona Beeli,Madlaina Capeder,Laura Decurtins,Gian Peder Gregori,Flavia Hobi,Gabriela Holderegger,Arina Lazzarini,Viviana Lazzarini,Walter Rosselli,Bettina Vital,Anna Rutkiewicz,Rico Sennrich*

Main category: cs.CL

TL;DR: 这篇论文为瑞士罗曼语语言创建了机器翻译评测基准，包括6种方言，基于WMT24++标准制作了人工翻译参考文本。自动评测显示从罗曼语到德语翻译效果较好，但向罗曼语翻译仍面临挑战。


<details>
  <summary>Details</summary>
Motivation: 瑞士罗曼语语言缺乏机器翻译评估资源，需要为该语言及其各种方言建立标准化的评测基准。

Method: 基于WMT24++标准化基准，通过人工翻译制作了罗曼语6种方言（包括Rumantsch Grischun和5种地区方言）的参考翻译文本，并对现有MT系统和LLM进行自动评测。

Result: 自动评测显示，从罗曼语各种方言向德语的翻译效果相对较好，但从其他语言向罗曼语的翻译仍然面临较大挑战。

Conclusion: 该研究为罗曼语语言提供了重要的评测基准，显示了当前机器翻译技术在小语种方面的不足，尤其是在向小语种翻译方向的难度。

Abstract: The Romansh language, spoken in Switzerland, has limited resources for
machine translation evaluation. In this paper, we present a benchmark for six
varieties of Romansh: Rumantsch Grischun, a supra-regional variety, and five
regional varieties: Sursilvan, Sutsilvan, Surmiran, Puter, and Vallader. Our
reference translations were created by human translators based on the WMT24++
benchmark, which ensures parallelism with more than 55 other languages. An
automatic evaluation of existing MT systems and LLMs shows that translation out
of Romansh into German is handled relatively well for all the varieties, but
translation into Romansh is still challenging.

</details>


### [19] [Domain Adaptation of LLMs for Process Data](https://arxiv.org/abs/2509.03161)
*Rafael Seidi Oyamada,Jari Peeperkorn,Jochen De Weerdt,Johannes De Smedt*

Main category: cs.CL

TL;DR: 本研究探索了直接使用预训练大语言模型处理过程数据的方法，通过参数高效微调技术，在预测性过程监控任务中取得了优于现有RNN方法和基于自然语言重构方案的性能表现。


<details>
  <summary>Details</summary>
Motivation: 现有过程挖掘研究主要关注提示工程或将事件日志转换为叙述式数据集来利用LLMs的语义能力，但本研究希望直接利用LLMs生成token序列的能力来处理过程数据，避免自然语言重构的开销。

Method: 采用参数高效微调技术对预训练LLMs进行适配，专注于预测性过程监控任务，包括单任务和多任务预测场景。

Result: 实验结果表明，该方法在预测性能上优于最先进的RNN方法和近期基于叙述式的解决方案，特别是在多任务设置中表现更佳。微调模型收敛更快且需要更少的超参数优化。

Conclusion: 直接微调预训练LLMs处理过程数据是可行的，参数高效微调技术能有效降低计算开销，在多任务预测场景中展现出显著优势，为过程挖掘领域提供了新的有效方法。

Abstract: In recent years, Large Language Models (LLMs) have emerged as a prominent
area of interest across various research domains, including Process Mining
(PM). Current applications in PM have predominantly centered on prompt
engineering strategies or the transformation of event logs into narrative-style
datasets, thereby exploiting the semantic capabilities of LLMs to address
diverse tasks. In contrast, this study investigates the direct adaptation of
pretrained LLMs to process data without natural language reformulation,
motivated by the fact that these models excel in generating sequences of
tokens, similar to the objective in PM. More specifically, we focus on
parameter-efficient fine-tuning techniques to mitigate the computational
overhead typically associated with such models. Our experimental setup focuses
on Predictive Process Monitoring (PPM), and considers both single- and
multi-task predictions. The results demonstrate a potential improvement in
predictive performance over state-of-the-art recurrent neural network (RNN)
approaches and recent narrative-style-based solutions, particularly in the
multi-task setting. Additionally, our fine-tuned models exhibit faster
convergence and require significantly less hyperparameter optimization.

</details>


### [20] [SinhalaMMLU: A Comprehensive Benchmark for Evaluating Multitask Language Understanding in Sinhala](https://arxiv.org/abs/2509.03162)
*Ashmari Pramodya,Nirasha Nelki,Heshan Shalinda,Chamila Liyanage,Yusuke Sakai,Randil Pushpananda,Ruvan Weerasinghe,Hidetaka Kamigaito,Taro Watanabe*

Main category: cs.CL

TL;DR: 首个专门为伪斯里兰伪斯里语设计的多选题回答测试集SinhalaMMLU，包含7000+问题，测试26个LLM发现模型在伪斯里兰文化和低资源语言上表现有限


<details>
  <summary>Details</summary>
Motivation: 现有LLM评测偏向全球性或英语中心化主题，忽视了低资源语言和文化特定内容，自动翻译方法存在错误和文化失真问题

Method: 创建SinhalaMMLU测试集，包含7000+问题，涵盖中学到大学教育水平，基于斯里兰国家课程，涵盖6个领域30个学科，包括普通学科和文化基础知识

Result: 在26个LLM上评测，Claude 3.5 sonnet和GPT-4o表现最好，分别达到67%和62%准确率，但整体性能仍有限，特别是在人文科学等文化丰富领域表现差

Conclusion: LLM在低资源语言和文化特定内容上仍有很大改进空间，需要专门的测试集来评估和推动模型在这些领域的发展

Abstract: Large Language Models (LLMs) demonstrate impressive general knowledge and
reasoning abilities, yet their evaluation has predominantly focused on global
or anglocentric subjects, often neglecting low-resource languages and
culturally specific content. While recent multilingual benchmarks attempt to
bridge this gap, many rely on automatic translation, which can introduce errors
and misrepresent the original cultural context. To address this, we introduce
SinhalaMMLU, the first multiple-choice question answering benchmark designed
specifically for Sinhala, a low-resource language. The dataset includes over
7,000 questions spanning secondary to collegiate education levels, aligned with
the Sri Lankan national curriculum, and covers six domains and 30 subjects,
encompassing both general academic topics and culturally grounded knowledge. We
evaluate 26 LLMs on SinhalaMMLU and observe that, while Claude 3.5 sonnet and
GPT-4o achieve the highest average accuracies at 67% and 62% respectively,
overall model performance remains limited. In particular, models struggle in
culturally rich domains such as the Humanities, revealing substantial room for
improvement in adapting LLMs to low-resource and culturally specific contexts.

</details>


### [21] [Comparison of End-to-end Speech Assessment Models for the NOCASA 2025 Challenge](https://arxiv.org/abs/2509.03256)
*Aleksei Žavoronkov,Tanel Alumäe*

Main category: cs.CL

TL;DR: 本文分析了三种端到端模型在挪威语二语儿童发音评估任务中的表现，其中基于GOP-CTC的新模型取得了最佳性能，显著超越基线并达到排行榜最高分。


<details>
  <summary>Details</summary>
Motivation: 为挪威语作为第二语言的儿童学习者开发自动发音评估系统，解决NOCASA 2025挑战赛中的单词级发音评估问题。

Method: 提出了三种模型：编码器-解码器孪生架构(E2E-R)、基于预训练wav2vec2.0的前缀调优直接分类模型，以及创新的基于CTC的无对齐GOP特征集成模型。引入了加权序数交叉熵损失函数来优化评估指标。

Result: GOP-CTC模型表现最佳，显著超越了挑战赛基线模型，在排行榜上获得了最高分数。

Conclusion: 基于CTC的无对齐GOP特征集成方法在儿童挪威语发音评估任务中表现出色，为发音评估提供了有效的端到端解决方案。

Abstract: This paper presents an analysis of three end-to-end models developed for the
NOCASA 2025 Challenge, aimed at automatic word-level pronunciation assessment
for children learning Norwegian as a second language. Our models include an
encoder-decoder Siamese architecture (E2E-R), a prefix-tuned direct
classification model leveraging pretrained wav2vec2.0 representations, and a
novel model integrating alignment-free goodness-of-pronunciation (GOP) features
computed via CTC. We introduce a weighted ordinal cross-entropy loss tailored
for optimizing metrics such as unweighted average recall and mean absolute
error. Among the explored methods, our GOP-CTC-based model achieved the highest
performance, substantially surpassing challenge baselines and attaining top
leaderboard scores.

</details>


### [22] [LatPhon: Lightweight Multilingual G2P for Romance Languages and English](https://arxiv.org/abs/2509.03300)
*Luis Felipe Chary,Miguel Arjona Ramirez*

Main category: cs.CL

TL;DR: LatPhon是一个7.5M参数的Transformer模型，在6种拉丁语系语言上联合训练，实现了3.5%的平均音素错误率，优于基线模型，接近语言特定WFSTs的性能，同时模型大小仅30MB，适合设备端部署。


<details>
  <summary>Details</summary>
Motivation: G2P转换是TTS、ASR、S2ST和对齐系统的关键前端组件，特别是在多拉丁语系语言场景下需要高效的通用解决方案。

Method: 使用7.5M参数的Transformer模型，在英语、西班牙语、法语、意大利语、葡萄牙语和罗马尼亚语六种语言上联合训练，基于公开的ipa-dict语料库。

Result: 平均音素错误率为3.5%，优于字节级ByT5基线（5.4%），接近语言特定WFSTs（3.2%），模型大小仅30MB。

Conclusion: 紧凑的多语言G2P模型可以作为拉丁语系语音处理管道的通用前端组件，具备设备端部署的可行性。

Abstract: Grapheme-to-phoneme (G2P) conversion is a key front-end for text-to-speech
(TTS), automatic speech recognition (ASR), speech-to-speech translation (S2ST)
and alignment systems, especially across multiple Latin-script languages.We
present LatPhon, a 7.5 M - parameter Transformer jointly trained on six such
languages--English, Spanish, French, Italian, Portuguese, and Romanian. On the
public ipa-dict corpus, it attains a mean phoneme error rate (PER) of 3.5%,
outperforming the byte-level ByT5 baseline (5.4%) and approaching
language-specific WFSTs (3.2%) while occupying 30 MB of memory, which makes
on-device deployment feasible when needed. These results indicate that compact
multilingual G2P can serve as a universal front-end for Latin-language speech
pipelines.

</details>


### [23] [AgenTracer: Who Is Inducing Failure in the LLM Agentic Systems?](https://arxiv.org/abs/2509.03312)
*Guibin Zhang,Junhao Wang,Junjie Chen,Wangchunshu Zhou,Kun Wang,Shuicheng Yan*

Main category: cs.CL

TL;DR: AgenTracer是一个用于多智能体系统故障归因的自动化框架，通过反事实重放和故障注入创建数据集，并训练出轻量级故障追踪模型AgenTracer-8B，在故障诊断准确率上超越大型专有LLM，并能提升现有多智能体系统性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型(LLM)驱动的多智能体系统虽然性能优异，但其复杂性也增加了系统脆弱性，故障归因变得困难。当前最先进的推理LLM在此任务上准确率低于10%，亟需解决方案。

Method: 提出AgenTracer框架：1)通过反事实重放和程序化故障注入自动标注失败的多智能体轨迹，创建TracerTraj数据集；2)利用该数据集训练AgenTracer-8B模型，采用多粒度强化学习方法进行故障追踪。

Result: 在Who&When基准测试中，AgenTracer-8B比Gemini-2.5-Pro和Claude-4-Sonnet等大型专有LLM性能提升高达18.18%。更重要的是，能为MetaGPT和MaAS等现有多智能体系统提供可操作的反馈，带来4.8-14.2%的性能提升。

Conclusion: AgenTracer-8B为多智能体系统故障归因设立了新标准，能够有效诊断冗长多智能体交互中的错误，赋能自校正和自进化的智能体AI系统。

Abstract: Large Language Model (LLM)-based agentic systems, often comprising multiple
models, complex tool invocations, and orchestration protocols, substantially
outperform monolithic agents. Yet this very sophistication amplifies their
fragility, making them more prone to system failure. Pinpointing the specific
agent or step responsible for an error within long execution traces defines the
task of agentic system failure attribution. Current state-of-the-art reasoning
LLMs, however, remain strikingly inadequate for this challenge, with accuracy
generally below 10%. To address this gap, we propose AgenTracer, the first
automated framework for annotating failed multi-agent trajectories via
counterfactual replay and programmed fault injection, producing the curated
dataset TracerTraj. Leveraging this resource, we develop AgenTracer-8B, a
lightweight failure tracer trained with multi-granular reinforcement learning,
capable of efficiently diagnosing errors in verbose multi-agent interactions.
On the Who&When benchmark, AgenTracer-8B outperforms giant proprietary LLMs
like Gemini-2.5-Pro and Claude-4-Sonnet by up to 18.18%, setting a new standard
in LLM agentic failure attribution. More importantly, AgenTracer-8B delivers
actionable feedback to off-the-shelf multi-agent systems like MetaGPT and MaAS
with 4.8-14.2% performance gains, empowering self-correcting and self-evolving
agentic AI.

</details>


### [24] [LMEnt: A Suite for Analyzing Knowledge in Language Models from Pretraining Data to Representations](https://arxiv.org/abs/2509.03405)
*Daniela Gottesman,Alon Gilae-Dotan,Ido Cohen,Yoav Gur-Arieh,Marius Mosbach,Ori Yoran,Mor Geva*

Main category: cs.CL

TL;DR: LMEnt是一个用于分析语言模型预训练过程中知识获取的套件，包含知识丰富的预训练语料库、改进的实体检索方法和多个预训练模型，为研究知识表示和学习动态提供受控环境。


<details>
  <summary>Details</summary>
Motivation: 语言模型在现实应用中需要世界知识，但模型如何将数据转化为知识表示的过程尚不清楚。理解这些过程有助于开发更一致、鲁棒和完整的知识表示模型。

Method: 提出LMEnt套件，包括：(1)基于Wikipedia的完全实体标注的知识丰富预训练语料库；(2)比先前方法性能提升80.4%的基于实体的检索方法；(3)12个最多10亿参数的预训练模型和4000个中间检查点。

Result: LMEnt提供了一个受控环境来分析预训练中实体提及与下游性能的关系，以及预训练数据中因果干预的效果。研究发现事实频率是关键因素，但不能完全解释学习趋势。

Conclusion: LMEnt支持研究语言模型中的知识表示、可塑性、编辑、归因和学习动态，为深入理解知识获取过程提供了重要工具和资源。

Abstract: Language models (LMs) increasingly drive real-world applications that require
world knowledge. However, the internal processes through which models turn data
into representations of knowledge and beliefs about the world, are poorly
understood. Insights into these processes could pave the way for developing LMs
with knowledge representations that are more consistent, robust, and complete.
To facilitate studying these questions, we present LMEnt, a suite for analyzing
knowledge acquisition in LMs during pretraining. LMEnt introduces: (1) a
knowledge-rich pretraining corpus, fully annotated with entity mentions, based
on Wikipedia, (2) an entity-based retrieval method over pretraining data that
outperforms previous approaches by as much as 80.4%, and (3) 12 pretrained
models with up to 1B parameters and 4K intermediate checkpoints, with
comparable performance to popular open-sourced models on knowledge benchmarks.
Together, these resources provide a controlled environment for analyzing
connections between entity mentions in pretraining and downstream performance,
and the effects of causal interventions in pretraining data. We show the
utility of LMEnt by studying knowledge acquisition across checkpoints, finding
that fact frequency is key, but does not fully explain learning trends. We
release LMEnt to support studies of knowledge in LMs, including knowledge
representations, plasticity, editing, attribution, and learning dynamics.

</details>


### [25] [Learning Mechanism Underlying NLP Pre-Training and Fine-Tuning](https://arxiv.org/abs/2509.03407)
*Yarden Tzach,Ronit D. Gross,Ella Koresh,Shalom Rosner,Or Shpringer,Tal Halevi,Ido Kanter*

Main category: cs.CL

TL;DR: 本文研究了NLP预训练机制，发现准确率随词频增加，预训练通过形成强匹配词簇来打破词汇对称性，沿transformer层提升性能，这些发现也反映在微调精度的提升中。


<details>
  <summary>Details</summary>
Motivation: 研究预训练的成功机制，探索预训练准确率与分类任务微调之间的相互作用关系。

Method: 使用BERT-6架构在Wikipedia数据集上进行预训练，然后在FewRel和DBpedia分类任务上进行微调，分析token准确率、混淆矩阵和transformer层的变化。

Result: token准确率随出现频率增加；预训练打破了词汇对称性，形成有限的强匹配词簇；沿transformer层性能显著提升；预训练生成高阶语言结构；微调精度沿层提升；输出标签预测置信度与平均输入APT无关。

Conclusion: 预训练机制在NLP中有效，即使学习成本函数仅针对单个token识别，也能生成高阶语言结构，这种机制在图像分类任务中具有普适性。

Abstract: Natural language processing (NLP) enables the understanding and generation of
meaningful human language, typically using a pre-trained complex architecture
on a large dataset to learn the language and next fine-tune its weights to
implement a specific task. Twofold goals are examined; to understand the
mechanism underlying successful pre-training and to determine the interplay
between the pre-training accuracy and the fine-tuning of classification tasks.
The following main results were obtained; the accuracy per token (APT)
increased with its appearance frequency in the dataset, and its average over
all tokens served as an order parameter to quantify pre-training success, which
increased along the transformer blocks. Pre-training broke the symmetry among
tokens and grouped them into finite, small, strong match token clusters, as
inferred from the presented token confusion matrix. This feature was sharpened
along the transformer blocks toward the output layer, enhancing its performance
considerably compared with that of the embedding layer. Consequently,
higher-order language structures were generated by pre-training, even though
the learning cost function was directed solely at identifying a single token.
These pre-training findings were reflected by the improved fine-tuning accuracy
along the transformer blocks. Additionally, the output label prediction
confidence was found to be independent of the average input APT, as the input
meaning was preserved since the tokens are replaced primarily by strong match
tokens. Finally, although pre-training is commonly absent in image
classification tasks, its underlying mechanism is similar to that used in
fine-tuning NLP classification tasks, hinting at its universality. The results
were based on the BERT-6 architecture pre-trained on the Wikipedia dataset and
fine-tuned on the FewRel and DBpedia classification tasks.

</details>


### [26] [Curse of Knowledge: When Complex Evaluation Context Benefits yet Biases LLM Judges](https://arxiv.org/abs/2509.03419)
*Weiyuan Li,Xintao Wang,Siyu Yuan,Rui Xu,Jiangjie Chen,Qingqing Dong,Yanghua Xiao,Deqing Yang*

Main category: cs.CL

TL;DR: 该论文构建了ComplexEval基准测试，系统性地揭示和量化了大型语言模型作为评估者时的辅助信息诱导偏见，发现所有模型都存在显著偏见且偏见程度随任务复杂度增加而加剧。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型能力增强，面对日益复杂多样的任务时，可靠的评估变得困难。LLM作为评估者的范式虽然可扩展，但在复杂任务中的可靠性研究不足，特别是涉及多维度评分标准、非结构化参考答案和细微评判标准的情况。

Method: 构建ComplexEval挑战基准，系统性研究和验证6种先前未探索的偏见，涵盖12个基础场景和3个高级场景，深入分析模型对这些偏见的敏感性。

Result: (1) 所有评估模型都表现出对这些偏见的显著敏感性，偏见程度随任务复杂度增加而加剧；(2) 大型推理模型(LRMs)表现出矛盾的脆弱性。

Conclusion: 研究为改进评估信号的准确性和可验证性提供了关键见解，为开发更通用和鲁棒的评估模型铺平了道路。

Abstract: As large language models (LLMs) grow more capable, they face increasingly
diverse and complex tasks, making reliable evaluation challenging. The paradigm
of LLMs as judges has emerged as a scalable solution, yet prior work primarily
focuses on simple settings. Their reliability in complex tasks--where
multi-faceted rubrics, unstructured reference answers, and nuanced criteria are
critical--remains understudied. In this paper, we constructed ComplexEval, a
challenge benchmark designed to systematically expose and quantify Auxiliary
Information Induced Biases. We systematically investigated and validated 6
previously unexplored biases across 12 basic and 3 advanced scenarios. Key
findings reveal: (1) all evaluated models exhibit significant susceptibility to
these biases, with bias magnitude scaling with task complexity; (2) notably,
Large Reasoning Models (LRMs) show paradoxical vulnerability. Our in-depth
analysis offers crucial insights for improving the accuracy and verifiability
of evaluation signals, paving the way for more general and robust evaluation
models.

</details>


### [27] [Continuous Saudi Sign Language Recognition: A Vision Transformer Approach](https://arxiv.org/abs/2509.03467)
*Soukeina Elhassen,Lama Al Khuzayem,Areej Alhothali,Ohoud Alzamzami,Nahed Alowaidi*

Main category: cs.CL

TL;DR: 这篇论文提出了第一个连续沙特手语语料集KAU-CSSL和一种基于Transformer的模型，为阿拉伯手语识别提供了重要资源和技术方案。


<details>
  <summary>Details</summary>
Motivation: 沙特手语(SSL)作为过蓄万听力障碍人士的主要沟通方式，但缺乏足够的技术资源和识别系统，特别是连续语句级别的识别方案。现有技术主要集中在非阿拉伯手语上，导致阿拉伯手语识别领域存在明显空白。

Method: 研究开发了第一个连续沙特手语语料集KAU-CSSL，重点关注完整句子。提出了基于Transformer的模型，使用预训练的ResNet-18进行空间特征提取，结合Transformer Encoder和双向LSTM处理时序依赖关系。

Result: 模型在签名者依赖模式下达到了99.02%的准确率，在签名者独立模式下达到了77.71%的准确率。

Conclusion: 这项研究为沙特手语社区提供了重要的资源和技术支持，不仅有助于改善沙特手语用户的沟通条件，也对手语识别领域的普遍发展做出了贡献。

Abstract: Sign language (SL) is an essential communication form for hearing-impaired
and deaf people, enabling engagement within the broader society. Despite its
significance, limited public awareness of SL often leads to inequitable access
to educational and professional opportunities, thereby contributing to social
exclusion, particularly in Saudi Arabia, where over 84,000 individuals depend
on Saudi Sign Language (SSL) as their primary form of communication. Although
certain technological approaches have helped to improve communication for
individuals with hearing impairments, there continues to be an urgent
requirement for more precise and dependable translation techniques, especially
for Arabic sign language variants like SSL. Most state-of-the-art solutions
have primarily focused on non-Arabic sign languages, resulting in a
considerable absence of resources dedicated to Arabic sign language,
specifically SSL. The complexity of the Arabic language and the prevalence of
isolated sign language datasets that concentrate on individual words instead of
continuous speech contribute to this issue. To address this gap, our research
represents an important step in developing SSL resources. To address this, we
introduce the first continuous Saudi Sign Language dataset called KAU-CSSL,
focusing on complete sentences to facilitate further research and enable
sophisticated recognition systems for SSL recognition and translation.
Additionally, we propose a transformer-based model, utilizing a pretrained
ResNet-18 for spatial feature extraction and a Transformer Encoder with
Bidirectional LSTM for temporal dependencies, achieving 99.02\% accuracy at
signer dependent mode and 77.71\% accuracy at signer independent mode. This
development leads the way to not only improving communication tools for the SSL
community but also making a substantial contribution to the wider field of sign
language.

</details>


### [28] [Design and Optimization of Reinforcement Learning-Based Agents in Text-Based Games](https://arxiv.org/abs/2509.03479)
*Haonan Wang,Mingjia Zhao,Junfeng Sun,Wei Liu*

Main category: cs.CL

TL;DR: 本文提出了一种基于强化学习的新型文本游戏智能体设计方法，通过深度学习处理游戏文本构建世界模型，并使用策略梯度强化学习方法训练智能体，在多个文本游戏中显著提升了完成率和胜率。


<details>
  <summary>Details</summary>
Motivation: 随着AI技术的发展，基于文本游戏的智能体研究越来越受欢迎。本文旨在探索如何利用强化学习方法更好地解决文本游戏中的智能体学习和决策问题。

Method: 首先应用深度学习模型处理游戏文本并构建世界模型，然后使用基于策略梯度的深度强化学习方法训练智能体，实现从状态价值到最优策略的转换。

Result: 增强后的智能体在多个文本游戏实验中表现更好，在游戏完成率和胜率方面显著超越了之前的智能体。

Conclusion: 本研究为使用强化学习解决文本游戏问题提供了新的理解和实证基础，为开发优化更通用领域的强化学习智能体奠定了基础。

Abstract: As AI technology advances, research in playing text-based games with agents
has becomeprogressively popular. In this paper, a novel approach to agent
design and agent learning ispresented with the context of reinforcement
learning. A model of deep learning is first applied toprocess game text and
build a world model. Next, the agent is learned through a policy gradient-based
deep reinforcement learning method to facilitate conversion from state value to
optimal policy.The enhanced agent works better in several text-based game
experiments and significantlysurpasses previous agents on game completion ratio
and win rate. Our study introduces novelunderstanding and empirical ground for
using reinforcement learning for text games and sets thestage for developing
and optimizing reinforcement learning agents for more general domains
andproblems.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [29] [LimiX: Unleashing Structured-Data Modeling Capability for Generalist Intelligence](https://arxiv.org/abs/2509.03505)
*Xingxuan Zhang,Gang Ren,Han Yu,Hao Yuan,Hui Wang,Jiansheng Li,Jiayun Wu,Lang Mo,Li Mao,Mingchao Hao,Ningbo Dai,Renzhe Xu,Shuyang Li,Tianyang Zhang,Yue He,Yuanrui Wang,Yunjia Zhang,Zijing Xu,Dongzhe Li,Fang Gao,Hao Zou,Jiandong Liu,Jiashuo Liu,Jiawei Xu,Kaijie Cheng,Kehan Li,Linjun Zhou,Qing Li,Shaohua Fan,Xiaoyu Lin,Xinyan Han,Xuanyue Li,Yan Lu,Yuan Xue,Yuanyuan Jiang,Zimu Wang,Zhenlei Wang,Peng Cui*

Main category: cs.LG

TL;DR: LimiX是首个大型结构化数据基础模型，通过单一模型处理多种表格任务，在10个基准测试中超越现有方法


<details>
  <summary>Details</summary>
Motivation: 实现通用智能需要基于语言、物理世界和结构化数据的互补基础模型，当前缺乏专门处理结构化数据的基础模型

Method: 采用掩码联合分布建模和情境条件目标进行预训练，将结构化数据视为变量和缺失值的联合分布，支持查询式条件预测

Result: 在分类、回归、缺失值填补和数据生成等任务上均显著优于梯度提升树、深度表格网络和其他表格基础模型

Conclusion: LimiX证明了单一模型通过统一接口处理多样化表格任务的可行性，为结构化数据基础模型的发展奠定了基础

Abstract: We argue that progress toward general intelligence requires complementary
foundation models grounded in language, the physical world, and structured
data. This report presents LimiX, the first installment of our large
structured-data models (LDMs). LimiX treats structured data as a joint
distribution over variables and missingness, thus capable of addressing a wide
range of tabular tasks through query-based conditional prediction via a single
model. LimiX is pretrained using masked joint-distribution modeling with an
episodic, context-conditional objective, where the model predicts for query
subsets conditioned on dataset-specific contexts, supporting rapid,
training-free adaptation at inference. We evaluate LimiX across 10 large
structured-data benchmarks with broad regimes of sample size, feature
dimensionality, class number, categorical-to-numerical feature ratio,
missingness, and sample-to-feature ratios. With a single model and a unified
interface, LimiX consistently surpasses strong baselines including
gradient-boosting trees, deep tabular networks, recent tabular foundation
models, and automated ensembles, as shown in Figure 1 and Figure 2. The
superiority holds across a wide range of tasks, such as classification,
regression, missing value imputation, and data generation, often by substantial
margins, while avoiding task-specific architectures or bespoke training per
task. All LimiX models are publicly accessible under Apache 2.0.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [30] [Speech DF Arena: A Leaderboard for Speech DeepFake Detection Models](https://arxiv.org/abs/2509.02859)
*Sandipana Dowerah,Atharva Kulkarni,Ajinkya Kulkarni,Hoan My Tran,Joonas Kalda,Artem Fedorchenko,Benoit Fauve,Damien Lolive,Tanel Alumäe,Matthew Magimai Doss*

Main category: cs.SD

TL;DR: Speech DF Arena是首个全面的音频深度伪造检测基准测试，包含14个数据集、标准化评估指标和协议，以及用于比较检测系统的排行榜。研究发现现有系统在跨域场景中表现不佳，强调了跨域评估的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着深度伪造音频生成技术的发展，音频深度伪造检测也取得了显著进展，但缺乏标准化和全面的基准测试来统一评估不同检测系统的性能。

Method: 开发了Speech DF Arena基准测试工具包，包含14个不同的数据集和攻击场景，采用标准化评估指标和协议，评估了12个开源和3个专有检测系统。

Result: 研究发现许多系统在跨域场景中表现出较高的等错误率(EER)，表明现有检测系统在泛化能力方面存在不足。

Conclusion: Speech DF Arena为音频深度伪造检测提供了首个全面的基准测试平台，强调了跨域评估的重要性，有助于研究人员和开发者提高检测系统的可靠性和鲁棒性。

Abstract: Parallel to the development of advanced deepfake audio generation, audio
deepfake detection has also seen significant progress. However, a standardized
and comprehensive benchmark is still missing. To address this, we introduce
Speech DeepFake (DF) Arena, the first comprehensive benchmark for audio
deepfake detection. Speech DF Arena provides a toolkit to uniformly evaluate
detection systems, currently across 14 diverse datasets and attack scenarios,
standardized evaluation metrics and protocols for reproducibility and
transparency. It also includes a leaderboard to compare and rank the systems to
help researchers and developers enhance their reliability and robustness. We
include 14 evaluation sets, 12 state-of-the-art open-source and 3 proprietary
detection systems. Our study presents many systems exhibiting high EER in
out-of-domain scenarios, highlighting the need for extensive cross-domain
evaluation. The leaderboard is hosted on Huggingface1 and a toolkit for
reproducing results across the listed datasets is available on GitHub.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [31] [Language Models Do Not Follow Occam's Razor: A Benchmark for Inductive and Abductive Reasoning](https://arxiv.org/abs/2509.03345)
*Yunxin Sun,Abulhair Saparov*

Main category: cs.AI

TL;DR: 该论文提出了InAbHyD数据集来评估大语言模型在归纳和溯因推理方面的能力，发现LLMs在简单场景中能进行这类推理，但在复杂世界模型中表现不佳。


<details>
  <summary>Details</summary>
Motivation: 当前大多数工作只关注演绎推理，而归纳和溯因推理在解决现实问题中同样重要但研究较少，需要系统评估LLMs在这方面的能力。

Method: 创建了可编程的合成数据集InAbHyD，包含不完整的世界模型和观察数据，提出基于奥卡姆剃刀原理的新指标来评估假设质量，并测试了最先进的LLMs。

Result: LLMs在简单场景中能够进行归纳和溯因推理，但在复杂世界模型中表现困难，即使使用上下文学习和RLVR等推理增强技术也难以产生高质量的假设。

Conclusion: 虽然LLMs在简单归纳和溯因推理方面显示出了一定能力，但在处理复杂推理任务时仍存在显著局限，需要进一步研究改进。

Abstract: Reasoning is a core capability in artificial intelligence systems, for which
large language models (LLMs) have recently shown remarkable progress. However,
most work focuses exclusively on deductive reasoning, which is problematic
since other types of reasoning are also essential in solving real-world
problems, and they are less explored. This work focuses on evaluating LLMs'
inductive and abductive reasoning capabilities. We introduce a programmable and
synthetic dataset, InAbHyD (pronounced in-a-bid), where each reasoning example
consists of an incomplete world model and a set of observations. The task for
the intelligent agent is to produce hypotheses to explain observations under
the incomplete world model to solve each reasoning example. We propose a new
metric to evaluate the quality of hypotheses based on Occam's Razor. We
evaluate and analyze some state-of-the-art LLMs. Our analysis shows that LLMs
can perform inductive and abductive reasoning in simple scenarios, but struggle
with complex world models and producing high-quality hypotheses, even with
popular reasoning-enhancing techniques such as in-context learning and RLVR.

</details>


### [32] [Situating AI Agents in their World: Aspective Agentic AI for Dynamic Partially Observable Information Systems](https://arxiv.org/abs/2509.03380)
*Peter J. Bentley,Soo Ling Lim,Fuyuki Ishikawa*

Main category: cs.AI

TL;DR: 本文提出了一种基于环境触发的自底向上AI智能体框架，通过引入"aspects"概念实现零信息泄露，相比传统架构83%的信息泄露率有显著改进


<details>
  <summary>Details</summary>
Motivation: 传统AI智能体通常只是自主聊天机器人，遵循脚本并由不可靠的控制器指挥，存在信息泄露和效率问题

Method: 采用自底向上框架，将AI智能体置于环境中，所有行为由环境变化触发，引入类似umwelt的aspects概念，使不同智能体以不同方式感知环境

Result: 相比典型架构83%的信息泄露率，aspective agentic AI实现了零信息泄露

Conclusion: 专业智能体在各自信息生态位中高效工作的概念可以同时提升安全性和效率

Abstract: Agentic LLM AI agents are often little more than autonomous chatbots: actors
following scripts, often controlled by an unreliable director. This work
introduces a bottom-up framework that situates AI agents in their environment,
with all behaviors triggered by changes in their environments. It introduces
the notion of aspects, similar to the idea of umwelt, where sets of agents
perceive their environment differently to each other, enabling clearer control
of information. We provide an illustrative implementation and show that
compared to a typical architecture, which leaks up to 83% of the time,
aspective agentic AI enables zero information leakage. We anticipate that this
concept of specialist agents working efficiently in their own information
niches can provide improvements to both security and efficiency.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [33] [Mitigating Multimodal Hallucinations via Gradient-based Self-Reflection](https://arxiv.org/abs/2509.03113)
*Shan Wang,Maying Shen,Nadine Chang,Chuong Nguyen,Hongdong Li,Jose M. Alvarez*

Main category: cs.CV

TL;DR: 提出基于梯度自反思的token影响估计方法，通过影响感知对比解码框架同时缓解多模态大语言模型中的文本-视觉偏差和共现偏差，无需额外资源即可有效减少幻觉。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型存在文本-视觉偏差和共现偏差导致的幻觉问题，现有方法缺乏对实例间偏差水平波动的理解，需要更精确的偏差缓解方案。

Method: 使用基于梯度的自反思方法估计不同类型token（视觉、提示、先前输出）的影响，检测物体相关视觉token，并将其整合到影响感知对比解码框架中。

Result: 在LLaVA-QA90上实现高达92%的准确率提升，有效减少幻觉现象。

Conclusion: 该方法无需额外微调、模型或数据统计，能够同时缓解两种偏差类型，为多模态大语言模型的幻觉问题提供了有效的解决方案。

Abstract: Hallucinations in multimodal large language model are caused by the
text-visual bias and the co-occurrence bias. The former reflects an
over-reliance on text information in the decision-making process, while the
latter arises from the statistical object-pairing patterns abstracted from the
training data. Existing mitigation methods heuristically address these biases
without understanding the fluctuating bias level across the instances. We first
propose estimating the influence of respective token types (visual, prompt, and
previous outputs) using a gradient-based self-reflection method. The estimated
token influence further enables the detection of object-related visual tokens
and their integration into an influence-aware contrastive decoding framework to
mitigate both types of biases simultaneously. Our method operates without the
need for additional resources, such as costly fine-tuning, extra models, or
data statistics. Extensive experiments show it effectively reduces
hallucinations, achieving up to a 92% accuracy increase on LLaVA-QA90.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [34] [Identifiability and minimality bounds of quantum and post-quantum models of classical stochastic processes](https://arxiv.org/abs/2509.03004)
*Paul M. Riechers,Thomas J. Elliott*

Main category: quant-ph

TL;DR: 本文解决了经典随机过程模型的可识别性问题，提出了比较任意两种模型（经典、量子或后量子）的方法，通过映射到规范化的广义隐马尔可夫模型，并给出了量子模型生成经典随机过程所需最小维度的界限。


<details>
  <summary>Details</summary>
Motivation: 为了解决不同模型（包括经典、量子或后量子模型）是否产生相同可观测行为的问题，即模型可识别性问题。特别是在量子模型能够以更高内存和热效率生成经典随机过程的情况下，需要建立统一的比较框架。

Method: 通过将任意模型映射到一个规范化的广义隐马尔可夫模型，建立统一的比较框架，从而解决不同模型之间的可识别性问题。

Result: 提供了比较任意两种模型的方法，能够确定它们是否产生相同的可观测行为，并给出了量子模型生成经典随机过程所需最小维度的界限，有时这些界限是紧的。

Conclusion: 该方法成功解决了经典随机过程模型的可识别性问题，为比较不同物理实现的模型提供了统一框架，并对量子模型的最小维度要求给出了理论界限。

Abstract: To make sense of the world around us, we develop models, constructed to
enable us to replicate, describe, and explain the behaviours we see. Focusing
on the broad case of sequences of correlated random variables, i.e., classical
stochastic processes, we tackle the question of determining whether or not two
different models produce the same observable behavior. This is the problem of
identifiability. Curiously, the physics of the model need not correspond to the
physics of the observations; recent work has shown that it is even advantageous
-- in terms of memory and thermal efficiency -- to employ quantum models to
generate classical stochastic processes. We resolve the identifiability problem
in this regime, providing a means to compare any two models of a classical
process, be the models classical, quantum, or `post-quantum', by mapping them
to a canonical `generalized' hidden Markov model. Further, this enables us to
place (sometimes tight) bounds on the minimal dimension required of a quantum
model to generate a given classical stochastic process.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [35] [SESGO: Spanish Evaluation of Stereotypical Generative Outputs](https://arxiv.org/abs/2509.03329)
*Melissa Robles,Catalina Bernal,Denniss Raigoso,Mateo Dulce Rubio*

Main category: cs.CY

TL;DR: 首个系统性评估多语言LLM在西班牙语拓拉丁美洲文化背景下的偏见问题，提出文化基础框架和新评量标准


<details>
  <summary>Details</summary>
Motivation: 当前多语言LLM评估主要集中在美式英语上，导致其他语言和文化背景下的偏见问题被忽视

Method: 基于BBQ数据集的未明确问题方法，融入拓拉丁美洲特有的文化表达和成语，过计4,000个提示，覆盖四个社会偏见类别

Result: 发现商业LLM在西班牙语中存在不同模式的偏见表现，英语偏见缩减技术在西班牙语任务中效果不佳，偏见模式在不同温度设置下保持稳定

Conclusion: 研究为多语言AI系统的公平性评估提供了重要步骤，框架可扩展到其他偏见类别和语言文化背景

Abstract: This paper addresses the critical gap in evaluating bias in multilingual
Large Language Models (LLMs), with a specific focus on Spanish language within
culturally-aware Latin American contexts. Despite widespread global deployment,
current evaluations remain predominantly US-English-centric, leaving potential
harms in other linguistic and cultural contexts largely underexamined. We
introduce a novel, culturally-grounded framework for detecting social biases in
instruction-tuned LLMs. Our approach adapts the underspecified question
methodology from the BBQ dataset by incorporating culturally-specific
expressions and sayings that encode regional stereotypes across four social
categories: gender, race, socioeconomic class, and national origin. Using more
than 4,000 prompts, we propose a new metric that combines accuracy with the
direction of error to effectively balance model performance and bias alignment
in both ambiguous and disambiguated contexts. To our knowledge, our work
presents the first systematic evaluation examining how leading commercial LLMs
respond to culturally specific bias in the Spanish language, revealing varying
patterns of bias manifestation across state-of-the-art models. We also
contribute evidence that bias mitigation techniques optimized for English do
not effectively transfer to Spanish tasks, and that bias patterns remain
largely consistent across different sampling temperatures. Our modular
framework offers a natural extension to new stereotypes, bias categories, or
languages and cultural contexts, representing a significant step toward more
equitable and culturally-aware evaluation of AI systems in the diverse
linguistic environments where they operate.

</details>
