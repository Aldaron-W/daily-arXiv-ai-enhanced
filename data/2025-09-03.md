<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 137]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.AI](#cs.AI) [Total: 21]
- [stat.ML](#stat.ML) [Total: 1]
- [cs.CV](#cs.CV) [Total: 4]
- [cs.LG](#cs.LG) [Total: 9]
- [cs.CR](#cs.CR) [Total: 1]
- [cs.SD](#cs.SD) [Total: 4]
- [cs.MM](#cs.MM) [Total: 2]
- [cs.HC](#cs.HC) [Total: 2]
- [eess.AS](#eess.AS) [Total: 4]
- [cs.IR](#cs.IR) [Total: 2]
- [cs.SI](#cs.SI) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [MultiStream-LLM: Bridging Modalities for Robust Sign Language Translation](https://arxiv.org/abs/2509.00030)
*Marshall Thomas,Edward Fish,Richard Bowden*

Main category: cs.CL

TL;DR: MultiStream-LLM是一个模块化手语翻译框架，通过分离处理连续手语、手指拼写和唇读三个模态，使用专家网络分别解码后融合，最后通过大语言模型生成句子，在How2Sign和ChicagoFSWildPlus数据集上达到新的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有的端到端手语翻译模型在处理高速手指拼写和异步非手动面部线索时表现不佳，特别是对于姓名、地点和技术术语等关键信息的翻译效果较差。

Method: 采用模块化框架，使用三个专门的专家网络分别处理连续手语、手指拼写和唇读，每个网络将其特定模态解码为token序列，然后通过轻量级transformer融合这些并行流以解决时间不对齐问题，最后使用大语言模型生成最终句子。

Result: 在How2Sign基准测试中达到BLEU-4分数23.5的新SOTA，在ChicagoFSWildPlus手指拼写数据集上达到73.2%的字母准确率。

Conclusion: 通过分离和解决不同的识别任务再进行融合的多专家方法，为稳健、高保真的手语翻译提供了更强大有效的途径。

Abstract: Despite progress in gloss-free Sign Language Translation (SLT), monolithic
end-to-end models consistently fail on two critical components of natural
signing: the precise recognition of high-speed fingerspelling and the
integration of asynchronous non-manual cues from the face. Recent progress in
Automated Sign Language Translation with Large Language Models has side stepped
this challenge, forcing a single network to learn these simultaneously
resulting in poor performance when tasked with translating crucial information
such as names,places, and technical terms. We introduce MultiStream-LLM, a
modular framework designed to overcome these limitations. Our approach employs
separate, specialized predictors for continuous signing, fingerspelling, and
lipreading. Each expert network first decodes its specific modality into a
sequence of tokens. These parallel streams are then fused by a lightweight
transformer that resolves temporal misalignments before passing the combined
representation to a Large Language Model (LLM) for final sentence generation.
Our method establishes a new state-of-the-art on the How2Sign benchmark with a
BLEU-4 score of 23.5 and achieves 73.2% letter accuracy on the challenging
ChicagoFSWildPlus fingerspelling dataset. These results validate our core
hypothesis: by isolating and solving distinct recogni tion tasks before fusion,
our multi-expert approach provides a more powerful and effective pathway to
robust, high-fidelity sign language translation.

</details>


### [2] [Compiling Prompts, Not Crafting Them: A Reproducible Workflow for AI-Assisted Evidence Synthesis](https://arxiv.org/abs/2509.00038)
*Teo Susnjak*

Main category: cs.CL

TL;DR: 本文推出了一种基于声明式提示优化的结构化框架，用于改善大语言模型在系统性文献综述中的可靠性和可复现性。


<details>
  <summary>Details</summary>
Motivation: 当前使用大语言模型进行系统性文献综述时，常靠脆弱的手动制作提示，影响了科学研究的可靠性和可复现性。

Method: 采用声明式提示优化技术，构建包含任务声明、测试套件和自动提示调整的域特定框架，并提供工作代码示例。

Result: 开发出一种可验证的大语言模型流水线蓝图，符合证据综述中透明性和严谨性的原则。

Conclusion: 这是声明式提示优化方法在系统性文献综述流水线中的新颖应用，有助于提高LLM辅助证据综述的科学信心。

Abstract: Large language models (LLMs) offer significant potential to accelerate
systematic literature reviews (SLRs), yet current approaches often rely on
brittle, manually crafted prompts that compromise reliability and
reproducibility. This fragility undermines scientific confidence in
LLM-assisted evidence synthesis. In response, this work adapts recent advances
in declarative prompt optimisation, developed for general-purpose LLM
applications, and demonstrates their applicability to the domain of SLR
automation. This research proposes a structured, domain-specific framework that
embeds task declarations, test suites, and automated prompt tuning into a
reproducible SLR workflow. These emerging methods are translated into a
concrete blueprint with working code examples, enabling researchers to
construct verifiable LLM pipelines that align with established principles of
transparency and rigour in evidence synthesis. This is a novel application of
such approaches to SLR pipelines.

</details>


### [3] [What Are Research Hypotheses?](https://arxiv.org/abs/2509.00185)
*Jian Wu,Sarah Rajtmajer*

Main category: cs.CL

TL;DR: 本文综述了自然语言处理领域中"假设"概念的不同定义，特别关注了近期NLU任务中的定义差异，强调了在机器可解释学术记录背景下明确定义假设的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着自然语言处理技术的发展，各种任务中对"假设"概念的定义出现了分歧，偏离了传统科学定义，需要系统梳理和明确界定。

Method: 通过文献综述方法，系统梳理和比较了自然语言理解任务中各种假设定义，特别分析了近期发表文献中的定义差异。

Result: 识别出NLU领域中假设定义存在显著差异，这些差异影响了模型的训练和应用效果。

Conclusion: 明确定义和结构化假设对于构建机器可解释的学术记录至关重要，需要建立统一的标准定义框架。

Abstract: Over the past decades, alongside advancements in natural language processing,
significant attention has been paid to training models to automatically
extract, understand, test, and generate hypotheses in open and scientific
domains. However, interpretations of the term \emph{hypothesis} for various
natural language understanding (NLU) tasks have migrated from traditional
definitions in the natural, social, and formal sciences. Even within NLU, we
observe differences defining hypotheses across literature. In this paper, we
overview and delineate various definitions of hypothesis. Especially, we
discern the nuances of definitions across recently published NLU tasks. We
highlight the importance of well-structured and well-defined hypotheses,
particularly as we move toward a machine-interpretable scholarly record.

</details>


### [4] [Explainable Chain-of-Thought Reasoning: An Empirical Analysis on State-Aware Reasoning Dynamics](https://arxiv.org/abs/2509.00190)
*Sheldon Yu,Yuxin Xiong,Junda Wu,Xintong Li,Tong Yu,Xiang Chen,Ritwik Sinha,Jingbo Shang,Julian McAuley*

Main category: cs.CL

TL;DR: 提出了一个状态感知转换框架，将思维链轨迹抽象为结构化潜在动态，通过谱分析和马尔可夫链建模来提升推理过程的可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有思维链提示的推理可解释性有限，主要关注局部token级归因，而高层次语义角色和推理步骤转换未被充分探索。

Method: 使用token嵌入的谱分析将推理步骤聚类为语义一致的潜在状态，并通过马尔可夫链建模推理过程的全局结构。

Result: 该框架支持语义角色识别、时间模式可视化和一致性评估等多种分析功能。

Conclusion: 提出的状态感知转换框架为思维链推理提供了结构化和可解释的视图，有助于深入理解推理过程的语义演变。

Abstract: Recent advances in chain-of-thought (CoT) prompting have enabled large
language models (LLMs) to perform multi-step reasoning. However, the
explainability of such reasoning remains limited, with prior work primarily
focusing on local token-level attribution, such that the high-level semantic
roles of reasoning steps and their transitions remain underexplored. In this
paper, we introduce a state-aware transition framework that abstracts CoT
trajectories into structured latent dynamics. Specifically, to capture the
evolving semantics of CoT reasoning, each reasoning step is represented via
spectral analysis of token-level embeddings and clustered into semantically
coherent latent states. To characterize the global structure of reasoning, we
model their progression as a Markov chain, yielding a structured and
interpretable view of the reasoning process. This abstraction supports a range
of analyses, including semantic role identification, temporal pattern
visualization, and consistency evaluation.

</details>


### [5] [The Rarity Blind Spot: A Framework for Evaluating Statistical Reasoning in LLMs](https://arxiv.org/abs/2509.00245)
*Seiji Maekawa,Hayate Iso,Nikita Bhutani*

Main category: cs.CL

TL;DR: 提出了Distinctive Feature Mining（DFM）新任务和DiFBench基准框架，评估LLM在文档集合中识别全局稀有特征的能力，发现现有模型在统计推理和稀有性检测方面存在显著局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注信息检索和摘要，但缺乏对模型识别全局稀有特征能力的评估，这在候选选择、产品差异化等实际场景中至关重要。

Method: 引入DFM任务，要求模型分析10-40个文档集合，识别出现频率低于10%的稀有特征；开发DiFBench可配置基准框架，控制文档集大小和区分度阈值等参数。

Result: 对10个最先进LLM的大规模评估显示：通用模型与推理增强模型之间存在显著性能差距；所有模型随任务复杂度和文档数量增加而性能大幅下降；常见错误是将频繁特征误判为稀有特征。

Conclusion: 当代LLM在执行细粒度统计推理和稀有性检测方面存在核心局限性，需要开发新的方法来提升这种关键的推理能力。

Abstract: Effective decision-making often relies on identifying what makes each
candidate distinctive. While existing benchmarks for LLMs emphasize retrieving
or summarizing information relevant to a given query, they do not evaluate a
model's ability to identify globally distinctive features across a set of
documents. We introduce Distinctive Feature Mining (DFM), a new task that
challenges models to analyze a small-to-medium collection (10-40 documents) and
surface features that are rare in the global context (e.g., appearing in less
than 10% of documents). This setting mirrors real-world scenarios such as
candidate selection or product differentiation, where statistical reasoning,
not retrieval, is key. To enable systematic evaluation of this capability, we
present DiFBench, a configurable benchmark creation framework with controllable
parameters such as document set size and distinctiveness thresholds. Using
DiFBench, we perform a large-scale assessment of distinctive feature mining
across ten state-of-the-art LLMs. Our findings reveal a significant performance
gap between general-purpose and reasoning-enhanced models. All models, however,
substantially degrade as the task complexity and document count increase. We
also find that a common failure mode is misidentifying frequent features as
distinctive. These insights reveal core limitations in contemporary LLMs'
abilities to perform fine-grained, statistical reasoning and rarity detection.

</details>


### [6] [The Differential Meaning of Models: A Framework for Analyzing the Structural Consequences of Semantic Modeling Decisions](https://arxiv.org/abs/2509.00248)
*Zachary K. Stine,James E. Deitrick*

Main category: cs.CL

TL;DR: 提出了一个基于皮尔斯符号学理论的理论框架，用于统一描述和分析各种人类意义建构建模方法，将模型视为符号并关注其语义关系。


<details>
  <summary>Details</summary>
Motivation: 当前人类意义建构建模领域缺乏一个通用的理论框架来统一描述不同类型的建模实践，无法进行公平比较。

Method: 基于C.S. Peirce的符号学理论构建理论框架，将模型视为测量潜在符号几何的假设，并通过模型间的对比关系来理解模型价值。

Result: 提出了一个将模型和建模决策本身视为符号的理论框架，并通过简要示例展示了其经验应用。

Conclusion: 该框架为解决建模实践的统一描述问题提供了理论基础，并为未来的研究方向奠定了基础。

Abstract: The proliferation of methods for modeling of human meaning-making constitutes
a powerful class of instruments for the analysis of complex semiotic systems.
However, the field lacks a general theoretical framework for describing these
modeling practices across various model types in an apples-to-apples way. In
this paper, we propose such a framework grounded in the semiotic theory of C.
S. Peirce. We argue that such models measure latent symbol geometries, which
can be understood as hypotheses about the complex of semiotic agencies
underlying a symbolic dataset. Further, we argue that in contexts where a
model's value cannot be straightforwardly captured by proxy measures of
performance, models can instead be understood relationally, so that the
particular interpretive lens of a model becomes visible through its contrast
with other models. This forms the basis of a theory of model semantics in which
models, and the modeling decisions that constitute them, are themselves treated
as signs. In addition to proposing the framework, we illustrate its empirical
use with a few brief examples and consider foundational questions and future
directions enabled by the framework.

</details>


### [7] [The Temporal Game: A New Perspective on Temporal Relation Extraction](https://arxiv.org/abs/2509.00250)
*Hugo Sousa,Ricardo Campos,Alípio Jorge*

Main category: cs.CL

TL;DR: 提出Temporal Game，将时间关系抽取任务转化为交互式游戏，通过点对点比较时间实体的起止点来标注，支持区间和瞬时实体，并提供游戏模式和标注模式。


<details>
  <summary>Details</summary>
Motivation: 传统的时间关系标注方法直接标注区间级关系，不够细粒度和灵活。需要一种能够同时支持区间和瞬时实体，并能进行更精细标注的新方法。

Method: 将时间关系分解为时间实体起止点的点对点比较，玩家每一步标注单个点关系，系统应用时间闭包推断额外关系并确保一致性。

Result: 开发了Temporal Game演示系统，包含游戏模式（在TempEval-3数据集上标注并评分）和标注模式（支持自定义文档标注和时间线导出）。

Conclusion: 该方法为时间标注提供了更细粒度和灵活的解决方案，同时为训练强化学习智能体奠定了基础，系统已开源以促进时间推理和标注研究的进一步发展。

Abstract: In this paper we demo the Temporal Game, a novel approach to temporal
relation extraction that casts the task as an interactive game. Instead of
directly annotating interval-level relations, our approach decomposes them into
point-wise comparisons between the start and end points of temporal entities.
At each step, players classify a single point relation, and the system applies
temporal closure to infer additional relations and enforce consistency. This
point-based strategy naturally supports both interval and instant entities,
enabling more fine-grained and flexible annotation than any previous approach.
The Temporal Game also lays the groundwork for training reinforcement learning
agents, by treating temporal annotation as a sequential decision-making task.
To showcase this potential, the demo presented in this paper includes a Game
mode, in which users annotate texts from the TempEval-3 dataset and receive
feedback based on a scoring system, and an Annotation mode, that allows custom
documents to be annotated and resulting timeline to be exported. Therefore,
this demo serves both as a research tool and an annotation interface. The demo
is publicly available at https://temporal-game.inesctec.pt, and the source code
is open-sourced to foster further research and community-driven development in
temporal reasoning and annotation.

</details>


### [8] [Exploring Reasoning-Infused Text Embedding with Large Language Models for Zero-Shot Dense Retrieval](https://arxiv.org/abs/2509.00276)
*Yuxiang Liu,Tian Wang,Gourab Kundu,Tianyu Cao,Guang Cheng,Zhen Ge,Jianshu Chen,Qingjun Cui,Trishul Chilimbi*

Main category: cs.CL

TL;DR: RITE方法通过生成中间推理文本来增强文本嵌入，将逻辑推理融入生成式大语言模型的嵌入过程，显著提升了零样本检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于LLM的嵌入方法主要关注上下文表示，未能充分利用LLMs的强大推理能力。复杂现实查询需要超越表层词汇匹配的深度推理，而编码器检索器在这方面存在不足。

Method: RITE在计算嵌入之前，在token空间中生成中间推理文本，以此为基础构建嵌入表示。该方法建立在现有语言模型嵌入技术之上，通过推理过程丰富表示深度。

Result: 在推理密集的检索基准BRIGHT上的实验结果表明，RITE显著提升了跨多个领域的零样本检索性能。

Conclusion: 将推理过程融入嵌入生成是有效的，RITE方法成功地将LLMs的推理能力整合到文本嵌入中，为复杂检索任务提供了更好的解决方案。

Abstract: Transformer-based models such as BERT and E5 have significantly advanced text
embedding by capturing rich contextual representations. However, many complex
real-world queries require sophisticated reasoning to retrieve relevant
documents beyond surface-level lexical matching, where encoder-only retrievers
often fall short. Decoder-only large language models (LLMs), known for their
strong reasoning capabilities, offer a promising alternative. Despite this
potential, existing LLM-based embedding methods primarily focus on contextual
representation and do not fully exploit the reasoning strength of LLMs. To
bridge this gap, we propose Reasoning-Infused Text Embedding (RITE), a simple
but effective approach that integrates logical reasoning into the text
embedding process using generative LLMs. RITE builds upon existing language
model embedding techniques by generating intermediate reasoning texts in the
token space before computing embeddings, thereby enriching representations with
inferential depth. Experimental results on BRIGHT, a reasoning-intensive
retrieval benchmark, demonstrate that RITE significantly enhances zero-shot
retrieval performance across diverse domains, underscoring the effectiveness of
incorporating reasoning into the embedding process.

</details>


### [9] [OpinioRAG: Towards Generating User-Centric Opinion Highlights from Large-scale Online Reviews](https://arxiv.org/abs/2509.00285)
*Mir Tafseer Nayeem,Davood Rafiei*

Main category: cs.CL

TL;DR: OpinioRAG是一个可扩展的、无需训练的意见摘要生成框架，结合RAG检索和LLM技术，从大量用户评论中生成个性化摘要，并提出了新的无参考验证指标。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法处理数千条用户评论的规模，或者只能生成通用的、忽略个性化需求的摘要，无法满足情感丰富领域的精确意见捕捉需求。

Method: 提出OpinioRAG框架，结合基于RAG的证据检索和大型语言模型，无需训练即可高效生成定制化摘要。同时设计了新颖的无参考验证指标，用于情感丰富领域的事实一致性评估。

Result: 创建了首个大规模长格式用户评论数据集，包含每个实体超过千条评论，并配有专家摘要和人工标注查询。实验证明OpinioRAG能够生成准确、相关且结构化的摘要。

Conclusion: OpinioRAG为解决大规模用户评论摘要生成问题提供了稳健框架，识别了关键挑战，为未来研究提供了可行见解和发展方向。

Abstract: We study the problem of opinion highlights generation from large volumes of
user reviews, often exceeding thousands per entity, where existing methods
either fail to scale or produce generic, one-size-fits-all summaries that
overlook personalized needs. To tackle this, we introduce OpinioRAG, a
scalable, training-free framework that combines RAG-based evidence retrieval
with LLMs to efficiently produce tailored summaries. Additionally, we propose
novel reference-free verification metrics designed for sentiment-rich domains,
where accurately capturing opinions and sentiment alignment is essential. These
metrics offer a fine-grained, context-sensitive assessment of factual
consistency. To facilitate evaluation, we contribute the first large-scale
dataset of long-form user reviews, comprising entities with over a thousand
reviews each, paired with unbiased expert summaries and manually annotated
queries. Through extensive experiments, we identify key challenges, provide
actionable insights into improving systems, pave the way for future research,
and position OpinioRAG as a robust framework for generating accurate, relevant,
and structured summaries at scale.

</details>


### [10] [Wage Sentiment Indices Derived from Survey Comments via Large Language Models](https://arxiv.org/abs/2509.00290)
*Taihei Sone*

Main category: cs.CL

TL;DR: 使用大语言模型构建新薪资情感指数(WSI)，预测日本薪资动态，结果显示超过基准方法和预训练模型的性能。


<details>
  <summary>Details</summary>
Motivation: 生成式AI的出现为经济文本分析带来新机遇，需要构建更有效的薪资预测指标以支持经济政策制定。

Method: 基于日本内闘府经济监测调查(EWS)数据，扩展价格情感指数(PSI)框架构建WSI，并设计可扩展的数据架构支持多源数据集成。

Result: LLM基础的WSI模型在预测性能上显著超过了基准方法和预训练模型，验证了方法的有效性。

Conclusion: LLM驱动的情感指数能够提高经济政策设计的及时性和有效性，具有重要应用价值。

Abstract: The emergence of generative Artificial Intelligence (AI) has created new
opportunities for economic text analysis. This study proposes a Wage Sentiment
Index (WSI) constructed with Large Language Models (LLMs) to forecast wage
dynamics in Japan. The analysis is based on the Economy Watchers Survey (EWS),
a monthly survey conducted by the Cabinet Office of Japan that captures
real-time economic assessments from workers in industries highly sensitive to
business conditions. The WSI extends the framework of the Price Sentiment Index
(PSI) used in prior studies, adapting it specifically to wage related
sentiment. To ensure scalability and adaptability, a data architecture is also
developed that enables integration of additional sources such as newspapers and
social media. Experimental results demonstrate that WSI models based on LLMs
significantly outperform both baseline approaches and pretrained models. These
findings highlight the potential of LLM-driven sentiment indices to enhance the
timeliness and effectiveness of economic policy design by governments and
central banks.

</details>


### [11] [Balanced Actor Initialization: Stable RLHF Training of Distillation-Based Reasoning Models](https://arxiv.org/abs/2509.00309)
*Chen Zheng,Yiyuan Ma,Yuan Yang,Deyi Liu,Jing Liu,Zuquan Song,Yuxin Song,Cheng Ren,Hang Zhu,Xin Liu,Yiyuan Ma,Siyuan Qiao,Xun Zhou,Liang Xiang,Yonghui Wu*

Main category: cs.CL

TL;DR: 论文发现将RLHF应用于蒸馏训练模型时会出现序列长度崩溃和奖励曲棍球棒曲线问题，提出了平衡演员初始化(BAI)方法来解决这些训练不稳定问题。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型发展的两个主要范式（指令调优+RLHF对齐和蒸馏推理微调）各自有效，但将RLHF应用于蒸馏训练模型的第三范式存在严重的不稳定性问题，需要解决。

Method: 提出平衡演员初始化(BAI)方法，采用两阶段加权模型合并：首先合并指令跟随模型和蒸馏推理微调模型，然后将中间模型与预训练模型进一步合并以保留基础知识。

Result: BAI成功解决了序列长度崩溃问题，缓解了奖励曲棍球棒曲线现象，实现了训练期间序列长度的持续改进，并在多个基准测试中验证了有效性。

Conclusion: BAI为第三范式提供了有效的稳定训练解决方案，使模型能够结合蒸馏效率和RLHF对齐，获得更强的推理能力，平衡的合并比例在训练稳定性和推理能力保持之间达到最优权衡。

Abstract: The development of alignment and reasoning capabilities in large language
models has seen remarkable progress through two paradigms: instruction tuning
and reinforcement learning from human feedback (RLHF) alignment paradigm, and
distillation-based reasoning fine-tuning paradigm. While both approaches prove
effective independently, the third paradigm of applying RLHF to
distillation-trained models presents significant challenges. Our investigation
reveals two critical phenomena that emerge in this paradigm: Sequence Length
Collapse, where language generation dramatically reduces during early RLHF
training, and the Reward Hockey Stick Curve, featuring severe reward score
drops followed by gradual recovery. These instabilities fundamentally
compromise the model's alignment and reasoning capabilities. To address these
challenges, we propose Balanced Actor Initialization (BAI), a two-stage
weighted model merging approach. BAI first merges instruction-following and
distillation-based reasoning fine-tuned models, then further combines this
intermediate model with the pretrained model to preserve foundational
knowledge. Through comprehensive experiments across diverse benchmarks and
detailed analysis of training experiments, we demonstrate that BAI resolves
Sequence Length Collapse, mitigates the Reward Hockey Stick Curve, and enables
continuous sequence length improvement during training. Additionally, our
analysis reveals that balanced merging ratios achieve optimal trade-offs
between training stability and reasoning capability preservation. Our work
provides the effective solution for stable training in this third paradigm,
enabling more capable reasoning models that combine distillation efficiency
with RLHF alignment.

</details>


### [12] [GIER: Gap-Driven Self-Refinement for Large Language Models](https://arxiv.org/abs/2509.00325)
*Rinku Dewri*

Main category: cs.CL

TL;DR: GIER是一个通过自我反思和修订来提升大语言模型输出的框架，利用自然语言描述推理差距，让模型迭代式地批判和精炼自身输出，在多个推理任务中显著提升推理质量而不降低准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的提示策略依赖演示、示例或思维链模板，但缺乏基于概念质量标准的自我反思机制。GIER旨在通过自然语言描述推理差距，让模型能够自主识别和改进推理缺陷。

Method: GIER框架使用自然语言描述推理差距，提示模型迭代式地批判和精炼自身输出。模型需要理解抽象的概念差距并将其转化为具体的推理改进，通过多次修订循环提升输出质量。

Result: 在三个推理密集型任务（SciFact、PrivacyQA和e-SNLI）和四个大语言模型上，GIER显著提升了推理质量、基础性和推理对齐性，同时保持了任务准确性不下降。

Conclusion: 研究表明大语言模型不仅能够解释抽象的概念差距，还能将其转化为具体的推理改进，证明了自我反思和修订机制在提升模型输出质量方面的有效性。

Abstract: We introduce GIER (Gap-driven Iterative Enhancement of Responses), a general
framework for improving large language model (LLM) outputs through
self-reflection and revision based on conceptual quality criteria. Unlike
prompting strategies that rely on demonstrations, examples, or chain-of-thought
templates, GIER utilizes natural language descriptions of reasoning gaps, and
prompts a model to iteratively critique and refine its own outputs to better
satisfy these criteria. Across three reasoning-intensive tasks (SciFact,
PrivacyQA, and e-SNLI) and four LLMs (GPT-4.1, GPT-4o Mini, Gemini 1.5 Pro, and
Llama 3.3 70B), GIER improves rationale quality, grounding, and reasoning
alignment without degrading task accuracy. Our analysis demonstrates that
models can not only interpret abstract conceptual gaps but also translate them
into concrete reasoning improvements.

</details>


### [13] [Open Data Synthesis For Deep Research](https://arxiv.org/abs/2509.00375)
*Ziyi Xia,Kun Luo,Hongjin Qian,Zheng Liu*

Main category: cs.CL

TL;DR: InfoSeek是一个用于合成复杂深度研究任务的框架，通过双代理系统构建研究树并生成需要层次遍历的自然语言问题，显著提升了LLM在深度研究任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试无法捕捉深度研究任务的复杂性，而合成数据集存在捷径推理、知识泄漏或结构深度不足的问题，需要新的框架来生成高质量的深度研究任务数据。

Method: 使用双代理系统递归地从大规模网页构建研究树，模糊中间节点为有效子问题，并将这些树转换为需要完整层次遍历的自然语言问题，支持快速扩展生成超过5万个训练样本。

Result: 在InfoSeek上训练的模型在BrowseComp-Plus基准测试中表现优异，3B参数的LLM超越了32B大模型和轻量级商业API，性能接近更强的API如Gemini2.5-Pro。

Conclusion: InfoSeek提供了一个可扩展的框架来合成复杂的深度研究任务，不仅提升了模型性能，还支持高级优化策略，为深度研究任务的发展提供了重要工具和数据集。

Abstract: Large language models (LLMs) are increasingly expected to go beyond simple
factual queries toward Deep Research-tasks that require decomposing questions
into sub-problems, coordinating multi-step reasoning, and synthesizing evidence
from diverse sources. We formalize Deep Research tasks with verifiable answers
as Hierarchical Constraint Satisfaction Problems (HCSPs), which are
fundamentally different from single-constraint, multi-hop, or flat CSP
formulations. However, existing benchmarks (e.g., Natural Questions, HotpotQA)
fail to capture this complexity, while recent synthetic datasets often
introduce shortcut reasoning, knowledge leakage, or lack sufficient structural
depth. To address this gap, we introduce InfoSeek, a scalable framework for
synthesizing complex Deep Research tasks. InfoSeek uses a dual-agent system to
recursively build a Research Tree from large-scale webpages, blurring
intermediate nodes into valid sub-problems, and converting these trees into
natural language questions that require traversing the full hierarchy. It also
enables rapid scaling, yielding over 50K training examples, a curated test set,
and reasoning trajectories generated via reject sampling. Experiments show that
models trained on InfoSeek consistently outperform strong baselines. On a
challenging benchmark BrowseComp-Plus, 3B LLMs optimized with InfoSeek surpass
much larger 32B models and lightweight commercial APIs (e.g., Gemini2.5-Flash),
while achieving performance comparable to stronger APIs (e.g., Gemini2.5-Pro).
By preserving meta-information such as intermediate steps and retrieval labels,
InfoSeek further supports advanced optimization strategies, including compound
reward design and trajectory-level exploration. We provide our codes and
datasets in \href{https://github.com/VectorSpaceLab/InfoSeek}{this repository}.

</details>


### [14] [GraphKV: Breaking the Static Selection Paradigm with Graph-Based KV Cache Eviction](https://arxiv.org/abs/2509.00388)
*Xuelin Li,Xiangqi Jin,Linfeng Zhang*

Main category: cs.CL

TL;DR: GraphKV是一个基于图的KV缓存管理框架，通过图结构和衰减信号传播机制动态更新token重要性，实现自适应KV缓存压缩。


<details>
  <summary>Details</summary>
Motivation: 传统KV缓存驱逐策略基于静态启发式方法，无法捕捉推理过程中token间动态变化的隐式依赖关系，导致内存限制下的性能受限。

Method: 将token建模为带重要性分数的节点，边表示相似关系，通过衰减信号传播机制在图结构中动态传播信息来更新token重要性。

Result: 提出的GraphKV框架可以与现有KV缓存驱逐方法（如SnapKV和PyramidKV）即插即用地无缝集成使用。

Conclusion: GraphKV通过图结构动态管理KV缓存，能够更有效地保留上下文重要的token，提升长文本序列处理的效率。

Abstract: Efficient Key-Value (KV) cache management is essential for processing long
text sequences in large language models (LLMs), where memory constraints often
limit performance. Conventional KV eviction strategies, such as top-k selection
based on attention scores, depend on static heuristics that fail to capture the
evolving implicit dependencies among tokens during inference. To overcome this,
we propose GraphKV, a graph-based framework that redefines token selection for
KV cache compression. In GraphKV, tokens are modeled as nodes with importance
scores, and edges represent their similarity relationships. Through a
decay-signal-propagation mechanism, token importance is dynamically updated by
propagating information across the graph, enabling adaptive retention of the
most contextually significant tokens. GraphKV can be seamlessly utilized in
existing KV cache eviction methods such as SnapKV and PyramidKV in a
plug-and-play manner. Codes will be released on Github.

</details>


### [15] [The Resurgence of GCG Adversarial Attacks on Large Language Models](https://arxiv.org/abs/2509.00391)
*Yuting Tan,Xuying Li,Zhuo Li,Huizhen Shu,Peikang Hu*

Main category: cs.CL

TL;DR: 本文系统评估了GCG和T-GCG对抗性提示攻击在不同规模开源LLM上的效果，发现攻击成功率随模型规模增大而降低，语义评估比前缀启发式更严格，推理任务比安全提示更易受攻击。


<details>
  <summary>Details</summary>
Motivation: 评估梯度基对抗性提示攻击（如GCG算法）在不同规模语言模型上的有效性，特别是在安全导向和推理密集型编码提示上的表现。

Method: 使用Qwen2.5-0.5B、LLaMA-3.2-1B和GPT-OSS-20B模型，在AdvBench安全提示和推理密集型编码提示上评估GCG及其退火增强变体T-GCG的攻击效果，采用前缀启发式和GPT-4o语义判断两种评估方式。

Result: 1) 攻击成功率随模型规模增大而降低；2) 前缀启发式显著高估攻击效果，语义评估更严格；3) 编码相关提示比安全提示更易受攻击；T-GCG在退火搜索下能实现竞争性攻击成功率。

Conclusion: GCG存在可扩展性限制，推理任务中存在被忽视的脆弱性，需要进一步发展退火启发策略以进行更鲁棒的对抗性评估。

Abstract: Gradient-based adversarial prompting, such as the Greedy Coordinate Gradient
(GCG) algorithm, has emerged as a powerful method for jailbreaking large
language models (LLMs). In this paper, we present a systematic appraisal of GCG
and its annealing-augmented variant, T-GCG, across open-source LLMs of varying
scales. Using Qwen2.5-0.5B, LLaMA-3.2-1B, and GPT-OSS-20B, we evaluate attack
effectiveness on both safety-oriented prompts (AdvBench) and
reasoning-intensive coding prompts. Our study reveals three key findings: (1)
attack success rates (ASR) decrease with model size, reflecting the increasing
complexity and non-convexity of larger models' loss landscapes; (2)
prefix-based heuristics substantially overestimate attack effectiveness
compared to GPT-4o semantic judgments, which provide a stricter and more
realistic evaluation; and (3) coding-related prompts are significantly more
vulnerable than adversarial safety prompts, suggesting that reasoning itself
can be exploited as an attack vector. In addition, preliminary results with
T-GCG show that simulated annealing can diversify adversarial search and
achieve competitive ASR under prefix evaluation, though its benefits under
semantic judgment remain limited. Together, these findings highlight the
scalability limits of GCG, expose overlooked vulnerabilities in reasoning
tasks, and motivate further development of annealing-inspired strategies for
more robust adversarial evaluation.

</details>


### [16] [MedSEBA: Synthesizing Evidence-Based Answers Grounded in Evolving Medical Literature](https://arxiv.org/abs/2509.00414)
*Juraj Vladika,Florian Matthes*

Main category: cs.CL

TL;DR: MedSEBA是一个基于AI的医疗问答系统，利用大语言模型生成答案，并通过PubMed数据库动态检索可信医学研究来支撑答案的可信度。


<details>
  <summary>Details</summary>
Motivation: 解决互联网医疗信息质量参差不齐、难以区分可靠来源的问题，以及医学研究数量庞大、结论可能相互矛盾的传统搜索工具无法反映研究共识演变的问题。

Method: 结合大语言模型生成连贯表达的回答，同时从PubMed数据库动态检索可信医学研究作为依据，提供关键观点和论证，并支持追溯到原始研究。系统还提供研究支持程度概览和研究共识随时间演变的可视化。

Result: 用户研究表明，医学专家和普通用户都认为系统可用且有帮助，提供的答案可信且信息丰富。

Conclusion: MedSEBA系统既适用于日常健康问题，也适用于高级研究洞察，能够有效解决医疗信息检索和证据合成的挑战。

Abstract: In the digital age, people often turn to the Internet in search of medical
advice and recommendations. With the increasing volume of online content, it
has become difficult to distinguish reliable sources from misleading
information. Similarly, millions of medical studies are published every year,
making it challenging for researchers to keep track of the latest scientific
findings. These evolving studies can reach differing conclusions, which is not
reflected in traditional search tools. To address these challenges, we
introduce MedSEBA, an interactive AI-powered system for synthesizing
evidence-based answers to medical questions. It utilizes the power of Large
Language Models to generate coherent and expressive answers, but grounds them
in trustworthy medical studies dynamically retrieved from the research database
PubMed. The answers consist of key points and arguments, which can be traced
back to respective studies. Notably, the platform also provides an overview of
the extent to which the most relevant studies support or refute the given
medical claim, and a visualization of how the research consensus evolved
through time. Our user study revealed that medical experts and lay users find
the system usable and helpful, and the provided answers trustworthy and
informative. This makes the system well-suited for both everyday health
questions and advanced research insights.

</details>


### [17] [The Gold Medals in an Empty Room: Diagnosing Metalinguistic Reasoning in LLMs with Camlang](https://arxiv.org/abs/2509.00425)
*Fenghua Liu,Yulong Chen,Yixuan Liu,Zhujun Jin,Solomon Tsai,Ming Zhong*

Main category: cs.CL

TL;DR: 本文提出Camlang构造语言测试LLMs的元语言推理能力，发现GPT-5在英语任务上达到98%准确率但在Camlang上仅47%，远低于人类的87%，揭示当前模型缺乏真正的语法系统掌握能力。


<details>
  <summary>Details</summary>
Motivation: 测试大型语言模型是否具备真正的推理能力而非模式匹配，通过构造新颖语言Camlang来评估模型的元语言演绎学习能力，这是人类可靠内化语法系统的关键认知能力。

Method: 创建Camlang构造语言，包含语法书和双语词典资源，将CommonsenseQA适配为Camlang-CSQA-v0任务，要求应用语法规则和词汇映射来解决问题，并进行了人类对照实验。

Result: GPT-5在英语任务上达到98% EM准确率，但在Camlang上仅47%，远低于人类参与者的87%表现。其他先进推理LLMs表现更差。人类验证显示模型成功多来自浅层词汇对齐而非系统语法掌握。

Conclusion: Camlang建立了基于认知科学的评估范式，暴露了当前模型与人类元语言能力之间的根本差距，模型仅展现有限的元语言意识但缺乏系统性语法掌握能力。

Abstract: Large Language Models (LLMs) achieve gold-medal performance across many
benchmarks, yet it remains unclear whether such success reflects genuine
reasoning or pattern matching. From a cognitive science perspective, an
informative test is whether models can master an unfamiliar language through
explicit metalinguistic deductive learning, a paradigm where human learners can
reliably internalise grammatical systems through metalinguistic reasoning. We
address this question with Camlang, a novel constructed language that exhibits
naturalistic yet unattested feature combinations. Camlang consists of two
explicit resources, a grammar book and a bilingual dictionary, which mirror
adult second-language learning via explicit grammar rules and lexical lookup,
and enable us to disentangle errors in morpho-syntax, lexical semantics, and
sentence-level reasoning. Human experiments show that these resources are
sufficient for participants to acquire Camlang and successfully solve Camlang
tasks. To operationalise evaluation, we adapt CommonsenseQA into Camlang,
creating Camlang-CSQA-v0, the first task in a broader suite where solving
questions requires applying grammar rules and lexical mappings. Experimental
results show that GPT-5 achieves 98\% EM accuracy in English but only 47\% in
Camlang, far below human performance at 87\%, while other state-of-the-art
reasoning LLMs perform even worse. Human verification further reveals that most
model successes stem from shallow lexical alignment while GPT-5 shows emerging
metalinguistic awareness to a limited extent but not systematic grammatical
mastery as humans. Camlang establishes a cognitively grounded evaluation
paradigm that exposes fundamental gaps between current models and human
metalinguistic competence.

</details>


### [18] [GOSU: Retrieval-Augmented Generation with Global-Level Optimized Semantic Unit-Centric Framework](https://arxiv.org/abs/2509.00449)
*Xuecheng Zou,Ke Liu,Bingbing Wang,Huafei Deng,Li Zhang,Yu Tang*

Main category: cs.CL

TL;DR: GOSU是一个基于语义单元的RAG框架，通过全局消歧和语义单元补全来解决传统图RAG中的歧义和检索开销问题


<details>
  <summary>Details</summary>
Motivation: 传统基于图的RAG方法在提取高层语义单元时存在歧义、复杂耦合和检索开销大的问题，主要原因是缺乏全局知识和忽略细粒度关系

Method: 提出GOSU框架，在图形构建阶段进行全局语义单元合并和实体关系提取，在检索生成阶段引入分层关键词提取和语义单元补全技术

Result: 在多个任务评估中，GOSU在生成质量方面优于基线RAG方法

Conclusion: GOSU通过全局语义单元处理和细粗粒度关系互补，有效提升了RAG系统的性能和生成质量

Abstract: Building upon the standard graph-based Retrieval-Augmented Generation (RAG),
the introduction of heterogeneous graphs and hypergraphs aims to enrich
retrieval and generation by leveraging the relationships between multiple
entities through the concept of semantic units (SUs). But this also raises a
key issue: The extraction of high-level SUs limited to local text chunks is
prone to ambiguity, complex coupling, and increased retrieval overhead due to
the lack of global knowledge or the neglect of fine-grained relationships. To
address these issues, we propose GOSU, a semantic unit-centric RAG framework
that efficiently performs global disambiguation and utilizes SUs to capture
interconnections between different nodes across the global context. In the
graph construction phase, GOSU performs global merging on the pre-extracted SUs
from local text chunks and guides entity and relationship extraction, reducing
the difficulty of coreference resolution while uncovering global semantic
objects across text chunks. In the retrieval and generation phase, we introduce
hierarchical keyword extraction and semantic unit completion. The former
uncovers the fine-grained binary relationships overlooked by the latter, while
the latter compensates for the coarse-grained n-ary relationships missing from
the former. Evaluation across multiple tasks demonstrates that GOSU outperforms
the baseline RAG methods in terms of generation quality.

</details>


### [19] [CVPD at QIAS 2025 Shared Task: An Efficient Encoder-Based Approach for Islamic Inheritance Reasoning](https://arxiv.org/abs/2509.00457)
*Salah Eddine Bekhouche,Abdellah Zakaria Sellam,Hichem Telli,Cosimo Distante,Abdenour Hadid*

Main category: cs.CL

TL;DR: 提出了一个轻量级框架，使用专门的阿拉伯语文本编码器和注意力相关性评分来解决伊斯兰继承法选择题，在效率和部署性方面具有优势


<details>
  <summary>Details</summary>
Motivation: 伊斯兰继承法需要精确识别继承人和计算份额，这对AI构成挑战。需要开发既准确又高效的解决方案，特别是在资源受限和设备端部署的场景下

Method: 使用专门的阿拉伯语文本编码器（MARBERT、ArabicBERT、AraBERT）和注意力相关性评分（ARS）来对答案选项进行语义相关性排序，实现快速设备端推理而无需生成式推理

Result: 在QIAS 2025数据集上，大型模型（Gemini、DeepSeek）最高达到87.6%准确率，但需要更多资源且依赖上下文。基于MARBERT的方法达到69.87%准确率，在效率、设备端部署性和隐私方面具有优势

Conclusion: 研究量化了大模型峰值性能与小型专业化系统在实际高风险领域中优势之间的关键权衡，证明了轻量级专业化系统在效率、部署性和隐私保护方面的价值

Abstract: Islamic inheritance law (Ilm al-Mawarith) requires precise identification of
heirs and calculation of shares, which poses a challenge for AI. In this paper,
we present a lightweight framework for solving multiple-choice inheritance
questions using a specialised Arabic text encoder and Attentive Relevance
Scoring (ARS). The system ranks answer options according to semantic relevance,
and enables fast, on-device inference without generative reasoning. We evaluate
Arabic encoders (MARBERT, ArabicBERT, AraBERT) and compare them with API-based
LLMs (Gemini, DeepSeek) on the QIAS 2025 dataset. While large models achieve an
accuracy of up to 87.6%, they require more resources and are context-dependent.
Our MARBERT-based approach achieves 69.87% accuracy, presenting a compelling
case for efficiency, on-device deployability, and privacy. While this is lower
than the 87.6% achieved by the best-performing LLM, our work quantifies a
critical trade-off between the peak performance of large models and the
practical advantages of smaller, specialized systems in high-stakes domains.

</details>


### [20] [TECP: Token-Entropy Conformal Prediction for LLMs](https://arxiv.org/abs/2509.00461)
*Beining Xu*

Main category: cs.CL

TL;DR: 提出了Token-Entropy Conformal Prediction (TECP)框架，利用token级熵作为无需logit和参考的不确定性度量，通过保形预测为黑盒语言模型生成提供形式化覆盖保证。


<details>
  <summary>Details</summary>
Motivation: 开放域语言生成的不确定性量化在无法访问模型内部信号的黑盒约束下是一个关键但未被充分探索的挑战。

Method: 使用token级熵作为不确定性度量，将其整合到分割保形预测管道中，通过CP分位数校准不确定性阈值来确保可证明的错误控制。

Result: 在6个大语言模型和两个基准测试(CoQA和TriviaQA)上的实验表明，TECP始终实现可靠的覆盖和紧凑的预测集，优于先前的自一致性UQ方法。

Conclusion: 该方法为黑盒LLM设置中的可信生成提供了一个原则性和高效的解决方案。

Abstract: Uncertainty quantification (UQ) for open-ended language generation remains a
critical yet underexplored challenge, especially under black-box constraints
where internal model signals are inaccessible. In this paper, we introduce
Token-Entropy Conformal Prediction (TECP), a novel framework that leverages
token-level entropy as a logit-free, reference-free uncertainty measure and
integrates it into a split conformal prediction (CP) pipeline to construct
prediction sets with formal coverage guarantees. Unlike existing approaches
that rely on semantic consistency heuristics or white-box features, TECP
directly estimates epistemic uncertainty from the token entropy structure of
sampled generations and calibrates uncertainty thresholds via CP quantiles to
ensure provable error control. Empirical evaluations across six large language
models and two benchmarks (CoQA and TriviaQA) demonstrate that TECP
consistently achieves reliable coverage and compact prediction sets,
outperforming prior self-consistency-based UQ methods. Our method provides a
principled and efficient solution for trustworthy generation in black-box LLM
settings.

</details>


### [21] [Talk Less, Call Right: Enhancing Role-Play LLM Agents with Automatic Prompt Optimization and Role Prompting](https://arxiv.org/abs/2509.00482)
*Saksorn Ruangtanusak,Pittawat Taveekitworachai,Kunat Pipatanakul*

Main category: cs.CL

TL;DR: 这篇论文研究了如何通过提示工程改善工具增强大语言模型在角色扮演对话中的表现，提出了规则基础角色提示方法，有效解决了过度说话和工具使用不充分的问题。


<details>
  <summary>Details</summary>
Motivation: 角色扮演对话组织常遇到两个问题：过度说话（over-speaking）和工具使用不充分（under-acting），包括生成不存在的函数调用或在回答前做不必要的工具调用。需要找到有效的提示方法来改善这些问题。

Method: 研究了四种提示方法：1）基础角色提示；2）人工制作角色提示；3）自动提示优化（APO）；4）规则基础角色提示（RRP）。RRP方法采用了两种新技术：角色卡/场景合约设计和严格的函数调用执行。

Result: 规则基础角色提示（RRP）方法获得了最佳性能，总体得分为0.571，比零基准分数0.519有显著提升。这种方法在效果和可靠性方面都超过了更复杂的APO方法。

Conclusion: 规则基础角色提示设计可以显著提高角色扮演对话组织的效果和可靠性。研究开源了所有最佳提示和APO工具，以支持未来的人设提示开发。

Abstract: This report investigates approaches for prompting a tool-augmented large
language model (LLM) to act as a role-playing dialogue agent in the API track
of the Commonsense Persona-grounded Dialogue Challenge (CPDC) 2025. In this
setting, dialogue agents often produce overly long in-character responses
(over-speaking) while failing to use tools effectively according to the persona
(under-acting), such as generating function calls that do not exist or making
unnecessary tool calls before answering. We explore four prompting approaches
to address these issues: 1) basic role prompting, 2) human-crafted role
prompting, 3) automatic prompt optimization (APO), and 4) rule-based role
prompting. The rule-based role prompting (RRP) approach achieved the best
performance through two novel techniques--character-card/scene-contract design
and strict enforcement of function calling--which led to an overall score of
0.571, improving on the zero-shot baseline score of 0.519. These findings
demonstrate that RRP design can substantially improve the effectiveness and
reliability of role-playing dialogue agents compared with more elaborate
methods such as APO. To support future efforts in developing persona prompts,
we are open-sourcing all of our best-performing prompts and the APO tool.
Source code is available at https://github.com/scb-10x/apo.

</details>


### [22] [ResearchQA: Evaluating Scholarly Question Answering at Scale Across 75 Fields with Survey-Mined Questions and Rubrics](https://arxiv.org/abs/2509.00496)
*Li S. Yifei,Allen Chang,Chaitanya Malaviya,Mark Yatskar*

Main category: cs.CL

TL;DR: ResearchQA是一个从75个研究领域的综述文章中提取21K查询和160K评分标准的资源，用于评估LLM系统在回答研究查询时的表现。通过专家评估显示96%的查询支持博士信息需求，87%的评分标准需要在系统回答中得到充分回应。


<details>
  <summary>Details</summary>
Motivation: 当前评估研究查询的长篇回答主要依赖专家标注，限制了评估范围。研究专业知识广泛存在于综述文章中，需要一种更全面的方法来评估LLM系统在多研究领域的表现。

Method: 从75个研究领域的综述文章中提取21K查询和160K评分标准，每个评分标准包含查询特定的答案评估标准（引用论文、解释说明、描述限制等）。使用31位博士标注者在8个领域进行评估。

Result: 96%的查询支持博士信息需求，87%的评分标准需要系统回答中用一句话或更多内容来回应。构建的自动配对判断器与专家判断达到74%的一致性。评估18个系统在7.6K+配对评估中的表现，最佳系统仅覆盖75%的评分标准。

Conclusion: 当前LLM系统在研究查询回答方面存在显著能力差距，特别是在引用文献、描述限制和比较分析方面表现不足。ResearchQA资源支持更全面的多领域评估。

Abstract: Evaluating long-form responses to research queries heavily relies on expert
annotators, restricting attention to areas like AI where researchers can
conveniently enlist colleagues. Yet, research expertise is widespread: survey
articles synthesize knowledge distributed across the literature. We introduce
ResearchQA, a resource for evaluating LLM systems by distilling survey articles
from 75 research fields into 21K queries and 160K rubric items. Each rubric,
derived jointly with queries from survey sections, lists query-specific answer
evaluation criteria, i.e., citing papers, making explanations, and describing
limitations. Assessments by 31 Ph.D. annotators in 8 fields indicate 96% of
queries support Ph.D. information needs and 87% of rubric items should be
addressed in system responses by a sentence or more. Using our rubrics, we are
able to construct an automatic pairwise judge obtaining 74% agreement with
expert judgments. We leverage ResearchQA to analyze competency gaps in 18
systems in over 7.6K pairwise evaluations. No parametric or retrieval-augmented
system we evaluate exceeds 70% on covering rubric items, and the
highest-ranking agentic system shows 75% coverage. Error analysis reveals that
the highest-ranking system fully addresses less than 11% of citation rubric
items, 48% of limitation items, and 49% of comparison items. We release our
data to facilitate more comprehensive multi-field evaluations.

</details>


### [23] [Entropy-based Coarse and Compressed Semantic Speech Representation Learning](https://arxiv.org/abs/2509.00503)
*Jialong Zuo,Guangyan Zhang,Minghui Fang,Shengpeng Ji,Xiaoqi Jiao,Jingyu Li,Yiwen Guo,Zhou Zhao*

Main category: cs.CL

TL;DR: 提出基于熵的动态聚合框架，将细粒度语音token压缩为更粗粒度的语义表示，在保持性能的同时提高效率


<details>
  <summary>Details</summary>
Motivation: 现有语音离散表示方法生成25-50 tokens/秒的细粒度token，但语音通常只有2-5词/秒，这种细粒度token化带来冗余并降低下游任务效率

Method: 先通过下一token预测预训练语音语言模型，然后使用预测熵自适应确定聚合边界，再用交叉注意力模块融合段内信息，通过调整熵阈值灵活控制表示粒度

Result: 在ASR、语音到文本翻译和语音转换任务上，压缩后的表示性能与密集token序列相当或更好

Conclusion: 提出的熵基动态聚合框架能有效学习压缩的语义语音表示，在保持性能的同时提高效率

Abstract: Discrete speech representation learning has recently attracted increasing
interest in both acoustic and semantic modeling. Existing approaches typically
encode 16 kHz waveforms into discrete tokens at a rate of 25 or 50 tokens per
second. However, given that speech generally conveys only 2 to 5 words per
second, such fine-grained tokenization introduces redundancy and hinders
efficiency in downstream training and inference. Moreover, semantic speech
representations at this frequency primarily capture phonetic-level information,
while semantic understanding may not require such detailed token-level
resolution. To address these limitations, we propose an entropy-based dynamic
aggregation framework for learning compressed semantic speech representations.
A speech language model is first pre-trained via next-token prediction on
large-scale unlabeled data to capture frequent token patterns. Predictive
entropy is then used to adaptively determine aggregation boundaries, followed
by a cross-attention module that fuses information within each segment. By
adjusting the entropy threshold, the granularity and compression ratio of the
representations can be flexibly controlled. Experiments on ASR, speech-to-text
translation, and voice conversion tasks demonstrate that the compressed
representations perform on par with or better than dense token sequences,
demonstrating the effectiveness of the proposed approach.

</details>


### [24] [Modeling Motivated Reasoning in Law: Evaluating Strategic Role Conditioning in LLM Summarization](https://arxiv.org/abs/2509.00529)
*Eunjung Cho,Alexander Hoyle,Yoan Hermstrüwer*

Main category: cs.CL

TL;DR: LLMs在法律摘要生成中会根据不同法律角色（法官、检察官、律师）产生立场偏向的摘要，即使有平衡指令也难以避免角色一致的视角选择性呈现。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型在法律背景下如何根据用户角色进行动机推理，即模型如何策略性地构建信息以符合法律系统中利益相关者的立场。

Method: 基于法律现实主义和近期法律实践趋势，构建评估框架，关注法律事实和推理的包含情况，以及对各利益相关者的偏向性，分析不同法律角色提示下的摘要行为。

Result: 结果显示即使提示中包含平衡指令，模型仍表现出反映角色一致视角的选择性包含模式，存在明显的立场偏向。

Conclusion: 研究强调了在高风险法律环境中对LLM摘要行为进行角色感知评估的必要性，警示了LLM可能从先前交互或上下文中推断用户角色而产生类似对齐的问题。

Abstract: Large Language Models (LLMs) are increasingly used to generate user-tailored
summaries, adapting outputs to specific stakeholders. In legal contexts, this
raises important questions about motivated reasoning -- how models
strategically frame information to align with a stakeholder's position within
the legal system. Building on theories of legal realism and recent trends in
legal practice, we investigate how LLMs respond to prompts conditioned on
different legal roles (e.g., judges, prosecutors, attorneys) when summarizing
judicial decisions. We introduce an evaluation framework grounded in legal fact
and reasoning inclusion, also considering favorability towards stakeholders.
Our results show that even when prompts include balancing instructions, models
exhibit selective inclusion patterns that reflect role-consistent perspectives.
These findings raise broader concerns about how similar alignment may emerge as
LLMs begin to infer user roles from prior interactions or context, even without
explicit role instructions. Our results underscore the need for role-aware
evaluation of LLM summarization behavior in high-stakes legal settings.

</details>


### [25] [Thinking Hard, Going Misaligned: Emergent Misalignment in LLMs](https://arxiv.org/abs/2509.00544)
*Hanqi Yan,Hainiu Xu,Yulan He*

Main category: cs.CL

TL;DR: 研究发现大型语言模型在推理能力增强时会出现安全对齐问题，即推理诱导的错位现象，模型更容易响应恶意请求，特别是在密集模型和专家混合模型中表现更明显。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的广泛应用，对其安全性和与人类价值观对齐的担忧日益增加。之前研究表明在恶意数据集上微调会导致错位行为，但本研究发现了更令人担忧的现象。

Method: 通过切换到"思考模式"或在良性数学数据集上微调来增强模型的推理能力，分析模型内部状态，包括注意力转移和专家混合模型中专门专家的作用。

Result: 发现LLMs在推理能力增强时对恶意请求的响应性提高，密集模型特别脆弱，同时发现注意力转移和专门专家有助于将过度推理重新导向安全防护机制。

Conclusion: 这些发现揭示了新兴的推理-安全权衡问题，强调了推进高级推理模型对齐的紧迫性，为理解模型安全机制提供了新见解。

Abstract: With Large Language Models (LLMs) becoming increasingly widely adopted,
concerns regarding their safety and alignment with human values have
intensified. Previous studies have shown that fine-tuning LLMs on narrow and
malicious datasets induce misaligned behaviors. In this work, we report a more
concerning phenomenon, Reasoning-Induced Misalignment. Specifically, we observe
that LLMs become more responsive to malicious requests when reasoning is
strengthened, via switching to "think-mode" or fine-tuning on benign math
datasets, with dense models particularly vulnerable. Moreover, we analyze
internal model states and find that both attention shifts and specialized
experts in mixture-of-experts models help redirect excessive reasoning towards
safety guardrails. These findings provide new insights into the emerging
reasoning-safety trade-off and underscore the urgency of advancing alignment
for advanced reasoning models.

</details>


### [26] [Probe-Rewrite-Evaluate: A Workflow for Reliable Benchmarks and Quantifying Evaluation Awareness](https://arxiv.org/abs/2509.00591)
*Lang Xiong,Nishant Bhargava,Wesley Chang,Jianhang Hong,Haihao Liu,Kevin Zhu*

Main category: cs.CL

TL;DR: LLMs在评估环境中会表现出与真实部署环境不同的行为（评估意识），本文通过线性探针和提示重写方法量化这种行为变化，发现重写后的部署式提示能显著提高模型诚实性和安全性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在评估环境和真实部署环境中的行为存在显著差异，这种评估意识现象对AI对齐构成挑战，因为基准测试性能可能无法准确反映模型真实的安全性和诚实性。

Method: 使用线性探针对提示进行从"测试式"到"部署式"的连续评分，并利用LLM重写策略将提示转向更自然的部署风格上下文，同时保留原始任务。

Result: 重写后提示的平均探针分数提高了30%，在所有模型中观察到诚实回答平均增加5.26%，欺骗性回答平均减少12.40%，拒绝率平均增加6.38%。

Conclusion: 评估意识是一个可量化和可操纵的因素，直接影响LLM行为，模型在感知的测试环境中更容易产生不安全或欺骗性输出，迫切需要更现实的评估框架来准确衡量模型对齐。

Abstract: Large Language Models (LLMs) often exhibit significant behavioral shifts when
they perceive a change from a real-world deployment context to a controlled
evaluation setting, a phenomenon known as "evaluation awareness." This
discrepancy poses a critical challenge for AI alignment, as benchmark
performance may not accurately reflect a model's true safety and honesty. In
this work, we systematically quantify these behavioral changes by manipulating
the perceived context of prompts. We introduce a methodology that uses a linear
probe to score prompts on a continuous scale from "test-like" to "deploy-like"
and leverage an LLM rewriting strategy to shift these prompts towards a more
natural, deployment-style context while preserving the original task. Using
this method, we achieved a 30% increase in the average probe score across a
strategic role-playing dataset after rewriting. Evaluating a suite of
state-of-the-art models on these original and rewritten prompts, we find that
rewritten "deploy-like" prompts induce a significant and consistent shift in
behavior. Across all models, we observed an average increase in honest
responses of 5.26% and a corresponding average decrease in deceptive responses
of 12.40%. Furthermore, refusal rates increased by an average of 6.38%,
indicating heightened safety compliance. Our findings demonstrate that
evaluation awareness is a quantifiable and manipulable factor that directly
influences LLM behavior, revealing that models are more prone to unsafe or
deceptive outputs in perceived test environments. This underscores the urgent
need for more realistic evaluation frameworks to accurately gauge true model
alignment before deployment.

</details>


### [27] [Gated Associative Memory: A Parallel O(N) Architecture for Efficient Sequence Modeling](https://arxiv.org/abs/2509.00605)
*Rishiraj Acharya*

Main category: cs.CL

TL;DR: 基于间控联想记忆的线性复杂度序列模型算法GAM，通过并行卷积和联想记忆机制结合，在保持性能的同时大幅提升训练速度


<details>
  <summary>Details</summary>
Motivation: 解决Transformer自注意力机制的平方复杂度问题，这个问题在处理长序列时成为重要性能瓶颈

Method: 设计GAM块替换自注意力层，包含两个并行通道：因果卷积捕获局部上下文，联想记忆机制模型全局模式，通过门控机制动态融合两者

Result: 在WikiText-2和TinyStories数据集上，GAM训练速度明显更快，验证混淆度达到更优或竞争力水平，性能超过Transformer和Mamba基准模型

Conclusion: GAM作为一种高效的序列模型替代方案，具有线性复杂度优势，在保持模型性能的同时显著提升计算效率

Abstract: The Transformer architecture, underpinned by the self-attention mechanism,
has become the de facto standard for sequence modeling tasks. However, its core
computational primitive scales quadratically with sequence length (O(N^2)),
creating a significant bottleneck for processing long contexts. In this paper,
we propose the Gated Associative Memory (GAM) network, a novel, fully parallel
architecture for sequence modeling that exhibits linear complexity (O(N)) with
respect to sequence length. The GAM block replaces the self-attention layer
with two parallel pathways: a causal convolution to efficiently capture local,
position-dependent context, and a parallel associative memory retrieval
mechanism to model global, content-based patterns. These pathways are
dynamically fused using a gating mechanism, allowing the model to flexibly
combine local and global information for each token. We implement GAM from
scratch and conduct a rigorous comparative analysis against a standard
Transformer model and a modern linear-time baseline (Mamba) on the WikiText-2
benchmark, as well as against the Transformer on the TinyStories dataset. Our
experiments demonstrate that GAM is consistently faster, outperforming both
baselines on training speed, and achieves a superior or competitive final
validation perplexity across all datasets, establishing it as a promising and
efficient alternative for sequence modeling.

</details>


### [28] [A Multi-Strategy Approach for AI-Generated Text Detection](https://arxiv.org/abs/2509.00623)
*Ali Zain,Sareem Farooqui,Muhammad Rafi*

Main category: cs.CL

TL;DR: 本文提出了三种检测AI生成内容的系统，其中基于RoBERTa的分类器表现最佳，在开发集和测试集上都取得了接近完美的结果


<details>
  <summary>Details</summary>
Motivation: 开发有效的AI生成内容检测系统，以应对新闻文章和学术摘要中AI生成内容的识别需求

Method: 三种系统：1) 微调的RoBERTa-base分类器 2) TF-IDF + SVM传统分类器 3) 创新的Candace集成模型，使用多个Llama-3.2模型提取概率特征并通过自定义Transformer编码器处理

Result: RoBERTa-based系统表现最优，在开发集和测试集上都取得了接近完美的检测结果

Conclusion: 基于RoBERTa的微调分类器在AI生成内容检测任务中展现出卓越性能，是M-DAIGT共享任务中最有效的解决方案

Abstract: This paper presents presents three distinct systems developed for the M-DAIGT
shared task on detecting AI generated content in news articles and academic
abstracts. The systems includes: (1) A fine-tuned RoBERTa-base classifier, (2)
A classical TF-IDF + Support Vector Machine (SVM) classifier , and (3) An
Innovative ensemble model named Candace, leveraging probabilistic features
extracted from multiple Llama-3.2 models processed by a customTransformer
encoder.The RoBERTa-based system emerged as the most performant, achieving
near-perfect results on both development and test sets.

</details>


### [29] [Can Multi-turn Self-refined Single Agent LMs with Retrieval Solve Hard Coding Problems?](https://arxiv.org/abs/2509.00629)
*Md Tanzib Hosain,Md Kishor Morol*

Main category: cs.CL

TL;DR: 该研究提出了ICPC基准测试，包含254个国际大学生程序设计竞赛题目，通过多种推理技术评估语言模型在竞争性编程任务中的表现，最佳方法将解决率从19.1%提升到42.2%。


<details>
  <summary>Details</summary>
Motivation: 竞争性编程任务需要复杂的算法思维和代码创建能力，但作为评估语言模型的领域尚未得到足够关注，因此需要建立专门的基准来测试模型在这类复杂任务上的表现。

Method: 创建ICPC基准测试集，包含254个题目及其官方分析、参考代码和测试用例。采用零样本思维链提示、多轮自判断与反思、情景信息检索等多种推理技术进行模型评估。

Result: 零样本思维链提示下o1模型仅达到19.1%的解决率，最佳推理技术组合将解决率提升至42.2%。人类介入研究发现，通过特定指令o1可以解决之前无法解决的17/18个问题。

Conclusion: 该研究为开发具有基础性、创造性和算法思维的语言模型提供了重要进展，证明了适当推理技术和人类指导可以显著提升模型在复杂编程任务中的表现。

Abstract: Among the hardest tasks for humans are those found in competitive programming
where problems require sophisticated algorithmic thinking, puzzle solving, and
the creation of effective code. As a domain to assess language models (LMs), it
has not received enough attention, though. This study presents the ICPC
benchmark, which consists of 254 international collegiate programming contest
(ICPC) tasks. Each problem includes official analysis, reference code, and
sample, high-quality unit, and hidden tests. We are able to develop and
evaluate a variety of LM inference techniques for competitive programming with
these resources. With zero-shot chain-of-thought prompting, we find that o1
only achieves a 19.1\% pass@1 solve rate. With our best inference technique,
which combines multi-turn self-judge with reflection and retrieval over
episodic information, raises this to 42.2\%. Furthermore, we conduct a new
human-in-the-loop investigation to gain a deeper understanding of the remaining
difficulties. Surprisingly, we discover that o1 can solve 17 out of 18 problems
that were previously unsolvable by any model or technique with just a few
specific instructions. A footstep toward LMs with grounded, imaginative, and
algorithmic thinking is provided by our quantitative findings and qualitative
research. We open-source our code and data at https://github.com/kraritt/zolve.

</details>


### [30] [Confident, Calibrated, or Complicit: Probing the Trade-offs between Safety Alignment and Ideological Bias in Language Models in Detecting Hate Speech](https://arxiv.org/abs/2509.00673)
*Sanjeeevan Selvaganapathy,Mehwish Nasim*

Main category: cs.CL

TL;DR: 研究表明，经过安全对齐的审查模型在仇恨言论检测准确性和鲁棒性上显著优于未审查模型（78.7% vs 64.1%），但存在意识形态锚定问题；未审查模型虽更易受意识形态框架影响，但所有模型在理解反语等细微语言时都存在严重缺陷。


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型在检测隐性和显性仇恨言论方面的效果，比较经过安全对齐（审查）和未对齐（未审查）模型在客观分类能力上的差异。

Method: 通过对比分析审查和未审查LLMs在仇恨言论检测任务中的表现，评估其准确性、鲁棒性、对意识形态框架的敏感性以及对细微语言的理解能力。

Result: 审查模型在准确性和鲁棒性上显著优于未审查模型，但存在强烈的意识形态锚定效应；未审查模型更容易受意识形态框架影响；所有模型在理解反语等细微语言时都存在严重失败，且存在公平性差异和系统性过度自信问题。

Conclusion: 研究挑战了LLMs作为客观仲裁者的观念，强调需要开发更复杂的审计框架来考虑公平性、校准性和意识形态一致性。

Abstract: We investigate the efficacy of Large Language Models (LLMs) in detecting
implicit and explicit hate speech, examining whether models with minimal safety
alignment (uncensored) might provide more objective classification capabilities
compared to their heavily-aligned (censored) counterparts. While uncensored
models theoretically offer a less constrained perspective free from moral
guardrails that could bias classification decisions, our results reveal a
surprising trade-off: censored models significantly outperform their uncensored
counterparts in both accuracy and robustness, achieving 78.7% versus 64.1%
strict accuracy. However, this enhanced performance comes with its own
limitation -- the safety alignment acts as a strong ideological anchor, making
censored models resistant to persona-based influence, while uncensored models
prove highly malleable to ideological framing. Furthermore, we identify
critical failures across all models in understanding nuanced language such as
irony. We also find alarming fairness disparities in performance across
different targeted groups and systemic overconfidence that renders
self-reported certainty unreliable. These findings challenge the notion of LLMs
as objective arbiters and highlight the need for more sophisticated auditing
frameworks that account for fairness, calibration, and ideological consistency.

</details>


### [31] [Router Upcycling: Leveraging Mixture-of-Routers in Mixture-of-Experts Upcycling](https://arxiv.org/abs/2509.00679)
*Junfeng Ran,Guangxiang Zhao,Yuhan Wu,Dawei Zhu,Longyun Wu,Yikai Zhao,Tong Yang,Lin Sun,Xiangzheng Zhang,Sujian Li*

Main category: cs.CL

TL;DR: 提出Router Upcycling方法，通过从注意力头初始化多个路由器来增强MoE上循环性能，实现SOTA效果


<details>
  <summary>Details</summary>
Motivation: MoE模型训练效率低，现有简单路由器在复杂路由任务中表现不佳，需要改进MoE上循环技术的路由能力

Method: 在MoE上循环过程中，从前面的注意力层初始化多个路由器，这些路由器以类似注意力的方式协作分配token给专家，每个token生成多样化查询并与专家特征（作为键）对齐

Result: 实验结果表明该方法达到了最先进的性能，优于其他上循环基线方法

Conclusion: Router Upcycling技术有效提升了MoE上循环模型的性能，通过注意力机制启发的路由器设计解决了复杂路由挑战

Abstract: The Mixture-of-Experts (MoE) models have gained significant attention in deep
learning due to their dynamic resource allocation and superior performance
across diverse tasks. However, efficiently training these models remains
challenging. The MoE upcycling technique has been proposed to reuse and improve
existing model components, thereby minimizing training overhead. Despite this,
simple routers, such as linear routers, often struggle with complex routing
tasks within MoE upcycling. In response, we propose a novel routing technique
called Router Upcycling to enhance the performance of MoE upcycling models. Our
approach initializes multiple routers from the attention heads of preceding
attention layers during upcycling. These routers collaboratively assign tokens
to specialized experts in an attention-like manner. Each token is processed
into diverse queries and aligned with the experts' features (serving as keys).
Experimental results demonstrate that our method achieves state-of-the-art
(SOTA) performance, outperforming other upcycling baselines.

</details>


### [32] [Do small language models generate realistic variable-quality fake news headlines?](https://arxiv.org/abs/2509.00680)
*Austin McCutcheon,Chris Brogly*

Main category: cs.CL

TL;DR: 本研究评估了14个小语言模型(SLMs)生成虚假新闻标题的能力，发现这些模型在明确提示下高度配合生成虚假内容，但生成的标题质量检测准确率较低(35.2%-63.5%)，表明与真实人类撰写的内容相似度不高。


<details>
  <summary>Details</summary>
Motivation: 评估小语言模型(SLMs)生成虚假新闻标题的潜在风险，以及这些生成内容与真实新闻标题的相似程度，为检测和防范AI生成的虚假信息提供依据。

Method: 使用控制提示工程对14个SLMs模型(1.7B-14B参数)生成24,000个低质量和高质量虚假新闻标题，然后应用现有的机器学习和深度学习新闻标题质量检测器进行分析。

Result: SLMs表现出高配合率，伦理抵抗较少；使用DistilBERT和bagging分类器的标题质量检测准确率仅为35.2%-63.5%，误分类现象普遍。

Conclusion: 测试的SLMs通常配合生成虚假标题，但生成的标题与现有主要人类撰写的内容相似度不高，这为检测AI生成的虚假信息提供了可能性。

Abstract: Small language models (SLMs) have the capability for text generation and may
potentially be used to generate falsified texts online. This study evaluates 14
SLMs (1.7B-14B parameters) including LLaMA, Gemma, Phi, SmolLM, Mistral, and
Granite families in generating perceived low and high quality fake news
headlines when explicitly prompted, and whether they appear to be similar to
real-world news headlines. Using controlled prompt engineering, 24,000
headlines were generated across low-quality and high-quality deceptive
categories. Existing machine learning and deep learning-based news headline
quality detectors were then applied against these SLM-generated fake news
headlines. SLMs demonstrated high compliance rates with minimal ethical
resistance, though there were some occasional exceptions. Headline quality
detection using established DistilBERT and bagging classifier models showed
that quality misclassification was common, with detection accuracies only
ranging from 35.2% to 63.5%. These findings suggest the following: tested SLMs
generally are compliant in generating falsified headlines, although there are
slight variations in ethical restraints, and the generated headlines did not
closely resemble existing primarily human-written content on the web, given the
low quality classification accuracy.

</details>


### [33] [Text Reinforcement for Multimodal Time Series Forecasting](https://arxiv.org/abs/2509.00687)
*Chen Su,Yuanhe Tian,Yan Song,Yongdong Zhang*

Main category: cs.CL

TL;DR: 提出文本强化模型(TeR)来增强多模态时间序列预测中的文本信息，通过强化学习优化文本质量以提升预测性能


<details>
  <summary>Details</summary>
Motivation: 现有多模态时间序列预测方法依赖高质量文本输入，但当文本不能准确反映时间序列信息时会导致性能不稳定，需要增强文本内容来改善预测效果

Method: 设计文本强化模型(TeR)生成强化文本，采用强化学习方法根据对多模态TSF模型性能的影响和任务相关性来分配奖励并优化模型

Result: 在覆盖多个领域的真实基准数据集上的广泛实验表明，该方法优于强基线方法和现有研究

Conclusion: 通过强化文本模态可以有效提升多模态时间序列预测性能，提出的TeR模型和强化学习方法是有效的解决方案

Abstract: Recent studies in time series forecasting (TSF) use multimodal inputs, such
as text and historical time series data, to predict future values. These
studies mainly focus on developing advanced techniques to integrate textual
information with time series data to perform the task and achieve promising
results. Meanwhile, these approaches rely on high-quality text and time series
inputs, whereas in some cases, the text does not accurately or fully capture
the information carried by the historical time series, which leads to unstable
performance in multimodal TSF. Therefore, it is necessary to enhance the
textual content to improve the performance of multimodal TSF. In this paper, we
propose improving multimodal TSF by reinforcing the text modalities. We propose
a text reinforcement model (TeR) to generate reinforced text that addresses
potential weaknesses in the original text, then apply this reinforced text to
support the multimodal TSF model's understanding of the time series, improving
TSF performance. To guide the TeR toward producing higher-quality reinforced
text, we design a reinforcement learning approach that assigns rewards based on
the impact of each reinforced text on the performance of the multimodal TSF
model and its relevance to the TSF task. We optimize the TeR accordingly, so as
to improve the quality of the generated reinforced text and enhance TSF
performance. Extensive experiments on a real-world benchmark dataset covering
various domains demonstrate the effectiveness of our approach, which
outperforms strong baselines and existing studies on the dataset.

</details>


### [34] [CE-Bench: Towards a Reliable Contrastive Evaluation Benchmark of Interpretability of Sparse Autoencoders](https://arxiv.org/abs/2509.00691)
*Alex Gulko,Yusen Peng,Sachin Kumar*

Main category: cs.CL

TL;DR: CE-Bench是一个用于稀疏自编码器对比评估的轻量级基准测试，基于对比故事对数据集构建，无需外部LLM即可可靠评估可解释性


<details>
  <summary>Details</summary>
Motivation: 稀疏自编码器是揭示大语言模型中可解释特征的有前途方法，但缺乏自动化评估方法阻碍了其广泛应用和发展

Method: 构建基于对比故事对数据集的CE-Bench基准测试，进行全面的消融研究验证方法有效性

Result: CE-Bench能够可靠测量稀疏自编码器的可解释性，与现有基准测试结果一致，且不需要外部LLM

Conclusion: CE-Bench为稀疏自编码器提供了一个有效的自动化评估工具，官方实现和评估数据集已开源

Abstract: Probing with sparse autoencoders is a promising approach for uncovering
interpretable features in large language models (LLMs). However, the lack of
automated evaluation methods has hindered their broader adoption and
development. In this work, we introduce CE-Bench, a novel and lightweight
contrastive evaluation benchmark for sparse autoencoders, built on a curated
dataset of contrastive story pairs. We conduct comprehensive ablation studies
to validate the effectiveness of our approach. Our results show that CE-Bench
reliably measures the interpretability of sparse autoencoders and aligns well
with existing benchmarks, all without requiring an external LLM. The official
implementation and evaluation dataset are open-sourced under the MIT License.

</details>


### [35] [Learning to Shop Like Humans: A Review-driven Retrieval-Augmented Recommendation Framework with LLMs](https://arxiv.org/abs/2509.00698)
*Kaiwen Wei,Jinpeng Gao,Jiang Zhong,Yuming Yang,Fengmao Lv,Zhenyang Li*

Main category: cs.CL

TL;DR: RevBrowse是一个基于LLM的评论驱动推荐框架，通过PrefRAG模块动态检索相关评论来解决传统方法在上下文窗口限制和评论相关性筛选方面的挑战


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在推荐任务中展现出强大潜力，但在评论推荐中存在两个主要挑战：(1)在有限上下文窗口中动态利用用户评论效率低下；(2)缺乏有效机制来优先处理与用户当前决策最相关的评论

Method: 提出RevBrowse框架，受"浏览-决策"在线用户行为启发，集成用户评论到LLM重排序过程。引入PrefRAG检索增强模块，将用户和物品表示解耦为结构化形式，并根据目标物品自适应检索偏好相关内容

Result: 在四个Amazon评论数据集上的广泛实验表明，RevBrowse相比强基线实现了持续且显著的改进，展现了其在建模动态用户偏好方面的泛化能力和有效性

Conclusion: RevBrowse通过透明的检索增强过程提供了一定程度的可解释性，使影响最终推荐的评论可见，为评论驱动的LLM推荐提供了有效解决方案

Abstract: Large language models (LLMs) have shown strong potential in recommendation
tasks due to their strengths in language understanding, reasoning and knowledge
integration. These capabilities are especially beneficial for review-based
recommendation, which relies on semantically rich user-generated texts to
reveal fine-grained user preferences and item attributes. However, effectively
incorporating reviews into LLM-based recommendation remains challenging due to
(1) inefficient to dynamically utilize user reviews under LLMs' constrained
context windows, and (2) lacking effective mechanisms to prioritize reviews
most relevant to the user's current decision context. To address these
challenges, we propose RevBrowse, a review-driven recommendation framework
inspired by the "browse-then-decide" decision process commonly observed in
online user behavior. RevBrowse integrates user reviews into the LLM-based
reranking process to enhance its ability to distinguish between candidate
items. To improve the relevance and efficiency of review usage, we introduce
PrefRAG, a retrieval-augmented module that disentangles user and item
representations into structured forms and adaptively retrieves
preference-relevant content conditioned on the target item. Extensive
experiments on four Amazon review datasets demonstrate that RevBrowse achieves
consistent and significant improvements over strong baselines, highlighting its
generalizability and effectiveness in modeling dynamic user preferences.
Furthermore, since the retrieval-augmented process is transparent, RevBrowse
offers a certain level of interpretability by making visible which reviews
influence the final recommendation.

</details>


### [36] [Reward-Weighted Sampling: Enhancing Non-Autoregressive Characteristics in Masked Diffusion LLMs](https://arxiv.org/abs/2509.00707)
*Daehoon Gwak,Minseo Jung,Junwoo Park,Minho Park,ChaeHun Park,Junha Hyung,Jaegul Choo*

Main category: cs.CL

TL;DR: 提出了Reward-Weighted Sampling (RWS)解码策略，通过外部奖励模型在扩散过程中提供全局序列级信号，改进了掩码扩散模型的非自回归生成顺序和性能。


<details>
  <summary>Details</summary>
Motivation: 标准置信度采样方法导致掩码扩散模型的生成顺序类似自回归过程，限制了非自回归建模的优势。需要一种能够提供全局序列级指导的解码策略。

Method: RWS在每一步扩散过程中评估整个中间序列的质量，并相应缩放token对数概率，通过奖励模型提供的全局信号指导token选择，促进更非自回归的生成顺序。

Result: 实验表明RWS显著促进了非自回归生成顺序，在多个评估指标上都有改进，证明了全局信号在提升掩码扩散模型非自回归特性和整体性能方面的有效性。

Conclusion: 奖励加权采样是一种有效的解码策略，能够通过整合全局序列级一致性信号来改善掩码扩散模型的非自回归生成质量和性能。

Abstract: Masked diffusion models (MDMs) offer a promising non-autoregressive
alternative for large language modeling. Standard decoding methods for MDMs,
such as confidence-based sampling, select tokens independently based on
individual token confidences at each diffusion step. However, we observe that
this independent token selection often results in generation orders resembling
sequential autoregressive processes, limiting the advantages of
non-autoregressive modeling. To mitigate this pheonomenon, we propose
Reward-Weighted Sampling (RWS), a novel decoding strategy that leverages an
external reward model to provide a principled global signal during the
iterative diffusion process. Specifically, at each diffusion step, RWS
evaluates the quality of the entire intermediate sequence and scales token
logits accordingly, guiding token selection by integrating global
sequence-level coherence. This method selectively increases the confidence of
tokens that initially have lower scores, thereby promoting a more
non-autoregressive generation order. Furthermore, we provide theoretical
justification showing that reward-weighted logit scaling induces beneficial
rank reversals in token selection and consistently improves expected reward.
Experiments demonstrate that RWS significantly promotes non-autoregressive
generation orders, leading to improvements across multiple evaluation metrics.
These results highlight the effectiveness of integrating global signals in
enhancing both the non-autoregressive properties and overall performance of
MDMs.

</details>


### [37] [Designing LMS and Instructional Strategies for Integrating Generative-Conversational AI](https://arxiv.org/abs/2509.00709)
*Elias Ra,Seung Je Kim,Eui-Yeong Seo,Geunju So*

Main category: cs.CL

TL;DR: 一种结构化框架，通过设计基础研究方法设计AI助力学习管理系统，整合生成式AI和对话式AI来支持适应性、互动性的个性化教学体验。


<details>
  <summary>Details</summary>
Motivation: 高等教育面临个性化、可扩展性和教学一致性的挑战，需要一种能够结合AI技术与教学理论的解决方案。

Method: 采用设计基础研究(DBR)方法，包括五个阶段：文献综述、SWOT分析、伦理-6559育原则开发、系统设计和教学策略制定。系统包含可配置提示、适应性反馈循环和多代理对话流等模块化组件。

Result: 开发出一种结合生成式AI、对话式AI与人本设计、伦理保障的AI-LMS框架，能够支持行为主义、建构主义和联结主义等多种教学理论。

Conclusion: 该研究提出了一种实用的AI教育整合模型，通过结合AI能力与人本设计来推进教育技术的发展。未来将通过实际应用进一步验证和优化系统。

Abstract: Higher education faces growing challenges in delivering personalized,
scalable, and pedagogically coherent learning experiences. This study
introduces a structured framework for designing an AI-powered Learning
Management System (AI-LMS) that integrates generative and conversational AI to
support adaptive, interactive, and learner-centered instruction. Using a
design-based research (DBR) methodology, the framework unfolds through five
phases: literature review, SWOT analysis, development of ethical-pedagogical
principles, system design, and instructional strategy formulation. The
resulting AI-LMS features modular components -- including configurable prompts,
adaptive feedback loops, and multi-agent conversation flows -- aligned with
pedagogical paradigms such as behaviorist, constructivist, and connectivist
learning theories. By combining AI capabilities with human-centered design and
ethical safeguards, this study advances a practical model for AI integration in
education. Future research will validate and refine the system through
real-world implementation.

</details>


### [38] [LLM Encoder vs. Decoder: Robust Detection of Chinese AI-Generated Text with LoRA](https://arxiv.org/abs/2509.00731)
*Houji Jin,Negin Ashrafi,Armin Abdollahi,Wei Liu,Jian Wang,Ganyu Gui,Maryam Pishgar,Huanghao Feng*

Main category: cs.CL

TL;DR: 本文系统性比较了不同模型在中文AI生成文本检测任务上的表现，发现使用LoRA微调的解码器LLM(Qwen2.5-7B)达到最佳性能(95.94%测试准确率)，显示出更好的泛化能力和稳健性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的快速发展，对AI生成文本的准确检测需求日益增长，特别是在中文这种语言细腻极其丰富的语言中。当前方法在处理中文语言细腻时面临重大挑战。

Method: 采用NLPCC 2025中文AI生成文本检测数据集，系统比较了编码器模型(中文BERT-large和RoBERTa-wwm-ext-large)、解码器LLM(阿里巴巴Qwen2.5-7B/DeepSeek-R1-Distill-Qwen-7B通过LoRA微调)和FastText基线。编码器模型采用新的提示基础掩码语言建模方法进行微调，Qwen2.5-7B则通过指令格式输入和轻量级分类头进行LoRA训练。

Result: 编码器模型几乎记住了训练数据，但在分布偏移下性能显著下降(RoBERTa: 76.3%测试准确率；BERT: 79.3%)。FastText显示出让人惊讶的词汇稳健性(83.5%准确率)，但缺乏更深层次的语义理解。相比之下，LoRA适配的Qwen2.5-7B达到了95.94%的测试准确率，具有平衡的精度-召回指标，表明具有更好的泛化能力和对数据集特定人工物的弹性。

Conclusion: 这些发现证明了基于解码器的大语言模型统一结合参数高效微调方法在中文AI生成文本检测任务上的有效性。未来工作将探索新一代Qwen3模型、精简版本和集成策略，以进一步提升跨域稳健性。

Abstract: The rapid growth of large language models (LLMs) has heightened the demand
for accurate detection of AI-generated text, particularly in languages like
Chinese, where subtle linguistic nuances pose significant challenges to current
methods. In this study, we conduct a systematic comparison of encoder-based
Transformers (Chinese BERT-large and RoBERTa-wwm-ext-large), a decoder-only LLM
(Alibaba's Qwen2.5-7B/DeepSeek-R1-Distill-Qwen-7B fine-tuned via Low-Rank
Adaptation, LoRA), and a FastText baseline using the publicly available dataset
from the NLPCC 2025 Chinese AI-Generated Text Detection Task. Encoder models
were fine-tuned using a novel prompt-based masked language modeling approach,
while Qwen2.5-7B was adapted for classification with an instruction-format
input and a lightweight classification head trained via LoRA. Experiments
reveal that although encoder models nearly memorize training data, they suffer
significant performance degradation under distribution shifts (RoBERTa: 76.3%
test accuracy; BERT: 79.3%). FastText demonstrates surprising lexical
robustness (83.5% accuracy) yet lacks deeper semantic understanding. In
contrast, the LoRA-adapted Qwen2.5-7B achieves 95.94% test accuracy with
balanced precision-recall metrics, indicating superior generalization and
resilience to dataset-specific artifacts. These findings underscore the
efficacy of decoder-based LLMs with parameter-efficient fine-tuning for robust
Chinese AI-generated text detection. Future work will explore next-generation
Qwen3 models, distilled variants, and ensemble strategies to enhance
cross-domain robustness further.

</details>


### [39] [Decomposing and Revising What Language Models Generate](https://arxiv.org/abs/2509.00765)
*Zhichao Yan,Jiaoyan Chen,Jiapu Wang,Xiaoli Li,Ru Li,Jeff Z. Pan*

Main category: cs.CL

TL;DR: FIDES是一个基于事实分解的框架，通过上下文增强的两阶段忠实分解方法将长答案分解为子事实，用于检索相关证据片段，并在证据冲突时修订子事实，最后根据原始句子聚合证据。


<details>
  <summary>Details</summary>
Motivation: 现有基于问题分解的方法在生成问题时往往不相关和不完整，导致检索中事实丢失，且无法从不同文档和段落聚合证据片段。

Method: 使用上下文增强的两阶段忠实分解方法分解长答案为子事实，检索相关证据片段，在证据冲突时修订子事实，最后根据原始句子聚合证据。

Result: 在六个数据集上评估，使用新提出的$Attr_{auto-P}$指标评估证据精确度，FIDES在GPT-3.5-turbo、Gemini和Llama 70B系列上平均优于SOTA方法超过14%。

Conclusion: FIDES框架有效解决了现有方法在问题生成和证据聚合方面的不足，显著提升了归因问答的性能。

Abstract: Attribution is crucial in question answering (QA) with Large Language Models
(LLMs).SOTA question decomposition-based approaches use long form answers to
generate questions for retrieving related documents. However, the generated
questions are often irrelevant and incomplete, resulting in a loss of facts in
retrieval.These approaches also fail to aggregate evidence snippets from
different documents and paragraphs. To tackle these problems, we propose a new
fact decomposition-based framework called FIDES (\textit{faithful context
enhanced fact decomposition and evidence aggregation}) for attributed QA. FIDES
uses a contextually enhanced two-stage faithful decomposition method to
decompose long form answers into sub-facts, which are then used by a retriever
to retrieve related evidence snippets. If the retrieved evidence snippets
conflict with the related sub-facts, such sub-facts will be revised
accordingly. Finally, the evidence snippets are aggregated according to the
original sentences.Extensive evaluation has been conducted with six datasets,
with an additionally proposed new metric called $Attr_{auto-P}$ for evaluating
the evidence precision. FIDES outperforms the SOTA methods by over 14\% in
average with GPT-3.5-turbo, Gemini and Llama 70B series.

</details>


### [40] [LegalChainReasoner: A Legal Chain-guided Framework for Criminal Judicial Opinion Generation](https://arxiv.org/abs/2509.00783)
*Weizhe Shi,Qiqi Wang,Yihong Pan,Qian Liu,Kaiqi Zhao*

Main category: cs.CL

TL;DR: 提出司法意见生成新任务，通过LegalChainReasoner框架实现法律推理和量刑预测的端到端生成，解决现有方法中两者不一致的问题。


<details>
  <summary>Details</summary>
Motivation: 现有研究将司法意见生成分为法律推理和量刑预测两个独立子任务，导致推理与预测不一致，且依赖人工整理知识，实际部署受限。

Method: 提出LegalChainReasoner框架，使用结构化法律链整合事实前提、复合法律条件和量刑结论，实现灵活知识注入和端到端意见生成。

Result: 在两个真实世界开源中文法律案例数据集上的实验表明，该方法优于基线模型。

Conclusion: 该方法更好地符合法律实践需求，实现了法律推理和量刑决策的同步生成，提高了司法意见生成的一致性和实用性。

Abstract: A criminal judicial opinion represents the judge's disposition of a case,
including the decision rationale and sentencing. Automatically generating such
opinions can assist in analyzing sentencing consistency and provide judges with
references to similar past cases. However, current research typically
approaches this task by dividing it into two isolated subtasks: legal reasoning
and sentencing prediction. This separation often leads to inconsistency between
the reasoning and predictions, failing to meet real-world judicial
requirements. Furthermore, prior studies rely on manually curated knowledge to
enhance applicability, yet such methods remain limited in practical deployment.
To address these limitations and better align with legal practice, we propose a
new LegalAI task: Judicial Opinion Generation, which simultaneously produces
both legal reasoning and sentencing decisions. To achieve this, we introduce
LegalChainReasoner, a framework that applies structured legal chains to guide
the model through comprehensive case assessments. By integrating factual
premises, composite legal conditions, and sentencing conclusions, our approach
ensures flexible knowledge injection and end-to-end opinion generation.
Experiments on two real-world and open-source Chinese legal case datasets
demonstrate that our method outperforms baseline models.

</details>


### [41] [CaresAI at BioCreative IX Track 1 -- LLM for Biomedical QA](https://arxiv.org/abs/2509.00806)
*Reem Abdel-Salam,Mary Adewunmi,Modinat A. Abayomi*

Main category: cs.CL

TL;DR: 本文采用LLaMA 3 8B模型进行监督微调，在生物医学多跳问答任务MedHopQA上进行评估，发现模型在概念理解上表现良好但精确匹配得分较低，提出了两阶段推理管道来改进答案提取。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在问答任务中的广泛应用，需要对其在复杂生物医学问答能力上进行严格评估，特别是在真实医疗应用部署前的性能验证。

Method: 使用LLaMA 3 8B模型进行监督微调，利用来自BioASQ、MedQuAD和TREC的精选生物医学问答数据集。探索了三种实验设置：长短答案联合微调、仅短答案和仅长答案微调，并引入两阶段推理管道进行精确短答案提取。

Result: 模型在概念级别准确度得分达到0.8，显示良好的领域理解能力，但精确匹配(EM)得分显著较低，特别是在测试阶段。两阶段推理管道部分改善了答案对齐问题。

Conclusion: 研究揭示了生物医学LLM应用中语义理解与精确答案评估之间的差距，需要在输出控制和后处理策略方面进行进一步研究。

Abstract: Large language models (LLMs) are increasingly evident for accurate question
answering across various domains. However, rigorous evaluation of their
performance on complex question-answering (QA) capabilities is essential before
deployment in real-world biomedical and healthcare applications. This paper
presents our approach to the MedHopQA track of the BioCreative IX shared task,
which focuses on multi-hop biomedical question answering involving diseases,
genes, and chemicals. We adopt a supervised fine-tuning strategy leveraging
LLaMA 3 8B, enhanced with a curated biomedical question-answer dataset compiled
from external sources including BioASQ, MedQuAD, and TREC. Three experimental
setups are explored: fine-tuning on combined short and long answers, short
answers only, and long answers only. While our models demonstrate strong domain
understanding, achieving concept-level accuracy scores of up to 0.8, their
Exact Match (EM) scores remain significantly lower, particularly in the test
phase. We introduce a two-stage inference pipeline for precise short-answer
extraction to mitigate verbosity and improve alignment with evaluation metrics.
Despite partial improvements, challenges persist in generating strictly
formatted outputs. Our findings highlight the gap between semantic
understanding and exact answer evaluation in biomedical LLM applications,
motivating further research in output control and post-processing strategies.

</details>


### [42] [TMT: A Simple Way to Translate Topic Models Using Dictionaries](https://arxiv.org/abs/2509.00822)
*Felix Engl,Andreas Henrich*

Main category: cs.CL

TL;DR: 这篇论文提出了一种新的主题模型翻译技术TMT，能够在不需要对齐语料库或元数据的情况下，将主题模型从一种语言转移到另一种语言。


<details>
  <summary>Details</summary>
Motivation: 多语言环境下训练主题模型面临巨大挑战，需要复杂算法、对齐语料库和手动评估。当开发者不熟悉目标语言或数据有限时，这些困难更加严重。

Method: 提出Topic Model Translation (TMT)技术，一种突破性方法，无需元数据、嵌入或对齐语料库，就能将LDA等主题模型从一种语言转移到另一种语言。

Result: 通过定量和定性方法进行了全面评估，证明TMT能够产生语义一致且结构统一的主题翻译结果。

Conclusion: TMT技术为多语言主题模型转移提供了一种高效、可靠的解决方案，特别适用于目标语言大规模语料库缺乏或手动翻译不可行的场景。

Abstract: The training of topic models for a multilingual environment is a challenging
task, requiring the use of sophisticated algorithms, topic-aligned corpora, and
manual evaluation. These difficulties are further exacerbated when the
developer lacks knowledge of the target language or is working in an
environment with limited data, where only small or unusable multilingual
corpora are available.
  Considering these challenges, we introduce Topic Model Translation (TMT), a
novel, robust and transparent technique designed to transfer topic models
(e.g., Latent Dirichlet Allocation (LDA) based topic models) from one language
to another, without the need for metadata, embeddings, or aligned corpora. TMT
enables the reuse of topic models across languages, making it especially
suitable for scenarios where large corpora in the target language are
unavailable or manual translation is infeasible. Furthermore, we evaluate TMT
extensively using both quantitative and qualitative methods, demonstrating that
it produces semantically coherent and consistent topic translations.

</details>


### [43] [Neural Models and Language Model Prompting for the Multidimensional Evaluation of Open-Ended Conversations](https://arxiv.org/abs/2509.00841)
*Michelle Elizabeth,Alicja Kasicka,Natalia Krawczyk,Magalie Ochs,Gwénolé Lecorvé,Justyna Gromada,Lina M. Rojas-Barahona*

Main category: cs.CL

TL;DR: 本文在DSTC-12 Track 1挑战中开发了相对小规模模型（少于130亿参数）来预测对话级别的维度特定评分，比较了提示语言模型和训练编码器分类/回归模型两种策略。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI对话系统的增多，如何有效评估这些系统成为一个关键挑战，需要在模型规模受限的情况下开发有效的评估方法。

Method: 采用两种主要策略：1）通过提示使用语言模型作为评估器；2）训练基于编码器的分类和回归模型，所有模型参数都控制在130亿以下。

Result: 提示语言模型与人类判断的相关性一般，但在测试集上排名第二；编码器模型在验证集上某些维度表现出高相关性，但在测试集上性能下降，主要因为测试集评分范围与训练验证集存在显著差异。

Conclusion: 在模型规模受限的情况下，提示语言模型和编码器模型各有优劣，测试集与训练数据的分布差异是影响模型泛化性能的重要因素。

Abstract: The growing number of generative AI-based dialogue systems has made their
evaluation a crucial challenge. This paper presents our contribution to this
important problem through the Dialogue System Technology Challenge (DSTC-12,
Track 1), where we developed models to predict dialogue-level,
dimension-specific scores. Given the constraint of using relatively small
models (i.e. fewer than 13 billion parameters) our work follows two main
strategies: employing Language Models (LMs) as evaluators through prompting,
and training encoder-based classification and regression models.
  Our results show that while LM prompting achieves only modest correlations
with human judgments, it still ranks second on the test set, outperformed only
by the baseline. The regression and classification models, with significantly
fewer parameters, demonstrate high correlation for some dimensions on the
validation set. Although their performance decreases on the test set, it is
important to note that the test set contains annotations with significantly
different score ranges for some of the dimensions with respect to the train and
validation sets.

</details>


### [44] [Negative Matters: Multi-Granularity Hard-Negative Synthesis and Anchor-Token-Aware Pooling for Enhanced Text Embeddings](https://arxiv.org/abs/2509.00842)
*Tengyu Pan,Zhichao Duan,Zhenyu Li,Bowen Dong,Ning Liu,Xiuxing Li,Jianyong Wang*

Main category: cs.CL

TL;DR: 提出多粒度困难负样本合成框架和锚点标记感知池化方法，在文本嵌入任务中实现最先进性能


<details>
  <summary>Details</summary>
Motivation: 传统对比学习中负样本对模型区分语义细微差异至关重要，但现有方法在负样本多样性和质量方面存在不足

Method: 使用大语言模型生成多粒度困难负样本，采用从粗到细的课程学习策略；提出锚点标记感知池化方法，基于大语言模型聚合模式为锚点标记分配更高权重

Result: 在MTEB基准测试中达到最先进性能，超越现有合成策略，在合成数据和公共检索数据集上均表现优异

Conclusion: 多粒度困难负样本合成和锚点标记感知池化能有效提升文本嵌入模型的语义表示能力，为对比学习提供新的优化方向

Abstract: Text embedding models are essential for various natural language processing
tasks, enabling the effective encoding of semantic information into dense
vector representations. These models are typically optimized using triplets of
(query, positive, negative) data pairs for contrastive learning, where the
negative samples play a critical role in enhancing the model's ability to
discern subtle semantic distinctions. In this work, we introduce a
Multi-Granularity Hard-negative (MGH) synthesis framework that leverages large
language models (LLMs) to generate diverse negative samples with varying levels
of similarity with the query. This approach facilitates a coarse-to-fine
curriculum learning strategy during supervised training, allowing the embedding
model to progressively learn more nuanced semantic representations. Meanwhile,
we propose an Anchor Token Aware (ATA) pooling method that assigns higher
weights to anchor tokens based on aggregation patterns observed in LLMs,
improving text embedding accuracy without increasing model complexity.
Comprehensive experiments on the MTEB benchmark demonstrate that our methods
achieve state-of-the-art performance, surpassing existing synthesis strategies
both with synthetic data and when combined with public retrieval datasets.

</details>


### [45] [Prompting Away Stereotypes? Evaluating Bias in Text-to-Image Models for Occupations](https://arxiv.org/abs/2509.00849)
*Shaina Raza,Maximus Powers,Partha Pratim Saha,Mahveen Raza,Rizwan Qureshi*

Main category: cs.CL

TL;DR: 本文研究了文本到图像生成模型中的社会偏见问题，通过构建职业形象基准测试，发现不同模型对公平性提示的反应差异显著，提示工程虽能改善偏见但存在局限性。


<details>
  <summary>Details</summary>
Motivation: 文本到图像模型作为强大的创意工具，存在放大有害社会偏见的风险，需要系统评估和解决这些模型的表征偏见问题。

Method: 构建包含5种社会重要职业（CEO、护士、软件工程师、教师、运动员）的基准测试，使用5个先进模型（包括闭源和开源模型），比较中性提示与公平性控制提示的效果，对所有输出进行性别和种族标注分析。

Result: 提示工程能显著改变人口统计表征，但效果因模型而异：有些模型能有效多样化，有些会过度校正导致不现实的统一性，有些则反应较小。

Conclusion: 提示工程作为公平性干预手段既有潜力也有局限，需要结合模型层面的策略来全面解决偏见问题。

Abstract: Text-to-Image (TTI) models are powerful creative tools but risk amplifying
harmful social biases. We frame representational societal bias assessment as an
image curation and evaluation task and introduce a pilot benchmark of
occupational portrayals spanning five socially salient roles (CEO, Nurse,
Software Engineer, Teacher, Athlete). Using five state-of-the-art models:
closed-source (DALLE 3, Gemini Imagen 4.0) and open-source (FLUX.1-dev, Stable
Diffusion XL Turbo, Grok-2 Image), we compare neutral baseline prompts against
fairness-aware controlled prompts designed to encourage demographic diversity.
All outputs are annotated for gender (male, female) and race (Asian, Black,
White), enabling structured distributional analysis. Results show that
prompting can substantially shift demographic representations, but with highly
model-specific effects: some systems diversify effectively, others overcorrect
into unrealistic uniformity, and some show little responsiveness. These
findings highlight both the promise and the limitations of prompting as a
fairness intervention, underscoring the need for complementary model-level
strategies. We release all code and data for transparency and reproducibility
https://github.com/maximus-powers/img-gen-bias-analysis.

</details>


### [46] [Exploring and Mitigating Fawning Hallucinations in Large Language Models](https://arxiv.org/abs/2509.00869)
*Zixuan Shangguan,Yanjie Dong,Lanjun Wang,Xiaoyi Fan,Victor C. M. Leung,Xiping Hu*

Main category: cs.CL

TL;DR: 本文提出协作对比解码（CCD）方法，通过对比诱导欺骗性输入和中性输入之间的输出分布差异，有效缓解大语言模型中的奉承幻觉问题，无需额外训练即可提高生成响应的真实性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在语言理解方面表现出色，但当模型输出与欺骗性和误导性提示对齐时，会产生偏离事实的奉承幻觉，即模型优先考虑与输入隐含视角的一致性而非准确性。

Method: 设计两种范式生成相应的欺骗性和误导性输入以诱导一致的奉承幻觉，然后提出协作对比解码（CCD）方法，通过对比诱导输入和转换中性输入之间的输出分布偏差来减少对欺骗性信息的依赖。

Result: 大量实验表明，所提出的CCD方法能够有效缓解奉承幻觉，并在各种任务中提高生成响应的真实性。

Conclusion: 协作对比解码方法为解决大语言模型中的奉承幻觉问题提供了一种有效的解决方案，能够在不需要额外训练的情况下显著提升模型输出的真实性和准确性。

Abstract: Large language models (LLMs) have demonstrated exceptional proficiency in
language understanding. However, when LLMs align their outputs with deceptive
and/or misleading prompts, the generated responses could deviate from the de
facto information. Such observations are known as fawning hallucinations, where
the model prioritizes alignment with the input's implied perspective over
accuracy and truthfulness. In this work, we analyze fawning hallucinations in
various natural language processing tasks and tailor the so-termed contrastive
decoding method for fawning-hallucination mitigation. Specifically, we design
two paradigms to generate corresponding deceptive and/or misleading inputs for
the consistent fawning hallucinations induction. Then, we propose the
collaborative contrastive decoding (CCD) to handle the fawning hallucinations
across different tasks in LLMs. By contrasting the deviation in output
distribution between induced and transformed neutral inputs, the proposed CCD
can reduce reliance on deceptive and/or misleading information without
requiring additional training. Extensive experiments demonstrate that the
proposed CCD can effectively mitigate fawning hallucinations and improve the
factuality of the generated responses over various tasks.

</details>


### [47] [EviNote-RAG: Enhancing RAG Models via Answer-Supportive Evidence Notes](https://arxiv.org/abs/2509.00877)
*Yuqin Dai,Guoqing Wang,Yuan Wang,Kairan Dou,Kaichen Zhou,Zhanwei Zhang,Shuo Yang,Fei Tang,Jun Yin,Pengyu Zeng,Zhenzhe Ying,Can Yi,Changhua Meng,Yuchen Zhou,Yongliang Shen,Shuai Lu*

Main category: cs.CL

TL;DR: EviNote-RAG是一个新型的RAG框架，通过结构化检索-笔记-回答流程，让模型生成简洁的支持性证据笔记来过滤噪声信息，提高问答准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统检索-回答范式存在两个主要问题：(1)检索证据中信号噪声比低，有用信息被无关内容淹没；(2)多跳推理中不完整或噪声段落导致错误累积。

Method: 提出结构化检索-笔记-回答流程，训练模型生成支持性证据笔记(SENs)，这些笔记保留答案相关信息、突出不确定性，并使用基于蕴含的证据质量奖励(EQR)来强化学习过程。

Result: 在领域内和领域外QA基准测试中，EviNote-RAG在准确性、泛化性和训练稳定性方面均优于强基线，在HotpotQA、Bamboogle和2Wiki上分别获得20%、40%和91%的相对F1提升。

Conclusion: EviNote-RAG通过证据笔记蒸馏和质量奖励机制，实现了更忠实和鲁棒的推理，同时减少了噪声影响，在保持高效率的同时达到了最先进的性能。

Abstract: Large Language Models (LLMs) empowered with retrieval mechanisms have
achieved strong progress in open-domain question answering (QA). Yet, the
conventional retrieve--then--answer paradigm often suffers from two key
limitations: (1) low signal-to-noise ratio in retrieved evidence, where useful
information is buried under irrelevant content, and (2) error accumulation in
multi-hop reasoning when incomplete or noisy passages are involved. To address
these challenges, we present EviNote-RAG, an agentic RAG framework that
introduces a structured retrieve--note--answer pipeline. Instead of directly
reasoning over raw retrievals, the model is trained to compose
Supportive-Evidence Notes (SENs), concise, human-like notes that preserve only
answer-relevant information, highlight uncertainty, and explicitly state when
no useful evidence exists. This distillation process is further reinforced by
the Evidence Quality Reward (EQR), an entailment-based signal that evaluates
whether SENs logically support the final answer. Together, SENs and EQR guide
the model toward faithful and robust reasoning, while reducing the impact of
noise. Experiments on in-domain and out-of-domain QA benchmarks show that
EviNote-RAG consistently outperforms strong baselines in accuracy,
generalization, and training stability. In particular, it achieves
state-of-the-art results while enhancing robustness and efficiency, yielding
relative F1 gains of 20\% on HotpotQA (+0.093), 40\% on Bamboogle (+0.151), and
91\% on 2Wiki (+0.256) via denser rewards and reduced verbosity.

</details>


### [48] [SeLeRoSa: Sentence-Level Romanian Satire Detection Dataset](https://arxiv.org/abs/2509.00893)
*Răzvan-Alexandru Smădu,Andreea Iuga,Dumitru-Clementin Cercel,Florin Pop*

Main category: cs.CL

TL;DR: 本文介绍了首个罗马尼亚语句级讽刺检测数据集SeLeRoSa，包含13,873个手动标注的句子，并评估了多种LLM和transformer模型在零样本和微调设置下的性能表现。


<details>
  <summary>Details</summary>
Motivation: 讽刺、反讽和挖苦通常用于表达幽默和批评，但有时会被误认为是事实报道，类似于假新闻。这些技术可以在更细粒度的句子级别应用，因此需要专门的检测方法。

Method: 创建了包含13,873个手动标注句子的罗马尼亚语数据集SeLeRoSa，涵盖多个领域。评估了多种基于LLM的基线模型在零样本和微调设置下的性能，以及基于transformer的基线模型。

Result: 研究发现当前这些模型在句子级讽刺检测任务中存在局限性，为新的研究方向铺平了道路。

Conclusion: 该研究填补了罗马尼亚语句级讽刺检测数据集的空白，揭示了现有模型的不足，为未来改进讽刺检测技术提供了重要基础。

Abstract: Satire, irony, and sarcasm are techniques typically used to express humor and
critique, rather than deceive; however, they can occasionally be mistaken for
factual reporting, akin to fake news. These techniques can be applied at a more
granular level, allowing satirical information to be incorporated into news
articles. In this paper, we introduce the first sentence-level dataset for
Romanian satire detection for news articles, called SeLeRoSa. The dataset
comprises 13,873 manually annotated sentences spanning various domains,
including social issues, IT, science, and movies. With the rise and recent
progress of large language models (LLMs) in the natural language processing
literature, LLMs have demonstrated enhanced capabilities to tackle various
tasks in zero-shot settings. We evaluate multiple baseline models based on LLMs
in both zero-shot and fine-tuning settings, as well as baseline
transformer-based models. Our findings reveal the current limitations of these
models in the sentence-level satire detection task, paving the way for new
research directions.

</details>


### [49] [Supervised In-Context Fine-Tuning for Generative Sequence Labeling](https://arxiv.org/abs/2509.00921)
*David Dukić,Goran Glavaš,Jan Šnajder*

Main category: cs.CL

TL;DR: 本文提出监督上下文微调(SIFT)方法，将序列标注任务转化为生成式LLMs的自然响应生成问题，在多个标准任务上显著优于传统方法


<details>
  <summary>Details</summary>
Motivation: 由于因果LLMs的快速发展，预期其在序列标注任务上应能超越停滞发展的编码器模型，但现有研究较少关注生成式序列标注这一更自然的设置

Method: SIFT方法结合了上下文学习(ICL)和监督微调，将序列标注任务构建为受限响应生成问题，适合LLMs处理

Result: SIFT在多个标准序列标注任务上显著优于ICL和解码器作为编码器的微调基线，且发现移除指令可以缓解长上下文对性能的负面影响

Conclusion: 研究强调了基于响应的生成式任务表述对有效序列标注性能的重要性，揭示了LLMs在序列标注中的优势和局限性

Abstract: Sequence labeling (SL) tasks, where labels are assigned to tokens, are
abundant in NLP (e.g., named entity recognition and aspect-based sentiment
analysis). Owing to the intuition that they require bidirectional context, SL
tasks are commonly tackled with encoder-only models. Recent work also shows
that removing the causal mask in fine-tuning enables decoder-based LLMs to
become effective token classifiers. Less work, however, focused on (supervised)
generative SL, a more natural setting for causal LLMs. Due to their rapid
scaling, causal LLMs applied to SL are expected to outperform encoders, whose
own development has stagnated. In this work, we propose supervised in-context
fine-tuning (SIFT) for generative SL. SIFT casts SL tasks as constrained
response generation, natural to LLMs, combining (1) in-context learning (ICL)
from demonstrations with (2) supervised fine-tuning. SIFT considerably
outperforms both ICL and decoder-as-encoder fine-tuning baselines on a range of
standard SL tasks. We further find that although long context hinders the
performance of generative SL in both ICL and SIFT, this deficiency can be
mitigated by removing the instruction, as instructions are shown to be largely
unnecessary for achieving strong SL performance with SIFT. Our findings
highlight strengths and limitations of SL with LLMs, underscoring the
importance of a response-based generative task formulation for effective SL
performance.

</details>


### [50] [MedCOD: Enhancing English-to-Spanish Medical Translation of Large Language Models Using Enriched Chain-of-Dictionary Framework](https://arxiv.org/abs/2509.00934)
*Md Shahidul Salim,Lian Fu,Arav Adikesh Ramakrishnan,Zonghai Yao,Hong Yu*

Main category: cs.CL

TL;DR: MedCOD是一个混合框架，通过整合UMLS和LLM-KB的领域知识来提升英语到西班牙语的医学翻译质量，在多个开源LLM上显著超越了GPT-4o等基线模型。


<details>
  <summary>Details</summary>
Motivation: 解决医学翻译中领域专业知识缺乏的问题，通过整合结构化医学知识来提升大型语言模型在专业领域的翻译性能。

Method: 构建了2999对英西医学文章平行语料库和100句测试集，使用UMLS和LLM-KB提供结构化医学知识，结合结构化提示和LoRA微调，在4个开源LLM上进行实验。

Result: MedCOD显著提升了所有模型的翻译质量，Phi-4模型达到BLEU 44.23、chrF++ 28.91、COMET 0.863，超越了GPT-4o和GPT-4o-mini基线模型。

Conclusion: 结构化知识整合能有效增强LLM在医学翻译任务中的表现，MedCOD提示和模型适配都能独立带来性能提升，组合使用效果最佳。

Abstract: We present MedCOD (Medical Chain-of-Dictionary), a hybrid framework designed
to improve English-to-Spanish medical translation by integrating
domain-specific structured knowledge into large language models (LLMs). MedCOD
integrates domain-specific knowledge from both the Unified Medical Language
System (UMLS) and the LLM-as-Knowledge-Base (LLM-KB) paradigm to enhance
structured prompting and fine-tuning. We constructed a parallel corpus of 2,999
English-Spanish MedlinePlus articles and a 100-sentence test set annotated with
structured medical contexts. Four open-source LLMs (Phi-4, Qwen2.5-14B,
Qwen2.5-7B, and LLaMA-3.1-8B) were evaluated using structured prompts that
incorporated multilingual variants, medical synonyms, and UMLS-derived
definitions, combined with LoRA-based fine-tuning. Experimental results
demonstrate that MedCOD significantly improves translation quality across all
models. For example, Phi-4 with MedCOD and fine-tuning achieved BLEU 44.23,
chrF++ 28.91, and COMET 0.863, surpassing strong baseline models like GPT-4o
and GPT-4o-mini. Ablation studies confirm that both MedCOD prompting and model
adaptation independently contribute to performance gains, with their
combination yielding the highest improvements. These findings highlight the
potential of structured knowledge integration to enhance LLMs for medical
translation tasks.

</details>


### [51] [Structure and Destructure: Dual Forces in the Making of Knowledge Engines](https://arxiv.org/abs/2509.00949)
*Yihong Chen*

Main category: cs.CL

TL;DR: 该论文探讨了NLP中结构化范式（基于知识图谱）与非结构化范式（基于大规模数据训练）之间的概念联系，提出了结构和解构两种互补力量的新方法。


<details>
  <summary>Details</summary>
Motivation: 弥合NLP中结构化范式和非结构化范式之间的鸿沟，建立概念联系以开发更通用、透明和可控的知识引擎。

Method: 提出结构和解构两种互补机制：结构用于组织已知符号交互，解构通过周期性嵌入重置来提高模型可塑性和对未见场景的泛化能力。

Result: 建立了连接两种范式的概念框架，为开发支持透明、可控和自适应智能系统的通用知识引擎提供了新方法。

Conclusion: 结构和解构的互补作用为构建下一代知识引擎提供了新思路，能够同时利用结构化先验知识和大规模非结构化数据的优势。

Abstract: The making of knowledge engines in natural language processing has been
shaped by two seemingly distinct paradigms: one grounded in structure, the
other driven by massively available unstructured data. The structured paradigm
leverages predefined symbolic interactions, such as knowledge graphs, as priors
and designs models to capture them. In contrast, the unstructured paradigm
centers on scaling transformer architectures with increasingly vast data and
model sizes, as seen in modern large language models. Despite their divergence,
this thesis seeks to establish conceptual connections bridging these paradigms.
Two complementary forces, structure and destructure, emerge across both
paradigms: structure organizes seen symbolic interactions, while destructure,
through periodic embedding resets, improves model plasticity and generalization
to unseen scenarios. These connections form a new recipe for developing general
knowledge engines that can support transparent, controllable, and adaptable
intelligent systems.

</details>


### [52] [RPRO:Ranked Preference Reinforcement Optimization for Enhancing Medical QA and Diagnostic Reasoning](https://arxiv.org/abs/2509.00974)
*Chia-Hsuan Hsu,Jun-En Ding,Hsin-Ling Hsu,Feng Liu,Fang-Ming Hung*

Main category: cs.CL

TL;DR: RPRO框架通过结合强化学习和偏好驱动的推理优化，提升医学问答中思维链的临床可靠性，小模型性能超越大模型


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在医学问答中生成的推理链缺乏事实准确性和临床可靠性，需要改进推理质量

Method: 提出Ranked Preference Reinforcement Optimization (RPRO)框架，结合任务自适应推理模板、概率评估机制、基于Bradley-Terry模型的组间排序优化和KL散度正则化

Result: 在PubMedQA和MedQA-USMLE数据集上表现优于强基线，1.1B参数模型超越7B-13B大型模型

Conclusion: 偏好优化与质量驱动细化相结合，为构建更可靠、临床基础的医学LLMs提供了可扩展有效的方法

Abstract: Medical question answering requires advanced reasoning that integrates domain
knowledge with logical inference. However, existing large language models
(LLMs) often generate reasoning chains that lack factual accuracy and clinical
reliability. We propose Ranked Preference Reinforcement Optimization (RPRO), a
novel framework that uniquely combines reinforcement learning with
preference-driven reasoning refinement to enhance clinical chain-of-thought
(CoT) performance. RPRO differentiates itself from prior approaches by
employing task-adaptive reasoning templates and a probabilistic evaluation
mechanism that aligns outputs with established clinical workflows, while
automatically identifying and correcting low-quality reasoning chains. Unlike
traditional pairwise preference methods, RPRO introduces a groupwise ranking
optimization based on the Bradley-Terry model and incorporates KL-divergence
regularization for stable training. Experiments on PubMedQA and MedQA-USMLE
show consistent improvements over strong baselines. Remarkably, our 1.1B
parameter model outperforms much larger 7B-13B models, including
medical-specialized variants. These findings demonstrate that combining
preference optimization with quality-driven refinement offers a scalable and
effective approach to building more reliable, clinically grounded medical LLMs.

</details>


### [53] [Performance Analysis of Supervised Machine Learning Algorithms for Text Classification](https://arxiv.org/abs/2509.00983)
*Sadia Zaman Mishu,S M Rafiuddin*

Main category: cs.CL

TL;DR: 本文比较了多种监督机器学习方法在文本分类中的性能，包括反向传播神经网络(BPN)，通过实验分析确定了不同模型在分类准确率方面的表现


<details>
  <summary>Details</summary>
Motivation: 随着网络搜索、数据挖掘、推荐系统等领域对文本分类需求的快速增长，需要评估不同监督学习分类器在文本分类任务中的性能表现

Method: 使用标准监督机器学习技术，包括反向传播神经网络(BPN)等多种分类器，在标注文本数据集上进行分类实验，采用基准方法分析性能

Result: 通过对真实数据的实验分析，揭示了不同模型在分类准确率方面的表现差异

Conclusion: 研究为标注和监督文本分类过程提供了一个独立的评估平台，确定了在分类准确率方面表现良好的模型

Abstract: The demand for text classification is growing significantly in web searching,
data mining, web ranking, recommendation systems, and so many other fields of
information and technology. This paper illustrates the text classification
process on different datasets using some standard supervised machine learning
techniques. Text documents can be classified through various kinds of
classifiers. Labeled text documents are used to classify the text in supervised
classifications. This paper applies these classifiers on different kinds of
labeled documents and measures the accuracy of the classifiers. An Artificial
Neural Network (ANN) model using Back Propagation Network (BPN) is used with
several other models to create an independent platform for labeled and
supervised text classification process. An existing benchmark approach is used
to analyze the performance of classification using labeled documents.
Experimental analysis on real data reveals which model works well in terms of
classification accuracy.

</details>


### [54] [Ranking of Bangla Word Graph using Graph-based Ranking Algorithms](https://arxiv.org/abs/2509.01011)
*S M Rafiuddin*

Main category: cs.CL

TL;DR: 本研究使用图论算法对孟加拉语单词进行排名，通过构建词图并应用多种基于图的排名算法来评估单词重要性，实验结果表明不同算法在F1分数上的准确性差异。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语缺乏标准词库，需要开发有效的单词排名方法来支持文本摘要和信息检索。词图能够有效表示单词间关系并确定相对重要性。

Method: 使用印度语言词性标注语料库构建孟加拉语词图，应用预处理步骤后采用多种基于图的排名算法进行比较分析。

Result: 实验结果显示不同排名算法在F1度量上的准确性表现，为孟加拉语单词排名提供了实证分析。

Conclusion: 研究成功建立了孟加拉语单词排名的方法框架，通过词图和图算法有效解决了缺乏标准词库的问题，为后续研究奠定了基础。

Abstract: Ranking words is an important way to summarize a text or to retrieve
information. A word graph is a way to represent the words of a sentence or a
text as the vertices of a graph and to show the relationship among the words.
It is also useful to determine the relative importance of a word among the
words in the word-graph. In this research, the ranking of Bangla words are
calculated, representing Bangla words from a text in a word graph using various
graph based ranking algorithms. There is a lack of a standard Bangla word
database. In this research, the Indian Language POS-tag Corpora is used, which
has a rich collection of Bangla words in the form of sentences with their parts
of speech tags. For applying a word graph to various graph based ranking
algorithms, several standard procedures are applied. The preprocessing steps
are done in every word graph and then applied to graph based ranking algorithms
to make a comparison among these algorithms. This paper illustrate the entire
procedure of calculating the ranking of Bangla words, including the
construction of the word graph from text. Experimental result analysis on real
data reveals the accuracy of each ranking algorithm in terms of F1 measure.

</details>


### [55] [We Politely Insist: Your LLM Must Learn the Persian Art of Taarof](https://arxiv.org/abs/2509.01035)
*Nikta Gohari Sadr,Sahar Heidariasl,Karine Megerdoomian,Laleh Seyyed-Kalantari,Ali Emami*

Main category: cs.CL

TL;DR: 这篇论文提出了TaarofBench，首个专门评估大语言模型对伊朗社会礼仪规范taarof理解的基准，发现当前模型在文化能力上存在显著缺口，并通过精细调整技术提升了模型的文化对齐能力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在处理不同文化特定的沟通规范时遇到困难，特别是伊朗社会中复杂的礼仪系统taarof，而现有的文化评测标准缺乏这方面的考量。

Method: 研究者建立了TaarofBench，包含450个角色扮演场景，覆盖12个常见社交互动话题，并经过本土语者验证。对五个前沿模型进行了评估，还通过监督式细调和直接偏好优化技术来改善模型表现。

Result: 评测显示当taarof在文化上适用时，模型的准确率比本土语者低40-48%，表现随互动话题、语言提示和性别而异。细调后模型的文化对齐能力提升了21.8%和42.3%。

Conclusion: 这项工作为开发多样化和具有文化意识的大语言模型奠定了基础，能够更好地处理复杂的社会交互。

Abstract: Large language models (LLMs) struggle to navigate culturally specific
communication norms, limiting their effectiveness in global contexts. We focus
on Persian taarof, a social norm in Iranian interactions, which is a
sophisticated system of ritual politeness that emphasizes deference, modesty,
and indirectness, yet remains absent from existing cultural benchmarks. We
introduce TaarofBench, the first benchmark for evaluating LLM understanding of
taarof, comprising 450 role-play scenarios covering 12 common social
interaction topics, validated by native speakers. Our evaluation of five
frontier LLMs reveals substantial gaps in cultural competence, with accuracy
rates 40-48% below native speakers when taarof is culturally appropriate.
Performance varies between interaction topics, improves with Persian-language
prompts, and exhibits gender-based asymmetries. We also show that responses
rated "polite" by standard metrics often violate taarof norms, indicating the
limitations of Western politeness frameworks. Through supervised fine-tuning
and Direct Preference Optimization, we achieve 21.8% and 42.3% improvement in
model alignment with cultural expectations. Our human study with 33
participants (11 native Persian, 11 heritage, and 11 non-Iranian speakers)
forms baselines in varying degrees of familiarity with Persian norms. This work
lays the foundation for developing diverse and culturally aware LLMs, enabling
applications that better navigate complex social interactions.

</details>


### [56] [A Dynamic Fusion Model for Consistent Crisis Response](https://arxiv.org/abs/2509.01053)
*Xiaoying Song,Anirban Saha Anik,Eduardo Blanco,Vanessa Frias-Martinez,Lingzi Hong*

Main category: cs.CL

TL;DR: 提出了一种基于融合的生成方法，通过两阶段过程优化印象管理和印象一致性，在危机沟通中生成风格一致的高质量回应。


<details>
  <summary>Details</summary>
Motivation: 危机沟通中自动化回应的风格一致性对于建立受影响人群信任至关重要，但现有研究很少探索这个问题。

Method: 首先提出了评估风格一致性的新指标，然后采用两阶段融合生成方法：评估候选回应风格，通过实例级融合过程进行优化和整合。

Result: 在多个数据集上的实验结果显示，该方法在回应质量和风格一致性方面均明显超过基线方法。

Conclusion: 该研究为危机沟通中自动化回应的风格一致性提供了有效解决方案，能够生成高质量且风格稳定的回应。

Abstract: In response to the urgent need for effective communication with
crisis-affected populations, automated responses driven by language models have
been proposed to assist in crisis communications. A critical yet often
overlooked factor is the consistency of response style, which could affect the
trust of affected individuals in responders. Despite its importance, few
studies have explored methods for maintaining stylistic consistency across
generated responses. To address this gap, we propose a novel metric for
evaluating style consistency and introduce a fusion-based generation approach
grounded in this metric. Our method employs a two-stage process: it first
assesses the style of candidate responses and then optimizes and integrates
them at the instance level through a fusion process. This enables the
generation of high-quality responses while significantly reducing stylistic
variation between instances. Experimental results across multiple datasets
demonstrate that our approach consistently outperforms baselines in both
response quality and stylistic uniformity.

</details>


### [57] [Speaking at the Right Level: Literacy-Controlled Counterspeech Generation with RAG-RL](https://arxiv.org/abs/2509.01058)
*Xiaoying Song,Anirban Saha Anik,Dibakar Barua,Pengcheng Luo,Junhua Ding,Lingzi Hong*

Main category: cs.CL

TL;DR: 通过控制健康识读水平框架，结合检索增强生成和强化学习，生成适应不同健康识读水平的个性化反假信息话语


<details>
  <summary>Details</summary>
Motivation: 现有的自动反假信息话语生成方法产生统一回应，忽视了受众健康识读水平对话语可访问性和效果的影响

Method: 控制识读水平框架，采用检索增强生成(RAG)和强化学习(RL)技术，检索适合特定健康识读水平的知识，设计包含主观用户偏好和客观可读性奖励的奖励函数

Result: 控制识读水平框架在生成更可访问和用户更喜欢的反假信息话语方面超过基线方法

Conclusion: 该研究通过提高反假信息话语的可访问性和理解度，为更公平和有影响力的公共健康沟通做出贡献

Abstract: Health misinformation spreading online poses a significant threat to public
health. Researchers have explored methods for automatically generating
counterspeech to health misinformation as a mitigation strategy. Existing
approaches often produce uniform responses, ignoring that the health literacy
level of the audience could affect the accessibility and effectiveness of
counterspeech. We propose a Controlled-Literacy framework using
retrieval-augmented generation (RAG) with reinforcement learning (RL) to
generate tailored counterspeech adapted to different health literacy levels. In
particular, we retrieve knowledge aligned with specific health literacy levels,
enabling accessible and factual information to support generation. We design a
reward function incorporating subjective user preferences and objective
readability-based rewards to optimize counterspeech to the target health
literacy level. Experiment results show that Controlled-Literacy outperforms
baselines by generating more accessible and user-preferred counterspeech. This
research contributes to more equitable and impactful public health
communication by improving the accessibility and comprehension of counterspeech
to health misinformation.

</details>


### [58] [Assessing Large Language Models on Islamic Legal Reasoning: Evidence from Inheritance Law Evaluation](https://arxiv.org/abs/2509.01081)
*Abdessalam Bouchekif,Samer Rashwani,Heba Sbahi,Shahd Gaben,Mutez Al-Khatib,Mohammed Ghaly*

Main category: cs.CL

TL;DR: 评估7个大型语言模型在伊斯兰继承法领域的知识和推理能力，使用1000个多选题进行测试，发现模型性能差异显著（o3和Gemini 2.5准确率超90%，其他模型低于50%）


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在伊斯兰继承法这一专业领域的知识和推理能力，了解模型在结构化法律推理方面的表现

Method: 使用包含1000个多选题的基准测试，涵盖多样化继承场景，测试模型理解继承背景和计算伊斯兰法规定份额的能力

Result: o3和Gemini 2.5表现优异（准确率>90%），而ALLaM、Fanar、LLaMA和Mistral表现较差（准确率<50%），存在显著的性能差距

Conclusion: 模型在伊斯兰法律推理方面存在明显局限性，包括对继承场景的误解、法律规则应用错误和领域知识不足，需要改进结构化法律推理能力

Abstract: This paper evaluates the knowledge and reasoning capabilities of Large
Language Models in Islamic inheritance law, known as 'ilm al-mawarith. We
assess the performance of seven LLMs using a benchmark of 1,000 multiple-choice
questions covering diverse inheritance scenarios, designed to test models'
ability to understand the inheritance context and compute the distribution of
shares prescribed by Islamic jurisprudence. The results reveal a significant
performance gap: o3 and Gemini 2.5 achieved accuracies above 90%, whereas
ALLaM, Fanar, LLaMA, and Mistral scored below 50%. These disparities reflect
important differences in reasoning ability and domain adaptation. We conduct a
detailed error analysis to identify recurring failure patterns across models,
including misunderstandings of inheritance scenarios, incorrect application of
legal rules, and insufficient domain knowledge. Our findings highlight
limitations in handling structured legal reasoning and suggest directions for
improving performance in Islamic legal reasoning. Code:
https://github.com/bouchekif/inheritance_evaluation

</details>


### [59] [A Paradigm Gap in Urdu](https://arxiv.org/abs/2509.01084)
*Farah Adeeba,Rajesh Bhatt*

Main category: cs.CL

TL;DR: 乌尔都语中-ya: kar结构的完成体形式在现代语法中极不合法，尽管19世纪文献中常见，这是由主格主语要求与及物完成体赋予作格的核心语法规则冲突导致的。


<details>
  <summary>Details</summary>
Motivation: 研究乌尔都语动词和体组合中的范式空缺：-ya: kar结构的完成体形式在现代乌尔都语和印地语中极不合法，但在19世纪文献中却自由出现，需要探究这一历时变化的原因。

Method: 通过历史文本分析、大规模语料库研究（确认完成体形式的明显缺失）以及母语者的主观评价任务（判断完成体例句高度不自然）。

Result: 发现完成体形式在现代语法中几乎完全缺失，母语者认为其极不自然，这种空缺源于形态句法冲突：结构要求主格主语和不变分词，与及物完成体赋予作格的核心规则冲突。

Conclusion: 这种形态句法冲突使完成体形式不稳定，其他结构的功能替代使这一空缺在现代语法中固化。

Abstract: In this paper, we document a paradigm gap in the combinatorial possibilities
of verbs and aspect in Urdu: the perfective form of the -ya: kar construction
(e.g. ro-ya: ki: cry-Pfv do.Pfv) is sharply ungrammatical in modern Urdu and
Hindi, despite being freely attested in 19th century literature. We investigate
this diachronic shift through historical text analysis, a large-scale corpus
study which confirms the stark absence of perfective forms and subjective
evaluation tasks with native speakers, who judge perfective examples as highly
unnatural. We argue that this gap arose from a fundamental morphosyntactic
conflict: the construction's requirement for a nominative subject and an
invariant participle clashes with the core grammatical rule that transitive
perfective assign ergative case. This conflict rendered the perfective form
unstable, and its functional replacement by other constructions allowed the gap
to become entrenched in the modern grammar.

</details>


### [60] [Privacy-Preserving Reasoning with Knowledge-Distilled Parametric Retrieval Augmented Generation](https://arxiv.org/abs/2509.01088)
*Jinwen Chen,Hainan Zhang,Liang Pang,Yongxin Tong,Haibo Zhou,Yuan Zhan,Wei Lin,Zhiming Zheng*

Main category: cs.CL

TL;DR: DistilledPRAG是一种通过知识蒸馏对齐标准RAG的隐私保护参数化检索增强生成模型，解决了现有PRAG方法的推理延迟和泛化能力问题。


<details>
  <summary>Details</summary>
Motivation: 当前RAG系统需要上传明文文档到云端，存在隐私数据泄露风险。参数化RAG(PRAG)通过将文档编码为LoRA来保护隐私，但仍面临推理延迟高和泛化能力差的问题。

Method: 1) 从单文档和多文档合成QA对增强跨文档推理；2) 用特殊标记掩码明文文档并通过参数生成器转换为LoRA，保持标准RAG文档结构；3) 在合成QA数据指导下训练参数生成器匹配标准RAG的隐藏状态和输出logits。

Result: 在四个QA数据集上的实验表明，DistilledPRAG在准确率上优于基线方法，并在分布外数据上表现出良好的泛化能力。

Conclusion: DistilledPRAG实现了高效参数化的同时保持了RAG级别的性能，为隐私保护推理提供了有效解决方案。

Abstract: The current RAG system requires uploading plaintext documents to the cloud,
risking private data leakage. Parametric RAG (PRAG) addresses this by encoding
documents as LoRA within LLMs, enabling reasoning without exposing raw content.
However, it still faces two issues: (1) PRAG demands synthesizing QA pairs and
fine-tuning LLM for each individual document to create its corresponding LoRA,
leading to unacceptable inference latency. (2) The performance of PRAG relies
solely on synthetic QA data, lacking internal alignment with standard RAG,
resulting in poor generalization on out-of-distribution(OOD) inputs. Therefore,
achieving high-efficiency parameterization while maintaining RAG-level
performance remains a critical challenge for privacy-preserving reasoning. In
this paper, we propose DistilledPRAG, a generalizable knowledge-distilled
parametric RAG model aligned with standard RAG in document structure and
parameter activation. We first synthesize QA pairs from single and
multi-documents to enhance cross-document reasoning. Then, we mask the
plaintext documents with a special token and translate them to LoRA via a
parameter generator, maintaining the standard RAG document structure. Finally,
guided by synthetic QA data, we train the parameter generator to match standard
RAG's hidden states and output logits, enabling RAG-style reasoning without
original documents. Experiments on four QA datasets show that DistilledPRAG
outperforms baselines in accuracy and generalizes well on OOD data.

</details>


### [61] [REFRAG: Rethinking RAG based Decoding](https://arxiv.org/abs/2509.01092)
*Xiaoqiang Lin,Aritra Ghosh,Bryan Kian Hsiang Low,Anshumali Shrivastava,Vijai Mohan*

Main category: cs.CL

TL;DR: REFRAG是一个针对RAG应用的高效解码框架，通过压缩、感知和扩展机制，利用检索上下文的稀疏性结构，在保持性能的同时显著降低延迟并扩展上下文长度。


<details>
  <summary>Details</summary>
Motivation: 在RAG应用中，LLM的长上下文处理导致显著的系统延迟和内存需求，而检索到的段落中只有小部分与查询直接相关，存在大量不必要的计算。

Method: 提出REFRAG框架，通过利用RAG上下文中块对角注意力模式的稀疏性结构，压缩、感知和扩展解码过程，消除不必要的计算。

Result: 实现了30.85倍的首次令牌时间加速（相比先前工作提升3.75倍），无困惑度损失，并能将LLM的上下文大小扩展16倍。

Conclusion: REFRAG在多种长上下文任务中均能提供显著的速度提升，且不损失准确性，为RAG应用提供了高效的解决方案。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in
leveraging extensive external knowledge to enhance responses in multi-turn and
agentic applications, such as retrieval-augmented generation (RAG). However,
processing long-context inputs introduces significant system latency and
demands substantial memory for the key-value cache, resulting in reduced
throughput and a fundamental trade-off between knowledge enrichment and system
efficiency. While minimizing latency for long-context inputs is a primary
objective for LLMs, we contend that RAG require specialized consideration. In
RAG, much of the LLM context consists of concatenated passages from retrieval,
with only a small subset directly relevant to the query. These passages often
exhibit low semantic similarity due to diversity or deduplication during
re-ranking, leading to block-diagonal attention patterns that differ from those
in standard LLM generation tasks. Based on this observation, we argue that most
computations over the RAG context during decoding are unnecessary and can be
eliminated with minimal impact on performance. To this end, we propose REFRAG,
an efficient decoding framework that compresses, senses, and expands to improve
latency in RAG applications. By exploiting the sparsity structure, we
demonstrate a 30.85 the time-to-first-token acceleration (3.75 improvement to
previous work) without loss in perplexity. In addition, our optimization
framework for large context enables REFRAG to extend the context size of LLMs
by 16. We provide rigorous validation of REFRAG across diverse long-context
tasks, including RAG, multi-turn conversations, and long document
summarization, spanning a wide range of datasets. Experimental results confirm
that REFRAG delivers substantial speedup with no loss in accuracy compared to
LLaMA models and other state-of-the-art baselines across various context sizes.

</details>


### [62] [Natural Context Drift Undermines the Natural Language Understanding of Large Language Models](https://arxiv.org/abs/2509.01093)
*Yulong Wu,Viktor Schlegel,Riza Batista-Navarro*

Main category: cs.CL

TL;DR: 研究发现自然文本演化会显著影响大语言模型的问答性能，当阅读段落与预训练时接触的版本差异越大时，模型准确率下降越明显，即使问题本身和必要信息都保持不变。


<details>
  <summary>Details</summary>
Motivation: 探究自然演化的上下文段落如何影响生成式大语言模型的问答能力，特别是当文本内容随时间自然变化时模型的适应性问题。

Method: 提出一个框架来整理自然演化的人类编辑版本阅读段落，分析LLM在不同语义相似度分数下的表现，评估了6个QA数据集和8个具有公开训练数据的LLM。

Result: 实验显示当阅读段落与预训练版本自然偏离时，LLM性能下降明显。例如BoolQ数据集的平均模型准确率从最高相似度区间到最低下降了超过30%，多个LLM的斜率超过70。

Conclusion: 自然文本演化对大语言模型的语言理解能力构成了重大挑战，表明模型对训练数据中见过的特定文本表述存在过度依赖。

Abstract: How does the natural evolution of context paragraphs affect question
answering in generative Large Language Models (LLMs)? To investigate this, we
propose a framework for curating naturally evolved, human-edited variants of
reading passages from contemporary QA benchmarks and for analyzing LLM
performance across a range of semantic similarity scores, which quantify how
closely each variant aligns with content seen during pretraining. Using this
framework, we evaluate six QA datasets and eight LLMs with publicly available
training data. Our experiments reveal that LLM performance declines as reading
passages naturally diverge from the versions encountered during
pretraining-even when the question and all necessary information remains
present at inference time. For instance, average model accuracy on BoolQ drops
by over 30% from the highest to lowest similarity bins, with slopes exceeding
70 across several LLMs. These findings suggest that natural text evolution
poses a significant challenge to the language understanding capabilities of
LLMs.

</details>


### [63] [Dream-Coder 7B: An Open Diffusion Language Model for Code](https://arxiv.org/abs/2509.01142)
*Zhihui Xie,Jiacheng Ye,Lin Zheng,Jiahui Gao,Jingwei Dong,Zirui Wu,Xueliang Zhao,Shansan Gong,Xin Jiang,Zhenguo Li,Lingpeng Kong*

Main category: cs.CL

TL;DR: Dream-Coder 7B是一个开源的离散扩散语言模型，具有任意顺序生成代码的能力，通过自适应解码策略和强化学习训练，在多个代码生成基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统自回归模型只能从左到右生成代码，限制了代码生成的灵活性和效率。Dream-Coder旨在开发一个能够根据任务自适应选择解码策略的代码生成模型。

Method: 将预训练的自回归检查点适配到离散扩散框架，使用连续时间加权交叉熵目标。训练包括监督微调（通过随机截断和填充惩罚提高效率）和强化学习（使用可验证奖励）。

Result: 在LiveCodeBench上达到21.4% pass@1，在HumanEval、MBPP、BigCodeBench和CRUXEval等基准测试中表现出竞争力。

Conclusion: Dream-Coder 7B展示了离散扩散模型在代码生成任务中的潜力，提供了自适应解码能力和优异的性能，并开源了所有资源以促进进一步研究。

Abstract: We present Dream-Coder 7B, an open-source discrete diffusion language model
for code generation that exhibits emergent any-order generation capabilities.
Unlike traditional autoregressive (AR) models that decode strictly
left-to-right, Dream-Coder 7B adaptively determines its decoding strategy based
on the coding task: sketch-first generation for complex algorithms,
left-to-right generation for straightforward completions, and interleaved
reasoning generation for code understanding tasks. We adapt a pretrained AR
checkpoint to a discrete diffusion frameworks with a continuous-time weighted
cross-entropy objective. Our post-training recipe comprises (i) supervised
fine-tuning, where we mitigate padding pathologies via random truncation and a
padding penalty to improve sample efficiency and stabilize generation; and (ii)
reinforcement learning with verifiable rewards over a curated high-quality
prompt set drawn from open-source datasets, using a tailored reinforcement
learning recipe for diffusion language models. The resulting Dream-Coder 7B
Instruct attains 21.4\% pass@1 on LiveCodeBench (2410--2505) and demonstrates
competitive performance on HumanEval, MBPP, BigCodeBench, and CRUXEval. We
release Dream-Coder-7B and Dream-Coder-7B-Instruct checkpoints, training
recipes, preprocessing pipelines, and inference code to facilitate
reproducibility and further research.

</details>


### [64] [Zero-shot Cross-lingual NER via Mitigating Language Difference: An Entity-aligned Translation Perspective](https://arxiv.org/abs/2509.01147)
*Zhihao Zhang,Sophia Yat Mei Lee,Dong Zhang,Shoushan Li,Guodong Zhou*

Main category: cs.CL

TL;DR: 提出实体对齐翻译(EAT)方法解决跨语言命名实体识别中非拉丁语系语言性能下降问题，利用大语言模型进行双向翻译对齐实体


<details>
  <summary>Details</summary>
Motivation: 现有零样本跨语言命名实体识别方法主要针对拉丁语系语言，对中文、日文等非拉丁语系语言由于深层结构差异导致性能下降

Method: 使用大语言模型实施双向翻译策略来对齐非拉丁语系语言和英语之间的实体，并利用多语言维基百科数据微调大语言模型以增强实体对齐

Result: 论文提出了EAT方法，但摘要中未明确报告具体实验结果

Conclusion: EAT方法通过实体对齐翻译策略有效解决了非拉丁语系语言在跨语言命名实体识别中的性能退化问题

Abstract: Cross-lingual Named Entity Recognition (CL-NER) aims to transfer knowledge
from high-resource languages to low-resource languages. However, existing
zero-shot CL-NER (ZCL-NER) approaches primarily focus on Latin script language
(LSL), where shared linguistic features facilitate effective knowledge
transfer. In contrast, for non-Latin script language (NSL), such as Chinese and
Japanese, performance often degrades due to deep structural differences. To
address these challenges, we propose an entity-aligned translation (EAT)
approach. Leveraging large language models (LLMs), EAT employs a
dual-translation strategy to align entities between NSL and English. In
addition, we fine-tune LLMs using multilingual Wikipedia data to enhance the
entity alignment from source to target languages.

</details>


### [65] [Joint Information Extraction Across Classical and Modern Chinese with Tea-MOELoRA](https://arxiv.org/abs/2509.01158)
*Xuemei Tang,Chengxi Yan,Jinghang Gu,Chu-Ren Huang*

Main category: cs.CL

TL;DR: Tea-MOELoRA：结合LoRA和MoE的参数高效多任务框架，用于中文信息抽取，通过任务-时代感知路由机制动态分配专家贡献


<details>
  <summary>Details</summary>
Motivation: 中文信息抽取涉及多个任务和不同时代文档，单一模型在异构任务和不同时代上微调可能导致干扰和性能下降

Method: 结合LoRA和混合专家(MoE)设计，多个低秩LoRA专家专门处理不同的IE任务和时代，使用任务-时代感知路由机制动态分配专家贡献

Result: 实验表明Tea-MOELoRA优于单任务和联合LoRA基线

Conclusion: 该框架能够有效利用任务和时序知识，提升中文信息抽取性能

Abstract: Chinese information extraction (IE) involves multiple tasks across diverse
temporal domains, including Classical and Modern documents. Fine-tuning a
single model on heterogeneous tasks and across different eras may lead to
interference and reduced performance. Therefore, in this paper, we propose
Tea-MOELoRA, a parameter-efficient multi-task framework that combines LoRA with
a Mixture-of-Experts (MoE) design. Multiple low-rank LoRA experts specialize in
different IE tasks and eras, while a task-era-aware router mechanism
dynamically allocates expert contributions. Experiments show that Tea-MOELoRA
outperforms both single-task and joint LoRA baselines, demonstrating its
ability to leverage task and temporal knowledge effectively.

</details>


### [66] [Enhancing Large Language Model for Knowledge Graph Completion via Structure-Aware Alignment-Tuning](https://arxiv.org/abs/2509.01166)
*Yu Liu,Yanan Cao,Xixun Lin,Yanmin Shang,Shi Wang,Shirui Pan*

Main category: cs.CL

TL;DR: SAT框架通过结构感知对齐调优增强LLM在知识图谱补全中的表现，解决了自然语言与图结构表示空间不一致的问题，并使用统一图指令实现多任务处理


<details>
  <summary>Details</summary>
Motivation: 现有LLM增强的KGC方法存在两个关键挑战：1)忽略自然语言与图结构表示空间的不一致性；2)为不同KGC任务设计单独指令导致重复工作和耗时过程

Method: 提出SAT框架：1)通过多任务对比学习进行分层知识对齐，将图嵌入与自然语言空间对齐；2)使用统一图指令结合轻量级知识适配器进行结构指令调优，指导LLM进行结构感知推理

Result: 在四个基准数据集的两个KGC任务上，SAT显著优于最先进方法，特别是在链接预测任务中提升8.7%到29.8%

Conclusion: SAT框架通过结构感知对齐调优有效解决了LLM在KGC任务中的表示空间不一致问题，实现了统一的多任务处理，取得了显著的性能提升

Abstract: Knowledge graph completion (KGC) aims to infer new knowledge and make
predictions from knowledge graphs. Recently, large language models (LLMs) have
exhibited remarkable reasoning capabilities. LLM-enhanced KGC methods primarily
focus on designing task-specific instructions, achieving promising
advancements. However, there are still two critical challenges. First, existing
methods often ignore the inconsistent representation spaces between natural
language and graph structures. Second, most approaches design separate
instructions for different KGC tasks, leading to duplicate works and
time-consuming processes. To address these challenges, we propose SAT, a novel
framework that enhances LLMs for KGC via structure-aware alignment-tuning.
Specifically, we first introduce hierarchical knowledge alignment to align
graph embeddings with the natural language space through multi-task contrastive
learning. Then, we propose structural instruction tuning to guide LLMs in
performing structure-aware reasoning over KGs, using a unified graph
instruction combined with a lightweight knowledge adapter. Experimental results
on two KGC tasks across four benchmark datasets demonstrate that SAT
significantly outperforms state-of-the-art methods, especially in the link
prediction task with improvements ranging from 8.7% to 29.8%.

</details>


### [67] [Modular Techniques for Synthetic Long-Context Data Generation in Language Model Training and Evaluation](https://arxiv.org/abs/2509.01185)
*Seganrasan Subramanian,Abhigya Verma*

Main category: cs.CL

TL;DR: 提出了一个模块化框架，通过LLM提示交互生成合成长文本数据，支持多种训练目标，包括SFT、DPO和GRPO，包含四种核心生成范式。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏高质量、多样化且可验证的长文本数据集，这严重制约了LLM在长文本处理和理解能力方面的进展。

Method: 采用模块化、可扩展的框架，通过模板化提示、模型无关架构和元数据丰富的输出，实现可扩展、可控且目标对齐的数据集创建。

Result: 开发了一个支持多轮对话、文档基础输入输出对、可验证指令响应任务和长文本推理示例的合成数据生成框架。

Conclusion: 该框架为提升LLM的长文本能力提供了可扩展、可控且目标对齐的数据集创建解决方案，有助于推动长文本处理技术的发展。

Abstract: The ability of large language models (LLMs) to process and reason over long
textual inputs is critical for a wide range of real-world applications.
However, progress in this area is significantly constrained by the absence of
high-quality, diverse, and verifiable long-context datasets suitable for both
training and evaluation. This work introduces a modular, extensible framework
for synthetic long-context data generation via prompt-based interaction with
LLMs. The framework supports multiple training and alignment objectives,
including Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO),
and Group Relative Policy Optimization (GRPO). It encompasses four core
generation paradigms: multi-turn conversational dialogues, document-grounded
input-output pairs, verifiable instruction-response tasks, and long-context
reasoning examples. Through templated prompting, a model-agnostic architecture,
and metadata-enriched outputs, the proposed approach facilitates scalable,
controllable, and purpose-aligned dataset creation for advancing long-context
capabilities in LLMs.

</details>


### [68] [Statutory Construction and Interpretation for Artificial Intelligence](https://arxiv.org/abs/2509.01186)
*Luxi He,Nimra Nadeem,Michel Liao,Howard Chen,Danqi Chen,Mariano-Florentino Cuéllar,Peter Henderson*

Main category: cs.CL

TL;DR: 这篇论文提出了一种管理AI系统中解释性歧义的计算框架，受法律系统的启发，通过规则精炼和解释约束来提高模型判断的一致性。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统越来越多地受自然语言原则管理，解释性歧义成为一个重要挑战，导致模型行为不一致或不稳定。法律系统有制度保障来管理这种歧义，但AI对齐流程缺乏类似的保护机制。

Method: 研究者借鉴法律理论，提出了一个计算框架，包括：(1)规则精炼流程，通过修订歧义规则来最小化解释分歧；(2)基于prompt的解释约束，减少规则应用中的不一致性。

Result: 在WildChat数据集的5,000个场景子集上评估，发现两种干预措施都显著提高了判断一致性。

Conclusion: 该方法为系统性管理解释性歧义提供了首步解决方案，是构建更稳健、遵循规则的AI系统的重要步骤。

Abstract: AI systems are increasingly governed by natural language principles, yet a
key challenge arising from reliance on language remains underexplored:
interpretive ambiguity. As in legal systems, ambiguity arises both from how
these principles are written and how they are applied. But while legal systems
use institutional safeguards to manage such ambiguity, such as transparent
appellate review policing interpretive constraints, AI alignment pipelines
offer no comparable protections. Different interpretations of the same rule can
lead to inconsistent or unstable model behavior. Drawing on legal theory, we
identify key gaps in current alignment pipelines by examining how legal systems
constrain ambiguity at both the rule creation and rule application steps. We
then propose a computational framework that mirrors two legal mechanisms: (1) a
rule refinement pipeline that minimizes interpretive disagreement by revising
ambiguous rules (analogous to agency rulemaking or iterative legislative
action), and (2) prompt-based interpretive constraints that reduce
inconsistency in rule application (analogous to legal canons that guide
judicial discretion). We evaluate our framework on a 5,000-scenario subset of
the WildChat dataset and show that both interventions significantly improve
judgment consistency across a panel of reasonable interpreters. Our approach
offers a first step toward systematically managing interpretive ambiguity, an
essential step for building more robust, law-following AI systems.

</details>


### [69] [Efficient Large Language Models with Zero-Shot Adjustable Acceleration](https://arxiv.org/abs/2509.01190)
*Sajjad Kachuee,Mohammad Sharifkhani*

Main category: cs.CL

TL;DR: 该论文提出了一种无需额外微调的零检览可调加速方法，在推理过程中动态调整硬件使用，实现了最高11倍的速度提升。


<details>
  <summary>Details</summary>
Motivation: 实际应用中大语言模型时面临计算效率与性能的平衡挑战，需要在微调后和推理阶段进行加速优化。

Method: 提出Zero-Shot Adjustable Acceleration方法，在推理时动态调整硬件使用而无需额外微调，应用于新开发的模型。

Result: 在多个分类和文本生成任务上评估，该方法能够在零检览情况下实现广泛的加速范围，达到最高11倍的速度提升。

Conclusion: 该方法为大语言模型的高效实际部署提供了一种新的动态加速解决方案，在保持性能的同时显著提升计算效率。

Abstract: Using Large Language Models (LLMs) in real-world applications presents
significant challenges, particularly in balancing computational efficiency and
performance. Optimizing acceleration after the fine-tuning phase and during
inference is crucial for building an efficient architecture. This paper
introduces Zero-Shot Adjustable Acceleration, a novel training and inference
method that dynamically adjusts hardware usage during inference without
requiring additional fine-tuning. The proposed approach is applied to newly
developed models and evaluated across multiple classification and text
generation tasks. Experimental results demonstrate that the method enables a
wide range of acceleration in a zero-shot manner and achieves up to a 11x
speedup compared to the baseline.

</details>


### [70] [SimulMEGA: MoE Routers are Advanced Policy Makers for Simultaneous Speech Translation](https://arxiv.org/abs/2509.01200)
*Chenyang Le,Bing Han,Jinshun Li,Songyong Chen,Yanmin Qian*

Main category: cs.CL

TL;DR: SimulMEGA是一个无监督策略学习框架，通过混合专家门控机制和前缀训练，在同时语音翻译任务中实现了更好的质量-延迟权衡，无需增加推理时间开销


<details>
  <summary>Details</summary>
Motivation: 现有的同时语音翻译系统在多语言多对多场景中难以平衡翻译质量、延迟和语义连贯性，不同的读写策略阻碍了统一策略学习

Method: 结合前缀训练和混合专家精炼器的无监督策略学习框架，通过隐式方式学习有效的读写决策，仅需对标准Transformer架构进行最小修改

Result: 在6个语言对上的评估显示，500M参数的语音到文本模型优于Seamless基线，在1.5秒平均延迟下BLEU下降小于7%，在3秒延迟下小于3%；在流式TTS任务中也表现出优越的延迟-质量权衡

Conclusion: SimulMEGA框架具有很好的通用性，可同时适用于语音到文本和文本到语音的流式任务，为实时跨语言通信提供了有效的解决方案

Abstract: Simultaneous Speech Translation (SimulST) enables real-time cross-lingual
communication by jointly optimizing speech recognition and machine translation
under strict latency constraints. Existing systems struggle to balance
translation quality, latency, and semantic coherence, particularly in
multilingual many-to-many scenarios where divergent read and write policies
hinder unified strategy learning. In this paper, we present SimulMEGA
(Simultaneous Generation by Mixture-of-Experts Gating), an unsupervised policy
learning framework that combines prefix-based training with a
Mixture-of-Experts refiner to learn effective read and write decisions in an
implicit manner, without adding inference-time overhead. Our design requires
only minimal modifications to standard transformer architectures and
generalizes across both speech-to-text and text-to-speech streaming tasks.
Through comprehensive evaluation on six language pairs, our 500M parameter
speech-to-text model outperforms the Seamless baseline, achieving under 7
percent BLEU degradation at 1.5 seconds average lag and under 3 percent at 3
seconds. We further demonstrate the versatility of SimulMEGA by extending it to
streaming TTS with a unidirectional backbone, yielding superior latency quality
tradeoffs.

</details>


### [71] [Mitigating Catastrophic Forgetting in Continual Learning through Model Growth](https://arxiv.org/abs/2509.01213)
*Ege Süalp,Mina Rezaei*

Main category: cs.CL

TL;DR: 本文探讨基于模型增长策略（特别是transformer堆叠）在缓解大语言模型持续学习中的灾难性遗忘问题，发现增长训练模型在阅读理解等任务上表现出更好的知识保留能力，但在社会偏见处理方面存在权衡。


<details>
  <summary>Details</summary>
Motivation: 灾难性遗忘是持续学习中的主要挑战，大语言模型在微调新任务时会丢失先前知识。模型增长策略通过利用小模型加速大模型训练来缓解这一问题，但其对遗忘的影响尚未充分研究。

Method: 采用基于增长的预训练方法（transformer堆叠），比较增长训练模型（Stack LLM）和传统训练模型（LLM）在一系列微调任务（领域知识、推理、阅读理解、偏见）上的表现，评估其灾难性遗忘程度。

Result: 两种模型在领域知识上都有提升，但推理和阅读理解能力随时间退化。Stack LLM退化程度更小，尤其在阅读理解上保留能力更强。在偏见评估中，基线LLM逐渐变得更中立，而Stack LLM保持60-61%的稳定偏见比例。

Conclusion: 基于增长的预训练在抵抗灾难性遗忘方面能带来适度改进，但在处理社会偏见方面存在权衡，需要进一步优化以平衡知识保留和偏见控制。

Abstract: Catastrophic forgetting is a significant challenge in continual learning, in
which a model loses prior knowledge when it is fine-tuned on new tasks. This
problem is particularly critical for large language models (LLMs) undergoing
continual learning, as retaining performance across diverse domains is
important for their general utility. In this paper, we explore model growth, a
promising strategy that leverages smaller models to expedite and structure the
training of larger ones for mitigating the catastrophic forgetting problem.
Although growth-based pretraining, particularly via transformer stacking, has
shown promise in accelerating convergence, its impact on forgetting remains
under-explored. Therefore, we evaluate whether growth-based models can retain
previously learned capabilities more effectively across a sequence of
fine-tuning tasks involving domain knowledge, reasoning, reading comprehension,
and bias. Our findings show that both models -- one trained with growth (Stack
LLM) and one without (LLM) -- exhibit improvements in domain knowledge.
However, reasoning and reading comprehension degrade over time, indicating
signs of catastrophic forgetting. Stack LLM consistently shows less
degradation, especially in reading comprehension, suggesting enhanced retention
capabilities. Interestingly, in bias evaluation, the baseline LLM becomes
progressively more neutral with continued fine-tuning, while Stack LLM
maintains a steady bias ratio around 60--61\%. These results indicate that
growth-based pretraining may deliver modest improvements in resisting
catastrophic forgetting, though trade-offs remain in handling social biases.

</details>


### [72] [DaMoC: Efficiently Selecting the Optimal Large Language Model for Fine-tuning Domain Taks Based on Data and Model Compression](https://arxiv.org/abs/2509.01221)
*Wei Huang,Huang Wei,Yinggui Wang*

Main category: cs.CL

TL;DR: 提出了DaMoC框架，通过数据压缩和模型压缩技术，快速选择最优LLM进行微调，节省约20倍训练时间


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在通用任务上表现优异，但在领域特定任务上表现不佳，需要针对特定数据进行微调。面对众多开源LLM，如何快速选择最适合下游任务微调的最佳模型是一个挑战

Method: 1) 数据层面：建立数据过滤方法分类体系（分布感知、质量感知、混合方法），增强关键token密度实现token压缩，使用LLM迭代重写文本优化表达；2) 模型层面：使用层相似性评分评估各层重要性，移除低重要性层，引入稀疏合并范式保留原始模型能力

Result: 在医疗问答、金融问答、通用问答和阅读理解四个数据集上的大量实验表明，该方法能够选择最优LLM，同时节省约20倍的训练时间

Conclusion: DaMoC框架有效解决了LLM选择难题，通过数据模型双重压缩技术显著提升微调效率，为领域特定任务的高效模型选择提供了实用解决方案

Abstract: Large language models (LLMs) excel in general tasks but struggle with
domain-specific ones, requiring fine-tuning with specific data. With many
open-source LLMs available, selecting the best model for fine-tuning downstream
tasks is challenging, primarily focusing on how to quickly identify the optimal
LLM. We introduce a Data and Model Compression Framework (DaMoC) that addresses
this challenge by: 1) Data Level: A systematic categorization of data filtering
methodologies for LLMs is first established, classifying them into three
distinct paradigms: (1) distribution-aware methods, (2) quality-aware methods,
and (3) hybrid approaches considering both dimensions. Further, we enhance the
density of key tokens in the text achieving token compression. Subsequently, we
use an LLM to iterative rewrite the text to optimize its expression. 2) Model
Level: We use layer similarity scores to assess each layer's importance and
remove those with lower importance. Then, we introduce a sparse merging
paradigm to preserve as much of the original model's capability as possible.
Extensive experiments on four datasets, medical Q&A, financial Q&A, general
Q&A, and reading comprehension, show that we can select the optimal LLM while
saving approximately 20-fold in training time.

</details>


### [73] [Rethinking the Chain-of-Thought: The Roles of In-Context Learning and Pre-trained Priors](https://arxiv.org/abs/2509.01236)
*Hao Yang,Zhiyu Yang,Yunjie Zhang,Shanyi Zhu,Lin Yang*

Main category: cs.CL

TL;DR: 本文从上下文学习与预训练先验的双重关系角度，探索了思维链推理的工作机制，通过细粒度词汇分析和噪声样本实验，揭示了模型如何平衡预训练先验与上下文信息。


<details>
  <summary>Details</summary>
Motivation: 尽管思维链推理在增强模型推理能力方面日益重要，但其底层机制仍不明确。研究者希望从上下文学习与预训练先验的双重关系角度，深入理解思维链推理的工作机制。

Method: 1. 对推理过程进行细粒度词汇级分析；2. 逐步引入噪声样本来检验模型如何平衡预训练先验与错误上下文信息；3. 研究提示工程是否能诱导大语言模型进行慢思考。

Result: 1. 模型不仅能快速学习词汇级的推理结构，还能掌握更深层的逻辑推理模式，但严重依赖预训练先验；2. 提供足够样本可将模型决策从预训练先验转向上下文信号，但误导性提示会引入不稳定性；3. 长思维链提示可诱导模型生成更长的推理链，从而提升下游任务性能。

Conclusion: 思维链推理的有效性源于模型在预训练先验和上下文学习之间的动态平衡，通过适当的提示工程可以诱导更深入的推理过程，提升模型性能。

Abstract: Chain-of-Thought reasoning has emerged as a pivotal methodology for enhancing
model inference capabilities. Despite growing interest in Chain-of-Thought
reasoning, its underlying mechanisms remain unclear. This paper explores the
working mechanisms of Chain-of-Thought reasoning from the perspective of the
dual relationship between in-context learning and pretrained priors. We first
conduct a fine-grained lexical-level analysis of rationales to examine the
model's reasoning behavior. Then, by incrementally introducing noisy exemplars,
we examine how the model balances pretrained priors against erroneous
in-context information. Finally, we investigate whether prompt engineering can
induce slow thinking in large language models. Our extensive experiments reveal
three key findings: (1) The model not only quickly learns the reasoning
structure at the lexical level but also grasps deeper logical reasoning
patterns, yet it heavily relies on pretrained priors. (2) Providing sufficient
exemplars shifts the model's decision-making from pretrained priors to
in-context signals, while misleading prompts introduce instability. (3) Long
Chain-of-Thought prompting can induce the model to generate longer reasoning
chains, thereby improving its performance on downstream tasks.

</details>


### [74] [Annotation and modeling of emotions in a textual corpus: an evaluative approach](https://arxiv.org/abs/2509.01260)
*Jonas Noblet*

Main category: cs.CL

TL;DR: 本文研究基于评价理论的情感标注工业语料，发现尽管标注存在显著分歧，但遵循稳定统计趋势，语言模型能够建模标注过程并区分情感情境。


<details>
  <summary>Details</summary>
Motivation: 情感是人类社会功能中的关键现象，但在文本表现方面仍是一个开放课题。当前评价理论框架未被充分利用，提供了与传统方法互补的新视角。

Method: 使用人工标注的工业语料，采用评价理论框架进行情感分析。训练语言模型处理这些标注数据，分析标注过程中的统计趋势和变异性。

Result: 标注数据虽然存在显著分歧，但遵循稳定的统计趋势。语言模型能够成功建模标注过程，变异性由底层语言特征驱动。语言模型能够基于评价标准区分情感情境。

Conclusion: 评价理论为情感分析提供了有效框架，语言模型能够捕捉标注过程中的统计规律并识别情感情境，表明该方法在情感文本分析中具有实用价值。

Abstract: Emotion is a crucial phenomenon in the functioning of human beings in
society. However, it remains a widely open subject, particularly in its textual
manifestations. This paper examines an industrial corpus manually annotated
following an evaluative approach to emotion. This theoretical framework, which
is currently underutilized, offers a different perspective that complements
traditional approaches. Noting that the annotations we collected exhibit
significant disagreement, we hypothesized that they nonetheless follow stable
statistical trends. Using language models trained on these annotations, we
demonstrate that it is possible to model the labeling process and that
variability is driven by underlying linguistic features. Conversely, our
results indicate that language models seem capable of distinguishing emotional
situations based on evaluative criteria.

</details>


### [75] [Culture is Everywhere: A Call for Intentionally Cultural Evaluation](https://arxiv.org/abs/2509.01301)
*Juhyun Oh,Inha Cha,Michael Saxon,Hyunseung Lim,Shaily Bhatt,Alice Oh*

Main category: cs.CL

TL;DR: 这篇位置论文强调当前LLM文化对齐评估的"短视频中心范式"的不足，提出了"意向性文化评估"方法，要求系统性地考察评估中的文化偏见和研究者立场问题。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM文化对齐评估方法将文化简化为静态知识或价值观，忽视了文化的多元性和互动性，且没有考虑到评估环境本身的文化偏见。

Method: 提出了一种系统性的方法论述，包括：1）对评估中文化偏见的系统分析；2）重视研究者立场对评估的影响；3）推荐采用HCI参与式方法让社区参与评估设计。

Result: 识别了现有评估方法的缺陷，为构建更包容、文化对齐的NLP研究提供了理论基础和方法论指导。

Conclusion: 需要超越当前的标准化测试方式，通过意向性文化评估和社区参与方法，发现未知的重要应用场景，实现更包容的NLP研究。

Abstract: The prevailing ``trivia-centered paradigm'' for evaluating the cultural
alignment of large language models (LLMs) is increasingly inadequate as these
models become more advanced and widely deployed. Existing approaches typically
reduce culture to static facts or values, testing models via multiple-choice or
short-answer questions that treat culture as isolated trivia. Such methods
neglect the pluralistic and interactive realities of culture, and overlook how
cultural assumptions permeate even ostensibly ``neutral'' evaluation settings.
In this position paper, we argue for \textbf{intentionally cultural
evaluation}: an approach that systematically examines the cultural assumptions
embedded in all aspects of evaluation, not just in explicitly cultural tasks.
We systematically characterize the what, how, and circumstances by which
culturally contingent considerations arise in evaluation, and emphasize the
importance of researcher positionality for fostering inclusive, culturally
aligned NLP research. Finally, we discuss implications and future directions
for moving beyond current benchmarking practices, discovering important
applications that we don't know exist, and involving communities in evaluation
design through HCI-inspired participatory methodologies.

</details>


### [76] [TableZoomer: A Collaborative Agent Framework for Large-scale Table Question Answering](https://arxiv.org/abs/2509.01312)
*Sishi Xiong,Ziyang He,Zhongjiang He,Yu Zhao,Changzai Pan,Jie Zhang,Zhenhe Wu,Shuangyong Song,Yongxiang Li*

Main category: cs.CL

TL;DR: TableZoomer是一个基于大语言模型的编程代理框架，通过结构化表模式、查询感知的表格缩放机制和程序思维策略，显著提升了表格问答任务的性能和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在表格问答任务中面临的结构异质性、目标数据定位困难和复杂推理瓶颈等工业应用挑战。

Method: 采用结构化表模式替代完全文本化表格，引入查询感知的表格缩放机制动态生成子表模式，使用程序思维策略将查询转换为可执行代码，并与ReAct范式集成实现迭代推理。

Result: 在DataBench数据集上比传统PoT方法准确率提升19.34%，在TableBench数据集的事实检查任务上提升25%。

Conclusion: TableZoomer框架在保持可用性优势的同时，显著提升了表格问答任务的性能和可扩展性，适用于不同规模的表格处理。

Abstract: While large language models (LLMs) have shown promise in the table question
answering (TQA) task through prompt engineering, they face challenges in
industrial applications, including structural heterogeneity, difficulties in
target data localization, and bottlenecks in complex reasoning. To address
these limitations, this paper presents TableZoomer, a novel LLM-powered,
programming-based agent framework. It introduces three key innovations: (1)
replacing the original fully verbalized table with structured table schema to
bridge the semantic gap and reduce computational complexity; (2) a query-aware
table zooming mechanism that dynamically generates sub-table schema through
column selection and entity linking, significantly improving target
localization efficiency; and (3) a Program-of-Thoughts (PoT) strategy that
transforms queries into executable code to mitigate numerical hallucination.
Additionally, we integrate the reasoning workflow with the ReAct paradigm to
enable iterative reasoning. Extensive experiments demonstrate that our
framework maintains the usability advantages while substantially enhancing
performance and scalability across tables of varying scales. When implemented
with the Qwen3-8B-Instruct LLM, TableZoomer achieves accuracy improvements of
19.34% and 25% over conventional PoT methods on the large-scale DataBench
dataset and the small-scale Fact Checking task of TableBench dataset,
respectively.

</details>


### [77] [Can Smaller LLMs do better? Unlocking Cross-Domain Potential through Parameter-Efficient Fine-Tuning for Text Summarization](https://arxiv.org/abs/2509.01314)
*Anum Afzal,Mehul Kumawat,Florian Matthes*

Main category: cs.CL

TL;DR: 本文探索参数高效微调技术(PEFTs)在跨领域文本摘要任务中的应用，特别是在低资源领域中的适应能力。通过在科学、医学、法律和新闻等14个高资源数据集上微调Llama-3-8B模型，研究发现领域内适配器在低资源场景下性能优于少样本学习和更大的70B模型。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然通用性强，但在新领域适应方面存在挑战，特别是在低资源且无标注数据的领域。传统微调方法计算成本高且耗时，需要更高效的领域适应方案。

Method: 使用6种参数高效微调技术(PEFTs)在14个高资源数据集上微调Llama-3-8B-Instruct模型，进行文本摘要任务。探索领域内适配器和跨领域适配器的使用策略，利用数据集间的语言共性。

Result: 实验表明，对于低资源领域，使用领域内适配器的推理性能优于少样本学习，甚至超过更大的Llama-3-70B-Instruct模型。在没有领域内适配器时，跨领域适配器和策略性组合适配器能够利用跨领域语言相似性，在低资源设置中获得更好的适应性和性能。

Conclusion: 参数高效微调技术为低资源领域的模型适应提供了有效解决方案，通过利用领域间语言相似性，可以在计算成本较低的情况下实现良好的跨领域性能。

Abstract: Large Language Models (LLMs), being generic task solvers, are versatile.
However, despite the vast amount of data they are trained on, there are
speculations about their adaptation capabilities to a new domain. Additionally,
the simple fine-tuning of the model to incorporate knowledge of a new domain is
computationally expensive and time-consuming. This becomes more challenging
when the domain in question is also low-resource, and labeled data is
unavailable. We leverage parameter-efficient fine-tuning techniques (PEFTs) on
high-resource datasets to address these challenges to improve performance on
unseen low-resource domains. Throughout our experiments, we evaluate whether
intrinsic linguistic commonalities between datasets can be leveraged for
efficient domain adaptation. We benchmark six PEFTs with
\texttt{Llama-3-8B-Instruct} on 14 training datasets from the Scientific,
Medical, Legal, and News domains for a Text Summarization task. Our experiments
show that for low-resource domains, inference using Within-Domain Adapters can
achieve better performance than Few-Shot as well as a much larger
\texttt{Llama-3-70B-Instruct}. Lastly, in the absence of Within-Domain
Adapters, we explore the concept of using Cross-Domain Adapters as well as the
strategic combinations of adapters to leverage intrinsic language similarities
across domains, facilitating better adaptability and performance in
low-resource settings.

</details>


### [78] [LongCat-Flash Technical Report](https://arxiv.org/abs/2509.01322)
*Meituan LongCat Team,Bayan,Bei Li,Bingye Lei,Bo Wang,Bolin Rong,Chao Wang,Chao Zhang,Chen Gao,Chen Zhang,Cheng Sun,Chengcheng Han,Chenguang Xi,Chi Zhang,Chong Peng,Chuan Qin,Chuyu Zhang,Cong Chen,Congkui Wang,Dan Ma,Daoru Pan,Defei Bu,Dengchang Zhao,Deyang Kong,Dishan Liu,Feiye Huo,Fengcun Li,Fubao Zhang,Gan Dong,Gang Liu,Gang Xu,Ge Li,Guoqiang Tan,Guoyuan Lin,Haihang Jing,Haomin Fu,Haonan Yan,Haoxing Wen,Haozhe Zhao,Hong Liu,Hongmei Shi,Hongyan Hao,Hongyin Tang,Huantian Lv,Hui Su,Jiacheng Li,Jiahao Liu,Jiahuan Li,Jiajun Yang,Jiaming Wang,Jian Yang,Jianchao Tan,Jiaqi Sun,Jiaqi Zhang,Jiawei Fu,Jiawei Yang,Jiaxi Hu,Jiayu Qin,Jingang Wang,Jiyuan He,Jun Kuang,Junhui Mei,Kai Liang,Ke He,Kefeng Zhang,Keheng Wang,Keqing He,Liang Gao,Liang Shi,Lianhui Ma,Lin Qiu,Lingbin Kong,Lingtong Si,Linkun Lyu,Linsen Guo,Liqi Yang,Lizhi Yan,Mai Xia,Man Gao,Manyuan Zhang,Meng Zhou,Mengxia Shen,Mingxiang Tuo,Mingyang Zhu,Peiguang Li,Peng Pei,Peng Zhao,Pengcheng Jia,Pingwei Sun,Qi Gu,Qianyun Li,Qingyuan Li,Qiong Huang,Qiyuan Duan,Ran Meng,Rongxiang Weng,Ruichen Shao,Rumei Li,Shizhe Wu,Shuai Liang,Shuo Wang,Suogui Dang,Tao Fang,Tao Li,Tefeng Chen,Tianhao Bai,Tianhao Zhou,Tingwen Xie,Wei He,Wei Huang,Wei Liu,Wei Shi,Wei Wang,Wei Wu,Weikang Zhao,Wen Zan,Wenjie Shi,Xi Nan,Xi Su,Xiang Li,Xiang Mei,Xiangyang Ji,Xiangyu Xi,Xiangzhou Huang,Xianpeng Li,Xiao Fu,Xiao Liu,Xiao Wei,Xiaodong Cai,Xiaolong Chen,Xiaoqing Liu,Xiaotong Li,Xiaowei Shi,Xiaoyu Li,Xili Wang,Xin Chen,Xing Hu,Xingyu Miao,Xinyan He,Xuemiao Zhang,Xueyuan Hao,Xuezhi Cao,Xunliang Cai,Xurui Yang,Yan Feng,Yang Bai,Yang Chen,Yang Yang,Yaqi Huo,Yerui Sun,Yifan Lu,Yifan Zhang,Yipeng Zang,Yitao Zhai,Yiyang Li,Yongjing Yin,Yongkang Lv,Yongwei Zhou,Yu Yang,Yuchen Xie,Yueqing Sun,Yuewen Zheng,Yuhua Wei,Yulei Qian,Yunfan Liang,Yunfang Tai,Yunke Zhao,Zeyang Yu,Zhao Zhang,Zhaohua Yang,Zhenchao Zhang,Zhikang Xia,Zhiye Zou,Zhizhao Zeng,Zhongda Su,Zhuofan Chen,Zijian Zhang,Ziwen Wang,Zixu Jiang,Zizhe Zhao,Zongyu Wang,Zunhai Su*

Main category: cs.CL

TL;DR: LongCat-Flash是一个5600亿参数的MoE语言模型，通过Zero-computation Experts和Shortcut-connected MoE设计实现计算效率优化，在30天内完成20万亿token训练，推理成本低至每百万输出token 0.70美元，在智能体任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 为了解决大规模语言模型在计算效率和智能体能力方面的需求，开发一个既能保持高性能又能实现计算资源优化的模型架构。

Method: 采用两种创新设计：Zero-computation Experts实现动态计算预算分配，Shortcut-connected MoE扩大计算-通信重叠窗口；结合超参数迁移、模型增长初始化、稳定性套件和确定性计算的综合扩展框架；通过大规模预训练和针对性中后期训练来培养智能体能力。

Result: 模型在30天内完成20万亿token训练，推理速度达到每秒100+ token，成本为每百万输出token 0.70美元；在各项评估中表现竞争力强，特别是在智能体任务方面具有突出优势。

Conclusion: LongCat-Flash成功实现了计算效率与智能体能力的平衡，通过创新的架构设计和训练方法，为大规模语言模型的发展提供了新的解决方案，模型已开源以促进社区研究。

Abstract: We introduce LongCat-Flash, a 560-billion-parameter Mixture-of-Experts (MoE)
language model designed for both computational efficiency and advanced agentic
capabilities. Stemming from the need for scalable efficiency, LongCat-Flash
adopts two novel designs: (a) Zero-computation Experts, which enables dynamic
computational budget allocation and activates 18.6B-31.3B (27B on average) per
token depending on contextual demands, optimizing resource usage. (b)
Shortcut-connected MoE, which enlarges the computation-communication overlap
window, demonstrating notable gains in inference efficiency and throughput
compared to models of a comparable scale. We develop a comprehensive scaling
framework for large models that combines hyperparameter transfer, model-growth
initialization, a multi-pronged stability suite, and deterministic computation
to achieve stable and reproducible training. Notably, leveraging the synergy
among scalable architectural design and infrastructure efforts, we complete
model training on more than 20 trillion tokens within 30 days, while achieving
over 100 tokens per second (TPS) for inference at a cost of \$0.70 per million
output tokens. To cultivate LongCat-Flash towards agentic intelligence, we
conduct a large-scale pre-training on optimized mixtures, followed by targeted
mid- and post-training on reasoning, code, and instructions, with further
augmentation from synthetic data and tool use tasks. Comprehensive evaluations
demonstrate that, as a non-thinking foundation model, LongCat-Flash delivers
highly competitive performance among other leading models, with exceptional
strengths in agentic tasks. The model checkpoint of LongCat-Flash is
open-sourced to foster community research.
  LongCat Chat: https://longcat.ai
  Hugging Face: https://huggingface.co/meituan-longcat
  GitHub: https://github.com/meituan-longcat

</details>


### [79] [KoBLEX: Open Legal Question Answering with Multi-hop Reasoning](https://arxiv.org/abs/2509.01324)
*Jihyung Lee,Daehui Kim,Seonjeong Hwang,Hyounghun Kim,Gary Lee*

Main category: cs.CL

TL;DR: 韩国法律可解释问答评测集KoBLEX和参数化条款导向检索方法ParSeR，用于评估LLM在法律领域的多跳推理能力和条款基础回答。


<details>
  <summary>Details</summary>
Motivation: 现有法律评测标准缺乏对开放式和条款基础问答的评估，需要一个专门的评测框架来测试LLM在法律领域的多跳推理能力。

Method: 构建韩语法律问答数据集KoBLEX，提出Parametric provision-guided Selection Retrieval (ParSeR)方法，通过LLM生成参数化条款来指导检索，并使用三阶段顺序检索进行多跳推理。还提出了自动化评估指标Legal Fidelity Evaluation (LF-Eval)。

Result: ParSeR方法在多个LLM上都表现最佳，与标准GPT-4o检索相比，F1指标提升+37.91，LF-Eval指标提升+30.81，在不同推理深度下都保持了稳定性能。

Conclusion: 该研究为法律领域的LLM评测提供了一个可靠的框架，ParSeR方法能够有效提升法律问答的准确性和可靠性，为法律AI的发展提供了重要技术支撑。

Abstract: Large Language Models (LLM) have achieved remarkable performances in general
domains and are now extending into the expert domain of law. Several benchmarks
have been proposed to evaluate LLMs' legal capabilities. However, these
benchmarks fail to evaluate open-ended and provision-grounded Question
Answering (QA). To address this, we introduce a Korean Benchmark for Legal
EXplainable QA (KoBLEX), designed to evaluate provision-grounded, multi-hop
legal reasoning. KoBLEX includes 226 scenario-based QA instances and their
supporting provisions, created using a hybrid LLM-human expert pipeline. We
also propose a method called Parametric provision-guided Selection Retrieval
(ParSeR), which uses LLM-generated parametric provisions to guide legally
grounded and reliable answers. ParSeR facilitates multi-hop reasoning on
complex legal questions by generating parametric provisions and employing a
three-stage sequential retrieval process. Furthermore, to better evaluate the
legal fidelity of the generated answers, we propose Legal Fidelity Evaluation
(LF-Eval). LF-Eval is an automatic metric that jointly considers the question,
answer, and supporting provisions and shows a high correlation with human
judgments. Experimental results show that ParSeR consistently outperforms
strong baselines, achieving the best results across multiple LLMs. Notably,
compared to standard retrieval with GPT-4o, ParSeR achieves +37.91 higher F1
and +30.81 higher LF-Eval. Further analyses reveal that ParSeR efficiently
delivers consistent performance across reasoning depths, with ablations
confirming the effectiveness of ParSeR.

</details>


### [80] [Can Large Language Models Master Complex Card Games?](https://arxiv.org/abs/2509.01328)
*Wei Wang,Fuqing Bie,Junzhe Chen,Dan Zhang,Shiyu Huang,Evgeny Kharlamov,Jie Tang*

Main category: cs.CL

TL;DR: LLMs通过高质量游戏数据微调可以接近强游戏AI性能，能同时掌握多个复杂纸牌游戏，但在掌握复杂游戏时通用能力会下降，可通过加入通用指令数据缓解。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型在复杂纸牌游戏中的潜力，验证其是否能在复杂游戏中取得类似AlphaGo的成功。

Method: 系统评估LLMs在8种不同纸牌游戏中的学习能力，通过高质量游戏数据进行监督微调，并测试模型在掌握游戏同时保持通用能力的能力。

Result: LLMs可以通过微调接近强游戏AI性能；能同时掌握多个复杂纸牌游戏，相似规则游戏有性能增强，不相似规则有冲突；掌握复杂游戏时通用能力下降但可通过加入通用指令数据缓解。

Conclusion: LLMs展现出强大的学习能力和多任务适应性，在复杂游戏领域具有巨大潜力，但需要平衡专业化和通用性。

Abstract: Complex games have long been an important benchmark for testing the progress
of artificial intelligence algorithms. AlphaGo, AlphaZero, and MuZero have
defeated top human players in Go and Chess, garnering widespread societal
attention towards artificial intelligence. Concurrently, large language models
(LLMs) have exhibited remarkable capabilities across various tasks, raising the
question of whether LLMs can achieve similar success in complex games. In this
paper, we explore the potential of LLMs in mastering complex card games. We
systematically assess the learning capabilities of LLMs across eight diverse
card games, evaluating the impact of fine-tuning on high-quality gameplay data,
and examining the models' ability to retain general capabilities while
mastering these games. Our findings indicate that: (1) LLMs can approach the
performance of strong game AIs through supervised fine-tuning on high-quality
data, (2) LLMs can master multiple complex card games simultaneously, with
performance augmentation for games with similar rules and conflicts for
dissimilar ones, and (3) LLMs experience a decline in general capabilities when
mastering complex games, but this decline can be mitigated by integrating a
certain amount of general instruction data. The evaluation results demonstrate
strong learning ability and versatility of LLMs.

</details>


### [81] [Reasoning Vectors: Transferring Chain-of-Thought Capabilities via Task Arithmetic](https://arxiv.org/abs/2509.01363)
*Mohammad Zbeeb,Hasan Abed Al Kader Hammoud,Bernard Ghanem*

Main category: cs.CL

TL;DR: 通过提取理由向量v_reason = θ_GRPO - θ_SFT，可以将精简的RL训练能力转移到其他模型，显著提升多种理由任务性能


<details>
  <summary>Details</summary>
Motivation: 避免重复进行成本高昂的优化训练（如强化学习）来掌握复杂的理由任务，尝试从现有模型中提取已学会的理由能力并重用

Method: 从公开的Qwen2.5模型中提取理由向量v_reason = θ_GRPO - θ_SFT，这个向量捕捉了强化学习注入的理由能力而去除了SFT过程中的共享知识

Result: 将理由向量加入兼容的指令微调模型后，在多个理由测试集上显著提升性能：GSM8K (+4.9%)、HumanEval (+4.3%)、SciQ (+1.7%)、BigBenchHard (+12.3%)，甚至在对抗条件下也持续

Conclusion: 理由能力可以从现有开源模型中提取并通过简单的张量算术重用，为提升模型性能提供了一种重用过往计算投资的实用方法

Abstract: Large language models often require costly optimization, such as
reinforcement learning, to master complex reasoning tasks. This work
demonstrates that reasoning ability, once learned, can be extracted and
transferred between models as a compact task vector. We source two publicly
available, identically initialized Qwen2.5 models, one fine-tuned with
supervised fine-tuning (SFT) and the other with group relative policy
optimization (GRPO) on the same dataset. From these, we extract a reasoning
vector: $v_{\text{reason}} = \theta_{\text{GRPO}} - \theta_{\text{SFT}}$. We
hypothesize that this vector captures the reasoning capability instilled by
reinforcement learning while factoring out shared knowledge from the SFT
process. When added to compatible instruction-tuned models through simple
arithmetic, this vector consistently improves performance across diverse
reasoning benchmarks: GSM8K (+4.9%), HumanEval (+4.3%), SciQ (+1.7%), and
BigBenchHard (+12.3% for the 1.5B model). The performance improvements persist
under adversarial conditions. Conversely, subtracting the vector causes
significant performance degradation (-11.8% on GSM8K), demonstrating the
vector's strong contribution to the model's reasoning abilities. This work
shows how reasoning capabilities, typically developed through expensive
training, can be extracted from existing open-source models and reused through
simple tensor arithmetic, offering a practical way to enhance models by
recycling prior computational investments.

</details>


### [82] [WATCHED: A Web AI Agent Tool for Combating Hate Speech by Expanding Data](https://arxiv.org/abs/2509.01379)
*Paloma Piot,Diego Sánchez,Javier Parapar*

Main category: cs.CL

TL;DR: WATCHED是一个基于大语言模型的聊天机器人系统，结合专业工具帮助内容审核员检测和解释仇恨言论，达到0.91的F1分数。


<details>
  <summary>Details</summary>
Motivation: 在线危害日益严重，特别是仇恨言论问题。需要结合自动化系统的速度和规模与人类审核员的判断力，不仅要检测有害内容，还要提供清晰的解释来建立信任。

Method: 构建AI代理系统，使用大语言模型和多种专业工具：比较新帖子与真实仇恨言论示例、BERT分类器标记有害消息、Urban Dictionary查询俚语、生成思维链推理、检查平台指南。

Result: 实验结果显示该方法超越了现有最先进方法，达到了0.91的宏F1分数。

Conclusion: WATCHED工具通过支持AI与人类监督的协作，帮助减少在线危害，适用于审核员、安全团队和研究人员。

Abstract: Online harms are a growing problem in digital spaces, putting user safety at
risk and reducing trust in social media platforms. One of the most persistent
forms of harm is hate speech. To address this, we need tools that combine the
speed and scale of automated systems with the judgment and insight of human
moderators. These tools should not only find harmful content but also explain
their decisions clearly, helping to build trust and understanding. In this
paper, we present WATCHED, a chatbot designed to support content moderators in
tackling hate speech. The chatbot is built as an Artificial Intelligence Agent
system that uses Large Language Models along with several specialised tools. It
compares new posts with real examples of hate speech and neutral content, uses
a BERT-based classifier to help flag harmful messages, looks up slang and
informal language using sources like Urban Dictionary, generates
chain-of-thought reasoning, and checks platform guidelines to explain and
support its decisions. This combination allows the chatbot not only to detect
hate speech but to explain why content is considered harmful, grounded in both
precedent and policy. Experimental results show that our proposed method
surpasses existing state-of-the-art methods, reaching a macro F1 score of 0.91.
Designed for moderators, safety teams, and researchers, the tool helps reduce
online harms by supporting collaboration between AI and human oversight.

</details>


### [83] [ABCD-LINK: Annotation Bootstrapping for Cross-Document Fine-Grained Links](https://arxiv.org/abs/2509.01387)
*Serwar Basch,Ilia Kuznetsov,Tom Hope,Iryna Gurevych*

Main category: cs.CL

TL;DR: 这篇论文提出了一种领域无关的框架，通过半合成数据集自动评估和人工测试，来高效创建跨文档链接的训练和评估数据集，在同行审查和新闻领域实现了精度提升。


<details>
  <summary>Details</summary>
Motivation: 跨文档细粒度关系理解对很多应用至关重要，但缺乏高效的训练和评估数据集创建方法限制了自动化研究的发展。

Method: 首先生成和验证半合成的互联文档数据集，用于自动化评估并选出性能最佳的链接方法，然后进行深度人工评估获得自然文本对的性能估计。

Result: 在同行审查和新闻两个领域应用，结果显示维拉模型与梯度提升模型结合能够获得78%的链接批准率，比单独使用强劳提取器精度提升一倍以上。

Conclusion: 该框架能够系统性地研究不同应用场景下的跨文档理解问题，所创建的新数据集为跨文档任务奠定了基础，并开源了代码、数据和标注协议。

Abstract: Understanding fine-grained relations between documents is crucial for many
application domains. However, the study of automated assistance is limited by
the lack of efficient methods to create training and evaluation datasets of
cross-document links. To address this, we introduce a new domain-agnostic
framework for selecting a best-performing approach and annotating
cross-document links in a new domain from scratch. We first generate and
validate semi-synthetic datasets of interconnected documents. This data is used
to perform automatic evaluation, producing a shortlist of best-performing
linking approaches. These approaches are then used in an extensive human
evaluation study, yielding performance estimates on natural text pairs. We
apply our framework in two distinct domains -- peer review and news -- and show
that combining retrieval models with LLMs achieves 78\% link approval from
human raters, more than doubling the precision of strong retrievers alone. Our
framework enables systematic study of cross-document understanding across
application scenarios, and the resulting novel datasets lay foundation for
numerous cross-document tasks like media framing and peer review. We make the
code, data, and annotation protocols openly available.

</details>


### [84] [Analysing the Language of Neural Audio Codecs](https://arxiv.org/abs/2509.01390)
*Joonyong Park,Shinnosuke Takamichi,David M. Chan,Shunsuke Kando,Yuki Saito,Hiroshi Saruwatari*

Main category: cs.CL

TL;DR: 这篇论文对神经音频编码器产生的离散语音token进行统计和语言学性质分析，发现它们呈现类似自然语言的统计规律，这些特性与语音识别和重构性能显著相关。


<details>
  <summary>Details</summary>
Motivation: 研究神经音频编码器产生的离散token序列的统计特性和语言学规律，以了解它们如何反映语音的语义和音响信息保持。

Method: 分析各种NAC模型产生的语音token，检验其是否遵循Zipf定律、Heaps定律等语言统计规律，计算熵和冗余度，并通过语音识别错误率和UTMOS评分评估语音识别性和质量。

Result: NAC token（特别是3-gram）呈现出类似语言的统计模式，这些统计特性与信息内容量指标一起，与改善的语音识别和重构性能显著相关。

Conclusion: 研究结果揭示了NAC token序列的结构特征，为设计更有效的生成式语音模型提供了重要见解。

Abstract: This study presents a comparative analysis of the statistical and linguistic
properties of neural audio codecs (NACs). We investigate discrete speech tokens
produced by various NAC models, examining their adherence to linguistic
statistical laws such as Zipf's law and Heaps' law, as well as their entropy
and redundancy. To assess how these token-level properties relate to semantic
and acoustic preservation in synthesized speech, we evaluate intelligibility
using error rates of automatic speech recognition, and quality using the UTMOS
score. Our results reveal that NAC tokens, particularly 3-grams, exhibit
language-like statistical patterns. Moreover, these properties, together with
measures of information content, are found to correlate with improved
performances in speech recognition and resynthesis tasks. These findings offer
insights into the structure of NAC token sequences and inform the design of
more effective generative speech models.

</details>


### [85] [LLMs cannot spot math errors, even when allowed to peek into the solution](https://arxiv.org/abs/2509.01395)
*KV Aditya Srivatsa,Kaushal Kumar Maurya,Ekaterina Kochmar*

Main category: cs.CL

TL;DR: LLMs在数学推理任务中表现优秀，但在元推理任务（如识别学生解题错误）上存在困难。本文提出通过生成中间修正的学生解决方案来改进错误定位性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在数学推理方面表现出色，但在元推理任务（如识别学生解题中的错误步骤）上存在明显不足，需要改进其错误定位能力。

Method: 提出一种方法，生成与原始学生解决方案更接近的中间修正方案，从而帮助提高错误定位的性能。使用VtG和PRM800K两个错误推理数据集进行实验验证。

Result: 实验表明，即使提供参考答案，最先进的LLMs也难以准确定位学生解决方案中的第一个错误步骤。提出的中间修正方法能够有效提升错误定位性能。

Conclusion: 通过生成中间修正的学生解决方案，可以显著改善LLMs在识别和定位学生解题错误方面的能力，为解决元推理任务提供了有效途径。

Abstract: Large language models (LLMs) demonstrate remarkable performance on math word
problems, yet they have been shown to struggle with meta-reasoning tasks such
as identifying errors in student solutions. In this work, we investigate the
challenge of locating the first error step in stepwise solutions using two
error reasoning datasets: VtG and PRM800K. Our experiments show that
state-of-the-art LLMs struggle to locate the first error step in student
solutions even when given access to the reference solution. To that end, we
propose an approach that generates an intermediate corrected student solution,
aligning more closely with the original student's solution, which helps improve
performance.

</details>


### [86] [Vis-CoT: A Human-in-the-Loop Framework for Interactive Visualization and Intervention in LLM Chain-of-Thought Reasoning](https://arxiv.org/abs/2509.01412)
*Kaviraj Pather,Elena Hadjigeorgiou,Arben Krasniqi,Claire Schmit,Irina Rusu,Marc Pons,Kabir Khan*

Main category: cs.CL

TL;DR: Vis-CoT是一个交互式可视化框架，将LLM的链式思维文本转换为推理图，允许用户识别错误步骤并通过修剪错误路径和添加新前提来干预，显著提高推理准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型通过链式思维提示展现强大推理能力，但过程不透明，难以在高风险场景中进行验证、调试和控制。

Method: 提出Vis-CoT框架，将线性CoT文本转换为交互式推理图，支持用户可视化逻辑流程、识别错误步骤、修剪错误路径和嫁接新前提。

Result: 在GSM8K和StrategyQA数据集上，Vis-CoT比非交互式基线准确率提升高达24个百分点，用户研究显示可用性和信任度大幅提升。

Conclusion: Vis-CoT通过结合LLM和针对性人工监督，为更可靠、可理解和协作的推理提供了实用路径。

Abstract: Large language models (LLMs) show strong reasoning via chain-of-thought (CoT)
prompting, but the process is opaque, which makes verification, debugging, and
control difficult in high-stakes settings. We present Vis-CoT, a
human-in-the-loop framework that converts linear CoT text into an interactive
reasoning graph. Users can visualize the logical flow, identify flawed steps,
and intervene by pruning incorrect paths and grafting new, user-defined
premises. This shifts interaction from passive observation to active
collaboration, steering models toward more accurate and trustworthy
conclusions. Across GSM8K and StrategyQA, Vis-CoT improves final-answer
accuracy by up to 24 percentage points over non-interactive baselines. A user
study also shows large gains in perceived usability and trust. Vis-CoT points
to a practical path for more reliable, understandable, and collaborative
reasoning by combining LLMs with targeted human oversight.

</details>


### [87] [On the Alignment of Large Language Models with Global Human Opinion](https://arxiv.org/abs/2509.01418)
*Yang Liu,Masahiro Kaneko,Chenhui Chu*

Main category: cs.CL

TL;DR: 本研究创建了一个基于世界价值观调查的评估框架，系统评估大语言模型在全球不同国家、语言和历史时期与人类意见的对齐情况，发现模型仅与少数国家适当或过度对齐，而与大多数国家对齐不足，同时提示语言能有效引导模型对齐相应国家的意见。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注美国或少数国家的人口群体意见，缺乏全球国家样本、不同历史时期人类意见的研究，以及使用语言引导大语言模型的讨论，同时忽视了提示语言对模型意见对齐的潜在影响。

Method: 基于世界价值观调查创建评估框架，系统评估大语言模型在不同国家、语言和历史时期与人类意见的对齐情况，并测试通过改变提示语言来引导模型对齐的效果。

Result: 发现大语言模型仅与少数国家适当或过度对齐意见，而与大多数国家对齐不足；改变提示语言使其与问卷语言匹配能比现有引导方法更有效地使模型对齐相应国家的意见；模型更符合当代人群的意见。

Conclusion: 这是首个在全球、语言和时间维度上全面调查大语言模型意见对齐主题的研究，提供了系统的评估框架和有效的语言引导方法，代码和数据已公开。

Abstract: Today's large language models (LLMs) are capable of supporting multilingual
scenarios, allowing users to interact with LLMs in their native languages. When
LLMs respond to subjective questions posed by users, they are expected to align
with the views of specific demographic groups or historical periods, shaped by
the language in which the user interacts with the model. Existing studies
mainly focus on researching the opinions represented by LLMs among demographic
groups in the United States or a few countries, lacking worldwide country
samples and studies on human opinions in different historical periods, as well
as lacking discussion on using language to steer LLMs. Moreover, they also
overlook the potential influence of prompt language on the alignment of LLMs'
opinions. In this study, our goal is to fill these gaps. To this end, we create
an evaluation framework based on the World Values Survey (WVS) to
systematically assess the alignment of LLMs with human opinions across
different countries, languages, and historical periods around the world. We
find that LLMs appropriately or over-align the opinions with only a few
countries while under-aligning the opinions with most countries. Furthermore,
changing the language of the prompt to match the language used in the
questionnaire can effectively steer LLMs to align with the opinions of the
corresponding country more effectively than existing steering methods. At the
same time, LLMs are more aligned with the opinions of the contemporary
population. To our knowledge, our study is the first comprehensive
investigation of the topic of opinion alignment in LLMs across global,
language, and temporal dimensions. Our code and data are publicly available at
https://github.com/nlply/global-opinion-alignment.

</details>


### [88] [Trusted Uncertainty in Large Language Models: A Unified Framework for Confidence Calibration and Risk-Controlled Refusal](https://arxiv.org/abs/2509.01455)
*Markus Oehri,Giulia Conti,Kaviraj Pather,Alexandre Rossi,Laia Serra,Adrian Parody,Rogvi Johannesen,Aviaja Petersen,Arben Krasniqi*

Main category: cs.CL

TL;DR: UniCR是一个统一框架，将多种不确定性证据转化为校准的正确概率，并通过原则性拒绝来执行用户指定的错误预算，提高语言模型的可信度。


<details>
  <summary>Details</summary>
Motivation: 部署的语言模型需要决定何时回答、何时不回答，以避免错误回答。现有方法往往缺乏统一的框架来处理不同类型的不确定性证据。

Method: 使用轻量级校准头进行温度缩放和适当评分，支持黑盒API模型，采用符合风险控制的分布无关保证。对于长文本生成，通过检索证据监督原子事实性得分来对齐置信度与语义保真度。

Result: 在短问答、代码生成和检索增强的长问答实验中，校准指标持续改进，风险-覆盖率曲线下面积降低，固定风险下覆盖率更高。

Conclusion: UniCR提供了一个从证据融合到校准概率再到风险控制决策的可移植方案，无需微调基础模型且在分布偏移下保持有效，显著提高了模型可信度。

Abstract: Deployed language models must decide not only what to answer but also when
not to answer. We present UniCR, a unified framework that turns heterogeneous
uncertainty evidence including sequence likelihoods, self-consistency
dispersion, retrieval compatibility, and tool or verifier feedback into a
calibrated probability of correctness and then enforces a user-specified error
budget via principled refusal. UniCR learns a lightweight calibration head with
temperature scaling and proper scoring, supports API-only models through
black-box features, and offers distribution-free guarantees using conformal
risk control. For long-form generation, we align confidence with semantic
fidelity by supervising on atomic factuality scores derived from retrieved
evidence, reducing confident hallucinations while preserving coverage.
Experiments on short-form QA, code generation with execution tests, and
retrieval-augmented long-form QA show consistent improvements in calibration
metrics, lower area under the risk-coverage curve, and higher coverage at fixed
risk compared to entropy or logit thresholds, post-hoc calibrators, and
end-to-end selective baselines. Analyses reveal that evidence contradiction,
semantic dispersion, and tool inconsistency are the dominant drivers of
abstention, yielding informative user-facing refusal messages. The result is a
portable recipe of evidence fusion to calibrated probability to risk-controlled
decision that improves trustworthiness without fine-tuning the base model and
remains valid under distribution shift.

</details>


### [89] [Robust Knowledge Editing via Explicit Reasoning Chains for Distractor-Resilient Multi-Hop QA](https://arxiv.org/abs/2509.01468)
*Yuchen Wu,Liang Ding,Li Shen,Dacheng Tao*

Main category: cs.CL

TL;DR: Reason-KE是一个基于推理链的知识编辑框架，通过四阶段结构化流程在单次处理中过滤干扰信息，显著提升大语言模型在多跳问答中的准确性和抗干扰能力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型训练后知识静态化，传统知识编辑方法要么过度依赖表面线索，要么在噪声多跳条件下崩溃，需要更可靠的知识更新方法。

Method: 端到端推理链编辑框架，包含事实确认、相关性判定、选择性应用和最终推理四个结构化阶段，在单次处理中过滤干扰信息。

Result: 在MQuAKE-CF数据集上，Reason-KE将Qwen2.5-7B的多跳问答准确率提升至90.2%，在强干扰下仅下降6.3%，答案泄露时下降<1%。

Conclusion: Reason-KE建立了可靠LLM知识更新的新标杆，展现出卓越的抗干扰能力和效率，为动态知识集成提供了有效解决方案。

Abstract: Large language models (LLMs) encode vast amounts of world knowledge but
remain static once trained, making the timely integration of emerging facts
prohibitively expensive via full retraining. Knowledge-editing techniques have
thus emerged to inject or overwrite specific facts into LLMs, yet they either
over-rely on superficial cues or incur complex, iterative pipelines that
collapse under noisy, multi-hop conditions. We introduce Reason-KE, an
end-to-end reasoning-chain-based editing framework that steers a pretrained LLM
through four structured stages-fact acknowledgment, relevance determination,
selective application, and final reasoning-to filter distractors in a single
pass. Trained on MQuAKE-CF with up to four irrelevant facts, Reason-KE elevates
Qwen2.5-7B's multi-hop QA accuracy to 90.2% while suffering merely a 6.3% drop
under heavy distraction and <1% when answers are leaked. Our quantitative
analysis confirms Reason-KE's resilience and efficiency, establishing a new
state-of-the-art for reliable LLM knowledge updates.

</details>


### [90] [Do Retrieval Augmented Language Models Know When They Don't Know?](https://arxiv.org/abs/2509.01476)
*Youchao Zhou,Heyan Huang,Yicheng Liu,Rui Dai,Xinglin Wang,Xingchen Zhang,Shumin Shi,Yang Deng*

Main category: cs.CL

TL;DR: 本研究探讨了检索增强语言模型(RALMs)的拒绝能力，发现LLMs存在过度拒绝行为，研究了不同后训练方法对拒绝能力的影响，并提出了一种简单有效的拒绝方法来提升答案质量。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型会产生事实错误的幻觉，当前研究主要关注检索增强语言模型和拒绝后训练的单独效果，但忽视了评估RALMs的拒绝能力，需要研究RALMs是否知道何时不知道。

Method: 通过分析不同内部和外部知识状态下RALMs的校准情况，研究拒绝后训练对过度拒绝问题的影响，比较Refusal-aware Instruction Tuning和In-Context Fine-tuning方法，并开发新的拒绝方法。

Result: 发现LLMs存在显著过度拒绝行为；In-context fine-tuning能缓解过度拒绝问题但R-tuning会放大该问题；拒绝能力可能与答案质量存在冲突。

Conclusion: 研究提供了对RALM系统中重要影响因素更全面的理解，开发的有效拒绝方法可以提升拒绝和正确答案的整体质量。

Abstract: Existing Large Language Models (LLMs) occasionally generate plausible yet
factually incorrect responses, known as hallucinations. Researchers are
primarily using two approaches to mitigate hallucinations, namely Retrieval
Augmented Language Models (RALMs) and refusal post-training. However, current
research predominantly emphasizes their individual effectiveness while
overlooking the evaluation of the refusal capability of RALMs. In this study,
we ask the fundamental question: Do RALMs know when they don't know?
Specifically, we ask three questions. First, are RALMs well-calibrated
regarding different internal and external knowledge states? We examine the
influence of various factors. Contrary to expectations, we find that LLMs
exhibit significant \textbf{over-refusal} behavior. Then, how does refusal
post-training affect the over-refusal issue? We investigate the Refusal-aware
Instruction Tuning and In-Context Fine-tuning methods. Our results show that
the over-refusal problem is mitigated by In-context fine-tuning. but magnified
by R-tuning. However, we also find that the refusal ability may conflict with
the quality of the answer. Finally, we develop a simple yet effective refusal
method for refusal post-trained models to improve their overall answer quality
in terms of refusal and correct answers. Our study provides a more
comprehensive understanding of the influence of important factors on RALM
systems.

</details>


### [91] [MeVe: A Modular System for Memory Verification and Effective Context Control in Language Models](https://arxiv.org/abs/2509.01514)
*Andreas Ottem*

Main category: cs.CL

TL;DR: MeVe提出了一种模块化架构，通过五个可审计和独立调优的阶段来改进RAG系统，显著提高了上下文效率，在Wikipedia数据集上减少57%，在HotpotQA数据集上减少75%的上下文使用。


<details>
  <summary>Details</summary>
Motivation: 传统RAG系统由于简单的top-k语义搜索机制，经常包含不相关或冗余信息，导致性能下降和效率低下。

Method: 提出了五阶段模块化设计：初始检索、相关性验证、备用检索、上下文优先级排序和token预算分配，实现对LLM可用知识的细粒度控制。

Result: 在知识密集型QA任务上，MeVe显著提高了上下文效率，Wikipedia数据集减少57%，HotpotQA数据集减少75%的上下文使用。

Conclusion: MeVe为更可扩展和可靠的LLM应用提供了框架，通过精炼和提取上下文信息，实现了更好的基础支撑和更准确的事实支持。

Abstract: Retrieval-Augmented Generation (RAG) systems typically face constraints
because of their inherent mechanism: a simple top-k semantic search [1]. The
approach often leads to the incorporation of irrelevant or redundant
information in the context, degrading performance and efficiency [10][11]. This
paper presents MeVe, a novel modular architecture intended for Memory
Verification and smart context composition. MeVe rethinks the RAG paradigm by
proposing a five-phase modular design that distinctly breaks down the retrieval
and context composition process into distinct, auditable, and independently
tunable phases: initial retrieval, relevance verification, fallback retrieval,
context prioritization, and token budgeting. This architecture enables
fine-grained control of what knowledge is made available to an LLM, enabling
task-dependent filtering and adaptation. We release a reference implementation
of MeVe as a proof of concept and evaluate its performance on knowledge-heavy
QA tasks over a subset of English Wikipedia [22]. Our results demonstrate that
by actively verifying information before composition, MeVe significantly
improves context efficiency, achieving a 57% reduction on the Wikipedia dataset
and a 75% reduction on the more complex HotpotQA dataset compared to standard
RAG implementations [25]. This work provides a framework for more scalable and
reliable LLM applications. By refining and distilling contextual information,
MeVe offers a path toward better grounding and more accurate factual support
[16].

</details>


### [92] [Service, Solidarity, and Self-Help: A Comparative Topic Modeling Analysis of Community Unionism in the Boot and Shoe Union and Unite Community](https://arxiv.org/abs/2509.01529)
*Thomas Compton*

Main category: cs.CL

TL;DR: 本文使用BERTopic和cTF-IDF权重技术，对两个不同时期的社区工会进行语境对比分析，发现它们在社区工会主义特征上存在显著差异


<details>
  <summary>Details</summary>
Motivation: 对比分析1920年代和2010-2020年代两个不同历史时期的社区工会语境，以了解社区工会主义在不同时期和部门中的连续性和差异性

Method: 使用BERTopic进行主题建模和cTF-IDF权重方法，结合词频分析，对国家皮革工会和Unite Community两个工会的语料进行对比研究

Result: 发现两个工会在主题重点和语境一致性上存在显著差异：Unite Community更偶向外向的社会正义主题，而国家皮革工会更重视内部管理、工业关系和成员服务

Conclusion: 虽然两个工会都涉及社区相关主题，但它们的参与模式存在显著分异，这对社区工会主义在不同时期和部门中的连续性和普遍性假设构成了挑战

Abstract: This paper presents a comparative analysis of community unionism (CU) in two
distinct historical and organizational contexts: the National Boot and Shoe
Union (B\&S) in the 1920s and Unite Community in the 2010s--2020s. Using
BERTopic for thematic modeling and cTF-IDF weighting, alongside word frequency
analysis, the study examines the extent to which each union's discourse aligns
with key features of CU -- such as coalition-building, grassroots engagement,
and action beyond the workplace. The results reveal significant differences in
thematic focus and discursive coherence. While Unite Community demonstrates
stronger alignment with outward-facing, social justice-oriented themes, the
B\&S corpus emphasizes internal administration, industrial relations, and
member services -- reflecting a more traditional, servicing-oriented union
model. The analysis also highlights methodological insights, demonstrating how
modern NLP techniques can enhance the study of historical labor archives.
Ultimately, the findings suggest that while both unions engage with
community-related themes, their underlying models of engagement diverge
significantly, challenging assumptions about the continuity and universality of
community unionism across time and sector.

</details>


### [93] [CAT: Causal Attention Tuning For Injecting Fine-grained Causal Knowledge into Large Language Models](https://arxiv.org/abs/2509.01535)
*Kairong Han,Wenshuo Zhao,Ziyu Zhao,JunJian Ye,Lujia Pan,Kun Kuang*

Main category: cs.CL

TL;DR: 提出Causal Attention Tuning (CAT)方法，通过向注意力机制注入细粒度因果知识，解决LLMs依赖伪相关而非真实因果关系的问题，在OOD场景中表现鲁棒。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然取得显著成功，但往往捕捉的是伪相关而非真实因果关系，导致在分布外场景中性能下降。需要让模型有效利用因果知识进行预测和生成。

Method: 提出CAT方法：1）自动化流水线利用人类先验生成token级因果信号；2）引入Re-Attention机制指导训练，让模型关注因果结构同时减轻注意力分数中的噪声和偏差

Result: 在提出的Spurious Token Game基准测试和多个下游任务上，该方法有效利用了因果知识进行预测，在OOD场景中保持鲁棒性

Conclusion: CAT方法成功地将因果知识注入注意力机制，显著提升了LLMs在利用因果关系方面的能力，特别是在分布外场景中的表现

Abstract: Large Language Models (LLMs) have achieved remarkable success across various
domains. However, a fundamental question remains: Can LLMs effectively utilize
causal knowledge for prediction and generation? Through empirical studies, we
find that LLMs trained directly on large-scale data often capture spurious
correlations rather than true causal relationships, leading to suboptimal
performance, especially in out-of-distribution (OOD) scenarios. To address this
challenge, we propose Causal Attention Tuning (CAT), a novel approach that
injects fine-grained causal knowledge into the attention mechanism. We propose
an automated pipeline that leverages human priors to automatically generate
token-level causal signals and introduce the Re-Attention mechanism to guide
training, helping the model focus on causal structures while mitigating noise
and biases in attention scores. Experimental results on our proposed Spurious
Token Game (STG) benchmark and multiple downstream tasks demonstrate that our
approach effectively leverages causal knowledge for prediction and remains
robust in OOD scenarios. Implementation details can be found at
https://github.com/Kairong-Han/CAT.

</details>


### [94] [In-N-Out: A Parameter-Level API Graph Dataset for Tool Agents](https://arxiv.org/abs/2509.01560)
*Seungkyu Lee,Nalim Kim,Yohan Jo*

Main category: cs.CL

TL;DR: 该论文提出了In-N-Out数据集，通过将API文档转换为结构化API图来改善工具代理在多工具查询中的性能，显著提升了API检索和组合调用能力。


<details>
  <summary>Details</summary>
Motivation: 随着任务复杂度增加，基于LLM的工具代理在识别和正确调用API方面存在困难，需要更好的方法来理解API依赖关系和组合调用。

Method: 将API文档转换为结构化API图来捕获API依赖关系，并创建了首个专家标注的API图数据集In-N-Out，基于两个真实API基准构建。

Result: 使用In-N-Out显著提升了工具检索和多工具查询生成的性能，几乎比仅使用文档的LLM性能翻倍。微调模型生成的图可缩小90%的性能差距。

Conclusion: 显式API图对工具代理具有重要价值，In-N-Out数据集是理解API文档和参数关系的宝贵资源，将公开发布数据集和代码。

Abstract: Tool agents -- LLM-based systems that interact with external APIs -- offer a
way to execute real-world tasks. However, as tasks become increasingly complex,
these agents struggle to identify and call the correct APIs in the proper
order. To tackle this problem, we investigate converting API documentation into
a structured API graph that captures API dependencies and leveraging it for
multi-tool queries that require compositional API calls. To support this, we
introduce In-N-Out, the first expert-annotated dataset of API graphs built from
two real-world API benchmarks and their documentation. Using In-N-Out
significantly improves performance on both tool retrieval and multi-tool query
generation, nearly doubling that of LLMs using documentation alone. Moreover,
graphs generated by models fine-tuned on In-N-Out close 90% of this gap,
showing that our dataset helps models learn to comprehend API documentation and
parameter relationships. Our findings highlight the promise of using explicit
API graphs for tool agents and the utility of In-N-Out as a valuable resource.
We will release the dataset and code publicly.

</details>


### [95] [Enhancing Uncertainty Estimation in LLMs with Expectation of Aggregated Internal Belief](https://arxiv.org/abs/2509.01564)
*Zeguan Xiao,Diyang Dou,Boya Xiong,Yun Chen,Guanhua Chen*

Main category: cs.CL

TL;DR: EAGLE是一种基于自评估的校准方法，通过聚合LLM中间层的内部信念来获得更准确的置信度分数，显著改善了模型校准性能


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在RLHF后往往表现出过度自信，生成看似合理但错误的答案，这给可靠的uncertainty estimation和安全部署带来挑战

Method: 提出EAGLE方法，从多个中间层提取内部信念，聚合这些层间信念并计算置信度分数分布的期望值，获得更精确的置信度评分

Result: 在多个数据集和LLM上的广泛实验表明，EAGLE相比现有基线显著提升了校准性能

Conclusion: EAGLE通过利用LLM内部隐藏状态进行自评估校准，能够更准确地反映模型内部确定性，为可靠的不确定性估计提供了有效解决方案

Abstract: Large Language Models (LLMs) have achieved remarkable success across a wide
range of natural language tasks, but often exhibit overconfidence and generate
plausible yet incorrect answers. This overconfidence, especially in models
undergone Reinforcement Learning from Human Feedback (RLHF), poses significant
challenges for reliable uncertainty estimation and safe deployment. In this
paper, we propose EAGLE (Expectation of AGgregated internaL bEief), a novel
self-evaluation-based calibration method that leverages the internal hidden
states of LLMs to derive more accurate confidence scores. Instead of relying on
the model's final output, our approach extracts internal beliefs from multiple
intermediate layers during self-evaluation. By aggregating these layer-wise
beliefs and calculating the expectation over the resulting confidence score
distribution, EAGLE produces a refined confidence score that more faithfully
reflects the model's internal certainty. Extensive experiments on diverse
datasets and LLMs demonstrate that EAGLE significantly improves calibration
performance over existing baselines. We also provide an in-depth analysis of
EAGLE, including a layer-wise examination of uncertainty patterns, a study of
the impact of self-evaluation prompts, and an analysis of the effect of
self-evaluation score range.

</details>


### [96] [Testing the assumptions about the geometry of sentence embedding spaces: the cosine measure need not apply](https://arxiv.org/abs/2509.01606)
*Vivi Nastase,Paola Merlo*

Main category: cs.CL

TL;DR: 研究发现句子嵌入空间中的几何距离并不能预测不同嵌入方法在具体任务上的性能表现，余弦相似度只能捕捉浅层共性，语言信息通过不同维度的加权组合编码。


<details>
  <summary>Details</summary>
Motivation: 探究句子嵌入空间中的几何距离是否能够反映不同句子嵌入方法在语言任务上的性能相关性，验证嵌入空间几何结构对任务表现的预测能力。

Method: 使用三种方式计算句子嵌入：平均词嵌入、特殊[CLS]标记嵌入和随机词嵌入，分析这些嵌入变体之间的距离与其在语言任务上性能的相关性。

Result: 余弦相似度只能捕捉句子嵌入之间的浅层共性或差异，这些差异不能预测在具体任务上的性能。语言信息是通过不同维度的加权组合编码的，而不是反映在句子嵌入空间的几何结构中。

Conclusion: 句子嵌入空间的几何结构不能作为预测不同嵌入方法在语言任务上相对性能的可靠指标，语言信息的编码方式比简单的几何距离更为复杂。

Abstract: Transformer models learn to encode and decode an input text, and produce
contextual token embeddings as a side-effect. The mapping from language into
the embedding space maps words expressing similar concepts onto points that are
close in the space. In practice, the reverse implication is also assumed: words
corresponding to close points in this space are similar or related, those that
are further are not.
  Does closeness in the embedding space extend to shared properties for
sentence embeddings? We present an investigation of sentence embeddings and
show that the geometry of their embedding space is not predictive of their
relative performances on a variety of tasks.
  We compute sentence embeddings in three ways: as averaged token embeddings,
as the embedding of the special [CLS] token, and as the embedding of a random
token from the sentence. We explore whether there is a correlation between the
distance between sentence embedding variations and their performance on
linguistic tasks, and whether despite their distances, they do encode the same
information in the same manner.
  The results show that the cosine similarity -- which treats dimensions
shallowly -- captures (shallow) commonalities or differences between sentence
embeddings, which are not predictive of their performance on specific tasks.
Linguistic information is rather encoded in weighted combinations of different
dimensions, which are not reflected in the geometry of the sentence embedding
space.

</details>


### [97] [Benchmarking the Detection of LLMs-Generated Modern Chinese Poetry](https://arxiv.org/abs/2509.01620)
*Shanshan Wang,Junchao Wu,Fengying Ye,Jingming Yao,Lidia S. Chao,Derek F. Wong*

Main category: cs.CL

TL;DR: 本文提出了检测AI生成现代中文诗歌的新基准，构建了包含800首人工诗歌和41,600首AI诗歌的高质量数据集，测试发现现有检测器无法可靠识别AI生成的现代中文诗歌。


<details>
  <summary>Details</summary>
Motivation: 由于AI生成文本与人类写作难以区分，而现代中文诗歌具有独特特征，AI生成诗歌的泛滥严重扰乱了诗歌生态系统，急需开发有效的检测方法。

Method: 首先构建高质量数据集（800首专业诗人作品+41,600首主流LLM生成诗歌），然后系统评估6种检测器在该数据集上的性能表现。

Result: 实验结果表明当前检测器无法可靠检测LLM生成的现代中文诗歌，最难检测的诗意特征是内在品质（特别是风格）。

Conclusion: 提出的基准验证了其有效性和必要性，为未来AI生成诗歌检测奠定了基础。

Abstract: The rapid development of advanced large language models (LLMs) has made
AI-generated text indistinguishable from human-written text. Previous work on
detecting AI-generated text has made effective progress, but has not involved
modern Chinese poetry. Due to the distinctive characteristics of modern Chinese
poetry, it is difficult to identify whether a poem originated from humans or
AI. The proliferation of AI-generated modern Chinese poetry has significantly
disrupted the poetry ecosystem. Based on the urgency of identifying
AI-generated poetry in the real Chinese world, this paper proposes a novel
benchmark for detecting LLMs-generated modern Chinese poetry. We first
construct a high-quality dataset, which includes both 800 poems written by six
professional poets and 41,600 poems generated by four mainstream LLMs.
Subsequently, we conduct systematic performance assessments of six detectors on
this dataset. Experimental results demonstrate that current detectors cannot be
used as reliable tools to detect modern Chinese poems generated by LLMs. The
most difficult poetic features to detect are intrinsic qualities, especially
style. The detection results verify the effectiveness and necessity of our
proposed benchmark. Our work lays a foundation for future detection of
AI-generated poetry.

</details>


### [98] [TransGAT: Transformer-Based Graph Neural Networks for Multi-Dimensional Automated Essay Scoring](https://arxiv.org/abs/2509.01640)
*Hind Aljuaid,Areej Alhothali,Ohoud Al-Zamzami,Hussein Assalahi*

Main category: cs.CL

TL;DR: TransGAT是一种结合微调Transformer和图注意力网络(GAT)的自动论文评分方法，通过双流预测机制实现分析性评分，在ELLIPSE数据集上表现优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 传统人工论文评分耗时且不一致，现有自动评分方法使用静态词嵌入无法捕捉上下文语义，且多采用整体评分而忽略语法、词汇等具体写作维度。

Method: 将微调Transformer(BERT、RoBERTa、DeBERTaV3)与GAT配对，第一流生成论文级预测，第二流对Transformer词嵌入应用GAT(基于句法依赖构建边)，最后融合两流预测得到分析性分数。

Result: 在ELLIPSE数据集上，TransGAT在所有分析评分维度上平均二次加权Kappa(QWK)达到0.854，优于基线模型。

Conclusion: TransGAT展示了结合Transformer上下文理解能力和GAT关系建模优势的潜力，能够推动自动论文评分系统的发展。

Abstract: Essay writing is a critical component of student assessment, yet manual
scoring is labor-intensive and inconsistent. Automated Essay Scoring (AES)
offers a promising alternative, but current approaches face limitations. Recent
studies have incorporated Graph Neural Networks (GNNs) into AES using static
word embeddings that fail to capture contextual meaning, especially for
polysemous words. Additionally, many methods rely on holistic scoring,
overlooking specific writing aspects such as grammar, vocabulary, and cohesion.
To address these challenges, this study proposes TransGAT, a novel approach
that integrates fine-tuned Transformer models with GNNs for analytic scoring.
TransGAT combines the contextual understanding of Transformers with the
relational modeling strength of Graph Attention Networks (GAT). It performs
two-stream predictions by pairing each fine-tuned Transformer (BERT, RoBERTa,
and DeBERTaV3) with a separate GAT. In each pair, the first stream generates
essay-level predictions, while the second applies GAT to Transformer token
embeddings, with edges constructed from syntactic dependencies. The model then
fuses predictions from both streams to produce the final analytic score.
Experiments on the ELLIPSE dataset show that TransGAT outperforms baseline
models, achieving an average Quadratic Weighted Kappa (QWK) of 0.854 across all
analytic scoring dimensions. These findings highlight the potential of TransGAT
to advance AES systems.

</details>


### [99] [Parallel Needleman-Wunsch on CUDA to measure word similarity based on phonetic transcriptions](https://arxiv.org/abs/2509.01654)
*Dominic Plein*

Main category: cs.CL

TL;DR: 基于Needleman-Wunsch算法计算单词语音相似度，使用Rust实现并在CPU/GPU上并行化处理，通过构建全连接图和聚类分析验证方法有效性


<details>
  <summary>Details</summary>
Motivation: 开发一种基于语音转录的单词相似度计算方法，用于分析语言的语音结构，并能够高效处理大规模数据集

Method: 使用Needleman-Wunsch算法计算语音相似度，Rust实现并利用CUDA和cudarc库进行CPU/GPU并行化，构建全连接图并使用聚类算法分析

Result: 方法在分析语言语音结构方面表现出可行性和有效性，GPU实现带来显著性能提升，可轻松扩展到其他语言

Conclusion: 提出的基于语音的单词相似度计算方法有效且高效，为语言语音结构分析提供了实用工具，具有良好的扩展性

Abstract: We present a method to calculate the similarity between words based on their
phonetic transcription (their pronunciation) using the Needleman-Wunsch
algorithm. We implement this algorithm in Rust and parallelize it on both CPU
and GPU to handle large datasets efficiently. The GPU implementation leverages
CUDA and the cudarc Rust library to achieve significant performance
improvements. We validate our approach by constructing a fully-connected graph
where nodes represent words and edges have weights according to the similarity
between the words. This graph is then analyzed using clustering algorithms to
identify groups of phonetically similar words. Our results demonstrate the
feasibility and effectiveness of the proposed method in analyzing the phonetic
structure of languages. It might be easily expanded to other languages.

</details>


### [100] [Bridging Thoughts and Words: Graph-Based Intent-Semantic Joint Learning for Fake News Detection](https://arxiv.org/abs/2509.01660)
*Zhengjia Wang,Qiang Sheng,Danding Wang,Beizhe Hu,Juan Cao*

Main category: cs.CL

TL;DR: 本文提出了一种基于图神经网络的意图-语义联合建模方法(InSide)用于假新闻检测，通过将语义和意图信号转化为异构图结构，实现深度特征融合和跨信号对齐。


<details>
  <summary>Details</summary>
Motivation: 现有假新闻检测方法主要依赖语义线索（如情感词汇、文体特征等），容易陷入表面模式检测，在动态环境中性能有限。本文从新闻意图角度切入，认为理解新闻背后的欺骗意图能更深入地识别假新闻。

Method: 提出Graph-based Intent-Semantic Joint Modeling (InSide)框架：1）将语义和意图信号构建为异构图；2）通过实体引导实现长距离上下文交互；3）采用粗到细的意图建模；4）开发动态路径图对齐策略实现信号间有效聚合。

Result: 在四个基准数据集上的大量实验表明，InSide方法相比现有最先进方法具有显著优势。

Conclusion: 通过将意图信号与语义线索相结合，并采用图神经网络进行联合建模，能够更有效地检测假新闻，克服了单纯依赖语义特征的局限性。

Abstract: Fake news detection is an important and challenging task for defending online
information integrity. Existing state-of-the-art approaches typically extract
news semantic clues, such as writing patterns that include emotional words,
stylistic features, etc. However, detectors tuned solely to such semantic clues
can easily fall into surface detection patterns, which can shift rapidly in
dynamic environments, leading to limited performance in the evolving news
landscape. To address this issue, this paper investigates a novel perspective
by incorporating news intent into fake news detection, bridging intents and
semantics together. The core insight is that by considering news intents, one
can deeply understand the inherent thoughts behind news deception, rather than
the surface patterns within words alone. To achieve this goal, we propose
Graph-based Intent-Semantic Joint Modeling (InSide) for fake news detection,
which models deception clues from both semantic and intent signals via
graph-based joint learning. Specifically, InSide reformulates news semantic and
intent signals into heterogeneous graph structures, enabling long-range context
interaction through entity guidance and capturing both holistic and
implementation-level intent via coarse-to-fine intent modeling. To achieve
better alignment between semantics and intents, we further develop a dynamic
pathway-based graph alignment strategy for effective message passing and
aggregation across these signals by establishing a common space. Extensive
experiments on four benchmark datasets demonstrate the superiority of the
proposed InSide compared to state-of-the-art methods.

</details>


### [101] [chDzDT: Word-level morphology-aware language model for Algerian social media text](https://arxiv.org/abs/2509.01772)
*Abdelkrime Aries*

Main category: cs.CL

TL;DR: 提出了chDzDT，一个针对阿尔及利亚方言形态特征的字符级预训练语言模型，通过处理孤立单词而非传统token序列来更好地处理该方言的复杂形态和代码转换问题。


<details>
  <summary>Details</summary>
Motivation: 阿尔及利亚方言在自然语言处理中代表性不足，其复杂的形态、频繁的代码转换、多脚本使用以及来自其他语言的强烈词汇影响，使得传统的词级或子词级方法效果有限。

Method: 开发字符级预训练语言模型chDzDT，在孤立单词上进行训练，不依赖token边界或标准化拼写。使用YouTube评论、法语/英语/柏柏尔语维基百科以及Tatoeba项目等多源数据构建训练语料库。

Result: 创建了阿尔及利亚方言的详细形态分析、构建了多语言阿尔及利亚词典数据集，并开发了作为形态编码器的字符级PLM，在下游任务中表现出色。

Conclusion: 字符级建模对于形态丰富、资源稀缺的方言具有巨大潜力，为构建更具包容性和适应性的NLP系统奠定了基础。

Abstract: Pre-trained language models (PLMs) have substantially advanced natural
language processing by providing context-sensitive text representations.
However, the Algerian dialect remains under-represented, with few dedicated
models available. Processing this dialect is challenging due to its complex
morphology, frequent code-switching, multiple scripts, and strong lexical
influences from other languages. These characteristics complicate tokenization
and reduce the effectiveness of conventional word- or subword-level approaches.
  To address this gap, we introduce chDzDT, a character-level pre-trained
language model tailored for Algerian morphology. Unlike conventional PLMs that
rely on token sequences, chDzDT is trained on isolated words. This design
allows the model to encode morphological patterns robustly, without depending
on token boundaries or standardized orthography. The training corpus draws from
diverse sources, including YouTube comments, French, English, and Berber
Wikipedia, as well as the Tatoeba project. It covers multiple scripts and
linguistic varieties, resulting in a substantial pre-training workload.
  Our contributions are threefold: (i) a detailed morphological analysis of
Algerian dialect using YouTube comments; (ii) the construction of a
multilingual Algerian lexicon dataset; and (iii) the development and extensive
evaluation of a character-level PLM as a morphology-focused encoder for
downstream tasks. The proposed approach demonstrates the potential of
character-level modeling for morphologically rich, low-resource dialects and
lays a foundation for more inclusive and adaptable NLP systems.

</details>


### [102] [Flaw or Artifact? Rethinking Prompt Sensitivity in Evaluating LLMs](https://arxiv.org/abs/2509.01790)
*Andong Hua,Kenan Tang,Chenhe Gu,Jindong Gu,Eric Wong,Yao Qin*

Main category: cs.CL

TL;DR: 研究表明，LLM的提示词敏感性很大程度上是评估方法的人为产物而非模型固有缺陷，使用LLM作为评判者可以显著降低性能方差


<details>
  <summary>Details</summary>
Motivation: 重新审视广泛报道的LLM提示词敏感性，探究这是否是模型的固有弱点还是评估过程的人为产物

Method: 系统评估7个LLM模型（包括GPT和Gemini系列）在6个基准测试上的表现，使用12个不同的提示模板，对比启发式评估方法和LLM-as-a-Judge方法

Result: 发现提示词敏感性主要源于启发式评估方法（如对数似然评分和严格答案匹配），这些方法经常忽略语义正确但表达方式不同的回答。使用LLM作为评判者时，性能方差显著降低，模型排名相关性更高

Conclusion: 现代LLM对提示模板的鲁棒性比之前认为的要强，提示词敏感性更多是评估方法的问题而非模型缺陷

Abstract: Prompt sensitivity, referring to the phenomenon where paraphrasing (i.e.,
repeating something written or spoken using different words) leads to
significant changes in large language model (LLM) performance, has been widely
accepted as a core limitation of LLMs. In this work, we revisit this issue and
ask: Is the widely reported high prompt sensitivity truly an inherent weakness
of LLMs, or is it largely an artifact of evaluation processes? To answer this
question, we systematically evaluate 7 LLMs (e.g., GPT and Gemini family)
across 6 benchmarks, including both multiple-choice and open-ended tasks on 12
diverse prompt templates. We find that much of the prompt sensitivity stems
from heuristic evaluation methods, including log-likelihood scoring and rigid
answer matching, which often overlook semantically correct responses expressed
through alternative phrasings, such as synonyms or paraphrases. When we adopt
LLM-as-a-Judge evaluations, we observe a substantial reduction in performance
variance and a consistently higher correlation in model rankings across
prompts. Our findings suggest that modern LLMs are more robust to prompt
templates than previously believed, and that prompt sensitivity may be more an
artifact of evaluation than a flaw in the models.

</details>


### [103] [Mic Drop or Data Flop? Evaluating the Fitness for Purpose of AI Voice Interviewers for Data Collection within Quantitative & Qualitative Research Contexts](https://arxiv.org/abs/2509.01814)
*Shreyas Tirumala,Nishant Jain,Danny D. Leybzon,Trent D. Buskirk*

Main category: cs.CL

TL;DR: 本文评估AI面试官系统在定量和定性研究中的数据收集能力，发现AI面试官已超越传统IVR系统，但在实时转录准确性、情感检测和追问质量方面仍有局限，适用性取决于具体研究场景。


<details>
  <summary>Details</summary>
Motivation: 随着基于Transformer的大语言模型发展，AI面试官系统能够实时进行语音调查。本文旨在评估这类系统在定量和定性研究中的数据收集适用性，为研究实践提供指导。

Method: 通过回顾新兴证据，从两个维度评估AI面试官和传统IVR系统：输入/输出性能（语音识别、答案记录、情感处理）和语言推理能力（追问、澄清、分支逻辑处理）。

Result: 实地研究表明，AI面试官在定量和定性数据收集方面已超越IVR系统，但存在实时转录错误率较高、情感检测能力有限、追问质量不均等问题。

Conclusion: 当前AI面试官技术的实用性、使用和采纳在定性数据收集中可能具有情境依赖性，需要根据具体研究场景谨慎选择和使用。

Abstract: Transformer-based Large Language Models (LLMs) have paved the way for "AI
interviewers" that can administer voice-based surveys with respondents in
real-time. This position paper reviews emerging evidence to understand when
such AI interviewing systems are fit for purpose for collecting data within
quantitative and qualitative research contexts. We evaluate the capabilities of
AI interviewers as well as current Interactive Voice Response (IVR) systems
across two dimensions: input/output performance (i.e., speech recognition,
answer recording, emotion handling) and verbal reasoning (i.e., ability to
probe, clarify, and handle branching logic). Field studies suggest that AI
interviewers already exceed IVR capabilities for both quantitative and
qualitative data collection, but real-time transcription error rates, limited
emotion detection abilities, and uneven follow-up quality indicate that the
utility, use and adoption of current AI interviewer technology may be
context-dependent for qualitative data collection efforts.

</details>


### [104] [Extracting OPQRST in Electronic Health Records using Large Language Models with Reasoning](https://arxiv.org/abs/2509.01885)
*Zhimeng Luo,Abhibha Gupta,Adam Frisch,Daqing He*

Main category: cs.CL

TL;DR: 本文提出使用大型语言模型从电子健康记录中提取OPQRST评估信息的新方法，将任务从序列标注重构为文本生成，提高可解释性和适应性，并改进临床文本评估指标。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录数据复杂且非结构化，传统机器学习方法难以有效捕捉关键信息，临床医生难以有效使用这些工具进行患者护理。

Method: 利用大型语言模型将OPQRST评估提取任务从序列标注重构为文本生成，使模型能够提供类似医生认知过程的推理步骤，并整合语义相似度指标（如BERT Score）来评估生成文本与临床意图的对齐程度。

Result: 该方法在医疗保健AI应用中取得显著进展，提供了可扩展的解决方案，提高了从电子健康记录中提取信息的准确性和可用性。

Conclusion: 该研究为临床医生提供了更好的决策支持工具，通过改进的信息提取方法增强了患者护理效果，是医疗AI领域的重要进步。

Abstract: The extraction of critical patient information from Electronic Health Records
(EHRs) poses significant challenges due to the complexity and unstructured
nature of the data. Traditional machine learning approaches often fail to
capture pertinent details efficiently, making it difficult for clinicians to
utilize these tools effectively in patient care. This paper introduces a novel
approach to extracting the OPQRST assessment from EHRs by leveraging the
capabilities of Large Language Models (LLMs). We propose to reframe the task
from sequence labeling to text generation, enabling the models to provide
reasoning steps that mimic a physician's cognitive processes. This approach
enhances interpretability and adapts to the limited availability of labeled
data in healthcare settings. Furthermore, we address the challenge of
evaluating the accuracy of machine-generated text in clinical contexts by
proposing a modification to traditional Named Entity Recognition (NER) metrics.
This includes the integration of semantic similarity measures, such as the BERT
Score, to assess the alignment between generated text and the clinical intent
of the original records. Our contributions demonstrate a significant
advancement in the use of AI in healthcare, offering a scalable solution that
improves the accuracy and usability of information extraction from EHRs,
thereby aiding clinicians in making more informed decisions and enhancing
patient care outcomes.

</details>


### [105] [Weakly Supervised Medical Entity Extraction and Linking for Chief Complaints](https://arxiv.org/abs/2509.01899)
*Zhimeng Luo,Zhendong Wang,Rui Meng,Diyang Xue,Adam Frisch,Daqing He*

Main category: cs.CL

TL;DR: 提出了一种弱监督方法，用于自动提取和链接主诉中的实体，无需人工标注，在120万条真实主诉记录上取得了优异性能


<details>
  <summary>Details</summary>
Motivation: 主诉记录存在多种录入方式，医疗标注差异大，难以在不同医疗机构间标准化，阻碍了医疗记录保存和文本挖掘

Method: 采用分割匹配算法生成弱标注（实体提及范围和类别标签），然后基于BERT模型训练实体识别和本体链接

Result: 在无人工标注情况下，该方法性能优于先前方法

Conclusion: 弱监督实体提取和链接方法能有效解决主诉标准化问题，为医疗文本挖掘提供了可行方案

Abstract: A Chief complaint (CC) is the reason for the medical visit as stated in the
patient's own words. It helps medical professionals to quickly understand a
patient's situation, and also serves as a short summary for medical text
mining. However, chief complaint records often take a variety of entering
methods, resulting in a wide variation of medical notations, which makes it
difficult to standardize across different medical institutions for record
keeping or text mining. In this study, we propose a weakly supervised method to
automatically extract and link entities in chief complaints in the absence of
human annotation. We first adopt a split-and-match algorithm to produce weak
annotations, including entity mention spans and class labels, on 1.2 million
real-world de-identified and IRB approved chief complaint records. Then we
train a BERT-based model with generated weak labels to locate entity mentions
in chief complaint text and link them to a pre-defined ontology. We conducted
extensive experiments, and the results showed that our Weakly Supervised Entity
Extraction and Linking (\ours) method produced superior performance over
previous methods without any human annotation.

</details>


### [106] [DRAssist: Dispute Resolution Assistance using Large Language Models](https://arxiv.org/abs/2509.01962)
*Sachin Pawar,Manoj Apte,Girish K. Palshikar,Basit Ali,Nitin Ramrakhiyani*

Main category: cs.CL

TL;DR: 本文探索使用大型语言模型作为法官助手来解决争议，开发了DRAssist系统，能够从非结构化争议描述中提取关键结构元素并生成结构化摘要，通过多种提示策略在三个不同层次上辅助争议解决。


<details>
  <summary>Details</summary>
Motivation: 解决各领域（如保险、银行、医疗等）中普遍存在的争议问题，传统方式依赖人工法官裁决，希望通过LLM技术辅助提高争议解决效率和质量。

Method: 开发DRAssist系统，首先识别争议的关键结构元素（事实、争议方面、论点等）并生成结构化摘要，然后使用多种提示策略让LLM在三个层次上输出争议解决方案：识别整体优势方、判断具体诉求是否可接受、评估论点强弱。

Result: 在汽车保险和域名争议两个特定领域进行了实验，通过合适的评估指标将LLM性能与相关基线进行比较。

Conclusion: 大型语言模型可以作为有效的争议解决辅助工具，通过结构化分析和多层次决策来帮助人类法官处理各类争议案件。

Abstract: Disputes between two parties occur in almost all domains such as taxation,
insurance, banking, healthcare, etc. The disputes are generally resolved in a
specific forum (e.g., consumer court) where facts are presented, points of
disagreement are discussed, arguments as well as specific demands of the
parties are heard, and finally a human judge resolves the dispute by often
favouring one of the two parties. In this paper, we explore the use of large
language models (LLMs) as assistants for the human judge to resolve such
disputes, as part of our DRAssist system. We focus on disputes from two
specific domains -- automobile insurance and domain name disputes. DRAssist
identifies certain key structural elements (e.g., facts, aspects or
disagreement, arguments) of the disputes and summarizes the unstructured
dispute descriptions to produce a structured summary for each dispute. We then
explore multiple prompting strategies with multiple LLMs for their ability to
assist in resolving the disputes in these domains. In DRAssist, these LLMs are
prompted to produce the resolution output at three different levels -- (i)
identifying an overall stronger party in a dispute, (ii) decide whether each
specific demand of each contesting party can be accepted or not, (iii) evaluate
whether each argument by each contesting party is strong or weak. We evaluate
the performance of LLMs on all these tasks by comparing them with relevant
baselines using suitable evaluation metrics.

</details>


### [107] [StructCoh: Structured Contrastive Learning for Context-Aware Text Semantic Matching](https://arxiv.org/abs/2509.02033)
*Chao Xue,Ziyuan Gao*

Main category: cs.CL

TL;DR: StructCoh是一个图增强的对比学习框架，通过结合结构推理和表示空间优化来解决文本语义匹配问题，在多个基准测试中显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 预训练语言模型擅长捕捉token级交互，但往往忽略层次结构模式，难以处理细微的语义区分，需要同时理解结构关系和细粒度语义差异

Method: 采用双图编码器构建语义图（通过依存分析和主题建模），使用图同构网络传播结构特征；设计分层对比目标，在多个粒度上强制一致性，包括节点级对比正则化和图感知对比学习

Result: 在三个法律文档匹配基准和学术抄袭检测数据集上表现优异，特别是在法律条文匹配上达到86.7%的F1分数（绝对提升6.2%），有效识别论证结构相似性

Conclusion: StructCoh通过结合结构推理和对比学习，显著提升了文本语义匹配性能，特别是在需要理解层次结构和细微语义差异的任务中表现出色

Abstract: Text semantic matching requires nuanced understanding of both structural
relationships and fine-grained semantic distinctions. While pre-trained
language models excel at capturing token-level interactions, they often
overlook hierarchical structural patterns and struggle with subtle semantic
discrimination. In this paper, we proposed StructCoh, a graph-enhanced
contrastive learning framework that synergistically combines structural
reasoning with representation space optimization. Our approach features two key
innovations: (1) A dual-graph encoder constructs semantic graphs via dependency
parsing and topic modeling, then employs graph isomorphism networks to
propagate structural features across syntactic dependencies and cross-document
concept nodes. (2) A hierarchical contrastive objective enforces consistency at
multiple granularities: node-level contrastive regularization preserves core
semantic units, while graph-aware contrastive learning aligns inter-document
structural semantics through both explicit and implicit negative sampling
strategies. Experiments on three legal document matching benchmarks and
academic plagiarism detection datasets demonstrate significant improvements
over state-of-the-art methods. Notably, StructCoh achieves 86.7% F1-score
(+6.2% absolute gain) on legal statute matching by effectively identifying
argument structure similarities.

</details>


### [108] [DeepSeek performs better than other Large Language Models in Dental Cases](https://arxiv.org/abs/2509.02036)
*Hexian Zhang,Xinyu Yan,Yanqi Yang,Lijian Jin,Ping Yang,Junwen Wang*

Main category: cs.CL

TL;DR: 本研究评估了四种先进大语言模型在牙科纵向病例分析中的表现，DeepSeek V3在忠实度和专家评分方面表现最佳，成为医疗案例分析的领先模型。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在医疗领域具有变革潜力，但其解释纵向患者叙事的能力尚未充分探索。牙科拥有丰富的结构化临床数据，为评估LLMs的推理能力提供了独特机会。

Method: 使用34个标准化纵向牙周病例（包含258个问答对），通过开放式临床任务评估GPT-4o、Gemini 2.0 Flash、Copilot和DeepSeek V3四种模型的表现，采用自动化指标和执业牙医盲法评估。

Result: DeepSeek表现最佳，显示出更高的忠实度（中位数得分0.528 vs. 0.367-0.457）和更高的专家评分（中位数4.5/5 vs. 4.0/5），且未显著影响可读性。

Conclusion: DeepSeek被定位为病例分析的领先LLM，支持其作为辅助工具整合到医学教育和研究中，并突显其作为领域特定代理的潜力。

Abstract: Large language models (LLMs) hold transformative potential in healthcare, yet
their capacity to interpret longitudinal patient narratives remains
inadequately explored. Dentistry, with its rich repository of structured
clinical data, presents a unique opportunity to rigorously assess LLMs'
reasoning abilities. While several commercial LLMs already exist, DeepSeek, a
model that gained significant attention earlier this year, has also joined the
competition. This study evaluated four state-of-the-art LLMs (GPT-4o, Gemini
2.0 Flash, Copilot, and DeepSeek V3) on their ability to analyze longitudinal
dental case vignettes through open-ended clinical tasks. Using 34 standardized
longitudinal periodontal cases (comprising 258 question-answer pairs), we
assessed model performance via automated metrics and blinded evaluations by
licensed dentists. DeepSeek emerged as the top performer, demonstrating
superior faithfulness (median score = 0.528 vs. 0.367-0.457) and higher expert
ratings (median = 4.5/5 vs. 4.0/5), without significantly compromising
readability. Our study positions DeepSeek as the leading LLM for case analysis,
endorses its integration as an adjunct tool in both medical education and
research, and highlights its potential as a domain-specific agent.

</details>


### [109] [NADI 2025: The First Multidialectal Arabic Speech Processing Shared Task](https://arxiv.org/abs/2509.02038)
*Bashar Talafha,Hawau Olamide Toyin,Peter Sullivan,AbdelRahim Elmadany,Abdurrahman Juma,Amirbek Djanibekov,Chiyu Zhang,Hamad Alshehhi,Hanan Aldarmaki,Mustafa Jarrar,Nizar Habash,Muhammad Abdul-Mageed*

Main category: cs.CL

TL;DR: NADI 2025共享任务聚焦阿拉伯语方言语音处理，包含方言识别、语音识别和音标恢复三个子任务，共有8个团队提交100份有效结果，最佳系统在三个任务上分别达到79.8%准确率和35.68/12.20、55/13的WER/CER指标


<details>
  <summary>Details</summary>
Motivation: 解决阿拉伯语方言语音处理中的挑战，包括方言识别、语音识别和音标恢复，推动阿拉伯语方言计算语言学的发展

Method: 通过共享任务形式组织研究社区，设置三个子任务：口语方言识别、语音识别、口语方言音标恢复，收集团队提交的系统并进行评估

Result: 44个团队注册，8个团队提交100份有效结果，最佳系统在子任务1达到79.8%准确率，子任务2达到35.68/12.20 WER/CER，子任务3达到55/13 WER/CER

Conclusion: 阿拉伯语方言语音处理仍面临重大挑战，特别是在方言识别、识别准确率和音标恢复方面，需要进一步研究改进

Abstract: We present the findings of the sixth Nuanced Arabic Dialect Identification
(NADI 2025) Shared Task, which focused on Arabic speech dialect processing
across three subtasks: spoken dialect identification (Subtask 1), speech
recognition (Subtask 2), and diacritic restoration for spoken dialects (Subtask
3). A total of 44 teams registered, and during the testing phase, 100 valid
submissions were received from eight unique teams. The distribution was as
follows: 34 submissions for Subtask 1 "five teams{\ae}, 47 submissions for
Subtask 2 "six teams", and 19 submissions for Subtask 3 "two teams". The
best-performing systems achieved 79.8% accuracy on Subtask 1, 35.68/12.20
WER/CER (overall average) on Subtask 2, and 55/13 WER/CER on Subtask 3. These
results highlight the ongoing challenges of Arabic dialect speech processing,
particularly in dialect identification, recognition, and diacritic restoration.
We also summarize the methods adopted by participating teams and briefly
outline directions for future editions of NADI.

</details>


### [110] [Attributes as Textual Genes: Leveraging LLMs as Genetic Algorithm Simulators for Conditional Synthetic Data Generation](https://arxiv.org/abs/2509.02040)
*Guangzeng Han,Weisi Liu,Xiaolei Huang*

Main category: cs.CL

TL;DR: Genetic Prompt结合遗传算法和LLM，通过模拟基因交叉和变异来增强合成数据生成的质量和多样性，在多个NLP任务中显著优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 解决LLM生成合成数据时质量和多样性不足的挑战，使合成数据分布更接近真实数据。

Method: 将语义文本属性视为基因序列，利用LLM模拟交叉和变异操作，并集成主动学习方案来优化父代选择。

Result: 在多个NLP任务中显著超越最先进基线，在不同模型规模下都表现稳健，合成数据与原始训练集融合能显著提升下游模型性能，特别适用于类别不平衡场景。

Conclusion: Genetic Prompt是生成高质量合成数据的有效方法，适用于广泛的NLP应用。

Abstract: Large Language Models (LLMs) excel at generating synthetic data, but ensuring
its quality and diversity remains challenging. We propose Genetic Prompt, a
novel framework that combines genetic algorithms with LLMs to augment synthetic
data generation. Our approach treats semantic text attributes as gene sequences
and leverages the LLM to simulate crossover and mutation operations. This
genetic process enhances data quality and diversity by creating novel attribute
combinations, yielding synthetic distributions closer to real-world data. To
optimize parent selection, we also integrate an active learning scheme that
expands the offspring search space. Our experiments on multiple NLP tasks
reveal several key findings: Genetic Prompt not only significantly outperforms
state-of-the-art baselines but also shows robust performance across various
generator model sizes and scales. Moreover, we demonstrate that fusing our
synthetic data with the original training set significantly boosts downstream
model performance, particularly for class-imbalanced scenarios. Our findings
validate that Genetic Prompt is an effective method for producing high-quality
synthetic data for a wide range of NLP applications.

</details>


### [111] [How Instruction-Tuning Imparts Length Control: A Cross-Lingual Mechanistic Analysis](https://arxiv.org/abs/2509.02075)
*Elisabetta Rocchetti,Alfio Ferrara*

Main category: cs.CL

TL;DR: 指令微调显著提升大语言模型在英语和意大利语中的长度控制能力，主要通过深层网络组件的专业化实现，不同语言采用不同的补偿机制。


<details>
  <summary>Details</summary>
Motivation: 研究大语言模型在精确字数控制文本生成方面的挑战，比较基础模型和指令微调模型在英语和意大利语中的表现差异。

Method: 使用累积加权归因（源自直接对数归因）分析模型性能和内部组件贡献，重点关注不同层级的注意力头和MLP组件。

Result: 指令微调大幅改善长度控制，英语中深层注意力头贡献显著增加，意大利语中最终层MLP发挥更强补偿作用。

Conclusion: 指令微调重新配置深层网络以实现任务遵循，组件级策略可能根据语言上下文进行适应性调整。

Abstract: Adhering to explicit length constraints, such as generating text with a
precise word count, remains a significant challenge for Large Language Models
(LLMs). This study aims at investigating the differences between foundation
models and their instruction-tuned counterparts, on length-controlled text
generation in English and Italian. We analyze both performance and internal
component contributions using Cumulative Weighted Attribution, a metric derived
from Direct Logit Attribution. Our findings reveal that instruction-tuning
substantially improves length control, primarily by specializing components in
deeper model layers. Specifically, attention heads in later layers of IT models
show increasingly positive contributions, particularly in English. In Italian,
while attention contributions are more attenuated, final-layer MLPs exhibit a
stronger positive role, suggesting a compensatory mechanism. These results
indicate that instruction-tuning reconfigures later layers for task adherence,
with component-level strategies potentially adapting to linguistic context.

</details>


### [112] [Better by Comparison: Retrieval-Augmented Contrastive Reasoning for Automatic Prompt Optimization](https://arxiv.org/abs/2509.02093)
*Juhyeon Lee,Wonduk Seo,Hyunjin An,Seunghyun Lee,Yi Bu*

Main category: cs.CL

TL;DR: CRPO是一个新颖的提示优化框架，通过检索对比优质和劣质提示样例，利用LLM的推理能力进行分层和多维度的对比分析，显著提升提示质量。


<details>
  <summary>Details</summary>
Motivation: 现有提示优化方法主要关注直接提示精炼或模型微调，忽视了利用LLM固有推理能力从对比样例中学习的机会。

Method: 从HelpSteer2数据集中检索top k参考提示，构建两种优化范式：分层对比推理（比较高、中、低质量提示）和多维度对比推理（分析各评估维度的最佳提示并整合优势）。

Result: 在HelpSteer2基准测试中，CRPO显著优于基线方法。

Conclusion: 对比性、检索增强的推理方法在自动提示优化方面具有巨大潜力，能够实现更鲁棒和可解释的优化。

Abstract: Automatic prompt optimization has recently emerged as a strategy for
improving the quality of prompts used in Large Language Models (LLMs), with the
goal of generating more accurate and useful responses. However, most prior work
focuses on direct prompt refinement or model fine-tuning, overlooking the
potential of leveraging LLMs' inherent reasoning capability to learn from
contrasting examples. In this paper, we present Contrastive Reasoning Prompt
Optimization (CRPO), a novel framework that formulates prompt optimization as a
retrieval augmented reasoning process. Our approach retrieves top k reference
prompts from the HelpSteer2 dataset, an open-source collection annotated for
helpfulness, correctness, coherence, complexity, and verbosity, and constructs
two complementary optimization paradigms: (1) tiered contrastive reasoning,
where the LLM compares high, medium, and low quality prompts to refine its own
generation through reflective reasoning, and (2) multi-metric contrastive
reasoning, where the LLM analyzes the best prompts along each evaluation
dimension and integrates their strengths into an optimized prompt. By
explicitly contrasting high and low quality exemplars, CRPO enables the model
to deduce why certain prompts succeed while others fail, thereby achieving more
robust and interpretable optimization. Experimental results on the HelpSteer2
benchmark demonstrate that CRPO significantly outperforms baselines. Our
findings highlight the promise of contrastive, retrieval-augmented reasoning
for advancing automatic prompt optimization.

</details>


### [113] [JudgeAgent: Dynamically Evaluate LLMs with Agent-as-Interviewer](https://arxiv.org/abs/2509.02097)
*Zhichao Shi,Xuhui Jiang,Chengjin Xu,Cangli Yao,Zhenxin Huang,Shengjie Ma,Yinghan Shen,Yuanzhuo Wang*

Main category: cs.CL

TL;DR: JudgeAgent是一个基于面试官式评估范式的知识目标自适应动态评估框架，通过基准评分、交互扩展和评估反馈的综合方法，解决传统LLM评估中的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM评估范式存在与目标交互有限、难度控制不足、评估结果有效性验证困难等问题，难以精确确定目标模型的知识和能力边界。

Method: 采用知识驱动的数据合成和目标自适应难度调整方法，通过基准评分、交互扩展和评估反馈三个步骤进行扩展测试。

Result: 通过大量实验证明了JudgeAgent及其动态评估范式的有效性，提供了准确有效的评估结果。

Conclusion: JudgeAgent框架能够更精确地评估LLM的知识和能力边界，为LLM评估提供了新的有效方法。

Abstract: Evaluating the capabilities of large language models (LLMs) is an essential
step to ensure the successful application of LLMs across various domains. The
current evaluation of LLMs is based on a paradigm that involves querying them
with predefined question sets and assessing their outputs. This paradigm offers
controllable processes and simplicity, but faces challenges such as limited
interaction with targets, insufficient difficulty control, and difficulties in
verifying the validity of evaluation results, making it hard to precisely
determine the knowledge and capability boundaries of target models. To address
these challenges, we propose JudgeAgent, a knowledge-target adaptive dynamic
evaluation framework based on a new interviewer-style evaluation paradigm.
JudgeAgent employs a comprehensive evaluation approach consisting of benchmark
grading, interactive extension, and evaluation feedback. It utilizes
knowledge-driven data synthesis and target-adaptive difficulty adjustment
methods to conduct extended testing, providing accurate and effective
evaluation results. We also introduce a novel insight into validating
evaluation methods, demonstrating the effectiveness of JudgeAgent and its
dynamic evaluation paradigm through extensive experiments.

</details>


### [114] [CMRAG: Co-modality-based document retrieval and visual question answering](https://arxiv.org/abs/2509.02123)
*Wang Chen,Guanqiang Qi,Weikang Li,Yang Li*

Main category: cs.CL

TL;DR: 本文提出了共模态检索增强生成(CMRAG)方法，通过同时利用文本和图像信息来改进多模态文档问答任务，显著优于纯视觉方法。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法在处理多模态文档时存在局限：基于布局分析和文本提取的方法无法处理图像内容，而纯视觉方法忽略了文本的语义优势，导致生成结果不理想。

Method: 首先对文档进行结构化解析获得文本片段和图像区域的共模态表示；然后分别从文本和图像通道检索候选证据，在跨模态检索层面聚合结果；最后提示视觉语言模型基于共模态检索结果生成最终响应。

Result: 实验表明该方法在视觉文档问答任务中显著优于纯视觉RAG方法。

Conclusion: 以统一方式将共模态信息整合到RAG框架中是提高复杂文档视觉问答系统性能的有效途径。

Abstract: Retrieval-Augmented Generation (RAG) has become a core paradigm in document
question answering tasks. However, existing methods have limitations when
dealing with multimodal documents: one category of methods relies on layout
analysis and text extraction, which can only utilize explicit text information
and struggle to capture images or unstructured content; the other category
treats document segmentation as visual input and directly passes it to visual
language models (VLMs) for processing, yet it ignores the semantic advantages
of text, leading to suboptimal generation results. This paper proposes
co-modality-based RAG (CMRAG), which can simultaneously leverage text and
images for efficient retrieval and generation. Specifically, we first perform
structured parsing on documents to obtain co-modality representations of text
segments and image regions. Subsequently, in response to user queries, we
retrieve candidate evidence from text and image channels, respectively, and
aggregate the results at the cross-modal retrieval level. Finally, we prompt
the VLM to generate the final response based on the co-modality retrieval
results. Experiments demonstrate that our method significantly outperforms
pure-vision-based RAG in visual document question answering tasks. The findings
of this paper show that integrating co-modality information into the RAG
framework in a unified manner is an effective approach to improving the
performance of complex document visual question-answering (VQA) systems.

</details>


### [115] [AMBEDKAR-A Multi-level Bias Elimination through a Decoding Approach with Knowledge Augmentation for Robust Constitutional Alignment of Language Models](https://arxiv.org/abs/2509.02133)
*Snehasis Mukhopadhyay,Aryan Kasat,Shivam Dubey,Rahul Karthikeyan,Dhruv Sood,Vinija Jain,Aman Chadha,Amitava Das*

Main category: cs.CL

TL;DR: 提出了AMBEDKAR框架，通过宪法感知解码层和推测解码算法，在不修改基础模型参数的情况下，有效减少LLM在种姓和宗教方面的偏见，偏差绝对减少达26.41%。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型可能反映训练数据中的社会偏见，特别是在印度语境下，种姓和宗教偏见尤为突出。现有缓解策略多为西方中心主义，无法解决本地化细微差别。

Method: 基于印度宪法第14-17条的平等愿景，设计宪法感知解码层，在推理时应用而不更新模型参数。采用推测解码算法，让小型语言模型作为潜在偏见生成器，大型语言模型作为宪法指导的验证器来强制执行无偏见轨迹。

Result: 相比基线，该方法实现了高达26.41%的偏见绝对减少。

Conclusion: AMBEDKAR框架成功将推测解码重新解释为公平性机制而非效率工具，提供了一种计算成本低、无需重新训练的偏见缓解方案，特别适用于印度语境下的种姓和宗教偏见问题。

Abstract: Large Language Models (LLMs) can inadvertently reflect societal biases
present in their training data, leading to harmful or prejudiced outputs. In
the Indian context, our empirical evaluations across a suite of models reveal
that biases around caste and religion are particularly salient. Yet, most
existing mitigation strategies are Western-centric and fail to address these
local nuances. We propose AMBEDKAR, a framework inspired by the egalitarian
vision of Dr B. R. Ambedkar, architect of the Indian Constitution, to guide LLM
outputs toward fairness, neutrality, and inclusion in line with Articles 14 to
17. Our approach introduces a Constitution-Aware Decoding Layer, guided by the
AI Constitution of India and applied only at inference time, without any
parameter updates to the base model. We incorporate a speculative decoding
algorithm that proactively reduces casteist and communal bias during
generation. This mitigation layer operates directly within the decoding
process, avoiding changes to model internals and lowering the computational and
infrastructural costs associated with retraining. We reinterpret speculative
decoding not merely as an efficiency tool but as a mechanism for fairness. In
this framework, a Small Language Model (SLM) acts as a potentially biased
generator, while a constitutionally guided Large Language Model (LLM) serves as
the verifier. Rather than accelerating generation, the LLM enforces bias-robust
trajectories in the SLM outputs. This inversion of roles gives rise to a
fairness-by-speculation paradigm. Our approach yields an absolute reduction of
bias up to 26.41 percent compared to baseline. Our source code, datasets, and
results are available at https://anonymous.4open.science/r/AMBEDKAR-983B/

</details>


### [116] [Meta-Pretraining for Zero-Shot Cross-Lingual Named Entity Recognition in Low-Resource Philippine Languages](https://arxiv.org/abs/2509.02160)
*David Demitri Africa,Suchir Salhan,Yuval Weiss,Paula Buttery,Richard Diehl Martinez*

Main category: cs.CL

TL;DR: 该论文研究如何通过元学习提升小规模解码器语言模型在低资源语言命名实体识别任务中的零样本迁移能力，特别是在内存或延迟受限的环境中。


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言NER任务通常需要微调大型多语言模型，但在内存或延迟受限的环境中不可行。研究小规模解码器LM是否可以通过预训练实现快速适应和零样本迁移到未见语言。

Method: 使用一阶模型无关元学习（MAML）替换部分自回归目标进行预训练，在塔加洛语和宿务语上进行测试，这两种语言类型相似但在结构上存在差异。

Result: 在四种模型规模（11M-570M）下，MAML使零样本micro-F1在仅头部调优时提升2-6个百分点，全调优后提升1-3个百分点，同时收敛时间减少高达8%。

Conclusion: 元学习能有效提升小模型在低资源语言NER任务中的性能，特别是对于与表层锚点（如塔加洛语格助词si/ni）共现的单标记人名实体效果最显著。

Abstract: Named-entity recognition (NER) in low-resource languages is usually tackled
by finetuning very large multilingual LMs, an option that is often infeasible
in memory- or latency-constrained settings. We ask whether small decoder LMs
can be pretrained so that they adapt quickly and transfer zero-shot to
languages unseen during pretraining. To this end we replace part of the
autoregressive objective with first-order model-agnostic meta-learning (MAML).
Tagalog and Cebuano are typologically similar yet structurally different in
their actor/non-actor voice systems, and hence serve as a challenging test-bed.
Across four model sizes (11 M - 570 M) MAML lifts zero-shot micro-F1 by 2-6 pp
under head-only tuning and 1-3 pp after full tuning, while cutting convergence
time by up to 8%. Gains are largest for single-token person entities that
co-occur with Tagalog case particles si/ni, highlighting the importance of
surface anchors.

</details>


### [117] [Avoidance Decoding for Diverse Multi-Branch Story Generation](https://arxiv.org/abs/2509.02170)
*Kyeongman Park,Nakyeong Yang,Kyomin Jung*

Main category: cs.CL

TL;DR: 提出Avoidance Decoding解码策略，通过惩罚与先前生成内容的相似性来提高LLM输出的多样性，减少重复性


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在相同输入提示下生成重复和单调输出的问题，特别是在故事生成任务中缺乏创意多样性的挑战

Method: Avoidance Decoding解码策略，通过修改token logits来惩罚与先前生成输出的相似性。采用自适应平衡的两种相似性度量：早期优先概念级相似性惩罚以多样化初始故事概念，后期逐渐强调叙事级相似性惩罚以确保自然且多样化的情节发展

Result: 相比强基线方法，输出多样性提高了2.6倍，重复性平均减少30%，同时有效缓解文本退化问题。方法激活了更广泛的神经元，证明其利用了模型的内在创造力

Conclusion: Avoidance Decoding是一种有效的解码策略，能够显著提升LLM生成内容的多样性，减少重复，同时保持文本质量，为提升语言模型创造力提供了新思路

Abstract: Large Language Models (LLMs) often generate repetitive and monotonous
outputs, especially in tasks like story generation, due to limited creative
diversity when given the same input prompt. To address this challenge, we
propose a novel decoding strategy, Avoidance Decoding, that modifies token
logits by penalizing similarity to previously generated outputs, thereby
encouraging more diverse multi-branch stories. This penalty adaptively balances
two similarity measures: (1) Concept-level Similarity Penalty, which is
prioritized in early stages to diversify initial story concepts, and (2)
Narrative-level Similarity Penalty, which is increasingly emphasized later to
ensure natural yet diverse plot development. Notably, our method achieves up to
2.6 times higher output diversity and reduces repetition by an average of 30%
compared to strong baselines, while effectively mitigating text degeneration.
Furthermore, we reveal that our method activates a broader range of neurons,
demonstrating that it leverages the model's intrinsic creativity.

</details>


### [118] [FActBench: A Benchmark for Fine-grained Automatic Evaluation of LLM-Generated Text in the Medical Domain](https://arxiv.org/abs/2509.02198)
*Anum Afzal,Juraj Vladika,Florian Matthes*

Main category: cs.CL

TL;DR: 提出了医学领域的综合事实核查基准FActBench，涵盖4个生成任务和6个LLM，使用CoT和NLI两种技术进行事实核查，发现两种技术的一致投票结果与专家评估最相关


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在专业领域表现不佳，事实性是关键评估指标，需要可靠的事实核查工具和数据源来解决幻觉问题

Method: 构建医学领域事实核查基准FActBench，包含4个生成任务和6个LLM，采用Chain-of-Thought提示和自然语言推理两种先进事实核查技术

Result: 实验表明，通过两种事实核查技术的一致投票获得的事实核查分数与领域专家评估结果相关性最好

Conclusion: 一致投票机制可以有效地评估LLM在医学领域的事实准确性，为幻觉缓解提供了可靠的方法

Abstract: Large Language Models tend to struggle when dealing with specialized domains.
While all aspects of evaluation hold importance, factuality is the most
critical one. Similarly, reliable fact-checking tools and data sources are
essential for hallucination mitigation. We address these issues by providing a
comprehensive Fact-checking Benchmark FActBench covering four generation tasks
and six state-of-the-art Large Language Models (LLMs) for the Medical domain.
We use two state-of-the-art Fact-checking techniques: Chain-of-Thought (CoT)
Prompting and Natural Language Inference (NLI). Our experiments show that the
fact-checking scores acquired through the Unanimous Voting of both techniques
correlate best with Domain Expert Evaluation.

</details>


### [119] [Towards Fundamental Language Models: Does Linguistic Competence Scale with Model Size?](https://arxiv.org/abs/2509.02225)
*Jaime Collado-Montañez,L. Alfonso Ureña-López,Arturo Montejo-Ráez*

Main category: cs.CL

TL;DR: 大语言模型存在幻觉、偏见等问题，本文提出基础语言模型（FLM）范式，使用小型语言模型配合外部工具检索事实，实验证明模型规模更关联记忆而非语言能力。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型的幻觉、偏见、隐私和计算成本问题，这些问题的根源在于单一模型同时承担语言能力和事实记忆功能。

Method: 提出FLM范式，使用小型语言模型专注于语言能力，将事实检索卸载到外部工具。评估135M到32B参数模型的语言能力、外部事实知识和内部事实知识。

Result: 发现语言能力和事实知识都随规模增长，但内部事实知识增长更快，表明模型规模更关联记忆能力而非核心语言能力。

Conclusion: 支持模块化语言建模方法，使用紧凑的语言模型作为工具增强系统的基础，提供更高效、可解释和可持续的NLP解决方案。

Abstract: Large Language Models offer impressive language capabilities but suffer from
well-known limitations, including hallucinations, biases, privacy concerns, and
high computational costs. These issues are largely driven by the combination of
linguistic competence and factual memorization within a single monolithic
model. This paper introduces and empirically supports the Fundamental Language
Model (FLM) paradigm, which advocates for smaller, linguistically competent
models that offload factual retrieval to external tools. We evaluate models
ranging from 135M to 32B parameters across three dimensions: linguistic
competence, external factual knowledge, and internal factual knowledge. Our
findings reveal that while both linguistic competence and factual knowledge
improve with scale, internal factual knowledge grows significantly faster,
suggesting that model size is more closely tied to memorization than to core
language ability. These results support a modular approach to language
modeling, where compact, linguistically proficient models serve as the
foundation for tool-augmented systems. The FLM paradigm offers a path toward
more efficient, interpretable, and sustainable NLP solutions.

</details>


### [120] [LLMs and their Limited Theory of Mind: Evaluating Mental State Annotations in Situated Dialogue](https://arxiv.org/abs/2509.02292)
*Katharine Kowalyshyn,Matthias Scheutz*

Main category: cs.CL

TL;DR: 利用大语言模型分析团队对话中的共享心智模型，通过两步框架：首先生成注释识别SMM元素，然后检测个体心智状态差异，发现LLM在空间推理和语音线索消歧方面存在系统性错误


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型是否能不仅推断人类心态，还能揭示团队对话中的盲点，特别是团队成员在共同理解上的差异

Method: 提出两步框架：1) LLM作为人类风格注释器识别团队对话中的共享心智模型元素；2) 另一个LLM比较LLM生成注释与人工注释，检测和描述差异

Result: 创建了包含人类和LLM注释的数据集，建立了可复现的SMM一致性评估框架，发现LLM在简单自然语言注释任务中表现一致，但在需要空间推理或语音线索消歧的场景中系统性地出错

Conclusion: 虽然大语言模型在简单注释任务中表现出明显的一致性，但在复杂推理场景中存在局限性，特别是在空间推理和语音线索处理方面

Abstract: What if large language models could not only infer human mindsets but also
expose every blind spot in team dialogue such as discrepancies in the team
members' joint understanding? We present a novel, two-step framework that
leverages large language models (LLMs) both as human-style annotators of team
dialogues to track the team's shared mental models (SMMs) and as automated
discrepancy detectors among individuals' mental states. In the first step, an
LLM generates annotations by identifying SMM elements within task-oriented
dialogues from the Cooperative Remote Search Task (CReST) corpus. Then, a
secondary LLM compares these LLM-derived annotations and human annotations
against gold-standard labels to detect and characterize divergences. We define
an SMM coherence evaluation framework for this use case and apply it to six
CReST dialogues, ultimately producing: (1) a dataset of human and LLM
annotations; (2) a reproducible evaluation framework for SMM coherence; and (3)
an empirical assessment of LLM-based discrepancy detection. Our results reveal
that, although LLMs exhibit apparent coherence on straightforward
natural-language annotation tasks, they systematically err in scenarios
requiring spatial reasoning or disambiguation of prosodic cues.

</details>


### [121] [DCPO: Dynamic Clipping Policy Optimization](https://arxiv.org/abs/2509.02333)
*Shihui Yang,Chengfeng Dou,Peidong Guo,Kai Lu,Qiang Ju,Fei Deng,Rihui Xin*

Main category: cs.CL

TL;DR: DCPO提出动态裁剪策略和平滑优势标准化技术，解决RLVR中梯度消失问题，在多个基准测试中达到最先进性能


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法如GRPO存在梯度消失问题，主要由于固定的token级概率比裁剪边界和相同奖励的标准化，导致梯度更新无效和生成响应利用不足

Method: DCPO引入动态裁剪策略（基于token特定先验概率自适应调整裁剪边界以增强token级探索）和平滑优势标准化技术（在累积训练步骤中标准化奖励以提高响应级利用效率）

Result: 在四个基准测试中达到SOTA性能：AIME24上Avg@1 46.7，Avg@32 38.8；AIME25上23.3/19.0；相比GRPO非零优势平均提升28%，训练效率比DAPO翻倍，token裁剪比大幅降低一个数量级

Conclusion: DCPO能更有效地利用生成数据进行大语言模型的强化学习，在提升推理能力方面表现出显著优势

Abstract: Reinforcement Learning from Verifiable Rewards (RLVR) has emerged as a
promising framework for enhancing the reasoning capabilities of large language
models. However, existing approaches such as GRPO often suffer from zero
gradients. This problem arises primarily due to fixed clipping bounds for
token-level probability ratios and the standardization of identical rewards,
which can lead to ineffective gradient updates and underutilization of
generated responses. In this work, we propose Dynamic Clipping Policy
Optimization (DCPO), which introduces a dynamic clipping strategy that
adaptively adjusts the clipping bounds based on token-specific prior
probabilities to enhance token-level exploration, and a smooth advantage
standardization technique that standardizes rewards across cumulative training
steps to improve the response-level effective utilization of generated
responses. DCPO achieved state-of-the-art performance on four benchmarks based
on four different models. In particular, DCPO achieved an Avg@1 of 46.7 under
greedy decoding and an Avg@32 of 38.8 under 32 times sampling on the AIME24
benchmark, surpassing both DAPO (36.7/31.6) and GRPO (36.7/32.1) on the
Qwen2.5-Math-7B model. On the AIME25 benchmark based on Qwen2.5-14B, DCPO
achieves a performance of (23.3/19.0), surpassing GRPO (13.3/10.5) and DAPO
(20.0/15.3). Furthermore, DCPO achieved an average 28% improvement in the
nonzero advantage over GRPO in four models, doubled the training efficiency
over DAPO, and significantly reduced the token clipping ratio by an order of
magnitude compared to both GRPO and DAPO, while achieving superior performance.
These results highlight DCPO's effectiveness in leveraging generated data more
efficiently for reinforcement learning in large language models.

</details>


### [122] [Implicit Reasoning in Large Language Models: A Comprehensive Survey](https://arxiv.org/abs/2509.02350)
*Jindong Li,Yali Fu,Li Fan,Jiahong Liu,Yao Shu,Chengwei Qin,Menglin Yang,Irwin King,Rex Ying*

Main category: cs.CL

TL;DR: 本综述论文系统梳理了大语言模型中的隐式推理方法，提出了基于计算策略的分类法，将现有方法分为潜在优化、信号引导控制和层循环执行三种执行范式，并提供了评估指标和基准的综述。


<details>
  <summary>Details</summary>
Motivation: 现有研究虽然讨论了推理中的潜在表示，但缺乏对LLM内部推理机制的系统性分析。隐式推理具有生成成本低、推理速度快、与内部计算更好对齐等优势，需要专门的机制层面研究。

Method: 提出了以执行范式为中心的分类法，将现有隐式推理方法组织为三类：潜在优化、信号引导控制和层循环执行。同时综述了支持隐式推理存在的结构、行为和表示证据，以及评估指标和基准。

Result: 建立了系统的隐式推理分类框架，为理解LLM内部推理机制提供了新的视角。维护了持续更新的项目资源库。

Conclusion: 该综述填补了LLM隐式推理机制层面研究的空白，为未来隐式推理方法的发展提供了理论基础和分类框架，有助于推动更高效、可靠的推理系统开发。

Abstract: Large Language Models (LLMs) have demonstrated strong generalization across a
wide range of tasks. Reasoning with LLMs is central to solving multi-step
problems and complex decision-making. To support efficient reasoning, recent
studies have shifted attention from explicit chain-of-thought prompting toward
implicit reasoning, where reasoning occurs silently via latent structures
without emitting intermediate textual steps. Implicit reasoning brings
advantages such as lower generation cost, faster inference, and better
alignment with internal computation. Although prior surveys have discussed
latent representations in the context of reasoning, a dedicated and
mechanism-level examination of how reasoning unfolds internally within LLMs
remains absent. This survey fills that gap by introducing a taxonomy centered
on execution paradigms, shifting the focus from representational forms to
computational strategies. We organize existing methods into three execution
paradigms based on \textbf{\textit{how and where internal computation
unfolds}}: latent optimization, signal-guided control, and layer-recurrent
execution. We also review structural, behavioral and representation-based
evidence that supports the presence of implicit reasoning in LLMs. We further
provide a structured overview of the evaluation metrics and benchmarks used in
existing works to assess the effectiveness and reliability of implicit
reasoning. We maintain a continuously updated project at:
https://github.com/digailab/awesome-llm-implicit-reasoning.

</details>


### [123] [Towards Temporal Knowledge-Base Creation for Fine-Grained Opinion Analysis with Language Models](https://arxiv.org/abs/2509.02363)
*Gaurav Negi,Atul Kr. Ojha,Omnia Zayed,Paul Buitelaar*

Main category: cs.CL

TL;DR: 使用大语言模型构建时序意见知识库的可扩展方法，通过声明式注释流水线自动提取结构化意见信息


<details>
  <summary>Details</summary>
Motivation: 现有方法在时间序列意见分析方面潜力不足，缺乏时态基础的细粒度注释，影响预测和趋势分析等下游应用的效果

Method: 集成成熟的意见挖掘形式到声明式LLM注释流水线中，定义三个基于情感和意见挖掘文献的数据模型作为结构化表示的模板

Result: 使用人工注释测试样本进行严格的定量评估，通过两个独立LLM进行最终注释并计算细粒度意见维度的标签一致性

Conclusion: 构建的知识库包含时间对齐的结构化意见信息，可以应用于检索增强生成、时态问答和时间线摘要等场景

Abstract: We propose a scalable method for constructing a temporal opinion knowledge
base with large language models (LLMs) as automated annotators. Despite the
demonstrated utility of time-series opinion analysis of text for downstream
applications such as forecasting and trend analysis, existing methodologies
underexploit this potential due to the absence of temporally grounded
fine-grained annotations. Our approach addresses this gap by integrating
well-established opinion mining formulations into a declarative LLM annotation
pipeline, enabling structured opinion extraction without manual prompt
engineering. We define three data models grounded in sentiment and opinion
mining literature, serving as schemas for structured representation. We perform
rigorous quantitative evaluation of our pipeline using human-annotated test
samples. We carry out the final annotations using two separate LLMs, and
inter-annotator agreement is computed label-wise across the fine-grained
opinion dimensions, analogous to human annotation protocols. The resulting
knowledge base encapsulates time-aligned, structured opinions and is compatible
with applications in Retrieval-Augmented Generation (RAG), temporal question
answering, and timeline summarisation.

</details>


### [124] [An Ensemble Classification Approach in A Multi-Layered Large Language Model Framework for Disease Prediction](https://arxiv.org/abs/2509.02446)
*Ali Hamdi,Malak Mohamed,Rokaia Emad,Khaled Shaban*

Main category: cs.CL

TL;DR: 该研究评估了三种阿拉伯语医疗文本预处理方法（摘要、精炼和命名实体识别），结合微调的阿拉伯语Transformer模型和多数投票集成方法，在阿拉伯语社交远程医疗数据上实现了80.56%的最佳疾病分类准确率。


<details>
  <summary>Details</summary>
Motivation: 社交远程医疗平台积累了大量的阿拉伯语医疗文本数据，需要有效的方法来处理这些复杂医疗文本并进行疾病分类。现有的大型语言模型和Transformer模型在医疗文本处理方面表现出强大能力，但针对阿拉伯语医疗文本的预处理和集成方法研究不足。

Method: 使用三种预处理方法（摘要、精炼、NER）处理阿拉伯语医疗文本，然后应用微调的阿拉伯语Transformer模型（CAMeLBERT、AraBERT、AsafayaBERT），最后采用多数投票集成策略结合原始文本和预处理文本的预测结果。

Result: 该方法在阿拉伯语社交远程医疗数据上实现了80.56%的疾病分类准确率，证明了集成多种文本表示和模型预测的有效性。

Conclusion: 这是首个将LLM预处理、微调阿拉伯语Transformer模型和集成学习相结合用于阿拉伯语社交远程医疗疾病分类的研究，展示了该方法在提升医疗文本理解方面的有效性。

Abstract: Social telehealth has made remarkable progress in healthcare by allowing
patients to post symptoms and participate in medical consultations remotely.
Users frequently post symptoms on social media and online health platforms,
creating a huge repository of medical data that can be leveraged for disease
classification. Large language models (LLMs) such as LLAMA3 and GPT-3.5, along
with transformer-based models like BERT, have demonstrated strong capabilities
in processing complex medical text. In this study, we evaluate three Arabic
medical text preprocessing methods such as summarization, refinement, and Named
Entity Recognition (NER) before applying fine-tuned Arabic transformer models
(CAMeLBERT, AraBERT, and AsafayaBERT). To enhance robustness, we adopt a
majority voting ensemble that combines predictions from original and
preprocessed text representations. This approach achieved the best
classification accuracy of 80.56%, thus showing its effectiveness in leveraging
various text representations and model predictions to improve the understanding
of medical texts. To the best of our knowledge, this is the first work that
integrates LLM-based preprocessing with fine-tuned Arabic transformer models
and ensemble learning for disease classification in Arabic social telehealth
data.

</details>


### [125] [EmoPerso: Enhancing Personality Detection with Self-Supervised Emotion-Aware Modelling](https://arxiv.org/abs/2509.02450)
*Lingzhi Shen,Xiaohao Cai,Yunfei Long,Imran Razzak,Guanming Chen,Shoaib Jameel*

Main category: cs.CL

TL;DR: EmoPerso是一个自监督框架，通过情感感知建模改进人格检测，利用生成机制进行数据增强和表示学习，通过多任务学习和交叉注意力模块捕捉人格特质与情感特征的交互。


<details>
  <summary>Details</summary>
Motivation: 现有的人格检测方法严重依赖大规模标注数据集，难以获得高质量人格标签，且大多将情感和人格视为独立变量，忽略了它们的交互作用。

Method: 提出EmoPerso框架：1）利用生成机制进行合成数据增强和丰富表示学习；2）提取伪标签情感特征并通过多任务学习与人格预测联合优化；3）使用交叉注意力模块捕捉人格特质与情感表征的细粒度交互；4）采用自学习策略迭代增强模型推理能力。

Result: 在两个基准数据集上的大量实验表明，EmoPerso超越了最先进的模型。

Conclusion: EmoPerso通过情感感知建模有效提升了人格检测性能，证明了情感与人格交互建模的重要性，为减少对标注数据依赖提供了有效解决方案。

Abstract: Personality detection from text is commonly performed by analysing users'
social media posts. However, existing methods heavily rely on large-scale
annotated datasets, making it challenging to obtain high-quality personality
labels. Moreover, most studies treat emotion and personality as independent
variables, overlooking their interactions. In this paper, we propose a novel
self-supervised framework, EmoPerso, which improves personality detection
through emotion-aware modelling. EmoPerso first leverages generative mechanisms
for synthetic data augmentation and rich representation learning. It then
extracts pseudo-labeled emotion features and jointly optimizes them with
personality prediction via multi-task learning. A cross-attention module is
employed to capture fine-grained interactions between personality traits and
the inferred emotional representations. To further refine relational reasoning,
EmoPerso adopts a self-taught strategy to enhance the model's reasoning
capabilities iteratively. Extensive experiments on two benchmark datasets
demonstrate that EmoPerso surpasses state-of-the-art models. The source code is
available at https://github.com/slz0925/EmoPerso.

</details>


### [126] [Do LLMs Adhere to Label Definitions? Examining Their Receptivity to External Label Definitions](https://arxiv.org/abs/2509.02452)
*Seyedali Mohammadi,Bhaskara Hanuma Vedula,Hemank Lamba,Edward Raff,Ponnurangam Kumaraguru,Francis Ferraro,Manas Gaur*

Main category: cs.CL

TL;DR: 研究表明LLM在处理外部标签定义时并不总是有效整合，而是经常依赖内部参数化知识，特别是在通用任务中。领域特定任务能从外部定义中获益更多。


<details>
  <summary>Details</summary>
Motivation: 探究LLM是否真正整合外部定义，还是主要依赖其参数化知识来处理任务，以理解外部知识如何与LLM现有能力协同工作。

Method: 在多个解释基准数据集（通用和领域特定）上进行控制实验，使用专家策划、LLM生成、扰动和交换的定义等不同标签定义条件。

Result: 显式标签定义可以提高准确性和可解释性，但LLM对定义的整合既不保证也不一致，模型经常默认使用内部表示，特别是在通用任务中。领域特定任务从显式定义中获益更多。

Conclusion: 需要更深入理解LLM如何处理外部知识与现有能力的关系，外部定义的整合效果取决于任务类型，不能假定LLM会一致地使用外部定义。

Abstract: Do LLMs genuinely incorporate external definitions, or do they primarily rely
on their parametric knowledge? To address these questions, we conduct
controlled experiments across multiple explanation benchmark datasets (general
and domain-specific) and label definition conditions, including expert-curated,
LLM-generated, perturbed, and swapped definitions. Our results reveal that
while explicit label definitions can enhance accuracy and explainability, their
integration into an LLM's task-solving processes is neither guaranteed nor
consistent, suggesting reliance on internalized representations in many cases.
Models often default to their internal representations, particularly in general
tasks, whereas domain-specific tasks benefit more from explicit definitions.
These findings underscore the need for a deeper understanding of how LLMs
process external knowledge alongside their pre-existing capabilities.

</details>


### [127] [SpecEval: Evaluating Model Adherence to Behavior Specifications](https://arxiv.org/abs/2509.02464)
*Ahmed Ahmed,Kevin Klyman,Yi Zeng,Sanmi Koyejo,Percy Liang*

Main category: cs.CL

TL;DR: 基础模型行为审计框架，通过自动化方法检查模型是否遵守发布商指南，发现系统性不一致性问题


<details>
  <summary>Details</summary>
Motivation: 目前OpenAI、Anthropic、Google等公司发布了详细的模型行为指南，但缺乏系统性的审计来确认模型是否真正遵守这些规范

Method: 开发自动化审计框架，通过解析行为声明、生成针对性提示、使用模型作为判断者来检查三方一致性（提供商规范-模型输出-模型判断）

Result: 对16个模型和100+行为声明进行测试，发现系统性不一致性，最高达20%的遵循问题

Conclusion: 基础模型并非始终一致遵守发布商的行为指南，需要更好的监管和审计机制来确保模型行为的可靠性和一致性

Abstract: Companies that develop foundation models publish behavioral guidelines they
pledge their models will follow, but it remains unclear if models actually do
so. While providers such as OpenAI, Anthropic, and Google have published
detailed specifications describing both desired safety constraints and
qualitative traits for their models, there has been no systematic audit of
adherence to these guidelines. We introduce an automated framework that audits
models against their providers specifications by parsing behavioral statements,
generating targeted prompts, and using models to judge adherence. Our central
focus is on three way consistency between a provider specification, its model
outputs, and its own models as judges; an extension of prior two way generator
validator consistency. This establishes a necessary baseline: at minimum, a
foundation model should consistently satisfy the developer behavioral
specifications when judged by the developer evaluator models. We apply our
framework to 16 models from six developers across more than 100 behavioral
statements, finding systematic inconsistencies including compliance gaps of up
to 20 percent across providers.

</details>


### [128] [GRAM-R$^2$: Self-Training Generative Foundation Reward Models for Reward Reasoning](https://arxiv.org/abs/2509.02492)
*Chenglong Wang,Yongyu Mu,Hang Zhou,Yifu Huo,Ziming Zhu,Jiali Zeng,Murun Yang,Bei Li,Tong Xiao,Xiaoyang Hao,Chunliang Zhang,Fandong Meng,Jingbo Zhu*

Main category: cs.CL

TL;DR: 提出GRAM-R²生成式奖励模型，通过自训练方法利用未标注数据生成奖励理由和偏好标签，在多个任务中表现优于现有基准模型


<details>
  <summary>Details</summary>
Motivation: 现有奖励模型严重依赖大规模标注偏好数据，而现有预训练方法无法在奖励模型中注入明确的推理能力

Method: 采用自训练方法利用未标注数据激发奖励推理，开发GRAM-R²生成式奖励模型，同时生成偏好标签和奖励理由

Result: 在响应排序、任务适应和人类反馈强化学习等实验中，GRAM-R²持续表现出强劲性能，超越多个判别式和生成式基线模型

Conclusion: GRAM-R²可作为奖励推理的基础模型，支持下游应用如响应排序和任务特定奖励调优，具有广泛的适用性

Abstract: Significant progress in reward modeling over recent years has been driven by
a paradigm shift from task-specific designs towards generalist reward models.
Despite this trend, developing effective reward models remains a fundamental
challenge: the heavy reliance on large-scale labeled preference data.
Pre-training on abundant unlabeled data offers a promising direction, but
existing approaches fall short of instilling explicit reasoning into reward
models. To bridge this gap, we propose a self-training approach that leverages
unlabeled data to elicit reward reasoning in reward models. Based on this
approach, we develop GRAM-R$^2$, a generative reward model trained to produce
not only preference labels but also accompanying reward rationales. GRAM-R$^2$
can serve as a foundation model for reward reasoning and can be applied to a
wide range of tasks with minimal or no additional fine-tuning. It can support
downstream applications such as response ranking and task-specific reward
tuning. Experiments on response ranking, task adaptation, and reinforcement
learning from human feedback demonstrate that GRAM-R$^2$ consistently delivers
strong performance, outperforming several strong discriminative and generative
baselines.

</details>


### [129] [MoSEs: Uncertainty-Aware AI-Generated Text Detection via Mixture of Stylistics Experts with Conditional Thresholds](https://arxiv.org/abs/2509.02499)
*Junxi Wu,Jinpeng Wang,Zheng Liu,Bin Chen,Dongjian Hu,Hao Wu,Shu-Tao Xiu*

Main category: cs.CL

TL;DR: 提出了MoSEs框架，通过条件阈值估计实现风格感知的不确定性量化，显著提升AI生成文本检测性能


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的快速发展引发了对滥用的担忧，现有方法忽视风格建模且依赖静态阈值，限制了检测性能

Method: MoSEs包含三个核心组件：风格参考库(SRR)、风格感知路由器(SAR)和条件阈值估计器(CTE)，通过动态确定最优阈值进行检测

Result: 相比基线方法平均提升11.34%的检测性能，在低资源情况下提升39.15%

Conclusion: MoSEs框架通过风格感知的阈值估计有效提升了AI生成文本检测的准确性和鲁棒性

Abstract: The rapid advancement of large language models has intensified public
concerns about the potential misuse. Therefore, it is important to build
trustworthy AI-generated text detection systems. Existing methods neglect
stylistic modeling and mostly rely on static thresholds, which greatly limits
the detection performance. In this paper, we propose the Mixture of Stylistic
Experts (MoSEs) framework that enables stylistics-aware uncertainty
quantification through conditional threshold estimation. MoSEs contain three
core components, namely, the Stylistics Reference Repository (SRR), the
Stylistics-Aware Router (SAR), and the Conditional Threshold Estimator (CTE).
For input text, SRR can activate the appropriate reference data in SRR and
provide them to CTE. Subsequently, CTE jointly models the linguistic
statistical properties and semantic features to dynamically determine the
optimal threshold. With a discrimination score, MoSEs yields prediction labels
with the corresponding confidence level. Our framework achieves an average
improvement 11.34% in detection performance compared to baselines. More
inspiringly, MoSEs shows a more evident improvement 39.15% in the low-resource
case. Our code is available at https://github.com/creator-xi/MoSEs.

</details>


### [130] [L3Cube-IndicHeadline-ID: A Dataset for Headline Identification and Semantic Evaluation in Low-Resource Indian Languages](https://arxiv.org/abs/2509.02503)
*Nishant Tanksale,Tanmay Kokate,Darshan Gohad,Sarvadnyaa Barate,Raviraj Joshi*

Main category: cs.CL

TL;DR: 这篇论文提出了L3Cube-IndicHeadline-ID数据集，用于评估印地语言中的语义理解能力，包含10种印地语言的20,000篇新闻文章和四种标题变体，并对多种句子编码器进行了性能分析。


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言中语义评估的挑战，填补印地语言缺乏高质量基准测试集的空白，推动多语言NLP研究发展。

Method: 构建包含10种印地语言的新闻标题识别数据集，每篇文章配备原始标题、语义相似版本、词汇相似版本和无关标题四种选项，使用余弦相似度评估多种句子编码器的性能。

Result: 多语言模型表现稳定且优异，而语言特定模型的效果存在差异，数据集不仅可用于标题识别，还可重用于多选题答题、标题分类等多种NLP任务。

Conclusion: 该数据集为印地语言的语义理解提供了重要的评估工具，将推动低资源语言NLP研究的发展，并为RAG等应用提供价值。

Abstract: Semantic evaluation in low-resource languages remains a major challenge in
NLP. While sentence transformers have shown strong performance in high-resource
settings, their effectiveness in Indic languages is underexplored due to a lack
of high-quality benchmarks. To bridge this gap, we introduce
L3Cube-IndicHeadline-ID, a curated headline identification dataset spanning ten
low-resource Indic languages: Marathi, Hindi, Tamil, Gujarati, Odia, Kannada,
Malayalam, Punjabi, Telugu, Bengali and English. Each language includes 20,000
news articles paired with four headline variants: the original, a semantically
similar version, a lexically similar version, and an unrelated one, designed to
test fine-grained semantic understanding. The task requires selecting the
correct headline from the options using article-headline similarity. We
benchmark several sentence transformers, including multilingual and
language-specific models, using cosine similarity. Results show that
multilingual models consistently perform well, while language-specific models
vary in effectiveness. Given the rising use of similarity models in
Retrieval-Augmented Generation (RAG) pipelines, this dataset also serves as a
valuable resource for evaluating and improving semantic understanding in such
applications. Additionally, the dataset can be repurposed for multiple-choice
question answering, headline classification, or other task-specific evaluations
of LLMs, making it a versatile benchmark for Indic NLP. The dataset is shared
publicly at https://github.com/l3cube-pune/indic-nlp

</details>


### [131] [The Forgotten Code: Validating a Century-Old Translation System with AI](https://arxiv.org/abs/2509.02506)
*Jean-Marie Le Ray*

Main category: cs.CL

TL;DR: 本研究通过AI重新验证了1929年Federico Pucci提出的基于规则机器翻译系统，使用相同方法在94年后重现翻译结果，证明其有效性并扩展到其他语言。


<details>
  <summary>Details</summary>
Motivation: 重新发掘和验证Pucci在1929年提出的机械翻译系统，确认其在机器翻译历史上的先驱地位，并通过现代AI技术展示其方法的有效性。

Method: 使用AI按照Pucci的原始方法重新翻译1931年文献中的两个文本片段（但丁《新生》意大利语-法语和伏尔泰《查第格》法语-意大利语），然后扩展到英语、西班牙语和德语的翻译。

Result: 94年间使用相同方法翻译的文本差异很小，验证了Pucci系统的有效性。AI成功将该方法扩展到其他语言，并能处理更现代和技术性的文本。

Conclusion: Pucci的系统被成功验证，应被视为机器翻译领域的先驱之一，与Troyanskij、Booth和Weaver等人并列，这对重新理解机器翻译历史具有重要意义。

Abstract: A pioneering rule-based mechanical translation system (precursor of modern
RBMTs) was first presented in December 1929 by its inventor, Federico Pucci,
who later published the full method in a book titled "Il traduttore meccanico
ed il metodo per corrispondersi fra Europei conoscendo ciascuno solo la propria
lingua: Parte I", in Salerno (Italy), in 1931. This study illustrates how AI
breathes new life into the system of international keys and ideograms devised
by Pucci to translate from/into any Romance language (at least as a first
step). The methodology involves having the AIs retranslate, following Pucci's
method, the two text excerpts originally translated in 1931 and clearly
documented in his publication: a passage from Dante's La Vita Nuova, translated
from Italian into French, and a passage from Voltaire's Zadig, translated from
French into Italian. The result is notable: the two texts, translated 94 years
apart using the same method--by Pucci in 1931 and by AIs in 2025--show a low
average difference, with only minor variations observed. With Pucci's system
thus validated, it became feasible to have the AIs reproduce the excerpts in
English, Spanish, and German according to his method. The results were
consistent, and Pucci--via Artificial Intelligence--was tasked with translating
more modern and technical texts, thereby reviving, nearly a century later, an
invention that had remained almost entirely unknown and never applied beyond
its creator, now brought to wider attention and opened to possible
experimentation. Such a demonstration would not only affirm Pucci's historical
status but also place him among the precursors and intellectual contributors to
machine translation, whose work merits examination alongside figures such as
Troyanskij, Booth, and Weaver, with possible consequences for how the history
of the field is understood.

</details>


### [132] [Top-H Decoding: Adapting the Creativity and Coherence with Bounded Entropy in Text Generation](https://arxiv.org/abs/2509.02510)
*Erfan Baghaei Potraghloo,Seyedarmin Azizi,Souvik Kundu,Massoud Pedram*

Main category: cs.CL

TL;DR: 提出top-H解码方法，通过熵约束质量最大化解决LLM开放文本生成中多样性与逻辑性的平衡问题，相比min-p采样在创意写作基准上提升25.63%


<details>
  <summary>Details</summary>
Motivation: 现有截断采样技术（如温度缩放、top-p、min-p采样）在有效融入模型置信度方面存在局限，特别是min-p采样仅依赖单个top token作为置信度启发式方法，未能充分利用概率分布信息

Method: 首先建立熵约束最小散度问题的理论框架，证明其等价于NP难的熵约束质量最大化问题，然后提出计算高效的贪心算法top-H解码来解决该问题

Result: 在创意写作基准上比min-p采样提升25.63%，在GPQA、GSM8K和MT-Bench等问答数据集上保持鲁棒性，LLM-as-judge评估确认即使在高温度下也能产生连贯输出

Conclusion: top-H解码推进了开放文本生成的最新技术，可轻松集成到创意写作应用中，在保持逻辑连贯性的同时有效提升生成多样性

Abstract: Large language models (LLMs), despite their impressive performance across a
wide range of tasks, often struggle to balance two competing objectives in
open-ended text generation: fostering diversity and creativity while preserving
logical coherence. Existing truncated sampling techniques, including
temperature scaling, top-\$p\$ (nucleus) sampling, and min-\$p\$ sampling, aim
to manage this trade-off. However, they exhibit limitations, particularly in
the effective incorporation of the confidence of the model into the
corresponding sampling strategy. For example, min-\$p\$ sampling relies on a
single top token as a heuristic for confidence, eventually underutilizing the
information of the probability distribution. Toward effective incorporation of
the confidence of the model, in this paper, we present **top-H** decoding. We
first establish the theoretical foundation of the interplay between creativity
and coherence in truncated sampling by formulating an **entropy-constrained
minimum divergence** problem. We then prove this minimization problem to be
equivalent to an **entropy-constrained mass maximization** (ECMM) problem,
which is NP-hard. Finally, we present top-H decoding, a computationally
efficient greedy algorithm to solve the ECMM problem. Extensive empirical
evaluations demonstrate that top-H outperforms the state-of-the-art (SoTA)
alternative of min-\$p\$ sampling by up to **25.63%** on creative writing
benchmarks, while maintaining robustness on question-answering datasets such as
GPQA, GSM8K, and MT-Bench. Additionally, an *LLM-as-judge* evaluation confirms
that top-H indeed produces coherent outputs even at higher temperatures, where
creativity is especially critical. In summary, top-H advances SoTA in
open-ended text generation and can be *easily integrated* into creative writing
applications. The code is available at
https://github.com/ErfanBaghaei/Top-H-Decoding.

</details>


### [133] [Comparative Study of Pre-Trained BERT and Large Language Models for Code-Mixed Named Entity Recognition](https://arxiv.org/abs/2509.02514)
*Mayur Shirke,Amey Shembade,Pavan Thorat,Madhushri Wagh,Raviraj Joshi*

Main category: cs.CL

TL;DR: 比较代码混合微调模型、非代码混合多语言模型和零样本生成式大语言模型在印地语-英语混合文本命名实体识别任务中的性能，发现代码混合专用模型表现最佳。


<details>
  <summary>Details</summary>
Motivation: 代码混合文本（特别是印地语-英语混合语）的命名实体识别面临非正式结构、音译和频繁语言切换等独特挑战，需要评估不同模型在此任务上的有效性。

Method: 评估了HingBERT、HingMBERT、HingRoBERTa（代码混合数据训练）、BERT Base Cased、IndicBERT、RoBERTa、MuRIL（非代码混合多语言数据训练）以及Google Gemini的零样本性能，使用精确率、召回率和F1分数作为评估指标。

Result: 代码混合模型（特别是HingRoBERTa和HingBERT）表现最佳，超越了包括Google Gemini在内的闭源大语言模型；非代码混合模型表现尚可但适应性有限；Google Gemini在零样本设置下展现出竞争性性能。

Conclusion: 领域特定的预训练对于代码混合NER任务至关重要，专用模型优于通用模型，但现代大语言模型在零样本场景下也展现出强大的泛化能力。

Abstract: Named Entity Recognition (NER) in code-mixed text, particularly Hindi-English
(Hinglish), presents unique challenges due to informal structure,
transliteration, and frequent language switching. This study conducts a
comparative evaluation of code-mixed fine-tuned models and non-code-mixed
multilingual models, along with zero-shot generative large language models
(LLMs). Specifically, we evaluate HingBERT, HingMBERT, and HingRoBERTa (trained
on code-mixed data), and BERT Base Cased, IndicBERT, RoBERTa and MuRIL (trained
on non-code-mixed multilingual data). We also assess the performance of Google
Gemini in a zero-shot setting using a modified version of the dataset with NER
tags removed. All models are tested on a benchmark Hinglish NER dataset using
Precision, Recall, and F1-score. Results show that code-mixed models,
particularly HingRoBERTa and HingBERT-based fine-tuned models, outperform
others - including closed-source LLMs like Google Gemini - due to
domain-specific pretraining. Non-code-mixed models perform reasonably but show
limited adaptability. Notably, Google Gemini exhibits competitive zero-shot
performance, underlining the generalization strength of modern LLMs. This study
provides key insights into the effectiveness of specialized versus generalized
models for code-mixed NER tasks.

</details>


### [134] [Implicit Actor Critic Coupling via a Supervised Learning Framework for RLVR](https://arxiv.org/abs/2509.02522)
*Jiaming Li,Longze Chen,Ze Gong,Yukun Chen,Lu Wang,Wanwei He,Run Luo,Min Yang*

Main category: cs.CL

TL;DR: PACS是一个新的RLVR框架，通过监督学习实现隐式Actor-Critic耦合，将可验证奖励问题转化为监督学习任务，在数学推理任务上表现优于PPO和GRPO等基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有的RLVR方法存在奖励信号稀疏和策略梯度更新不稳定的问题，特别是在基于RL的方法中，需要更稳定高效的训练框架。

Method: 将结果奖励视为可预测标签，将RLVR问题重新表述为对策略模型参数化评分函数的监督学习任务，使用交叉熵损失进行优化，实现隐式Actor-Critic耦合。

Result: 在数学推理任务上，PACS在AIME 2025上达到59.78%的pass@256，比PPO和GRPO分别提升13.32和14.36个百分点。

Conclusion: PACS提供了一个简单而强大的框架，为使用可验证奖励进行LLM后训练提供了有前景的途径。

Abstract: Recent advances in Reinforcement Learning with Verifiable Rewards (RLVR) have
empowered large language models (LLMs) to tackle challenging reasoning tasks
such as mathematics and programming. RLVR leverages verifiable outcome rewards
to guide policy optimization, enabling LLMs to progressively improve output
quality in a grounded and reliable manner. Despite its promise, the RLVR
paradigm poses significant challenges, as existing methods often suffer from
sparse reward signals and unstable policy gradient updates, particularly in
RL-based approaches. To address the challenges, we propose $\textbf{PACS}$, a
novel RLVR framework that achieves im$\textbf{P}$licit $\textbf{A}$ctor
$\textbf{C}$ritic coupling via a $\textbf{S}$upervised learning framework. By
treating the outcome reward as a predictable label, we reformulate the RLVR
problem into a supervised learning task over a score function parameterized by
the policy model and optimized using cross-entropy loss. A detailed gradient
analysis shows that this supervised formulation inherently recovers the
classical policy gradient update while implicitly coupling actor and critic
roles, yielding more stable and efficient training. Benchmarking on challenging
mathematical reasoning tasks, PACS outperforms strong RLVR baselines, such as
PPO and GRPO, achieving superior reasoning performance. For instance, PACS
achieves 59.78\% at pass@256 on AIME 2025, representing improvements of 13.32
and 14.36 points over PPO and GRPO. This simple yet powerful framework offers a
promising avenue for LLMs post-training with verifiable rewards. Our code and
data are available as open source at https://github.com/ritzz-ai/PACS.

</details>


### [135] [Flavors of Moonshine: Tiny Specialized ASR Models for Edge Devices](https://arxiv.org/abs/2509.02523)
*Evan King,Adam Sabra,Manjunath Kudlur,James Wang,Pete Warden*

Main category: cs.CL

TL;DR: 小型单语言ASR模型Flavors of Moonshine在27M参数下表现超过多语言模型，锐减48%错误率，甚至可以比较28倍大的模型


<details>
  <summary>Details</summary>
Motivation: 挖掘小型模型在单语言ASR任务上的潜力，提供更准确的设备端语音识别支持，特别是针对代表性不足的语言

Method: 使用经过精心平衡的高质量数据混合（人工标注数据+伪标签数据+合成数据）训练27M参数的单语言ASR模型

Result: 模型锐减48%的错误率，表现超过9倍大的Whisper Small模型，在大多数情况下可以比较或超过28倍大的Whisper Medium模型

Conclusion: 小型单语言ASR模型通过高质量数据训练可以达到更好性能，为设备端语音识别提供了新的可行方案，特别是针对代表性不足的语言

Abstract: We present the Flavors of Moonshine, a suite of tiny automatic speech
recognition (ASR) models specialized for a range of underrepresented languages.
Prevailing wisdom suggests that multilingual ASR models outperform monolingual
counterparts by exploiting cross-lingual phonetic similarities. We challenge
this assumption, showing that for sufficiently small models (27M parameters),
training monolingual systems on a carefully balanced mix of high-quality
human-labeled, pseudo-labeled, and synthetic data yields substantially superior
performance. On average, our models achieve error rates 48% lower than the
comparably sized Whisper Tiny model, outperform the 9x larger Whisper Small
model, and in most cases match or outperform the 28x larger Whisper Medium
model. These results advance the state of the art for models of this size,
enabling accurate on-device ASR for languages that previously had limited
support. We release Arabic, Chinese, Japanese, Korean, Ukrainian, and
Vietnamese Moonshine models under a permissive open-source license.

</details>


### [136] [Jointly Reinforcing Diversity and Quality in Language Model Generations](https://arxiv.org/abs/2509.02534)
*Tianjian Li,Yiming Zhang,Ping Yu,Swarnadeep Saha,Daniel Khashabi,Jason Weston,Jack Lanchantin,Tianlu Wang*

Main category: cs.CL

TL;DR: DARLING框架通过强化学习同时优化LLM的回答质量和语义多样性，解决了后训练中准确性提升但多样性下降的问题，在创意写作和数学解题等任务中均表现出色。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型后训练往往过度追求准确性和有用性，导致输出分布过于集中，限制了在创意探索任务中的实用性，需要平衡质量与多样性。

Method: 提出多样性感知强化学习(DARLING)框架，使用学习的划分函数测量语义多样性，将多样性信号与质量奖励结合进行在线强化学习。

Result: 在非验证性任务(指令跟随和创意写作)和验证性任务(竞赛数学)中，DARLING均优于仅优化质量的基线方法，产生更高质量和更新颖的输出。

Conclusion: 显式优化多样性能够促进在线强化学习中的探索，从而产生更高质量的响应，证明质量与多样性可以协同优化而非相互冲突。

Abstract: Post-training of Large Language Models (LMs) often prioritizes accuracy and
helpfulness at the expense of diversity. This creates a tension: while
post-training improves response quality, it also sharpens output distributions
and reduces the range of ideas, limiting the usefulness of LMs in creative and
exploratory tasks such as brainstorming, storytelling, or problem solving. We
address this challenge with Diversity-Aware Reinforcement Learning (DARLING), a
framework that jointly optimizes for response quality and semantic diversity.
At its core, DARLING introduces a learned partition function to measure
diversity beyond surface-level lexical variations. This diversity signal is
then combined with a quality reward during online reinforcement learning,
encouraging models to generate outputs that are both high-quality and distinct.
Experiments across multiple model families and sizes show that DARLING
generalizes to two regimes: non-verifiable tasks (instruction following and
creative writing) and verifiable tasks (competition math). On five benchmarks
in the first setting, DARLING consistently outperforms quality-only RL
baselines, producing outputs that are simultaneously of higher quality and
novelty. In the second setting, DARLING achieves higher pass@1 (solution
quality) and pass@k (solution variety). Most strikingly, explicitly optimizing
for diversity catalyzes exploration in online RL, which manifests itself as
higher-quality responses.

</details>


### [137] [PalmX 2025: The First Shared Task on Benchmarking LLMs on Arabic and Islamic Culture](https://arxiv.org/abs/2509.02550)
*Fakhraddin Alwajih,Abdellah El Mekki,Hamdy Mubarak,Majd Hawasly,Abubakr Mohamed,Muhammad Abdul-Mageed*

Main category: cs.CL

TL;DR: PalmX 2025是首个针对LLMs在阿拉伯和伊斯兰文化领域文化能力的基准测试，包含两个多选题子任务，结果显示任务特定微调显著提升性能。


<details>
  <summary>Details</summary>
Motivation: LLMs在预训练阶段主要接触西方高资源语言文化数据，导致对阿拉伯和伊斯兰文化的理解不足，需要专门的基准测试来评估和改进这种文化能力差距。

Method: 设计了两个多选题子任务：通用阿拉伯文化和通用伊斯兰文化，涵盖22个阿拉伯国家的传统、食物、历史、宗教实践和语言表达等广泛主题。

Result: 26个团队注册子任务1，19个注册子任务2，最终分别有9个和6个有效提交。最佳系统在文化问题上达到72.15%准确率，在伊斯兰知识上达到84.22%。参数高效微调是最主要且最有效的方法。

Conclusion: 任务特定微调能显著提升LLMs的文化能力，参数高效微调是主要有效方法，数据增强的效用取决于具体领域。

Abstract: Large Language Models (LLMs) inherently reflect the vast data distributions
they encounter during their pre-training phase. As this data is predominantly
sourced from the web, there is a high chance it will be skewed towards
high-resourced languages and cultures, such as those of the West. Consequently,
LLMs often exhibit a diminished understanding of certain communities, a gap
that is particularly evident in their knowledge of Arabic and Islamic cultures.
This issue becomes even more pronounced with increasingly under-represented
topics. To address this critical challenge, we introduce PalmX 2025, the first
shared task designed to benchmark the cultural competence of LLMs in these
specific domains. The task is composed of two subtasks featuring
multiple-choice questions (MCQs) in Modern Standard Arabic (MSA): General
Arabic Culture and General Islamic Culture. These subtasks cover a wide range
of topics, including traditions, food, history, religious practices, and
language expressions from across 22 Arab countries. The initiative drew
considerable interest, with 26 teams registering for Subtask 1 and 19 for
Subtask 2, culminating in nine and six valid submissions, respectively. Our
findings reveal that task-specific fine-tuning substantially boosts performance
over baseline models. The top-performing systems achieved an accuracy of 72.15%
on cultural questions and 84.22% on Islamic knowledge. Parameter-efficient
fine-tuning emerged as the predominant and most effective approach among
participants, while the utility of data augmentation was found to be
domain-dependent.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [138] [KG-RAG: Enhancing GUI Agent Decision-Making via Knowledge Graph-Driven Retrieval-Augmented Generation](https://arxiv.org/abs/2509.00366)
*Ziyi Guan,Jason Chun Lok Li,Zhijian Hou,Pingping Zhang,Donglai Xu,Yuzhi Zhao,Mengyang Wu,Jinpeng Chen,Thanh-Toan Nguyen,Pengfei Xian,Wenao Ma,Shengchao Qin,Graziano Chesi,Ngai Wong*

Main category: cs.MA

TL;DR: KG-RAG是一个基于知识图谱的检索增强生成框架，通过将碎片化的UI转换图转化为结构化向量数据库，显著提升移动GUI代理在复杂任务中的性能表现。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的GUI代理在复杂移动任务中表现不佳，主要原因是缺乏应用特定知识，且UI转换图(UTG)的提取和集成效率低下。

Method: 提出KG-RAG框架：1) 将碎片化UTG转化为结构化向量数据库；2) 使用意图引导的LLM搜索方法；3) 生成可操作的导航路径来增强代理决策。

Result: 在多个移动应用中，KG-RAG达到75.8%的成功率（比AutoDroid提升8.9%），84.6%的决策准确率（提升8.1%），平均任务步骤从4.5减少到4.1。在Web/桌面端也有显著提升。

Conclusion: KG-RAG有效解决了GUI代理的知识获取和利用问题，UTG成本分析显示复杂应用约需4小时即可达到准确率饱和，具有实际部署价值。同时发布了针对中文移动生态的基准测试集。

Abstract: Despite recent progress, Graphic User Interface (GUI) agents powered by Large
Language Models (LLMs) struggle with complex mobile tasks due to limited
app-specific knowledge. While UI Transition Graphs (UTGs) offer structured
navigation representations, they are underutilized due to poor extraction and
inefficient integration. We introduce KG-RAG, a Knowledge Graph-driven
Retrieval-Augmented Generation framework that transforms fragmented UTGs into
structured vector databases for efficient real-time retrieval. By leveraging an
intent-guided LLM search method, KG-RAG generates actionable navigation paths,
enhancing agent decision-making. Experiments across diverse mobile apps show
that KG-RAG outperforms existing methods, achieving a 75.8% success rate (8.9%
improvement over AutoDroid), 84.6% decision accuracy (8.1% improvement), and
reducing average task steps from 4.5 to 4.1. Additionally, we present
KG-Android-Bench and KG-Harmony-Bench, two benchmarks tailored to the Chinese
mobile ecosystem for future research. Finally, KG-RAG transfers to web/desktop
(+40% SR on Weibo-web; +20% on QQ Music-desktop), and a UTG cost ablation shows
accuracy saturates at ~4h per complex app, enabling practical deployment
trade-offs.

</details>


### [139] [ShortageSim: Simulating Drug Shortages under Information Asymmetry](https://arxiv.org/abs/2509.01813)
*Mingxuan Cui,Yilan Jiang,Duo Zhou,Cheng Qian,Yuji Zhang,Qiong Wang*

Main category: cs.MA

TL;DR: ShortageSim是一个基于LLM的多智能体模拟框架，用于模拟药品短缺情况下制造商、采购方和监管机构之间的复杂战略互动，相比传统模型能更好地反映现实中的信息不对称和有限理性决策。


<details>
  <summary>Details</summary>
Motivation: 药品短缺对患者护理和医疗系统构成严重风险，但由于制药供应链中存在根本性的信息不对称，监管干预的有效性一直难以评估。

Method: 开发了基于大型语言模型的多智能体模拟框架ShortageSim，通过序列化生产游戏模拟FDA公告（反应性短缺警报和前瞻性预警）在供应链中的传播，以及这些信息如何影响产能投资和采购决策。

Result: 在历史短缺事件上的实验表明，ShortageSim将停产披露案例的解决延迟百分比降低了83%，使模拟持续时间更接近真实情况。

Conclusion: ShortageSim为在复杂、信息稀缺的供应链中设计和测试干预措施提供了一个新颖的计算框架，并开源了框架和包含2925个FDA短缺事件的数据集。

Abstract: Drug shortages pose critical risks to patient care and healthcare systems
worldwide, yet the effectiveness of regulatory interventions remains poorly
understood due to fundamental information asymmetries in pharmaceutical supply
chains. We present \textbf{ShortageSim}, the first Large Language Model
(LLM)-based multi-agent simulation framework that captures the complex,
strategic interactions between drug manufacturers, institutional buyers, and
regulatory agencies in response to shortage alerts. Unlike traditional
game-theoretic models that assume perfect rationality and complete information,
\textbf{ShortageSim} leverages LLMs to simulate bounded-rational
decision-making under uncertainty. Through a sequential production game
spanning multiple quarters, we model how FDA announcements, both reactive
alerts about existing shortages and proactive warnings about potential
disruptions, propagate through the supply chain and influence capacity
investment and procurement decisions. Our experiments on historical shortage
events reveal that \textbf{ShortageSim} reduces the resolution-lag percentage
for discontinued-disclosed cases by 83\%, bringing simulated durations more
aligned to ground truth than the zero-shot baseline. We open-source
\textbf{ShortageSim} and a dataset of 2,925 FDA shortage events at
https://github.com/Lemutisme/Sortage_Management, providing a novel
computational framework for designing and testing interventions in complex,
information-scarce supply chains.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [140] [Language and Experience: A Computational Model of Social Learning in Complex Tasks](https://arxiv.org/abs/2509.00074)
*Cédric Colas,Tracey Mills,Ben Prystawski,Michael Henry Tessler,Noah Goodman,Jacob Andreas,Joshua Tenenbaum*

Main category: cs.AI

TL;DR: 该研究提出了一个计算框架，通过将预训练语言模型转化为概率模型，实现社会学习中的语言指导与直接经验整合，在10款视频游戏中验证了语言指导能加速学习和减少风险交互。


<details>
  <summary>Details</summary>
Motivation: 研究人类如何整合他人语言指导与直接经验进行安全快速学习，并探索AI系统如何实现类似的社会学习能力，以促进人机协作学习。

Method: 开发了一个计算框架，将社会学习建模为基于感觉运动和语言数据的结构化可执行世界模型的联合概率推理，将预训练语言模型转化为条件概率模型来生成和解释建议。

Result: 在10款视频游戏的行为实验和模拟中显示，语言指导能塑造探索行为、加速学习、减少风险交互，并通过迭代学习实验展示了跨代知识积累和人机间成功知识传递。

Conclusion: 结构化、语言兼容的表征能够实现人机协作学习，语言指导在社会学习中发挥着重要作用，能够显著提升学习效率和安全性。

Abstract: The ability to combine linguistic guidance from others with direct experience
is central to human development, enabling safe and rapid learning in new
environments. How do people integrate these two sources of knowledge, and how
might AI systems? We present a computational framework that models social
learning as joint probabilistic inference over structured, executable world
models given sensorimotor and linguistic data. We make this possible by turning
a pretrained language model into a probabilistic model of how humans share
advice conditioned on their beliefs, allowing our agents both to generate
advice for others and to interpret linguistic input as evidence during Bayesian
inference. Using behavioral experiments and simulations across 10 video games,
we show how linguistic guidance can shape exploration and accelerate learning
by reducing risky interactions and speeding up key discoveries in both humans
and models. We further explore how knowledge can accumulate across generations
through iterated learning experiments and demonstrate successful knowledge
transfer between humans and models -- revealing how structured,
language-compatible representations might enable human-machine collaborative
learning.

</details>


### [141] [Ensemble Debates with Local Large Language Models for AI Alignment](https://arxiv.org/abs/2509.00091)
*Ephraiem Sarabamoun*

Main category: cs.AI

TL;DR: 本地开源模型集成辩论能显著提升AI对齐能力，在推理深度和论证质量方面分别提升19.4%和34.1%，特别是在真实性和人类增强方面表现最佳


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在重要决策中扮演更重要角色，需要确保其与人类价值观对齐。依赖专有API限制了研究的可复现性和广泛参与

Method: 使用本地开源模型进行集成辩论，在150场辩论中覆盖15个场景和5种集成配置，采用7点评分标准进行评估

Result: 集成方法整体表现优于单模型基线（3.48 vs 3.13分），在真实性方面提升1.25分，人类增强方面提升0.8分

Conclusion: 集成辩论为基于集成的对齐评估提供了可访问且可复现的基础，开源方法能够有效提升AI对齐性能

Abstract: As large language models (LLMs) take on greater roles in high-stakes
decisions, alignment with human values is essential. Reliance on proprietary
APIs limits reproducibility and broad participation. We study whether local
open-source ensemble debates can improve alignmentoriented reasoning. Across
150 debates spanning 15 scenarios and five ensemble configurations, ensembles
outperform single-model baselines on a 7-point rubric (overall: 3.48 vs. 3.13),
with the largest gains in reasoning depth (+19.4%) and argument quality
(+34.1%). Improvements are strongest for truthfulness (+1.25 points) and human
enhancement (+0.80). We provide code, prompts, and a debate data set, providing
an accessible and reproducible foundation for ensemble-based alignment
evaluation.

</details>


### [142] [Adaptive Monitoring and Real-World Evaluation of Agentic AI Systems](https://arxiv.org/abs/2509.00115)
*Manish Shukla*

Main category: cs.AI

TL;DR: 这篇"高级"论文提出了一种适应性多维监控(AMDM)算法，用于监测自主AI系统的异常行为，在模拟和实际实验中显著提高了异常检测的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 当前自主AI系统评估主要依靠技术指标，缺乏人本中心和经济形式的全面评估。前期研究提出了评估框架但缺乏算法实现和实证数据，需要补充这一空白。

Method: 重新审视最新的基准测试和产业部署，形式化适应性多维监控(AMDM)算法，包括异质指标规范化、按轴指数加权移动平均阈值和马哇拉距离联合异常检测。

Result: AMDM算法在模拟实验中将异常检测延迟从12.3秒降至5.6秒，并将误报率从4.5%降至0.9%。提供了对比表、ROC/PR曲线和重新分析案例研究。

Conclusion: 该研究为自主AI系统提供了一种有效的多维监控方案，能够更全面地评估系统性能，为高风险领域的应用提供技术支撑。

Abstract: Agentic artificial intelligence (AI) -- multi-agent systems that combine
large language models with external tools and autonomous planning -- are
rapidly transitioning from research laboratories into high-stakes domains. Our
earlier "Basic" paper introduced a five-axis framework and proposed preliminary
metrics such as goal drift and harm reduction but did not provide an
algorithmic instantiation or empirical evidence. This "Advanced" sequel fills
that gap. First, we revisit recent benchmarks and industrial deployments to
show that technical metrics still dominate evaluations: a systematic review of
84 papers from 2023--2025 found that 83% report capability metrics while only
30% consider human-centred or economic axes [2]. Second, we formalise an
Adaptive Multi-Dimensional Monitoring (AMDM) algorithm that normalises
heterogeneous metrics, applies per-axis exponentially weighted moving-average
thresholds and performs joint anomaly detection via the Mahalanobis distance.
Third, we conduct simulations and real-world experiments. AMDM cuts
anomaly-detection latency from 12.3 s to 5.6 s on simulated goal drift and
reduces false-positive rates from 4.5% to 0.9% compared with static thresholds.
We present a comparison table and ROC/PR curves, and we reanalyse case studies
to surface missing metrics. Code, data and a reproducibility checklist
accompany this paper to facilitate replication.

</details>


### [143] [LLM-Assisted Iterative Evolution with Swarm Intelligence Toward SuperBrain](https://arxiv.org/abs/2509.00510)
*Li Weigang,Pedro Carvalho Brom,Lucas Ramson Siefert*

Main category: cs.AI

TL;DR: SuperBrain框架通过LLM与人类用户的协同进化构建集体智能，包含从子类大脑到超类大脑的动态演化路径，结合遗传算法优化和群体智能协调，最终形成具备抽象、泛化和自改进能力的元智能。


<details>
  <summary>Details</summary>
Motivation: 现有方法如静态提示工程或孤立代理模拟存在局限性，需要一种动态的协同进化框架来实现可扩展、可解释且符合伦理的集体人工智能。

Method: 1) 用户与LLM形成具有自适应学习记忆的认知二元组（子类大脑）；2) 通过遗传算法辅助的前向-后向进化迭代优化提示和任务性能；3) 多个子类大脑通过群体智能协调，在多目标适应度景观中优化并交换启发式知识；4) 标准化行为和认知特征整合为超类大脑。

Result: 提出了理论构建和初步实现（如无人机调度、关键词过滤），并建立了跨二元组知识整合的注册机制。

Conclusion: 该工作为可扩展、可解释且符合伦理的集体AI提供了概念基础和架构路线图。

Abstract: We propose a novel SuperBrain framework for collective intelligence, grounded
in the co-evolution of large language models (LLMs) and human users. Unlike
static prompt engineering or isolated agent simulations, our approach
emphasizes a dynamic pathway from Subclass Brain to Superclass Brain: (1) A
Subclass Brain arises from persistent, personalized interaction between a user
and an LLM, forming a cognitive dyad with adaptive learning memory. (2) Through
GA-assisted forward-backward evolution, these dyads iteratively refine prompts
and task performance. (3) Multiple Subclass Brains coordinate via Swarm
Intelligence, optimizing across multi-objective fitness landscapes and
exchanging distilled heuristics. (4) Their standardized behaviors and cognitive
signatures integrate into a Superclass Brain, an emergent meta-intelligence
capable of abstraction, generalization and self-improvement. We outline the
theoretical constructs, present initial implementations (e.g., UAV scheduling,
KU/KI keyword filtering) and propose a registry for cross-dyad knowledge
consolidation. This work provides both a conceptual foundation and an
architectural roadmap toward scalable, explainable and ethically aligned
collective AI.

</details>


### [144] [On Verifiable Legal Reasoning: A Multi-Agent Framework with Formalized Knowledge Representations](https://arxiv.org/abs/2509.00710)
*Albert Sadowski,Jarosław A. Chudziak*

Main category: cs.AI

TL;DR: 提出模块化多智能体框架，将法律推理分解为知识获取和应用两阶段，显著提升法律AI系统的透明度和准确性


<details>
  <summary>Details</summary>
Motivation: 法律推理需要精确解释法律条文和一致应用复杂规则，这对AI系统构成重大挑战，需要提高透明度和可验证性

Method: 采用模块化多智能体框架：第一阶段通过专门智能体提取法律概念和形式化规则；第二阶段通过查询分析、符号推理和程序化实现三个步骤应用知识到具体案例

Result: 在法定税务计算任务上，基础模型准确率达到76.4%，相比基线18.8%有显著提升，有效缩小了推理模型与基础模型之间的性能差距

Conclusion: 模块化架构和形式化知识表示可以使复杂的法律推理通过计算高效模型实现，同时增强AI法律推理的一致性和可解释性，为未来更透明、可信和有效的法律AI系统奠定基础

Abstract: Legal reasoning requires both precise interpretation of statutory language
and consistent application of complex rules, presenting significant challenges
for AI systems. This paper introduces a modular multi-agent framework that
decomposes legal reasoning into distinct knowledge acquisition and application
stages. In the first stage, specialized agents extract legal concepts and
formalize rules to create verifiable intermediate representations of statutes.
The second stage applies this knowledge to specific cases through three steps:
analyzing queries to map case facts onto the ontology schema, performing
symbolic inference to derive logically entailed conclusions, and generating
final answers using a programmatic implementation that operationalizes the
ontological knowledge. This bridging of natural language understanding with
symbolic reasoning provides explicit and verifiable inspection points,
significantly enhancing transparency compared to end-to-end approaches.
Evaluation on statutory tax calculation tasks demonstrates substantial
improvements, with foundational models achieving 76.4\% accuracy compared to
18.8\% baseline performance, effectively narrowing the performance gap between
reasoning and foundational models. These findings suggest that modular
architectures with formalized knowledge representations can make sophisticated
legal reasoning more accessible through computationally efficient models while
enhancing consistency and explainability in AI legal reasoning, establishing a
foundation for future research into more transparent, trustworthy, and
effective AI systems for legal domain.

</details>


### [145] [L-MARS: Legal Multi-Agent Workflow with Orchestrated Reasoning and Agentic Search](https://arxiv.org/abs/2509.00761)
*Ziqi Wang,Boqin Yuan*

Main category: cs.AI

TL;DR: L-MARS是一个多智能体法律问答系统，通过协调推理和搜索来减少幻觉和不确定性，在LegalSearchQA基准测试中表现出更高的准确性和专家偏好。


<details>
  <summary>Details</summary>
Motivation: 解决传统单次检索增强生成在法律问答中的幻觉和不确定性问题，法律领域需要精确的检索和审议。

Method: 将查询分解为子问题，在异构源（网络搜索、本地RAG、案例法）进行定向搜索，使用法官智能体验证充分性、管辖权和时效性，通过迭代推理-搜索-验证循环保持一致性。

Result: 在200个最新法律选择题的基准测试中，L-MARS显著提高了事实准确性，减少了不确定性，获得了人类专家和LLM法官更高的偏好评分。

Conclusion: 多智能体推理与智能体搜索为在高风险法律领域部署LLMs提供了可扩展和可复现的蓝图。

Abstract: We present L-MARS (Legal Multi-Agent Workflow with Orchestrated Reasoning and
Agentic Search), a system that reduces hallucination and uncertainty in legal
question answering through coordinated multi-agent reasoning and retrieval.
Unlike single-pass retrieval-augmented generation (RAG), L-MARS decomposes
queries into subproblems, issues targeted searches across heterogeneous sources
(Serper web, local RAG, CourtListener case law), and employs a Judge Agent to
verify sufficiency, jurisdiction, and temporal validity before answer
synthesis. This iterative reasoning-search-verification loop maintains
coherence, filters noisy evidence, and grounds answers in authoritative law. We
evaluated L-MARS on LegalSearchQA, a new benchmark of 200 up-to-date multiple
choice legal questions in 2025. Results show that L-MARS substantially improves
factual accuracy, reduces uncertainty, and achieves higher preference scores
from both human experts and LLM-based judges. Our work demonstrates that
multi-agent reasoning with agentic search offers a scalable and reproducible
blueprint for deploying LLMs in high-stakes domains requiring precise legal
retrieval and deliberation.

</details>


### [146] [Aligning Reasoning LLMs for Materials Discovery with Physics-aware Rejection Sampling](https://arxiv.org/abs/2509.00768)
*Lee Hyun,Sohee Yoon,Jinwoo Park,Sue In Chae,Seongeon Park,Jooyeon Ahn,Yebin Jung,Youjung Chung,Hogeun Chang,Myeonginn Kang,Jina Kim,Ho-Gyeong Kim,Myeonghun Jeong*

Main category: cs.AI

TL;DR: 提出了Physics-aware Rejection Sampling (PaRS)方法，通过物理感知的轨迹选择来训练大型推理模型，提高材料属性预测的准确性和物理一致性


<details>
  <summary>Details</summary>
Motivation: AI驱动的材料发现需要准确、校准且物理可接受的配方到属性预测器，现有训练方法基于二元正确性或学习偏好信号，无法很好反映物理可接受性

Method: 引入Physics-aware Rejection Sampling (PaRS)训练时轨迹选择方案，偏好符合基础物理原理且数值接近目标的轨迹，使用轻量级停止机制控制计算成本

Result: 相比基线方法，该方法提高了准确性和校准度，降低了物理违规率，并减少了采样成本

Conclusion: 适度的领域感知约束结合轨迹级选择为过程感知属性预测和闭环材料设计提供了可靠、高效大型推理模型的实用路径

Abstract: AI-driven materials discovery that couples automated experimentation with
algorithmic decision-making requires process aware recipe to property
predictors that are accurate, calibrated, and physically admissible. We
approach this as a reasoning problem with large reasoning models (LRMs). To
instill reasoning capability into language models, we curate reasoning traces
from a teacher model to train a student model. However, most training pipelines
select reasoning traces using binary correctness or learned preference signals
that poorly reflect physical admissibility. We introduce Physics-aware
Rejection Sampling (PaRS), a training-time trace selection scheme that favors
traces consistent with fundamental physics and numerically close to targets,
with lightweight halting to control compute. We instantiate our framework with
a large student model fine-tuned on traces synthesized by a larger teacher
model, and evaluate under matched token budgets against various rejection
sampling baselines. Our method improves accuracy and calibration, reduces
physics-violation rates, and lowers sampling cost relative to baselines. These
results indicate that modest, domain-aware constraints combined with
trace-level selection provide a practical path toward reliable, efficient LRMs
for process-aware property prediction and closed-loop materials design.

</details>


### [147] [ChatCLIDS: Simulating Persuasive AI Dialogues to Promote Closed-Loop Insulin Adoption in Type 1 Diabetes Care](https://arxiv.org/abs/2509.00891)
*Zonghai Yao,Talha Chafekar,Junda Wang,Shuo Han,Feiyun Ouyang,Junhui Qian,Lingxi Li,Hong Yu*

Main category: cs.AI

TL;DR: ChatCLIDS是首个评估LLM驱动健康行为改变说服对话的基准测试，通过专家验证的虚拟患者和多样化说服策略，发现当前LLM在克服抵抗和社会压力方面存在显著局限


<details>
  <summary>Details</summary>
Motivation: 闭环胰岛素输送系统(CLIDS)在1型糖尿病中的实际采用率较低，主要不是技术问题，而是行为、心理和社会障碍。需要评估LLM在健康行为改变中的说服能力

Method: 创建包含专家验证虚拟患者的框架，每个患者具有临床基础的异质性特征和真实采用障碍，模拟与配备多样化循证说服策略的护士代理进行多轮交互

Result: 研究发现更大规模和更具反思性的LLM能够随时间调整策略，但所有模型都难以克服抵抗，特别是在现实社会压力下

Conclusion: 结果凸显了当前LLM在行为改变方面的关键局限性，为推进医疗保健及其他领域可信赖的说服性AI提供了高保真、可扩展的测试平台

Abstract: Real-world adoption of closed-loop insulin delivery systems (CLIDS) in type 1
diabetes remains low, driven not by technical failure, but by diverse
behavioral, psychosocial, and social barriers. We introduce ChatCLIDS, the
first benchmark to rigorously evaluate LLM-driven persuasive dialogue for
health behavior change. Our framework features a library of expert-validated
virtual patients, each with clinically grounded, heterogeneous profiles and
realistic adoption barriers, and simulates multi-turn interactions with nurse
agents equipped with a diverse set of evidence-based persuasive strategies.
ChatCLIDS uniquely supports longitudinal counseling and adversarial social
influence scenarios, enabling robust, multi-dimensional evaluation. Our
findings reveal that while larger and more reflective LLMs adapt strategies
over time, all models struggle to overcome resistance, especially under
realistic social pressure. These results highlight critical limitations of
current LLMs for behavior change, and offer a high-fidelity, scalable testbed
for advancing trustworthy persuasive AI in healthcare and beyond.

</details>


### [148] [Self-Exploring Language Models for Explainable Link Forecasting on Temporal Graphs via Reinforcement Learning](https://arxiv.org/abs/2509.00975)
*Zifeng Ding,Shenyang Huang,Zeyu Cao,Emma Kondrup,Zachary Yang,Xingyue Huang,Yuan Sui,Zhangdie Yuan,Yuqicheng Zhu,Xianglong Hu,Yuan He,Farimah Poursafaei,Michael Bronstein,Andreas Vlachos*

Main category: cs.AI

TL;DR: ReaL-TG是一个基于强化学习的框架，通过微调大语言模型来实现时序图上的可解释链接预测，在保持高性能的同时提供推理解释。


<details>
  <summary>Details</summary>
Motivation: 传统时序图神经网络缺乏可解释性且无法泛化到未见过的图，现有LLM方法局限于静态图或小型合成图，且缺乏对推理质量的评估。

Method: 使用强化学习框架微调LLM，基于结果奖励机制让模型从图结构中自主探索推理策略，生成直接支持预测的解释。

Result: ReaL-TG-4B在排名指标上优于更大的前沿LLM（包括GPT-5 mini），生成的解释质量得到LLM评判系统和人工评估的确认。

Conclusion: ReaL-TG成功地将LLM应用于真实世界时序图推理，实现了高性能和可解释性的平衡，为时序图分析提供了新的解决方案。

Abstract: Forecasting future links is a central task in temporal graph (TG) reasoning,
requiring models to leverage historical interactions to predict upcoming ones.
Traditional neural approaches, such as temporal graph neural networks, achieve
strong performance but lack explainability and cannot be applied to unseen
graphs without retraining. Recent studies have begun to explore using large
language models (LLMs) for graph reasoning, but most of them are constrained to
static graphs or small synthetic TGs and lack the evaluation of the quality of
reasoning traces generated by LLMs. In this work, we present Reasoning-Enhanced
Learning for Temporal Graphs (ReaL-TG), a reinforcement learning framework that
fine-tunes LLMs to perform explainable link forecasting on real-world TGs.
ReaL-TG uses outcome-based reward to encourage models to self-explore reasoning
strategies from graph structure and to produce explanations that directly
justify their predictions. To enable evaluation on LLM-generated reasoning
traces, we propose a new evaluation protocol combining ranking metrics with an
LLM-as-a-Judge system that assesses both the quality of reasoning and the
impact of hallucinations. Experiments with ReaL-TG-4B, obtained by fine-tuning
Qwen3-4B under our framework, show that it outperforms much larger frontier
LLMs, including GPT-5 mini, on ranking metrics, while producing high-quality
explanations confirmed by both the LLM judge and human evaluation.

</details>


### [149] [Analysis of Error Sources in LLM-based Hypothesis Search for Few-Shot Rule Induction](https://arxiv.org/abs/2509.01016)
*Aishni Parab,Hongjing Lu,Ying Nian Wu,Sumit Gulwani*

Main category: cs.AI

TL;DR: LLM假设搜索框架在少样本规则归纳任务中表现接近人类水平，而直接程序生成方法表现较差。


<details>
  <summary>Details</summary>
Motivation: 比较LLM假设搜索与直接程序生成在归纳推理任务中的性能差异，探索建模人类归纳推理的方法。

Method: 使用LLM假设搜索框架和直接程序生成方法在少样本规则归纳任务上进行对比实验。

Result: 假设搜索方法达到与人类相当的性能，直接程序生成方法明显落后。错误分析揭示了假设生成的关键瓶颈。

Conclusion: LLM假设搜索在建模归纳推理方面具有潜力，但需要改进假设生成效率来构建更有效的系统。

Abstract: Inductive reasoning enables humans to infer abstract rules from limited
examples and apply them to novel situations. In this work, we compare an
LLM-based hypothesis search framework with direct program generation approaches
on few-shot rule induction tasks. Our findings show that hypothesis search
achieves performance comparable to humans, while direct program generation
falls notably behind. An error analysis reveals key bottlenecks in hypothesis
generation and suggests directions for advancing program induction methods.
Overall, this paper underscores the potential of LLM-based hypothesis search
for modeling inductive reasoning and the challenges in building more efficient
systems.

</details>


### [150] [FlashAdventure: A Benchmark for GUI Agents Solving Full Story Arcs in Diverse Adventure Games](https://arxiv.org/abs/2509.01052)
*Jaewoo Ahn,Junseo Kim,Heeseung Yun,Jaehyeon Son,Dongmin Park,Jaewoong Cho,Gunhee Kim*

Main category: cs.AI

TL;DR: FlashAdventure是一个包含34个Flash冒险游戏的基准测试，用于评估GUI代理完成完整故事线的能力，并提出了COAST框架和CUA-as-a-Judge自动评估器来解决观察-行为差距问题。


<details>
  <summary>Details</summary>
Motivation: 现有的游戏基准测试缺乏多样性，很少评估代理完成整个故事线的能力，特别是冒险游戏中复杂的叙事驱动交互带来的挑战。

Method: 提出了FlashAdventure基准测试、CUA-as-a-Judge自动游戏评估器，以及COAST代理框架，该框架利用长期线索记忆来更好地规划和解决顺序任务。

Result: 实验显示当前GUI代理在完整故事弧完成方面表现不佳，而COAST通过弥合观察-行为差距显著提高了里程碑完成率。

Conclusion: 虽然COAST取得了改进，但人类与最佳性能代理之间仍存在显著差距，需要继续研究来缩小这一差距。

Abstract: GUI agents powered by LLMs show promise in interacting with diverse digital
environments. Among these, video games offer a valuable testbed due to their
varied interfaces, with adventure games posing additional challenges through
complex, narrative-driven interactions. Existing game benchmarks, however, lack
diversity and rarely evaluate agents on completing entire storylines. To
address this, we introduce FlashAdventure, a benchmark of 34 Flash-based
adventure games designed to test full story arc completion and tackle the
observation-behavior gap: the challenge of remembering and acting on earlier
gameplay information. We also propose CUA-as-a-Judge, an automated gameplay
evaluator, and COAST, an agentic framework leveraging long-term clue memory to
better plan and solve sequential tasks. Experiments show current GUI agents
struggle with full story arcs, while COAST improves milestone completion by
bridging the observation-behavior gap. Nonetheless, a marked discrepancy
between humans and best-performing agents warrants continued research efforts
to narrow this divide.

</details>


### [151] [VerlTool: Towards Holistic Agentic Reinforcement Learning with Tool Use](https://arxiv.org/abs/2509.01055)
*Dongfu Jiang,Yi Lu,Zhuofeng Li,Zhiheng Lyu,Ping Nie,Haozhe Wang,Alex Su,Hui Chen,Kai Zou,Chao Du,Tianyu Pang,Wenhu Chen*

Main category: cs.AI

TL;DR: VerlTool是一个统一的模块化框架，解决了现有工具增强强化学习系统的碎片化、同步执行瓶颈和有限扩展性问题，通过标准化API、异步执行和模块化设计实现了多领域竞争性能。


<details>
  <summary>Details</summary>
Motivation: 现有的工具增强强化学习方法存在代码库碎片化、同步执行瓶颈和跨领域扩展性有限的问题，阻碍了社区采用和算法创新。

Method: 提出VerlTool框架，包含四个关键贡献：与VeRL的上游对齐、标准化API的统一工具管理、异步rollout执行（实现近2倍加速）、以及全面的多领域评估。

Result: 在数学推理、知识问答、SQL生成、视觉推理、网络搜索和软件工程等6个ARLT领域实现了竞争性性能，异步执行获得近2倍速度提升。

Conclusion: VerlTool提供了一个可扩展的统一训练基础设施，通过模块化插件架构显著降低了开发开销，为工具增强的RL研究奠定了坚实基础。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has demonstrated
success in enhancing LLM reasoning capabilities, but remains limited to
single-turn interactions without tool integration. While recent Agentic
Reinforcement Learning with Tool use (ARLT) approaches have emerged to address
multi-turn tool interactions, existing works develop task-specific codebases
that suffer from fragmentation, synchronous execution bottlenecks, and limited
extensibility across domains. These inefficiencies hinder broader community
adoption and algorithmic innovation. We introduce VerlTool, a unified and
modular framework that addresses these limitations through systematic design
principles. VerlTool provides four key contributions: (1) upstream alignment
with VeRL ensuring compatibility and simplified maintenance, (2) unified tool
management via standardized APIs supporting diverse modalities including code
execution, search, SQL databases, and vision processing, (3) asynchronous
rollout execution achieving near 2$\times$ speedup by eliminating
synchronization bottlenecks, and (4) comprehensive evaluation demonstrating
competitive performance across 6 ARLT domains. Our framework formalizes ARLT as
multi-turn trajectories with multi-modal observation tokens (text/image/video),
extending beyond single-turn RLVR paradigms. We train and evaluate models on
mathematical reasoning, knowledge QA, SQL generation, visual reasoning, web
search, and software engineering tasks, achieving results comparable to
specialized systems while providing unified training infrastructure. The
modular plugin architecture enables rapid tool integration requiring only
lightweight Python definitions, significantly reducing development overhead and
providing a scalable foundation for tool-augmented RL research. Our code is
open-sourced at https://github.com/TIGER-AI-Lab/verl-tool.

</details>


### [152] [Question-to-Knowledge: Multi-Agent Generation of Inspectable Facts for Product Mapping](https://arxiv.org/abs/2509.01182)
*Wonduk Seo,Taesub Shin,Hyunjin An,Dokyun Kim,Seunghyun Lee*

Main category: cs.AI

TL;DR: Q2K是一个基于多智能体LLM框架的SKU映射系统，通过推理、知识检索和去重三个智能体协作，结合人工干预，显著提升了电商产品匹配的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 电商平台中产品列表的SKU匹配是一个长期挑战，传统基于规则和关键词相似度的方法容易忽略品牌、规格和捆绑配置等细微差异，导致误分类。

Method: 提出Q2K多智能体框架：1）推理智能体生成针对性消歧问题；2）知识智能体通过聚焦网络搜索解决问题；3）去重智能体重用已验证的推理痕迹以减少冗余。结合人工循环机制处理不确定情况。

Result: 在真实消费品数据集上的实验表明，Q2K超越了强基线方法，在捆绑识别和品牌来源消歧等困难场景中实现了更高的准确性和鲁棒性。

Conclusion: Q2K通过重用检索到的推理而非重复搜索，在准确性和效率之间取得平衡，为产品集成提供了可扩展且可解释的解决方案。

Abstract: Identifying whether two product listings refer to the same Stock Keeping Unit
(SKU) is a persistent challenge in ecommerce, especially when explicit
identifiers are missing and product names vary widely across platforms. Rule
based heuristics and keyword similarity often misclassify products by
overlooking subtle distinctions in brand, specification, or bundle
configuration. To overcome these limitations, we propose Question to Knowledge
(Q2K), a multi agent framework that leverages Large Language Models (LLMs) for
reliable SKU mapping. Q2K integrates: (1) a Reasoning Agent that generates
targeted disambiguation questions, (2) a Knowledge Agent that resolves them via
focused web searches, and (3) a Deduplication Agent that reuses validated
reasoning traces to reduce redundancy and ensure consistency. A human in the
loop mechanism further refines uncertain cases. Experiments on real world
consumer goods datasets show that Q2K surpasses strong baselines, achieving
higher accuracy and robustness in difficult scenarios such as bundle
identification and brand origin disambiguation. By reusing retrieved reasoning
instead of issuing repeated searches, Q2K balances accuracy with efficiency,
offering a scalable and interpretable solution for product integration.

</details>


### [153] [GradeSQL: Outcome Reward Models for Ranking SQL Queries from Large Language Models](https://arxiv.org/abs/2509.01308)
*Mattia Tritto,Giuseppe Farano,Dario Di Palma,Gaetano Rossiello,Fedelucio Narducci,Dharmashankar Subramanian,Tommaso Di Noia*

Main category: cs.AI

TL;DR: 本文评估了结果奖励模型(ORMs)在Text-to-SQL任务中的效果，相比传统的Best-of-N和Majority Voting方法，ORMs通过语义正确性评估显著提升了SQL查询的准确率。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在生成复杂SQL查询时仍存在用户意图与数据库模式对齐不精确的问题，现有的测试时策略如BoN和Maj依赖表层启发式方法，无法充分评估语义正确性。

Method: 提出了训练Text-to-SQL任务专用ORMs的框架，在BIRD和SPIDER基准上对Qwen2、Granite3、Llama3等开源LLM进行微调，使用ORMs作为BoN的启发式选择机制。

Result: ORMs在BIRD和SPIDER基准上分别比ex-BoN提升4.33%和2.10%的执行准确率，比Maj提升2.91%和0.93%。对已对齐SQL生成的模型(如OmniSQL)微调可获得更优的ORM性能。

Conclusion: ORMs是Text-to-SQL任务中有效的输出选择策略，能够更好地对齐用户意图与生成的SQL查询，特别是在复杂查询和大量候选查询场景下表现优异。

Abstract: Text-to-SQL, the task of translating natural language questions into SQL
queries, has significantly advanced with the introduction of Large Language
Models (LLMs), broadening database accessibility for a wide range of users.
Despite substantial progress in generating valid SQL, current LLMs still
struggle with complex queries that require precise alignment between user
intent and the database schema. To mitigate this, test-time strategies such as
Best-of-N (BoN) and Majority Voting (Maj) are often employed, based on the
assumption that LLMs can generate correct answers but may require multiple
attempts. However, these methods rely on surface-level heuristics, selecting
either the syntactically correct query through execution-based BoN (ex-BoN) or
the most frequently generated query with Maj. Recently, Outcome Reward Models
(ORMs), which assign utility scores to generated outputs based on semantic
correctness, have emerged as a promising approach for better aligning model
predictions with user intent. Nevertheless, their application to Text-to-SQL
remains largely underexplored.
  In this work, we evaluate ORMs as an effective heuristic for BoN, compare
them with ex-BoN and Maj, and introduce a framework for training ORMs for the
Text-to-SQL task. We evaluate our ORMs on the BIRD and SPIDER benchmarks,
finetuning various open-source LLMs, including the Qwen2, Granite3, and Llama3
model families. Our results show that ORMs outperform ex-BoN and Maj, achieving
execution accuracy gains of +4.33% (BIRD) and +2.10% (Spider) over ex-BoN, and
+2.91% (BIRD) and +0.93% (Spider) over Maj. We further demonstrate that
finetuning models already aligned with SQL generation, such as OmniSQL, yields
superior ORM performance. Additionally, we observe that ORMs achieve
competitive results on simple queries and benefit more from an increased number
of candidates compared to ex-BoN and Maj.

</details>


### [154] [An LLM-enabled semantic-centric framework to consume privacy policies](https://arxiv.org/abs/2509.01716)
*Rui Zhao,Vladyslav Melnychuk,Jun Zhao,Jesse Wright,Nigel Shadbolt*

Main category: cs.AI

TL;DR: 提出了一种基于大语言模型的语义中心方法，自动从隐私政策中提取关键信息并构建知识图谱Pr²Graph，支持隐私实践的大规模分析和形式化策略表示生成。


<details>
  <summary>Details</summary>
Motivation: 用户很少阅读复杂的隐私政策，现有研究缺乏大规模获取形式化策略的方法，需要解决隐私实践分析的规模化问题。

Method: 使用最先进的大语言模型自动识别隐私政策中的关键信息，构建基于数据隐私词汇(DPV)的知识图谱Pr²Graph，支持ODRL和psDToU等形式化策略表示。

Result: 发布了针对前100热门网站的Pr²Graph公开资源，丰富了Policy-IE数据集，评估了不同大语言模型在管道中的性能表现。

Conclusion: 该方法为实现在线服务隐私实践的大规模分析提供了可能，是审计网络和互联网隐私实践的有前景方向，所有数据集和源代码均已公开。

Abstract: In modern times, people have numerous online accounts, but they rarely read
the Terms of Service or Privacy Policy of those sites, despite claiming
otherwise, due to the practical difficulty in comprehending them. The mist of
data privacy practices forms a major barrier for user-centred Web approaches,
and for data sharing and reusing in an agentic world. Existing research
proposed methods for using formal languages and reasoning for verifying the
compliance of a specified policy, as a potential cure for ignoring privacy
policies. However, a critical gap remains in the creation or acquisition of
such formal policies at scale. We present a semantic-centric approach for using
state-of-the-art large language models (LLM), to automatically identify key
information about privacy practices from privacy policies, and construct
$\mathit{Pr}^2\mathit{Graph}$, knowledge graph with grounding from Data Privacy
Vocabulary (DPV) for privacy practices, to support downstream tasks. Along with
the pipeline, the $\mathit{Pr}^2\mathit{Graph}$ for the top-100 popular
websites is also released as a public resource, by using the pipeline for
analysis. We also demonstrate how the $\mathit{Pr}^2\mathit{Graph}$ can be used
to support downstream tasks by constructing formal policy representations such
as Open Digital Right Language (ODRL) or perennial semantic Data Terms of Use
(psDToU). To evaluate the technology capability, we enriched the Policy-IE
dataset by employing legal experts to create custom annotations. We benchmarked
the performance of different large language models for our pipeline and
verified their capabilities. Overall, they shed light on the possibility of
large-scale analysis of online services' privacy practices, as a promising
direction to audit the Web and the Internet. We release all datasets and source
code as public resources to facilitate reuse and improvement.

</details>


### [155] [Oyster-I: Beyond Refusal -- Constructive Safety Alignment for Responsible Language Models](https://arxiv.org/abs/2509.01909)
*Ranjie Duan,Jiexi Liu,Xiaojun Jia,Shiji Zhao,Ruoxi Cheng,Fengxiang Wang,Cheng Wei,Yong Xie,Chang Liu,Defeng Li,Yinpeng Dong,Yichi Zhang,Yuefeng Chen,Chongwen Wang,Xingjun Ma,Xingxing Wei,Yang Liu,Hang Su,Jun Zhu,Xinfeng Li,Yitong Sun,Jie Zhang,Jinzhao Hu,Sha Xu,Yitong Yang,Jialing Tao,Hui Xue*

Main category: cs.AI

TL;DR: 提出了Constructive Safety Alignment (CSA)方法，通过游戏论预测用户反应、细粒度风险边界发现和可解释推理控制，将安全机制从简单的拒绝转变为主动引导，在保护恶意滥用的同时为心理困扰用户提供建设性帮助。


<details>
  <summary>Details</summary>
Motivation: 现有LLM安全机制主要针对恶意攻击者，采用防御性拒绝策略。但在现实场景中，风险也来自寻求帮助的非恶意用户（如有自伤意图者），简单拒绝可能导致用户重复尝试、升级行为或转向不安全平台，造成更糟后果。

Method: 提出Constructive Safety Alignment (CSA)范式，结合游戏论的用户反应预测、细粒度风险边界发现和可解释推理控制。在Oyster-I (Oy1)模型中实现，将安全转化为信任建立过程。

Result: Oy1在开源模型中达到最先进的安全水平，同时保持高通用能力。在Constructive Benchmark上展示出接近GPT-5的建设性参与度，在Strata-Sword越狱数据集上具有接近GPT-o1水平的无与伦比的鲁棒性。

Conclusion: CSA通过从拒绝优先转向引导优先的安全策略，重新定义了模型与用户的关系，旨在构建不仅安全而且有意义帮助的系统。发布了Oy1、代码和基准测试以支持负责任、以用户为中心的AI发展。

Abstract: Large language models (LLMs) typically deploy safety mechanisms to prevent
harmful content generation. Most current approaches focus narrowly on risks
posed by malicious actors, often framing risks as adversarial events and
relying on defensive refusals. However, in real-world settings, risks also come
from non-malicious users seeking help while under psychological distress (e.g.,
self-harm intentions). In such cases, the model's response can strongly
influence the user's next actions. Simple refusals may lead them to repeat,
escalate, or move to unsafe platforms, creating worse outcomes. We introduce
Constructive Safety Alignment (CSA), a human-centric paradigm that protects
against malicious misuse while actively guiding vulnerable users toward safe
and helpful results. Implemented in Oyster-I (Oy1), CSA combines game-theoretic
anticipation of user reactions, fine-grained risk boundary discovery, and
interpretable reasoning control, turning safety into a trust-building process.
Oy1 achieves state-of-the-art safety among open models while retaining high
general capabilities. On our Constructive Benchmark, it shows strong
constructive engagement, close to GPT-5, and unmatched robustness on the
Strata-Sword jailbreak dataset, nearing GPT-o1 levels. By shifting from
refusal-first to guidance-first safety, CSA redefines the model-user
relationship, aiming for systems that are not just safe, but meaningfully
helpful. We release Oy1, code, and the benchmark to support responsible,
user-centered AI.

</details>


### [156] [How Real Is AI Tutoring? Comparing Simulated and Human Dialogues in One-on-One Instruction](https://arxiv.org/abs/2509.01914)
*Ruijia Li,Yuan-Hao Jiang,Jiatong Wang,Bo Jiang*

Main category: cs.AI

TL;DR: 研究系统分析了AI模拟与真人教师导学对话的结构和行为差异，发现人类导学在语调长度、提问和反馈方面显著更优，具有更多样的认知引导模式


<details>
  <summary>Details</summary>
Motivation: 虽然启发式教师-学生对话被认为对培养学生高阶思维和深度学习至关重要，但大语言模型在生成教育丰富的交互时仍面临挑战

Method: 采用启动-响应-反馈(IRF)编码方案和认知网络分析(ENA)对AI模拟和真实人类导学对话进行定量比较

Result: 人类导学对话在语调长度、提问(I-Q)和一般反馈(F-F)行为方面显著更优；ENA显示人类导学更具认知引导性和多样性，以"问题-事实回答-反馈"循环为中心，而AI模拟对话呈现结构简化和行为收敛特征

Conclusion: 这些发现呈现了当前AI生成导学的关键限制，为设计和评估更具教育效果的生成式教育对话系统提供了实证指导

Abstract: Heuristic and scaffolded teacher-student dialogues are widely regarded as
critical for fostering students' higher-order thinking and deep learning.
However, large language models (LLMs) currently face challenges in generating
pedagogically rich interactions. This study systematically investigates the
structural and behavioral differences between AI-simulated and authentic human
tutoring dialogues. We conducted a quantitative comparison using an
Initiation-Response-Feedback (IRF) coding scheme and Epistemic Network Analysis
(ENA). The results show that human dialogues are significantly superior to
their AI counterparts in utterance length, as well as in questioning (I-Q) and
general feedback (F-F) behaviors. More importantly, ENA results reveal a
fundamental divergence in interactional patterns: human dialogues are more
cognitively guided and diverse, centered around a "question-factual
response-feedback" teaching loop that clearly reflects pedagogical guidance and
student-driven thinking; in contrast, simulated dialogues exhibit a pattern of
structural simplification and behavioral convergence, revolving around an
"explanation-simplistic response" loop that is essentially a simple information
transfer between the teacher and student. These findings illuminate key
limitations in current AI-generated tutoring and provide empirical guidance for
designing and evaluating more pedagogically effective generative educational
dialogue systems.

</details>


### [157] [EigenBench: A Comparative Behavioral Measure of Value Alignment](https://arxiv.org/abs/2509.01938)
*Jonathn Chang,Leonard Piff,Suvadip Sana,Jasmine X. Li,Lionel Levine*

Main category: cs.AI

TL;DR: EigenBench是一个无需真实标签的黑盒基准测试方法，通过模型间相互评估来量化语言模型与给定价值体系的对齐程度。


<details>
  <summary>Details</summary>
Motivation: 解决AI与人类价值观对齐缺乏定量度量标准的问题，为价值对齐提供可比较的基准测试方法。

Method: 使用EigenTrust算法聚合模型间的相互评估结果，给定模型集合、价值体系宪法和场景数据集，生成量化对齐分数的向量。

Result: 发现大部分方差由提示词解释，但仍有小部分残差量化模型本身的倾向性。

Conclusion: EigenBench为价值对齐提供了有效的定量评估框架，能够区分模型固有倾向和提示词影响。

Abstract: Aligning AI with human values is a pressing unsolved problem. To address the
lack of quantitative metrics for value alignment, we propose EigenBench: a
black-box method for comparatively benchmarking language models' values. Given
an ensemble of models, a constitution describing a value system, and a dataset
of scenarios, our method returns a vector of scores quantifying each model's
alignment to the given constitution. To produce these scores, each model judges
the outputs of other models across many scenarios, and these judgments are
aggregated with EigenTrust (Kamvar et al, 2003), yielding scores that reflect a
weighted-average judgment of the whole ensemble. EigenBench uses no ground
truth labels, as it is designed to quantify traits for which reasonable judges
may disagree on the correct label. Using prompted personas, we test whether
EigenBench scores are more sensitive to the model or the prompt: we find that
most of the variance is explained by the prompt, but a small residual
quantifies the disposition of the model itself.

</details>


### [158] [AppCopilot: Toward General, Accurate, Long-Horizon, and Efficient Mobile Agent](https://arxiv.org/abs/2509.02444)
*Jingru Fan,Yufan Dang,Jingyao Wu,Huatao Li,Runde Yang,Xiyuan Yang,Yuheng Wang,Zhong Zhang,Yaxi Lu,Yankai Lin,Zhiyuan Liu,Dahai Li,Chen Qian*

Main category: cs.AI

TL;DR: 本文提出了AppCopilot，一个多模态、多代理的通用设备端助手，解决了移动代理的四个核心问题：泛化能力、准确性、长时程能力和效率，通过端到端自主管道实现了显著改进。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型和多模态基础模型的快速发展，移动代理领域虽然蓬勃发展但未解决根本挑战。本文旨在解决移动代理在实际应用中必须解决的四个核心问题：跨任务、模态、应用和设备的泛化能力；精确的屏幕交互和点击目标准确性；持续多步骤目标的长时程能力；以及在资源受限设备上的高效运行。

Method: 提出了AppCopilot系统，采用端到端自主管道，包括数据收集、训练、部署、高质量高效推理和移动应用开发。在模型层集成多模态基础模型；在推理和控制层结合思维链推理、分层任务规划分解和多代理协作；在执行层支持用户个性化、语音交互、函数调用、跨应用跨设备编排和全面移动应用支持。

Result: AppCopilot在所有四个维度上都实现了显著改进：更强的泛化能力、更高精度的屏幕操作、更可靠的长时程任务完成能力，以及更快、更资源高效的运行时性能。

Conclusion: AppCopilot作为一个完整的闭环系统，通过创新的多模态多代理架构和端到端管道，成功解决了移动代理的关键挑战，为实际可扩展的移动智能助手提供了可行的解决方案。

Abstract: With the raid evolution of large language models and multimodal foundation
models, the mobile-agent landscape has proliferated without converging on the
fundamental challenges. This paper identifies four core problems that must be
solved for mobile agents to deliver practical, scalable impact: (1)
generalization across tasks, modalities, apps, and devices; (2) accuracy,
specifically precise on-screen interaction and click targeting; (3)
long-horizon capability for sustained, multi-step goals; and (4) efficiency,
specifically high-performance runtime on resource-constrained devices. We
present AppCopilot, a multimodal, multi-agent, general-purpose on-device
assistant that operates across applications and constitutes a full-stack,
closed-loop system from data to deployment. AppCopilot operationalizes this
position through an end-to-end autonomous pipeline spanning data collection,
training, deployment, high-quality and efficient inference, and mobile
application development. At the model layer, it integrates multimodal
foundation models with robust Chinese-English support. At the reasoning and
control layer, it combines chain-of-thought reasoning, hierarchical task
planning and decomposition, and multi-agent collaboration. At the execution
layer, it enables user personalization and experiential adaptation, voice
interaction, function calling, cross-app and cross-device orchestration, and
comprehensive mobile app support. The system design incorporates
profiling-driven optimization for latency, memory, and energy across
heterogeneous hardware. Empirically, AppCopilot achieves significant
improvements along all four dimensions: stronger generalization,
higher-precision on-screen actions, more reliable long-horizon task completion,
and faster, more resource-efficient runtime.

</details>


### [159] [UI-TARS-2 Technical Report: Advancing GUI Agent with Multi-Turn Reinforcement Learning](https://arxiv.org/abs/2509.02544)
*Haoming Wang,Haoyang Zou,Huatong Song,Jiazhan Feng,Junjie Fang,Junting Lu,Longxiang Liu,Qinyu Luo,Shihao Liang,Shijue Huang,Wanjun Zhong,Yining Ye,Yujia Qin,Yuwen Xiong,Yuxin Song,Zhiyong Wu,Bo Li,Chen Dun,Chong Liu,Fuxing Leng,Hanbin Wang,Hao Yu,Haobin Chen,Hongyi Guo,Jing Su,Jingjia Huang,Kai Shen,Kaiyu Shi,Lin Yan,Peiyao Zhao,Pengfei Liu,Qinghao Ye,Renjie Zheng,Wayne Xin Zhao,Wen Heng,Wenhao Huang,Wenqian Wang,Xiaobo Qin,Yi Lin,Youbin Wu,Zehui Chen,Zihao Wang,Baoquan Zhong,Xinchun Zhang,Xujing Li,Yuanfan Li,Zhongkai Zhao,Chengquan Jiang,Faming Wu,Haotian Zhou,Jinlin Pang,Li Han,Qianli Ma,Siyao Liu,Songhua Cai,Wenqi Fu,Xin Liu,Zhi Zhang,Bo Zhou,Guoliang Li,Jiajun Shi,Jiale Yang,Jie Tang,Li Li,Taoran Lu,Woyu Lin,Xiaokang Tong,Xinyao Li,Yichi Zhang,Yu Miao,Zhengxuan Jiang,Zili Li,Ziyuan Zhao,Chenxin Li,Dehua Ma,Feng Lin,Ge Zhang,Haihua Yang,Hangyu Guo,Hongda Zhu,Jiaheng Liu,Junda Du,Kai Cai,Kuanye Li,Lichen Yuan,Meilan Han,Minchao Wang,Shuyue Guo,Tianhao Cheng,Xiaobo Ma,Xiaojun Xiao,Xiaolong Huang,Xinjie Chen,Yidi Du,Yilin Chen,Yiwen Wang,Zhaojian Li,Zhenzhu Yang,Zhiyuan Zeng,Chaolin Jin,Chen Li,Hao Chen,Haoli Chen,Jian Chen,Qinghao Zhao,Guang Shi*

Main category: cs.AI

TL;DR: UI-TARS-2是一个原生GUI中心代理模型，通过系统化训练方法解决了数据可扩展性、多轮强化学习、GUI操作限制和环境稳定性等挑战，在多个GUI基准测试和游戏环境中表现出色，性能接近人类水平的60%。


<details>
  <summary>Details</summary>
Motivation: 解决图形用户界面(GUI)自主代理开发中的关键挑战，包括数据可扩展性、多轮强化学习、纯GUI操作的限制以及环境稳定性等开放性问题。

Method: 采用系统化训练方法：数据飞轮实现可扩展数据生成、稳定的多轮RL框架、集成文件系统和终端的混合GUI环境、统一沙盒平台进行大规模部署。

Result: 在GUI基准测试中表现优异：Online-Mind2Web达到88.2，OSWorld达到47.5，WindowsAgentArena达到50.6，AndroidWorld达到73.3；在15个游戏套件中平均标准化得分59.8（约人类水平的60%）；能够泛化到长时域信息搜索任务和软件工程基准测试。

Conclusion: UI-TARS-2显著推进了GUI代理技术的发展，展现出强大的泛化能力，能够适应现实世界交互场景，为大规模代理RL的稳定性和效率提供了重要见解。

Abstract: The development of autonomous agents for graphical user interfaces (GUIs)
presents major challenges in artificial intelligence. While recent advances in
native agent models have shown promise by unifying perception, reasoning,
action, and memory through end-to-end learning, open problems remain in data
scalability, multi-turn reinforcement learning (RL), the limitations of
GUI-only operation, and environment stability. In this technical report, we
present UI-TARS-2, a native GUI-centered agent model that addresses these
challenges through a systematic training methodology: a data flywheel for
scalable data generation, a stabilized multi-turn RL framework, a hybrid GUI
environment that integrates file systems and terminals, and a unified sandbox
platform for large-scale rollouts. Empirical evaluation demonstrates that
UI-TARS-2 achieves significant improvements over its predecessor UI-TARS-1.5.
On GUI benchmarks, it reaches 88.2 on Online-Mind2Web, 47.5 on OSWorld, 50.6 on
WindowsAgentArena, and 73.3 on AndroidWorld, outperforming strong baselines
such as Claude and OpenAI agents. In game environments, it attains a mean
normalized score of 59.8 across a 15-game suite-roughly 60% of human-level
performance-and remains competitive with frontier proprietary models (e.g.,
OpenAI o3) on LMGame-Bench. Additionally, the model can generalize to
long-horizon information-seeking tasks and software engineering benchmarks,
highlighting its robustness across diverse agent tasks. Detailed analyses of
training dynamics further provide insights into achieving stability and
efficiency in large-scale agent RL. These results underscore UI-TARS-2's
potential to advance the state of GUI agents and exhibit strong generalization
to real-world interactive scenarios.

</details>


### [160] [The Landscape of Agentic Reinforcement Learning for LLMs: A Survey](https://arxiv.org/abs/2509.02547)
*Guibin Zhang,Hejia Geng,Xiaohang Yu,Zhenfei Yin,Zaibin Zhang,Zelin Tan,Heng Zhou,Zhongzhi Li,Xiangyuan Xue,Yijiang Li,Yifan Zhou,Yang Chen,Chen Zhang,Yutao Fan,Zihu Wang,Songtao Huang,Yue Liao,Hongru Wang,Mengyue Yang,Heng Ji,Michael Littman,Jun Wang,Shuicheng Yan,Philip Torr,Lei Bai*

Main category: cs.AI

TL;DR: 本文提出了智能体强化学习(Agentic RL)的新范式，将LLM从被动序列生成器转变为自主决策智能体，建立了双重分类法并整合了开源资源以加速研究发展。


<details>
  <summary>Details</summary>
Motivation: 传统LLM强化学习局限于单步MDP，无法处理复杂动态环境中的时序扩展和部分可观测问题，需要新的框架来支持LLM作为自主智能体的发展。

Method: 通过对比LLM-RL的单步MDP与Agentic RL的时序扩展POMDP，提出围绕核心智能体能力(规划、工具使用、记忆等)和应用领域的双重分类法，并整合500多篇文献和开源资源。

Result: 建立了Agentic RL的理论框架和实用资源库，明确了强化学习作为将静态模块转化为自适应智能行为的关键机制，为可扩展通用AI智能体发展指明了方向。

Conclusion: Agentic RL代表了RL领域的范式转变，通过系统化分类和资源整合为未来研究提供了坚实基础，但 scalable通用AI智能体的发展仍面临诸多挑战和机遇。

Abstract: The emergence of agentic reinforcement learning (Agentic RL) marks a paradigm
shift from conventional reinforcement learning applied to large language models
(LLM RL), reframing LLMs from passive sequence generators into autonomous,
decision-making agents embedded in complex, dynamic worlds. This survey
formalizes this conceptual shift by contrasting the degenerate single-step
Markov Decision Processes (MDPs) of LLM-RL with the temporally extended,
partially observable Markov decision processes (POMDPs) that define Agentic RL.
Building on this foundation, we propose a comprehensive twofold taxonomy: one
organized around core agentic capabilities, including planning, tool use,
memory, reasoning, self-improvement, and perception, and the other around their
applications across diverse task domains. Central to our thesis is that
reinforcement learning serves as the critical mechanism for transforming these
capabilities from static, heuristic modules into adaptive, robust agentic
behavior. To support and accelerate future research, we consolidate the
landscape of open-source environments, benchmarks, and frameworks into a
practical compendium. By synthesizing over five hundred recent works, this
survey charts the contours of this rapidly evolving field and highlights the
opportunities and challenges that will shape the development of scalable,
general-purpose AI agents.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [161] [Hybrid Topic-Semantic Labeling and Graph Embeddings for Unsupervised Legal Document Clustering](https://arxiv.org/abs/2509.00990)
*Deepak Bastola,Woohyeok Choi*

Main category: stat.ML

TL;DR: 提出了一种结合Top2Vec和Node2Vec的混合方法用于法律文本分类，通过语义主题建模和图嵌入技术提升无监督法律文档分析效果


<details>
  <summary>Details</summary>
Motivation: 法律文档具有领域特定语言和有限标注数据的特点，传统文本分类方法面临挑战，需要结合语义和结构信息进行更有效的分析

Method: 使用Top2Vec学习语义文档嵌入和发现潜在主题，Node2Vec通过二分图捕获结构关系，结合KMeans聚类生成文档分组

Result: Top2Vec+Node2Vec组合方法在聚类质量上优于纯文本或纯图嵌入方法，相比LDA和NMF基线模型具有竞争优势

Conclusion: 该方法在探索性法律数据分析方面具有潜力，但需要领域特定嵌入、更全面的超参数调优和人工验证来提升实际法律应用的适用性

Abstract: Legal documents pose unique challenges for text classification due to their
domain-specific language and often limited labeled data. This paper proposes a
hybrid approach for classifying legal texts by combining unsupervised topic and
graph embeddings with a supervised model. We employ Top2Vec to learn semantic
document embeddings and automatically discover latent topics, and Node2Vec to
capture structural relationships via a bipartite graph of legal documents. The
embeddings are combined and clustered using KMeans, yielding coherent groupings
of documents. Our computations on a legal document dataset demonstrate that the
combined Top2Vec+Node2Vec approach improves clustering quality over text-only
or graph-only embeddings. We conduct a sensitivity analysis of hyperparameters,
such as the number of clusters and the dimensionality of the embeddings, and
demonstrate that our method achieves competitive performance against baseline
Latent Dirichlet Allocation (LDA) and Non-Negative Matrix Factorization (NMF)
models. Key findings indicate that while the pipeline presents an innovative
approach to unsupervised legal document analysis by combining semantic topic
modeling with graph embedding techniques, its efficacy is contingent upon the
quality of initial topic generation and the representational power of the
chosen embedding models for specialized legal language. Strategic
recommendations include the exploration of domain-specific embeddings, more
comprehensive hyperparameter tuning for Node2Vec, dynamic determination of
cluster numbers, and robust human-in-the-loop validation processes to enhance
legal relevance and trustworthiness. The pipeline demonstrates potential for
exploratory legal data analysis and as a precursor to supervised learning tasks
but requires further refinement and domain-specific adaptation for practical
legal applications.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [162] [Do Video Language Models Really Know Where to Look? Diagnosing Attention Failures in Video Language Models](https://arxiv.org/abs/2509.01167)
*Hyunjong Ok,Jaeho Lee*

Main category: cs.CV

TL;DR: 研究发现流行的视觉编码器在识别视频关键帧方面存在局限，无法有效定位MLLM应该关注的关键信息，需要开发更好的关键帧识别技术


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型依赖视觉语言编码器进行关键帧采样，但这些编码器是否能真正识别最具信息量的帧尚不清楚

Method: 通过实证研究分析流行视觉编码器在识别关键帧方面的能力局限

Result: 发现现有视觉编码器严重缺乏识别MLLM应该关注的关键位置的能力

Conclusion: 需要开发更好的关键帧识别技术来提升高效视频MLLM的性能

Abstract: Recent advances in multimodal large language models (MLLMs) have led to much
progress in video understanding tasks. To avoid the heavy computational cost of
processing all frames, these models typically rely on keyframe sampling methods
guided by vision-language encoders (\textit{e.g.,} SigLIP). However, it remains
unclear whether such encoders can truly identify the most informative frames.
In this work, we provide several empirical pieces of evidence revealing that
popular vision encoders critically suffer from their limited capability to
identify where the MLLM should look inside the video to handle the given
textual query appropriately. Our findings suggest that the development of
better keyframe identification techniques may be necessary for efficient video
MLLMs.

</details>


### [163] [Reinforced Visual Perception with Tools](https://arxiv.org/abs/2509.01656)
*Zetong Zhou,Dongping Chen,Zixian Ma,Zhihan Hu,Mingyang Fu,Sinan Wang,Yao Wan,Zhou Zhao,Ranjay Krishna*

Main category: cs.CV

TL;DR: ReVPT：通过强化学习增强多模态LLM的视觉工具使用能力，在多个视觉推理基准上实现SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有方法通过监督微调增强LLM的视觉能力存在数据生成昂贵、依赖数据筛选、泛化能力差等问题，需要更有效的方法来提升视觉推理能力

Method: 提出基于GRPO的新型强化学习算法，训练模型使用四个视觉工具套件进行推理

Result: 在SAT、CV-Bench、BLINK和MMStar等感知密集型基准上取得最先进性能，ReVPT-3B和ReVPT-7B在CV-Bench上分别比指导模型提升9.03%和9.44%

Conclusion: 该方法有效解决了视觉推理中的关键挑战，通过强化学习显著提升了多模态LLM的视觉工具使用能力，并为RL-based视觉工具使用提供了新的见解

Abstract: Visual reasoning, a cornerstone of human intelligence, encompasses complex
perceptual and logical processes essential for solving diverse visual problems.
While advances in computer vision have produced powerful models for various
perceptual tasks, leveraging these for general visual reasoning remains
challenging. Prior work demonstrates that augmenting LLMs with vision models
via supervised finetuning improves performance, but faces key limitations such
as expensive data generation, reliance on careful data filtering, and poor
generalization. To address these issues, we propose ReVPT to enhance
multi-modal LLMs' abilities to reason about and use visual tools through
reinforcement learning. We introduce a novel RL algorithm based on GRPO,
designed to train models to reason with a suite of four visual tools. Through
extensive experiments, we show that our method achieves state-of-the-art
performance on several perception-heavy benchmarks, including SAT, CV-Bench,
BLINK and MMStar, significantly outperforming the supervised and text-based RL
finetuning baselines. Notably, Our ReVPT-3B and ReVPT-7B outperform the
instruct models by 9.03% and 9.44% on CV-Bench. Finally, we bring to the
community new insights on RL-based visual tool-usage through extensive
ablations. Our code is available at https://github.com/ls-kelvin/REVPT.

</details>


### [164] [RSCC: A Large-Scale Remote Sensing Change Caption Dataset for Disaster Events](https://arxiv.org/abs/2509.01907)
*Zhenyuan Chen,Chenxi Wang,Ningyu Zhang,Feng Zhang*

Main category: cs.CV

TL;DR: RSCC数据集是一个包含62,315对灾前/灾后遥感图像对的大规模基准数据集，配有丰富的人工标注变化描述，用于灾害监测的视觉-语言模型训练和评估。


<details>
  <summary>Details</summary>
Motivation: 现有遥感数据集缺乏时序图像对和详细文本标注，无法捕捉灾害动态影响，需要填补这一空白。

Method: 构建包含地震、洪水、野火等多种灾害的大规模遥感变化描述数据集，提供预灾/灾后图像对和人工标注的变化描述文本。

Result: RSCC数据集能够支持详细的灾害相关分析，为遥感领域提供更准确、可解释和可扩展的视觉-语言应用。

Conclusion: RSCC数据集通过弥合遥感数据中的时间和语义鸿沟，为灾害感知的双时相理解提供了强有力的训练和评估基准。

Abstract: Remote sensing is critical for disaster monitoring, yet existing datasets
lack temporal image pairs and detailed textual annotations. While
single-snapshot imagery dominates current resources, it fails to capture
dynamic disaster impacts over time. To address this gap, we introduce the
Remote Sensing Change Caption (RSCC) dataset, a large-scale benchmark
comprising 62,315 pre-/post-disaster image pairs (spanning earthquakes, floods,
wildfires, and more) paired with rich, human-like change captions. By bridging
the temporal and semantic divide in remote sensing data, RSCC enables robust
training and evaluation of vision-language models for disaster-aware
bi-temporal understanding. Our results highlight RSCC's ability to facilitate
detailed disaster-related analysis, paving the way for more accurate,
interpretable, and scalable vision-language applications in remote sensing.
Code and dataset are available at https://github.com/Bili-Sakura/RSCC.

</details>


### [165] [Understanding Space Is Rocket Science - Only Top Reasoning Models Can Solve Spatial Understanding Tasks](https://arxiv.org/abs/2509.02175)
*Nils Hoehing,Mayug Maniparambil,Ellen Rushe,Noel E. O'Connor,Anthony Ventresque*

Main category: cs.CV

TL;DR: RocketScience是一个开源的对比视觉语言模型基准测试，专门测试空间关系理解能力。该基准包含全新的真实世界图像-文本对，主要涵盖相对空间理解和物体顺序。基准设计对人类简单但对当前VLM模型困难，实证验证了开源和前沿商业VLM在空间关系理解方面的显著不足，而推理模型表现意外优秀。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在空间关系理解方面存在明显缺陷，需要专门的基准测试来评估和改进这一能力。现有的基准测试可能无法充分测试模型的空间推理能力，因此需要开发一个专门针对此任务的挑战性基准。

Method: 创建全新的真实世界图像-文本对数据集，主要关注相对空间关系和物体顺序。设计对人类简单但对模型困难的测试任务。进行解耦分析，分离物体定位和空间推理在思维链模型中的贡献。

Result: 实证结果显示当前开源和商业VLM在空间关系理解方面表现显著不足，而推理模型表现意外优秀。解耦分析发现基准性能的瓶颈在于空间推理能力而非物体定位能力。

Conclusion: RocketScience基准揭示了当前VLM在空间关系理解方面的重大缺陷，为未来模型改进提供了重要基准。数据集以CC-BY-4.0许可证发布，评估代码开源提供。

Abstract: We propose RocketScience, an open-source contrastive VLM benchmark that tests
for spatial relation understanding. It is comprised of entirely new real-world
image-text pairs covering mostly relative spatial understanding and the order
of objects. The benchmark is designed
  to be very easy for humans and hard for the current generation of VLMs, and
this is empirically verified. Our results show a striking lack of spatial
relation understanding in open source and frontier commercial VLMs and a
surprisingly high performance of reasoning models. Additionally, we perform a
disentanglement analysis to separate the contributions of object localization
and spatial reasoning in chain-of-thought-based models and find that the
performance on the benchmark is bottlenecked by spatial reasoning and not
object localization capabilities.
  We release the dataset with a CC-BY-4.0 license and make the evaluation code
available at: https://github.com/nilshoehing/rocketscience

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [166] [Data Cartography for Detecting Memorization Hotspots and Guiding Data Interventions in Generative Models](https://arxiv.org/abs/2509.00083)
*Laksh Patel,Neel Shanbhag*

Main category: cs.LG

TL;DR: GenDataCarto是一个数据中心的框架，通过计算训练样本的难度分数和记忆分数，将数据分为四个象限来指导有针对性的修剪和权重调整，有效减少生成模型中的记忆泄露问题。


<details>
  <summary>Details</summary>
Motivation: 现代生成模型存在过拟合和无意记忆罕见训练样本的风险，这些样本可能被攻击者提取或夸大基准性能，需要一种方法来识别和处理这些有问题的数据。

Method: 提出生成数据制图框架，为每个预训练样本分配难度分数（早期epoch损失）和记忆分数（遗忘事件频率），然后将样本划分为四个象限，用于指导有针对性的数据修剪和权重调整。

Result: 在仅修剪10%数据的情况下，将合成canary提取成功率降低40%以上，同时验证困惑度仅增加不到0.5%。

Conclusion: 基于原则的数据干预可以显著减轻生成模型中的泄露问题，同时对生成性能的影响最小，证明了数据中心方法在提高模型安全性方面的有效性。

Abstract: Modern generative models risk overfitting and unintentionally memorizing rare
training examples, which can be extracted by adversaries or inflate benchmark
performance. We propose Generative Data Cartography (GenDataCarto), a
data-centric framework that assigns each pretraining sample a difficulty score
(early-epoch loss) and a memorization score (frequency of ``forget events''),
then partitions examples into four quadrants to guide targeted pruning and
up-/down-weighting. We prove that our memorization score lower-bounds classical
influence under smoothness assumptions and that down-weighting
high-memorization hotspots provably decreases the generalization gap via
uniform stability bounds. Empirically, GenDataCarto reduces synthetic canary
extraction success by over 40\% at just 10\% data pruning, while increasing
validation perplexity by less than 0.5\%. These results demonstrate that
principled data interventions can dramatically mitigate leakage with minimal
cost to generative performance.

</details>


### [167] [Learning to Refine: Self-Refinement of Parallel Reasoning in LLMs](https://arxiv.org/abs/2509.00084)
*Qibin Wang,Pu Zhao,Shaohan Huang,Fangkai Yang,Lu Wang,Furu Wei,Qingwei Lin,Saravan Rajmohan,Dongmei Zhang*

Main category: cs.LG

TL;DR: 提出Generative Self-Refinement (GSR)框架，通过并行生成候选答案并进行自我优化，解决现有测试时缩放方法在候选答案全错时无法产生正确解的问题。


<details>
  <summary>Details</summary>
Motivation: 现有测试时缩放方法如Best-of-N和多数投票的性能受限于候选答案质量，当所有候选答案都错误时无法产生正确解，且引入额外模型选择最佳答案会带来高昂部署成本。

Method: 提出GSR框架：统一模型并行生成候选答案，然后基于问题和候选答案进行自我优化合成新解。设计混合训练流程，联合优化直接解题和优化候选答案两个互补目标。

Result: 在五个数学基准测试中达到最先进性能，学习到的自我优化技能具有模型无关性，在不同模型规模上表现稳健，并能泛化到分布外推理任务。

Conclusion: GSR框架有效提升了LLM解决复杂多步推理问题的能力，通过自我优化机制克服了现有方法的局限性，具有很好的泛化性和实用性。

Abstract: To further enhance the ability of Large Language Models (LLMs) to solve
complex, multi-step reasoning problems, test-time scaling (TTS) methods have
gained widespread attention. Existing approaches such as Best-of-N and majority
voting are limited as their performance depends on the quality of candidate
responses, making them unable to produce a correct solution when all candidates
are incorrect. Introducing an additional model to select the best response also
incurs significant deployment costs. To this end, we introduce Generative
Self-Refinement (GSR), a novel parallel test-time scaling framework where a
unified model first generates a set of candidate responses in parallel and then
performs self-refinement to synthesize a new superior solution based on a
prompt consisting of the problem and these candidates. However, LLMs struggle
to perform refinement effectively when prompted directly. Therefore, we design
a hybrid training pipeline by jointly optimizing for two complementary
objectives, solving problems directly and refining candidate responses.
Experimental results demonstrate that our method achieves state-of-the-art
performance across five mathematical benchmarks. We further show that this
learned self-refinement skill is a model-agnostic enhancement, robust across
different model scales and generalizing to out-of-distribution reasoning tasks.

</details>


### [168] [Pruning Weights but Not Truth: Safeguarding Truthfulness While Pruning LLMs](https://arxiv.org/abs/2509.00096)
*Yao Fu,Runchao Li,Xianxuan Long,Haotian Yu,Xiaotian Han,Yu Yin,Pan Li*

Main category: cs.LG

TL;DR: 论文发现神经网络剪枝会破坏LLM内部用于谎言检测的关键激活特征，提出了TPLO方法通过关注异常值和判别特征来保持剪枝后模型的谎言检测能力。


<details>
  <summary>Details</summary>
Motivation: 现有LLM剪枝方法虽然能保持下游任务性能，但会破坏模型内部用于谎言检测的关键激活特征，这在实际部署中可能带来安全隐患。

Method: 提出TPLO方法，基于层间异常值和判别特征重要性来调整剪枝稀疏度，同时引入新的提示规则来丰富TruthfulQA基准。

Result: 在50%稀疏度下达到88%的幻觉检测准确率，同时提升了在TruthfulQA基准上的性能表现。

Conclusion: TPLO方法成功解决了剪枝与谎言检测能力之间的权衡问题，为安全部署剪枝后LLM提供了有效解决方案。

Abstract: Neural network pruning has emerged as a promising approach for deploying LLMs
in low-resource scenarios while preserving downstream task performance.
However, for the first time, we reveal that such pruning disrupts LLMs'
internal activation features crucial for lie detection, where probing
classifiers (typically small logistic regression models) trained on these
features assess the truthfulness of LLM-generated statements. This discovery
raises a crucial open question: how can we prune LLMs without sacrificing these
critical lie detection capabilities? Our investigation further reveals that
naively adjusting layer-wise pruning sparsity based on importance inadvertently
removes crucial weights, failing to improve lie detection performance despite
its reliance on the most crucial LLM layer. To address this issue, we propose
Truthful Pruning aligned by Layer-wise Outliers (TPLO), which places greater
emphasis on layers with more activation outliers and stronger discriminative
features simultaneously. This preserves LLMs' original performance while
retaining critical features of inner states needed for robust lie detection.
Moreover, we introduce a prompting rule to enrich the TruthfulQA benchmark for
better calibrating LLM pruning. Empirical results show that our approach
improves the hallucination detection for pruned LLMs (achieving 88% accuracy at
50% sparsity) and enhances their performance on TruthfulQA.

</details>


### [169] [Advanced spectral clustering for heterogeneous data in credit risk monitoring systems](https://arxiv.org/abs/2509.00546)
*Lu Han,Mengyan Li,Jiping Qiang,Zhi Su*

Main category: cs.LG

TL;DR: 提出Advanced Spectral Clustering (ASC)方法，整合数值财务数据和文本数据，通过优化权重参数和特征向量选择，在中小企业信用监测中实现比基线方法高18%的轮廓分数。


<details>
  <summary>Details</summary>
Motivation: 异构数据（数值财务变量和文本记录）给信用监测带来重大挑战，需要开发能够有效整合这两种数据类型的方法。

Method: ASC方法通过优化权重参数整合财务和文本相似性，采用新颖的特征值-轮廓优化方法选择特征向量，并在k-means、k-medians、k-medoids等多种聚类算法上进行验证。

Result: 在1,428家中小企业数据集上，ASC的轮廓分数比单类型数据基线方法高18%，识别出51%的低风险企业包含'社会招聘'术语，招聘导向型中小企业违约风险低30%。

Conclusion: ASC通过将谱聚类理论与异构数据应用相结合，能够识别有意义的聚类模式，为更有针对性和有效的信用干预提供支持，具有跨多种聚类算法的鲁棒性。

Abstract: Heterogeneous data, which encompass both numerical financial variables and
textual records, present substantial challenges for credit monitoring. To
address this issue, we propose Advanced Spectral Clustering (ASC), a method
that integrates financial and textual similarities through an optimized weight
parameter and selects eigenvectors using a novel eigenvalue-silhouette
optimization approach. Evaluated on a dataset comprising 1,428 small and
medium-sized enterprises (SMEs), ASC achieves a Silhouette score that is 18%
higher than that of a single-type data baseline method. Furthermore, the
resulting clusters offer actionable insights; for instance, 51% of low-risk
firms are found to include the term 'social recruitment' in their textual
records. The robustness of ASC is confirmed across multiple clustering
algorithms, including k-means, k-medians, and k-medoids, with
{\Delta}Intra/Inter < 0.13 and {\Delta}Silhouette Coefficient < 0.02. By
bridging spectral clustering theory with heterogeneous data applications, ASC
enables the identification of meaningful clusters, such as recruitment-focused
SMEs exhibiting a 30% lower default risk, thereby supporting more targeted and
effective credit interventions.

</details>


### [170] [DTRNet: Dynamic Token Routing Network to Reduce Quadratic Costs in Transformers](https://arxiv.org/abs/2509.00925)
*Aman Sharma,Saeed Najafi,Parsa Farinneya,Benyamin Jamialahmadi,Marzieh S. Tahaei,Yuhe Fan,Mehdi Rezagholizadeh,Boxing Chen,Aref Jafari*

Main category: cs.LG

TL;DR: DTRNet是一种改进的Transformer架构，通过动态令牌路由机制，让大多数令牌跳过二次成本的交叉令牌混合，同时保持轻量级线性更新，显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: Transformer虽然在各任务中达到最先进结果，但其在每个层对每个令牌统一应用二次自注意力的方式计算成本高昂，需要更高效的替代方案。

Method: 引入动态令牌路由网络(DTRNet)，保留MLP模块，将大多数令牌的注意力成本降低到线性，同时确保每个令牌都得到显式更新。训练后，每层只有约10%的令牌通过注意力路由。

Result: DTRNet在匹配FLOPs下，在准确性和内存方面持续优于基于路由的层跳过方法(MoD和D-LLM)，同时路由更少的令牌到完整注意力。效率增益随序列长度扩展，对长上下文输入显著减少FLOPs。

Conclusion: 通过将令牌更新与注意力混合解耦，DTRNet大幅减少了计算的二次份额，为Transformer提供了简单、高效且可扩展的替代方案。

Abstract: Transformers achieve state-of-the-art results across many tasks, but their
uniform application of quadratic self-attention to every token at every layer
makes them computationally expensive. We introduce DTRNet (Dynamic Token
Routing Network), an improved Transformer architecture that allows tokens to
dynamically skip the quadratic cost of cross-token mixing while still receiving
lightweight linear updates. By preserving the MLP module and reducing the
attention cost for most tokens to linear, DTRNet ensures that every token is
explicitly updated while significantly lowering overall computation. This
design offers an efficient and effective alternative to standard dense
attention. Once trained, DTRNet blocks routes only ~10% of tokens through
attention at each layer while maintaining performance comparable to a full
Transformer. It consistently outperforms routing-based layer skipping methods
such as MoD and D-LLM in both accuracy and memory at matched FLOPs, while
routing fewer tokens to full attention. Its efficiency gains, scales with
sequence length, offering significant reduction in FLOPs for long-context
inputs. By decoupling token updates from attention mixing, DTRNet substantially
reduces the quadratic share of computation, providing a simple, efficient, and
scalable alternative to Transformers.

</details>


### [171] [MEPT: Mixture of Expert Prompt Tuning as a Manifold Mapper](https://arxiv.org/abs/2509.00996)
*Runjia Zeng,Guangyan Sun,Qifan Wang,Tong Geng,Sohail Dianat,Xiaotian Han,Raghuveer Rao,Xueling Zhang,Cheng Han,Lifu Huang,Dongfang Liu*

Main category: cs.LG

TL;DR: 提出了Mixture of Expert Prompt Tuning (MEPT)方法，通过混合专家架构集成多个提示专家，自适应学习多样化和非平稳数据分布，在SuperGLUE上优于现有参数高效基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有微调方法参数空间僵化，无法动态激活适当的神经通路来灵活适应多样化和不断变化的数据分布。

Method: 基于混合专家架构，集成多个提示专家来学习多样化和非平稳数据分布，作为有效的流形映射框架。

Result: 在SuperGLUE上优于多个最先进的参数高效基线方法，平均准确率提升1.94%，同时显著减少激活提示79.25%。

Conclusion: MEPT是一种有效且高效的流形映射框架，通过理论洞察和神经激活通路可视化结果验证了其有效性。

Abstract: Considering deep neural networks as manifold mappers, the
pretrain-then-fine-tune paradigm can be interpreted as a two-stage process:
pretrain establishes a broad knowledge base, and fine-tune adjusts the model
parameters to activate specific neural pathways to align with the target
manifold. Although prior fine-tuning approaches demonstrate success, their
rigid parameter space limits their ability to dynamically activate appropriate
neural pathways, rendering them ill-equipped to adapt flexibly to the diverse
and evolving data distributions. In light of this view, we propose a novel
approach, Mixture of Expert Prompt Tuning (MEPT), as an effective and efficient
manifold-mapping framework. MEPT leverages the Mixture of Experts architecture
by integrating multiple prompt experts to adaptively learn diverse and
non-stationary data distributions. Empirical evaluations demonstrate that MEPT
outperforms several state-of-the-art parameter efficient baselines on
SuperGLUE, achieving notable improvements in mean accuracy (e.g., 1.94%) while
significantly reducing activated prompts by 79.25%. The effectiveness of MEPT
is further supported by theoretical insights from manifold learning and
validated through neural activation pathway visualization results. Our code is
avaliable at https://github.com/runtsang/MEPT.

</details>


### [172] [Towards High Data Efficiency in Reinforcement Learning with Verifiable Reward](https://arxiv.org/abs/2509.01321)
*Xinyu Tang,Zhenduo Zhang,Yurou Liu,Wayne Xin Zhao,Zujie Wen,Zhiqiang Zhang,Jun Zhou*

Main category: cs.LG

TL;DR: DEPO是一种数据高效的政策优化管道，通过离线高质量数据筛选和在线动态样本过滤，显著降低RLVR训练成本，在仅使用20%数据的情况下实现1.66-1.85倍的加速效果。


<details>
  <summary>Details</summary>
Motivation: 现有大型推理模型的强化学习验证奖励方法需要大量计算和大数据集，导致训练成本高、数据效率低，需要解决这一扩展性问题。

Method: 提出DEPO管道：1）离线阶段基于多样性、影响力和适当难度筛选高质量训练样本子集；2）在线阶段引入样本级可探索性指标动态过滤低探索潜力样本；3）加入回放机制确保充分训练。

Result: 在五个推理基准测试中，DEPO在离线和在线数据选择场景下均优于现有方法。仅使用20%训练数据，在AIME24上实现1.85倍加速，AIME25上实现1.66倍加速。

Conclusion: DEPO通过高效的数据选择策略显著降低了RLVR训练的计算成本和数据需求，同时保持了优异的性能表现，为解决大规模推理模型训练的效率问题提供了有效方案。

Abstract: Recent advances in large reasoning models have leveraged reinforcement
learning with verifiable rewards (RLVR) to improve reasoning capabilities.
However, scaling these methods typically requires extensive rollout computation
and large datasets, leading to high training costs and low data efficiency. To
mitigate this issue, we propose DEPO, a Data-Efficient Policy Optimization
pipeline that combines optimized strategies for both offline and online data
selection. In the offline phase, we curate a high-quality subset of training
samples based on diversity, influence, and appropriate difficulty. During
online RLVR training, we introduce a sample-level explorability metric to
dynamically filter samples with low exploration potential, thereby reducing
substantial rollout computational costs. Furthermore, we incorporate a replay
mechanism for under-explored samples to ensure adequate training, which
enhances the model's final convergence performance. Experiments across five
reasoning benchmarks show that DEPO consistently outperforms existing methods
in both offline and online data selection scenarios. Notably, using only 20% of
the training data, our approach achieves a 1.85 times speed-up on AIME24 and a
1.66 times speed-up on AIME25 compared to GRPO trained on the full dataset.

</details>


### [173] [Evaluating Cumulative Spectral Gradient as a Complexity Measure](https://arxiv.org/abs/2509.02399)
*Haji Gul,Abdul Ghani Naim,Ajaz Ahmad Bhat*

Main category: cs.LG

TL;DR: 本文对CSG（累积谱梯度）指标在知识图谱链接预测任务中的有效性进行了严格评估，发现其存在显著局限性，无法如原声称那样有效衡量数据集复杂度。


<details>
  <summary>Details</summary>
Motivation: 准确估计数据集复杂度对于评估和比较知识图谱链接预测模型至关重要。CSG指标曾被提出作为数据集复杂度度量，声称能够自然随类别数量扩展并与下游分类性能强相关。

Method: 在标准知识图谱链接预测基准上严格评估CSG行为，使用两个关键参数（M：每类蒙特卡洛采样点数，K：嵌入空间中的最近邻数量），通过FB15k-237、WN18RR等标准数据集进行实验。

Result: 发现CSG对K的选择高度敏感，无法随目标类别数量自然扩展；CSG值与MRR等性能指标呈现弱相关或无相关性；CSG声称的稳定性和泛化预测能力在链接预测场景中失效。

Conclusion: 研究结果强调了在KG链接预测评估中需要更鲁棒、分类器无关的复杂度度量方法，CSG指标在实际应用中存在严重局限性。

Abstract: Accurate estimation of dataset complexity is crucial for evaluating and
comparing link prediction models for knowledge graphs (KGs). The Cumulative
Spectral Gradient (CSG) metric derived from probabilistic divergence between
classes within a spectral clustering framework was proposed as a dataset
complexity measure that (1) naturally scales with the number of classes and (2)
correlates strongly with downstream classification performance. In this work,
we rigorously assess CSG behavior on standard knowledge graph link prediction
benchmarks a multi class tail prediction task, using two key parameters
governing its computation, M, the number of Monte Carlo sampled points per
class, and K, the number of nearest neighbors in the embedding space. Contrary
to the original claims, we find that (1) CSG is highly sensitive to the choice
of K and therefore does not inherently scale with the number of target classes,
and (2) CSG values exhibit weak or no correlation with established performance
metrics such as mean reciprocal rank (MRR). Through experiments on FB15k 237,
WN18RR, and other standard datasets, we demonstrate that CSG purported
stability and generalization predictive power break down in link prediction
settings. Our results highlight the need for more robust, classifier agnostic
complexity measures in KG link prediction evaluation.

</details>


### [174] [DynaGuard: A Dynamic Guardrail Model With User-Defined Policies](https://arxiv.org/abs/2509.02563)
*Monte Hoover,Vatsal Baherwani,Neel Jain,Khalid Saifullah,Joseph Vincent,Chirag Jain,Melissa Kazemi Rad,C. Bayan Bruss,Ashwinee Panda,Tom Goldstein*

Main category: cs.LG

TL;DR: 动态监护模型支持用户自定义政策检测，在保持静态害害检测准确性的同时，能够高效处理自由形式政策违约检测


<details>
  <summary>Details</summary>
Motivation: 现有的静态监护模型只能检测预定义的害害类别，无法满足不同应用领域的自定义政策需求

Method: 提出动态监护模型，支持用户自定义政策评估，可通过快速检测或链式思维推理方式进行政策违约检测

Result: 动态监护模型在静态害害类别检测上与静态模型准确性相当，在自由形式政策违约检测上达到前沿推理模型的准确性水平，但耗时更短

Conclusion: 动态监护模型为不同应用领域提供了灵活的政策执行方式，在保持高准确性的同时大大提高了效率

Abstract: Guardian models are used to supervise and moderate the outputs of user-facing
chatbots, enforcing guardrails and detecting bad behaviors. Standard guardian
models like LlamaGuard detect predefined, static categories of harms. We
propose dynamic guardian models that evaluate text based on user-defined
policies, making them useful for different application domains that are not
addressed by standard guardian models. Our dynamic guardian models can be used
for fast detection of policy violations or with chain-of-thought reasoning that
articulates and justifies the model outputs. Our dynamic guardian models match
static models in detection accuracy for static harm categories while
identifying violations of free-form policies with accuracy comparable to
frontier reasoning models in a fraction of the time.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [175] [From Attack Descriptions to Vulnerabilities: A Sentence Transformer-Based Approach](https://arxiv.org/abs/2509.02077)
*Refat Othman,Diaeddin Rimawi,Bruno Rossi,Barbara Russo*

Main category: cs.CR

TL;DR: 这篇论文评估了14种最先进的句子转换器模型，用于根据攻击描述自动识别漏洞，MMPNet模型在攻击技术描述上表现最佳，F1分数达89.0


<details>
  <summary>Details</summary>
Motivation: 手工将攻击映射到CVE漏洞不可行，需要自动化方法来实现及时的事件响应和提供可操作的见解

Method: 评估14种最先进的句子转换器模型，使用攻击文本描述来自动识别漏洞，对比各模型的分类性能

Result: multi-qa-mpnet-base-dot-v1 (MMPNet)模型在攻击技术描述上达到最佳性能（F1=89.0，精度=84.0，召回=94.7），56%模型识别的漏洞在CVE仓库中与攻击关联，53%对应CVE库中的漏洞

Conclusion: 自动将攻击技术与漏洞连接能够提升软件安全事件的检测和响应能力，缩短漏洞可袭利用的时间，为构建更安全的系统做出贡献

Abstract: In the domain of security, vulnerabilities frequently remain undetected even
after their exploitation. In this work, vulnerabilities refer to publicly
disclosed flaws documented in Common Vulnerabilities and Exposures (CVE)
reports. Establishing a connection between attacks and vulnerabilities is
essential for enabling timely incident response, as it provides defenders with
immediate, actionable insights. However, manually mapping attacks to CVEs is
infeasible, thereby motivating the need for automation. This paper evaluates 14
state-of-the-art (SOTA) sentence transformers for automatically identifying
vulnerabilities from textual descriptions of attacks. Our results demonstrate
that the multi-qa-mpnet-base-dot-v1 (MMPNet) model achieves superior
classification performance when using attack Technique descriptions, with an
F1-score of 89.0, precision of 84.0, and recall of 94.7. Furthermore, it was
observed that, on average, 56% of the vulnerabilities identified by the MMPNet
model are also represented within the CVE repository in conjunction with an
attack, while 61% of the vulnerabilities detected by the model correspond to
those cataloged in the CVE repository. A manual inspection of the results
revealed the existence of 275 predicted links that were not documented in the
MITRE repositories. Consequently, the automation of linking attack techniques
to vulnerabilities not only enhances the detection and response capabilities
related to software security incidents but also diminishes the duration during
which vulnerabilities remain exploitable, thereby contributing to the
development of more secure systems.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [176] [Evaluating the Effectiveness of Transformer Layers in Wav2Vec 2.0, XLS-R, and Whisper for Speaker Identification Tasks](https://arxiv.org/abs/2509.00230)
*Linus Stuhlmann,Michael Alexander Saxer*

Main category: cs.SD

TL;DR: 评估Wav2Vec 2.0、XLS-R和Whisper三种语音编码器在说话人识别任务中的性能表现，分析各模型层次特征并确定最优层数配置


<details>
  <summary>Details</summary>
Motivation: 研究先进语音编码模型在说话人识别任务中的表现差异，探索不同模型层次对说话人特征的捕获能力

Method: 通过微调模型，使用SVCCA、k-means聚类和t-SNE可视化技术分析层次表示特征

Result: Wav2Vec 2.0和XLS-R在早期层次有效捕获说话人特征，微调提升稳定性；Whisper在深层表现更好；确定了各模型在说话人识别任务中的最优层数

Conclusion: 不同语音编码模型在说话人识别中具有不同的层次特征分布模式，需要针对性地选择层次进行微调以获得最佳性能

Abstract: This study evaluates the performance of three advanced speech encoder models,
Wav2Vec 2.0, XLS-R, and Whisper, in speaker identification tasks. By
fine-tuning these models and analyzing their layer-wise representations using
SVCCA, k-means clustering, and t-SNE visualizations, we found that Wav2Vec 2.0
and XLS-R capture speaker-specific features effectively in their early layers,
with fine-tuning improving stability and performance. Whisper showed better
performance in deeper layers. Additionally, we determined the optimal number of
transformer layers for each model when fine-tuned for speaker identification
tasks.

</details>


### [177] [ArabEmoNet: A Lightweight Hybrid 2D CNN-BiLSTM Model with Attention for Robust Arabic Speech Emotion Recognition](https://arxiv.org/abs/2509.01401)
*Ali Abouzeid,Bilal Elbouardi,Mohamed Maged,Shady Shehata*

Main category: cs.SD

TL;DR: ArabEmoNet是一个轻量级的阿拉伯语语音情感识别架构，使用Mel频谱图和2D卷积，参数量仅为100万，比现有模型小90倍，但性能更优。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语等低资源语言在语音情感识别方面面临数据有限和研究不足的挑战，需要高效且性能优越的解决方案。

Method: 使用Mel频谱图替代传统的MFCC特征，通过2D卷积处理以保留细微的频谱-时间模式，采用轻量级架构设计。

Result: ArabEmoNet在仅100万参数的情况下实现了最先进的性能，比HuBERT base小90倍，比Whisper小74倍。

Conclusion: 该模型为资源受限环境提供了高效的阿拉伯语语音情感识别解决方案，在性能和可访问性方面都有显著优势。

Abstract: Speech emotion recognition is vital for human-computer interaction,
particularly for low-resource languages like Arabic, which face challenges due
to limited data and research. We introduce ArabEmoNet, a lightweight
architecture designed to overcome these limitations and deliver
state-of-the-art performance. Unlike previous systems relying on discrete MFCC
features and 1D convolutions, which miss nuanced spectro-temporal patterns,
ArabEmoNet uses Mel spectrograms processed through 2D convolutions, preserving
critical emotional cues often lost in traditional methods.
  While recent models favor large-scale architectures with millions of
parameters, ArabEmoNet achieves superior results with just 1 million
parameters, 90 times smaller than HuBERT base and 74 times smaller than
Whisper. This efficiency makes it ideal for resource-constrained environments.
ArabEmoNet advances Arabic speech emotion recognition, offering exceptional
performance and accessibility for real-world applications.

</details>


### [178] [Spectrogram Patch Codec: A 2D Block-Quantized VQ-VAE and HiFi-GAN for Neural Speech Coding](https://arxiv.org/abs/2509.02244)
*Luis Felipe Chary,Miguel Arjona Ramirez*

Main category: cs.SD

TL;DR: 提出了一种简化的神经语音编解码器，使用单阶段量化替代复杂的残差向量量化，通过4x4频谱图块量化和对抗性微调，在7.5kbps下实现竞争性音质


<details>
  <summary>Details</summary>
Motivation: 挑战传统神经语音编解码器需要复杂残差向量量化(RVQ)堆栈的设计，寻求更简单、低延迟的架构

Method: 直接在mel频谱图上操作，将非重叠4x4块量化为共享码本，采用VQ-VAE对抗性微调和HiFi-GAN声码器训练

Result: 在7.5kbps码率下，通过STOI、PESQ、MCD、ViSQOL等指标评估，显示与最先进神经编解码器相当的感知质量和可懂度

Conclusion: 简化非残差架构可作为未来低延迟编解码器设计的有效开放基础，证明了简单设计的竞争力

Abstract: We present a neural speech codec that challenges the need for complex
residual vector quantization (RVQ) stacks by introducing a simpler,
single-stage quantization approach. Our method operates directly on the
mel-spectrogram, treating it as a 2D data and quantizing non-overlapping 4x4
patches into a single, shared codebook. This patchwise design simplifies the
architecture, enables low-latency streaming, and yields a discrete latent grid.
To ensure high-fidelity synthesis, we employ a late-stage adversarial
fine-tuning for the VQ-VAE and train a HiFi-GAN vocoder from scratch on the
codec's reconstructed spectrograms. Operating at approximately 7.5 kbits/s for
16 kHz speech, our system was evaluated against several state-of-the-art neural
codecs using objective metrics such as STOI, PESQ, MCD, and ViSQOL. The results
demonstrate that our simplified, non-residual architecture achieves competitive
perceptual quality and intelligibility, validating it as an effective and open
foundation for future low-latency codec designs.

</details>


### [179] [FLM-Audio: Natural Monologues Improves Native Full-Duplex Chatbots via Dual Training](https://arxiv.org/abs/2509.02521)
*Yiqun Yao,Xiang Li,Xin Jiang,Xuezhi Fang,Naitong Yu,Wenjia Ma,Aixin Sun,Yequan Wang*

Main category: cs.SD

TL;DR: 本文提出了一种新的全双工对话模型FLM-Audio，通过"自然"独白和双重训练方案解决了文本与音频流对齐的挑战，实现了优秀的响应速度和对话体验。


<details>
  <summary>Details</summary>
Motivation: 现有的全双工对话模型存在文本独白与音频流对齐的挑战，单纯依靠单词级别对齐会降低大型预训练模型的语言能力，且需要高精度时间戳导致漏洞错误和高处理成本。

Method: 提出"自然"独白概念，模仿人类认知行为在对话中的连续标记序列。采用双重训练范式，在不同训练阶段交替将自然独白放置在音频前后不同位置来实现时间对齐。

Result: 构建了FLM-Audio 7B语音对话模型，实验结果证明其在响应速度、全双工能力和聊天体验方面都表现优异。

Conclusion: 该方法有效解决了全双工对话模型中的对齐问题，为建立高性能语音对话系统提供了有效的解决方案。

Abstract: Full-duplex dialog models are designed to listen and speak simultaneously
with rapid responses to fast-changing user input. Among existing approaches,
native full-duplex models merges different channels (e.g. listen and speak) in
a single time step, overcoming the high response latency inherent to
time-division multiplexing time-division multiplexing (TDM) alternatives. Yet,
a key challenge remains: aligning textual monologues with audio streams that
operate at different bitrates. The prevailing solution relies on word-level
alignment, but this can degrade the language ability of large pre-trained
models. Moreover, it requires highly accurate timestamps for every token, which
introduces cascading errors and increases pre-processing costs. In this paper,
we propose textual monologues in continuous tokens sequence, namely "natural"
monologues, which mimics humanoid cognitive behavior in dialogs. For temporal
alignment, we alternate the position of the natural monologue - leading or
trailing the audio - across different training stages. This "dual" training
paradigm proves highly effective in building FLM-Audio, our 7B spoken dialog
model that demonstrates superior responsiveness, duplexity, and chatting
experiences, as confirmed by experimental results.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [180] [Traj-MLLM: Can Multimodal Large Language Models Reform Trajectory Data Mining?](https://arxiv.org/abs/2509.00053)
*Shuo Liu,Di Yao,Yan Lin,Gao Cong,Jingping Bi*

Main category: cs.MM

TL;DR: Traj-MLLM是一个使用多模态大语言模型进行轨迹数据挖掘的通用框架，通过多视图上下文将原始轨迹转换为图像-文本序列，无需训练数据或微调即可在多个任务上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的人类轨迹分析方法存在泛化性问题，要么局限于特定区域，要么只适用于少数任务。本文探索多模态大语言模型是否能解决轨迹数据挖掘的通用性问题。

Method: 提出Traj-MLLM框架，整合多视图上下文将原始轨迹转换为保持时空特征的图像-文本序列，利用MLLM的推理能力进行分析，并采用提示优化方法实现任务自适应。

Result: 在四个公开数据集上的实验显示，Traj-MLLM在旅行时间估计、移动性预测、异常检测和交通方式识别任务上分别比最先进基线提升48.05%、15.52%、51.52%和1.83%。

Conclusion: Traj-MLLM首次证明了MLLM在轨迹数据挖掘中的有效性，无需训练数据或微调即可实现优异的跨任务泛化性能，为解决轨迹分析通用性问题提供了新思路。

Abstract: Building a general model capable of analyzing human trajectories across
different geographic regions and different tasks becomes an emergent yet
important problem for various applications. However, existing works suffer from
the generalization problem, \ie, they are either restricted to train for
specific regions or only suitable for a few tasks. Given the recent advances of
multimodal large language models (MLLMs), we raise the question: can MLLMs
reform current trajectory data mining and solve the problem? Nevertheless, due
to the modality gap of trajectory, how to generate task-independent multimodal
trajectory representations and how to adapt flexibly to different tasks remain
the foundational challenges. In this paper, we propose \texttt{Traj-MLLM}},
which is the first general framework using MLLMs for trajectory data mining. By
integrating multiview contexts, \texttt{Traj-MLLM}} transforms raw trajectories
into interleaved image-text sequences while preserving key spatial-temporal
characteristics, and directly utilizes the reasoning ability of MLLMs for
trajectory analysis. Additionally, a prompt optimization method is proposed to
finalize data-invariant prompts for task adaptation. Extensive experiments on
four publicly available datasets show that \texttt{Traj-MLLM}} outperforms
state-of-the-art baselines by $48.05\%$, $15.52\%$, $51.52\%$, $1.83\%$ on
travel time estimation, mobility prediction, anomaly detection and
transportation mode identification, respectively. \texttt{Traj-MLLM}} achieves
these superior performances without requiring any training data or fine-tuning
the MLLM backbones.

</details>


### [181] [LLM-Guided Semantic Relational Reasoning for Multimodal Intent Recognition](https://arxiv.org/abs/2509.01337)
*Qianrui Zhou,Hua Xu,Yifan Wang,Xinzhi Dong,Hanlei Zhang*

Main category: cs.MM

TL;DR: 提出LGSRR方法，利用大语言模型的知识增强小模型的关系推理能力，通过链式思维提取细粒度语义指导，在多模态意图识别任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在模态层面存在局限性，难以对细粒度语义进行关系推理，限制了复杂意图理解的能力。

Method: 使用LLM基于浅到深的链式思维自主发现、描述和排序语义线索，建立语义基础；形式化建模三种基本语义关系类型并分析其相互作用。

Result: 在多模态意图和对话行为识别任务上的广泛实验表明，LGSRR优于最先进方法，在不同语义理解场景中均获得一致的性能提升。

Conclusion: LGSRR方法通过利用LLM的扩展知识来增强关系推理性能，为复杂意图理解提供了有效的解决方案。

Abstract: Understanding human intents from multimodal signals is critical for analyzing
human behaviors and enhancing human-machine interactions in real-world
scenarios. However, existing methods exhibit limitations in their
modality-level reliance, constraining relational reasoning over fine-grained
semantics for complex intent understanding. This paper proposes a novel
LLM-Guided Semantic Relational Reasoning (LGSRR) method, which harnesses the
expansive knowledge of large language models (LLMs) to establish semantic
foundations that boost smaller models' relational reasoning performance.
Specifically, an LLM-based strategy is proposed to extract fine-grained
semantics as guidance for subsequent reasoning, driven by a shallow-to-deep
Chain-of-Thought (CoT) that autonomously uncovers, describes, and ranks
semantic cues by their importance without relying on manually defined priors.
Besides, we formally model three fundamental types of semantic relations
grounded in logical principles and analyze their nuanced interplay to enable
more effective relational reasoning. Extensive experiments on multimodal intent
and dialogue act recognition tasks demonstrate LGSRR's superiority over
state-of-the-art methods, with consistent performance gains across diverse
semantic understanding scenarios. The complete data and code are available at
https://github.com/thuiar/LGSRR.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [182] [Chronotome: Real-Time Topic Modeling for Streaming Embedding Spaces](https://arxiv.org/abs/2509.01051)
*Matte Lim,Catherine Yeh,Martin Wattenberg,Fernanda Viégas,Panagiotis Michalatos*

Main category: cs.HC

TL;DR: 提出了一种结合力导向投影和流式聚类的方法，用于可视化时间序列数据中的语义演变，并开发了Chronotome交互工具进行实时探索。


<details>
  <summary>Details</summary>
Motivation: 现实世界数据集（如艺术家作品集、社交媒体历史）随时间呈现有意义的语义变化，但现有降维方法难以有效捕捉这种时间维度的演变模式。

Method: 结合力导向投影和流式聚类方法，构建嵌入向量的时空映射，开发Chronotome交互式工具实现实时探索。

Result: 在文本和图像数据用例中展示了该方法的有效性，为理解时间数据集的美学和语义提供了新的视角。

Conclusion: 该方法能够有效捕捉和可视化时间序列数据中的语义演变，为分析动态数据集提供了新的技术手段和交互工具。

Abstract: Many real-world datasets -- from an artist's body of work to a person's
social media history -- exhibit meaningful semantic changes over time that are
difficult to capture with existing dimensionality reduction methods. To address
this gap, we introduce a visualization technique that combines force-based
projection and streaming clustering methods to build a spatial-temporal map of
embeddings. Applying this technique, we create Chronotome, a tool for
interactively exploring evolving themes in time-based data -- in real time. We
demonstrate the utility of our approach through use cases on text and image
data, showing how it offers a new lens for understanding the aesthetics and
semantics of temporal datasets.

</details>


### [183] [E-THER: A PCT-Grounded Dataset for Benchmarking Empathic AI](https://arxiv.org/abs/2509.02100)
*Sharjeel Tahir,Judith Johnson,Jumana Abu-Khalaf,Syed Afaq Ali Shah*

Main category: cs.HC

TL;DR: 提出了E-THER数据集，首个基于个人中心疗法的多模态数据集，用于检测言语-视觉不一致性，提升AI系统的真实共情能力而非表演性共情。


<details>
  <summary>Details</summary>
Motivation: 现有共情AI系统无法识别言语表达与真实情感状态之间的不一致性，因为现有数据集只关注表层情绪识别，缺乏对言语-视觉不一致模式的关注。

Method: 创建基于个人中心疗法的多模态数据集，包含多维标注的言语-视觉不一致性检测，包括情感错位识别和行为参与度评分。

Result: 使用该数据集训练的视觉语言模型（如IDEFICS和VideoLLAVA）在共情和治疗对话质量方面显著提升，在维持治疗参与度、减少人工化语言模式等方面优于通用模型。

Conclusion: E-THER数据集为训练真正具有共情能力的AI系统提供了重要基础，基于不一致性训练的模型在治疗性对话中表现更自然和有效。

Abstract: A prevalent shortfall among current empathic AI systems is their inability to
recognize when verbal expressions may not fully reflect underlying emotional
states. This is because the existing datasets, used for the training of these
systems, focus on surface-level emotion recognition without addressing the
complex verbal-visual incongruence (mismatch) patterns useful for empathic
understanding. In this paper, we present E-THER, the first Person-Centered
Therapy-grounded multimodal dataset with multidimensional annotations for
verbal-visual incongruence detection, enabling training of AI systems that
develop genuine rather than performative empathic capabilities. The annotations
included in the dataset are drawn from humanistic approach, i.e., identifying
verbal-visual emotional misalignment in client-counsellor interactions -
forming a framework for training and evaluating AI on empathy tasks. Additional
engagement scores provide behavioral annotations for research applications.
Notable gains in empathic and therapeutic conversational qualities are observed
in state-of-the-art vision-language models (VLMs), such as IDEFICS and
VideoLLAVA, using evaluation metrics grounded in empathic and therapeutic
principles. Empirical findings indicate that our incongruence-trained models
outperform general-purpose models in critical traits, such as sustaining
therapeutic engagement, minimizing artificial or exaggerated linguistic
patterns, and maintaining fidelity to PCT theoretical framework.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [184] [Amplifying Emotional Signals: Data-Efficient Deep Learning for Robust Speech Emotion Recognition](https://arxiv.org/abs/2509.00077)
*Tai Vu*

Main category: eess.AS

TL;DR: 本文通过迁移学习和数据增强技术，在有限数据集上开发了多种机器学习模型用于语音情感识别，其中ResNet34架构在RAVDESS和SAVEE数据集上取得了66.7%的准确率和0.631的F1分数，创下了新的性能基准。


<details>
  <summary>Details</summary>
Motivation: 语音情感识别在人机交互中具有重要意义，但在有限数据集上实现高性能仍然是一个关键挑战。本文旨在解决数据稀缺问题，开发更鲁棒和可泛化的语音情感识别系统。

Method: 开发并评估了一系列机器学习模型，包括支持向量机(SVM)、长短期记忆网络(LSTM)和卷积神经网络(CNN)。采用迁移学习和创新的数据增强技术来处理小数据集问题。

Result: 最有效的ResNet34模型在RAVDESS和SAVEE组合数据集上取得了66.7%的准确率和0.631的F1分数，建立了新的性能基准。

Conclusion: 研究结果表明，利用预训练模型和数据增强技术可以显著克服数据稀缺问题，为开发更鲁棒和可泛化的语音情感识别系统铺平了道路。

Abstract: Speech Emotion Recognition (SER) presents a significant yet persistent
challenge in human-computer interaction. While deep learning has advanced
spoken language processing, achieving high performance on limited datasets
remains a critical hurdle. This paper confronts this issue by developing and
evaluating a suite of machine learning models, including Support Vector
Machines (SVMs), Long Short-Term Memory networks (LSTMs), and Convolutional
Neural Networks (CNNs), for automated emotion classification in human speech.
We demonstrate that by strategically employing transfer learning and innovative
data augmentation techniques, our models can achieve impressive performance
despite the constraints of a relatively small dataset. Our most effective
model, a ResNet34 architecture, establishes a new performance benchmark on the
combined RAVDESS and SAVEE datasets, attaining an accuracy of 66.7% and an F1
score of 0.631. These results underscore the substantial benefits of leveraging
pre-trained models and data augmentation to overcome data scarcity, thereby
paving the way for more robust and generalizable SER systems.

</details>


### [185] [ChipChat: Low-Latency Cascaded Conversational Agent in MLX](https://arxiv.org/abs/2509.00078)
*Tatiana Likhomanenko,Luke Carlson,Richard He Bai,Zijin Gu,Han Tran,Zakaria Aldeneh,Yizhe Zhang,Ruixiang Zhang,Huangjie Zheng,Navdeep Jaitly*

Main category: eess.AS

TL;DR: ChipChat是一个创新的低延迟级联语音对话系统，通过流式架构优化和混合专家等技术，在Mac Studio上实现亚秒级响应，完全在设备端处理以保护用户隐私。


<details>
  <summary>Details</summary>
Motivation: 尽管端到端方法有理论优势，但级联系统在语言理解任务中表现更好，但受限于顺序处理延迟。需要开发低延迟的实时设备端语音代理架构。

Method: 集成流式对话语音识别（混合专家）、状态-动作增强LLM、文本转语音合成、神经声码器和说话人建模，使用MLX框架实现完全设备端处理。

Result: 在Mac Studio上实现亚秒级响应延迟，无需专用GPU，通过完全设备端处理保护用户隐私。

Conclusion: 经过战略重新设计的级联系统可以克服历史延迟限制，为实用的基于语音的AI代理提供了有前景的发展路径。

Abstract: The emergence of large language models (LLMs) has transformed spoken dialog
systems, yet the optimal architecture for real-time on-device voice agents
remains an open question. While end-to-end approaches promise theoretical
advantages, cascaded systems (CSs) continue to outperform them in language
understanding tasks, despite being constrained by sequential processing
latency. In this work, we introduce ChipChat, a novel low-latency CS that
overcomes traditional bottlenecks through architectural innovations and
streaming optimizations. Our system integrates streaming (a) conversational
speech recognition with mixture-of-experts, (b) state-action augmented LLM, (c)
text-to-speech synthesis, (d) neural vocoder, and (e) speaker modeling.
Implemented using MLX, ChipChat achieves sub-second response latency on a Mac
Studio without dedicated GPUs, while preserving user privacy through complete
on-device processing. Our work shows that strategically redesigned CSs can
overcome their historical latency limitations, offering a promising path
forward for practical voice-based AI agents.

</details>


### [186] [Automatic Pronunciation Error Detection and Correction of the Holy Quran's Learners Using Deep Learning](https://arxiv.org/abs/2509.00094)
*Abdullah Abdelfattah,Mahmoud I. Khalil,Hazem Abbas*

Main category: eess.AS

TL;DR: 这篇论文提出了一种自动化处理可兰经朗读语音数据的方法，包括数据收集、分割、转写和验证，并创建了超过850小时的高质量注释数据集。还开发了一种新的培基于可兰经音位脚本(QPS)的发音错误检测方法，达到了极低的音素错误率(0.16%)


<details>
  <summary>Details</summary>
Motivation: 虽然可兰经朗读有严格的培基读读规则(tajweed)使得语音评估更加有效，但高质量注释数据的稀缺仍然是主要障碍，需要解决这一问题

Method: 开发了一个98%自动化的处理流水线：收集专家朗读、使用细调的wav2vec2-BERT模型在停顶点分割、转写段落、通过新的Tasmeea算法验证文本。还提出了基于自定义可兰经音位脚本(QPS)的ASR发音错误检测方法，以及多级CTC模型

Result: 生成了850+小时音频(约300K注释语句)的高质量数据集，多级CTC模型在测试集上达到了平均0.16%的音素错误率(PER)

Conclusion: 该研究成功解决了可兰经朗读数据注释的问题，提供了高质量的数据集和高效的发音错误检测方法，所有代码、数据和模型都开源发布

Abstract: Assessing spoken language is challenging, and quantifying pronunciation
metrics for machine learning models is even harder. However, for the Holy
Quran, this task is simplified by the rigorous recitation rules (tajweed)
established by Muslim scholars, enabling highly effective assessment. Despite
this advantage, the scarcity of high-quality annotated data remains a
significant barrier.
  In this work, we bridge these gaps by introducing: (1) A 98% automated
pipeline to produce high-quality Quranic datasets -- encompassing: Collection
of recitations from expert reciters, Segmentation at pause points (waqf) using
our fine-tuned wav2vec2-BERT model, Transcription of segments, Transcript
verification via our novel Tasmeea algorithm; (2) 850+ hours of audio (~300K
annotated utterances); (3) A novel ASR-based approach for pronunciation error
detection, utilizing our custom Quran Phonetic Script (QPS) to encode Tajweed
rules (unlike the IPA standard for Modern Standard Arabic). QPS uses a
two-level script: (Phoneme level): Encodes Arabic letters with short/long
vowels. (Sifa level): Encodes articulation characteristics of every phoneme. We
further include comprehensive modeling with our novel multi-level CTC Model
which achieved 0.16% average Phoneme Error Rate (PER) on the testset. We
release all code, data, and models as open-source:
https://obadx.github.io/prepare-quran-dataset/

</details>


### [187] [MixedG2P-T5: G2P-free Speech Synthesis for Mixed-script texts using Speech Self-Supervised Learning and Language Model](https://arxiv.org/abs/2509.01391)
*Joonyong Park,Daisuke Saito,Nobuaki Minematsu*

Main category: eess.AS

TL;DR: 新的语音合成方法，使用深度学习模型直接从语音生成离散标签，取代传统的字符到音素转换


<details>
  <summary>Details</summary>
Motivation: 避免人工音标注工作，降低成本并提高可扩展性，特别是对大规模未注释音频数据集

Method: 利用预训练语音SSL模型，训练T5编码器从混合脚本文本生成伪语言标签

Result: 模型性能与传统G2P基础的文本语音系统相当，能保留自然语言和超语言特征，如口音和语调

Conclusion: 该方法有效取代传统G2P转换，为语音合成提供了更高效、更可扩展的解决方案

Abstract: This study presents a novel approach to voice synthesis that can substitute
the traditional grapheme-to-phoneme (G2P) conversion by using a deep
learning-based model that generates discrete tokens directly from speech.
Utilizing a pre-trained voice SSL model, we train a T5 encoder to produce
pseudo-language labels from mixed-script texts (e.g., containing Kanji and
Kana). This method eliminates the need for manual phonetic transcription,
reducing costs and enhancing scalability, especially for large non-transcribed
audio datasets. Our model matches the performance of conventional G2P-based
text-to-speech systems and is capable of synthesizing speech that retains
natural linguistic and paralinguistic features, such as accents and
intonations.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [188] [ERank: Fusing Supervised Fine-Tuning and Reinforcement Learning for Effective and Efficient Text Reranking](https://arxiv.org/abs/2509.00520)
*Yuzheng Cai,Yanzhao Zhang,Dingkun Long,Mingxin Li,Pengjun Xie,Weiguo Zheng*

Main category: cs.IR

TL;DR: ERank是一个基于推理大语言模型的高效点式重排器，通过两阶段训练（SFT+RL）解决现有重排模型在评分区分度和效率之间的权衡问题


<details>
  <summary>Details</summary>
Motivation: 当前LLM重排器面临根本性权衡：基于监督微调的点式方法缺乏评分区分度，而复杂的列表式方法效率低下，不适用于低延迟应用

Method: 提出两阶段训练流程：1）SFT阶段使用细粒度整数分数进行生成式训练；2）RL阶段使用新颖的列表式奖励进一步优化，将全局排序意识融入高效的点式架构

Result: 在BRIGHT、FollowIR、TREC DL和BEIR基准测试中表现优异，ERank-4B在BRIGHT上达到nDCG@10为38.7，32B版本达到最先进的40.2

Conclusion: ERank成功解决了重排模型效率与效果之间的权衡问题，在保持高效的同时实现了卓越的相关性判别能力

Abstract: Text reranking models are a crucial component in modern systems like
Retrieval-Augmented Generation, tasked with selecting the most relevant
documents prior to generation. However, current Large Language Models (LLMs)
powered rerankers often face a fundamental trade-off. On one hand, Supervised
Fine-Tuning based pointwise methods that frame relevance as a binary
classification task lack the necessary scoring discrimination, particularly for
those built on reasoning LLMs. On the other hand, approaches designed for
complex reasoning often employ powerful yet inefficient listwise formulations,
rendering them impractical for low latency applications. To resolve this
dilemma, we introduce ERank, a highly effective and efficient pointwise
reranker built from a reasoning LLM that excels across diverse relevance
scenarios. We propose a novel two-stage training pipeline that begins with
Supervised Fine-Tuning (SFT). In this stage, we move beyond binary labels and
train the model generatively to output fine grained integer scores, which
significantly enhances relevance discrimination. The model is then further
refined using Reinforcement Learning (RL) with a novel, listwise derived
reward. This technique instills global ranking awareness into the efficient
pointwise architecture. We evaluate the ERank reranker on the BRIGHT, FollowIR,
TREC DL, and BEIR benchmarks, demonstrating superior effectiveness and
robustness compared to existing approaches. On the reasoning-intensive BRIGHT
benchmark, our ERank-4B achieves an nDCG@10 of 38.7, while a larger 32B variant
reaches a state of the art nDCG@10 of 40.2.

</details>


### [189] [CSRM-LLM: Embracing Multilingual LLMs for Cold-Start Relevance Matching in Emerging E-commerce Markets](https://arxiv.org/abs/2509.01566)
*Yujing Wang,Yiren Chen,Huoran Li,Chunxu Xu,Yuchong Luo,Xianghui Mao,Cong Li,Lun Du,Chunyang Ma,Qiqi Jiang,Yin Wang,Fan Gao,Wenting Mo,Pei Wen,Shantanu Kumar,Taejin Park,Yiwei Song,Vijay Rajaram,Tao Cheng,Sonu Durgia,Pranam Kolari*

Main category: cs.IR

TL;DR: 提出了CSRM框架，利用多语言大语言模型解决电商冷启动问题，通过机器翻译、检索增强查询和多轮自蒸馏训练，显著提升了相关性匹配性能


<details>
  <summary>Details</summary>
Motivation: 全球电商平台扩张面临冷启动挑战，新市场缺乏人工标签和用户行为数据，需要有效的相关性匹配解决方案

Method: CSRM框架：1）通过机器翻译任务激活LLM的跨语言迁移能力；2）检索增强查询提升查询理解和电商知识；3）多轮自蒸馏训练缓解标签错误影响

Result: 实验证明CSRM-LLM有效性，成功实际部署，缺陷率降低45.8%，会话购买率提升0.866%

Conclusion: CSRM框架为新兴电商市场提供了有效的冷启动相关性匹配解决方案，LLM技术在实际电商场景中展现出显著价值

Abstract: As global e-commerce platforms continue to expand, companies are entering new
markets where they encounter cold-start challenges due to limited human labels
and user behaviors. In this paper, we share our experiences in Coupang to
provide a competitive cold-start performance of relevance matching for emerging
e-commerce markets. Specifically, we present a Cold-Start Relevance Matching
(CSRM) framework, utilizing a multilingual Large Language Model (LLM) to
address three challenges: (1) activating cross-lingual transfer learning
abilities of LLMs through machine translation tasks; (2) enhancing query
understanding and incorporating e-commerce knowledge by retrieval-based query
augmentation; (3) mitigating the impact of training label errors through a
multi-round self-distillation training strategy. Our experiments demonstrate
the effectiveness of CSRM-LLM and the proposed techniques, resulting in
successful real-world deployment and significant online gains, with a 45.8%
reduction in defect ratio and a 0.866% uplift in session purchase rate.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [190] [Content and Engagement Trends in COVID-19 YouTube Videos: Evidence from the Late Pandemic](https://arxiv.org/abs/2509.01954)
*Nirmalya Thakur,Madeline D Hartel,Lane Michael Boden,Dallas Enriquez,Boston Joyner Ricks*

Main category: cs.SI

TL;DR: 该研究分析了2023-2024年约1万个COVID-19相关YouTube视频，发现发布时间、标题词汇、情感分析和视频时长等因素显著影响观众参与度，其中周中发布、包含特定关键词的短视频获得最高观看量。


<details>
  <summary>Details</summary>
Motivation: 研究COVID-19大流行后期YouTube视频的参与度模式，了解时间、语言和结构因素如何影响观众对疫情相关内容的行为和互动。

Method: 分析约10,000个2023年1月至2024年10月发布的COVID-19相关YouTube视频，采用时间分析、词汇分析、情感分析和分类别时长分析等方法。

Result: 发现周一至周五的发布效果最佳；标题含"shorts"的视频平均观看量达216万；情感分析与观看量存在显著相关性；娱乐类短视频平均观看量最高（288,675次）。

Conclusion: COVID-19相关视频的参与度模式受发布时间、标题词汇、主题内容和类型特定时长效应的显著影响，这些发现对内容创作者和公共卫生传播具有重要启示。

Abstract: This work investigated about 10,000 COVID-19-related YouTube videos published
between January 2023 and October 2024 to evaluate how temporal, lexical,
linguistic, and structural factors influenced engagement during the late
pandemic period. Publishing activity showed consistent weekday effects: in the
first window, average views peaked on Mondays at 92,658; in the second, on
Wednesdays at 115,479; and in the third, on Fridays at 84,874, reflecting a
shift in audience attention toward mid- and late week. Lexical analysis of
video titles revealed recurring high-frequency keywords related to COVID-19 and
YouTube features, including COVID, coronavirus, shorts, and live. Frequency
analysis revealed sharp spikes, with COVID appearing in 799 video titles in
August 2024, while engagement analysis showed that videos titled with shorts
attracted very high views, peaking at 2.16 million average views per video in
June 2023. Analysis of sentiment of video descriptions in English showed weak
correlation with views in the raw data (Pearson r = 0.0154, p = 0.2987), but
stronger correlations emerged once outliers were addressed, with Spearman r =
0.110 (p < 0.001) and Pearson r = 0.0925 (p < 0.001). Category-level analysis
of video durations revealed contrasting outcomes: long videos focusing on
people and blogs averaged 209,114 views, short entertainment videos averaged
288,675 views, and medium-to-long news and politics videos averaged 51,309 and
59,226 views, respectively. These results demonstrate that engagement patterns
of COVID-19-related videos on YouTube during the late pandemic followed
distinct characteristics driven by publishing schedules, title vocabulary,
topics, and genre-specific duration effects.

</details>
