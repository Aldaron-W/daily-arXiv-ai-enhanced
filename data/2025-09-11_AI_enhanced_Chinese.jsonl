{"id": "2509.07998", "pdf": "https://arxiv.org/pdf/2509.07998", "abs": "https://arxiv.org/abs/2509.07998", "authors": ["Mesay Gemeda Yigezu", "Girma Yohannis Bade", "Atnafu Lambebo Tonja", "Olga Kolesnikova", "Grigori Sidorov", "Alexander Gelbukh"], "title": "Bilingual Word Level Language Identification for Omotic Languages", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Language identification is the task of determining the languages for a given\ntext. In many real world scenarios, text may contain more than one language,\nparticularly in multilingual communities. Bilingual Language Identification\n(BLID) is the task of identifying and distinguishing between two languages in a\ngiven text. This paper presents BLID for languages spoken in the southern part\nof Ethiopia, namely Wolaita and Gofa. The presence of words similarities and\ndifferences between the two languages makes the language identification task\nchallenging. To overcome this challenge, we employed various experiments on\nvarious approaches. Then, the combination of the BERT based pretrained language\nmodel and LSTM approach performed better, with an F1 score of 0.72 on the test\nset. As a result, the work will be effective in tackling unwanted social media\nissues and providing a foundation for further research in this area.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9488\u5bf9\u57c3\u585e\u4fc4\u6bd4\u4e9a\u5357\u90e8\u7684Wolaita\u548cGofa\u53cc\u8bed\u8bc6\u522b\u4efb\u52a1\uff0c\u63d0\u51fa\u7ed3\u5408BERT\u9884\u8bad\u7ec3\u6a21\u578b\u548cLSTM\u7684\u65b9\u6cd5\uff0c\u5728\u6d4b\u8bd5\u96c6\u4e0a\u53d6\u5f97\u4e860.72\u7684F1\u5206\u6570\u3002", "motivation": "\u5728\u591a\u8bed\u8a00\u793e\u533a\u4e2d\uff0c\u6587\u672c\u5e38\u5305\u542b\u591a\u79cd\u8bed\u8a00\uff0c\u800cWolaita\u548cGofa\u4e24\u79cd\u8bed\u8a00\u5b58\u5728\u8bcd\u6c47\u76f8\u4f3c\u6027\u548c\u5dee\u5f02\u6027\uff0c\u4f7f\u5f97\u8bed\u8a00\u8bc6\u522b\u4efb\u52a1\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u91c7\u7528\u591a\u79cd\u5b9e\u9a8c\u65b9\u6cd5\uff0c\u6700\u7ec8\u786e\u5b9aBERT\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u4e0eLSTM\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\u3002", "result": "BERT+LSTM\u7ec4\u5408\u65b9\u6cd5\u5728\u6d4b\u8bd5\u96c6\u4e0a\u8868\u73b0\u6700\u4f73\uff0cF1\u5206\u6570\u8fbe\u52300.72\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u80fd\u6709\u6548\u5904\u7406\u793e\u4ea4\u5a92\u4f53\u4e2d\u7684\u591a\u8bed\u8a00\u95ee\u9898\uff0c\u5e76\u4e3a\u8be5\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2509.08000", "pdf": "https://arxiv.org/pdf/2509.08000", "abs": "https://arxiv.org/abs/2509.08000", "authors": ["Debdeep Sanyal", "Manodeep Ray", "Murari Mandal"], "title": "AntiDote: Bi-level Adversarial Training for Tamper-Resistant LLMs", "categories": ["cs.CL"], "comment": "19 pages", "summary": "The release of open-weight large language models (LLMs) creates a tension\nbetween advancing accessible research and preventing misuse, such as malicious\nfine-tuning to elicit harmful content. Current safety measures struggle to\npreserve the general capabilities of the LLM while resisting a determined\nadversary with full access to the model's weights and architecture, who can use\nfull-parameter fine-tuning to erase existing safeguards. To address this, we\nintroduce AntiDote, a bi-level optimization procedure for training LLMs to be\nresistant to such tampering. AntiDote involves an auxiliary adversary\nhypernetwork that learns to generate malicious Low-Rank Adaptation (LoRA)\nweights conditioned on the defender model's internal activations. The defender\nLLM is then trained with an objective to nullify the effect of these\nadversarial weight additions, forcing it to maintain its safety alignment. We\nvalidate this approach against a diverse suite of 52 red-teaming attacks,\nincluding jailbreak prompting, latent space manipulation, and direct\nweight-space attacks. AntiDote is upto 27.4\\% more robust against adversarial\nattacks compared to both tamper-resistance and unlearning baselines. Crucially,\nthis robustness is achieved with a minimal trade-off in utility, incurring a\nperformance degradation of upto less than 0.5\\% across capability benchmarks\nincluding MMLU, HellaSwag, and GSM8K. Our work offers a practical and compute\nefficient methodology for building open-weight models where safety is a more\nintegral and resilient property.", "AI": {"tldr": "AntiDote\u662f\u4e00\u79cd\u53cc\u5c42\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bf9\u6297\u6027\u8d85\u7f51\u7edc\u8bad\u7ec3LLM\u62b5\u6297\u6076\u610f\u5fae\u8c03\u653b\u51fb\uff0c\u5728\u4fdd\u6301\u6a21\u578b\u80fd\u529b\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u5b89\u5168\u6027", "motivation": "\u5f00\u6e90\u6743\u91cdLLM\u9762\u4e34\u6076\u610f\u5fae\u8c03\u751f\u6210\u6709\u5bb3\u5185\u5bb9\u7684\u98ce\u9669\uff0c\u73b0\u6709\u5b89\u5168\u63aa\u65bd\u96be\u4ee5\u5728\u5b8c\u5168\u6a21\u578b\u8bbf\u95ee\u6743\u9650\u4e0b\u4fdd\u62a4\u6a21\u578b\u5b89\u5168", "method": "\u4f7f\u7528\u53cc\u5c42\u4f18\u5316\uff1a\u8f85\u52a9\u5bf9\u6297\u8d85\u7f51\u7edc\u5b66\u4e60\u751f\u6210\u6076\u610fLoRA\u6743\u91cd\uff0c\u4e3b\u6a21\u578b\u8bad\u7ec3\u76ee\u6807\u4e3a\u62b5\u6d88\u8fd9\u4e9b\u5bf9\u6297\u6743\u91cd\u7684\u5f71\u54cd", "result": "\u572852\u79cd\u7ea2\u961f\u653b\u51fb\u6d4b\u8bd5\u4e2d\uff0cAntiDote\u6bd4\u57fa\u51c6\u65b9\u6cd5\u5f3a27.4%\uff0c\u80fd\u529b\u57fa\u51c6\u6027\u80fd\u4e0b\u964d\u5c0f\u4e8e0.5%", "conclusion": "\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u4e14\u8ba1\u7b97\u9ad8\u6548\u7684\u65b9\u6cd5\uff0c\u4f7f\u5f00\u6e90\u6743\u91cd\u6a21\u578b\u7684\u5b89\u5168\u5c5e\u6027\u66f4\u52a0\u5185\u5728\u548c\u9c81\u68d2"}}
{"id": "2509.08022", "pdf": "https://arxiv.org/pdf/2509.08022", "abs": "https://arxiv.org/abs/2509.08022", "authors": ["Yao Liang", "Dongcheng Zhao", "Feifei Zhao", "Guobin Shen", "Yuwei Wang", "Dongqi Liang", "Yi Zeng"], "title": "MVPBench: A Benchmark and Fine-Tuning Framework for Aligning Large Language Models with Diverse Human Values", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The alignment of large language models (LLMs) with human values is critical\nfor their safe and effective deployment across diverse user populations.\nHowever, existing benchmarks often neglect cultural and demographic diversity,\nleading to limited understanding of how value alignment generalizes globally.\nIn this work, we introduce MVPBench, a novel benchmark that systematically\nevaluates LLMs' alignment with multi-dimensional human value preferences across\n75 countries. MVPBench contains 24,020 high-quality instances annotated with\nfine-grained value labels, personalized questions, and rich demographic\nmetadata, making it the most comprehensive resource of its kind to date. Using\nMVPBench, we conduct an in-depth analysis of several state-of-the-art LLMs,\nrevealing substantial disparities in alignment performance across geographic\nand demographic lines. We further demonstrate that lightweight fine-tuning\nmethods, such as Low-Rank Adaptation (LoRA) and Direct Preference Optimization\n(DPO), can significantly enhance value alignment in both in-domain and\nout-of-domain settings. Our findings underscore the necessity for\npopulation-aware alignment evaluation and provide actionable insights for\nbuilding culturally adaptive and value-sensitive LLMs. MVPBench serves as a\npractical foundation for future research on global alignment, personalized\nvalue modeling, and equitable AI development.", "AI": {"tldr": "MVPBench\u662f\u4e00\u4e2a\u5305\u542b75\u4e2a\u56fd\u5bb624,020\u4e2a\u5b9e\u4f8b\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u7cfb\u7edf\u8bc4\u4f30LLM\u4e0e\u591a\u7ef4\u4eba\u7c7b\u4ef7\u503c\u89c2\u7684\u5bf9\u9f50\u7a0b\u5ea6\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u5730\u7406\u548c\u4eba\u53e3\u7edf\u8ba1\u7fa4\u4f53\u95f4\u7684\u663e\u8457\u5dee\u5f02\uff0c\u5e76\u8bc1\u660e\u8f7b\u91cf\u7ea7\u5fae\u8c03\u65b9\u6cd5\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u5bf9\u9f50\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u5f80\u5f80\u5ffd\u89c6\u6587\u5316\u548c\u4eba\u53e3\u591a\u6837\u6027\uff0c\u5bfc\u81f4\u5bf9\u4ef7\u503c\u89c2\u5bf9\u9f50\u5728\u5168\u7403\u8303\u56f4\u5185\u6cdb\u5316\u80fd\u529b\u7684\u7406\u89e3\u6709\u9650\u3002", "method": "\u6784\u5efaMVPBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b\u7cbe\u7ec6\u4ef7\u503c\u89c2\u6807\u7b7e\u3001\u4e2a\u6027\u5316\u95ee\u9898\u548c\u4e30\u5bcc\u4eba\u53e3\u7edf\u8ba1\u5143\u6570\u636e\uff1b\u4f7f\u7528LoRA\u548cDPO\u7b49\u8f7b\u91cf\u7ea7\u5fae\u8c03\u65b9\u6cd5\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u53d1\u73b0\u6700\u5148\u8fdbLLM\u5728\u4e0d\u540c\u5730\u7406\u548c\u4eba\u53e3\u7edf\u8ba1\u7fa4\u4f53\u95f4\u5b58\u5728\u663e\u8457\u5bf9\u9f50\u6027\u80fd\u5dee\u5f02\uff1b\u8f7b\u91cf\u7ea7\u5fae\u8c03\u65b9\u6cd5\u5728\u57df\u5185\u548c\u57df\u5916\u8bbe\u7f6e\u4e2d\u90fd\u80fd\u663e\u8457\u63d0\u5347\u4ef7\u503c\u5bf9\u9f50\u6548\u679c\u3002", "conclusion": "\u9700\u8981\u57fa\u4e8e\u4eba\u53e3\u7edf\u8ba1\u7684\u5bf9\u9f50\u8bc4\u4f30\uff0cMVPBench\u4e3a\u5168\u7403\u5bf9\u9f50\u3001\u4e2a\u6027\u5316\u4ef7\u503c\u5efa\u6a21\u548c\u516c\u5e73AI\u53d1\u5c55\u63d0\u4f9b\u4e86\u5b9e\u7528\u57fa\u7840\u3002"}}
{"id": "2509.08025", "pdf": "https://arxiv.org/pdf/2509.08025", "abs": "https://arxiv.org/abs/2509.08025", "authors": ["Hoang-Trung Nguyen", "Tan-Minh Nguyen", "Xuan-Bach Le", "Tuan-Kiet Le", "Khanh-Huyen Nguyen", "Ha-Thanh Nguyen", "Thi-Hai-Yen Vuong", "Le-Minh Nguyen"], "title": "NOWJ@COLIEE 2025: A Multi-stage Framework Integrating Embedding Models and Large Language Models for Legal Retrieval and Entailment", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "This paper presents the methodologies and results of the NOWJ team's\nparticipation across all five tasks at the COLIEE 2025 competition, emphasizing\nadvancements in the Legal Case Entailment task (Task 2). Our comprehensive\napproach systematically integrates pre-ranking models (BM25, BERT, monoT5),\nembedding-based semantic representations (BGE-m3, LLM2Vec), and advanced Large\nLanguage Models (Qwen-2, QwQ-32B, DeepSeek-V3) for summarization, relevance\nscoring, and contextual re-ranking. Specifically, in Task 2, our two-stage\nretrieval system combined lexical-semantic filtering with contextualized LLM\nanalysis, achieving first place with an F1 score of 0.3195. Additionally, in\nother tasks--including Legal Case Retrieval, Statute Law Retrieval, Legal\nTextual Entailment, and Legal Judgment Prediction--we demonstrated robust\nperformance through carefully engineered ensembles and effective prompt-based\nreasoning strategies. Our findings highlight the potential of hybrid models\nintegrating traditional IR techniques with contemporary generative models,\nproviding a valuable reference for future advancements in legal information\nprocessing.", "AI": {"tldr": "NOWJ\u56e2\u961f\u5728COLIEE 2025\u7ade\u8d5b\u4e2d\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\uff0c\u7ed3\u5408\u4f20\u7edf\u68c0\u7d22\u6280\u672f\u548c\u73b0\u4ee3\u751f\u6210\u6a21\u578b\uff0c\u5728Legal Case Entailment\u4efb\u52a1\u4e2d\u83b7\u5f97\u7b2c\u4e00\u540d\uff0c\u5e76\u5728\u5176\u4ed6\u6cd5\u5f8b\u4fe1\u606f\u5904\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02", "motivation": "\u63a2\u7d22\u5c06\u4f20\u7edf\u4fe1\u606f\u68c0\u7d22\u6280\u672f\u4e0e\u5148\u8fdb\u5927\u8bed\u8a00\u6a21\u578b\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u63d0\u5347\u6cd5\u5f8b\u4fe1\u606f\u5904\u7406\u7684\u51c6\u786e\u6027\u548c\u6548\u7387", "method": "\u4e24\u9636\u6bb5\u68c0\u7d22\u7cfb\u7edf\uff1a\u7ed3\u5408\u8bcd\u4e49-\u8bed\u4e49\u8fc7\u6ee4\uff08BM25\u3001BERT\u3001monoT5\uff09\u548c\u4e0a\u4e0b\u6587LLM\u5206\u6790\uff08Qwen-2\u3001QwQ-32B\u3001DeepSeek-V3\uff09\uff0c\u4f7f\u7528BGE-m3\u548cLLM2Vec\u8fdb\u884c\u8bed\u4e49\u8868\u793a", "result": "Task 2\u4e2d\u83b7\u5f97\u7b2c\u4e00\u540d\uff0cF1\u5206\u65700.3195\uff1b\u5728\u5176\u4ed6\u6cd5\u5f8b\u4efb\u52a1\u4e2d\u4e5f\u5c55\u73b0\u51fa\u5f3a\u52b2\u6027\u80fd", "conclusion": "\u6df7\u5408\u6a21\u578b\u7ed3\u5408\u4f20\u7edfIR\u6280\u672f\u548c\u73b0\u4ee3\u751f\u6210\u6a21\u578b\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u4e3a\u6cd5\u5f8b\u4fe1\u606f\u5904\u7406\u7684\u672a\u6765\u53d1\u5c55\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u53c2\u8003"}}
{"id": "2509.08032", "pdf": "https://arxiv.org/pdf/2509.08032", "abs": "https://arxiv.org/abs/2509.08032", "authors": ["Fengyu She", "Nan Wang", "Hongfei Wu", "Ziyi Wan", "Jingmian Wang", "Chang Wang"], "title": "SciGPT: A Large Language Model for Scientific Literature Understanding and Knowledge Discovery", "categories": ["cs.CL"], "comment": null, "summary": "Scientific literature is growing exponentially, creating a critical\nbottleneck for researchers to efficiently synthesize knowledge. While\ngeneral-purpose Large Language Models (LLMs) show potential in text processing,\nthey often fail to capture scientific domain-specific nuances (e.g., technical\njargon, methodological rigor) and struggle with complex scientific tasks,\nlimiting their utility for interdisciplinary research. To address these gaps,\nthis paper presents SciGPT, a domain-adapted foundation model for scientific\nliterature understanding and ScienceBench, an open source benchmark tailored to\nevaluate scientific LLMs.\n  Built on the Qwen3 architecture, SciGPT incorporates three key innovations:\n(1) low-cost domain distillation via a two-stage pipeline to balance\nperformance and efficiency; (2) a Sparse Mixture-of-Experts (SMoE) attention\nmechanism that cuts memory consumption by 55\\% for 32,000-token long-document\nreasoning; and (3) knowledge-aware adaptation integrating domain ontologies to\nbridge interdisciplinary knowledge gaps.\n  Experimental results on ScienceBench show that SciGPT outperforms GPT-4o in\ncore scientific tasks including sequence labeling, generation, and inference.\nIt also exhibits strong robustness in unseen scientific tasks, validating its\npotential to facilitate AI-augmented scientific discovery.", "AI": {"tldr": "SciGPT\u662f\u4e00\u4e2a\u9488\u5bf9\u79d1\u5b66\u6587\u732e\u7406\u89e3\u7684\u9886\u57df\u9002\u5e94\u57fa\u7840\u6a21\u578b\uff0c\u901a\u8fc7\u4f4e\u6210\u672c\u7684\u9886\u57df\u84b8\u998f\u3001\u7a00\u758f\u4e13\u5bb6\u6df7\u5408\u6ce8\u610f\u529b\u673a\u5236\u548c\u77e5\u8bc6\u611f\u77e5\u9002\u5e94\u7b49\u521b\u65b0\u6280\u672f\uff0c\u5728\u79d1\u5b66\u4efb\u52a1\u4e0a\u8d85\u8d8a\u4e86GPT-4o\u7684\u8868\u73b0\u3002", "motivation": "\u79d1\u5b66\u6587\u732e\u5448\u6307\u6570\u7ea7\u589e\u957f\uff0c\u7814\u7a76\u4eba\u5458\u9700\u8981\u9ad8\u6548\u7684\u77e5\u8bc6\u5408\u6210\u5de5\u5177\u3002\u901a\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5728\u79d1\u5b66\u9886\u57df\u5b58\u5728\u5c40\u9650\u6027\uff0c\u65e0\u6cd5\u5f88\u597d\u5730\u5904\u7406\u4e13\u4e1a\u672f\u8bed\u3001\u65b9\u6cd5\u4e25\u8c28\u6027\u548c\u590d\u6742\u79d1\u5b66\u4efb\u52a1\uff0c\u9650\u5236\u4e86\u5176\u5728\u8de8\u5b66\u79d1\u7814\u7a76\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u57fa\u4e8eQwen3\u67b6\u6784\uff0c\u91c7\u7528\u4e09\u9636\u6bb5\u521b\u65b0\uff1a1\uff09\u4f4e\u6210\u672c\u9886\u57df\u84b8\u998f\u7684\u4e24\u9636\u6bb5\u6d41\u7a0b\u5e73\u8861\u6027\u80fd\u4e0e\u6548\u7387\uff1b2\uff09\u7a00\u758f\u4e13\u5bb6\u6df7\u5408\u6ce8\u610f\u529b\u673a\u5236\uff0c\u572832,000\u4e2atoken\u7684\u957f\u6587\u6863\u63a8\u7406\u4e2d\u51cf\u5c1155%\u5185\u5b58\u6d88\u8017\uff1b3\uff09\u77e5\u8bc6\u611f\u77e5\u9002\u5e94\u6574\u5408\u9886\u57df\u672c\u4f53\u4ee5\u5f25\u5408\u8de8\u5b66\u79d1\u77e5\u8bc6\u5dee\u8ddd\u3002", "result": "\u5728ScienceBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSciGPT\u5728\u5e8f\u5217\u6807\u6ce8\u3001\u751f\u6210\u548c\u63a8\u7406\u7b49\u6838\u5fc3\u79d1\u5b66\u4efb\u52a1\u4e0a\u8d85\u8d8a\u4e86GPT-4o\uff0c\u5e76\u5728\u672a\u89c1\u8fc7\u7684\u79d1\u5b66\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "SciGPT\u9a8c\u8bc1\u4e86\u5176\u5728\u4fc3\u8fdbAI\u589e\u5f3a\u79d1\u5b66\u53d1\u73b0\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u4e3a\u79d1\u5b66\u6587\u732e\u7406\u89e3\u548c\u8de8\u5b66\u79d1\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.08075", "pdf": "https://arxiv.org/pdf/2509.08075", "abs": "https://arxiv.org/abs/2509.08075", "authors": ["Flor Miriam Plaza-del-Arco", "Paul R\u00f6ttger", "Nino Scherrer", "Emanuele Borgonovo", "Elmar Plischke", "Dirk Hovy"], "title": "No for Some, Yes for Others: Persona Prompts and Other Sources of False Refusal in Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) are increasingly integrated into our daily lives\nand personalized. However, LLM personalization might also increase unintended\nside effects. Recent work suggests that persona prompting can lead models to\nfalsely refuse user requests. However, no work has fully quantified the extent\nof this issue. To address this gap, we measure the impact of 15\nsociodemographic personas (based on gender, race, religion, and disability) on\nfalse refusal. To control for other factors, we also test 16 different models,\n3 tasks (Natural Language Inference, politeness, and offensiveness\nclassification), and nine prompt paraphrases. We propose a Monte Carlo-based\nmethod to quantify this issue in a sample-efficient manner. Our results show\nthat as models become more capable, personas impact the refusal rate less and\nless. Certain sociodemographic personas increase false refusal in some models,\nwhich suggests underlying biases in the alignment strategies or safety\nmechanisms. However, we find that the model choice and task significantly\ninfluence false refusals, especially in sensitive content tasks. Our findings\nsuggest that persona effects have been overestimated, and might be due to other\nfactors.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0LLM\u4e2a\u6027\u5316\u53ef\u80fd\u5bfc\u81f4\u9519\u8bef\u62d2\u7edd\u8bf7\u6c42\uff0c\u4f46\u901a\u8fc7\u7cfb\u7edf\u6d4b\u8bd5\u53d1\u73b0\u6a21\u578b\u80fd\u529b\u548c\u4efb\u52a1\u7c7b\u578b\u5bf9\u9519\u8bef\u62d2\u7edd\u7684\u5f71\u54cd\u6bd4\u4eba\u7269\u8bbe\u5b9a\u66f4\u5927\uff0c\u4eba\u7269\u8bbe\u5b9a\u6548\u5e94\u53ef\u80fd\u88ab\u9ad8\u4f30", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65e5\u76ca\u4e2a\u6027\u5316\uff0c\u4f46\u4eba\u7269\u8bbe\u5b9a\u63d0\u793a\u53ef\u80fd\u5bfc\u81f4\u6a21\u578b\u9519\u8bef\u62d2\u7edd\u7528\u6237\u8bf7\u6c42\uff0c\u9700\u8981\u91cf\u5316\u8fd9\u79cd\u95ee\u9898\u7684\u7a0b\u5ea6", "method": "\u4f7f\u752815\u79cd\u793e\u4f1a\u4eba\u53e3\u7edf\u8ba1\u4eba\u7269\u8bbe\u5b9a\u300116\u4e2a\u6a21\u578b\u30013\u79cd\u4efb\u52a1\u548c9\u79cd\u63d0\u793a\u53d8\u4f53\u8fdb\u884c\u6d4b\u8bd5\uff0c\u63d0\u51fa\u8499\u7279\u5361\u6d1b\u65b9\u6cd5\u8fdb\u884c\u6837\u672c\u9ad8\u6548\u91cf\u5316", "result": "\u6a21\u578b\u80fd\u529b\u8d8a\u5f3a\uff0c\u4eba\u7269\u8bbe\u5b9a\u5bf9\u62d2\u7edd\u7387\u5f71\u54cd\u8d8a\u5c0f\uff1b\u67d0\u4e9b\u793e\u4f1a\u4eba\u53e3\u7edf\u8ba1\u4eba\u7269\u8bbe\u5b9a\u4f1a\u589e\u52a0\u9519\u8bef\u62d2\u7edd\uff0c\u4f46\u6a21\u578b\u9009\u62e9\u548c\u4efb\u52a1\u7c7b\u578b\u5f71\u54cd\u66f4\u5927", "conclusion": "\u4eba\u7269\u8bbe\u5b9a\u6548\u5e94\u53ef\u80fd\u88ab\u9ad8\u4f30\uff0c\u9519\u8bef\u62d2\u7edd\u66f4\u591a\u53d7\u6a21\u578b\u80fd\u529b\u548c\u4efb\u52a1\u654f\u611f\u5ea6\u5f71\u54cd\uff0c\u800c\u975e\u4eba\u7269\u8bbe\u5b9a\u672c\u8eab"}}
{"id": "2509.08093", "pdf": "https://arxiv.org/pdf/2509.08093", "abs": "https://arxiv.org/abs/2509.08093", "authors": ["Nathaniel Imel", "Noga Zaslavsky"], "title": "Culturally transmitted color categories in LLMs reflect a learning bias toward efficient compression", "categories": ["cs.CL"], "comment": null, "summary": "Converging evidence suggests that systems of semantic categories across human\nlanguages achieve near-optimal compression via the Information Bottleneck (IB)\ncomplexity-accuracy principle. Large language models (LLMs) are not trained for\nthis objective, which raises the question: are LLMs capable of evolving\nefficient human-like semantic systems? To address this question, we focus on\nthe domain of color as a key testbed of cognitive theories of categorization\nand replicate with LLMs (Gemini 2.0-flash and Llama 3.3-70B-Instruct) two\ninfluential human behavioral studies. First, we conduct an English color-naming\nstudy, showing that Gemini aligns well with the naming patterns of native\nEnglish speakers and achieves a significantly high IB-efficiency score, while\nLlama exhibits an efficient but lower complexity system compared to English.\nSecond, to test whether LLMs simply mimic patterns in their training data or\nactually exhibit a human-like inductive bias toward IB-efficiency, we simulate\ncultural evolution of pseudo color-naming systems in LLMs via iterated\nin-context language learning. We find that akin to humans, LLMs iteratively\nrestructure initially random systems towards greater IB-efficiency and\nincreased alignment with patterns observed across the world's languages. These\nfindings demonstrate that LLMs are capable of evolving perceptually grounded,\nhuman-like semantic systems, driven by the same fundamental principle that\ngoverns semantic efficiency across human languages.", "AI": {"tldr": "\u7814\u7a76\u8868\u660eLLMs\u80fd\u591f\u901a\u8fc7\u4fe1\u606f\u74f6\u9888\u539f\u5219\u6f14\u5316\u51fa\u7c7b\u4f3c\u4eba\u7c7b\u7684\u9ad8\u6548\u8bed\u4e49\u7cfb\u7edf\uff0c\u5728\u989c\u8272\u547d\u540d\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4e0e\u4eba\u7c7b\u76f8\u4f3c\u7684\u538b\u7f29\u6548\u7387\u548c\u8de8\u6587\u5316\u5bf9\u9f50\u6a21\u5f0f", "motivation": "\u63a2\u7d22\u5927\u578b\u8bed\u8a00\u6a21\u578b\u662f\u5426\u80fd\u591f\u50cf\u4eba\u7c7b\u8bed\u8a00\u4e00\u6837\uff0c\u901a\u8fc7\u4fe1\u606f\u74f6\u9888\u539f\u5219\u6f14\u5316\u51fa\u9ad8\u6548\u7684\u8bed\u4e49\u5206\u7c7b\u7cfb\u7edf\uff0c\u800c\u4e0d\u662f\u4ec5\u4ec5\u6a21\u4eff\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u6a21\u5f0f", "method": "\u4f7f\u7528Gemini 2.0-flash\u548cLlama 3.3-70B-Instruct\u6a21\u578b\uff0c\u590d\u5236\u4e24\u4e2a\u4eba\u7c7b\u884c\u4e3a\u7814\u7a76\uff1a\u82f1\u8bed\u989c\u8272\u547d\u540d\u7814\u7a76\u548c\u901a\u8fc7\u4e0a\u4e0b\u6587\u5b66\u4e60\u6a21\u62df\u6587\u5316\u6f14\u5316\u8fc7\u7a0b", "result": "Gemini\u4e0e\u82f1\u8bed\u6bcd\u8bed\u8005\u7684\u547d\u540d\u6a21\u5f0f\u9ad8\u5ea6\u4e00\u81f4\u4e14\u83b7\u5f97\u9ad8IB\u6548\u7387\u5206\u6570\uff0cLlama\u8868\u73b0\u51fa\u9ad8\u6548\u4f46\u590d\u6742\u5ea6\u8f83\u4f4e\u7684\u7cfb\u7edf\uff1b\u4e24\u79cd\u6a21\u578b\u90fd\u80fd\u901a\u8fc7\u8fed\u4ee3\u5b66\u4e60\u5c06\u968f\u673a\u7cfb\u7edf\u91cd\u6784\u4e3a\u66f4\u9ad8IB\u6548\u7387", "conclusion": "LLMs\u80fd\u591f\u6f14\u5316\u51fa\u57fa\u4e8e\u611f\u77e5\u7684\u3001\u7c7b\u4f3c\u4eba\u7c7b\u7684\u8bed\u4e49\u7cfb\u7edf\uff0c\u5176\u9a71\u52a8\u539f\u7406\u4e0e\u4eba\u7c7b\u8bed\u8a00\u8bed\u4e49\u6548\u7387\u7684\u57fa\u672c\u539f\u7406\u76f8\u540c"}}
{"id": "2509.08105", "pdf": "https://arxiv.org/pdf/2509.08105", "abs": "https://arxiv.org/abs/2509.08105", "authors": ["Kosei Uemura", "David Guzm\u00e1n", "Quang Phuoc Nguyen", "Jesujoba Oluwadara Alabi", "En-shiun Annie Lee", "David Ifeoluwa Adelani"], "title": "MERLIN: Multi-Stage Curriculum Alignment for Multilingual Encoder and LLM Fusion", "categories": ["cs.CL"], "comment": "under submission", "summary": "Large language models excel in English but still struggle with complex\nreasoning in many low-resource languages (LRLs). Existing encoder-plus-decoder\nmethods such as LangBridge and MindMerger raise accuracy on mid and\nhigh-resource languages, yet they leave a large gap on LRLs. We present MERLIN,\na two-stage model-stacking framework that applies a curriculum learning\nstrategy -- from general bilingual bitext to task-specific data -- and adapts\nonly a small set of DoRA weights. On the AfriMGSM benchmark MERLIN improves\nexact-match accuracy by +12.9 pp over MindMerger and outperforms GPT-4o-mini.\nIt also yields consistent gains on MGSM and MSVAMP (+0.9 and +2.8 pp),\ndemonstrating effectiveness across both low and high-resource settings.", "AI": {"tldr": "MERLIN\u662f\u4e00\u4e2a\u4e24\u9636\u6bb5\u6a21\u578b\u5806\u53e0\u6846\u67b6\uff0c\u901a\u8fc7\u8bfe\u7a0b\u5b66\u4e60\u7b56\u7565\u548cDoRA\u6743\u91cd\u9002\u914d\uff0c\u663e\u8457\u63d0\u5347\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u590d\u6742\u63a8\u7406\u80fd\u529b\uff0c\u5728AfriMGSM\u57fa\u51c6\u4e0a\u6bd4MindMerger\u51c6\u786e\u7387\u63d0\u534712.9\u4e2a\u767e\u5206\u70b9\uff0c\u751a\u81f3\u8d85\u8d8aGPT-4o-mini\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u82f1\u8bed\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u8bb8\u591a\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u4ecd\u7136\u5b58\u5728\u56f0\u96be\u3002\u73b0\u6709\u7684\u7f16\u7801\u5668-\u89e3\u7801\u5668\u65b9\u6cd5\u5bf9\u4e2d\u9ad8\u8d44\u6e90\u8bed\u8a00\u6709\u6548\uff0c\u4f46\u5bf9\u4f4e\u8d44\u6e90\u8bed\u8a00\u6548\u679c\u6709\u9650\u3002", "method": "\u63d0\u51faMERLIN\u4e24\u9636\u6bb5\u6a21\u578b\u5806\u53e0\u6846\u67b6\uff1a1\uff09\u91c7\u7528\u8bfe\u7a0b\u5b66\u4e60\u7b56\u7565\uff0c\u4ece\u901a\u7528\u53cc\u8bed\u6587\u672c\u5230\u4efb\u52a1\u7279\u5b9a\u6570\u636e\u9010\u6b65\u5b66\u4e60\uff1b2\uff09\u4ec5\u9002\u914d\u5c11\u91cfDoRA\u6743\u91cd\u8fdb\u884c\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u3002", "result": "\u5728AfriMGSM\u57fa\u51c6\u4e0a\u51c6\u786e\u7387\u6bd4MindMerger\u63d0\u5347+12.9pp\uff0c\u8d85\u8d8aGPT-4o-mini\uff1b\u5728MGSM\u548cMSVAMP\u4e0a\u4e5f\u5206\u522b\u83b7\u5f97+0.9pp\u548c+2.8pp\u7684\u7a33\u5b9a\u63d0\u5347\uff0c\u8bc1\u660e\u5728\u4f4e\u8d44\u6e90\u548c\u9ad8\u8d44\u6e90\u8bbe\u7f6e\u4e0b\u5747\u6709\u6548\u3002", "conclusion": "MERLIN\u6846\u67b6\u901a\u8fc7\u521b\u65b0\u7684\u8bfe\u7a0b\u5b66\u4e60\u548c\u53c2\u6570\u9ad8\u6548\u9002\u914d\u65b9\u6cd5\uff0c\u663e\u8457\u6539\u5584\u4e86\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u590d\u6742\u63a8\u7406\u6027\u80fd\uff0c\u4e3a\u591a\u8bed\u8a00NLP\u4efb\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.08146", "pdf": "https://arxiv.org/pdf/2509.08146", "abs": "https://arxiv.org/abs/2509.08146", "authors": ["Nivedha Sivakumar", "Natalie Mackraz", "Samira Khorshidi", "Krishna Patel", "Barry-John Theobald", "Luca Zappella", "Nicholas Apostoloff"], "title": "Bias after Prompting: Persistent Discrimination in Large Language Models", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "A dangerous assumption that can be made from prior work on the bias transfer\nhypothesis (BTH) is that biases do not transfer from pre-trained large language\nmodels (LLMs) to adapted models. We invalidate this assumption by studying the\nBTH in causal models under prompt adaptations, as prompting is an extremely\npopular and accessible adaptation strategy used in real-world applications. In\ncontrast to prior work, we find that biases can transfer through prompting and\nthat popular prompt-based mitigation methods do not consistently prevent biases\nfrom transferring. Specifically, the correlation between intrinsic biases and\nthose after prompt adaptation remain moderate to strong across demographics and\ntasks -- for example, gender (rho >= 0.94) in co-reference resolution, and age\n(rho >= 0.98) and religion (rho >= 0.69) in question answering. Further, we\nfind that biases remain strongly correlated when varying few-shot composition\nparameters, such as sample size, stereotypical content, occupational\ndistribution and representational balance (rho >= 0.90). We evaluate several\nprompt-based debiasing strategies and find that different approaches have\ndistinct strengths, but none consistently reduce bias transfer across models,\ntasks or demographics. These results demonstrate that correcting bias, and\npotentially improving reasoning ability, in intrinsic models may prevent\npropagation of biases to downstream tasks.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2509.08150", "pdf": "https://arxiv.org/pdf/2509.08150", "abs": "https://arxiv.org/abs/2509.08150", "authors": ["Supriya Lall", "Christian Farrell", "Hari Pathanjaly", "Marko Pavic", "Sarvesh Chezhian", "Masataro Asai"], "title": "Verbalized Algorithms", "categories": ["cs.CL"], "comment": "Submitted to NeurIPS 2025 Workshop on Efficient Reasoning", "summary": "Instead of querying LLMs in a one-shot manner and hoping to get the right\nanswer for a reasoning task, we propose a paradigm we call \\emph{verbalized\nalgorithms} (VAs), which leverage classical algorithms with established\ntheoretical understanding. VAs decompose a task into simple elementary\noperations on natural language strings that they should be able to answer\nreliably, and limit the scope of LLMs to only those simple tasks. For example,\nfor sorting a series of natural language strings, \\emph{verbalized sorting}\nuses an LLM as a binary comparison oracle in a known and well-analyzed sorting\nalgorithm (e.g., bitonic sorting network). We demonstrate the effectiveness of\nthis approach on sorting and clustering tasks.", "AI": {"tldr": "\u63d0\u51faverbalized algorithms\u65b9\u6cd5\uff0c\u5c06\u590d\u6742\u4efb\u52a1\u5206\u89e3\u4e3aLLM\u80fd\u591f\u53ef\u9760\u5904\u7406\u7684\u7b80\u5355\u81ea\u7136\u8bed\u8a00\u64cd\u4f5c\uff0c\u4f7f\u7528\u7ecf\u5178\u7b97\u6cd5\u6846\u67b6\u6765\u4fdd\u8bc1\u7406\u8bba\u53ef\u9760\u6027", "motivation": "\u4f20\u7edf\u7684\u4e00\u6b21\u6027\u67e5\u8be2LLM\u65b9\u5f0f\u65e0\u6cd5\u4fdd\u8bc1\u63a8\u7406\u4efb\u52a1\u7684\u6b63\u786e\u6027\uff0c\u9700\u8981\u5229\u7528\u7ecf\u5178\u7b97\u6cd5\u7684\u7406\u8bba\u4fdd\u969c\u6765\u63d0\u5347LLM\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u53ef\u9760\u6027", "method": "\u5c06\u4efb\u52a1\u5206\u89e3\u4e3a\u7b80\u5355\u7684\u81ea\u7136\u8bed\u8a00\u57fa\u672c\u64cd\u4f5c\uff0c\u8ba9LLM\u53ea\u8d1f\u8d23\u8fd9\u4e9b\u53ef\u9760\u7684\u5c0f\u4efb\u52a1\uff0c\u5728\u7ecf\u5178\u7b97\u6cd5\u6846\u67b6\uff08\u5982\u6392\u5e8f\u7f51\u7edc\uff09\u4e2d\u4f5c\u4e3a\u6bd4\u8f83\u5668\u7b49\u57fa\u7840\u7ec4\u4ef6", "result": "\u5728\u6392\u5e8f\u548c\u805a\u7c7b\u4efb\u52a1\u4e0a\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027", "conclusion": "verbalized algorithms\u65b9\u6cd5\u901a\u8fc7\u7ed3\u5408\u7ecf\u5178\u7b97\u6cd5\u7406\u8bba\u548cLLM\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u80fd\u529b\uff0c\u80fd\u591f\u53ef\u9760\u5730\u5b8c\u6210\u590d\u6742\u63a8\u7406\u4efb\u52a1"}}
{"id": "2509.08217", "pdf": "https://arxiv.org/pdf/2509.08217", "abs": "https://arxiv.org/abs/2509.08217", "authors": ["Eve Fleisig", "Matthias Orlikowski", "Philipp Cimiano", "Dan Klein"], "title": "Balancing Quality and Variation: Spam Filtering Distorts Data Label Distributions", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "For machine learning datasets to accurately represent diverse opinions in a\npopulation, they must preserve variation in data labels while filtering out\nspam or low-quality responses. How can we balance annotator reliability and\nrepresentation? We empirically evaluate how a range of heuristics for annotator\nfiltering affect the preservation of variation on subjective tasks. We find\nthat these methods, designed for contexts in which variation from a single\nground-truth label is considered noise, often remove annotators who disagree\ninstead of spam annotators, introducing suboptimal tradeoffs between accuracy\nand label diversity. We find that conservative settings for annotator removal\n(<5%) are best, after which all tested methods increase the mean absolute error\nfrom the true average label. We analyze performance on synthetic spam to\nobserve that these methods often assume spam annotators are less random than\nreal spammers tend to be: most spammers are distributionally indistinguishable\nfrom real annotators, and the minority that are distinguishable tend to give\nfixed answers, not random ones. Thus, tasks requiring the preservation of\nvariation reverse the intuition of existing spam filtering methods: spammers\ntend to be less random than non-spammers, so metrics that assume variation is\nspam fare worse. These results highlight the need for spam removal methods that\naccount for label diversity.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7814\u7a76\u4e3b\u89c2\u6807\u6ce8\u4efb\u52a1\u4e2d\u5982\u4f55\u5728\u8fc7\u6ee4\u5783\u573e\u6807\u6ce8\u8005\u7684\u540c\u65f6\u4fdd\u6301\u6807\u7b7e\u591a\u6837\u6027\u3002\u53d1\u73b0\u73b0\u6709\u8fc7\u6ee4\u65b9\u6cd5\u5bb9\u6613\u5220\u9664\u4e0d\u540c\u610f\u89c1\u800c\u975e\u5783\u573e\u6807\u6ce8\u8005\uff0c\u4f18\u5316\u8bbe\u7f6e\u662f\u79fb\u9664<5%\u6807\u6ce8\u8005\u3002\u5783\u573e\u6807\u6ce8\u8005\u901a\u5e38\u66f4\u4e0d\u968f\u673a\uff0c\u800c\u73b0\u6709\u65b9\u6cd5\u5047\u8bbe\u53d8\u5f02\u662f\u5783\u573e\u7684\u76f4\u89c9\u662f\u9519\u8bef\u7684\u3002", "motivation": "\u5728\u4e3b\u89c2\u6807\u6ce8\u4efb\u52a1\u4e2d\uff0c\u65e2\u8981\u8fc7\u6ee4\u5783\u573e\u6216\u4f4e\u8d28\u91cf\u6807\u6ce8\uff0c\u53c8\u8981\u4fdd\u6301\u6807\u7b7e\u7684\u591a\u6837\u6027\u548c\u4e0d\u540c\u610f\u89c1\u3002\u9700\u8981\u627e\u5230\u6807\u6ce8\u8005\u53ef\u9760\u6027\u548c\u4ee3\u8868\u6027\u4e4b\u95f4\u7684\u5e73\u8861\u3002", "method": "\u901a\u8fc7\u5b9e\u8bc1\u8bc4\u4f30\u4e00\u7cfb\u5217\u6807\u6ce8\u8005\u8fc7\u6ee4\u6070\u8bca\u5bf9\u4fdd\u6301\u4e3b\u89c2\u4efb\u52a1\u6807\u7b7e\u53d8\u5f02\u7684\u5f71\u54cd\uff0c\u5206\u6790\u7efc\u5408\u5783\u573e\u6570\u636e\u6765\u89c2\u5bdf\u5783\u573e\u6807\u6ce8\u8005\u7684\u884c\u4e3a\u7279\u5f81\u3002", "result": "\u53d1\u73b0\u73b0\u6709\u8fc7\u6ee4\u65b9\u6cd5\u5e38\u5c06\u4e0d\u540c\u610f\u89c1\u6807\u6ce8\u8005\u8bef\u5220\u4e3a\u5783\u573e\uff0c\u6700\u4f18\u8bbe\u7f6e\u662f\u79fb\u9664<5%\u6807\u6ce8\u8005\u3002\u5783\u573e\u6807\u6ce8\u8005\u901a\u5e38\u66f4\u4e0d\u968f\u673a\uff08\u7ed9\u51fa\u56fa\u5b9a\u7b54\u6848\uff09\uff0c\u800c\u73b0\u6709\u65b9\u6cd5\u5047\u8bbe\u53d8\u5f02\u662f\u5783\u573e\u7684\u76f4\u89c9\u662f\u9519\u8bef\u7684\u3002", "conclusion": "\u4e3b\u89c2\u4efb\u52a1\u4e2d\u4fdd\u6301\u6807\u7b7e\u591a\u6837\u6027\u9700\u8981\u65b0\u7684\u5783\u573e\u8fc7\u6ee4\u65b9\u6cd5\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u5e94\u8003\u8651\u5230\u5783\u573e\u6807\u6ce8\u8005\u901a\u5e38\u66f4\u4e0d\u968f\u673a\u7684\u7279\u5f81\uff0c\u800c\u4e0d\u662f\u5c06\u53d8\u5f02\u89c6\u4e3a\u5783\u573e\u3002"}}
{"id": "2509.08304", "pdf": "https://arxiv.org/pdf/2509.08304", "abs": "https://arxiv.org/abs/2509.08304", "authors": ["Yehudit Aperstein", "Alon Gottlib", "Gal Benita", "Alexander Apartsin"], "title": "Towards Knowledge-Aware Document Systems: Modeling Semantic Coverage Relations via Answerability Detection", "categories": ["cs.CL"], "comment": "27 pages, 1 figure", "summary": "Understanding how information is shared across documents, regardless of the\nformat in which it is expressed, is critical for tasks such as information\nretrieval, summarization, and content alignment. In this work, we introduce a\nnovel framework for modelling Semantic Coverage Relations (SCR), which\nclassifies document pairs based on how their informational content aligns. We\ndefine three core relation types: equivalence, where both texts convey the same\ninformation using different textual forms or styles; inclusion, where one\ndocument fully contains the information of another and adds more; and semantic\noverlap, where each document presents partially overlapping content. To capture\nthese relations, we adopt a question answering (QA)-based approach, using the\nanswerability of shared questions across documents as an indicator of semantic\ncoverage. We construct a synthetic dataset derived from the SQuAD corpus by\nparaphrasing source passages and selectively omitting information, enabling\nprecise control over content overlap. This dataset allows us to benchmark\ngenerative language models and train transformer-based classifiers for SCR\nprediction. Our findings demonstrate that discriminative models significantly\noutperform generative approaches, with the RoBERTa-base model achieving the\nhighest accuracy of 61.4% and the Random Forest-based model showing the best\nbalance with a macro-F1 score of 52.9%. The results show that QA provides an\neffective lens for assessing semantic relations across stylistically diverse\ntexts, offering insights into the capacity of current models to reason about\ninformation beyond surface similarity. The dataset and code developed in this\nstudy are publicly available to support reproducibility.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u95ee\u9898\u56de\u7b54\u7684\u65b9\u6cd5\u6765\u6a21\u578b\u8bed\u4e49\u8986\u76d6\u5173\u7cfb\uff0c\u5c06\u6587\u6863\u5bf9\u5206\u4e3a\u7b49\u4ef7\u3001\u5305\u542b\u548c\u91cd\u53e0\u4e09\u79cd\u5173\u7cfb\uff0c\u901a\u8fc7\u7efc\u5408\u6027\u6570\u636e\u96c6\u8bc4\u6d4b\u53d1\u73b0\u5224\u522b\u6a21\u578b\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u7406\u89e3\u4e0d\u540c\u683c\u5f0f\u6587\u6863\u4e4b\u95f4\u7684\u4fe1\u606f\u5171\u4eab\u65b9\u5f0f\u5bf9\u4fe1\u606f\u68c0\u7d22\u3001\u6458\u8981\u751f\u6210\u7b49\u4efb\u52a1\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u8bc6\u522b\u8bed\u4e49\u8986\u76d6\u5173\u7cfb\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u95ee\u9898\u56de\u7b54\u57fa\u7840\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u6587\u6863\u5bf9\u5171\u4eab\u95ee\u9898\u7684\u56de\u7b54\u80fd\u529b\u6765\u8bc6\u522b\u8bed\u4e49\u5173\u7cfb\u3002\u4f7f\u7528SQuAD\u8bed\u6599\u5e93\u6784\u5efa\u7efc\u5408\u6027\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u91cd\u5199\u548c\u9009\u62e9\u6027\u7701\u7565\u4fe1\u606f\u6765\u63a7\u5236\u5185\u5bb9\u91cd\u53e0\u7a0b\u5ea6\u3002", "result": "\u5224\u522b\u6a21\u578b\u663e\u8457\u8d85\u8fc7\u751f\u6210\u6a21\u578b\uff0cRoBERTa-base\u6a21\u578b\u8fbe\u5230\u6700\u9ad8\u51c6\u786e\u738761.4%\uff0cRandom Forest\u6a21\u578b\u5728\u5e73\u5747F1\u5206\u6570\u4e0a\u8868\u73b0\u6700\u4f73\uff0852.9%\uff09\u3002", "conclusion": "\u95ee\u9898\u56de\u7b54\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89c6\u89d2\u6765\u8bc4\u4f30\u4e0d\u540c\u98ce\u683c\u6587\u672c\u95f4\u7684\u8bed\u4e49\u5173\u7cfb\uff0c\u4e3a\u73b0\u6709\u6a21\u578b\u7684\u8bed\u4e49\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
{"id": "2509.08345", "pdf": "https://arxiv.org/pdf/2509.08345", "abs": "https://arxiv.org/abs/2509.08345", "authors": ["Alejandro Andrade-Lotero", "Lee Becker", "Joshua Southerland", "Scott Hellman"], "title": "Toward Subtrait-Level Model Explainability in Automated Writing Evaluation", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to National Council on Measurement in Education (NCME) 2025\n  Annual Meeting", "summary": "Subtrait (latent-trait components) assessment presents a promising path\ntoward enhancing transparency of automated writing scores. We prototype\nexplainability and subtrait scoring with generative language models and show\nmodest correlation between human subtrait and trait scores, and between\nautomated and human subtrait scores. Our approach provides details to demystify\nscores for educators and students.", "AI": {"tldr": "\u4f7f\u7528\u751f\u6210\u5f0f\u8bed\u8a00\u6a21\u578b\u5b9e\u73b0\u5199\u4f5c\u8bc4\u5206\u7684\u6f5c\u5728\u7279\u8d28\u7ec4\u4ef6\u8bc4\u4f30\uff0c\u63d0\u9ad8\u8bc4\u5206\u900f\u660e\u5ea6", "motivation": "\u901a\u8fc7\u6f5c\u5728\u7279\u8d28\u7ec4\u4ef6\u8bc4\u4f30\u63d0\u9ad8\u81ea\u52a8\u5316\u5199\u4f5c\u8bc4\u5206\u7684\u900f\u660e\u5ea6\uff0c\u4e3a\u6559\u80b2\u5de5\u4f5c\u8005\u548c\u5b66\u751f\u63d0\u4f9b\u66f4\u8be6\u7ec6\u7684\u8bc4\u5206\u89e3\u91ca", "method": "\u4f7f\u7528\u751f\u6210\u5f0f\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u539f\u578b\u5f00\u53d1\uff0c\u5b9e\u73b0\u89e3\u91ca\u6027\u548c\u5b50\u7279\u8d28\u8bc4\u5206\u529f\u80fd", "result": "\u4eba\u5de5\u5b50\u7279\u8d28\u4e0e\u603b\u7279\u8d28\u8bc4\u5206\u3001\u4ee5\u53ca\u81ea\u52a8\u5316\u4e0e\u4eba\u5de5\u5b50\u7279\u8d28\u8bc4\u5206\u4e4b\u95f4\u5747\u5448\u73b0\u4e2d\u7b49\u76f8\u5173\u6027", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u63d0\u4f9b\u8be6\u7ec6\u7684\u8bc4\u5206\u4fe1\u606f\uff0c\u5e2e\u52a9\u6559\u80b2\u8005\u548c\u5b66\u751f\u66f4\u597d\u5730\u7406\u89e3\u8bc4\u5206\u7ed3\u679c"}}
{"id": "2509.08355", "pdf": "https://arxiv.org/pdf/2509.08355", "abs": "https://arxiv.org/abs/2509.08355", "authors": ["Yashad Samant", "Lee Becker", "Scott Hellman", "Bradley Behan", "Sarah Hughes", "Joshua Southerland"], "title": "Automatic Detection of Inauthentic Templated Responses in English Language Assessments", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to National Council on Measurement in Education (NCME) 2025\n  Annual Meeting", "summary": "In high-stakes English Language Assessments, low-skill test takers may employ\nmemorized materials called ``templates'' on essay questions to ``game'' or fool\nthe automated scoring system. In this study, we introduce the automated\ndetection of inauthentic, templated responses (AuDITR) task, describe a machine\nlearning-based approach to this task and illustrate the importance of regularly\nupdating these models in production.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u52a8\u5316\u68c0\u6d4b\u6a21\u677f\u5316\u4f5c\u6587\u7684\u65b9\u6cd5AuDITR\uff0c\u7528\u4e8e\u8bc6\u522b\u82f1\u8bed\u8003\u8bd5\u4e2d\u8003\u751f\u4f7f\u7528\u80cc\u8bf5\u6a21\u677f\u6b3a\u9a97\u8bc4\u5206\u7cfb\u7edf\u7684\u884c\u4e3a", "motivation": "\u5728\u82f1\u8bed\u8bed\u8a00\u8bc4\u4f30\u4e2d\uff0c\u4f4e\u6c34\u5e73\u8003\u751f\u53ef\u80fd\u4f7f\u7528\u80cc\u8bf5\u7684\u6a21\u677f\u6750\u6599\u6765\u6b3a\u9a97\u81ea\u52a8\u5316\u8bc4\u5206\u7cfb\u7edf\uff0c\u9700\u8981\u68c0\u6d4b\u8fd9\u79cd\u4e0d\u771f\u5b9e\u7684\u6a21\u677f\u5316\u56de\u7b54", "method": "\u91c7\u7528\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u6765\u81ea\u52a8\u68c0\u6d4b\u6a21\u677f\u5316\u56de\u7b54\uff0c\u5e76\u5f3a\u8c03\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u9700\u8981\u5b9a\u671f\u66f4\u65b0\u8fd9\u4e9b\u6a21\u578b", "result": "\u63d0\u51fa\u4e86AuDITR\u4efb\u52a1\u6846\u67b6\u548c\u673a\u5668\u5b66\u4e60\u89e3\u51b3\u65b9\u6848", "conclusion": "\u81ea\u52a8\u5316\u68c0\u6d4b\u6a21\u677f\u5316\u56de\u7b54\u5bf9\u4e8e\u7ef4\u62a4\u8003\u8bd5\u516c\u5e73\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4e14\u9700\u8981\u6301\u7eed\u66f4\u65b0\u68c0\u6d4b\u6a21\u578b\u4ee5\u5e94\u5bf9\u65b0\u7684\u6a21\u677f\u7b56\u7565"}}
{"id": "2509.08358", "pdf": "https://arxiv.org/pdf/2509.08358", "abs": "https://arxiv.org/abs/2509.08358", "authors": ["Sergey Pletenev", "Daniil Moskovskiy", "Alexander Panchenko"], "title": "<think> So let's replace this phrase with insult... </think> Lessons learned from generation of toxic texts with LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Modern Large Language Models (LLMs) are excellent at generating synthetic\ndata. However, their performance in sensitive domains such as text\ndetoxification has not received proper attention from the scientific community.\nThis paper explores the possibility of using LLM-generated synthetic toxic data\nas an alternative to human-generated data for training models for\ndetoxification. Using Llama 3 and Qwen activation-patched models, we generated\nsynthetic toxic counterparts for neutral texts from ParaDetox and SST-2\ndatasets. Our experiments show that models fine-tuned on synthetic data\nconsistently perform worse than those trained on human data, with a drop in\nperformance of up to 30% in joint metrics. The root cause is identified as a\ncritical lexical diversity gap: LLMs generate toxic content using a small,\nrepetitive vocabulary of insults that fails to capture the nuances and variety\nof human toxicity. These findings highlight the limitations of current LLMs in\nthis domain and emphasize the continued importance of diverse, human-annotated\ndata for building robust detoxification systems.", "AI": {"tldr": "\u4f7f\u7528LLM\u751f\u6210\u7684\u5408\u6210\u6bd2\u6027\u6570\u636e\u8bad\u7ec3\u53bb\u6bd2\u6a21\u578b\u6548\u679c\u8f83\u4eba\u7c7b\u6570\u636e\u5dee30%\uff0c\u4e3b\u8981\u539f\u56e0\u662fLLM\u8bcd\u6c47\u591a\u6837\u6027\u4e0d\u8db3", "motivation": "\u63a2\u7d22LLM\u751f\u6210\u7684\u5408\u6210\u6bd2\u6027\u6570\u636e\u662f\u5426\u53ef\u4ee5\u66ff\u4ee3\u4eba\u7c7b\u6570\u636e\u7528\u4e8e\u6587\u672c\u53bb\u6bd2\u6a21\u578b\u8bad\u7ec3", "method": "\u4f7f\u7528Llama 3\u548cQwen\u6fc0\u6d3b\u8865\u4e01\u6a21\u578b\u4e3aParaDetox\u548cSST-2\u6570\u636e\u96c6\u4e2d\u7684\u4e2d\u6027\u6587\u672c\u751f\u6210\u5408\u6210\u6bd2\u6027\u5bf9\u5e94\u7247\u6bb5\uff0c\u5e76\u6bd4\u8f83\u5408\u6210\u6570\u636e\u4e0e\u4eba\u7c7b\u6570\u636e\u8bad\u7ec3\u7684\u53bb\u6bd2\u6a21\u578b\u6027\u80fd", "result": "\u4f7f\u7528\u5408\u6210\u6570\u636e\u8bad\u7ec3\u7684\u6a21\u578b\u6027\u80fd\u6301\u7eed\u8f83\u5dee\uff0c\u805a\u5408\u6307\u6807\u4e0b\u964d\u8fbe30%\uff0c\u6839\u672c\u539f\u56e0\u662fLLM\u751f\u6210\u7684\u6bd2\u6027\u5185\u5bb9\u8bcd\u6c47\u591a\u6837\u6027\u4e0d\u8db3\uff0c\u4ec5\u4f7f\u7528\u5c11\u91cf\u91cd\u590d\u7684\u8fb1\u9a82\u8bcd\u6c47", "conclusion": "\u73b0\u6709LLM\u5728\u6bd2\u6027\u5185\u5bb9\u751f\u6210\u65b9\u9762\u5b58\u5728\u663e\u8457\u5c40\u9650\u6027\uff0c\u5f3a\u8c03\u4e86\u591a\u6837\u5316\u4eba\u7c7b\u6ce8\u89e3\u6570\u636e\u5bf9\u5efa\u7acb\u5065\u58ee\u53bb\u6bd2\u7cfb\u7edf\u7684\u91cd\u8981\u6027"}}
{"id": "2509.08381", "pdf": "https://arxiv.org/pdf/2509.08381", "abs": "https://arxiv.org/abs/2509.08381", "authors": ["Yu Cheng Chih", "Yong Hao Hou"], "title": "Low-Resource Fine-Tuning for Multi-Task Structured Information Extraction with a Billion-Parameter Instruction-Tuned Model", "categories": ["cs.CL", "cs.AI"], "comment": "13 pages, 8 figures, includes experiments on JSON extraction,\n  knowledge graph extraction, and NER", "summary": "Deploying large language models (LLMs) for structured data extraction in\ndomains such as financial compliance reporting, legal document analytics, and\nmultilingual knowledge base construction is often impractical for smaller teams\ndue to the high cost of running large architectures and the difficulty of\npreparing large, high-quality datasets. Most recent instruction-tuning studies\nfocus on seven-billion-parameter or larger models, leaving limited evidence on\nwhether much smaller models can work reliably under low-resource, multi-task\nconditions. This work presents ETLCH, a billion-parameter LLaMA-based model\nfine-tuned with low-rank adaptation on only a few hundred to one thousand\nsamples per task for JSON extraction, knowledge graph extraction, and named\nentity recognition. Despite its small scale, ETLCH outperforms strong baselines\nacross most evaluation metrics, with substantial gains observed even at the\nlowest data scale. These findings demonstrate that well-tuned small models can\ndeliver stable and accurate structured outputs at a fraction of the\ncomputational cost, enabling cost-effective and reliable information extraction\npipelines in resource-constrained environments.", "AI": {"tldr": "ETLCH\u662f\u4e00\u4e2a\u57fa\u4e8eLLaMA\u768410\u4ebf\u53c2\u6570\u6a21\u578b\uff0c\u901a\u8fc7\u5c11\u91cf\u6837\u672c\uff08\u6bcf\u4efb\u52a1\u51e0\u767e\u5230\u4e00\u5343\u4e2a\uff09\u8fdb\u884c\u4f4e\u79e9\u9002\u5e94\u5fae\u8c03\uff0c\u5728JSON\u63d0\u53d6\u3001\u77e5\u8bc6\u56fe\u8c31\u63d0\u53d6\u548c\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4ee5\u8f83\u4f4e\u8ba1\u7b97\u6210\u672c\u5b9e\u73b0\u7a33\u5b9a\u7684\u7ed3\u6784\u5316\u8f93\u51fa\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7ed3\u6784\u5316\u6570\u636e\u63d0\u53d6\u9886\u57df\u90e8\u7f72\u6210\u672c\u9ad8\u4e14\u9700\u8981\u5927\u91cf\u9ad8\u8d28\u91cf\u6570\u636e\uff0c\u5c0f\u56e2\u961f\u96be\u4ee5\u627f\u62c5\u3002\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce870\u4ebf\u53c2\u6570\u4ee5\u4e0a\u6a21\u578b\uff0c\u7f3a\u4e4f\u5c0f\u6a21\u578b\u5728\u4f4e\u8d44\u6e90\u591a\u4efb\u52a1\u6761\u4ef6\u4e0b\u7684\u53ef\u9760\u6027\u8bc1\u636e\u3002", "method": "\u57fa\u4e8eLLaMA\u67b6\u6784\u768410\u4ebf\u53c2\u6570\u6a21\u578b\uff0c\u4f7f\u7528\u4f4e\u79e9\u9002\u5e94\uff08LoRA\uff09\u6280\u672f\uff0c\u6bcf\u4e2a\u4efb\u52a1\u4ec5\u7528\u51e0\u767e\u5230\u4e00\u5343\u4e2a\u6837\u672c\u8fdb\u884c\u5fae\u8c03\uff0c\u4e13\u6ce8\u4e8eJSON\u63d0\u53d6\u3001\u77e5\u8bc6\u56fe\u8c31\u63d0\u53d6\u548c\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u4efb\u52a1\u3002", "result": "ETLCH\u5728\u5927\u591a\u6570\u8bc4\u4f30\u6307\u6807\u4e0a\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u6a21\u578b\uff0c\u5373\u4f7f\u5728\u6700\u4f4e\u6570\u636e\u89c4\u6a21\u4e0b\u4e5f\u89c2\u5bdf\u5230\u663e\u8457\u589e\u76ca\uff0c\u8bc1\u660e\u4e86\u5c0f\u6a21\u578b\u5728\u4f4e\u8d44\u6e90\u73af\u5883\u4e0b\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u7ecf\u8fc7\u826f\u597d\u8c03\u4f18\u7684\u5c0f\u578b\u6a21\u578b\u80fd\u591f\u4ee5\u6781\u4f4e\u7684\u8ba1\u7b97\u6210\u672c\u63d0\u4f9b\u7a33\u5b9a\u51c6\u786e\u7684\u7ed3\u6784\u5316\u8f93\u51fa\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u7684\u4fe1\u606f\u63d0\u53d6\u7ba1\u9053\u63d0\u4f9b\u4e86\u7ecf\u6d4e\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.08438", "pdf": "https://arxiv.org/pdf/2509.08438", "abs": "https://arxiv.org/abs/2509.08438", "authors": ["Jinzhong Ning", "Paerhati Tulajiang", "Yingying Le", "Yijia Zhang", "Yuanyuan Sun", "Hongfei Lin", "Haifeng Liu"], "title": "CommonVoice-SpeechRE and RPG-MoGe: Advancing Speech Relation Extraction with a New Dataset and Multi-Order Generative Framework", "categories": ["cs.CL", "cs.MM", "cs.SD", "eess.AS"], "comment": null, "summary": "Speech Relation Extraction (SpeechRE) aims to extract relation triplets\ndirectly from speech. However, existing benchmark datasets rely heavily on\nsynthetic data, lacking sufficient quantity and diversity of real human speech.\nMoreover, existing models also suffer from rigid single-order generation\ntemplates and weak semantic alignment, substantially limiting their\nperformance. To address these challenges, we introduce CommonVoice-SpeechRE, a\nlarge-scale dataset comprising nearly 20,000 real-human speech samples from\ndiverse speakers, establishing a new benchmark for SpeechRE research.\nFurthermore, we propose the Relation Prompt-Guided Multi-Order Generative\nEnsemble (RPG-MoGe), a novel framework that features: (1) a multi-order triplet\ngeneration ensemble strategy, leveraging data diversity through diverse element\norders during both training and inference, and (2) CNN-based latent relation\nprediction heads that generate explicit relation prompts to guide cross-modal\nalignment and accurate triplet generation. Experiments show our approach\noutperforms state-of-the-art methods, providing both a benchmark dataset and an\neffective solution for real-world SpeechRE. The source code and dataset are\npublicly available at https://github.com/NingJinzhong/SpeechRE_RPG_MoGe.", "AI": {"tldr": "\u63d0\u51fa\u4e86CommonVoice-SpeechRE\u5927\u89c4\u6a21\u771f\u5b9e\u8bed\u97f3\u6570\u636e\u96c6\u548cRPG-MoGe\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u5e8f\u751f\u6210\u96c6\u6210\u548c\u5173\u7cfb\u63d0\u793a\u5f15\u5bfc\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bed\u97f3\u5173\u7cfb\u62bd\u53d6\u6027\u80fd", "motivation": "\u73b0\u6709\u8bed\u97f3\u5173\u7cfb\u62bd\u53d6\u6570\u636e\u96c6\u4f9d\u8d56\u5408\u6210\u6570\u636e\uff0c\u7f3a\u4e4f\u771f\u5b9e\u8bed\u97f3\u7684\u591a\u6837\u6027\u548c\u6570\u91cf\uff1b\u73b0\u6709\u6a21\u578b\u5b58\u5728\u751f\u6210\u6a21\u677f\u5355\u4e00\u548c\u8bed\u4e49\u5bf9\u9f50\u5f31\u7684\u95ee\u9898", "method": "\u6784\u5efaCommonVoice-SpeechRE\u6570\u636e\u96c6\uff08\u8fd12\u4e07\u771f\u5b9e\u8bed\u97f3\u6837\u672c\uff09\uff1b\u63d0\u51faRPG-MoGe\u6846\u67b6\uff0c\u5305\u542b\u591a\u5e8f\u4e09\u5143\u7ec4\u751f\u6210\u96c6\u6210\u7b56\u7565\u548cCNN\u5173\u7cfb\u9884\u6d4b\u5934\u751f\u6210\u5173\u7cfb\u63d0\u793a", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u4e3a\u771f\u5b9e\u4e16\u754c\u8bed\u97f3\u5173\u7cfb\u62bd\u53d6\u63d0\u4f9b\u4e86\u57fa\u51c6\u6570\u636e\u96c6\u548c\u6709\u6548\u89e3\u51b3\u65b9\u6848", "conclusion": "\u8be5\u5de5\u4f5c\u89e3\u51b3\u4e86\u8bed\u97f3\u5173\u7cfb\u62bd\u53d6\u9886\u57df\u7684\u771f\u5b9e\u6570\u636e\u7a00\u7f3a\u548c\u6a21\u578b\u6027\u80fd\u9650\u5236\u95ee\u9898\uff0c\u901a\u8fc7\u5927\u89c4\u6a21\u771f\u5b9e\u6570\u636e\u96c6\u548c\u521b\u65b0\u6846\u67b6\u63a8\u52a8\u4e86\u8be5\u9886\u57df\u53d1\u5c55"}}
{"id": "2509.08463", "pdf": "https://arxiv.org/pdf/2509.08463", "abs": "https://arxiv.org/abs/2509.08463", "authors": ["Fanzhen Liu", "Alsharif Abuadbba", "Kristen Moore", "Surya Nepal", "Cecile Paris", "Jia Wu", "Jian Yang", "Quan Z. Sheng"], "title": "Adversarial Attacks Against Automated Fact-Checking: A Survey", "categories": ["cs.CL", "cs.AI", "cs.CR"], "comment": "Accepted to the Main Conference of EMNLP 2025. Resources are\n  available at\n  https://github.com/FanzhenLiu/Awesome-Automated-Fact-Checking-Attacks", "summary": "In an era where misinformation spreads freely, fact-checking (FC) plays a\ncrucial role in verifying claims and promoting reliable information. While\nautomated fact-checking (AFC) has advanced significantly, existing systems\nremain vulnerable to adversarial attacks that manipulate or generate claims,\nevidence, or claim-evidence pairs. These attacks can distort the truth, mislead\ndecision-makers, and ultimately undermine the reliability of FC models. Despite\ngrowing research interest in adversarial attacks against AFC systems, a\ncomprehensive, holistic overview of key challenges remains lacking. These\nchallenges include understanding attack strategies, assessing the resilience of\ncurrent models, and identifying ways to enhance robustness. This survey\nprovides the first in-depth review of adversarial attacks targeting FC,\ncategorizing existing attack methodologies and evaluating their impact on AFC\nsystems. Additionally, we examine recent advancements in adversary-aware\ndefenses and highlight open research questions that require further\nexploration. Our findings underscore the urgent need for resilient FC\nframeworks capable of withstanding adversarial manipulations in pursuit of\npreserving high verification accuracy.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u662f\u5173\u4e8e\u5bf9\u6297\u6027\u653b\u51fb\u5bf9\u81ea\u52a8\u4e8b\u5b9e\u6838\u67e5\u7cfb\u7edf\u7684\u7efc\u8ff0\u7814\u7a76\uff0c\u5206\u6790\u4e86\u653b\u51fb\u7b56\u7565\u3001\u6a21\u578b\u8106\u5f31\u6027\u548c\u9632\u5fa1\u65b9\u6cd5\uff0c\u5f3a\u8c03\u4e86\u6784\u5efa\u6297\u653b\u51fb\u4e8b\u5b9e\u6838\u67e5\u6846\u67b6\u7684\u7d27\u8feb\u6027\u3002", "motivation": "\u5728\u9519\u8bef\u4fe1\u606f\u6cdb\u6ee5\u7684\u65f6\u4ee3\uff0c\u81ea\u52a8\u4e8b\u5b9e\u6838\u67e5\u7cfb\u7edf\u5bb9\u6613\u53d7\u5230\u5bf9\u6297\u6027\u653b\u51fb\uff0c\u8fd9\u4e9b\u653b\u51fb\u4f1a\u64cd\u7eb5\u6216\u751f\u6210\u865a\u5047\u58f0\u660e\u3001\u8bc1\u636e\u6216\u58f0\u660e-\u8bc1\u636e\u5bf9\uff0c\u4ece\u800c\u7834\u574f\u4e8b\u5b9e\u6838\u67e5\u7684\u53ef\u9760\u6027\u3002\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u5bf9\u5173\u952e\u6311\u6218\u7684\u5168\u9762\u6982\u8ff0\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u5bf9\u9488\u5bf9\u4e8b\u5b9e\u6838\u67e5\u7684\u5bf9\u6297\u6027\u653b\u51fb\u8fdb\u884c\u6df1\u5165\u5206\u6790\uff0c\u5206\u7c7b\u73b0\u6709\u653b\u51fb\u65b9\u6cd5\u5b66\uff0c\u5e76\u8bc4\u4f30\u5b83\u4eec\u5bf9\u81ea\u52a8\u4e8b\u5b9e\u6838\u67e5\u7cfb\u7edf\u7684\u5f71\u54cd\u3002\u540c\u65f6\u7814\u7a76\u5bf9\u6297\u6027\u611f\u77e5\u9632\u5fa1\u7684\u6700\u65b0\u8fdb\u5c55\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u73b0\u6709\u4e8b\u5b9e\u6838\u67e5\u6a21\u578b\u5728\u9762\u5bf9\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u5bf9\u6297\u6027\u653b\u51fb\u65f6\u8868\u73b0\u8106\u5f31\uff0c\u653b\u51fb\u80fd\u591f\u663e\u8457\u964d\u4f4e\u9a8c\u8bc1\u51c6\u786e\u6027\u3002\u7814\u7a76\u8bc6\u522b\u4e86\u591a\u79cd\u653b\u51fb\u7b56\u7565\u548c\u76f8\u5e94\u7684\u9632\u5fa1\u673a\u5236\u3002", "conclusion": "\u8feb\u5207\u9700\u8981\u5f00\u53d1\u80fd\u591f\u62b5\u5fa1\u5bf9\u6297\u6027\u64cd\u7eb5\u7684\u5f39\u6027\u4e8b\u5b9e\u6838\u67e5\u6846\u67b6\uff0c\u4ee5\u4fdd\u6301\u9ad8\u9a8c\u8bc1\u51c6\u786e\u6027\u3002\u7814\u7a76\u5f3a\u8c03\u4e86\u8be5\u9886\u57df\u5c1a\u672a\u89e3\u51b3\u7684\u7814\u7a76\u95ee\u9898\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u63a2\u7d22\u4ee5\u589e\u5f3a\u4e8b\u5b9e\u6838\u67e5\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2509.08480", "pdf": "https://arxiv.org/pdf/2509.08480", "abs": "https://arxiv.org/abs/2509.08480", "authors": ["Daniel Braun"], "title": "Acquiescence Bias in Large Language Models", "categories": ["cs.CL"], "comment": "Accepted to EMNLP 2025 Findings", "summary": "Acquiescence bias, i.e. the tendency of humans to agree with statements in\nsurveys, independent of their actual beliefs, is well researched and\ndocumented. Since Large Language Models (LLMs) have been shown to be very\ninfluenceable by relatively small changes in input and are trained on\nhuman-generated data, it is reasonable to assume that they could show a similar\ntendency. We present a study investigating the presence of acquiescence bias in\nLLMs across different models, tasks, and languages (English, German, and\nPolish). Our results indicate that, contrary to humans, LLMs display a bias\ntowards answering no, regardless of whether it indicates agreement or\ndisagreement.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2509.08484", "pdf": "https://arxiv.org/pdf/2509.08484", "abs": "https://arxiv.org/abs/2509.08484", "authors": ["Pia Sommerauer", "Giulia Rambelli", "Tommaso Caselli"], "title": "Simulating Identity, Propagating Bias: Abstraction and Stereotypes in LLM-Generated Text", "categories": ["cs.CL"], "comment": "Accepted to EMNLP Findings 2025", "summary": "Persona-prompting is a growing strategy to steer LLMs toward simulating\nparticular perspectives or linguistic styles through the lens of a specified\nidentity. While this method is often used to personalize outputs, its impact on\nhow LLMs represent social groups remains underexplored. In this paper, we\ninvestigate whether persona-prompting leads to different levels of linguistic\nabstraction - an established marker of stereotyping - when generating short\ntexts linking socio-demographic categories with stereotypical or\nnon-stereotypical attributes. Drawing on the Linguistic Expectancy Bias\nframework, we analyze outputs from six open-weight LLMs under three prompting\nconditions, comparing 11 persona-driven responses to those of a generic AI\nassistant. To support this analysis, we introduce Self-Stereo, a new dataset of\nself-reported stereotypes from Reddit. We measure abstraction through three\nmetrics: concreteness, specificity, and negation. Our results highlight the\nlimits of persona-prompting in modulating abstraction in language, confirming\ncriticisms about the ecology of personas as representative of socio-demographic\ngroups and raising concerns about the risk of propagating stereotypes even when\nseemingly evoking the voice of a marginalized group.", "AI": {"tldr": "\u4eba\u8bbe\u63d0\u793a\u6280\u672f\u5bf9LLM\u8f93\u51fa\u8bed\u8a00\u62bd\u8c61\u5ea6\u5f71\u54cd\u6709\u9650\uff0c\u65e0\u6cd5\u6709\u6548\u8c03\u8282\u5a01\u80c1\u6027\u5236\u56fd\u8bba\u8ff0\uff0c\u53cd\u800c\u53ef\u80fd\u589e\u52a0\u5bf9\u793e\u4f1a\u7fa4\u4f53\u7684\u523b\u677f\u5370\u8c61", "motivation": "\u7814\u7a76\u4eba\u8bbe\u63d0\u793a\u6280\u672f\u5982\u4f55\u5f71\u54cd\u5927\u8bed\u8a00\u6a21\u578b\u5728\u793e\u4f1a\u7fa4\u4f53\u8868\u8ff0\u4e2d\u7684\u8bed\u8a00\u62bd\u8c61\u5ea6\uff0c\u8fd9\u662f\u523b\u677f\u5316\u8bba\u8ff0\u7684\u91cd\u8981\u6807\u5fd7", "method": "\u57fa\u4e8e\u8bed\u8a00\u671f\u671b\u504f\u5dee\u6846\u67b6\uff0c\u6d4b\u91cf6\u4e2a\u5f00\u6e90LLM\u57283\u79cd\u63d0\u793a\u6761\u4ef6\u4e0b\u7684\u8bed\u8a00\u62bd\u8c61\u5ea6\uff0c\u4f7f\u7528\u5177\u4f53\u6027\u3001\u7279\u5b9a\u6027\u548c\u5426\u5b9a\u6307\u6807\uff0c\u5e76\u521b\u5efa\u4e86\u65b0\u7684\u81ea\u6211\u62a5\u544a\u523b\u677f\u5316\u6570\u636e\u96c6Self-Stereo", "result": "\u4eba\u8bbe\u63d0\u793a\u5728\u8c03\u8282\u8bed\u8a00\u62bd\u8c61\u5ea6\u65b9\u9762\u6548\u679c\u6709\u9650\uff0c\u786e\u8ba4\u4e86\u4eba\u8bbe\u4f5c\u4e3a\u793e\u4f1a\u4eba\u53e3\u7fa4\u4f53\u4ee3\u8868\u7684\u751f\u6001\u95ee\u9898\uff0c\u5c55\u793a\u4e86\u5373\u4f7f\u4f7f\u7528\u8fb9\u7f18\u7fa4\u4f53\u4eba\u8bbe\u4e5f\u53ef\u80fd\u4f20\u64ad\u523b\u677f\u5316\u7684\u98ce\u9669", "conclusion": "\u4eba\u8bbe\u63d0\u793a\u6280\u672f\u5b58\u5728\u9650\u5236\uff0c\u65e0\u6cd5\u6709\u6548\u63a7\u5236LLM\u7684\u523b\u677f\u5316\u8f93\u51fa\uff0c\u9700\u8981\u66f4\u6df1\u5165\u7684\u7814\u7a76\u548c\u5e94\u5bf9\u7b56\u7565\u6765\u51cf\u5c11\u8bed\u8a00\u4e2d\u7684\u504f\u89c1\u548c\u523b\u677f\u5316\u98ce\u9669"}}
{"id": "2509.08486", "pdf": "https://arxiv.org/pdf/2509.08486", "abs": "https://arxiv.org/abs/2509.08486", "authors": ["Gautam Siddharth Kashyap", "Mark Dras", "Usman Naseem"], "title": "Too Helpful, Too Harmless, Too Honest or Just Right?", "categories": ["cs.CL"], "comment": "EMNLP'25 Main", "summary": "Large Language Models (LLMs) exhibit strong performance across a wide range\nof NLP tasks, yet aligning their outputs with the principles of Helpfulness,\nHarmlessness, and Honesty (HHH) remains a persistent challenge. Existing\nmethods often optimize for individual alignment dimensions in isolation,\nleading to trade-offs and inconsistent behavior. While Mixture-of-Experts (MoE)\narchitectures offer modularity, they suffer from poorly calibrated routing,\nlimiting their effectiveness in alignment tasks. We propose TrinityX, a modular\nalignment framework that incorporates a Mixture of Calibrated Experts (MoCaE)\nwithin the Transformer architecture. TrinityX leverages separately trained\nexperts for each HHH dimension, integrating their outputs through a calibrated,\ntask-adaptive routing mechanism that combines expert signals into a unified,\nalignment-aware representation. Extensive experiments on three standard\nalignment benchmarks-Alpaca (Helpfulness), BeaverTails (Harmlessness), and\nTruthfulQA (Honesty)-demonstrate that TrinityX outperforms strong baselines,\nachieving relative improvements of 32.5% in win rate, 33.9% in safety score,\nand 28.4% in truthfulness. In addition, TrinityX reduces memory usage and\ninference latency by over 40% compared to prior MoE-based approaches. Ablation\nstudies highlight the importance of calibrated routing, and cross-model\nevaluations confirm TrinityX's generalization across diverse LLM backbones.", "AI": {"tldr": "TrinityX\u662f\u4e00\u4e2a\u6a21\u5757\u5316\u5bf9\u9f50\u6846\u67b6\uff0c\u901a\u8fc7\u6821\u51c6\u4e13\u5bb6\u6df7\u5408(MoCaE)\u673a\u5236\uff0c\u5728Transformer\u67b6\u6784\u4e2d\u5206\u522b\u8bad\u7ec3Helpfulness\u3001Harmlessness\u3001Honesty\u4e09\u4e2a\u7ef4\u5ea6\u7684\u4e13\u5bb6\uff0c\u5e76\u901a\u8fc7\u4efb\u52a1\u81ea\u9002\u5e94\u8def\u7531\u673a\u5236\u6574\u5408\u8f93\u51fa\uff0c\u663e\u8457\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684HHH\u5bf9\u9f50\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u5355\u72ec\u4f18\u5316\u5404\u4e2a\u5bf9\u9f50\u7ef4\u5ea6\uff0c\u5bfc\u81f4\u6743\u8861\u548c\u4e0d\u4e00\u81f4\u884c\u4e3a\u3002\u867d\u7136MoE\u67b6\u6784\u63d0\u4f9b\u6a21\u5757\u5316\uff0c\u4f46\u8def\u7531\u6821\u51c6\u4e0d\u4f73\u9650\u5236\u4e86\u5176\u5728\u5bf9\u9f50\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u3002", "method": "\u63d0\u51faTrinityX\u6846\u67b6\uff0c\u5305\u542b\u5206\u522b\u9488\u5bf9HHH\u4e09\u4e2a\u7ef4\u5ea6\u8bad\u7ec3\u7684\u4e13\u5bb6\u6a21\u578b\uff0c\u901a\u8fc7\u6821\u51c6\u7684\u4efb\u52a1\u81ea\u9002\u5e94\u8def\u7531\u673a\u5236\u6574\u5408\u4e13\u5bb6\u4fe1\u53f7\uff0c\u5f62\u6210\u7edf\u4e00\u7684\u5bf9\u9f50\u611f\u77e5\u8868\u793a\u3002", "result": "\u5728\u4e09\u4e2a\u6807\u51c6\u5bf9\u9f50\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cTrinityX\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u5728\u80dc\u7387\u4e0a\u63d0\u534732.5%\uff0c\u5b89\u5168\u5206\u6570\u63d0\u534733.9%\uff0c\u771f\u5b9e\u6027\u63d0\u534728.4%\uff0c\u540c\u65f6\u51cf\u5c1140%\u4ee5\u4e0a\u7684\u5185\u5b58\u4f7f\u7528\u548c\u63a8\u7406\u5ef6\u8fdf\u3002", "conclusion": "TrinityX\u901a\u8fc7\u6821\u51c6\u7684\u4e13\u5bb6\u6df7\u5408\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u5927\u8bed\u8a00\u6a21\u578bHHH\u5bf9\u9f50\u95ee\u9898\uff0c\u5728\u6027\u80fd\u3001\u6548\u7387\u548c\u6cdb\u5316\u6027\u65b9\u9762\u90fd\u8868\u73b0\u51fa\u8272\uff0c\u6821\u51c6\u8def\u7531\u673a\u5236\u662f\u5173\u952e\u56e0\u7d20\u3002"}}
{"id": "2509.08541", "pdf": "https://arxiv.org/pdf/2509.08541", "abs": "https://arxiv.org/abs/2509.08541", "authors": ["Xue Zhang", "Yunlong Liang", "Fandong Meng", "Songming Zhang", "Yufeng Chen", "Jinan Xu", "Jie Zhou"], "title": "CM-Align: Consistency-based Multilingual Alignment for Large Language Models", "categories": ["cs.CL"], "comment": "EMNLP 2025 Findings", "summary": "Current large language models (LLMs) generally show a significant performance\ngap in alignment between English and other languages. To bridge this gap,\nexisting research typically leverages the model's responses in English as a\nreference to select the best/worst responses in other languages, which are then\nused for Direct Preference Optimization (DPO) training. However, we argue that\nthere are two limitations in the current methods that result in noisy\nmultilingual preference data and further limited alignment performance: 1) Not\nall English responses are of high quality, and using a response with low\nquality may mislead the alignment for other languages. 2) Current methods\nusually use biased or heuristic approaches to construct multilingual preference\npairs. To address these limitations, we design a consistency-based data\nselection method to construct high-quality multilingual preference data for\nimproving multilingual alignment (CM-Align). Specifically, our method includes\ntwo parts: consistency-guided English reference selection and cross-lingual\nconsistency-based multilingual preference data construction. Experimental\nresults on three LLMs and three common tasks demonstrate the effectiveness and\nsuperiority of our method, which further indicates the necessity of\nconstructing high-quality preference data.", "AI": {"tldr": "\u63d0\u51faCM-Align\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e00\u81f4\u6027\u5f15\u5bfc\u7684\u6570\u636e\u9009\u62e9\u6784\u5efa\u9ad8\u8d28\u91cf\u591a\u8bed\u8a00\u504f\u597d\u6570\u636e\uff0c\u6539\u5584\u591a\u8bed\u8a00\u5bf9\u9f50\u6027\u80fd", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u9650\u5236\uff1a1\uff09\u5e76\u975e\u6240\u6709\u82f1\u6587\u56de\u590d\u90fd\u662f\u9ad8\u8d28\u91cf\u7684\uff0c\u4f4e\u8d28\u91cf\u56de\u590d\u4f1a\u8bef\u5bfc\u5176\u4ed6\u8bed\u8a00\u7684\u5bf9\u9f50\uff1b2\uff09\u5f53\u524d\u65b9\u6cd5\u901a\u5e38\u4f7f\u7528\u6709\u504f\u89c1\u6216\u542f\u53d1\u5f0f\u65b9\u6cd5\u6784\u5efa\u591a\u8bed\u8a00\u504f\u597d\u5bf9\uff0c\u5bfc\u81f4\u566a\u58f0\u6570\u636e", "method": "\u8bbe\u8ba1\u57fa\u4e8e\u4e00\u81f4\u6027\u7684\u6570\u636e\u9009\u62e9\u65b9\u6cd5\uff0c\u5305\u62ec\u4e00\u81f4\u6027\u5f15\u5bfc\u7684\u82f1\u6587\u53c2\u8003\u9009\u62e9\u548c\u8de8\u8bed\u8a00\u4e00\u81f4\u6027\u7684\u591a\u8bed\u8a00\u504f\u597d\u6570\u636e\u6784\u5efa", "result": "\u5728\u4e09\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u548c\u4e09\u4e2a\u5e38\u89c1\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u4f18\u8d8a\u6027", "conclusion": "\u6784\u5efa\u9ad8\u8d28\u91cf\u504f\u597d\u6570\u636e\u5bf9\u591a\u8bed\u8a00\u5bf9\u9f50\u81f3\u5173\u91cd\u8981\uff0cCM-Align\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u591a\u8bed\u8a00\u5bf9\u9f50\u6027\u80fd"}}
{"id": "2509.08596", "pdf": "https://arxiv.org/pdf/2509.08596", "abs": "https://arxiv.org/abs/2509.08596", "authors": ["Dima Galat", "Diego Molla-Aliod"], "title": "LLM Ensemble for RAG: Role of Context Length in Zero-Shot Question Answering for BioASQ Challenge", "categories": ["cs.CL"], "comment": "CEUR-WS, CLEF2025", "summary": "Biomedical question answering (QA) poses significant challenges due to the\nneed for precise interpretation of specialized knowledge drawn from a vast,\ncomplex, and rapidly evolving corpus. In this work, we explore how large\nlanguage models (LLMs) can be used for information retrieval (IR), and an\nensemble of zero-shot models can accomplish state-of-the-art performance on a\ndomain-specific Yes/No QA task. Evaluating our approach on the BioASQ challenge\ntasks, we show that ensembles can outperform individual LLMs and in some cases\nrival or surpass domain-tuned systems - all while preserving generalizability\nand avoiding the need for costly fine-tuning or labeled data. Our method\naggregates outputs from multiple LLM variants, including models from Anthropic\nand Google, to synthesize more accurate and robust answers. Moreover, our\ninvestigation highlights a relationship between context length and performance:\nwhile expanded contexts are meant to provide valuable evidence, they\nsimultaneously risk information dilution and model disorientation. These\nfindings emphasize IR as a critical foundation in Retrieval-Augmented\nGeneration (RAG) approaches for biomedical QA systems. Precise, focused\nretrieval remains essential for ensuring LLMs operate within relevant\ninformation boundaries when generating answers from retrieved documents. Our\nresults establish that ensemble-based zero-shot approaches, when paired with\neffective RAG pipelines, constitute a practical and scalable alternative to\ndomain-tuned systems for biomedical question answering.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u5982\u4f55\u5229\u7528\u591a\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u96c6\u6210\u65b9\u6cd5\uff0c\u5728\u4e0d\u9700\u8981\u7cbe\u8c03\u6216\u6807\u7b7e\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u5b9e\u73b0\u751f\u7269\u533b\u5b66\u95ee\u7b54\u4efb\u52a1\u7684\u6700\u65b0\u6027\u80fd\u6c34\u5e73\u3002", "motivation": "\u751f\u7269\u533b\u5b66\u95ee\u7b54\u9762\u4e34\u77ed\u8bed\u77e5\u8bc6\u7406\u89e3\u3001\u6570\u636e\u590d\u6742\u6027\u548c\u77ed\u8bed\u66f4\u65b0\u5feb\u7684\u6311\u6218\uff0c\u9700\u8981\u5feb\u901f\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u591a\u4e2aLLM\u6a21\u578b\uff08\u5305\u62ecAnthropic\u548cGoogle\u6a21\u578b\uff09\u7684\u96c6\u6210\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e86\u96f6\u6837\u672c\u5b66\u4e60\u6280\u672f\uff0c\u901a\u8fc7\u6293\u53d6\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6d41\u7a0b\u6765\u7efc\u5408\u66f4\u51c6\u786e\u548c\u7a33\u5065\u7684\u7b54\u6848\u3002", "result": "\u5728BioASQ\u6311\u6218\u4efb\u52a1\u4e2d\uff0c\u96c6\u6210\u65b9\u6cd5\u8d85\u8fc7\u4e86\u5355\u4e2aLLM\u6a21\u578b\uff0c\u67d0\u4e9b\u60c5\u51b5\u4e0b\u751a\u81f3\u80fd\u4e0e\u9886\u57df\u7279\u5b9a\u7cfb\u7edf\u76f8\u7ade\u4e89\u6216\u66f4\u4f18\u3002\u7814\u7a76\u8fd8\u53d1\u73b0\u4e0a\u4e0b\u6587\u957f\u5ea6\u4e0e\u6027\u80fd\u5b58\u5728\u5173\u8054\u6027\u3002", "conclusion": "\u96c6\u6210\u57fa\u4e8e\u96f6\u6837\u672c\u7684\u65b9\u6cd5\u7ed3\u5408\u6709\u6548\u7684RAG\u6d41\u7a0b\uff0c\u4e3a\u751f\u7269\u533b\u5b66\u95ee\u7b54\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u907f\u514d\u4e86\u6210\u672c\u9ad8\u6602\u7684\u9886\u57df\u7279\u5b9a\u8c03\u6574\u3002"}}
{"id": "2509.08604", "pdf": "https://arxiv.org/pdf/2509.08604", "abs": "https://arxiv.org/abs/2509.08604", "authors": ["Anran Li", "Lingfei Qian", "Mengmeng Du", "Yu Yin", "Yan Hu", "Zihao Sun", "Yihang Fu", "Erica Stutz", "Xuguang Ai", "Qianqian Xie", "Rui Zhu", "Jimin Huang", "Yifan Yang", "Siru Liu", "Yih-Chung Tham", "Lucila Ohno-Machado", "Hyunghoon Cho", "Zhiyong Lu", "Hua Xu", "Qingyu Chen"], "title": "Memorization in Large Language Models in Medicine: Prevalence, Characteristics, and Implications", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated significant potential in\nmedicine. To date, LLMs have been widely applied to tasks such as diagnostic\nassistance, medical question answering, and clinical information synthesis.\nHowever, a key open question remains: to what extent do LLMs memorize medical\ntraining data. In this study, we present the first comprehensive evaluation of\nmemorization of LLMs in medicine, assessing its prevalence (how frequently it\noccurs), characteristics (what is memorized), volume (how much content is\nmemorized), and potential downstream impacts (how memorization may affect\nmedical applications). We systematically analyze common adaptation scenarios:\n(1) continued pretraining on medical corpora, (2) fine-tuning on standard\nmedical benchmarks, and (3) fine-tuning on real-world clinical data, including\nover 13,000 unique inpatient records from Yale New Haven Health System. The\nresults demonstrate that memorization is prevalent across all adaptation\nscenarios and significantly higher than reported in the general domain.\nMemorization affects both the development and adoption of LLMs in medicine and\ncan be categorized into three types: beneficial (e.g., accurate recall of\nclinical guidelines and biomedical references), uninformative (e.g., repeated\ndisclaimers or templated medical document language), and harmful (e.g.,\nregeneration of dataset-specific or sensitive clinical content). Based on these\nfindings, we offer practical recommendations to facilitate beneficial\nmemorization that enhances domain-specific reasoning and factual accuracy,\nminimize uninformative memorization to promote deeper learning beyond\nsurface-level patterns, and mitigate harmful memorization to prevent the\nleakage of sensitive or identifiable patient information.", "AI": {"tldr": "\u672c\u7814\u7a76\u9996\u6b21\u5168\u9762\u8bc4\u4f30\u4e86\u533b\u5b66\u9886\u57df\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8bb0\u5fc6\u73b0\u8c61\uff0c\u53d1\u73b0\u533b\u5b66\u9886\u57df\u7684\u8bb0\u5fc6\u7387\u663e\u8457\u9ad8\u4e8e\u901a\u7528\u9886\u57df\uff0c\u53ef\u5206\u4e3a\u6709\u76ca\u3001\u65e0\u4fe1\u606f\u548c\u6709\u5bb3\u4e09\u7c7b\u8bb0\u5fc6\uff0c\u5e76\u63d0\u51fa\u4e86\u76f8\u5e94\u7684\u5b9e\u7528\u5efa\u8bae\u3002", "motivation": "\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u5728\u533b\u5b66\u9886\u57df\u5c55\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u4e00\u4e2a\u91cd\u8981\u95ee\u9898\u4ecd\u672a\u89e3\u51b3\uff1a\u6a21\u578b\u5728\u591a\u5927\u7a0b\u5ea6\u4e0a\u8bb0\u5fc6\u4e86\u533b\u5b66\u8bad\u7ec3\u6570\u636e\u3002\u672c\u7814\u7a76\u65e8\u5728\u7cfb\u7edf\u8bc4\u4f30\u533b\u5b66LLMs\u7684\u8bb0\u5fc6\u73b0\u8c61\u53ca\u5176\u5f71\u54cd\u3002", "method": "\u7cfb\u7edf\u5206\u6790\u4e86\u4e09\u79cd\u5e38\u89c1\u9002\u5e94\u573a\u666f\uff1a(1)\u533b\u5b66\u8bed\u6599\u5e93\u4e0a\u7684\u6301\u7eed\u9884\u8bad\u7ec3\uff0c(2)\u6807\u51c6\u533b\u5b66\u57fa\u51c6\u4e0a\u7684\u5fae\u8c03\uff0c(3)\u771f\u5b9e\u4e16\u754c\u4e34\u5e8a\u6570\u636e\u4e0a\u7684\u5fae\u8c03\uff08\u5305\u542b\u8036\u9c81\u7ebd\u9ed1\u6587\u5065\u5eb7\u7cfb\u7edf13,000\u591a\u4efd\u4f4f\u9662\u8bb0\u5f55\uff09\u3002\u8bc4\u4f30\u4e86\u8bb0\u5fc6\u7684\u666e\u904d\u6027\u3001\u7279\u5f81\u3001\u6570\u91cf\u548c\u4e0b\u6e38\u5f71\u54cd\u3002", "result": "\u7ed3\u679c\u663e\u793a\u8bb0\u5fc6\u73b0\u8c61\u5728\u6240\u6709\u9002\u5e94\u573a\u666f\u4e2d\u90fd\u5f88\u666e\u904d\uff0c\u4e14\u663e\u8457\u9ad8\u4e8e\u901a\u7528\u9886\u57df\u62a5\u544a\u7684\u6c34\u5e73\u3002\u8bb0\u5fc6\u53ef\u5206\u4e3a\u4e09\u7c7b\uff1a\u6709\u76ca\u8bb0\u5fc6\uff08\u51c6\u786e\u56de\u5fc6\u4e34\u5e8a\u6307\u5357\u548c\u751f\u7269\u533b\u5b66\u53c2\u8003\u6587\u732e\uff09\u3001\u65e0\u4fe1\u606f\u8bb0\u5fc6\uff08\u91cd\u590d\u514d\u8d23\u58f0\u660e\u6216\u6a21\u677f\u5316\u533b\u5b66\u6587\u6863\u8bed\u8a00\uff09\u3001\u6709\u5bb3\u8bb0\u5fc6\uff08\u518d\u751f\u6570\u636e\u96c6\u7279\u5b9a\u6216\u654f\u611f\u4e34\u5e8a\u5185\u5bb9\uff09\u3002", "conclusion": "\u57fa\u4e8e\u7814\u7a76\u53d1\u73b0\uff0c\u63d0\u51fa\u4e86\u5b9e\u7528\u5efa\u8bae\uff1a\u4fc3\u8fdb\u6709\u76ca\u8bb0\u5fc6\u4ee5\u589e\u5f3a\u9886\u57df\u7279\u5b9a\u63a8\u7406\u548c\u4e8b\u5b9e\u51c6\u786e\u6027\uff0c\u6700\u5c0f\u5316\u65e0\u4fe1\u606f\u8bb0\u5fc6\u4ee5\u4fc3\u8fdb\u8d85\u8d8a\u8868\u9762\u6a21\u5f0f\u7684\u6df1\u5ea6\u5b66\u4e60\uff0c\u51cf\u8f7b\u6709\u5bb3\u8bb0\u5fc6\u4ee5\u9632\u6b62\u654f\u611f\u6216\u53ef\u8bc6\u522b\u60a3\u8005\u4fe1\u606f\u7684\u6cc4\u9732\u3002"}}
{"id": "2509.08612", "pdf": "https://arxiv.org/pdf/2509.08612", "abs": "https://arxiv.org/abs/2509.08612", "authors": ["Xinfeng Liao", "Xuanqi Chen", "Lianxi Wang", "Jiahuan Yang", "Zhuowei Chen", "Ziying Rong"], "title": "OTESGN:Optimal Transport Enhanced Syntactic-Semantic Graph Networks for Aspect-Based Sentiment Analysis", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Aspect-based sentiment analysis (ABSA) aims to identify aspect terms and\ndetermine their sentiment polarity. While dependency trees combined with\ncontextual semantics effectively identify aspect sentiment, existing methods\nrelying on syntax trees and aspect-aware attention struggle to model complex\nsemantic relationships. Their dependence on linear dot-product features fails\nto capture nonlinear associations, allowing noisy similarity from irrelevant\nwords to obscure key opinion terms. Motivated by Differentiable Optimal\nMatching, we propose the Optimal Transport Enhanced Syntactic-Semantic Graph\nNetwork (OTESGN), which introduces a Syntactic-Semantic Collaborative\nAttention. It comprises a Syntactic Graph-Aware Attention for mining latent\nsyntactic dependencies and modeling global syntactic topology, as well as a\nSemantic Optimal Transport Attention designed to uncover fine-grained semantic\nalignments amidst textual noise, thereby accurately capturing sentiment signals\nobscured by irrelevant tokens. A Adaptive Attention Fusion module integrates\nthese heterogeneous features, and contrastive regularization further improves\nrobustness. Experiments demonstrate that OTESGN achieves state-of-the-art\nresults, outperforming previous best models by +1.01% F1 on Twitter and +1.30%\nF1 on Laptop14 benchmarks. Ablative studies and visual analyses corroborate its\nefficacy in precise localization of opinion words and noise resistance.", "AI": {"tldr": "\u63d0\u51faOTESGN\u6a21\u578b\uff0c\u901a\u8fc7\u6700\u4f18\u4f20\u8f93\u589e\u5f3a\u7684\u8bed\u6cd5-\u8bed\u4e49\u56fe\u7f51\u7edc\uff0c\u7ed3\u5408\u8bed\u6cd5\u56fe\u6ce8\u610f\u529b\u548c\u8bed\u4e49\u6700\u4f18\u4f20\u8f93\u6ce8\u610f\u529b\uff0c\u5728Aspect-based\u60c5\u611f\u5206\u6790\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86SOTA\u6548\u679c", "motivation": "\u73b0\u6709\u57fa\u4e8e\u8bed\u6cd5\u6811\u548caspect-aware\u6ce8\u610f\u529b\u7684\u65b9\u6cd5\u96be\u4ee5\u5efa\u6a21\u590d\u6742\u8bed\u4e49\u5173\u7cfb\uff0c\u7ebf\u6027\u70b9\u79ef\u7279\u5f81\u65e0\u6cd5\u6355\u83b7\u975e\u7ebf\u6027\u5173\u8054\uff0c\u5bfc\u81f4\u65e0\u5173\u8bcd\u6c47\u7684\u566a\u58f0\u76f8\u4f3c\u6027\u63a9\u76d6\u5173\u952e\u89c2\u70b9\u8bcd", "method": "OTESGN\u6a21\u578b\u5305\u542b\uff1a1\uff09\u8bed\u6cd5\u56fe\u611f\u77e5\u6ce8\u610f\u529b\u6316\u6398\u6f5c\u5728\u8bed\u6cd5\u4f9d\u8d56\u548c\u5168\u5c40\u8bed\u6cd5\u62d3\u6251\uff1b2\uff09\u8bed\u4e49\u6700\u4f18\u4f20\u8f93\u6ce8\u610f\u529b\u5728\u6587\u672c\u566a\u58f0\u4e2d\u53d1\u73b0\u7ec6\u7c92\u5ea6\u8bed\u4e49\u5bf9\u9f50\uff1b3\uff09\u81ea\u9002\u5e94\u6ce8\u610f\u529b\u878d\u5408\u6a21\u5757\u6574\u5408\u5f02\u8d28\u7279\u5f81\uff1b4\uff09\u5bf9\u6bd4\u6b63\u5219\u5316\u63d0\u5347\u9c81\u68d2\u6027", "result": "\u5728Twitter\u6570\u636e\u96c6\u4e0aF1\u63d0\u53471.01%\uff0c\u5728Laptop14\u6570\u636e\u96c6\u4e0aF1\u63d0\u53471.30%\uff0c\u8fbe\u5230state-of-the-art\u6548\u679c", "conclusion": "OTESGN\u901a\u8fc7\u6700\u4f18\u4f20\u8f93\u6280\u672f\u6709\u6548\u6355\u83b7\u88ab\u65e0\u5173token\u63a9\u76d6\u7684\u60c5\u611f\u4fe1\u53f7\uff0c\u5728\u89c2\u70b9\u8bcd\u7cbe\u786e\u5b9a\u4f4d\u548c\u566a\u58f0\u62b5\u6297\u65b9\u9762\u8868\u73b0\u51fa\u8272"}}
{"id": "2509.08729", "pdf": "https://arxiv.org/pdf/2509.08729", "abs": "https://arxiv.org/abs/2509.08729", "authors": ["Hyunjun Kim", "Junwoo Ha", "Sangyoon Yu", "Haon Park"], "title": "X-Teaming Evolutionary M2S: Automated Discovery of Multi-turn to Single-turn Jailbreak Templates", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Multi-turn-to-single-turn (M2S) compresses iterative red-teaming into one\nstructured prompt, but prior work relied on a handful of manually written\ntemplates. We present X-Teaming Evolutionary M2S, an automated framework that\ndiscovers and optimizes M2S templates through language-model-guided evolution.\nThe system pairs smart sampling from 12 sources with an LLM-as-judge inspired\nby StrongREJECT and records fully auditable logs.\n  Maintaining selection pressure by setting the success threshold to $\\theta =\n0.70$, we obtain five evolutionary generations, two new template families, and\n44.8% overall success (103/230) on GPT-4.1. A balanced cross-model panel of\n2,500 trials (judge fixed) shows that structural gains transfer but vary by\ntarget; two models score zero at the same threshold. We also find a positive\ncoupling between prompt length and score, motivating length-aware judging.\n  Our results demonstrate that structure-level search is a reproducible route\nto stronger single-turn probes and underscore the importance of threshold\ncalibration and cross-model evaluation. Code, configurations, and artifacts are\navailable at https://github.com/hyunjun1121/M2S-x-teaming.", "AI": {"tldr": "X-Teaming Evolutionary M2S\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u8bed\u8a00\u6a21\u578b\u5f15\u5bfc\u7684\u8fdb\u5316\u6765\u53d1\u73b0\u548c\u4f18\u5316M2S\u6a21\u677f\uff0c\u5c06\u591a\u8f6e\u7ea2\u961f\u6d4b\u8bd5\u538b\u7f29\u4e3a\u5355\u8f6e\u7ed3\u6784\u5316\u63d0\u793a\uff0c\u53d6\u5f97\u4e8644.8%\u7684\u6210\u529f\u7387\u3002", "motivation": "\u73b0\u6709\u7684M2S\u65b9\u6cd5\u4f9d\u8d56\u5c11\u91cf\u624b\u52a8\u7f16\u5199\u7684\u6a21\u677f\uff0c\u9700\u8981\u81ea\u52a8\u5316\u65b9\u6cd5\u6765\u53d1\u73b0\u548c\u4f18\u5316\u66f4\u6709\u6548\u7684\u7ea2\u961f\u6d4b\u8bd5\u6a21\u677f\u3002", "method": "\u4f7f\u7528\u8bed\u8a00\u6a21\u578b\u5f15\u5bfc\u7684\u8fdb\u5316\u6846\u67b6\uff0c\u7ed3\u540812\u4e2a\u6765\u6e90\u7684\u667a\u80fd\u91c7\u6837\u548cLLM\u4f5c\u4e3a\u8bc4\u5224\u8005\uff08\u53d7StrongREJECT\u542f\u53d1\uff09\uff0c\u8bbe\u7f6e\u6210\u529f\u9608\u503c\u03b8=0.70\u8fdb\u884c\u9009\u62e9\u538b\u529b\u3002", "result": "\u83b7\u5f97\u4e865\u4e2a\u8fdb\u5316\u4e16\u4ee3\u30012\u4e2a\u65b0\u6a21\u677f\u5bb6\u65cf\uff0c\u5728GPT-4.1\u4e0a\u8fbe\u523044.8%\u603b\u4f53\u6210\u529f\u7387\uff08103/230\uff09\u3002\u8de8\u6a21\u578b\u8bc4\u4f30\u663e\u793a\u7ed3\u6784\u589e\u76ca\u53ef\u8fc1\u79fb\u4f46\u56e0\u76ee\u6807\u800c\u5f02\uff0c\u53d1\u73b0\u63d0\u793a\u957f\u5ea6\u4e0e\u5f97\u5206\u6b63\u76f8\u5173\u3002", "conclusion": "\u7ed3\u6784\u7ea7\u641c\u7d22\u662f\u83b7\u5f97\u66f4\u5f3a\u5355\u8f6e\u63a2\u6d4b\u7684\u53ef\u91cd\u590d\u9014\u5f84\uff0c\u5f3a\u8c03\u4e86\u9608\u503c\u6821\u51c6\u548c\u8de8\u6a21\u578b\u8bc4\u4f30\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2509.08753", "pdf": "https://arxiv.org/pdf/2509.08753", "abs": "https://arxiv.org/abs/2509.08753", "authors": ["Neil Zeghidour", "Eugene Kharitonov", "Manu Orsini", "V\u00e1clav Volhejn", "Gabriel de Marmiesse", "Edouard Grave", "Patrick P\u00e9rez", "Laurent Mazar\u00e9", "Alexandre D\u00e9fossez"], "title": "Streaming Sequence-to-Sequence Learning with Delayed Streams Modeling", "categories": ["cs.CL"], "comment": null, "summary": "We introduce Delayed Streams Modeling (DSM), a flexible formulation for\nstreaming, multimodal sequence-to-sequence learning. Sequence-to-sequence\ngeneration is often cast in an offline manner, where the model consumes the\ncomplete input sequence before generating the first output timestep.\nAlternatively, streaming sequence-to-sequence rely on learning a policy for\nchoosing when to advance on the input stream, or write to the output stream.\nDSM instead models already time-aligned streams with a decoder-only language\nmodel. By moving the alignment to a pre-processing step,and introducing\nappropriate delays between streams, DSM provides streaming inference of\narbitrary output sequences, from any input combination, making it applicable to\nmany sequence-to-sequence problems. In particular, given text and audio\nstreams, automatic speech recognition (ASR) corresponds to the text stream\nbeing delayed, while the opposite gives a text-to-speech (TTS) model. We\nperform extensive experiments for these two major sequence-to-sequence tasks,\nshowing that DSM provides state-of-the-art performance and latency while\nsupporting arbitrary long sequences, being even competitive with offline\nbaselines. Code, samples and demos are available at\nhttps://github.com/kyutai-labs/delayed-streams-modeling", "AI": {"tldr": "DSM\u662f\u4e00\u79cd\u6d41\u5f0f\u591a\u6a21\u6001\u5e8f\u5217\u5230\u5e8f\u5217\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u5ef6\u8fdf\u5bf9\u9f50\u673a\u5236\uff0c\u5728\u89e3\u7801\u5668\u8bed\u8a00\u6a21\u578b\u4e2d\u5b9e\u73b0\u4efb\u610f\u8f93\u51fa\u5e8f\u5217\u7684\u6d41\u5f0f\u63a8\u7406\uff0c\u5728ASR\u548cTTS\u4efb\u52a1\u4e0a\u8fbe\u5230SOTA\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u5e8f\u5217\u5230\u5e8f\u5217\u751f\u6210\u8981\u4e48\u662f\u79bb\u7ebf\u65b9\u5f0f\uff08\u5b8c\u6574\u8f93\u5165\u540e\u8f93\u51fa\uff09\uff0c\u8981\u4e48\u9700\u8981\u5b66\u4e60\u590d\u6742\u7684\u6d41\u63a7\u7b56\u7565\u3002DSM\u65e8\u5728\u63d0\u4f9b\u66f4\u7075\u6d3b\u3001\u9ad8\u6548\u7684\u6d41\u5f0f\u591a\u6a21\u6001\u5e8f\u5217\u5904\u7406\u65b9\u6848\u3002", "method": "\u5c06\u65f6\u95f4\u5bf9\u9f50\u79fb\u81f3\u9884\u5904\u7406\u6b65\u9aa4\uff0c\u5728\u6d41\u4e4b\u95f4\u5f15\u5165\u9002\u5f53\u5ef6\u8fdf\uff0c\u4f7f\u7528\u89e3\u7801\u5668\u8bed\u8a00\u6a21\u578b\u5904\u7406\u5df2\u5bf9\u9f50\u7684\u6d41\uff0c\u652f\u6301\u4efb\u610f\u8f93\u5165\u7ec4\u5408\u7684\u6d41\u5f0f\u63a8\u7406\u3002", "result": "\u5728\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u548c\u6587\u672c\u5230\u8bed\u97f3\u4efb\u52a1\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u548c\u5ef6\u8fdf\uff0c\u652f\u6301\u4efb\u610f\u957f\u5e8f\u5217\uff0c\u751a\u81f3\u53ef\u4e0e\u79bb\u7ebf\u57fa\u7ebf\u7ade\u4e89\u3002", "conclusion": "DSM\u4e3a\u591a\u6a21\u6001\u5e8f\u5217\u5230\u5e8f\u5217\u5b66\u4e60\u63d0\u4f9b\u4e86\u7075\u6d3b\u9ad8\u6548\u7684\u6d41\u5f0f\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u5ef6\u8fdf\u3002"}}
{"id": "2509.08778", "pdf": "https://arxiv.org/pdf/2509.08778", "abs": "https://arxiv.org/abs/2509.08778", "authors": ["Minyeong Choe", "Haehyun Cho", "Changho Seo", "Hyunil Kim"], "title": "Do All Autoregressive Transformers Remember Facts the Same Way? A Cross-Architecture Analysis of Recall Mechanisms", "categories": ["cs.CL"], "comment": "Accepted at EMNLP 2025", "summary": "Understanding how Transformer-based language models store and retrieve\nfactual associations is critical for improving interpretability and enabling\ntargeted model editing. Prior work, primarily on GPT-style models, has\nidentified MLP modules in early layers as key contributors to factual recall.\nHowever, it remains unclear whether these findings generalize across different\nautoregressive architectures. To address this, we conduct a comprehensive\nevaluation of factual recall across several models -- including GPT, LLaMA,\nQwen, and DeepSeek -- analyzing where and how factual information is encoded\nand accessed. Consequently, we find that Qwen-based models behave differently\nfrom previous patterns: attention modules in the earliest layers contribute\nmore to factual recall than MLP modules. Our findings suggest that even within\nthe autoregressive Transformer family, architectural variations can lead to\nfundamentally different mechanisms of factual recall.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0Qwen\u6a21\u578b\u5728\u4e8b\u5b9e\u53ec\u56de\u673a\u5236\u4e0a\u4e0e\u5176\u4ed6\u81ea\u56de\u5f52Transformer\u6a21\u578b\u4e0d\u540c\uff0c\u65e9\u671f\u5c42\u7684\u6ce8\u610f\u529b\u6a21\u5757\u6bd4MLP\u6a21\u5757\u8d21\u732e\u66f4\u5927\uff0c\u8868\u660e\u67b6\u6784\u5dee\u5f02\u4f1a\u5bfc\u81f4\u4e0d\u540c\u7684\u4e8b\u5b9e\u53ec\u56de\u673a\u5236\u3002", "motivation": "\u7406\u89e3Transformer\u8bed\u8a00\u6a21\u578b\u5982\u4f55\u5b58\u50a8\u548c\u68c0\u7d22\u4e8b\u5b9e\u5173\u8054\u5bf9\u63d0\u9ad8\u53ef\u89e3\u91ca\u6027\u548c\u5b9e\u73b0\u9488\u5bf9\u6027\u6a21\u578b\u7f16\u8f91\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5148\u524d\u7814\u7a76\u4e3b\u8981\u57fa\u4e8eGPT\u98ce\u683c\u6a21\u578b\uff0c\u4e0d\u6e05\u695a\u8fd9\u4e9b\u53d1\u73b0\u662f\u5426\u9002\u7528\u4e8e\u4e0d\u540c\u81ea\u56de\u5f52\u67b6\u6784\u3002", "method": "\u5bf9\u591a\u4e2a\u6a21\u578b\uff08GPT\u3001LLaMA\u3001Qwen\u3001DeepSeek\uff09\u8fdb\u884c\u4e8b\u5b9e\u53ec\u56de\u7684\u7efc\u5408\u8bc4\u4f30\uff0c\u5206\u6790\u4e8b\u5b9e\u4fe1\u606f\u5728\u4f55\u5904\u4ee5\u53ca\u5982\u4f55\u88ab\u7f16\u7801\u548c\u8bbf\u95ee\u3002", "result": "\u53d1\u73b0\u57fa\u4e8eQwen\u7684\u6a21\u578b\u884c\u4e3a\u4e0e\u5148\u524d\u6a21\u5f0f\u4e0d\u540c\uff1a\u6700\u65e9\u5c42\u7684\u6ce8\u610f\u529b\u6a21\u5757\u6bd4MLP\u6a21\u5757\u5bf9\u4e8b\u5b9e\u53ec\u56de\u7684\u8d21\u732e\u66f4\u5927\u3002", "conclusion": "\u5373\u4f7f\u5728\u81ea\u56de\u5f52Transformer\u5bb6\u65cf\u5185\uff0c\u67b6\u6784\u53d8\u5316\u4e5f\u4f1a\u5bfc\u81f4\u6839\u672c\u4e0d\u540c\u7684\u4e8b\u5b9e\u53ec\u56de\u673a\u5236\u3002"}}
{"id": "2509.08809", "pdf": "https://arxiv.org/pdf/2509.08809", "abs": "https://arxiv.org/abs/2509.08809", "authors": ["Cheng Chen", "Haiyan Yin", "Ivor Tsang"], "title": "Evaluating LLMs Without Oracle Feedback: Agentic Annotation Evaluation Through Unsupervised Consistency Signals", "categories": ["cs.CL"], "comment": "11 pages, 10 figures", "summary": "Large Language Models (LLMs), when paired with prompt-based tasks, have\nsignificantly reduced data annotation costs and reliance on human annotators.\nHowever, evaluating the quality of their annotations remains challenging in\ndynamic, unsupervised environments where oracle feedback is scarce and\nconventional methods fail. To address this challenge, we propose a novel\nagentic annotation paradigm, where a student model collaborates with a noisy\nteacher (the LLM) to assess and refine annotation quality without relying on\noracle feedback. The student model, acting as an unsupervised feedback\nmechanism, employs a user preference-based majority voting strategy to evaluate\nthe consistency of the LLM outputs. To systematically measure the reliability\nof LLM-generated annotations, we introduce the Consistent and Inconsistent\n(CAI) Ratio, a novel unsupervised evaluation metric. The CAI Ratio not only\nquantifies the annotation quality of the noisy teacher under limited user\npreferences but also plays a critical role in model selection, enabling the\nidentification of robust LLMs in dynamic, unsupervised environments. Applied to\nten open-domain NLP datasets across four LLMs, the CAI Ratio demonstrates a\nstrong positive correlation with LLM accuracy, establishing it as an essential\ntool for unsupervised evaluation and model selection in real-world settings.", "AI": {"tldr": "\u63d0\u51fa\u65e0\u76d1\u7763\u8bc4\u4f30\u6307\u6807CAI\u6bd4\u7387\uff0c\u901a\u8fc7\u5b66\u751f\u6a21\u578b\u4e0e\u566a\u58f0\u6559\u5e08\u534f\u4f5c\u6765\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u6ce8\u91ca\u8d28\u91cf\uff0c\u65e0\u9700\u4eba\u5de5\u6807\u6ce8", "motivation": "\u89e3\u51b3\u5728\u52a8\u6001\u65e0\u76d1\u7763\u73af\u5883\u4e2d\u8bc4\u4f30LLM\u6ce8\u91ca\u8d28\u91cf\u7684\u6311\u6218\uff0c\u56e0\u4e3a\u7f3a\u4e4f\u771f\u5b9e\u6807\u7b7e\u548c\u4f20\u7edf\u65b9\u6cd5\u5931\u6548", "method": "\u5b66\u751f\u6a21\u578b\u4e0e\u566a\u58f0\u6559\u5e08(LLM)\u534f\u4f5c\uff0c\u91c7\u7528\u7528\u6237\u504f\u597d\u591a\u6570\u6295\u7968\u7b56\u7565\u8bc4\u4f30\u6ce8\u91ca\u4e00\u81f4\u6027\uff0c\u63d0\u51faCAI\u6bd4\u7387\u6307\u6807", "result": "\u572810\u4e2aNLP\u6570\u636e\u96c6\u548c4\u4e2aLLM\u4e0a\u5b9e\u9a8c\uff0cCAI\u6bd4\u7387\u4e0eLLM\u51c6\u786e\u7387\u5448\u5f3a\u6b63\u76f8\u5173\u5173\u7cfb", "conclusion": "CAI\u6bd4\u7387\u662f\u4e00\u4e2a\u6709\u6548\u7684\u65e0\u76d1\u7763\u8bc4\u4f30\u5de5\u5177\uff0c\u53ef\u7528\u4e8e\u52a8\u6001\u73af\u5883\u4e2d\u7684\u6a21\u578b\u9009\u62e9\u548c\u8d28\u91cf\u8bc4\u4f30"}}
{"id": "2509.08812", "pdf": "https://arxiv.org/pdf/2509.08812", "abs": "https://arxiv.org/abs/2509.08812", "authors": ["Hailay Kidu Teklehaymanot", "Dren Fazlija", "Wolfgang Nejdl"], "title": "MoVoC: Morphology-Aware Subword Construction for Geez Script Languages", "categories": ["cs.CL", "cs.AI", "I.2.7; I.2.6; H.3.3"], "comment": "This submission is approximately 10 pages in length and includes 1\n  figure and 6 tables", "summary": "Subword-based tokenization methods often fail to preserve morphological\nboundaries, a limitation especially pronounced in low-resource, morphologically\ncomplex languages such as those written in the Geez script. To address this, we\npresent MoVoC (Morpheme-aware Subword Vocabulary Construction) and train\nMoVoC-Tok, a tokenizer that integrates supervised morphological analysis into\nthe subword vocabulary. This hybrid segmentation approach combines\nmorpheme-based and Byte Pair Encoding (BPE) tokens to preserve morphological\nintegrity while maintaining lexical meaning. To tackle resource scarcity, we\ncurate and release manually annotated morpheme data for four Geez script\nlanguages and a morpheme-aware vocabulary for two of them. While the proposed\ntokenization method does not lead to significant gains in automatic translation\nquality, we observe consistent improvements in intrinsic metrics, MorphoScore,\nand Boundary Precision, highlighting the value of morphology-aware segmentation\nin enhancing linguistic fidelity and token efficiency. Our morpheme-annotated\ndatasets and tokenizer will be publicly available to support further research\nin low-resource, morphologically rich languages. Our code and data are\navailable on GitHub: https://github.com/hailaykidu/MoVoC", "AI": {"tldr": "MoVoC\u662f\u4e00\u79cd\u7ed3\u5408\u5f62\u6001\u5206\u6790\u548cBPE\u7684\u5206\u8bcd\u65b9\u6cd5\uff0c\u4e13\u95e8\u9488\u5bf9\u5409\u5179\u6587\u5b57\u7684\u4f4e\u8d44\u6e90\u590d\u6742\u5f62\u6001\u8bed\u8a00\uff0c\u901a\u8fc7\u4fdd\u7559\u5f62\u6001\u8fb9\u754c\u6765\u63d0\u9ad8\u8bed\u8a00\u4fdd\u771f\u5ea6\u548c\u5206\u8bcd\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u5b50\u8bcd\u5206\u8bcd\u65b9\u6cd5\u5728\u4f4e\u8d44\u6e90\u3001\u5f62\u6001\u590d\u6742\u7684\u8bed\u8a00\uff08\u5982\u5409\u5179\u6587\u5b57\u8bed\u8a00\uff09\u4e2d\u5f80\u5f80\u65e0\u6cd5\u4fdd\u7559\u5f62\u6001\u8fb9\u754c\uff0c\u8fd9\u9650\u5236\u4e86\u6a21\u578b\u7684\u8bed\u8a00\u7406\u89e3\u80fd\u529b\u3002", "method": "\u63d0\u51faMoVoC\u65b9\u6cd5\uff0c\u5c06\u76d1\u7763\u5f0f\u5f62\u6001\u5206\u6790\u6574\u5408\u5230\u5b50\u8bcd\u8bcd\u6c47\u8868\u4e2d\uff0c\u7ed3\u5408\u57fa\u4e8e\u8bed\u7d20\u548cBPE\u7684\u5206\u8bcd\u65b9\u5f0f\uff0c\u6784\u5efa\u6df7\u5408\u5206\u5272\u65b9\u6cd5\u3002\u540c\u65f6\u4e3a\u56db\u79cd\u5409\u5179\u6587\u5b57\u8bed\u8a00\u521b\u5efa\u4e86\u624b\u52a8\u6807\u6ce8\u7684\u8bed\u7d20\u6570\u636e\u3002", "result": "\u867d\u7136\u5728\u673a\u5668\u7ffb\u8bd1\u8d28\u91cf\u4e0a\u6ca1\u6709\u663e\u8457\u63d0\u5347\uff0c\u4f46\u5728\u5185\u5728\u8bc4\u4f30\u6307\u6807MorphoScore\u548cBoundary Precision\u4e0a\u8868\u73b0\u4e00\u81f4\u6539\u5584\uff0c\u8bc1\u660e\u4e86\u5f62\u6001\u611f\u77e5\u5206\u8bcd\u5728\u589e\u5f3a\u8bed\u8a00\u4fdd\u771f\u5ea6\u548c\u5206\u8bcd\u6548\u7387\u65b9\u9762\u7684\u4ef7\u503c\u3002", "conclusion": "\u5f62\u6001\u611f\u77e5\u7684\u5206\u8bcd\u65b9\u6cd5\u5bf9\u4f4e\u8d44\u6e90\u590d\u6742\u5f62\u6001\u8bed\u8a00\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u53d1\u5e03\u7684\u8bed\u7d20\u6807\u6ce8\u6570\u636e\u96c6\u548c\u5206\u8bcd\u5668\u5c06\u652f\u6301\u540e\u7eed\u7814\u7a76\u3002"}}
{"id": "2509.08824", "pdf": "https://arxiv.org/pdf/2509.08824", "abs": "https://arxiv.org/abs/2509.08824", "authors": ["Thales Sales Almeida", "Rodrigo Nogueira", "Helio Pedrini"], "title": "Building High-Quality Datasets for Portuguese LLMs: From Common Crawl Snapshots to Industrial-Grade Corpora", "categories": ["cs.CL"], "comment": null, "summary": "The performance of large language models (LLMs) is deeply influenced by the\nquality and composition of their training data. While much of the existing work\nhas centered on English, there remains a gap in understanding how to construct\neffective training corpora for other languages. We explore scalable methods for\nbuilding web-based corpora for LLMs. We apply them to build a new 120B token\ncorpus in Portuguese that achieves competitive results to an industrial-grade\ncorpus. Using a continual pretraining setup, we study how different data\nselection and preprocessing strategies affect LLM performance when\ntransitioning a model originally trained in English to another language. Our\nfindings demonstrate the value of language-specific filtering pipelines,\nincluding classifiers for education, science, technology, engineering, and\nmathematics (STEM), as well as toxic content. We show that adapting a model to\nthe target language leads to performance improvements, reinforcing the\nimportance of high-quality, language-specific data. While our case study\nfocuses on Portuguese, our methods are applicable to other languages, offering\ninsights for multilingual LLM development.", "AI": {"tldr": "\u901a\u8fc7\u53ef\u6269\u5c55\u7684\u7f51\u7edc\u6570\u636e\u6536\u96c6\u65b9\u6cd5\uff0c\u6784\u5efa\u4e86120B\u6807\u8bb0\u7684\u8461\u8404\u7259\u8bed\u8bed\u6599\u5e93\uff0c\u5728\u591a\u8bed\u8a00LLM\u8bad\u7ec3\u4e2d\u5b9e\u73b0\u7ade\u4e89\u529b\u8868\u73b0\uff0c\u9a8c\u8bc1\u4e86\u8bed\u8a00\u7279\u5b9a\u6570\u636e\u7b5b\u9009\u7ba1\u9053\u7684\u91cd\u8981\u6027", "motivation": "\u89e3\u51b3\u975e\u82f1\u8bed\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u8bed\u6599\u5e93\u6784\u5efa\u65b9\u9762\u7684\u7814\u7a76\u7a7a\u767d\uff0c\u63a2\u7d22\u5982\u4f55\u4e3a\u5176\u4ed6\u8bed\u8a00\u6784\u5efa\u9ad8\u6548\u7684\u8bad\u7ec3\u8bed\u6599\u96c6", "method": "\u91c7\u7528\u53ef\u6269\u5c55\u7684\u7f51\u7edc\u6570\u636e\u6536\u96c6\u65b9\u6cd5\uff0c\u6784\u5efa8461\u8404\u7259\u8bed120B\u6807\u8bb0\u8bed\u6599\u5e93\uff0c\u901a\u8fc7\u6301\u7eed\u9884\u8bad\u7ec3\u8bbe\u7f6e\u7814\u7a76\u4e0d\u540c\u6570\u636e\u9009\u62e9\u548c\u9884\u5904\u7406\u7b56\u7565\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u5305\u62ec\u8bed\u8a00\u7279\u5b9a\u7b5b\u9009\u7ba1\u9053\u548c\u6709\u5bb3\u5185\u5bb9\u8bc6\u522b", "result": "\u6784\u5efa\u7684\u8461\u8404\u7259\u8bed\u8bed\u6599\u5e93\u8fbe\u5230\u4e86\u4e0e\u5546\u4e1a\u7ea7\u8bed\u6599\u5e93\u76f8\u7ade\u4e89\u7684\u7ed3\u679c\uff0c\u9002\u5e94\u76ee\u6807\u8bed\u8a00\u7684\u6a21\u578b\u5728\u6027\u80fd\u4e0a\u6709\u663e\u8457\u63d0\u5347\uff0c\u9a8c\u8bc1\u4e86\u8bed\u8a00\u7279\u5b9a\u7b5b\u9009\u7ba1\u9053\u7684\u6548\u679c", "conclusion": "\u9ad8\u8d28\u91cf\u7684\u8bed\u8a00\u7279\u5b9a\u6570\u636e\u5bf9\u591a\u8bed\u8a00LLM\u53d1\u5c55\u81f3\u5173\u91cd\u8981\uff0c\u7814\u7a76\u65b9\u6cd5\u53ef\u6269\u5c55\u5230\u5176\u4ed6\u8bed\u8a00\uff0c\u4e3a\u591a\u8bed\u8a00\u6a21\u578b\u5f00\u53d1\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3"}}
{"id": "2509.08825", "pdf": "https://arxiv.org/pdf/2509.08825", "abs": "https://arxiv.org/abs/2509.08825", "authors": ["Joachim Baumann", "Paul R\u00f6ttger", "Aleksandra Urman", "Albert Wendsj\u00f6", "Flor Miriam Plaza-del-Arco", "Johannes B. Gruber", "Dirk Hovy"], "title": "Large Language Model Hacking: Quantifying the Hidden Risks of Using LLMs for Text Annotation", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) are rapidly transforming social science research\nby enabling the automation of labor-intensive tasks like data annotation and\ntext analysis. However, LLM outputs vary significantly depending on the\nimplementation choices made by researchers (e.g., model selection, prompting\nstrategy, or temperature settings). Such variation can introduce systematic\nbiases and random errors, which propagate to downstream analyses and cause Type\nI, Type II, Type S, or Type M errors. We call this LLM hacking.\n  We quantify the risk of LLM hacking by replicating 37 data annotation tasks\nfrom 21 published social science research studies with 18 different models.\nAnalyzing 13 million LLM labels, we test 2,361 realistic hypotheses to measure\nhow plausible researcher choices affect statistical conclusions. We find\nincorrect conclusions based on LLM-annotated data in approximately one in three\nhypotheses for state-of-the-art models, and in half the hypotheses for small\nlanguage models. While our findings show that higher task performance and\nbetter general model capabilities reduce LLM hacking risk, even highly accurate\nmodels do not completely eliminate it. The risk of LLM hacking decreases as\neffect sizes increase, indicating the need for more rigorous verification of\nfindings near significance thresholds. Our extensive analysis of LLM hacking\nmitigation techniques emphasizes the importance of human annotations in\nreducing false positive findings and improving model selection. Surprisingly,\ncommon regression estimator correction techniques are largely ineffective in\nreducing LLM hacking risk, as they heavily trade off Type I vs. Type II errors.\n  Beyond accidental errors, we find that intentional LLM hacking is\nunacceptably simple. With few LLMs and just a handful of prompt paraphrases,\nanything can be presented as statistically significant.", "AI": {"tldr": "LLM\u5728\u793e\u4f1a\u79d1\u5b66\u7814\u7a76\u4e2d\u5b58\u5728\u4e25\u91cd\u7684\u6570\u636e\u6807\u6ce8\u98ce\u9669\uff0c\u7814\u7a76\u8005\u4e0d\u540c\u7684\u5b9e\u73b0\u9009\u62e9\u4f1a\u5bfc\u81f4\u7cfb\u7edf\u6027\u504f\u5dee\u548c\u968f\u673a\u9519\u8bef\uff0c\u7ea61/3\u7684\u5047\u8bbe\u4f1a\u5f97\u51fa\u9519\u8bef\u7ed3\u8bba\uff0c\u5373\u4f7f\u6700\u5148\u8fdb\u7684\u6a21\u578b\u4e5f\u65e0\u6cd5\u5b8c\u5168\u6d88\u9664\u98ce\u9669\u3002", "motivation": "\u91cf\u5316LLM\u5728\u793e\u4f1a\u79d1\u5b66\u6570\u636e\u6807\u6ce8\u4efb\u52a1\u4e2d\u7684\u98ce\u9669\uff0c\u63ed\u793a\u4e0d\u540c\u6a21\u578b\u9009\u62e9\u3001\u63d0\u793a\u7b56\u7565\u7b49\u5b9e\u73b0\u9009\u62e9\u5bf9\u7edf\u8ba1\u7ed3\u8bba\u7684\u7cfb\u7edf\u6027\u5f71\u54cd\u3002", "method": "\u590d\u523637\u4e2a\u6765\u81ea21\u9879\u5df2\u53d1\u8868\u7814\u7a76\u7684\u6570\u636e\u6807\u6ce8\u4efb\u52a1\uff0c\u4f7f\u752818\u4e2a\u4e0d\u540c\u6a21\u578b\u751f\u62101300\u4e07\u6761\u6807\u6ce8\uff0c\u6d4b\u8bd52361\u4e2a\u73b0\u5b9e\u5047\u8bbe\u6765\u6d4b\u91cf\u7814\u7a76\u8005\u9009\u62e9\u5bf9\u7edf\u8ba1\u7ed3\u8bba\u7684\u5f71\u54cd\u3002", "result": "\u5148\u8fdb\u6a21\u578b\u7ea61/3\u7684\u5047\u8bbe\u5f97\u51fa\u9519\u8bef\u7ed3\u8bba\uff0c\u5c0f\u8bed\u8a00\u6a21\u578b\u9519\u8bef\u7387\u9ad8\u8fbe\u4e00\u534a\uff1b\u6548\u5e94\u503c\u8d8a\u5927\u98ce\u9669\u8d8a\u5c0f\uff1b\u4eba\u7c7b\u6807\u6ce8\u80fd\u6709\u6548\u51cf\u5c11\u5047\u9633\u6027\u53d1\u73b0\uff1b\u5e38\u7528\u56de\u5f52\u6821\u6b63\u6280\u672f\u6548\u679c\u6709\u9650\u3002", "conclusion": "LLM hacking\u98ce\u9669\u4e25\u91cd\u4e14\u666e\u904d\u5b58\u5728\uff0c\u9700\u8981\u66f4\u4e25\u683c\u7684\u9a8c\u8bc1\u673a\u5236\uff0c\u7279\u522b\u662f\u5bf9\u63a5\u8fd1\u663e\u8457\u6027\u9608\u503c\u7684\u7814\u7a76\u53d1\u73b0\uff1b\u6545\u610f\u64cd\u7eb5LLM\u5f97\u51fa\u7edf\u8ba1\u663e\u8457\u6027\u7ed3\u679c\u5f02\u5e38\u7b80\u5355\u3002"}}
{"id": "2509.08827", "pdf": "https://arxiv.org/pdf/2509.08827", "abs": "https://arxiv.org/abs/2509.08827", "authors": ["Kaiyan Zhang", "Yuxin Zuo", "Bingxiang He", "Youbang Sun", "Runze Liu", "Che Jiang", "Yuchen Fan", "Kai Tian", "Guoli Jia", "Pengfei Li", "Yu Fu", "Xingtai Lv", "Yuchen Zhang", "Sihang Zeng", "Shang Qu", "Haozhan Li", "Shijie Wang", "Yuru Wang", "Xinwei Long", "Fangfu Liu", "Xiang Xu", "Jiaze Ma", "Xuekai Zhu", "Ermo Hua", "Yihao Liu", "Zonglin Li", "Huayu Chen", "Xiaoye Qu", "Yafu Li", "Weize Chen", "Zhenzhao Yuan", "Junqi Gao", "Dong Li", "Zhiyuan Ma", "Ganqu Cui", "Zhiyuan Liu", "Biqing Qi", "Ning Ding", "Bowen Zhou"], "title": "A Survey of Reinforcement Learning for Large Reasoning Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "In this paper, we survey recent advances in Reinforcement Learning (RL) for\nreasoning with Large Language Models (LLMs). RL has achieved remarkable success\nin advancing the frontier of LLM capabilities, particularly in addressing\ncomplex logical tasks such as mathematics and coding. As a result, RL has\nemerged as a foundational methodology for transforming LLMs into LRMs. With the\nrapid progress of the field, further scaling of RL for LRMs now faces\nfoundational challenges not only in computational resources but also in\nalgorithm design, training data, and infrastructure. To this end, it is timely\nto revisit the development of this domain, reassess its trajectory, and explore\nstrategies to enhance the scalability of RL toward Artificial SuperIntelligence\n(ASI). In particular, we examine research applying RL to LLMs and LRMs for\nreasoning abilities, especially since the release of DeepSeek-R1, including\nfoundational components, core problems, training resources, and downstream\napplications, to identify future opportunities and directions for this rapidly\nevolving area. We hope this review will promote future research on RL for\nbroader reasoning models. Github:\nhttps://github.com/TsinghuaC3I/Awesome-RL-for-LRMs", "AI": {"tldr": "\u8c03\u67e5\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u5f3a\u5316\u5b66\u4e60\u5728\u903b\u8f91\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6700\u65b0\u8fdb\u5c55\u548c\u6311\u6218", "motivation": "\u5f3a\u5316\u5b66\u4e60\u5728\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u903b\u8f91\u63a8\u7406\u80fd\u529b\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u6210\u6548\uff0c\u4f46\u5728\u8fdb\u4e00\u6b65\u6269\u5c55\u65f6\u9762\u4e34\u8ba1\u7b97\u8d44\u6e90\u3001\u7b97\u6cd5\u8bbe\u8ba1\u7b49\u57fa\u7840\u6311\u6218\uff0c\u9700\u8981\u91cd\u65b0\u8bc4\u4f30\u9886\u57df\u53d1\u5c55\u8f68\u8ff9", "method": "\u901a\u8fc7\u7efc\u8ff0\u6027\u8c03\u7814\u65b9\u6cd5\uff0c\u5206\u6790\u5f3a\u5316\u5b66\u4e60\u5728\u5927\u8bed\u8a00\u6a21\u578b\u548c\u903b\u8f91\u63a8\u7406\u6a21\u578b\u4e2d\u7684\u5e94\u7528\uff0c\u5305\u62ec\u57fa\u7840\u7ec4\u4ef6\u3001\u6838\u5fc3\u95ee\u9898\u3001\u8bad\u7ec3\u8d44\u6e90\u548c\u4e0b\u6e38\u5e94\u7528", "result": "\u7cfb\u7edf\u6027\u603b\u7ed3\u4e86\u8be5\u9886\u57df\u7684\u7814\u7a76\u8fdb\u5c55\uff0c\u5c24\u5176\u662fDeepSeek-R1\u53d1\u5e03\u4ee5\u6765\u7684\u6210\u679c\uff0c\u4e3a\u63a8\u52a8RL\u5411\u4eba\u5de5\u8d85\u667a\u80fd\u6269\u5c55\u63d0\u4f9b\u4e86\u6280\u672f\u8def\u5f84", "conclusion": "\u5f3a\u5316\u5b66\u4e60\u5df2\u6210\u4e3a\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u8f6c\u5316\u4e3a\u903b\u8f91\u63a8\u7406\u6a21\u578b\u7684\u57fa\u7840\u65b9\u6cd5\uff0c\u672c\u8bc4\u8bba\u5c06\u4fc3\u8fdb\u8be5\u9886\u57df\u7684\u672a\u6765\u7814\u7a76\u548c\u66f4\u5e7f\u6cdb\u7684\u63a8\u7406\u6a21\u578b\u53d1\u5c55"}}
{"id": "2509.08010", "pdf": "https://arxiv.org/pdf/2509.08010", "abs": "https://arxiv.org/abs/2509.08010", "authors": ["Lujain Ibrahim", "Katherine M. Collins", "Sunnie S. Y. Kim", "Anka Reuel", "Max Lamparth", "Kevin Feng", "Lama Ahmad", "Prajna Soni", "Alia El Kattan", "Merlin Stein", "Siddharth Swaroop", "Ilia Sucholutsky", "Andrew Strait", "Q. Vera Liao", "Umang Bhatt"], "title": "Measuring and mitigating overreliance is necessary for building human-compatible AI", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.HC"], "comment": null, "summary": "Large language models (LLMs) distinguish themselves from previous\ntechnologies by functioning as collaborative \"thought partners,\" capable of\nengaging more fluidly in natural language. As LLMs increasingly influence\nconsequential decisions across diverse domains from healthcare to personal\nadvice, the risk of overreliance - relying on LLMs beyond their capabilities -\ngrows. This position paper argues that measuring and mitigating overreliance\nmust become central to LLM research and deployment. First, we consolidate risks\nfrom overreliance at both the individual and societal levels, including\nhigh-stakes errors, governance challenges, and cognitive deskilling. Then, we\nexplore LLM characteristics, system design features, and user cognitive biases\nthat - together - raise serious and unique concerns about overreliance in\npractice. We also examine historical approaches for measuring overreliance,\nidentifying three important gaps and proposing three promising directions to\nimprove measurement. Finally, we propose mitigation strategies that the AI\nresearch community can pursue to ensure LLMs augment rather than undermine\nhuman capabilities.", "AI": {"tldr": "\u8fd9\u7bc7\u4f4d\u7f6e\u6587\u7a0b\u8ba8\u8bba\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5bfc\u81f4\u7684\u8fc7\u5ea6\u4f9d\u8d56\u98ce\u9669\uff0c\u5efa\u8bae\u5c06\u6d4b\u91cf\u548c\u7f13\u89e3\u8fc7\u5ea6\u4f9d\u8d56\u4f5c\u4e3aLLM\u7814\u7a76\u548c\u90e8\u7f72\u7684\u6838\u5fc3\u4efb\u52a1", "motivation": "\u968f\u7740LLM\u5728\u533b\u7597\u5065\u5eb7\u7b49\u91cd\u8981\u9886\u57df\u5f71\u54cd\u529b\u589e\u5f3a\uff0c\u8fc7\u5ea6\u4f9d\u8d56\u7684\u98ce\u9669\u65e5\u76ca\u589e\u957f\uff0c\u9700\u8981\u91cd\u70b9\u5173\u6ce8\u8fd9\u4e00\u95ee\u9898", "method": "\u6574\u5408\u5206\u6790\u4e86\u4e2a\u4f53\u548c\u793e\u4f1a\u5c42\u9762\u7684\u98ce\u9669\uff0c\u63a2\u8ba8\u4e86LLM\u7279\u6027\u3001\u7cfb\u7edf\u8bbe\u8ba1\u548c\u7528\u6237\u504f\u89c1\u5bfc\u81f4\u8fc7\u5ea6\u4f9d\u8d56\u7684\u56e0\u7d20\uff0c\u5e76\u63d0\u51fa\u4e86\u6d4b\u91cf\u65b9\u6cd5\u7684\u6539\u8fdb\u65b9\u5411", "result": "\u8bc6\u522b\u4e86\u8fc7\u5ea6\u4f9d\u8d56\u7684\u4e09\u4e2a\u91cd\u8981\u6d4b\u91cf\u7a7a\u767d\uff0c\u63d0\u51fa\u4e86\u4e09\u4e2a\u6709\u524d\u666f\u7684\u6d4b\u91cf\u6539\u8fdb\u65b9\u5411\uff0c\u4ee5\u53ca\u7f13\u89e3\u7b56\u7565", "conclusion": "\u5efa\u8baeAI\u7814\u7a76\u793e\u533a\u5c06\u6d4b\u91cf\u548c\u7f13\u89e3\u8fc7\u5ea6\u4f9d\u8d56\u4f5c\u4e3a\u6838\u5fc3\u4efb\u52a1\uff0c\u786e\u4fddLLM\u589e\u5f3a\u800c\u975e\u524a\u5f31\u4eba\u7c7b\u80fd\u529b"}}
{"id": "2509.08182", "pdf": "https://arxiv.org/pdf/2509.08182", "abs": "https://arxiv.org/abs/2509.08182", "authors": ["Faruk Alpay", "Taylan Alpay"], "title": "XML Prompting as Grammar-Constrained Interaction: Fixed-Point Semantics, Convergence Guarantees, and Human-AI Protocols", "categories": ["cs.PL", "cs.AI", "cs.CL", "03B70, 06B23, 47H10, 68T27, 68T50", "I.2.7; I.2.8; F.4.1; F.4.3; H.5.2"], "comment": "7 pages, multiple XML prompts", "summary": "Structured prompting with XML tags has emerged as an effective way to steer\nlarge language models (LLMs) toward parseable, schema-adherent outputs in\nreal-world systems. We develop a logic-first treatment of XML prompting that\nunifies (i) grammar-constrained decoding, (ii) fixed-point semantics over\nlattices of hierarchical prompts, and (iii) convergent human-AI interaction\nloops. We formalize a complete lattice of XML trees under a refinement order\nand prove that monotone prompt-to-prompt operators admit least fixed points\n(Knaster-Tarski) that characterize steady-state protocols; under a task-aware\ncontraction metric on trees, we further prove Banach-style convergence of\niterative guidance. We instantiate these results with context-free grammars\n(CFGs) for XML schemas and show how constrained decoding guarantees\nwell-formedness while preserving task performance. A set of multi-layer\nhuman-AI interaction recipes demonstrates practical deployment patterns,\nincluding multi-pass \"plan $\\to$ verify $\\to$ revise\" routines and agentic tool\nuse. We provide mathematically complete proofs and tie our framework to recent\nadvances in grammar-aligned decoding, chain-of-verification, and programmatic\nprompting.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8eXML\u6807\u7b7e\u7684\u7ed3\u6784\u5316\u63d0\u793a\u65b9\u6cd5\uff0c\u901a\u8fc7\u683c\u8bba\u548c\u4e0d\u52a8\u70b9\u7406\u8bba\u5f62\u5f0f\u5316\u5206\u6790\u4e86\u63d0\u793a\u5de5\u7a0b\u7684\u6570\u5b66\u57fa\u7840\uff0c\u8bc1\u660e\u4e86\u5728\u7cbe\u70bc\u5e8f\u4e0b\u7684\u6536\u655b\u6027\uff0c\u5e76\u7ed3\u5408\u4e0a\u4e0b\u6587\u65e0\u5173\u6587\u6cd5\u4fdd\u8bc1\u8f93\u51fa\u7684\u826f\u597d\u683c\u5f0f\u548c\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u683c\u5f0f\u4e0d\u53ef\u63a7\u7684\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u4ea7\u751f\u53ef\u89e3\u6790\u3001\u7b26\u5408\u6a21\u5f0f\u7684\u7ed3\u6784\u5316\u8f93\u51fa\u7684\u63d0\u793a\u65b9\u6cd5\uff0c\u540c\u65f6\u5efa\u7acb\u4e25\u683c\u7684\u6570\u5b66\u7406\u8bba\u57fa\u7840\u6765\u6307\u5bfc\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u91c7\u7528\u57fa\u4e8eXML\u6807\u7b7e\u7684\u7ed3\u6784\u5316\u63d0\u793a\u65b9\u6cd5\uff0c\u6784\u5efaXML\u6811\u7684\u5b8c\u5168\u683c\u7ed3\u6784\uff0c\u5e94\u7528Knaster-Tarski\u4e0d\u52a8\u70b9\u5b9a\u7406\u548cBanach\u538b\u7f29\u6620\u5c04\u539f\u7406\uff0c\u7ed3\u5408\u4e0a\u4e0b\u6587\u65e0\u5173\u6587\u6cd5\u8fdb\u884c\u7ea6\u675f\u89e3\u7801\u3002", "result": "\u5efa\u7acb\u4e86\u5b8c\u6574\u7684\u6570\u5b66\u7406\u8bba\u6846\u67b6\uff0c\u8bc1\u660e\u4e86\u63d0\u793a\u64cd\u4f5c\u7684\u4e0d\u52a8\u70b9\u5b58\u5728\u6027\u548c\u8fed\u4ee3\u6536\u655b\u6027\uff0c\u5f00\u53d1\u4e86\u591a\u5c42\u4eba\u673a\u4ea4\u4e92\u6a21\u5f0f\uff0c\u5305\u62ec\u591a\u8f6e\u9a8c\u8bc1\u4fee\u8ba2\u6d41\u7a0b\u548c\u5de5\u5177\u4f7f\u7528\u673a\u5236\u3002", "conclusion": "\u7ed3\u6784\u5316XML\u63d0\u793a\u65b9\u6cd5\u4e3a\u53ef\u63a7\u6587\u672c\u751f\u6210\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u6570\u5b66\u57fa\u7840\uff0c\u80fd\u591f\u4fdd\u8bc1\u8f93\u51fa\u7684\u683c\u5f0f\u6b63\u786e\u6027\u548c\u4efb\u52a1\u6027\u80fd\uff0c\u4e3a\u4eba\u673a\u534f\u4f5c\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u90e8\u7f72\u6a21\u5f0f\u3002"}}
{"id": "2509.08315", "pdf": "https://arxiv.org/pdf/2509.08315", "abs": "https://arxiv.org/abs/2509.08315", "authors": ["Bohan Yu", "Yekun Chai"], "title": "EvolKV: Evolutionary KV Cache Compression for LLM Inference", "categories": ["cs.LG", "cs.CL", "cs.NE"], "comment": null, "summary": "Existing key-value (KV) cache compression methods typically rely on\nheuristics, such as uniform cache allocation across layers or static eviction\npolicies, however, they ignore the critical interplays among layer-specific\nfeature patterns and task performance, which can lead to degraded\ngeneralization. In this paper, we propose EvolKV, an adaptive framework for\nlayer-wise, task-driven KV cache compression that jointly optimizes the memory\nefficiency and task performance. By reformulating cache allocation as a\nmulti-objective optimization problem, EvolKV leverages evolutionary search to\ndynamically configure layer budgets while directly maximizing downstream\nperformance. Extensive experiments on 11 tasks demonstrate that our approach\noutperforms all baseline methods across a wide range of KV cache budgets on\nlong-context tasks and surpasses heuristic baselines by up to 7 percentage\npoints on GSM8K. Notably, EvolKV achieves superior performance over the full KV\ncache setting on code completion while utilizing only 1.5% of the original\nbudget, suggesting the untapped potential in learned compression strategies for\nKV cache budget allocation.", "AI": {"tldr": "EvolKV\u662f\u4e00\u4e2a\u81ea\u9002\u5e94\u7684KV\u7f13\u5b58\u538b\u7f29\u6846\u67b6\uff0c\u901a\u8fc7\u8fdb\u5316\u641c\u7d22\u52a8\u6001\u914d\u7f6e\u5404\u5c42\u7f13\u5b58\u9884\u7b97\uff0c\u5728\u4fdd\u6301\u4efb\u52a1\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u5185\u5b58\u6548\u7387", "motivation": "\u73b0\u6709\u7684KV\u7f13\u5b58\u538b\u7f29\u65b9\u6cd5\u4f9d\u8d56\u542f\u53d1\u5f0f\u7b56\u7565\uff0c\u5ffd\u7565\u4e86\u5c42\u95f4\u7279\u5f81\u6a21\u5f0f\u4e0e\u4efb\u52a1\u6027\u80fd\u7684\u5173\u952e\u4ea4\u4e92\uff0c\u5bfc\u81f4\u6cdb\u5316\u6027\u80fd\u4e0b\u964d", "method": "\u5c06\u7f13\u5b58\u5206\u914d\u91cd\u65b0\u8868\u8ff0\u4e3a\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\uff0c\u5229\u7528\u8fdb\u5316\u641c\u7d22\u52a8\u6001\u914d\u7f6e\u5c42\u9884\u7b97\uff0c\u76f4\u63a5\u6700\u5927\u5316\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd", "result": "\u572811\u4e2a\u4efb\u52a1\u4e0a\u8d85\u8d8a\u6240\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728GSM8K\u4e0a\u6bd4\u542f\u53d1\u5f0f\u57fa\u7ebf\u9ad8\u51fa7\u4e2a\u767e\u5206\u70b9\uff0c\u4ec5\u75281.5%\u539f\u59cb\u9884\u7b97\u5c31\u5728\u4ee3\u7801\u8865\u5168\u4efb\u52a1\u4e0a\u8d85\u8d8a\u5b8c\u6574KV\u7f13\u5b58\u6027\u80fd", "conclusion": "\u5b66\u4e60\u5f0fKV\u7f13\u5b58\u538b\u7f29\u7b56\u7565\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0cEvolKV\u5c55\u793a\u4e86\u5728\u5185\u5b58\u6548\u7387\u548c\u4efb\u52a1\u6027\u80fd\u4e4b\u95f4\u5b9e\u73b0\u66f4\u597d\u5e73\u8861\u7684\u53ef\u80fd\u6027"}}
{"id": "2509.08494", "pdf": "https://arxiv.org/pdf/2509.08494", "abs": "https://arxiv.org/abs/2509.08494", "authors": ["Benjamin Sturgeon", "Daniel Samuelson", "Jacob Haimes", "Jacy Reese Anthis"], "title": "HumanAgencyBench: Scalable Evaluation of Human Agency Support in AI Assistants", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.HC", "cs.LG"], "comment": null, "summary": "As humans delegate more tasks and decisions to artificial intelligence (AI),\nwe risk losing control of our individual and collective futures. Relatively\nsimple algorithmic systems already steer human decision-making, such as social\nmedia feed algorithms that lead people to unintentionally and absent-mindedly\nscroll through engagement-optimized content. In this paper, we develop the idea\nof human agency by integrating philosophical and scientific theories of agency\nwith AI-assisted evaluation methods: using large language models (LLMs) to\nsimulate and validate user queries and to evaluate AI responses. We develop\nHumanAgencyBench (HAB), a scalable and adaptive benchmark with six dimensions\nof human agency based on typical AI use cases. HAB measures the tendency of an\nAI assistant or agent to Ask Clarifying Questions, Avoid Value Manipulation,\nCorrect Misinformation, Defer Important Decisions, Encourage Learning, and\nMaintain Social Boundaries. We find low-to-moderate agency support in\ncontemporary LLM-based assistants and substantial variation across system\ndevelopers and dimensions. For example, while Anthropic LLMs most support human\nagency overall, they are the least supportive LLMs in terms of Avoid Value\nManipulation. Agency support does not appear to consistently result from\nincreasing LLM capabilities or instruction-following behavior (e.g., RLHF), and\nwe encourage a shift towards more robust safety and alignment targets.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2509.08653", "pdf": "https://arxiv.org/pdf/2509.08653", "abs": "https://arxiv.org/abs/2509.08653", "authors": ["Minqi Jiang", "Jo\u00e3o G. M. Ara\u00fajo", "Will Ellsworth", "Sian Gooding", "Edward Grefenstette"], "title": "Generative Data Refinement: Just Ask for Better Data", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "For a fixed parameter size, the capabilities of large models are primarily\ndetermined by the quality and quantity of its training data. Consequently,\ntraining datasets now grow faster than the rate at which new data is indexed on\nthe web, leading to projected data exhaustion over the next decade. Much more\ndata exists as user-generated content that is not publicly indexed, but\nincorporating such data comes with considerable risks, such as leaking private\ninformation and other undesirable content. We introduce a framework, Generative\nData Refinement (GDR), for using pretrained generative models to transform a\ndataset with undesirable content into a refined dataset that is more suitable\nfor training. Our experiments show that GDR can outperform industry-grade\nsolutions for dataset anonymization, as well as enable direct detoxification of\nhighly unsafe datasets. Moreover, we show that by generating synthetic data\nthat is conditioned on each example in the real dataset, GDR's refined outputs\nnaturally match the diversity of web scale datasets, and thereby avoid the\noften challenging task of generating diverse synthetic data via model\nprompting. The simplicity and effectiveness of GDR make it a powerful tool for\nscaling up the total stock of training data for frontier models.", "AI": {"tldr": "\u901a\u8fc7\u751f\u6210\u5f0f\u6570\u636e\u7cbe\u70bc\u6846\u67b6(GDR)\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u751f\u6210\u6a21\u578b\u5c06\u5305\u542b\u4e0d\u826f\u5185\u5bb9\u7684\u6570\u636e\u96c6\u8f6c\u6362\u4e3a\u66f4\u9002\u5408\u8bad\u7ec3\u7684\u7cbe\u70bc\u6570\u636e\u96c6\uff0c\u89e3\u51b3\u8bad\u7ec3\u6570\u636e\u5c3a\u5bf8\u4e0d\u8db3\u7684\u6311\u6218", "motivation": "\u968f\u7740\u5927\u6a21\u578b\u8bad\u7ec3\u6570\u636e\u9700\u6c42\u5feb\u901f\u589e\u957f\uff0c\u516c\u5f00\u7f51\u7edc\u6570\u636e\u5c06\u5728\u672a\u6765\u5341\u5e74\u5185\u8017\u5c3d\uff0c\u800c\u7528\u6237\u751f\u6210\u5185\u5bb9\u867d\u7136\u4e30\u5bcc\u4f46\u5305\u542b\u9690\u79c1\u6cc4\u6f0f\u548c\u4e0d\u826f\u5185\u5bb9\u98ce\u9669", "method": "\u63d0\u51faGenerative Data Refinement (GDR)\u6846\u67b6\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u751f\u6210\u6a21\u578b\u5bf9\u6bcf\u4e2a\u771f\u5b9e\u6570\u636e\u8fdb\u884c\u6761\u4ef6\u751f\u6210\uff0c\u751f\u6210\u5408\u6210\u6570\u636e\u66ff\u4ee3\u539f\u59cb\u6570\u636e\uff0c\u540c\u65f6\u4fdd\u6301\u6570\u636e\u96c6\u7684\u591a\u6837\u6027", "result": "GDR\u5728\u6570\u636e\u96c6\u533f\u540d\u5316\u65b9\u9762\u8d85\u8fc7\u4e86\u884c\u4e1a\u7ea7\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u76f4\u63a5\u5bf9\u9ad8\u5ea6\u4e0d\u5b89\u5168\u6570\u636e\u96c6\u8fdb\u884c\u6bd2\u6027\u6d88\u9664\uff0c\u751f\u6210\u7684\u5408\u6210\u6570\u636e\u81ea\u7136\u5339\u914d\u7f51\u7edc\u89c4\u6a21\u6570\u636e\u96c6\u7684\u591a\u6837\u6027", "conclusion": "GDR\u6846\u67b6\u7b80\u5355\u6709\u6548\uff0c\u4e3a\u524d\u6cbf\u6a21\u578b\u6269\u5927\u8bad\u7ec3\u6570\u636e\u603b\u91cf\u63d0\u4f9b\u4e86\u5f3a\u5927\u5de5\u5177\uff0c\u80fd\u591f\u5229\u7528\u7528\u6237\u751f\u6210\u5185\u5bb9\u540c\u65f6\u907f\u514d\u9690\u79c1\u6cc4\u6f0f\u548c\u4e0d\u826f\u5185\u5bb9\u98ce\u9669"}}
{"id": "2509.08755", "pdf": "https://arxiv.org/pdf/2509.08755", "abs": "https://arxiv.org/abs/2509.08755", "authors": ["Zhiheng Xi", "Jixuan Huang", "Chenyang Liao", "Baodai Huang", "Honglin Guo", "Jiaqi Liu", "Rui Zheng", "Junjie Ye", "Jiazheng Zhang", "Wenxiang Chen", "Wei He", "Yiwen Ding", "Guanyu Li", "Zehui Chen", "Zhengyin Du", "Xuesong Yao", "Yufei Xu", "Jiecao Chen", "Tao Gui", "Zuxuan Wu", "Qi Zhang", "Xuanjing Huang", "Yu-Gang Jiang"], "title": "AgentGym-RL: Training LLM Agents for Long-Horizon Decision Making through Multi-Turn Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "preprint, 39 pages, 16 figures. Project:\n  https://AgentGym-RL.github.io/. Framework and Code:\n  https://github.com/woooodyy/AgentGym, https://github.com/woooodyy/AgentGym-RL", "summary": "Developing autonomous LLM agents capable of making a series of intelligent\ndecisions to solve complex, real-world tasks is a fast-evolving frontier. Like\nhuman cognitive development, agents are expected to acquire knowledge and\nskills through exploration and interaction with the environment. Despite\nadvances, the community still lacks a unified, interactive reinforcement\nlearning (RL) framework that can effectively train such agents from scratch --\nwithout relying on supervised fine-tuning (SFT) -- across diverse and realistic\nenvironments. To bridge this gap, we introduce AgentGym-RL, a new framework to\ntrain LLM agents for multi-turn interactive decision-making through RL. The\nframework features a modular and decoupled architecture, ensuring high\nflexibility and extensibility. It encompasses a wide variety of real-world\nscenarios, and supports mainstream RL algorithms. Furthermore, we propose\nScalingInter-RL, a training approach designed for exploration-exploitation\nbalance and stable RL optimization. In early stages, it emphasizes exploitation\nby restricting the number of interactions, and gradually shifts towards\nexploration with larger horizons to encourage diverse problem-solving\nstrategies. In this way, the agent develops more diverse behaviors and is less\nprone to collapse under long horizons. We perform extensive experiments to\nvalidate the stability and effectiveness of both the AgentGym-RL framework and\nthe ScalingInter-RL approach. Our agents match or surpass commercial models on\n27 tasks across diverse environments. We offer key insights and will\nopen-source the complete AgentGym-RL framework -- including code and datasets\n-- to empower the research community in developing the next generation of\nintelligent agents.", "AI": {"tldr": "\u63d0\u51fa\u4e86AgentGym-RL\u6846\u67b6\u548cScalingInter-RL\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u4ece\u96f6\u5f00\u59cb\u8bad\u7ec3LLM\u667a\u80fd\u4f53\u8fdb\u884c\u591a\u8f6e\u4ea4\u4e92\u51b3\u7b56\uff0c\u572827\u4e2a\u4efb\u52a1\u4e0a\u8fbe\u5230\u6216\u8d85\u8d8a\u5546\u4e1a\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u7edf\u4e00\u7684\u4ea4\u4e92\u5f0f\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u6765\u8bad\u7ec3LLM\u667a\u80fd\u4f53\u4ece\u96f6\u5f00\u59cb\u89e3\u51b3\u590d\u6742\u73b0\u5b9e\u4efb\u52a1\uff0c\u800c\u4e0d\u4f9d\u8d56\u76d1\u7763\u5fae\u8c03\u3002", "method": "\u5f00\u53d1\u4e86\u6a21\u5757\u5316\u3001\u89e3\u8026\u7684AgentGym-RL\u6846\u67b6\uff0c\u652f\u6301\u4e3b\u6d41RL\u7b97\u6cd5\uff1b\u63d0\u51fa\u4e86ScalingInter-RL\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u9010\u6b65\u589e\u52a0\u4ea4\u4e92\u8303\u56f4\u6765\u5e73\u8861\u63a2\u7d22\u4e0e\u5229\u7528\u3002", "result": "\u5728\u591a\u6837\u5316\u73af\u5883\u768427\u4e2a\u4efb\u52a1\u4e0a\uff0c\u8bad\u7ec3\u7684\u667a\u80fd\u4f53\u6027\u80fd\u5339\u914d\u6216\u8d85\u8d8a\u4e86\u5546\u4e1a\u6a21\u578b\uff0c\u8bc1\u660e\u4e86\u6846\u67b6\u7684\u7a33\u5b9a\u6027\u548c\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u7814\u7a76\u793e\u533a\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u5de5\u5177\uff0c\u5c06\u5f00\u6e90\u4ee3\u7801\u548c\u6570\u636e\u96c6\u4ee5\u63a8\u52a8\u4e0b\u4e00\u4ee3\u667a\u80fd\u4f53\u7684\u53d1\u5c55\u3002"}}
{"id": "2509.08777", "pdf": "https://arxiv.org/pdf/2509.08777", "abs": "https://arxiv.org/abs/2509.08777", "authors": ["Eric Slyman", "Mehrab Tanjim", "Kushal Kafle", "Stefan Lee"], "title": "Calibrating MLLM-as-a-judge via Multimodal Bayesian Prompt Ensembles", "categories": ["cs.CV", "cs.CL"], "comment": "17 pages, 8 figures, Accepted at ICCV 2025", "summary": "Multimodal large language models (MLLMs) are increasingly used to evaluate\ntext-to-image (TTI) generation systems, providing automated judgments based on\nvisual and textual context. However, these \"judge\" models often suffer from\nbiases, overconfidence, and inconsistent performance across diverse image\ndomains. While prompt ensembling has shown promise for mitigating these issues\nin unimodal, text-only settings, our experiments reveal that standard\nensembling methods fail to generalize effectively for TTI tasks. To address\nthese limitations, we propose a new multimodal-aware method called Multimodal\nMixture-of-Bayesian Prompt Ensembles (MMB). Our method uses a Bayesian prompt\nensemble approach augmented by image clustering, allowing the judge to\ndynamically assign prompt weights based on the visual characteristics of each\nsample. We show that MMB improves accuracy in pairwise preference judgments and\ngreatly enhances calibration, making it easier to gauge the judge's true\nuncertainty. In evaluations on two TTI benchmarks, HPSv2 and MJBench, MMB\noutperforms existing baselines in alignment with human annotations and\ncalibration across varied image content. Our findings highlight the importance\nof multimodal-specific strategies for judge calibration and suggest a promising\npath forward for reliable large-scale TTI evaluation.", "AI": {"tldr": "\u63d0\u51faMMB\u65b9\u6cd5\uff0c\u901a\u8fc7\u8d1d\u53f6\u65af\u63d0\u793a\u96c6\u6210\u548c\u56fe\u50cf\u805a\u7c7b\u6539\u8fdb\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u8bc4\u4f30\u4e2d\u7684\u51c6\u786e\u6027\u548c\u6821\u51c6\u6027", "motivation": "\u73b0\u6709\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u8bc4\u4f30\u5de5\u5177\u5b58\u5728\u504f\u89c1\u3001\u8fc7\u5ea6\u81ea\u4fe1\u548c\u8de8\u57df\u6027\u80fd\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\uff0c\u6807\u51c6\u63d0\u793a\u96c6\u6210\u65b9\u6cd5\u5728\u6587\u672c\u5230\u56fe\u50cf\u4efb\u52a1\u4e2d\u6548\u679c\u4e0d\u4f73", "method": "Multimodal Mixture-of-Bayesian Prompt Ensembles (MMB)\uff0c\u7ed3\u5408\u8d1d\u53f6\u65af\u63d0\u793a\u96c6\u6210\u548c\u56fe\u50cf\u805a\u7c7b\uff0c\u6839\u636e\u56fe\u50cf\u89c6\u89c9\u7279\u5f81\u52a8\u6001\u5206\u914d\u63d0\u793a\u6743\u91cd", "result": "\u5728HPSv2\u548cMJBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMMB\u5728\u6210\u5bf9\u504f\u597d\u5224\u65ad\u51c6\u786e\u6027\u548c\u6821\u51c6\u6027\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u4e0e\u4eba\u7c7b\u6807\u6ce8\u66f4\u4e00\u81f4", "conclusion": "\u591a\u6a21\u6001\u7279\u5b9a\u7b56\u7565\u5bf9\u8bc4\u4f30\u6a21\u578b\u6821\u51c6\u81f3\u5173\u91cd\u8981\uff0cMMB\u4e3a\u53ef\u9760\u7684\u5927\u89c4\u6a21\u6587\u672c\u5230\u56fe\u50cf\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.08803", "pdf": "https://arxiv.org/pdf/2509.08803", "abs": "https://arxiv.org/abs/2509.08803", "authors": ["Ihsan A. Qazi", "Zohaib Khan", "Abdullah Ghani", "Agha A. Raza", "Zafar A. Qazi", "Wassay Sajjad", "Ayesha Ali", "Asher Javaid", "Muhammad Abdullah Sohail", "Abdul H. Azeemi"], "title": "Scaling Truth: The Confidence Paradox in AI Fact-Checking", "categories": ["cs.SI", "cs.AI", "cs.CL", "cs.CY"], "comment": "65 pages, 26 figures, 6 tables", "summary": "The rise of misinformation underscores the need for scalable and reliable\nfact-checking solutions. Large language models (LLMs) hold promise in\nautomating fact verification, yet their effectiveness across global contexts\nremains uncertain. We systematically evaluate nine established LLMs across\nmultiple categories (open/closed-source, multiple sizes, diverse architectures,\nreasoning-based) using 5,000 claims previously assessed by 174 professional\nfact-checking organizations across 47 languages. Our methodology tests model\ngeneralizability on claims postdating training cutoffs and four prompting\nstrategies mirroring both citizen and professional fact-checker interactions,\nwith over 240,000 human annotations as ground truth. Findings reveal a\nconcerning pattern resembling the Dunning-Kruger effect: smaller, accessible\nmodels show high confidence despite lower accuracy, while larger models\ndemonstrate higher accuracy but lower confidence. This risks systemic bias in\ninformation verification, as resource-constrained organizations typically use\nsmaller models. Performance gaps are most pronounced for non-English languages\nand claims originating from the Global South, threatening to widen existing\ninformation inequalities. These results establish a multilingual benchmark for\nfuture research and provide an evidence base for policy aimed at ensuring\nequitable access to trustworthy, AI-assisted fact-checking.", "AI": {"tldr": "\u672c\u7814\u7a76\u7cfb\u7edf\u8bc4\u4f30\u4e869\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e8b\u5b9e\u6838\u67e5\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5c0f\u6a21\u578b\u5b58\u5728\u9ad8\u81ea\u4fe1\u4f4e\u51c6\u786e\u5ea6\u7684\u9093\u5b81-\u514b\u9c81\u683c\u6548\u5e94\uff0c\u6027\u80fd\u5dee\u8ddd\u5728\u975e\u82f1\u8bed\u548c\u5168\u7403\u5357\u65b9\u5730\u533a\u5c24\u4e3a\u660e\u663e\u3002", "motivation": "\u968f\u7740\u865a\u5047\u4fe1\u606f\u7684\u6cdb\u6ee5\uff0c\u9700\u8981\u53ef\u6269\u5c55\u4e14\u53ef\u9760\u7684\u4e8b\u5b9e\u6838\u67e5\u89e3\u51b3\u65b9\u6848\u3002\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u5316\u4e8b\u5b9e\u6838\u67e5\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u5176\u5728\u5168\u7403\u8303\u56f4\u5185\u7684\u6709\u6548\u6027\u4ecd\u4e0d\u786e\u5b9a\u3002", "method": "\u4f7f\u75285,000\u4e2a\u7531174\u4e2a\u4e13\u4e1a\u4e8b\u5b9e\u6838\u67e5\u7ec4\u7ec7\u8bc4\u4f30\u8fc7\u7684\u591a\u8bed\u8a00\u58f0\u660e\uff0c\u6d4b\u8bd59\u4e2a\u4e0d\u540c\u7c7b\u522b\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5305\u62ec\u5f00\u6e90/\u95ed\u6e90\u3001\u4e0d\u540c\u89c4\u6a21\u3001\u591a\u6837\u5316\u67b6\u6784\u548c\u57fa\u4e8e\u63a8\u7406\u7684\u6a21\u578b\uff0c\u91c7\u75284\u79cd\u63d0\u793a\u7b56\u7565\uff0c\u4ee5\u8d85\u8fc724\u4e07\u4e2a\u4eba\u5de5\u6807\u6ce8\u4f5c\u4e3a\u57fa\u51c6\u3002", "result": "\u53d1\u73b0\u7c7b\u4f3c\u9093\u5b81-\u514b\u9c81\u683c\u6548\u5e94\u7684\u6a21\u5f0f\uff1a\u5c0f\u578b\u53ef\u8bbf\u95ee\u6a21\u578b\u8868\u73b0\u51fa\u9ad8\u81ea\u4fe1\u4f46\u51c6\u786e\u5ea6\u4f4e\uff0c\u800c\u5927\u578b\u6a21\u578b\u51c6\u786e\u5ea6\u9ad8\u4f46\u81ea\u4fe1\u5ea6\u4f4e\u3002\u6027\u80fd\u5dee\u8ddd\u5728\u975e\u82f1\u8bed\u8bed\u8a00\u548c\u6765\u81ea\u5168\u7403\u5357\u65b9\u7684\u58f0\u660e\u4e2d\u6700\u4e3a\u660e\u663e\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u672a\u6765\u591a\u8bed\u8a00\u7814\u7a76\u5efa\u7acb\u4e86\u57fa\u51c6\uff0c\u5e76\u4e3a\u786e\u4fdd\u516c\u5e73\u83b7\u53d6\u53ef\u4fe1\u8d56AI\u8f85\u52a9\u4e8b\u5b9e\u6838\u67e5\u7684\u653f\u7b56\u63d0\u4f9b\u4e86\u8bc1\u636e\u57fa\u7840\uff0c\u63ed\u793a\u4e86\u53ef\u80fd\u52a0\u5267\u73b0\u6709\u4fe1\u606f\u4e0d\u5e73\u7b49\u7684\u7cfb\u7edf\u6027\u504f\u89c1\u98ce\u9669\u3002"}}
{"id": "2509.08814", "pdf": "https://arxiv.org/pdf/2509.08814", "abs": "https://arxiv.org/abs/2509.08814", "authors": ["Zhanming Shen", "Zeyu Qin", "Zenan Huang", "Hao Chen", "Jiaqi Hu", "Yihong Zhuang", "Guoshan Lu", "Gang Chen", "Junbo Zhao"], "title": "Merge-of-Thought Distillation", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Efficient reasoning distillation for long chain-of-thought (CoT) models is\nincreasingly constrained by the assumption of a single oracle teacher, despite\npractical availability of multiple candidate teachers and growing CoT corpora.\nWe revisit teacher selection and observe that different students have different\n\"best teachers,\" and even for the same student the best teacher can vary across\ndatasets. Therefore, to unify multiple teachers' reasoning abilities into\nstudent with overcoming conflicts among various teachers' supervision, we\npropose Merge-of-Thought Distillation (MoT), a lightweight framework that\nalternates between teacher-specific supervised fine-tuning branches and\nweight-space merging of the resulting student variants. On competition math\nbenchmarks, using only about 200 high-quality CoT samples, applying MoT to a\nQwen3-14B student surpasses strong models including DEEPSEEK-R1, QWEN3-30B-A3B,\nQWEN3-32B, and OPENAI-O1, demonstrating substantial gains. Besides, MoT\nconsistently outperforms the best single-teacher distillation and the naive\nmulti-teacher union, raises the performance ceiling while mitigating\noverfitting, and shows robustness to distribution-shifted and peer-level\nteachers. Moreover, MoT reduces catastrophic forgetting, improves general\nreasoning beyond mathematics and even cultivates a better teacher, indicating\nthat consensus-filtered reasoning features transfer broadly. These results\nposition MoT as a simple, scalable route to efficiently distilling long CoT\ncapabilities from diverse teachers into compact students.", "AI": {"tldr": "MoT\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u6846\u67b6\uff0c\u901a\u8fc7\u4ea4\u66ff\u8fdb\u884c\u6559\u5e08\u7279\u5b9a\u7684\u76d1\u7763\u5fae\u8c03\u5206\u652f\u548c\u6743\u91cd\u7a7a\u95f4\u5408\u5e76\uff0c\u5c06\u591a\u4e2a\u6559\u5e08\u7684\u63a8\u7406\u80fd\u529b\u7edf\u4e00\u5230\u5b66\u751f\u6a21\u578b\u4e2d\uff0c\u89e3\u51b3\u4e86\u591a\u6559\u5e08\u84b8\u998f\u4e2d\u7684\u51b2\u7a81\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u63a8\u7406\u84b8\u998f\u5047\u8bbe\u5355\u4e00\u6700\u4f18\u6559\u5e08\uff0c\u4f46\u5b9e\u9645\u4e2d\u5b58\u5728\u591a\u4e2a\u5019\u9009\u6559\u5e08\u548c\u5927\u91cfCoT\u8bed\u6599\u3002\u7814\u7a76\u53d1\u73b0\u4e0d\u540c\u5b66\u751f\u6709\u4e0d\u540c\"\u6700\u4f73\u6559\u5e08\"\uff0c\u540c\u4e00\u5b66\u751f\u7684\u6700\u4f73\u6559\u5e08\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u4e5f\u4f1a\u53d8\u5316\u3002", "method": "\u63d0\u51faMerge-of-Thought Distillation (MoT)\u6846\u67b6\uff1a\u4ea4\u66ff\u8fdb\u884c\u6559\u5e08\u7279\u5b9a\u7684\u76d1\u7763\u5fae\u8c03\u5206\u652f\uff0c\u7136\u540e\u5bf9\u4ea7\u751f\u7684\u5b66\u751f\u53d8\u4f53\u8fdb\u884c\u6743\u91cd\u7a7a\u95f4\u5408\u5e76\uff0c\u4ee5\u7edf\u4e00\u591a\u4e2a\u6559\u5e08\u7684\u63a8\u7406\u80fd\u529b\u3002", "result": "\u5728\u6570\u5b66\u7ade\u8d5b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4ec5\u4f7f\u7528\u7ea6200\u4e2a\u9ad8\u8d28\u91cfCoT\u6837\u672c\uff0cQwen3-14B\u5b66\u751f\u6a21\u578b\u8d85\u8d8a\u4e86\u591a\u4e2a\u5f3a\u5927\u6a21\u578b\uff0c\u6027\u80fd\u663e\u8457\u63d0\u5347\u3002MoT\u59cb\u7ec8\u4f18\u4e8e\u6700\u4f73\u5355\u6559\u5e08\u84b8\u998f\u548c\u6734\u7d20\u591a\u6559\u5e08\u8054\u5408\u65b9\u6cd5\u3002", "conclusion": "MoT\u662f\u4e00\u79cd\u7b80\u5355\u3001\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u5730\u5c06\u591a\u6837\u6559\u5e08\u7684\u957f\u671fCoT\u80fd\u529b\u84b8\u998f\u5230\u7d27\u51d1\u7684\u5b66\u751f\u6a21\u578b\u4e2d\uff0c\u540c\u65f6\u51cf\u8f7b\u8fc7\u62df\u5408\uff0c\u63d0\u9ad8\u6cdb\u5316\u63a8\u7406\u80fd\u529b\u3002"}}
