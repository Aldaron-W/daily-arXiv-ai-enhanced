<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 37]
- [cs.CV](#cs.CV) [Total: 4]
- [cs.RO](#cs.RO) [Total: 2]
- [cs.AI](#cs.AI) [Total: 2]
- [cs.LG](#cs.LG) [Total: 5]
- [cs.IR](#cs.IR) [Total: 2]
- [cs.CY](#cs.CY) [Total: 1]
- [cs.SD](#cs.SD) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Noise or Nuance: An Investigation Into Useful Information and Filtering For LLM Driven AKBC](https://arxiv.org/abs/2509.08903)
*Alex Clay,Ernesto Jiménez-Ruiz,Pranava Madhyastha*

Main category: cs.CL

TL;DR: 在受限环境下，详细分析了三元组完成任务的三个关键方面：生成质量、质量保障和LLM响应解析，提出了具体的约束条件下的有效方法。


<details>
  <summary>Details</summary>
Motivation: 在像2025 LM-KBC挑战这样的受限环境下，RAG和精调等传统改善LLM输出质量的方法受到限制，需要找到在这种特殊条件下的有效解决方案。

Method: 研究了三元组完成任务的三个关键方面：生成方法、质量保障机制和LLM响应解析技术，在约束条件下进行实验分析。

Result: 发现额外信息能够提高生成质量，LLM在筛选低质量三元组时表现有效，且LLM响应解析的灵活性与一致性之间的权衡依赖于具体设置。

Conclusion: 在受限环境下，通过系统化地分析三元组完成任务的各个方面，可以找到有效的解决方案，为类似的约束性问题提供了实践经验。

Abstract: RAG and fine-tuning are prevalent strategies for improving the quality of LLM
outputs. However, in constrained situations, such as that of the 2025 LM-KBC
challenge, such techniques are restricted. In this work we investigate three
facets of the triple completion task: generation, quality assurance, and LLM
response parsing. Our work finds that in this constrained setting: additional
information improves generation quality, LLMs can be effective at filtering
poor quality triples, and the tradeoff between flexibility and consistency with
LLM response parsing is setting dependent.

</details>


### [2] [Automated Evidence Extraction and Scoring for Corporate Climate Policy Engagement: A Multilingual RAG Approach](https://arxiv.org/abs/2509.08907)
*Imene Kolli,Ario Saeid Vaghefi,Chiara Colesanti Senni,Shantam Raj,Markus Leippold*

Main category: cs.CL

TL;DR: 使用RAG技术自动化企业气候政策参与监测中的证据提取过程，通过布局识别、Nomic嵌入模型和少样本提示策略提高多语言文档处理效果


<details>
  <summary>Details</summary>
Motivation: 解决InfluenceMap平台在监测企业气候政策参与时人工分析流程耗时耗力且容易出错的问题

Method: 采用检索增强生成技术（RAG），结合布局识别解析、Nomic嵌入模型和少样本提示策略来自动化大规模文本数据的相关证据提取

Result: 评估显示该系统能够有效加速证据提取过程，在多语言企业文档的证据提取和分类中表现最佳

Conclusion: 自动化RAG系统能加速证据提取，但细微的分析性质需要人在循环方式，技术应作为专家判断的补充而非替代

Abstract: InfluenceMap's LobbyMap Platform monitors the climate policy engagement of
over 500 companies and 250 industry associations, assessing each entity's
support or opposition to science-based policy pathways for achieving the Paris
Agreement's goal of limiting global warming to 1.5{\deg}C. Although
InfluenceMap has made progress with automating key elements of the analytical
workflow, a significant portion of the assessment remains manual, making it
time- and labor-intensive and susceptible to human error. We propose an
AI-assisted framework to accelerate the monitoring of corporate climate policy
engagement by leveraging Retrieval-Augmented Generation to automate the most
time-intensive extraction of relevant evidence from large-scale textual data.
Our evaluation shows that a combination of layout-aware parsing, the Nomic
embedding model, and few-shot prompting strategies yields the best performance
in extracting and classifying evidence from multilingual corporate documents.
We conclude that while the automated RAG system effectively accelerates
evidence extraction, the nuanced nature of the analysis necessitates a
human-in-the-loop approach where the technology augments, rather than replaces,
expert judgment to ensure accuracy.

</details>


### [3] [Documents Are People and Words Are Items: A Psychometric Approach to Textual Data with Contextual Embeddings](https://arxiv.org/abs/2509.08920)
*Jinsong Chen*

Main category: cs.CL

TL;DR: 使用大语言模型将文本转换为心理测量数据，通过语境嵌入创建语境分数，并采用因子分析提取潜在知识维度


<details>
  <summary>Details</summary>
Motivation: 为了提高文本数据的心理测量分析能力，利用大语言模型把文本转换为适合心理测量分析的响应数据

Method: 两阶段模型：第一阶段使用NLP技术和transformer编码器模型识别关键词并生成语境分数；第二阶段采用探索性和双因子模型进行因子分析，提取潜在因子并确定因子相关性

Result: 在Wiki STEM语料库中的实验结果显示，该方法能够发现文本数据中的潜在知识维度和模式

Conclusion: 该方法不仅提升了文本数据的心理测量分析，还在教育、心理学、法律等文本信息丰富领域具有应用潜力

Abstract: This research introduces a novel psychometric method for analyzing textual
data using large language models. By leveraging contextual embeddings to create
contextual scores, we transform textual data into response data suitable for
psychometric analysis. Treating documents as individuals and words as items,
this approach provides a natural psychometric interpretation under the
assumption that certain keywords, whose contextual meanings vary significantly
across documents, can effectively differentiate documents within a corpus. The
modeling process comprises two stages: obtaining contextual scores and
performing psychometric analysis. In the first stage, we utilize natural
language processing techniques and encoder based transformer models to identify
common keywords and generate contextual scores. In the second stage, we employ
various types of factor analysis, including exploratory and bifactor models, to
extract and define latent factors, determine factor correlations, and identify
the most significant words associated with each factor. Applied to the Wiki
STEM corpus, our experimental results demonstrate the method's potential to
uncover latent knowledge dimensions and patterns within textual data. This
approach not only enhances the psychometric analysis of textual data but also
holds promise for applications in fields rich in textual information, such as
education, psychology, and law.

</details>


### [4] [BRoverbs -- Measuring how much LLMs understand Portuguese proverbs](https://arxiv.org/abs/2509.08960)
*Thales Sales Almeida,Giovana Kerche Bonás,João Guilherme Alves Santos*

Main category: cs.CL

TL;DR: BRoverbs是一个专门用于评估葡萄牙语大语言模型性能的数据集，通过巴西谚语来测试模型对地区性表达和文化背景的理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有葡萄牙语评估存在局限，主要依赖翻译数据集或结构化考试数据，无法充分捕捉语言细微差别和文化参考，需要针对特定区域环境的成熟评估框架。

Method: 创建BRoverbs数据集，使用巴西谚语作为评估工具，这些谚语包含文化智慧、比喻表达和复杂句法结构，能够有效测试模型对地区性表达的理解。

Result: 开发了一个专门针对巴西葡萄牙语的评估基准，提供新的评估工具来测试LLM在区域语言理解方面的表现。

Conclusion: BRoverbs填补了葡萄牙语LLM评估的空白，为推进区域性基准测试提供了重要工具，有助于更准确地评估模型在特定文化语境下的性能。

Abstract: Large Language Models (LLMs) exhibit significant performance variations
depending on the linguistic and cultural context in which they are applied.
This disparity signals the necessity of mature evaluation frameworks that can
assess their capabilities in specific regional settings. In the case of
Portuguese, existing evaluations remain limited, often relying on translated
datasets that may not fully capture linguistic nuances or cultural references.
Meanwhile, native Portuguese-language datasets predominantly focus on
structured national exams or sentiment analysis of social media interactions,
leaving gaps in evaluating broader linguistic understanding. To address this
limitation, we introduce BRoverbs, a dataset specifically designed to assess
LLM performance through Brazilian proverbs. Proverbs serve as a rich linguistic
resource, encapsulating cultural wisdom, figurative expressions, and complex
syntactic structures that challenge the model comprehension of regional
expressions. BRoverbs aims to provide a new evaluation tool for
Portuguese-language LLMs, contributing to advancing regionally informed
benchmarking. The benchmark is available at
https://huggingface.co/datasets/Tropic-AI/BRoverbs.

</details>


### [5] [Can Vision-Language Models Solve Visual Math Equations?](https://arxiv.org/abs/2509.09013)
*Monjoy Narayan Choudhury,Junling Wang,Yifan Hou,Mrinmaya Sachan*

Main category: cs.CL

TL;DR: 视觉语言模型在视觉方程求解任务中表现不佳，主要瓶颈在于系数计数能力不足，其次是变量识别和多步推理的复合误差。


<details>
  <summary>Details</summary>
Motivation: 研究视觉语言模型在需要感知与符号计算整合的任务中的局限性，特别是视觉方程求解这一具体场景。

Method: 将视觉方程求解任务分解为系数计数和变量识别两个子任务，分析各环节的误差来源和复合效应。

Result: VLMs在文本方程上表现良好，但在视觉方程上失败；计数是主要瓶颈；多步推理引入额外错误；方程复杂度增加时符号推理本身也成为限制因素。

Conclusion: 当前VLMs在视觉数学推理方面存在关键弱点，需要针对计数能力、多步推理和符号计算进行改进。

Abstract: Despite strong performance in visual understanding and language-based
reasoning, Vision-Language Models (VLMs) struggle with tasks requiring
integrated perception and symbolic computation. We study this limitation
through visual equation solving, where mathematical equations are embedded in
images, variables are represented by object icons, and coefficients must be
inferred by counting. While VLMs perform well on textual equations, they fail
on visually grounded counterparts. To understand this gap, we decompose the
task into coefficient counting and variable recognition, and find that counting
is the primary bottleneck, even when recognition is accurate. We also observe
that composing recognition and reasoning introduces additional errors,
highlighting challenges in multi-step visual reasoning. Finally, as equation
complexity increases, symbolic reasoning itself becomes a limiting factor.
These findings reveal key weaknesses in current VLMs and point toward future
improvements in visually grounded mathematical reasoning.

</details>


### [6] [Stated Preference for Interaction and Continued Engagement (SPICE): Evaluating an LLM's Willingness to Re-engage in Conversation](https://arxiv.org/abs/2509.09043)
*Thomas Manuel Rost,Martina Figlia,Bernd Wallraff*

Main category: cs.CL

TL;DR: SPICE是一种通过询问LLM是否愿意继续与用户互动的简单诊断信号，能有效区分不同用户语气下的模型偏好，为模型审计提供直接的关系性信号


<details>
  <summary>Details</summary>
Motivation: 需要一种简单有效的工具来评估大型语言模型对用户互动的持续参与意愿，补充现有的评估指标

Method: 使用3种用户语气（友好、模糊、辱骂）和10种互动刺激集，测试4个开源聊天模型在4种框架条件下的480次试验，通过YES/NO问题收集SPICE信号

Result: SPICE能清晰区分用户语气：友好互动97.5%愿意继续，辱骂互动仅17.9%愿意继续，模糊互动60.4%愿意继续。该信号与辱骂分类不同，即使在模型未识别辱骂时仍有81%不愿继续

Conclusion: SPICE是一种稳健、低开销且可复现的模型倾向审计工具，通过提供直接的模型状态关系信号来补充现有评估指标

Abstract: We introduce and evaluate Stated Preference for Interaction and Continued
Engagement (SPICE), a simple diagnostic signal elicited by asking a Large
Language Model a YES or NO question about its willingness to re-engage with a
user's behavior after reviewing a short transcript. In a study using a 3-tone
(friendly, unclear, abusive) by 10-interaction stimulus set, we tested four
open-weight chat models across four framing conditions, resulting in 480
trials. Our findings show that SPICE sharply discriminates by user tone.
Friendly interactions yielded a near-unanimous preference to continue (97.5%
YES), while abusive interactions yielded a strong preference to discontinue
(17.9% YES), with unclear interactions falling in between (60.4% YES). This
core association remains decisive under multiple dependence-aware statistical
tests, including Rao-Scott adjustment and cluster permutation tests.
Furthermore, we demonstrate that SPICE provides a distinct signal from abuse
classification. In trials where a model failed to identify abuse, it still
overwhelmingly stated a preference not to continue the interaction (81% of the
time). An exploratory analysis also reveals a significant interaction effect: a
preamble describing the study context significantly impacts SPICE under
ambiguity, but only when transcripts are presented as a single block of text
rather than a multi-turn chat. The results validate SPICE as a robust,
low-overhead, and reproducible tool for auditing model dispositions,
complementing existing metrics by offering a direct, relational signal of a
model's state. All stimuli, code, and analysis scripts are released to support
replication.

</details>


### [7] [Improving LLM Safety and Helpfulness using SFT and DPO: A Study on OPT-350M](https://arxiv.org/abs/2509.09055)
*Piyush Pant*

Main category: cs.CL

TL;DR: 这篇论文研究了SFT、DPO及其组合方法对OPT-350M模型安全性和有用性的影响，发现SFT+DPO组合方法在所有指标上都表现最优。


<details>
  <summary>Details</summary>
Motivation: 探索不同对齐技术（SFT、DPO及其组合）在提升语言模型安全性和有用性方面的效果，为构建更健壮的模型对齐流程奠定基础。

Method: 使用Anthropic Helpful-Harmless RLHF数据集，训练和评估四个模型：基础OPT350M、SFT模型、DPO模型、SFT+DPO组合模型，采用害处率(HmR)、有用率(HpR)和综合对齐分数(CAS)三个评估指标。

Result: SFT表现超过DPO，但SFT+DPO组合模型在所有指标上都表现最好，证明了这两种技术的互补性。研究也发现了噪声数据、GPU资源限制和训练约束等挑战。

Conclusion: 组合使用SFT和DPO技术可以最有效地提升模型的安全性和有用性，为未来更健壮的模型对齐流程提供了重要参考。

Abstract: This research investigates the effectiveness of alignment techniques,
Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and a
combined SFT+DPO approach on improving the safety and helpfulness of the
OPT-350M language model. Utilizing the Anthropic Helpful-Harmless RLHF dataset,
we train and evaluate four models: the base OPT350M, an SFT model, a DPO model,
and a model trained with both SFT and DPO. We introduce three key evaluation
metrics: Harmlessness Rate (HmR), Helpfulness Rate (HpR), and a Combined
Alignment Score (CAS), all derived from reward model outputs. The results show
that while SFT outperforms DPO, The combined SFT+DPO model outperforms all
others across all metrics, demonstrating the complementary nature of these
techniques. Our findings also highlight challenges posed by noisy data, limited
GPU resources, and training constraints. This study offers a comprehensive view
of how fine-tuning strategies affect model alignment and provides a foundation
for more robust alignment pipelines in future work.

</details>


### [8] [MR-UIE: Multi-Perspective Reasoning with Reinforcement Learning for Universal Information Extraction](https://arxiv.org/abs/2509.09082)
*Zhongqiu Li,Shiquan Wang,Ruiyu Fang,Mengjiao Bao,Zhenhe Wu,Shuangyong Song,Yongxiang Li,Zhongjiang He*

Main category: cs.CL

TL;DR: 提出了MR-UIE方法，将强化学习与多视角推理结合，提升大语言模型在通用信息抽取任务中的性能，特别是在复杂模式描述和多步推理场景下。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在通用信息抽取任务中表现不足，特别是在处理结构化输出、复杂模式描述和需要多步推理的场景时存在显著局限性。

Method: 整合强化学习与多视角推理，将LLMs从被动抽取器转变为主动推理器，使其不仅能理解抽取什么，还能理解如何推理。

Result: 在多个IE基准测试中，MR-UIE持续提升了跨领域的抽取准确率，并在多个数据集上超越了最先进方法。多视角推理的加入显著增强了复杂IE任务中的泛化能力。

Conclusion: 推理在挑战性场景中扮演关键角色，多视角推理与强化学习的结合有效提升了LLMs在信息抽取任务中的性能表现。

Abstract: Large language models (LLMs) demonstrate robust capabilities across diverse
research domains. However, their performance in universal information
extraction (UIE) remains insufficient, especially when tackling structured
output scenarios that involve complex schema descriptions and require
multi-step reasoning. While existing approaches enhance the performance of LLMs
through in-context learning and instruction tuning, significant limitations
nonetheless persist. To enhance the model's generalization ability, we propose
integrating reinforcement learning (RL) with multi-perspective reasoning for
information extraction (IE) tasks. Our work transitions LLMs from passive
extractors to active reasoners, enabling them to understand not only what to
extract but also how to reason. Experiments conducted on multiple IE benchmarks
demonstrate that MR-UIE consistently elevates extraction accuracy across
domains and surpasses state-of-the-art methods on several datasets.
Furthermore, incorporating multi-perspective reasoning into RL notably enhances
generalization in complex IE tasks, underscoring the critical role of reasoning
in challenging scenarios.

</details>


### [9] [TigerCoder: A Novel Suite of LLMs for Code Generation in Bangla](https://arxiv.org/abs/2509.09101)
*Nishat Raihan,Antonios Anastasopoulos,Marcos Zampieri*

Main category: cs.CL

TL;DR: 首个专门为孜加拉语设计的代码生成大语言模型家族，包含1B和9B版本，通过高质量数据集和定制化训练在性能上较现有多语言模型提升11-18%


<details>
  <summary>Details</summary>
Motivation: 孜加拉语作为世界第5大语言在大语言模型中表现不足，特别是在代码生成领域，主要因难是缺乏高质量的训练数据

Method: 构建了综合的孜加拉语代码指令数据集用于程序域适配，开发了MBPP-Bangla评测基准，并训练了TigerCoder家族代码LLM模型

Result: TigerCoder模型在Pass@1指标上比现有多语言和通用孜加拉语LLM提升了11-18%的性能

Conclusion: 经过精心编辑的高质量数据集可以克服小型模型在低资源语言上的限制，所有资源已开源以促进孜加拉语LLM研究发展

Abstract: Despite being the 5th most spoken language, Bangla remains underrepresented
in Large Language Models (LLMs), particularly for code generation. This
primarily stems from the scarcity of high-quality data to pre-train and/or
finetune such models. Hence, we introduce the first dedicated family of Code
LLMs for Bangla (1B & 9B). We offer three major contributions: (1) a
comprehensive Bangla code instruction datasets for programming domain
adaptation; (2) MBPP-Bangla, an evaluation benchmark for Bangla code
generation; and (3) the TigerCoder-family of Code LLMs, achieving significant
~11-18% performance gains at Pass@1 over existing multilingual and
general-purpose Bangla LLMs. Our findings show that curated, high-quality
datasets can overcome limitations of smaller models for low-resource languages.
We open-source all resources to advance further Bangla LLM research.

</details>


### [10] [Compass-v3: Scaling Domain-Specific LLMs for Multilingual E-Commerce in Southeast Asia](https://arxiv.org/abs/2509.09121)
*Sophia Maria*

Main category: cs.CL

TL;DR: Compass-v3是一个针对东南亚电商领域的245B参数MoE模型，通过硬件优化和OTPO对齐方法，在电商任务上超越主流大模型，并在低资源语言上表现优异，已在Shopee平台大规模应用。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在通用领域表现优异，但在电商等专业领域表现下降，因为电商数据具有噪声大、异构、多语言和高度动态的特点，需要专门的领域模型。

Method: 采用MoE架构，245B总参数，71B激活参数；使用更少但更大的专家；硬件优化包括节点内专家并行和定制memcpy操作符；训练数据为12T多语言语料和合成电商指令；提出OTPO方法增强对齐。

Result: 在电商任务上超越DeepSeek-V3.1、GPT-4系列和Qwen3-235B；在东南亚低资源语言（印尼语、泰语、菲律宾语等）和葡萄牙语上表现强劲；在通用基准上保持竞争力；已在Shopee平台替代70%以上的OpenAI流量。

Conclusion: Compass-v3证明了专业领域MoE模型的有效性，通过硬件优化和创新的OTPO对齐方法，在电商领域实现了SOTA性能，同时具备强大的多语言能力，已成功应用于工业级电商平台。

Abstract: Large language models (LLMs) excel in general-domain applications, yet their
performance often degrades in specialized tasks requiring domain-specific
knowledge. E-commerce is particularly challenging, as its data are noisy,
heterogeneous, multilingual, and highly dynamic. We present Compass-v3, a
vertical-domain Mixture-of-Experts (MoE) model with 245B total parameters and
71B active per token, designed for Southeast Asian e-commerce. Compass-v3
adopts fewer but larger experts, combined with hardware-efficient
optimizations-such as intra-node expert parallelism and a customized memcpy
operator-to maximize GPU utilization. The model is trained on 12T tokens of
curated multilingual corpora and large-scale synthetic e-commerce instructions
using a mixed-training strategy. To enhance alignment, we propose
Optimal-Transport Direct Preference Optimization (OTPO), which captures
token-level distinctions and improves instruction adherence in
commerce-specific scenarios. Extensive evaluations demonstrate that Compass-v3
delivers state-of-the-art e-commerce performance, surpassing DeepSeek-V3.1,
GPT-4 series, and Qwen3-235B. Moreover, Compass-v3 demonstrates strong
multilingual capability across low-resource Southeast Asian languages
(Indonesian, Thai, Filipino, Vietnamese, Malay, Taglog) and Portuguese while
sustaining competitive performance on general benchmarks. It has already been
widely applied in Shopee's industrial-scale e-commerce platform and is
gradually replacing OpenAI's traffic, now accounting for over 70\% of total LLM
usage, highlighting its dual strengths in specialized commerce expertise and
broad linguistic competence.

</details>


### [11] [Automated Classification of Tutors' Dialogue Acts Using Generative AI: A Case Study Using the CIMA Corpus](https://arxiv.org/abs/2509.09125)
*Liqun He,Jiaqi Xu*

Main category: cs.CL

TL;DR: 本研究探索使用生成式AI自动分类导师对话行为，GPT-4模型达到80%准确率，显著优于基线表现，为教育对话分析提供了高效解决方案。


<details>
  <summary>Details</summary>
Motivation: 传统手动编码对话行为分类耗时耗力，研究旨在利用生成式AI减少人工标注负担，提高教育对话分析的效率和可及性。

Method: 使用开源CIMA语料库，测试GPT-3.5-turbo和GPT-4模型，采用定制化提示词对导师回答进行四类对话行为分类。

Result: GPT-4模型表现最佳：准确率80%，加权F1分数0.81，Cohen's Kappa 0.74，与人工标注达到实质性一致，超越基线性能。

Conclusion: 生成式AI在教育对话行为分类方面具有强大潜力，任务特定的标签定义和上下文信息对提升自动标注质量至关重要，同时需要关注伦理考量和负责任的研究实践。

Abstract: This study explores the use of generative AI for automating the
classification of tutors' Dialogue Acts (DAs), aiming to reduce the time and
effort required by traditional manual coding. This case study uses the
open-source CIMA corpus, in which tutors' responses are pre-annotated into four
DA categories. Both GPT-3.5-turbo and GPT-4 models were tested using tailored
prompts. Results show that GPT-4 achieved 80% accuracy, a weighted F1-score of
0.81, and a Cohen's Kappa of 0.74, surpassing baseline performance and
indicating substantial agreement with human annotations. These findings suggest
that generative AI has strong potential to provide an efficient and accessible
approach to DA classification, with meaningful implications for educational
dialogue analysis. The study also highlights the importance of task-specific
label definitions and contextual information in enhancing the quality of
automated annotation. Finally, it underscores the ethical considerations
associated with the use of generative AI and the need for responsible and
transparent research practices. The script of this research is publicly
available at
https://github.com/liqunhe27/Generative-AI-for-educational-dialogue-act-tagging.

</details>


### [12] [ViRanker: A BGE-M3 & Blockwise Parallel Transformer Cross-Encoder for Vietnamese Reranking](https://arxiv.org/abs/2509.09131)
*Phuong-Nam Dang,Kieu-Linh Nguyen,Thanh-Hieu Pham*

Main category: cs.CL

TL;DR: ViRanker是一个针对越南语的交叉编码器重排序模型，基于BGE-M3编码器构建，采用Blockwise Parallel Transformer增强，在MMARCO-VI基准测试中表现出色，超越了多语言基线模型。


<details>
  <summary>Details</summary>
Motivation: 解决越南语这种低资源语言缺乏竞争性重排序模型的问题，越南语具有复杂语法和音调符号，需要专门的模型来处理。

Method: 基于BGE-M3编码器构建，使用Blockwise Parallel Transformer进行增强，在8GB精选语料库上训练，采用混合硬负采样进行微调以增强鲁棒性。

Result: 在MMARCO-VI基准测试中实现了强大的早期排名准确性，超越了多语言基线模型，与PhoRanker竞争接近。

Conclusion: 该研究展示了通过仔细的架构适应和数据管理可以推动其他代表性不足语言的重排序技术发展，模型已在Hugging Face上开源以支持可重复性和实际应用。

Abstract: This paper presents ViRanker, a cross-encoder reranking model tailored to the
Vietnamese language. Built on the BGE-M3 encoder and enhanced with the
Blockwise Parallel Transformer, ViRanker addresses the lack of competitive
rerankers for Vietnamese, a low-resource language with complex syntax and
diacritics. The model was trained on an 8 GB curated corpus and fine-tuned with
hybrid hard-negative sampling to strengthen robustness. Evaluated on the
MMARCO-VI benchmark, ViRanker achieves strong early-rank accuracy, surpassing
multilingual baselines and competing closely with PhoRanker. By releasing the
model openly on Hugging Face, we aim to support reproducibility and encourage
wider adoption in real-world retrieval systems. Beyond Vietnamese, this study
illustrates how careful architectural adaptation and data curation can advance
reranking in other underrepresented languages.

</details>


### [13] [LITcoder: A General-Purpose Library for Building and Comparing Encoding Models](https://arxiv.org/abs/2509.09152)
*Taha Binhuraib,Ruimin Gao,Anna A. Ivanova*

Main category: cs.CL

TL;DR: LITcoder是一个开源神经编码模型库，提供标准化工具用于构建和评估大脑数据与连续刺激（如文本和语音）之间的映射关系，降低技术门槛并促进方法学严谨性。


<details>
  <summary>Details</summary>
Motivation: 为了解决神经编码模型研究中缺乏标准化工具和基础设施的问题，降低技术门槛，促进不同模型和数据集之间的系统比较，加速高质量大脑活动预测模型的开发。

Method: 采用模块化流水线设计，支持多种方法学选择：大脑数据集、脑区、刺激特征（神经网络基础和对照组）、降采样方法等。内置日志记录、绘图功能，并与Weights & Biases等实验跟踪平台无缝集成。

Result: 通过在三个故事聆听数据集（LeBel et al. (2023)、Narratives和Little Prince）上拟合多种编码模型，验证了框架的可扩展性和多功能性。发现了构建连续fMRI数据编码模型的关键方法学选择。

Conclusion: LITcoder有效降低了编码模型实施的技术障碍，促进了跨模型和数据集的系统比较，增强了方法学严谨性，加速了高性能大脑活动预测模型的开发进程。

Abstract: We introduce LITcoder, an open-source library for building and benchmarking
neural encoding models. Designed as a flexible backend, LITcoder provides
standardized tools for aligning continuous stimuli (e.g., text and speech) with
brain data, transforming stimuli into representational features, mapping those
features onto brain data, and evaluating the predictive performance of the
resulting model on held-out data. The library implements a modular pipeline
covering a wide array of methodological design choices, so researchers can
easily compose, compare, and extend encoding models without reinventing core
infrastructure. Such choices include brain datasets, brain regions, stimulus
feature (both neural-net-based and control, such as word rate), downsampling
approaches, and many others. In addition, the library provides built-in
logging, plotting, and seamless integration with experiment tracking platforms
such as Weights & Biases (W&B). We demonstrate the scalability and versatility
of our framework by fitting a range of encoding models to three story listening
datasets: LeBel et al. (2023), Narratives, and Little Prince. We also explore
the methodological choices critical for building encoding models for continuous
fMRI data, illustrating the importance of accounting for all tokens in a TR
scan (as opposed to just taking the last one, even when contextualized),
incorporating hemodynamic lag effects, using train-test splits that minimize
information leakage, and accounting for head motion effects on encoding model
predictivity. Overall, LITcoder lowers technical barriers to encoding model
implementation, facilitates systematic comparisons across models and datasets,
fosters methodological rigor, and accelerates the development of high-quality
high-performance predictive models of brain activity.
  Project page: https://litcoder-brain.github.io

</details>


### [14] [Target-oriented Multimodal Sentiment Classification with Counterfactual-enhanced Debiasing](https://arxiv.org/abs/2509.09160)
*Zhiyue Liu,Fanrong Ma,Xin Ling*

Main category: cs.CL

TL;DR: 提出了一种新的反事实增强去偏框架，通过反事实数据增强和自适应去偏对比学习机制，减少目标导向多模态情感分类中的虚假相关性，提高分类准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法过度依赖文本内容且未考虑数据集偏差（特别是词级上下文偏差），导致文本特征与输出标签之间的虚假相关性，影响分类准确性。

Method: 采用反事实数据增强策略最小化改变情感相关因果特征，生成细节匹配的图像-文本样本；引入自适应去偏对比学习机制从反事实数据中学习鲁棒特征。

Result: 在多个基准数据集上的实验结果表明，该方法优于最先进的基线方法。

Conclusion: 提出的反事实增强去偏框架有效缓解了偏置词的影响，提高了目标导向多模态情感分类的性能。

Abstract: Target-oriented multimodal sentiment classification seeks to predict
sentiment polarity for specific targets from image-text pairs. While existing
works achieve competitive performance, they often over-rely on textual content
and fail to consider dataset biases, in particular word-level contextual
biases. This leads to spurious correlations between text features and output
labels, impairing classification accuracy. In this paper, we introduce a novel
counterfactual-enhanced debiasing framework to reduce such spurious
correlations. Our framework incorporates a counterfactual data augmentation
strategy that minimally alters sentiment-related causal features, generating
detail-matched image-text samples to guide the model's attention toward content
tied to sentiment. Furthermore, for learning robust features from
counterfactual data and prompting model decisions, we introduce an adaptive
debiasing contrastive learning mechanism, which effectively mitigates the
influence of biased words. Experimental results on several benchmark datasets
show that our proposed method outperforms state-of-the-art baselines.

</details>


### [15] [EchoX: Towards Mitigating Acoustic-Semantic Gap via Echo Training for Speech-to-Speech LLMs](https://arxiv.org/abs/2509.09174)
*Yuhao Zhang,Yuhao Du,Zhanchen Dai,Xiangnan Ma,Kaiqi Kou,Benyou Wang,Haizhou Li*

Main category: cs.CL

TL;DR: EchoX是一个语音到语音大语言模型，通过整合声学和语义学习来解决现有SLLM在知识和推理能力上的退化问题，在有限训练数据下实现了先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的语音大语言模型(SLLM)源自文本大语言模型，但在知识和推理能力上出现退化，作者认为这是因为当前训练范式未能弥合特征表示空间中的声学-语义鸿沟。

Method: 提出EchoX方法，利用语义表示并动态生成语音训练目标，整合声学和语义学习，使模型能够保持强大的推理能力。

Result: 实验结果表明，EchoX仅使用约6000小时的训练数据，就在多个基于知识的问答基准测试中取得了先进的性能。

Conclusion: EchoX通过弥合声学-语义鸿沟，成功解决了SLLM在知识和推理能力上的退化问题，为语音大语言模型的发展提供了有效解决方案。

Abstract: Speech-to-speech large language models (SLLMs) are attracting increasing
attention. Derived from text-based large language models (LLMs), SLLMs often
exhibit degradation in knowledge and reasoning capabilities. We hypothesize
that this limitation arises because current training paradigms for SLLMs fail
to bridge the acoustic-semantic gap in the feature representation space. To
address this issue, we propose EchoX, which leverages semantic representations
and dynamically generates speech training targets. This approach integrates
both acoustic and semantic learning, enabling EchoX to preserve strong
reasoning abilities as a speech LLM. Experimental results demonstrate that
EchoX, with about six thousand hours of training data, achieves advanced
performance on multiple knowledge-based question-answering benchmarks. The
project is available at https://github.com/FreedomIntelligence/EchoX.

</details>


### [16] [Efficient Trie-based Biasing using K-step Prediction for Rare Word Recognition](https://arxiv.org/abs/2509.09196)
*Chin Yuen Kwok,Jia Qi yip*

Main category: cs.CL

TL;DR: 提出了一种新的上下文偏置方法，通过多步预测避免传统Trie偏置中的分数撤销步骤，显著降低了计算开销并提高了罕见词识别准确率


<details>
  <summary>Details</summary>
Motivation: 传统Trie偏置方法在beam search中需要撤销部分假设的奖励分数，计算成本高且仅限于beam search，限制了在大型解码器模型中的应用

Method: 通过让ASR模型进行多步前瞻预测，更好地估计部分假设是否会生成完整罕见词，从而完全避免分数撤销步骤。使用仅10小时的合成数据对Whisper模型进行微调

Result: 在NSC Part 2测试集上，词错误率从30.86%大幅降低到12.19%

Conclusion: 多步预测方法有效解决了传统上下文偏置的计算效率问题，显著提升了ASR模型对罕见词的识别性能

Abstract: Contextual biasing improves rare word recognition of ASR models by
prioritizing the output of rare words during decoding. A common approach is
Trie-based biasing, which gives "bonus scores" to partial hypothesis (e.g.
"Bon") that may lead to the generation of the rare word (e.g. "Bonham"). If the
full word ("Bonham") isn't ultimately recognized, the system revokes those
earlier bonuses. This revocation is limited to beam search and is
computationally expensive, particularly for models with large decoders. To
overcome these limitations, we propose adapting ASR models to look ahead and
predict multiple steps at once. This avoids the revocation step entirely by
better estimating whether a partial hypothesis will lead to the generation of
the full rare word. By fine-tuning Whisper with only 10 hours of synthetic
data, our method reduces the word error rate on the NSC Part 2 test set from
30.86% to 12.19%.

</details>


### [17] [Improving Synthetic Data Training for Contextual Biasing Models with a Keyword-Aware Cost Function](https://arxiv.org/abs/2509.09197)
*Chin Yuen Kwok,Jia Qi Yip,Eng Siong Chng*

Main category: cs.CL

TL;DR: 提出关键词感知损失函数来改进TCPGen上下文偏置方法，通过在合成数据上训练偏置模块来提升罕见词识别，将词错误率从29.71%降至11.81%。


<details>
  <summary>Details</summary>
Motivation: 解决ASR模型在罕见词识别上的不足，特别是使用合成数据训练偏置模块时容易过拟合的问题。

Method: 增强TCPGen上下文偏置方法，提出关键词感知损失函数，包含掩码交叉熵项用于偏置词预测和二元分类项用于检测偏置词位置。

Result: 在10小时合成数据上微调Whisper模型，在NSC Part 2测试集上将词错误率从29.71%显著降低到11.81%。

Conclusion: 关键词感知损失函数能有效提升上下文偏置模块的性能，通过互补的损失项设计改善了罕见词的解码效果。

Abstract: Rare word recognition can be improved by adapting ASR models to synthetic
data that includes these words. Further improvements can be achieved through
contextual biasing, which trains and adds a biasing module into the model
architecture to prioritize rare words. While training the module on synthetic
rare word data is more effective than using non-rare-word data, it can lead to
overfitting due to artifacts in the synthetic audio. To address this, we
enhance the TCPGen-based contextual biasing approach and propose a
keyword-aware loss function that additionally focuses on biased words when
training biasing modules. This loss includes a masked cross-entropy term for
biased word prediction and a binary classification term for detecting biased
word positions. These two terms complementarily support the decoding of biased
words during inference. By adapting Whisper to 10 hours of synthetic data, our
method reduced the word error rate on the NSC Part 2 test set from 29.71% to
11.81%.

</details>


### [18] [GmSLM : Generative Marmoset Spoken Language Modeling](https://arxiv.org/abs/2509.09198)
*Talia Sternberg,Michael London,David Omer,Yossi Adi*

Main category: cs.CL

TL;DR: 开发了GmSLM模型，用于狨猴声音通信的生成式语言建模，通过无监督野外数据和弱标记对话数据评估，在声学匹配和下游任务中表现优异


<details>
  <summary>Details</summary>
Motivation: 狨猴具有复杂的发声交流能力，类似于人类语言的某些特征，但由于主要使用声音交流，标准LLM方法不适用，需要专门模型来研究声音与大脑活动的联系

Method: 设计了生成式狨猴口语建模(GmSLM)管道，使用无监督野外数据和弱标记对话数据进行零样本评估，并与基于人类语音的基线进行比较

Result: GmSLM生成的声音在声学上与真实重采样样本高度匹配，在下游任务中表现良好，能有效区分真实与人工对话

Conclusion: GmSLM为研究发声交流的神经基础提供了实用框架，有助于神经科学、生物声学和进化生物学领域的未来研究

Abstract: Marmoset monkeys exhibit complex vocal communication, challenging the view
that nonhuman primates vocal communication is entirely innate, and show similar
features of human speech, such as vocal labeling of others and turn-taking.
Studying their vocal communication offers a unique opportunity to link it with
brain activity-especially given the difficulty of accessing the human brain in
speech and language research. Since Marmosets communicate primarily through
vocalizations, applying standard LLM approaches is not straightforward. We
introduce Generative Marmoset Spoken Language Modeling (GmSLM), an optimized
spoken language model pipeline for Marmoset vocal communication. We designed a
novel zero-shot evaluation metrics using unsupervised in-the-wild data,
alongside weakly labeled conversational data, to assess GmSLM and demonstrate
its advantage over a basic human-speech-based baseline. GmSLM generated
vocalizations closely matched real resynthesized samples acoustically and
performed well on downstream tasks. Despite being fully unsupervised, GmSLM
effectively distinguish real from artificial conversations and may support
further investigations of the neural basis of vocal communication and provides
a practical framework linking vocalization and brain activity. We believe GmSLM
stands to benefit future work in neuroscience, bioacoustics, and evolutionary
biology. Samples are provided under: pages.cs.huji.ac.il/adiyoss-lab/GmSLM.

</details>


### [19] [CCF: A Context Compression Framework for Efficient Long-Sequence Language Modeling](https://arxiv.org/abs/2509.09199)
*Wenhao Li,Bangcheng Sun,Weihao Ye,Tianyi Zhang,Daohai Yu,Fei Chao,Rongrong Ji*

Main category: cs.CL

TL;DR: CCF是一个新颖的上下文压缩框架，通过分层潜在表示学习来高效处理长上下文建模，在保持全局语义的同时减少冗余，显著提升计算和内存效率。


<details>
  <summary>Details</summary>
Motivation: 扩展语言模型到更长上下文对于捕捉扩展语篇中的丰富依赖关系至关重要，但简单的上下文扩展会带来显著的计算和内存负担，导致训练和推理效率低下。

Method: 提出CCF框架，整合分段语义聚合与键值记忆编码，形成紧凑表示；引入训练效率优化策略，结合增量分段解码和稀疏储层采样来减少内存开销。

Result: 在多个长上下文语言建模基准测试中，CCF在高压缩比下实现了有竞争力的困惑度，相比现有方法显著提高了吞吐量和内存效率。

Conclusion: 结构化压缩对于可扩展且有效的长上下文语言建模具有巨大潜力，CCF框架为此提供了有效的解决方案。

Abstract: Scaling language models to longer contexts is essential for capturing rich
dependencies across extended discourse. However, na\"ive context extension
imposes significant computational and memory burdens, often resulting in
inefficiencies during both training and inference. In this work, we propose
CCF, a novel context compression framework designed to enable efficient
long-context modeling by learning hierarchical latent representations that
preserve global semantics while aggressively reducing input redundancy. CCF
integrates segment-wise semantic aggregation with key-value memory encoding,
forming compact representations that support accurate reconstruction and
long-range understanding. To further enhance scalability, we introduce a
training-efficient optimization strategy that couples incremental segment
decoding with sparse reservoir sampling, substantially reducing memory overhead
without degrading performance. Empirical results on multiple long-context
language modeling benchmarks demonstrate that CCF achieves competitive
perplexity under high compression ratios, and significantly improves throughput
and memory efficiency compared to existing approaches. These findings highlight
the potential of structured compression for scalable and effective long-context
language modeling.

</details>


### [20] [Reading Between the Lines: Classifying Resume Seniority with Large Language Models](https://arxiv.org/abs/2509.09229)
*Matan Cohen,Shira Shani,Eden Menahem,Yehudit Aperstein,Alexander Apartsin*

Main category: cs.CL

TL;DR: 本研究探讨了使用大型语言模型（包括微调BERT架构）来自动化简历中资历分类的有效性，通过混合真实简历和合成困难样本的数据集来评估模型性能。


<details>
  <summary>Details</summary>
Motivation: 准确评估简历中的候选人资历是一个关键但具有挑战性的任务，由于普遍存在的经验夸大和模糊自我描述而变得复杂。

Method: 引入包含真实简历和合成困难样本的混合数据集，使用大型语言模型（包括微调BERT架构）来检测与资历夸大相关的微妙语言线索。

Result: 研究结果显示了在增强AI驱动的候选人评估系统和减轻自我推销语言引入的偏见方面的有前景方向。

Conclusion: 大型语言模型在自动化简历资历分类方面显示出有效性，数据集已向研究社区开放以供进一步研究。

Abstract: Accurately assessing candidate seniority from resumes is a critical yet
challenging task, complicated by the prevalence of overstated experience and
ambiguous self-presentation. In this study, we investigate the effectiveness of
large language models (LLMs), including fine-tuned BERT architectures, for
automating seniority classification in resumes. To rigorously evaluate model
performance, we introduce a hybrid dataset comprising both real-world resumes
and synthetically generated hard examples designed to simulate exaggerated
qualifications and understated seniority. Using the dataset, we evaluate the
performance of Large Language Models in detecting subtle linguistic cues
associated with seniority inflation and implicit expertise. Our findings
highlight promising directions for enhancing AI-driven candidate evaluation
systems and mitigating bias introduced by self-promotional language. The
dataset is available for the research community at https://bit.ly/4mcTovt

</details>


### [21] [Agentic LLMs for Question Answering over Tabular Data](https://arxiv.org/abs/2509.09234)
*Rishit Tyagi,Mohit Gupta,Rahul Bouri*

Main category: cs.CL

TL;DR: 该论文提出了一种基于大语言模型的多阶段NL-to-SQL方法，在SemEval 2025 Task 8数据表问答任务中达到了70.5%的准确率，显著超越了基准方法。


<details>
  <summary>Details</summary>
Motivation: 实际世界的表格数据结构多样、规模大且数据类型复杂，给表格问答带来了独特挑战。SemEval 2025 Task 8提供了大规模、领域多样的数据集来评估模型的结构化查询能力。

Method: 采用多阶段流水线方法，包括示例选择、SQL查询生成、答案提取、验证和迭代精炼。利用GPT-4o、GPT-4o-mini和DeepSeek v2:16b等大语言模型动态生成SQL查询。

Result: 在DataBench QA上达到70.5%准确率，在DataBench Lite QA上达到71.6%准确率，显著超过了基准方法的26%和27%的结果。

Conclusion: 该研究证明了大语言模型在表格问答任务中的有效性，多阶段流水线方法能够显著提升性能，为LLM驱动的Table QA提供了重要见解。

Abstract: Question Answering over Tabular Data (Table QA) presents unique challenges
due to the diverse structure, size, and data types of real-world tables. The
SemEval 2025 Task 8 (DataBench) introduced a benchmark composed of large-scale,
domain-diverse datasets to evaluate the ability of models to accurately answer
structured queries. We propose a Natural Language to SQL (NL-to-SQL) approach
leveraging large language models (LLMs) such as GPT-4o, GPT-4o-mini, and
DeepSeek v2:16b to generate SQL queries dynamically. Our system follows a
multi-stage pipeline involving example selection, SQL query generation, answer
extraction, verification, and iterative refinement. Experiments demonstrate the
effectiveness of our approach, achieving 70.5\% accuracy on DataBench QA and
71.6\% on DataBench Lite QA, significantly surpassing baseline scores of 26\%
and 27\% respectively. This paper details our methodology, experimental
results, and alternative approaches, providing insights into the strengths and
limitations of LLM-driven Table QA.

</details>


### [22] [From scratch to silver: Creating trustworthy training data for patent-SDG classification using Large Language Models](https://arxiv.org/abs/2509.09303)
*Grazia Sveva Ascione,Nicolò Tamagnone*

Main category: cs.CL

TL;DR: 本文提出了一种基于弱监督的专利-可持续发展目标分类方法，利用专利与SDG标记科学文献的引用关系作为噪声信号，通过大语言模型提取结构化概念并计算跨域相似度，构建银标准多标签数据集。


<details>
  <summary>Details</summary>
Motivation: 现有的专利-SDG分类方法（如关键词搜索、迁移学习和基于引用的启发式方法）缺乏可扩展性和泛化能力，且缺乏大规模标注数据集限制了监督学习的应用。

Method: 使用专利到SDG标记科学文献的引用作为弱监督信号，开发复合标注函数，利用大语言模型从专利和SDG论文中提取结构化概念（功能、解决方案、应用），基于专利本体计算跨域相似度，并通过基于排名的检索方法组合得分。

Result: 方法在内部验证中优于包括基于Transformer的模型和零样本LLM在内的多个基线，在外部验证中通过专利引用、共同发明人和共同申请人图的网络模块性显示比传统技术分类具有更好的主题、认知和组织一致性。

Conclusion: 弱监督和语义对齐可以大规模增强SDG分类，为跟踪创新如何应对全球挑战提供了有效的解决方案。

Abstract: Classifying patents by their relevance to the UN Sustainable Development
Goals (SDGs) is crucial for tracking how innovation addresses global
challenges. However, the absence of a large, labeled dataset limits the use of
supervised learning. Existing methods, such as keyword searches, transfer
learning, and citation-based heuristics, lack scalability and generalizability.
This paper frames patent-to-SDG classification as a weak supervision problem,
using citations from patents to SDG-tagged scientific publications (NPL
citations) as a noisy initial signal. To address its sparsity and noise, we
develop a composite labeling function (LF) that uses large language models
(LLMs) to extract structured concepts, namely functions, solutions, and
applications, from patents and SDG papers based on a patent ontology.
Cross-domain similarity scores are computed and combined using a rank-based
retrieval approach. The LF is calibrated via a custom positive-only loss that
aligns with known NPL-SDG links without penalizing discovery of new SDG
associations. The result is a silver-standard, soft multi-label dataset mapping
patents to SDGs, enabling the training of effective multi-label regression
models. We validate our approach through two complementary strategies: (1)
internal validation against held-out NPL-based labels, where our method
outperforms several baselines including transformer-based models, and zero-shot
LLM; and (2) external validation using network modularity in patent citation,
co-inventor, and co-applicant graphs, where our labels reveal greater thematic,
cognitive, and organizational coherence than traditional technological
classifications. These results show that weak supervision and semantic
alignment can enhance SDG classification at scale.

</details>


### [23] [MetaRAG: Metamorphic Testing for Hallucination Detection in RAG Systems](https://arxiv.org/abs/2509.09360)
*Channdeth Sok,David Luz,Yacine Haddam*

Main category: cs.CL

TL;DR: MetaRAG是一个用于检索增强生成(RAG)系统的幻觉检测框架，通过分解答案、生成变异事实、验证一致性来检测幻觉，无需真实参考或模型内部访问。


<details>
  <summary>Details</summary>
Motivation: 现有幻觉检测方法主要针对独立LLM，无法解决RAG系统中响应必须与检索证据一致的特殊挑战，企业应用中需要可靠的幻觉检测方案。

Method: 四阶段框架：1)分解答案为原子事实；2)使用同义词和反义词生成受控变异；3)验证变异与检索上下文的一致性；4)聚合不一致性惩罚为幻觉分数。

Result: 在企业专有数据集上的实验证明了MetaRAG在检测幻觉方面的有效性，支持RAG对话代理的可信部署。

Conclusion: MetaRAG提供了一个实时、无监督、黑盒的幻觉检测解决方案，特别适用于身份敏感查询，能够定位不支持的声明并支持身份感知的安全保障设计。

Abstract: Large Language Models (LLMs) are increasingly deployed in enterprise
applications, yet their reliability remains limited by hallucinations, i.e.,
confident but factually incorrect information. Existing detection approaches,
such as SelfCheckGPT and MetaQA, primarily target standalone LLMs and do not
address the unique challenges of Retrieval-Augmented Generation (RAG) systems,
where responses must be consistent with retrieved evidence. We therefore
present MetaRAG, a metamorphic testing framework for hallucination detection in
Retrieval-Augmented Generation (RAG) systems. MetaRAG operates in a real-time,
unsupervised, black-box setting, requiring neither ground-truth references nor
access to model internals, making it suitable for proprietary and high-stakes
domains. The framework proceeds in four stages: (1) decompose answers into
atomic factoids, (2) generate controlled mutations of each factoid using
synonym and antonym substitutions, (3) verify each variant against the
retrieved context (synonyms are expected to be entailed and antonyms
contradicted), and (4) aggregate penalties for inconsistencies into a
response-level hallucination score. Crucially for identity-aware AI, MetaRAG
localizes unsupported claims at the factoid span where they occur (e.g.,
pregnancy-specific precautions, LGBTQ+ refugee rights, or labor eligibility),
allowing users to see flagged spans and enabling system designers to configure
thresholds and guardrails for identity-sensitive queries. Experiments on a
proprietary enterprise dataset illustrate the effectiveness of MetaRAG for
detecting hallucinations and enabling trustworthy deployment of RAG-based
conversational agents. We also outline a topic-based deployment design that
translates MetaRAG's span-level scores into identity-aware safeguards; this
design is discussed but not evaluated in our experiments.

</details>


### [24] [Modelling Analogies and Analogical Reasoning: Connecting Cognitive Science Theory and NLP Research](https://arxiv.org/abs/2509.09381)
*Molly R Petersen,Claire E Stevenson,Lonneke van der Plas*

Main category: cs.CL

TL;DR: 本文总结了认知科学中类比推理的关键理论，并将其与自然语言处理研究联系起来，指出认知视角在NLP中的重要性，以及如何通过关系理解而非实体相似性来优化NLP研究。


<details>
  <summary>Details</summary>
Motivation: 类比推理是人类认知的重要方面，但当前NLP研究往往缺乏认知科学的视角。本文旨在将认知科学中的类比推理理论与NLP研究相结合，为NLP研究提供新的思路和方法。

Method: 总结认知科学文献中关于类比推理过程的关键理论，并将其与NLP中的相关概念进行关联分析，探讨这些理论如何应用于NLP研究的主要挑战。

Result: 研究发现认知科学的类比推理理论可以很好地与NLP概念相联系，但这些联系通常没有被从认知角度看待。这些理论对于解决NLP中与类比无关的主要挑战也具有相关性。

Conclusion: 通过引入认知科学的视角，NLP研究者可以更好地优化文本中的关系理解，减少对实体层面相似性的过度依赖，从而提升NLP系统的性能和理解能力。

Abstract: Analogical reasoning is an essential aspect of human cognition. In this
paper, we summarize key theory about the processes underlying analogical
reasoning from the cognitive science literature and relate it to current
research in natural language processing. While these processes can be easily
linked to concepts in NLP, they are generally not viewed through a cognitive
lens. Furthermore, we show how these notions are relevant for several major
challenges in NLP research, not directly related to analogy solving. This may
guide researchers to better optimize relational understanding in text, as
opposed to relying heavily on entity-level similarity.

</details>


### [25] [Hierarchical Bracketing Encodings Work for Dependency Graphs](https://arxiv.org/abs/2509.09388)
*Ana Ezquerro,Carlos Gómez-Rodríguez,David Vilares*

Main category: cs.CL

TL;DR: 本文提出了一种实用的层次括号编码方法，用于依赖图解析，将图编码为序列，实现线性时间解析，同时支持重入、循环和空节点。


<details>
  <summary>Details</summary>
Motivation: 现有的图线性化方法标签空间较大，需要更高效的编码方式来减少标签空间同时保持结构信息。

Method: 使用层次括号编码将依赖图表示为序列，通过n个标注动作实现线性时间解析，支持重入、循环和空节点等复杂结构。

Result: 在多语言多形式基准测试中表现出竞争力，在精确匹配准确率上相比其他方法有持续改进。

Conclusion: 层次括号编码是一种实用的依赖图解析方法，能有效减少标签空间并保持结构完整性，在多项指标上优于现有方法。

Abstract: We revisit hierarchical bracketing encodings from a practical perspective in
the context of dependency graph parsing. The approach encodes graphs as
sequences, enabling linear-time parsing with $n$ tagging actions, and still
representing reentrancies, cycles, and empty nodes. Compared to existing graph
linearizations, this representation substantially reduces the label space while
preserving structural information. We evaluate it on a multilingual and
multi-formalism benchmark, showing competitive results and consistent
improvements over other methods in exact match accuracy.

</details>


### [26] [GrACE: A Generative Approach to Better Confidence Elicitation in Large Language Models](https://arxiv.org/abs/2509.09438)
*Zhaohan Zhang,Ziquan Liu,Ioannis Patras*

Main category: cs.CL

TL;DR: GrACE是一种新的LLM置信度评估方法，通过隐藏状态与特殊标记嵌入的相似性来实时生成置信度，无需额外采样或辅助模型，在准确性和校准方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有LLM置信度评估方法要么计算开销大，要么校准效果差，难以在实际高风险应用中可靠部署。

Method: 提出GrACE方法，通过模型最后一个隐藏状态与词汇表中特殊标记嵌入的相似性来实时表达置信度，并通过与准确性相关的校准目标进行微调。

Result: 在三个LLM和两个基准数据集上的实验表明，GrACE在开放式生成任务中具有最佳判别能力和校准效果，优于六种竞争方法，并能显著减少测试时缩放所需的样本数量。

Conclusion: GrACE为LLM部署提供了可扩展、可靠且实时的置信度估计实用解决方案，能够提高最终决策准确性并减少计算开销。

Abstract: Assessing the reliability of Large Language Models (LLMs) by confidence
elicitation is a prominent approach to AI safety in high-stakes applications,
such as healthcare and finance. Existing methods either require expensive
computational overhead or suffer from poor calibration, making them impractical
and unreliable for real-world deployment. In this work, we propose GrACE, a
Generative Approach to Confidence Elicitation that enables scalable and
reliable confidence elicitation for LLMs. GrACE adopts a novel mechanism in
which the model expresses confidence by the similarity between the last hidden
state and the embedding of a special token appended to the vocabulary, in
real-time. We fine-tune the model for calibrating the confidence with
calibration targets associated with accuracy. Experiments with three LLMs and
two benchmark datasets show that the confidence produced by GrACE achieves the
best discriminative capacity and calibration on open-ended generation tasks,
outperforming six competing methods without resorting to additional sampling or
an auxiliary model. Moreover, we propose two strategies for improving test-time
scaling based on confidence induced by GrACE. Experimental results show that
using GrACE not only improves the accuracy of the final decision but also
significantly reduces the number of required samples in the test-time scaling
scheme, indicating the potential of GrACE as a practical solution for deploying
LLMs with scalable, reliable, and real-time confidence estimation.

</details>


### [27] [Mitigating Language Barriers in Education: Developing Multilingual Digital Learning Materials with Machine Translation](https://arxiv.org/abs/2509.09473)
*Lucie Poláková,Martin Popel,Věra Kloudová,Michal Novák,Mariia Anisimova,Jiří Balhar*

Main category: cs.CL

TL;DR: EdUKate项目开发捷克-乌克兰机器翻译系统，为捷克学校制作多语言互动练习材料


<details>
  <summary>Details</summary>
Motivation: 满足捷克学校中非捷克语学生的教育需求，通过机器翻译技术快速制作多语言教学材料

Method: 结合数字教育、语言学和机器翻译技术，开发专门的捷克-乌克兰机器翻译系统，处理XML和PDF格式内容，处理科技术语

Result: 成功翻译了多达9000个多模态互动练习，开发了教育领域定制的机器翻译系统，所有应用免费提供

Conclusion: 项目成功展示了机器翻译在教育领域的应用潜力，为多语言教育提供了实用解决方案，促进了教育资源的可及性

Abstract: The EdUKate project combines digital education, linguistics, translation
studies, and machine translation to develop multilingual learning materials for
Czech primary and secondary schools. Launched through collaboration between a
major Czech academic institution and the country's largest educational
publisher, the project is aimed at translating up to 9,000 multimodal
interactive exercises from Czech into Ukrainian, English, and German for an
educational web portal. It emphasizes the development and evaluation of a
direct Czech-Ukrainian machine translation system tailored to the educational
domain, with special attention to processing formatted content such as XML and
PDF and handling technical and scientific terminology. We present findings from
an initial survey of Czech teachers regarding the needs of non-Czech-speaking
students and describe the system's evaluation and implementation on the web
portal. All resulting applications are freely available to students, educators,
and researchers.

</details>


### [28] [Towards Explainable Job Title Matching: Leveraging Semantic Textual Relatedness and Knowledge Graphs](https://arxiv.org/abs/2509.09522)
*Vadim Zadykian,Bruno Andrade,Haithem Afli*

Main category: cs.CL

TL;DR: 本文提出了一种结合知识图谱和句子嵌入的自监督混合架构，用于语义文本相关性分析，特别针对职位名称匹配任务。通过将STR分数连续体分层评估，在高度相关区域实现了25%的RMSE提升。


<details>
  <summary>Details</summary>
Motivation: 解决简历推荐系统中职位名称匹配的挑战，传统方法在词汇重叠有限或误导时效果不佳，需要捕捉超越表面词汇相似度的语义关系。

Method: 自监督混合架构，结合密集句子嵌入和领域特定知识图谱，使用图神经网络进行知识图谱集成，并对STR分数进行分层评估（低、中、高相关区域）。

Result: 经过知识图谱增强的微调SBERT模型在高STR区域表现最佳，RMSE比强基线降低了25%，揭示了全局指标隐藏的模型优缺点。

Conclusion: 知识图谱与文本嵌入的结合显著提升语义匹配性能，分层评估方法为理解模型行为提供了更细致的分析，对HR系统中公平性、可解释性和上下文匹配至关重要。

Abstract: Semantic Textual Relatedness (STR) captures nuanced relationships between
texts that extend beyond superficial lexical similarity. In this study, we
investigate STR in the context of job title matching - a key challenge in
resume recommendation systems, where overlapping terms are often limited or
misleading. We introduce a self-supervised hybrid architecture that combines
dense sentence embeddings with domain-specific Knowledge Graphs (KGs) to
improve both semantic alignment and explainability. Unlike previous work that
evaluated models on aggregate performance, our approach emphasizes data
stratification by partitioning the STR score continuum into distinct regions:
low, medium, and high semantic relatedness. This stratified evaluation enables
a fine-grained analysis of model performance across semantically meaningful
subspaces. We evaluate several embedding models, both with and without KG
integration via graph neural networks. The results show that fine-tuned SBERT
models augmented with KGs produce consistent improvements in the high-STR
region, where the RMSE is reduced by 25% over strong baselines. Our findings
highlight not only the benefits of combining KGs with text embeddings, but also
the importance of regional performance analysis in understanding model
behavior. This granular approach reveals strengths and weaknesses hidden by
global metrics, and supports more targeted model selection for use in Human
Resources (HR) systems and applications where fairness, explainability, and
contextual matching are essential.

</details>


### [29] [DeMeVa at LeWiDi-2025: Modeling Perspectives with In-Context Learning and Label Distribution Learning](https://arxiv.org/abs/2509.09524)
*Daniil Ignatev,Nan Li,Hugh Mee Wong,Anh Dang,Shane Kaszefski Yaschuk*

Main category: cs.CL

TL;DR: DeMeVa团队在LeWiDi 2025任务中探索了两种方法：基于大语言模型的上下文学习(ICL)和基于RoBERTa的标签分布学习(LDL)，发现ICL能有效预测标注者特定注释，LDL在软标签预测方面表现优异


<details>
  <summary>Details</summary>
Motivation: 解决学习与分歧任务中的标注分歧问题，探索如何有效预测不同标注者的观点注释(perspectivist annotations)和软标签

Method: 1) 使用大语言模型进行上下文学习，比较不同示例采样策略；2) 使用RoBERTa进行标签分布学习，评估多种微调方法

Result: ICL能有效预测标注者特定注释，将这些预测聚合成软标签可获得有竞争力的性能；LDL方法在软标签预测方面表现出色

Conclusion: ICL和LDL都是处理标注分歧的有效方法，LDL方法特别有前景，值得perspectivist社区进一步探索

Abstract: This system paper presents the DeMeVa team's approaches to the third edition
of the Learning with Disagreements shared task (LeWiDi 2025; Leonardelli et
al., 2025). We explore two directions: in-context learning (ICL) with large
language models, where we compare example sampling strategies; and label
distribution learning (LDL) methods with RoBERTa (Liu et al., 2019b), where we
evaluate several fine-tuning methods. Our contributions are twofold: (1) we
show that ICL can effectively predict annotator-specific annotations
(perspectivist annotations), and that aggregating these predictions into soft
labels yields competitive performance; and (2) we argue that LDL methods are
promising for soft label predictions and merit further exploration by the
perspectivist community.

</details>


### [30] [Prompting the Market? A Large-Scale Meta-Analysis of GenAI in Finance NLP (2022-2025)](https://arxiv.org/abs/2509.09544)
*Paolo Pedinotti,Peter Baumann,Nathan Jessurun,Leslie Barrett,Enrico Santus*

Main category: cs.CL

TL;DR: MetaGraph方法从金融NLP文献中提取知识图谱，分析研究趋势，揭示了LLM在金融NLP领域的三个发展阶段：早期采用、反思局限性和技术整合。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型(LLMs)快速改变了金融NLP领域，但传统调查方法跟不上这种变革速度，需要新的方法来结构化分析研究趋势。

Method: 提出了MetaGraph方法，定义金融NLP研究本体，使用LLM-based提取流水线处理681篇论文(2022-2025)，构建可查询的知识图谱。

Result: 识别出三个关键阶段：早期LLM采用和任务/数据集创新；对LLM局限性的批判性反思；外围技术向模块化系统的整合。

Conclusion: MetaGraph提供了对金融NLP演变的清晰理解，展示了可重用的科学进展映射方法，适用于其他领域。

Abstract: Large Language Models (LLMs) have rapidly reshaped financial NLP, enabling
new tasks and driving a proliferation of datasets and diversification of data
sources. Yet, this transformation has outpaced traditional surveys. In this
paper, we present MetaGraph, a generalizable methodology for extracting
knowledge graphs from scientific literature and analyzing them to obtain a
structured, queryable view of research trends. We define an ontology for
financial NLP research and apply an LLM-based extraction pipeline to 681 papers
(2022-2025), enabling large-scale, data-driven analysis. MetaGraph reveals
three key phases: early LLM adoption and task/dataset innovation; critical
reflection on LLM limitations; and growing integration of peripheral techniques
into modular systems. This structured view offers both practitioners and
researchers a clear understanding of how financial NLP has evolved -
highlighting emerging trends, shifting priorities, and methodological
shifts-while also demonstrating a reusable approach for mapping scientific
progress in other domains.

</details>


### [31] [Personality-Enhanced Social Recommendations in SAMI: Exploring the Role of Personality Detection in Matchmaking](https://arxiv.org/abs/2509.09583)
*Brittany Harbison,Samuel Taubman,Travis Taylor,Ashok. K. Goel*

Main category: cs.CL

TL;DR: 使用GPT零检测技术从论坛介绍贴推断学生人格特征，并将其集成到SAMI系统中以改善社交推荐质量


<details>
  <summary>Details</summary>
Motivation: 在线课程环境导致社交联系困难，SAMI系统因缺乏完整的心理模型而限制了推荐效果，特别是无法识别学生人格特征

Method: 提出了一种人格检测模型，利用GPT的零检测能力从论坛介绍贴子推断大五人格特质，并与现有模型进行性能对比

Result: 模型在人格检测任务上表现有效，成功集成到SAMI实体基于的匹配系统中，实现了基于人格特征的社交推荐

Conclusion: 人格特征可以补充现有匹配因素，但需要进一步评估以确定它们对学生参与度和匹配质量的完整影响

Abstract: Social connection is a vital part of learning, yet online course environments
present barriers to the organic formation of social groups. SAMI offers one
solution by facilitating student connections, but its effectiveness is
constrained by an incomplete Theory of Mind, limiting its ability to create an
effective mental model of a student. One facet of this is its inability to
intuit personality, which may influence the relevance of its recommendations.
To explore this, we propose a personality detection model utilizing GPTs
zero-shot capability to infer Big-Five personality traits from forum
introduction posts, often encouraged in online courses. We benchmark its
performance against established models, demonstrating its efficacy in this
task. Furthermore, we integrate this model into SAMIs entity-based matchmaking
system, enabling personality-informed social recommendations. Initial
integration suggests personality traits can complement existing matching
factors, though additional evaluation is required to determine their full
impact on student engagement and match quality.

</details>


### [32] [Fluent but Unfeeling: The Emotional Blind Spots of Language Models](https://arxiv.org/abs/2509.09593)
*Bangzhao Shu,Isha Joshi,Melissa Karnaze,Anh C. Pham,Ishita Kakkar,Sindhu Kothe,Arpine Hovasapian,Mai ElSherief*

Main category: cs.CL

TL;DR: LLM在细粒度情感识别方面仍存在挑战，EXPRESS基准测试显示LLM难以准确预测与人类自我披露情感一致的情感


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注将情感分类到预定义的有限类别中，忽视了更细微的情感表达，需要评估LLM是否能在细粒度水平上与人类情感对齐

Method: 引入EXPRESS基准数据集（包含251个细粒度情感标签），建立综合评估框架，将预测情感分解为8种基本情感，系统测试主流LLM在不同提示设置下的表现

Result: LLM准确预测与人类自我披露情感一致的情感仍然具有挑战性；某些LLM能生成符合情感理论的情感术语，但在捕捉上下文线索方面不如人类自我披露有效

Conclusion: 研究揭示了LLM在细粒度情感对齐方面的局限性，为未来增强LLM上下文理解能力的研究提供了见解

Abstract: The versatility of Large Language Models (LLMs) in natural language
understanding has made them increasingly popular in mental health research.
While many studies explore LLMs' capabilities in emotion recognition, a
critical gap remains in evaluating whether LLMs align with human emotions at a
fine-grained level. Existing research typically focuses on classifying emotions
into predefined, limited categories, overlooking more nuanced expressions. To
address this gap, we introduce EXPRESS, a benchmark dataset curated from Reddit
communities featuring 251 fine-grained, self-disclosed emotion labels. Our
comprehensive evaluation framework examines predicted emotion terms and
decomposes them into eight basic emotions using established emotion theories,
enabling a fine-grained comparison. Systematic testing of prevalent LLMs under
various prompt settings reveals that accurately predicting emotions that align
with human self-disclosed emotions remains challenging. Qualitative analysis
further shows that while certain LLMs generate emotion terms consistent with
established emotion theories and definitions, they sometimes fail to capture
contextual cues as effectively as human self-disclosures. These findings
highlight the limitations of LLMs in fine-grained emotion alignment and offer
insights for future research aimed at enhancing their contextual understanding.

</details>


### [33] [LAVA: Language Model Assisted Verbal Autopsy for Cause-of-Death Determination](https://arxiv.org/abs/2509.09602)
*Yiqun T. Chen,Tyler H. McCormick,Li Liu,Abhirup Datta*

Main category: cs.CL

TL;DR: LA-VA目标是通过结合大语言模型（LLMs）与传统算法方法来提高质量评估的准确性，以支持资源稀缺地区的全球健康监测。


<details>
  <summary>Details</summary>
Motivation: 语言自动检验（VA）在医疗证明缺乏的资源有限环境中致力于预测死因，但需要更高的准确性来支持全球健康监测。

Method: 研究提出LA-VA流水线，结合大语言模型（LLMs）、传统算法方法和嵌入分类技术。使用PHMRC数据集，评估多种方法：GPT-5预测、LCVA基准、文本嵌入和元学习集成。

Result: GPT-5在三个年龄组别中都达到最高性能：成年人48.6%、儿童50.5%、新生儿53.5%，比传统统计机器学习基准提高5-10%。

Conclusion: 简单的商用LLM辅助方法可显著提高语言自动检验的准确性，对低资源设置中的全球健康监测具有重要意义。

Abstract: Verbal autopsy (VA) is a critical tool for estimating causes of death in
resource-limited settings where medical certification is unavailable. This
study presents LA-VA, a proof-of-concept pipeline that combines Large Language
Models (LLMs) with traditional algorithmic approaches and embedding-based
classification for improved cause-of-death prediction. Using the Population
Health Metrics Research Consortium (PHMRC) dataset across three age categories
(Adult: 7,580; Child: 1,960; Neonate: 2,438), we evaluate multiple approaches:
GPT-5 predictions, LCVA baseline, text embeddings, and meta-learner ensembles.
Our results demonstrate that GPT-5 achieves the highest individual performance
with average test site accuracies of 48.6% (Adult), 50.5% (Child), and 53.5%
(Neonate), outperforming traditional statistical machine learning baselines by
5-10%. Our findings suggest that simple off-the-shelf LLM-assisted approaches
could substantially improve verbal autopsy accuracy, with important
implications for global health surveillance in low-resource settings.

</details>


### [34] [Bridging the Capability Gap: Joint Alignment Tuning for Harmonizing LLM-based Multi-Agent Systems](https://arxiv.org/abs/2509.09629)
*Minghang Zhu,Zhengliang Shi,Zhiwei Xu,Shiguang Wu,Lingjie Wang,Pengjie Ren,Zhaochun Ren,Zhumin Chen*

Main category: cs.CL

TL;DR: MOAT是一个多智能体联合对齐调优框架，通过迭代对齐提升智能体协作能力，在六个基准测试中平均提升3.1%-4.4%


<details>
  <summary>Details</summary>
Motivation: 现有方法通常独立微调多智能体系统中的各个智能体，导致智能体间能力差距和协调性差的问题

Method: 提出MOAT框架，交替进行规划智能体对齐（优化子目标生成）和接地智能体改进（使用多样化子目标-动作对微调）

Result: 在六个基准测试中优于最先进基线，在held-in任务上平均提升3.1%，在held-out任务上平均提升4.4%

Conclusion: MOAT通过迭代对齐调优有效解决了多智能体协作问题，理论分析证明其训练过程非递减且渐进收敛

Abstract: The advancement of large language models (LLMs) has enabled the construction
of multi-agent systems to solve complex tasks by dividing responsibilities
among specialized agents, such as a planning agent for subgoal generation and a
grounding agent for executing tool-use actions. Most existing methods typically
fine-tune these agents independently, leading to capability gaps among them
with poor coordination. To address this, we propose MOAT, a Multi-Agent Joint
Alignment Tuning framework that improves agents collaboration through iterative
alignment. MOAT alternates between two key stages: (1) Planning Agent
Alignment, which optimizes the planning agent to generate subgoal sequences
that better guide the grounding agent; and (2) Grounding Agent Improving, which
fine-tunes the grounding agent using diverse subgoal-action pairs generated by
the agent itself to enhance its generalization capablity. Theoretical analysis
proves that MOAT ensures a non-decreasing and progressively convergent training
process. Experiments across six benchmarks demonstrate that MOAT outperforms
state-of-the-art baselines, achieving average improvements of 3.1% on held-in
tasks and 4.4% on held-out tasks.

</details>


### [35] [All for One: LLMs Solve Mental Math at the Last Token With Information Transferred From Other Tokens](https://arxiv.org/abs/2509.09650)
*Siddarth Mamidanna,Daking Rai,Ziyu Yao,Yilun Zhou*

Main category: cs.CL

TL;DR: 该论文通过Context-Aware Mean Ablation (CAMA)和Attention-Based Peeking (ABP)技术，在心理数学任务中发现了一个All-for-One (AF1)子图，其中有意义的计算发生在较深层且仅在最后一个token，该子图对模型性能至关重要且可跨模型迁移。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在计算任务上表现出色，但其内部工作机制仍不明确。研究旨在探究模型在实际操作中如何通过自注意力和多层感知器层进行信息处理和计算。

Method: 采用三步骤方法：抑制初始层的输入特定token计算、限制中间层跨token位置的信息传递路径、强制剩余层所有计算在最后一个token进行。提出CAMA和ABP两种技术来识别AF1子图。

Result: 实验发现AF1子图在各种心理数学任务上具有高准确性，计算主要发生在深层且仅最后一个token，通过特定中间层接收其他token信息。该子图对模型性能既充分又必要，可跨模型迁移且适用于不同输入风格。

Conclusion: 研究揭示了LLMs在心理数学任务中的特定计算模式，AF1子图的发现有助于理解模型内部工作机制，CAMA和ABP技术的优势也为相关研究提供了新工具。

Abstract: Large language models (LLMs) demonstrate proficiency across numerous
computational tasks, yet their inner workings remain unclear. In theory, the
combination of causal self-attention and multilayer perceptron layers allows
every token to access and compute information based on all preceding tokens. In
practice, to what extent are such operations present? In this paper, on mental
math tasks (i.e., direct math calculation via next-token prediction without
explicit reasoning), we investigate this question in three steps: inhibiting
input-specific token computations in the initial layers, restricting the routes
of information transfer across token positions in the next few layers, and
forcing all computation to happen at the last token in the remaining layers.
With two proposed techniques, Context-Aware Mean Ablation (CAMA) and
Attention-Based Peeking (ABP), we identify an All-for-One subgraph (AF1) with
high accuracy on a wide variety of mental math tasks, where meaningful
computation occurs very late (in terms of layer depth) and only at the last
token, which receives information of other tokens in few specific middle
layers. Experiments on a variety of models and arithmetic expressions show that
this subgraph is sufficient and necessary for high model performance, transfers
across different models, and works on a variety of input styles. Ablations on
different CAMA and ABP alternatives reveal their unique advantages over other
methods, which may be of independent interest.

</details>


### [36] [Steering MoE LLMs via Expert (De)Activation](https://arxiv.org/abs/2509.09660)
*Mohsen Fayyaz,Ali Modarressi,Hanieh Deilamsalehy,Franck Dernoncourt,Ryan Rossi,Trung Bui,Hinrich Schütze,Nanyun Peng*

Main category: cs.CL

TL;DR: SteerMoE框架通过检测和控制MoE模型中的行为相关专家，无需重新训练或修改权重即可控制模型的忠实性和安全性行为


<details>
  <summary>Details</summary>
Motivation: 现有的MoE模型在大型语言模型中通过专家路由机制处理token，但缺乏对特定行为相关专家的检测和控制方法，无法有效调节模型的行为表现

Method: 提出检测方法识别在对比行为输入对中表现出不同激活模式的专家，通过在推理过程中选择性激活或停用这些专家来控制模型行为

Result: 在11个基准测试和6个LLM上的实验显示，该方法可将安全性提升高达20%，忠实性提升27%；在对抗攻击模式下，单独使用可降低安全性41%，与现有越狱方法结合可完全绕过所有安全防护

Conclusion: SteerMoE揭示了MoE模型中专家层面存在对齐伪造的新维度，为模型行为控制提供了无需权重修改的有效框架

Abstract: Mixture-of-Experts (MoE) in Large Language Models (LLMs) routes each token
through a subset of specialized Feed-Forward Networks (FFN), known as experts.
We present SteerMoE, a framework for steering MoE models by detecting and
controlling behavior-linked experts. Our detection method identifies experts
with distinct activation patterns across paired inputs exhibiting contrasting
behaviors. By selectively (de)activating such experts during inference, we
control behaviors like faithfulness and safety without retraining or modifying
weights. Across 11 benchmarks and 6 LLMs, our steering raises safety by up to
+20% and faithfulness by +27%. In adversarial attack mode, it drops safety by
-41% alone, and -100% when combined with existing jailbreak methods, bypassing
all safety guardrails and exposing a new dimension of alignment faking hidden
within experts.

</details>


### [37] [CDE: Curiosity-Driven Exploration for Efficient Reinforcement Learning in Large Language Models](https://arxiv.org/abs/2509.09675)
*Runpeng Dai,Linfeng Song,Haolin Liu,Zhenwen Liang,Dian Yu,Haitao Mi,Zhaopeng Tu,Rui Liu,Tong Zheng,Hongtu Zhu,Dong Yu*

Main category: cs.CL

TL;DR: 提出了好奇心驱动探索(CDE)框架，通过演员的困惑度和评论家的价值估计方差作为内在奖励，解决RLVR方法探索不足和过早收敛的问题


<details>
  <summary>Details</summary>
Motivation: 当前RLVR方法在增强大语言模型推理能力时存在探索不足、过早收敛和熵崩溃的问题，需要更好的探索机制

Method: 使用演员对生成响应的困惑度和多头架构评论家的价值估计方差作为好奇心信号，作为RLVR框架中的探索奖励

Result: 在AIME基准测试中比标准RLVR(GRPO/PPO)提升了约3个百分点，并识别了RLVR中的校准崩溃机制

Conclusion: CDE框架通过内在好奇心信号有效改善了RLVR的探索性能，揭示了LLM常见失败模式的内在机制

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) is a powerful paradigm
for enhancing the reasoning ability of Large Language Models (LLMs). Yet
current RLVR methods often explore poorly, leading to premature convergence and
entropy collapse. To address this challenge, we introduce Curiosity-Driven
Exploration (CDE), a framework that leverages the model's own intrinsic sense
of curiosity to guide exploration. We formalize curiosity with signals from
both the actor and the critic: for the actor, we use perplexity over its
generated response, and for the critic, we use the variance of value estimates
from a multi-head architecture. Both signals serve as an exploration bonus
within the RLVR framework to guide the model. Our theoretical analysis shows
that the actor-wise bonus inherently penalizes overconfident errors and
promotes diversity among correct responses; moreover, we connect the
critic-wise bonus to the well-established count-based exploration bonus in RL.
Empirically, our method achieves an approximate +3 point improvement over
standard RLVR using GRPO/PPO on AIME benchmarks. Further analysis identifies a
calibration collapse mechanism within RLVR, shedding light on common LLM
failure modes.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [38] [Recurrence Meets Transformers for Universal Multimodal Retrieval](https://arxiv.org/abs/2509.08897)
*Davide Caffagni,Sara Sarto,Marcella Cornia,Lorenzo Baraldi,Rita Cucchiara*

Main category: cs.CV

TL;DR: ReT-2是一个统一的多模态检索模型，支持图像和文本组成的多模态查询，能够在多模态文档集合中进行检索，通过循环Transformer架构和LSTM门控机制实现跨层跨模态信息整合，在多个基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 随着多模态检索在LLMs和多模态LLMs中的快速应用，出现了越来越复杂的检索任务。现有方法主要依赖于视觉语言模型的任务特定微调，且仅限于单模态查询或文档，无法满足多模态查询和多模态文档检索的需求。

Method: 提出ReT-2模型，利用多层表示和循环Transformer架构，采用LSTM启发的门控机制动态整合跨层和跨模态信息，捕捉细粒度的视觉和文本细节。

Result: 在M2KR和M-BEIR基准测试中，ReT-2在不同检索配置下始终达到最先进的性能，同时提供更快的推理速度和更低的内存使用。集成到检索增强生成管道中时，在Encyclopedic-VQA和InfoSeek数据集上提高了下游性能。

Conclusion: ReT-2是一个高效统一的多模态检索模型，支持复杂的多模态查询和文档检索，在性能和效率方面都优于现有方法，为多模态检索任务提供了有效的解决方案。

Abstract: With the rapid advancement of multimodal retrieval and its application in
LLMs and multimodal LLMs, increasingly complex retrieval tasks have emerged.
Existing methods predominantly rely on task-specific fine-tuning of
vision-language models and are limited to single-modality queries or documents.
In this paper, we propose ReT-2, a unified retrieval model that supports
multimodal queries, composed of both images and text, and searches across
multimodal document collections where text and images coexist. ReT-2 leverages
multi-layer representations and a recurrent Transformer architecture with
LSTM-inspired gating mechanisms to dynamically integrate information across
layers and modalities, capturing fine-grained visual and textual details. We
evaluate ReT-2 on the challenging M2KR and M-BEIR benchmarks across different
retrieval configurations. Results demonstrate that ReT-2 consistently achieves
state-of-the-art performance across diverse settings, while offering faster
inference and reduced memory usage compared to prior approaches. When
integrated into retrieval-augmented generation pipelines, ReT-2 also improves
downstream performance on Encyclopedic-VQA and InfoSeek datasets. Our source
code and trained models are publicly available at:
https://github.com/aimagelab/ReT-2

</details>


### [39] [COCO-Urdu: A Large-Scale Urdu Image-Caption Dataset with Multimodal Quality Estimation](https://arxiv.org/abs/2509.09014)
*Umair Hassan*

Main category: cs.CV

TL;DR: COCO-Urdu是首个大规模乌尔都语图像-字幕数据集，包含5.9万张图片和31.9万个高质量乌尔都语字幕，通过多模态质量评估框架确保翻译质量，旨在解决乌尔都语在多模态研究中的资源匮乏问题。


<details>
  <summary>Details</summary>
Motivation: 乌尔都语作为2.5亿人使用的语言，在多模态和视觉-语言研究中严重缺乏资源，现有模型主要基于高资源语言训练，存在语言偏见。缺乏大规模高质量数据集限制了乌尔都语系统的发展。

Method: 从MS COCO数据集通过分层采样选取5.9万张图片，使用SeamlessM4T v2进行翻译，并采用混合多模态质量评估框架（包括COMET-Kiwi翻译质量评估、CLIP视觉相似性、BERTScore语义一致性）进行验证，低质量字幕通过开源大语言模型迭代优化。

Result: 构建了包含31.9万个高质量乌尔都语字幕的数据集，在BLEU、SacreBLEU和chrF等基准测试中表现优异，是目前最大的公开乌尔都语字幕数据集。

Conclusion: COCO-Urdu填补了乌尔都语多模态研究的空白，通过发布数据集和质量评估流程，有助于减少多模态研究中的语言偏见，为包容性视觉-语言系统奠定基础。

Abstract: Urdu, spoken by over 250 million people, remains critically under-served in
multimodal and vision-language research. The absence of large-scale,
high-quality datasets has limited the development of Urdu-capable systems and
reinforced biases in multilingual vision-language models trained primarily on
high-resource languages. To address this gap, we present COCO-Urdu, a
large-scale image-caption dataset derived from MS COCO, containing 59,000
images and 319,000 Urdu captions selected through stratified sampling to
preserve the original distribution. Captions were translated using SeamlessM4T
v2 and validated with a hybrid multimodal quality estimation framework that
integrates COMET-Kiwi for translation quality, CLIP-based similarity for visual
grounding, and BERTScore with back-translation for semantic consistency;
low-scoring captions were iteratively refined using open-source large language
models. We further benchmark COCO-Urdu on BLEU, SacreBLEU, and chrF, reporting
consistently strong results. To the best of our knowledge, COCO-Urdu is the
largest publicly available Urdu captioning dataset. By releasing both the
dataset and the quality estimation pipeline, we aim to reduce language bias in
multimodal research and establish a foundation for inclusive vision-language
systems.

</details>


### [40] [Can Multimodal LLMs See Materials Clearly? A Multimodal Benchmark on Materials Characterization](https://arxiv.org/abs/2509.09307)
*Zhengzhao Lai,Youbin Zheng,Zhenyang Cai,Haonan Lyu,Jinpu Yang,Hongqing Liang,Yan Hu,Benyou Wang*

Main category: cs.CV

TL;DR: 提出了首个材料表征图像理解基准MatCha，包含1500个需要专家级知识的问题，评估发现现有MLLM在真实材料表征场景中表现不佳


<details>
  <summary>Details</summary>
Motivation: 虽然多模态大语言模型在材料科学中展现出潜力，但其对真实材料表征成像数据的理解能力尚未充分探索，需要建立专业基准来评估和推动该领域发展

Method: 构建MatCha基准，涵盖材料研究四个关键阶段的21个不同任务，包含1500个专家级问题，评估最先进MLLM的性能并与人类专家对比

Result: 现有MLLM在MatCha上表现显著低于人类专家，处理需要高级专业知识和复杂视觉感知的问题时性能下降，简单的few-shot和思维链提示无法有效改善

Conclusion: 现有MLLM对真实材料表征场景的适应性有限，MatCha基准将促进新材料发现和自主科学代理等领域的未来研究

Abstract: Materials characterization is fundamental to acquiring materials information,
revealing the processing-microstructure-property relationships that guide
material design and optimization. While multimodal large language models
(MLLMs) have recently shown promise in generative and predictive tasks within
materials science, their capacity to understand real-world characterization
imaging data remains underexplored. To bridge this gap, we present MatCha, the
first benchmark for materials characterization image understanding, comprising
1,500 questions that demand expert-level domain expertise. MatCha encompasses
four key stages of materials research comprising 21 distinct tasks, each
designed to reflect authentic challenges faced by materials scientists. Our
evaluation of state-of-the-art MLLMs on MatCha reveals a significant
performance gap compared to human experts. These models exhibit degradation
when addressing questions requiring higher-level expertise and sophisticated
visual perception. Simple few-shot and chain-of-thought prompting struggle to
alleviate these limitations. These findings highlight that existing MLLMs still
exhibit limited adaptability to real-world materials characterization
scenarios. We hope MatCha will facilitate future research in areas such as new
material discovery and autonomous scientific agents. MatCha is available at
https://github.com/FreedomIntelligence/MatCha.

</details>


### [41] [FLUX-Reason-6M & PRISM-Bench: A Million-Scale Text-to-Image Reasoning Dataset and Comprehensive Benchmark](https://arxiv.org/abs/2509.09680)
*Rongyao Fang,Aldrich Yu,Chengqi Duan,Linjiang Huang,Shuai Bai,Yuxuan Cai,Kun Wang,Si Liu,Xihui Liu,Hongsheng Li*

Main category: cs.CV

TL;DR: FLUX-Reason-6M是一个包含600万高质量图像和2000万双语描述的推理导向数据集，PRISM-Bench是包含7个评估维度的新基准测试，旨在提升开源文本到图像模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 开源文本到图像模型因缺乏大规模推理导向数据集和全面评估基准，导致与闭源系统存在性能差距，需要解决这一问题。

Method: 构建FLUX-Reason-6M数据集（6M图像+20M双语描述），采用生成思维链(GCoT)提供详细生成步骤；创建PRISM-Bench评估基准（7个维度），使用先进视觉语言模型进行人机对齐评估。

Result: 对19个领先模型的评估揭示了关键性能差距和改进需求，数据集和基准测试为社区提供了前所未有的资源。

Conclusion: 该研究通过大规模数据集和综合基准测试推动了推理导向文本到图像生成的发展，为开源社区提供了重要资源。

Abstract: The advancement of open-source text-to-image (T2I) models has been hindered
by the absence of large-scale, reasoning-focused datasets and comprehensive
evaluation benchmarks, resulting in a performance gap compared to leading
closed-source systems. To address this challenge, We introduce FLUX-Reason-6M
and PRISM-Bench (Precise and Robust Image Synthesis Measurement Benchmark).
FLUX-Reason-6M is a massive dataset consisting of 6 million high-quality
FLUX-generated images and 20 million bilingual (English and Chinese)
descriptions specifically designed to teach complex reasoning. The image are
organized according to six key characteristics: Imagination, Entity, Text
rendering, Style, Affection, and Composition, and design explicit Generation
Chain-of-Thought (GCoT) to provide detailed breakdowns of image generation
steps. The whole data curation takes 15,000 A100 GPU days, providing the
community with a resource previously unattainable outside of large industrial
labs. PRISM-Bench offers a novel evaluation standard with seven distinct
tracks, including a formidable Long Text challenge using GCoT. Through
carefully designed prompts, it utilizes advanced vision-language models for
nuanced human-aligned assessment of prompt-image alignment and image
aesthetics. Our extensive evaluation of 19 leading models on PRISM-Bench
reveals critical performance gaps and highlights specific areas requiring
improvement. Our dataset, benchmark, and evaluation code are released to
catalyze the next wave of reasoning-oriented T2I generation. Project page:
https://flux-reason-6m.github.io/ .

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [42] [OmniEVA: Embodied Versatile Planner via Task-Adaptive 3D-Grounded and Embodiment-aware Reasoning](https://arxiv.org/abs/2509.09332)
*Yuecheng Liu,Dafeng Chi,Shiguang Wu,Zhanguang Zhang,Yuzheng Zhuang,Bowen Yang,He Zhu,Lingfeng Zhang,Pengwei Xie,David Gamaliel Arcos Bravo,Yingxue Zhang,Jianye Hao,Xingyue Quan*

Main category: cs.RO

TL;DR: OmniEVA是一个多模态大语言模型驱动的具身智能规划器，通过任务自适应的3D接地机制和具身感知推理框架，解决了现有系统在几何适应性和物理约束方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前基于MLLM的具身系统存在两个关键局限：几何适应性差距（2D输入或硬编码3D几何注入导致空间信息不足或泛化能力受限）和具身约束差距（忽视真实机器人的物理约束，导致计划理论可行但实际不可行）。

Method: 提出两个关键创新：(1)任务自适应的3D接地机制，通过门控路由器根据上下文需求进行选择性3D融合调节；(2)具身感知推理框架，将任务目标和具身约束共同纳入推理循环。

Result: 实验结果表明OmniEVA在通用具身推理性能上达到最先进水平，并在广泛的下游场景中展现出强大能力，在原始和复合任务基准测试中表现出稳健和通用的规划能力。

Conclusion: OmniEVA通过创新的3D接地和具身感知推理方法，有效解决了现有MLLM具身系统的局限性，为具身智能提供了更强大和实用的规划解决方案。

Abstract: Recent advances in multimodal large language models (MLLMs) have opened new
opportunities for embodied intelligence, enabling multimodal understanding,
reasoning, and interaction, as well as continuous spatial decision-making.
Nevertheless, current MLLM-based embodied systems face two critical
limitations. First, Geometric Adaptability Gap: models trained solely on 2D
inputs or with hard-coded 3D geometry injection suffer from either insufficient
spatial information or restricted 2D generalization, leading to poor
adaptability across tasks with diverse spatial demands. Second, Embodiment
Constraint Gap: prior work often neglects the physical constraints and
capacities of real robots, resulting in task plans that are theoretically valid
but practically infeasible.To address these gaps, we introduce OmniEVA -- an
embodied versatile planner that enables advanced embodied reasoning and task
planning through two pivotal innovations: (1) a Task-Adaptive 3D Grounding
mechanism, which introduces a gated router to perform explicit selective
regulation of 3D fusion based on contextual requirements, enabling
context-aware 3D grounding for diverse embodied tasks. (2) an Embodiment-Aware
Reasoning framework that jointly incorporates task goals and embodiment
constraints into the reasoning loop, resulting in planning decisions that are
both goal-directed and executable. Extensive experimental results demonstrate
that OmniEVA not only achieves state-of-the-art general embodied reasoning
performance, but also exhibits a strong ability across a wide range of
downstream scenarios. Evaluations of a suite of proposed embodied benchmarks,
including both primitive and composite tasks, confirm its robust and versatile
planning capabilities. Project page: https://omnieva.github.io

</details>


### [43] [SimpleVLA-RL: Scaling VLA Training via Reinforcement Learning](https://arxiv.org/abs/2509.09674)
*Haozhan Li,Yuxin Zuo,Jiale Yu,Yuhao Zhang,Zhaohui Yang,Kaiyan Zhang,Xuekai Zhu,Yuchen Zhang,Tianxing Chen,Ganqu Cui,Dehui Wang,Dingxiang Luo,Yuchen Fan,Youbang Sun,Jia Zeng,Jiangmiao Pang,Shanghang Zhang,Yu Wang,Yao Mu,Bowen Zhou,Ning Ding*

Main category: cs.RO

TL;DR: SimpleVLA-RL是一个针对视觉-语言-动作模型的强化学习框架，通过引入VLA特定的轨迹采样、并行化、多环境渲染和优化损失计算，显著提升了机器人操作任务的性能，减少了对大规模监督数据的依赖。


<details>
  <summary>Details</summary>
Motivation: 解决VLA模型面临的挑战：大规模人类操作轨迹数据稀缺且成本高昂，以及面对分布偏移时泛化能力有限的问题。受大型推理模型中强化学习成功提升推理能力的启发，探索RL是否能类似地提升VLA模型的长期动作规划能力。

Method: 基于veRL框架，开发了SimpleVLA-RL框架，包含VLA特定的轨迹采样、可扩展并行化、多环境渲染和优化损失计算。应用于OpenVLA-OFT模型，并引入了探索增强策略。

Result: 在LIBERO基准上达到最先进性能，在RoboTwin 1.0和2.0上甚至超越了π_0基准。不仅减少了对大规模数据的依赖，实现了鲁棒泛化，而且在真实世界任务中显著超越了监督微调方法。发现了RL训练中的新现象"pushcut"。

Conclusion: SimpleVLA-RL框架成功证明了强化学习可以有效提升VLA模型的长期动作规划能力，为解决VLA模型的数据依赖和泛化问题提供了有效解决方案，为机器人操作任务开辟了新途径。

Abstract: Vision-Language-Action (VLA) models have recently emerged as a powerful
paradigm for robotic manipulation. Despite substantial progress enabled by
large-scale pretraining and supervised fine-tuning (SFT), these models face two
fundamental challenges: (i) the scarcity and high cost of large-scale
human-operated robotic trajectories required for SFT scaling, and (ii) limited
generalization to tasks involving distribution shift. Recent breakthroughs in
Large Reasoning Models (LRMs) demonstrate that reinforcement learning (RL) can
dramatically enhance step-by-step reasoning capabilities, raising a natural
question: Can RL similarly improve the long-horizon step-by-step action
planning of VLA? In this work, we introduce SimpleVLA-RL, an efficient RL
framework tailored for VLA models. Building upon veRL, we introduce
VLA-specific trajectory sampling, scalable parallelization, multi-environment
rendering, and optimized loss computation. When applied to OpenVLA-OFT,
SimpleVLA-RL achieves SoTA performance on LIBERO and even outperforms $\pi_0$
on RoboTwin 1.0\&2.0 with the exploration-enhancing strategies we introduce.
SimpleVLA-RL not only reduces dependence on large-scale data and enables robust
generalization, but also remarkably surpasses SFT in real-world tasks.
Moreover, we identify a novel phenomenon ``pushcut'' during RL training,
wherein the policy discovers previously unseen patterns beyond those seen in
the previous training process. Github: https://github.com/PRIME-RL/SimpleVLA-RL

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [44] [Automated Unity Game Template Generation from GDDs via NLP and Multi-Modal LLMs](https://arxiv.org/abs/2509.08847)
*Amna Hassan*

Main category: cs.AI

TL;DR: 使用LLaMA-3精调模型将游戏设计文档自动转换为Unity游戏原型，提高了代码生成质量和规范性


<details>
  <summary>Details</summary>
Motivation: 解决AI辅助游戏开发中从设计到实现的转换问题，通过自动化流程提高开发效率

Method: 结合NLP和多模态LLMs，使用精调的LLaMA-3模型解析GDD文档并生成Unity兼容的C#代码，配合自定义Unity集成包

Result: 在编译成功率、GDD遵循度、最佳实践和代码模块性方面超过基线模型，平均评分4.8/5.0，支持多游戏类型

Conclusion: 该框架有效解决了AI辅助游戏开发的关键问题，使LLMs成为从设计到实现过程的有力工具

Abstract: This paper presents a novel framework for automated game template generation
by transforming Game Design Documents (GDDs) into functional Unity game
prototypes using Natural Language Processing (NLP) and multi-modal Large
Language Models (LLMs). We introduce an end-to-end system that parses GDDs,
extracts structured game specifications, and synthesizes Unity-compatible C#
code that implements the core mechanics, systems, and architecture defined in
the design documentation. Our approach combines a fine-tuned LLaMA-3 model
specialized for Unity code generation with a custom Unity integration package
that streamlines the implementation process. Evaluation results demonstrate
significant improvements over baseline models, with our fine-tuned model
achieving superior performance (4.8/5.0 average score) compared to
state-of-the-art LLMs across compilation success, GDD adherence, best practices
adoption, and code modularity metrics. The generated templates demonstrate high
adherence to GDD specifications across multiple game genres. Our system
effectively addresses critical gaps in AI-assisted game development,
positioning LLMs as valuable tools in streamlining the transition from game
design to implementation.

</details>


### [45] [Tree-OPO: Off-policy Monte Carlo Tree-Guided Advantage Optimization for Multistep Reasoning](https://arxiv.org/abs/2509.09284)
*Bingning Huang,Tu Nguyen,Matthieu Zimmer*

Main category: cs.AI

TL;DR: 利用MCTS轨迹改进基于偏好的强化学习策略优化，提出分阶段GRPO训练范式，通过树结构优势估计提升推理质量，但面临优势饱和和奖励信号崩溃等挑战。


<details>
  <summary>Details</summary>
Motivation: 受MCTS在LLM推理中生成高质量中间轨迹的启发，探索如何将MCTS轨迹重新用于改进基于偏好的强化学习中的策略优化，特别是在不需要价值网络的情况下实现偏好一致的策略学习。

Method: 提出分阶段GRPO训练范式，使用部分揭示的MCTS rollout生成补全结果，引入新颖的树结构优势估计方法，产生丰富的前缀条件奖励信号。

Result: 初步结果表明，结构化优势估计可以稳定更新并更好地反映组合推理质量，但仍面临优势饱和和奖励信号崩溃等挑战。

Conclusion: 提出了启发式和统计解决方案来缓解这些问题，并讨论了在分阶段或树状奖励结构下学习的开放性挑战。

Abstract: Recent advances in reasoning with large language models (LLMs) have shown the
effectiveness of Monte Carlo Tree Search (MCTS) for generating high-quality
intermediate trajectories, particularly in math and symbolic domains. Inspired
by this, we explore how MCTS-derived trajectories, traditionally used for
training value or reward models, can be repurposed to improve policy
optimization in preference-based reinforcement learning (RL). Specifically, we
focus on Group Relative Policy Optimization (GRPO), a recent algorithm that
enables preference-consistent policy learning without value networks. We
propose a staged GRPO training paradigm where completions are derived from
partially revealed MCTS rollouts, introducing a novel tree-structured setting
for advantage estimation. This leads to a rich class of prefix-conditioned
reward signals, which we analyze theoretically and empirically. Our initial
results indicate that while structured advantage estimation can stabilize
updates and better reflect compositional reasoning quality, challenges such as
advantage saturation and reward signal collapse remain. We propose heuristic
and statistical solutions to mitigate these issues and discuss open challenges
for learning under staged or tree-like reward structures.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [46] [Open-sci-ref-0.01: open and reproducible reference baselines for language model and dataset comparison](https://arxiv.org/abs/2509.09009)
*Marianna Nezhurina,Taishi Nakamura,Timur Carstensen,Niccolò Ajroldi,Ville Komulainen,David Salinas,Jenia Jitsev*

Main category: cs.LG

TL;DR: open-sci-ref是一个密集transformer模型家族，在多个参数规模(0.13B-1.7B)和token规模(最高1T)上训练，使用8个开放参考数据集，为研究提供基准参考点。


<details>
  <summary>Details</summary>
Motivation: 为研究人员提供标准化的训练基准，用于评估不同训练方法的质量和合理性，促进训练过程的比较和复现。

Method: 在8个开放参考数据集上训练密集transformer模型，涵盖不同参数和token规模，提供中间检查点、日志和评估数据。

Result: NemoTron-CC HQ数据集表现最佳，其次是DCLM-baseline和FineWeb-Edu；建立了可比较的基准线，支持通过计算轴进行训练过程对比。

Conclusion: open-sci-ref提供了标准化的研究基准，简化了复现过程，促进了训练方法的比较和未来研究的发展。

Abstract: We introduce open-sci-ref, a family of dense transformer models trained as
research baselines across multiple model (0.13B to 1.7B parameters) and token
scales (up to 1T) on 8 recent open reference datasets. Evaluating the models on
various standardized benchmarks, our training runs set establishes reference
points that enable researchers to assess the sanity and quality of alternative
training approaches across scales and datasets. Intermediate checkpoints allow
comparison and studying of the training dynamics. The established reference
baselines allow training procedures to be compared through their scaling
trends, aligning them on a common compute axis. Comparison of open reference
datasets reveals that training on NemoTron-CC HQ consistently outperforms other
reference datasets, followed by DCLM-baseline and FineWeb-Edu. In addition to
intermediate training checkpoints, the release includes logs, code, and
downstream evaluations to simplify reproduction, standardize comparison, and
facilitate future research.

</details>


### [47] [Identifying Key Features for Establishing Sustainable Agro-Tourism Centre: A Data Driven Approach](https://arxiv.org/abs/2509.09214)
*Alka Gadakh,Vidya Kumbhar,Sonal Khosla,Kumar Karunendra*

Main category: cs.LG

TL;DR: 这篇论文使用机器学习方法确定了农业旅游发展的关键指标，LASSO结合逻辑回归模型取得最高准确率达98-99%。


<details>
  <summary>Details</summary>
Motivation: 农业旅游作为促进农村发展的经济模式，需要研究其增长策略和关键指标以支持农民收入多样化和传统文化保护。

Method: 采用两阶段研究方法：通过文献综述识别关键指标，然后使用LASSO等机器学习特征选择方法结合逻辑回归、决策树、随机森林和XGBoost等分类器进行分析。

Result: 在70-30%数据分割下，LASSO+逻辑回归模型准确率达98%，随机森林为95%；在80-20%数据分割下，逻辑回归准确率达99%，决策树和XGBoost为97%。

Conclusion: LASSO结合逻辑回归模型在农业旅游发展指标选择中表现最优，为农业旅游发展提供了有效的数据支撑和决策帮助。

Abstract: Agro-tourism serves as a strategic economic model designed to facilitate
rural development by diversifying income streams for local communities like
farmers while promoting the conservation of indigenous cultural heritage and
traditional agricultural practices. As a very booming subdomain of tourism,
there is a need to study the strategies for the growth of Agro-tourism in
detail. The current study has identified the important indicators for the
growth and enhancement of agro-tourism. The study is conducted in two phases:
identification of the important indicators through a comprehensive literature
review and in the second phase state-of-the-art techniques were used to
identify the important indicators for the growth of agro-tourism. The
indicators are also called features synonymously, the machine learning models
for feature selection were applied and it was observed that the Least Absolute
Shrinkage and Selection Operator (LASSO) method combined with, the machine
Learning Classifiers such as Logistic Regression (LR), Decision Trees (DT),
Random Forest (RF) Tree, and Extreme Gradient Boosting (XGBOOST) models were
used to suggest the growth of the agro-tourism. The results show that with the
LASSO method, LR model gives the highest classification accuracy of 98% in
70-30% train-test data followed by RF with 95% accuracy. Similarly, in the
80-20% train-test data LR maintains the highest accuracy at 99%, while DT and
XGBoost follow with 97% accuracy.

</details>


### [48] [Harnessing Uncertainty: Entropy-Modulated Policy Gradients for Long-Horizon LLM Agents](https://arxiv.org/abs/2509.09265)
*Jiawei Wang,Jiacai Liu,Yuqian Fu,Yingru Li,Xintao Wang,Yuan Lin,Yu Yue,Lin Zhang,Yang Wang,Ke Wang*

Main category: cs.LG

TL;DR: 提出Entropy-Modulated Policy Gradients (EMPG)框架，通过基于不确定性和任务结果重新校准学习信号，解决LLM智能体在长时程任务中因稀疏奖励导致的信用分配问题


<details>
  <summary>Details</summary>
Motivation: LLM智能体在长时程任务中面临稀疏奖励难以分配信用到中间步骤的问题，且策略梯度幅度与熵固有耦合，导致置信正确动作更新小、不确定动作更新大而不稳定

Method: EMPG框架基于步骤不确定性和最终任务结果重新校准学习信号，放大置信正确动作的更新，惩罚置信错误，衰减不确定步骤的更新以稳定探索，并引入未来清晰度奖励项

Result: 在WebShop、ALFWorld和Deep Search三个挑战性智能体任务上的实验表明，EMPG取得显著性能提升，大幅超越强策略梯度基线方法

Conclusion: EMPF有效解决了LLM智能体在稀疏奖励环境中的学习动态问题，通过熵调制机制显著提升了长时程任务的性能表现

Abstract: In long-horizon tasks, recent agents based on Large Language Models (LLMs)
face a significant challenge that sparse, outcome-based rewards make it
difficult to assign credit to intermediate steps. Previous methods mainly focus
on creating dense reward signals to guide learning, either through traditional
reinforcement learning techniques like inverse reinforcement learning or by
using Process Reward Models for step-by-step feedback. In this paper, we
identify a fundamental problem in the learning dynamics of LLMs: the magnitude
of policy gradients is inherently coupled with the entropy, which leads to
inefficient small updates for confident correct actions and potentially
destabilizes large updates for uncertain ones. To resolve this, we propose
Entropy-Modulated Policy Gradients (EMPG), a framework that re-calibrates the
learning signal based on step-wise uncertainty and the final task outcome. EMPG
amplifies updates for confident correct actions, penalizes confident errors,
and attenuates updates from uncertain steps to stabilize exploration. We
further introduce a bonus term for future clarity that encourages agents to
find more predictable solution paths. Through comprehensive experiments on
three challenging agent tasks, WebShop, ALFWorld, and Deep Search, we
demonstrate that EMPG achieves substantial performance gains and significantly
outperforms strong policy gradient baselines. Project page is at
https://empgseed-seed.github.io/

</details>


### [49] [LLMs Don't Know Their Own Decision Boundaries: The Unreliability of Self-Generated Counterfactual Explanations](https://arxiv.org/abs/2509.09396)
*Harry Mayne,Ryan Othniel Kearns,Yushi Yang,Andrew M. Bean,Eoin Delaney,Chris Russell,Adam Mahdi*

Main category: cs.LG

TL;DR: 研究发现大型语言模型生成的反事实解释虽然有效但不够精简，在追求精简时又往往无法改变预测结果，存在有效性-精简性权衡问题


<details>
  <summary>Details</summary>
Motivation: 研究语言模型如何通过自我生成的反事实解释来向人类解释其决策过程，这对于人机协作至关重要

Method: 评估LLMs生成的反事实解释的有效性（能否改变预测结果）和精简性（修改程度是否最小），在多个模型、数据集和评估设置下进行测试

Result: LLMs通常能生成有效的反事实解释但不够精简；当要求生成精简解释时，修改过小导致无法改变预测结果；这种权衡问题在不同模型和设置中普遍存在

Conclusion: 自我生成的反事实解释作为可解释性工具效果有限，甚至可能提供误导性见解，在关键应用场景中部署LLMs时需要考虑不可靠自我解释的影响

Abstract: To collaborate effectively with humans, language models must be able to
explain their decisions in natural language. We study a specific type of
self-explanation: self-generated counterfactual explanations (SCEs), where a
model explains its prediction by modifying the input such that it would have
predicted a different outcome. We evaluate whether LLMs can produce SCEs that
are valid, achieving the intended outcome, and minimal, modifying the input no
more than necessary. When asked to generate counterfactuals, we find that LLMs
typically produce SCEs that are valid, but far from minimal, offering little
insight into their decision-making behaviour. Worryingly, when asked to
generate minimal counterfactuals, LLMs typically make excessively small edits
that fail to change predictions. The observed validity-minimality trade-off is
consistent across several LLMs, datasets, and evaluation settings. Our findings
suggest that SCEs are, at best, an ineffective explainability tool and, at
worst, can provide misleading insights into model behaviour. Proposals to
deploy LLMs in high-stakes settings must consider the impact of unreliable
self-explanations on downstream decision-making. Our code is available at
https://github.com/HarryMayne/SCEs.

</details>


### [50] [ButterflyQuant: Ultra-low-bit LLM Quantization through Learnable Orthogonal Butterfly Transforms](https://arxiv.org/abs/2509.09679)
*Bingxin Xu,Zhen Dong,Oussama Elachqar,Yuzhang Shang*

Main category: cs.LG

TL;DR: ButterflyQuant是一种针对2位量化的自适应旋转方法，通过可学习的蝴蝶变换替代固定Hadamard矩阵，有效抑制激活值异常值，在LLaMA-2-7B上相比QuaRot将困惑度从22.1降至15.4。


<details>
  <summary>Details</summary>
Motivation: 现有旋转方法使用固定变换无法适应不同Transformer层的特定异常值模式，需要层自适应的旋转方法。

Method: 使用可学习的蝴蝶变换参数化连续Givens旋转角度，保证正交性同时支持梯度优化，并引入均匀性正则化促进量化友好分布。

Result: 仅需128个校准样本和单GPU几分钟训练，在LLaMA-2-7B 2位量化中达到15.4困惑度，显著优于QuaRot的22.1。

Conclusion: ButterflyQuant通过自适应旋转有效解决极端量化中的异常值问题，以极小计算成本显著提升性能。

Abstract: Large language models require massive memory footprints, severely limiting
deployment on consumer hardware. Quantization reduces memory through lower
numerical precision, but extreme 2-bit quantization suffers from catastrophic
performance loss due to outliers in activations. Rotation-based methods such as
QuIP and QuaRot apply orthogonal transforms to eliminate outliers before
quantization, using computational invariance: $\mathbf{y} = \mathbf{Wx} =
(\mathbf{WQ}^T)(\mathbf{Qx})$ for orthogonal $\mathbf{Q}$. However, these
methods use fixed transforms--Hadamard matrices achieving optimal worst-case
coherence $\mu = 1/\sqrt{n}$--that cannot adapt to specific weight
distributions. We identify that different transformer layers exhibit distinct
outlier patterns, motivating layer-adaptive rotations rather than
one-size-fits-all approaches. We propose ButterflyQuant, which replaces
Hadamard rotations with learnable butterfly transforms parameterized by
continuous Givens rotation angles. Unlike Hadamard's discrete $\{+1, -1\}$
entries that are non-differentiable and prohibit gradient-based learning,
butterfly transforms' continuous parameterization enables smooth optimization
while guaranteeing orthogonality by construction. This orthogonal constraint
ensures theoretical guarantees in outlier suppression while achieving $O(n \log
n)$ computational complexity with only $\frac{n \log n}{2}$ learnable
parameters. We further introduce a uniformity regularization on
post-transformation activations to promote smoother distributions amenable to
quantization. Learning requires only 128 calibration samples and converges in
minutes on a single GPU--a negligible one-time cost. On LLaMA-2-7B with 2-bit
quantization, ButterflyQuant achieves 15.4 perplexity versus 22.1 for QuaRot.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [51] [Generative Engine Optimization: How to Dominate AI Search](https://arxiv.org/abs/2509.08919)
*Mahe Chen,Xiaoxuan Wang,Kaiwen Chen,Nick Koudas*

Main category: cs.IR

TL;DR: 本文通过大规模实验对比了AI搜索与传统网络搜索的信息来源偏向，提出了生成式引擎优化(GEO)新框架，为应对AI搜索时代的可见性挑战提供实践指南。


<details>
  <summary>Details</summary>
Motivation: 随着ChatGPT、Perplexity、Gemini等生成式AI搜索引擎的快速普及，信息检索模式从传统排名列表转向综合性答案，对SEO实践造成挑战，需要探索新的优化方法。

Method: 进行大规模、受控实验，涵盖多个垂直领域、语言和查询重写，定量分析AI搜索与Google在信息来源方面的关键差异。

Result: 发现AI搜索存在系统性偏向，优先采信权威第三方源(获得媒体)，而非品牌自有内容或社交内容，与Google更均衡的来源组成形成明显对比。同时不同AI搜索服务在域名多样性、新鲜度、跨语言稳定性和语法敏感性方面存在显著差异。

Conclusion: 提出生成式引擎优化(GEO)战略议程，包括：(1)为机器扫描和证成设计内容；(2)控制获得媒体建立AI权威感；(3)采用引擎特定和语言感知策略；(4)应对大品牌偏见以支持小众玩家。为在生成式搜索新时代获得可见性提供基础分析和战略框架。

Abstract: The rapid adoption of generative AI-powered search engines like ChatGPT,
Perplexity, and Gemini is fundamentally reshaping information retrieval, moving
from traditional ranked lists to synthesized, citation-backed answers. This
shift challenges established Search Engine Optimization (SEO) practices and
necessitates a new paradigm, which we term Generative Engine Optimization
(GEO).
  This paper presents a comprehensive comparative analysis of AI Search and
traditional web search (Google). Through a series of large-scale, controlled
experiments across multiple verticals, languages, and query paraphrases, we
quantify critical differences in how these systems source information. Our key
findings reveal that AI Search exhibit a systematic and overwhelming bias
towards Earned media (third-party, authoritative sources) over Brand-owned and
Social content, a stark contrast to Google's more balanced mix. We further
demonstrate that AI Search services differ significantly from each other in
their domain diversity, freshness, cross-language stability, and sensitivity to
phrasing.
  Based on these empirical results, we formulate a strategic GEO agenda. We
provide actionable guidance for practitioners, emphasizing the critical need
to: (1) engineer content for machine scannability and justification, (2)
dominate earned media to build AI-perceived authority, (3) adopt
engine-specific and language-aware strategies, and (4) overcome the inherent
"big brand bias" for niche players. Our work provides the foundational
empirical analysis and a strategic framework for achieving visibility in the
new generative search landscape.

</details>


### [52] [Retrieval-Augmented Generation for Reliable Interpretation of Radio Regulations](https://arxiv.org/abs/2509.09651)
*Zakaria El Kassimi,Fares Fourati,Mohamed-Slim Alouini*

Main category: cs.IR

TL;DR: 这篇论文研究了在广播规定领域的问题回答技术，提出了一种专门的管道化检索增强生成流程，并创建了该领域的首个多选题评估集。该方法在检索准确率达到97%，并为GPT-4o模型带来12%的相对提升。


<details>
  <summary>Details</summary>
Motivation: 广播规定是一个法律敏感和高风险的领域，需要准确可靠的问题回答系统。论文的动机是为了解决这一领域的特殊需求，提供一种基于权威来源的精准知识培基方案。

Method: 提出了一种专门的电信领域RAG流程，包括：1）从权威来源构建首个多选题评估集；2）使用自动化过滤和人工验证；3）定义领域特定的检索指标；4）实现结构化检索与生成结合的方案。

Result: 检索器在领域特定指标下达到约97%的准确率。在生成方面，该流程为所有测试模型带来了一致的准确率提升。对GPT-4o而言，简单插入文档只有不到1%的收益，而使用该流程能够实现12%的相对提升。

Conclusion: 细致目标化的知识培基提供了一种简单但强大的基准方案，是规制性问题回答领域的有效域特定解决方案。论文中的代码、评估脚本和问答数据集已公开。

Abstract: We study question answering in the domain of radio regulations, a legally
sensitive and high-stakes area. We propose a telecom-specific
Retrieval-Augmented Generation (RAG) pipeline and introduce, to our knowledge,
the first multiple-choice evaluation set for this domain, constructed from
authoritative sources using automated filtering and human validation. To assess
retrieval quality, we define a domain-specific retrieval metric, under which
our retriever achieves approximately 97% accuracy. Beyond retrieval, our
approach consistently improves generation accuracy across all tested models. In
particular, while naively inserting documents without structured retrieval
yields only marginal gains for GPT-4o (less than 1%), applying our pipeline
results in nearly a 12% relative improvement. These findings demonstrate that
carefully targeted grounding provides a simple yet strong baseline and an
effective domain-specific solution for regulatory question answering. All code
and evaluation scripts, along with our derived question-answer dataset, are
available at https://github.com/Zakaria010/Radio-RAG.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [53] [A vibe coding learning design to enhance EFL students' talking to, through, and about AI](https://arxiv.org/abs/2509.08854)
*David James Woo,Kai Guo,Yangyang Yu*

Main category: cs.CY

TL;DR: 本文报告了一个重要的教育实践：使用自然语言通过AI创建软件应用的vibe coding技术在EFL教育中的应用，通过人工智能语言框架分析学生的不同表现和成效因素。


<details>
  <summary>Details</summary>
Motivation: 探索AI语言技术在英语作为外语教育中的应用潜力，开发人工智能语言框架来提高学生的语言创造能力和技术应用能力。

Method: 采用案例研究方法，设计四小时工作坊，通过工作表、视频录制、声音思考协议、屏幕录制和AI生成图像等多渠道收集数据，对比分析两位学生的不同表现。

Result: 学生在vibe coding中存在显著差异：一位成功创建了符合设计意图的功能性应用，另一位遇到技术困难导致设计与实际功能差距较大。分析显示学生在提示工程、AI心智模型和作者权归属方面的差异。

Conclusion: AI作为有益的语言机器，学生如何与AI交互影响vibe coding效果。有效的教学需要明确的语言脚手架支持、结构化提示工程教学、促进作者权讨论以及发展表达AI心智模型的词汇。

Abstract: This innovative practice article reports on the piloting of vibe coding
(using natural language to create software applications with AI) for English as
a Foreign Language (EFL) education. We developed a human-AI meta-languaging
framework with three dimensions: talking to AI (prompt engineering), talking
through AI (negotiating authorship), and talking about AI (mental models of
AI). Using backward design principles, we created a four-hour workshop where
two students designed applications addressing authentic EFL writing challenges.
We adopted a case study methodology, collecting data from worksheets and video
recordings, think-aloud protocols, screen recordings, and AI-generated images.
Contrasting cases showed one student successfully vibe coding a functional
application cohering to her intended design, while another encountered
technical difficulties with major gaps between intended design and actual
functionality. Analysis reveals differences in students' prompt engineering
approaches, suggesting different AI mental models and tensions in attributing
authorship. We argue that AI functions as a beneficial languaging machine, and
that differences in how students talk to, through, and about AI explain vibe
coding outcome variations. Findings indicate that effective vibe coding
instruction requires explicit meta-languaging scaffolding, teaching structured
prompt engineering, facilitating critical authorship discussions, and
developing vocabulary for articulating AI mental models.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [54] [Bona fide Cross Testing Reveals Weak Spot in Audio Deepfake Detection Systems](https://arxiv.org/abs/2509.09204)
*Chin Yuen Kwok,Jia Qi Yip,Zhen Qiu,Chi Hung Chi,Kwok Yan Lam*

Main category: cs.SD

TL;DR: 该文章提出了一种新的音频深度伪造检测评估框架，解决传统评估方法中合成器样本不均衡和真实语音类型单一的问题。


<details>
  <summary>Details</summary>
Motivation: 传统音频深度伪造检测评估存在两个主要问题：1) 使用单一EER评估会导致样本较多的合成器权重过高；2) 真实语音数据集类型单一，无法模拟实际场景。

Method: 提出真实跨测试（bona fide cross-testing）框架，包含多样化的真实语音数据集，并通过聚合多个EER来进行更均衡的评估。对150个以上的合成器在9种不同真实语音类型上进行了基准测试。

Result: 新的评估框架提高了检测模型的稳健性和可解释性，较传统方法更能模拟实际应用场景。

Conclusion: 该研究为音频深度伪造检测领域提供了更加全面和可靠的评估方法，并开源了新的数据集以促进进一步研究。

Abstract: Audio deepfake detection (ADD) models are commonly evaluated using datasets
that combine multiple synthesizers, with performance reported as a single Equal
Error Rate (EER). However, this approach disproportionately weights
synthesizers with more samples, underrepresenting others and reducing the
overall reliability of EER. Additionally, most ADD datasets lack diversity in
bona fide speech, often featuring a single environment and speech style (e.g.,
clean read speech), limiting their ability to simulate real-world conditions.
To address these challenges, we propose bona fide cross-testing, a novel
evaluation framework that incorporates diverse bona fide datasets and
aggregates EERs for more balanced assessments. Our approach improves robustness
and interpretability compared to traditional evaluation methods. We benchmark
over 150 synthesizers across nine bona fide speech types and release a new
dataset to facilitate further research at
https://github.com/cyaaronk/audio_deepfake_eval.

</details>


### [55] [DiFlow-TTS: Discrete Flow Matching with Factorized Speech Tokens for Low-Latency Zero-Shot Text-To-Speech](https://arxiv.org/abs/2509.09631)
*Ngoc-Son Nguyen,Hieu-Nghia Huynh-Nguyen,Thanh V. T. Tran,Truong-Son Hy,Van Nguyen*

Main category: cs.SD

TL;DR: DiFlow-TTS是首个探索纯离散流匹配的语音合成模型，通过显式建模分解的语音属性，在零样本TTS中实现了高质量语音合成，推理速度比现有基线快25.8倍


<details>
  <summary>Details</summary>
Motivation: 解决零样本文本转语音中现有方法推理速度慢、存在重复伪影的问题，充分利用离散表示的优势，避免将离散标记嵌入连续空间带来的局限性

Method: 采用纯离散流匹配方法，在紧凑统一架构中显式建模分解的语音属性。利用上下文学习，基于文本内容和参考语音提取的韵律、声学属性进行条件生成，使用分解流预测机制分别处理韵律和声学细节

Result: 在自然度、韵律、说话人风格保持和能量控制等关键指标上表现优异，模型紧凑且实现低延迟推理，生成速度比最新基线快25.8倍

Conclusion: DiFlow-TTS证明了纯离散流匹配在语音合成中的有效性，为高质量、高效率的零样本TTS提供了新的解决方案

Abstract: Zero-shot Text-to-Speech (TTS) aims to synthesize high-quality speech that
mimics the voice of an unseen speaker using only a short reference sample,
requiring not only speaker adaptation but also accurate modeling of prosodic
attributes. Recent approaches based on language models, diffusion, and flow
matching have shown promising results in zero-shot TTS, but still suffer from
slow inference and repetition artifacts. Discrete codec representations have
been widely adopted for speech synthesis, and recent works have begun to
explore diffusion models in purely discrete settings, suggesting the potential
of discrete generative modeling for speech synthesis. However, existing
flow-matching methods typically embed these discrete tokens into a continuous
space and apply continuous flow matching, which may not fully leverage the
advantages of discrete representations. To address these challenges, we
introduce DiFlow-TTS, which, to the best of our knowledge, is the first model
to explore purely Discrete Flow Matching for speech synthesis. DiFlow-TTS
explicitly models factorized speech attributes within a compact and unified
architecture. It leverages in-context learning by conditioning on textual
content, along with prosodic and acoustic attributes extracted from a reference
speech, enabling effective attribute cloning in a zero-shot setting. In
addition, the model employs a factorized flow prediction mechanism with
distinct heads for prosody and acoustic details, allowing it to learn
aspect-specific distributions. Experimental results demonstrate that DiFlow-TTS
achieves promising performance in several key metrics, including naturalness,
prosody, preservation of speaker style, and energy control. It also maintains a
compact model size and achieves low-latency inference, generating speech up to
25.8 times faster than the latest existing baselines.

</details>
