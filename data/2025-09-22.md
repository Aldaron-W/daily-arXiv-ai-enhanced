<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 56]
- [cs.LG](#cs.LG) [Total: 6]
- [cs.IR](#cs.IR) [Total: 1]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.SD](#cs.SD) [Total: 2]
- [cs.CY](#cs.CY) [Total: 1]
- [cs.MM](#cs.MM) [Total: 1]
- [cs.CV](#cs.CV) [Total: 5]
- [eess.AS](#eess.AS) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Synthetic bootstrapped pretraining](https://arxiv.org/abs/2509.15248)
*Zitong Yang,Aonan Zhang,Hong Liu,Tatsunori Hashimoto,Emmanuel Candès,Chong Wang,Ruoming Pang*

Main category: cs.CL

TL;DR: SBP是一种语言模型预训练方法，通过学习文档间关系来合成新语料进行联合训练，相比标准预训练能更好地建模文档间相关性，在3B参数模型上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 标准预训练只学习单个文档内的token相关性，无法有效建模文档间丰富的可学习相关性，而这些相关性可能带来更好的性能。

Method: SBP首先从预训练数据集中学习文档间关系模型，然后利用该模型合成大量新语料进行联合训练，通过计算匹配的预训练设置验证方法。

Result: 在3B参数模型上预训练1T tokens，SBP持续优于强重复基线，获得了接近访问20倍独特数据的oracle上限的性能提升。合成文档超越了简单改写，能够抽象核心概念并构建新叙述。

Conclusion: SBP不仅具有强实证性能，还具备自然的贝叶斯解释：合成器隐式学习相关文档间共享的潜在概念抽象。

Abstract: We introduce Synthetic Bootstrapped Pretraining (SBP), a language model (LM)
pretraining procedure that first learns a model of relations between documents
from the pretraining dataset and then leverages it to synthesize a vast new
corpus for joint training. While the standard pretraining teaches LMs to learn
causal correlations among tokens within a single document, it is not designed
to efficiently model the rich, learnable inter-document correlations that can
potentially lead to better performance. We validate SBP by designing a
compute-matched pretraining setup and pretrain a 3B-parameter model on up to 1T
tokens from scratch. We find SBP consistently improves upon a strong repetition
baseline and delivers a significant fraction of performance improvement
attainable by an oracle upper bound with access to 20x more unique data.
Qualitative analysis reveals that the synthesized documents go beyond mere
paraphrases -- SBP first abstracts a core concept from the seed material and
then crafts a new narration on top of it. Besides strong empirical performance,
SBP admits a natural Bayesian interpretation: the synthesizer implicitly learns
to abstract the latent concepts shared between related documents.

</details>


### [2] [Comparative Analysis of Tokenization Algorithms for Low-Resource Language Dzongkha](https://arxiv.org/abs/2509.15255)
*Tandin Wangchuk,Tad Gonsalves*

Main category: cs.CL

TL;DR: 本文评估了三种分词算法（BPE、WordPiece、SentencePiece）在不丹低资源语言宗喀语中的表现，发现SentencePiece最适合宗喀语分词，为构建宗喀语大语言模型奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 大多数预训练分词器适用于英语等高资源语言，但对宗喀语等低资源语言效果不佳。宗喀语作为不丹的官方语言，其语言复杂性给NLP带来独特挑战，特别是在分词方面缺乏深入研究。

Method: 使用三种常见分词算法（BPE、WordPiece、SentencePiece）对宗喀语进行分词训练，并通过子词生育率、连续词比例、归一化序列长度和执行时间等指标评估性能。

Result: 三种算法都显示出潜力，但SentencePiece在宗喀语分词中表现最有效。

Conclusion: 研究强调了为低资源语言定制分词方法的必要性，SentencePiece的成功为宗喀语NLP的进一步发展铺平了道路，有助于构建宗喀语大语言模型。

Abstract: Large Language Models (LLMs) are gaining popularity and improving rapidly.
Tokenizers are crucial components of natural language processing, especially
for LLMs. Tokenizers break down input text into tokens that models can easily
process while ensuring the text is accurately represented, capturing its
meaning and structure. Effective tokenizers enhance the capabilities of LLMs by
improving a model's understanding of context and semantics, ultimately leading
to better performance in various downstream tasks, such as translation,
classification, sentiment analysis, and text generation. Most pre-trained
tokenizers are suitable for high-resource languages like English but perform
poorly for low-resource languages. Dzongkha, Bhutan's national language spoken
by around seven hundred thousand people, is a low-resource language, and its
linguistic complexity poses unique NLP challenges. Despite some progress,
significant research in Dzongkha NLP is lacking, particularly in tokenization.
This study evaluates the training and performance of three common tokenization
algorithms in comparison to other popular methods. Specifically, Byte-Pair
Encoding (BPE), WordPiece, and SentencePiece (Unigram) were evaluated for their
suitability for Dzongkha. Performance was assessed using metrics like Subword
Fertility, Proportion of Continued Words, Normalized Sequence Length, and
execution time. The results show that while all three algorithms demonstrate
potential, SentencePiece is the most effective for Dzongkha tokenization,
paving the way for further NLP advancements. This underscores the need for
tailored approaches for low-resource languages and ongoing research. In this
study, we presented three tokenization algorithms for Dzongkha, paving the way
for building Dzongkha Large Language Models.

</details>


### [3] [Toxicity Red-Teaming: Benchmarking LLM Safety in Singapore's Low-Resource Languages](https://arxiv.org/abs/2509.15260)
*Yujia Hu,Ming Shan Hee,Preslav Nakov,Roy Ka-Wei Lee*

Main category: cs.CL

TL;DR: SGToxicGuard是一个针对新加坡多语言环境（包括Singlish、中文、马来语和泰米尔语）的LLM安全评估数据集和框架，通过红队测试方法在对话、问答和内容创作三个场景中系统性地评估LLM的安全漏洞。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的安全机制在低资源多语言环境中的研究不足，特别是在新加坡这样语言多样化的环境中，需要填补这一空白。

Method: 采用红队测试方法，在对话、问答和内容创作三个真实场景中系统性地探测LLM的脆弱性，使用最先进的多语言LLM进行广泛实验。

Result: 实验结果揭示了现有LLM安全防护机制存在严重缺陷，特别是在多语言环境下的安全防护不足。

Conclusion: 该研究为在语言多样化环境中构建更安全、更具包容性的AI系统提供了可操作的见解，奠定了文化敏感性和毒性缓解的基础。

Abstract: The advancement of Large Language Models (LLMs) has transformed natural
language processing; however, their safety mechanisms remain under-explored in
low-resource, multilingual settings. Here, we aim to bridge this gap. In
particular, we introduce \textsf{SGToxicGuard}, a novel dataset and evaluation
framework for benchmarking LLM safety in Singapore's diverse linguistic
context, including Singlish, Chinese, Malay, and Tamil. SGToxicGuard adopts a
red-teaming approach to systematically probe LLM vulnerabilities in three
real-world scenarios: \textit{conversation}, \textit{question-answering}, and
\textit{content composition}. We conduct extensive experiments with
state-of-the-art multilingual LLMs, and the results uncover critical gaps in
their safety guardrails. By offering actionable insights into cultural
sensitivity and toxicity mitigation, we lay the foundation for safer and more
inclusive AI systems in linguistically diverse environments.\footnote{Link to
the dataset: https://github.com/Social-AI-Studio/SGToxicGuard.}
\textcolor{red}{Disclaimer: This paper contains sensitive content that may be
disturbing to some readers.}

</details>


### [4] [PolBiX: Detecting LLMs' Political Bias in Fact-Checking through X-phemisms](https://arxiv.org/abs/2509.15335)
*Charlott Jakob,David Harbecke,Patrick Parschan,Pia Wenzel Neves,Vera Schmitt*

Main category: cs.CL

TL;DR: 本研究通过构建政治内涵不同的最小化事实对，评估了LLMs在事实核查任务中的政治偏见，发现判断性词汇比政治倾向更显著影响真实性评估。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在需要客观评估的应用中越来越重要，但可能受到政治偏见影响。现有研究发现LLMs偏好左倾立场，但对事实核查等下游任务的影响尚未充分探索。

Method: 通过将德语声明中的词汇替换为委婉语或贬义词，构建事实等价但政治内涵不同的最小化对，评估六个LLMs在分类真假声明时的一致性。

Result: 研究发现判断性词汇的存在比政治倾向更显著影响真实性评估。少数模型显示出政治偏见倾向，但通过明确要求客观性的提示并不能减轻这种偏见。

Conclusion: LLMs在事实核查任务中主要受到判断性词汇的影响而非政治倾向，提示工程对减轻偏见效果有限。

Abstract: Large Language Models are increasingly used in applications requiring
objective assessment, which could be compromised by political bias. Many
studies found preferences for left-leaning positions in LLMs, but downstream
effects on tasks like fact-checking remain underexplored. In this study, we
systematically investigate political bias through exchanging words with
euphemisms or dysphemisms in German claims. We construct minimal pairs of
factually equivalent claims that differ in political connotation, to assess the
consistency of LLMs in classifying them as true or false. We evaluate six LLMs
and find that, more than political leaning, the presence of judgmental words
significantly influences truthfulness assessment. While a few models show
tendencies of political bias, this is not mitigated by explicitly calling for
objectivism in prompts.

</details>


### [5] [Quantifying Self-Awareness of Knowledge in Large Language Models](https://arxiv.org/abs/2509.15339)
*Yeongbin Seo,Dongha Lee,Jinyoung Yeo*

Main category: cs.CL

TL;DR: 该论文提出AQE方法来量化问题侧捷径对LLM幻觉预测的影响，并开发SCAO方法增强模型侧信号，实验表明SCAO在减少问题侧线索的情况下仍能保持稳定性能。


<details>
  <summary>Details</summary>
Motivation: 当前LLM幻觉预测常被解释为自我意识的表现，但作者认为这种性能可能源于问题侧捷径而非真正的模型侧内省。

Method: 提出近似问题侧效应(AQE)来量化问题意识贡献，并引入SCAO(单词回答语义压缩)方法来增强模型侧信号的使用。

Result: 分析显示大部分报告的成功源于利用问题中的表面模式，SCAO在问题侧线索减少的情况下实现了强大且一致的性能。

Conclusion: SCAO方法在促进LLM真正自我意识方面具有有效性，特别是在减少问题侧提示的设置中表现突出。

Abstract: Hallucination prediction in large language models (LLMs) is often interpreted
as a sign of self-awareness. However, we argue that such performance can arise
from question-side shortcuts rather than true model-side introspection. To
disentangle these factors, we propose the Approximate Question-side Effect
(AQE), which quantifies the contribution of question-awareness. Our analysis
across multiple datasets reveals that much of the reported success stems from
exploiting superficial patterns in questions. We further introduce SCAO
(Semantic Compression by Answering in One word), a method that enhances the use
of model-side signals. Experiments show that SCAO achieves strong and
consistent performance, particularly in settings with reduced question-side
cues, highlighting its effectiveness in fostering genuine self-awareness in
LLMs.

</details>


### [6] [Real, Fake, or Manipulated? Detecting Machine-Influenced Text](https://arxiv.org/abs/2509.15350)
*Yitong Wang,Zhongping Zhang,Margherita Piana,Zheng Zhou,Peter Gerstoft,Bryan A. Plummer*

Main category: cs.CL

TL;DR: 提出了HERO检测器，能够区分四种文本类型：人工撰写、机器生成、机器润色和机器翻译，通过长度专家模型和子类别指导模块提升检测性能


<details>
  <summary>Details</summary>
Motivation: 现有机器生成文本检测方法主要关注区分人工与机器撰写，忽略了细粒度的使用意图（如润色、翻译等），这些意图对于理解文本可信度很重要

Method: HERO采用分层长度鲁棒检测器，结合长度专家模型的预测，并使用子类别指导模块来区分易混淆的类别（如不同源语言）

Result: 在5个LLM和6个领域上的实验表明，HERO平均比现有最优方法提升2.5-3 mAP

Conclusion: HERO能够有效识别细粒度的机器影响文本类型，为理解LLM使用意图提供了更精确的检测工具

Abstract: Large Language Model (LLMs) can be used to write or modify documents,
presenting a challenge for understanding the intent behind their use. For
example, benign uses may involve using LLM on a human-written document to
improve its grammar or to translate it into another language. However, a
document entirely produced by a LLM may be more likely to be used to spread
misinformation than simple translation (\eg, from use by malicious actors or
simply by hallucinating). Prior works in Machine Generated Text (MGT) detection
mostly focus on simply identifying whether a document was human or machine
written, ignoring these fine-grained uses. In this paper, we introduce a
HiErarchical, length-RObust machine-influenced text detector (HERO), which
learns to separate text samples of varying lengths from four primary types:
human-written, machine-generated, machine-polished, and machine-translated.
HERO accomplishes this by combining predictions from length-specialist models
that have been trained with Subcategory Guidance. Specifically, for categories
that are easily confused (\eg, different source languages), our Subcategory
Guidance module encourages separation of the fine-grained categories, boosting
performance. Extensive experiments across five LLMs and six domains demonstrate
the benefits of our HERO, outperforming the state-of-the-art by 2.5-3 mAP on
average.

</details>


### [7] [Beyond Spurious Signals: Debiasing Multimodal Large Language Models via Counterfactual Inference and Adaptive Expert Routing](https://arxiv.org/abs/2509.15361)
*Zichen Wu,Hsiu-Yuan Huang,Yunfang Wu*

Main category: cs.CL

TL;DR: 本文提出了一种基于因果中介的新型去偏框架，通过区分核心语义与虚假上下文来解决多模态大语言模型中的表面相关性偏差问题。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在整合视觉和文本信息方面表现出强大能力，但经常依赖虚假相关性，这削弱了其在复杂多模态推理任务中的鲁棒性和泛化能力。

Method: 通过反事实示例区分核心语义与虚假文本和视觉上下文，实现训练阶段去偏；采用混合专家架构和动态路由机制，选择性激活模态特定的去偏专家。

Result: 在多模态讽刺检测和情感分析任务上的实证评估表明，该框架显著优于单模态去偏策略和现有最先进模型。

Conclusion: 提出的因果中介去偏框架有效解决了MLLMs中的表面相关性偏差问题，提升了模型的鲁棒性和泛化性能。

Abstract: Multimodal Large Language Models (MLLMs) have shown substantial capabilities
in integrating visual and textual information, yet frequently rely on spurious
correlations, undermining their robustness and generalization in complex
multimodal reasoning tasks. This paper addresses the critical challenge of
superficial correlation bias in MLLMs through a novel causal mediation-based
debiasing framework. Specially, we distinguishing core semantics from spurious
textual and visual contexts via counterfactual examples to activate
training-stage debiasing and employ a Mixture-of-Experts (MoE) architecture
with dynamic routing to selectively engages modality-specific debiasing
experts. Empirical evaluation on multimodal sarcasm detection and sentiment
analysis tasks demonstrates that our framework significantly surpasses unimodal
debiasing strategies and existing state-of-the-art models.

</details>


### [8] [Speech Language Models for Under-Represented Languages: Insights from Wolof](https://arxiv.org/abs/2509.15362)
*Yaya Sy,Dioula Doucouré,Christophe Cerisara,Irina Illina*

Main category: cs.CL

TL;DR: 本文介绍了为西非低资源语言沃洛夫语训练语音语言模型的历程，分享了关键见解，包括数据收集的重要性、语音编码器集成以及多步思维链训练方法。


<details>
  <summary>Details</summary>
Motivation: 沃洛夫语作为西非代表性不足的语言，缺乏高质量的语音语言模型。研究旨在为这类低资源语言开发首个语音LLM，扩展其语音识别和翻译能力。

Method: 1. 收集大规模、自发、高质量的沃洛夫语语音数据；2. 在HuBERT基础上进行持续预训练；3. 将语音编码器集成到沃洛夫语LLM中；4. 探索多步思维链训练方法。

Result: 训练出的语音LLM在语音识别方面优于基础模型和非洲中心模型，同时在语音翻译任务中也表现良好。模型和代码将公开分享。

Conclusion: 该方法成功为低资源语言沃洛夫语开发了首个语音LLM，证明了数据质量和模型架构对提升语音处理性能的重要性，为其他低资源语言的类似研究提供了可行路径。

Abstract: We present our journey in training a speech language model for Wolof, an
underrepresented language spoken in West Africa, and share key insights. We
first emphasize the importance of collecting large-scale, spontaneous,
high-quality speech data, and show that continued pretraining HuBERT on this
dataset outperforms both the base model and African-centric models on ASR. We
then integrate this speech encoder into a Wolof LLM to train the first Speech
LLM for this language, extending its capabilities to tasks such as speech
translation. Furthermore, we explore training the Speech LLM to perform
multi-step Chain-of-Thought before transcribing or translating. Our results
show that the Speech LLM not only improves speech recognition but also performs
well in speech translation. The models and the code will be openly shared.

</details>


### [9] [Frustratingly Easy Data Augmentation for Low-Resource ASR](https://arxiv.org/abs/2509.15373)
*Katsumi Ibaraki,David Chiang*

Main category: cs.CL

TL;DR: 本文提出了三种独立的数据增强方法用于低资源自动语音识别，通过文本生成和文本转语音技术合成音频数据，在四种低资源语言上验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言自动语音识别任务中数据稀缺的问题，利用有限标注数据生成更多训练样本。

Method: 使用三种文本生成方法（基于同义词替换、随机替换和LLM生成）创建新文本，然后通过文本转语音技术生成合成音频数据。

Result: 在四种低资源语言上，结合原始音频和合成数据微调预训练模型后，性能显著提升，其中Nashta语言实现了14.3%的绝对WER降低。

Conclusion: 该方法在低资源语言上表现有效，在高资源语言如英语上也显示出实用性，具有广泛的适用性。

Abstract: This paper introduces three self-contained data augmentation methods for
low-resource Automatic Speech Recognition (ASR). Our techniques first generate
novel text--using gloss-based replacement, random replacement, or an LLM-based
approach--and then apply Text-to-Speech (TTS) to produce synthetic audio. We
apply these methods, which leverage only the original annotated data, to four
languages with extremely limited resources (Vatlongos, Nashta, Shinekhen
Buryat, and Kakabe). Fine-tuning a pretrained Wav2Vec2-XLSR-53 model on a
combination of the original audio and generated synthetic data yields
significant performance gains, including a 14.3% absolute WER reduction for
Nashta. The methods prove effective across all four low-resource languages and
also show utility for high-resource languages like English, demonstrating their
broad applicability.

</details>


### [10] [Quantifying Uncertainty in Natural Language Explanations of Large Language Models for Question Answering](https://arxiv.org/abs/2509.15403)
*Yangyi Li,Mengdi Huai*

Main category: cs.CL

TL;DR: 本文提出了一种为大型语言模型生成的自然语言解释提供有效不确定性保证的新框架，特别是在存在噪声的医学查询场景下。


<details>
  <summary>Details</summary>
Motivation: 尽管自然语言解释能够以自解释的方式解释LLMs行为，但目前缺乏对这些生成解释的有效不确定性量化方法，这在理解解释背后的置信度方面至关重要。

Method: 提出了一个后处理且模型无关的不确定性估计框架，并设计了一种新颖的鲁棒不确定性估计方法，即使在噪声存在时也能保持有效的不确定性保证。

Result: 在问答任务上的大量实验证明了所提出方法的理想性能。

Conclusion: 该工作填补了为自然语言解释提供不确定性量化的研究空白，特别是在具有挑战性的医学查询场景中。

Abstract: Large language models (LLMs) have shown strong capabilities, enabling
concise, context-aware answers in question answering (QA) tasks. The lack of
transparency in complex LLMs has inspired extensive research aimed at
developing methods to explain large language behaviors. Among existing
explanation methods, natural language explanations stand out due to their
ability to explain LLMs in a self-explanatory manner and enable the
understanding of model behaviors even when the models are closed-source.
However, despite these promising advancements, there is no existing work
studying how to provide valid uncertainty guarantees for these generated
natural language explanations. Such uncertainty quantification is critical in
understanding the confidence behind these explanations. Notably, generating
valid uncertainty estimates for natural language explanations is particularly
challenging due to the auto-regressive generation process of LLMs and the
presence of noise in medical inquiries. To bridge this gap, in this work, we
first propose a novel uncertainty estimation framework for these generated
natural language explanations, which provides valid uncertainty guarantees in a
post-hoc and model-agnostic manner. Additionally, we also design a novel robust
uncertainty estimation method that maintains valid uncertainty guarantees even
under noise. Extensive experiments on QA tasks demonstrate the desired
performance of our methods.

</details>


### [11] [Deep learning and abstractive summarisation for radiological reports: an empirical study for adapting the PEGASUS models' family with scarce data](https://arxiv.org/abs/2509.15419)
*Claudio Benzoni,Martina Langhals,Martin Boeker,Luise Modersohn,Máté E. Maros*

Main category: cs.CL

TL;DR: 该论文研究了在医学领域中使用PEGASUS和PEGASUS-X模型进行抽象文本摘要的微调过程，重点关注如何避免过拟合和欠拟合问题。


<details>
  <summary>Details</summary>
Motivation: 尽管人工智能快速发展，但在医学等敏感和数据受限领域，抽象摘要仍然具有挑战性。随着医学影像数量的增加，自动化复杂医学文本摘要工具的需求日益重要。

Method: 使用PEGASUS和PEGASUS-X模型家族，在中等规模放射学报告公共数据集上进行微调。对每个模型评估了两个不同检查点，并使用不同大小的训练数据，通过词汇和语义指标监控模型性能。

Result: PEGASUS表现出与epoch-wise双下降或峰值-下降-恢复行为相关的不同阶段。对于PEGASUS-X，使用更大的检查点会导致性能下降。

Conclusion: 这项工作强调了在处理稀缺训练数据时微调高表达能力模型所面临的挑战和风险，为未来研究专门领域摘要模型更稳健的微调策略奠定了基础。

Abstract: Regardless of the rapid development of artificial intelligence, abstractive
summarisation is still challenging for sensitive and data-restrictive domains
like medicine. With the increasing number of imaging, the relevance of
automated tools for complex medical text summarisation is expected to become
highly relevant. In this paper, we investigated the adaptation via fine-tuning
process of a non-domain-specific abstractive summarisation encoder-decoder
model family, and gave insights to practitioners on how to avoid over- and
underfitting. We used PEGASUS and PEGASUS-X, on a medium-sized radiological
reports public dataset. For each model, we comprehensively evaluated two
different checkpoints with varying sizes of the same training data. We
monitored the models' performances with lexical and semantic metrics during the
training history on the fixed-size validation set. PEGASUS exhibited different
phases, which can be related to epoch-wise double-descent, or
peak-drop-recovery behaviour. For PEGASUS-X, we found that using a larger
checkpoint led to a performance detriment. This work highlights the challenges
and risks of fine-tuning models with high expressivity when dealing with scarce
training data, and lays the groundwork for future investigations into more
robust fine-tuning strategies for summarisation models in specialised domains.

</details>


### [12] [BiRQ: Bi-Level Self-Labeling Random Quantization for Self-Supervised Speech Recognition](https://arxiv.org/abs/2509.15430)
*Liuyuan Jiang,Xiaodong Cui,Brian Kingsbury,Tianyi Chen,Lisha Chen*

Main category: cs.CL

TL;DR: BiRQ是一种双层自监督学习框架，结合了BEST-RQ的效率和HuBERT风格的标签增强优势，通过模型内部生成伪标签，实现端到端训练和迭代标签优化。


<details>
  <summary>Details</summary>
Motivation: 解决语音自监督学习中伪标签生成的核心挑战：强标签（如HuBERT）性能好但依赖外部编码器和多阶段流程，而高效方法（如BEST-RQ）简单但标签质量较弱。

Method: 使用双层SSL框架，将模型中间表示通过随机投影量化器离散化生成增强标签，同时使用原始输入的直接锚定标签稳定训练。采用一阶双层优化和可微分Gumbel-softmax选择实现端到端训练。

Result: 在多个数据集（960小时LibriSpeech、150小时AMI会议、5000小时YODAS）上验证，BiRQ相比BEST-RQ获得了一致的性能提升，同时保持低复杂度和计算效率。

Conclusion: BiRQ框架成功结合了效率与标签质量优势，消除了对外部标签编码器的依赖，降低了内存成本，实现了端到端的迭代标签优化。

Abstract: Speech is a rich signal, and labeled audio-text pairs are costly, making
self-supervised learning essential for scalable representation learning. A core
challenge in speech SSL is generating pseudo-labels that are both informative
and efficient: strong labels, such as those used in HuBERT, improve downstream
performance but rely on external encoders and multi-stage pipelines, while
efficient methods like BEST-RQ achieve simplicity at the cost of weaker labels.
We propose BiRQ, a bilevel SSL framework that combines the efficiency of
BEST-RQ with the refinement benefits of HuBERT-style label enhancement. The key
idea is to reuse part of the model itself as a pseudo-label generator:
intermediate representations are discretized by a random-projection quantizer
to produce enhanced labels, while anchoring labels derived directly from the
raw input stabilize training and prevent collapse. Training is formulated as an
efficient first-order bilevel optimization problem, solved end-to-end with
differentiable Gumbel-softmax selection. This design eliminates the need for
external label encoders, reduces memory cost, and enables iterative label
refinement in an end-to-end fashion. BiRQ consistently improves over BEST-RQ
while maintaining low complexity and computational efficiency. We validate our
method on various datasets, including 960-hour LibriSpeech, 150-hour AMI
meetings and 5,000-hour YODAS, demonstrating consistent gains over BEST-RQ.

</details>


### [13] [PILOT: Steering Synthetic Data Generation with Psychological & Linguistic Output Targeting](https://arxiv.org/abs/2509.15447)
*Caitlin Cisar,Emily Sheffield,Joshua Drake,Alden Harrell,Subramanian Chidambaram,Nikita Nangia,Vinayak Arannil,Alex Williams*

Main category: cs.CL

TL;DR: PILOT是一个两阶段框架，用于通过结构化心理语言学配置文件来引导大语言模型生成更可控的合成数据，相比传统自然语言人物描述方法，能显著减少人工感并提高输出一致性。


<details>
  <summary>Details</summary>
Motivation: 现有生成式AI应用依赖自然语言人物描述来引导合成数据生成，但这种方法迫使模型对需要强调的属性做出非预期的推断，限制了输出的精确控制。

Method: PILOT框架分为两个阶段：第一阶段将自然语言人物描述转换为具有标准化分数的多维心理语言学配置文件；第二阶段使用这些配置文件沿可测量的变化轴引导生成过程。评估了三种引导方法：自然语言人物引导(NPS)、基于模式的引导(SBS)和混合人物-模式引导(HPS)。

Result: 基于模式的方法显著减少了人工感的人物重复，提高了输出连贯性，轮廓分数从0.098增加到0.237，主题纯度从0.773增加到0.957。SBS产生更简洁且主题一致性更高的输出，NPS提供更大的词汇多样性但可预测性降低，HPS在两者之间取得平衡。

Conclusion: PILOT在所有条件下都保持了高质量的回答，不同引导方法之间没有统计学显著差异。该框架在输出可控性和质量之间实现了有效平衡。

Abstract: Generative AI applications commonly leverage user personas as a steering
mechanism for synthetic data generation, but reliance on natural language
representations forces models to make unintended inferences about which
attributes to emphasize, limiting precise control over outputs. We introduce
PILOT (Psychological and Linguistic Output Targeting), a two-phase framework
for steering large language models with structured psycholinguistic profiles.
In Phase 1, PILOT translates natural language persona descriptions into
multidimensional profiles with normalized scores across linguistic and
psychological dimensions. In Phase 2, these profiles guide generation along
measurable axes of variation. We evaluate PILOT across three state-of-the-art
LLMs (Mistral Large 2, Deepseek-R1, LLaMA 3.3 70B) using 25 synthetic personas
under three conditions: Natural-language Persona Steering (NPS), Schema-Based
Steering (SBS), and Hybrid Persona-Schema Steering (HPS). Results demonstrate
that schema-based approaches significantly reduce artificial-sounding persona
repetition while improving output coherence, with silhouette scores increasing
from 0.098 to 0.237 and topic purity from 0.773 to 0.957. Our analysis reveals
a fundamental trade-off: SBS produces more concise outputs with higher topical
consistency, while NPS offers greater lexical diversity but reduced
predictability. HPS achieves a balance between these extremes, maintaining
output variety while preserving structural consistency. Expert linguistic
evaluation confirms that PILOT maintains high response quality across all
conditions, with no statistically significant differences between steering
approaches.

</details>


### [14] [Evaluating Multimodal Large Language Models on Spoken Sarcasm Understanding](https://arxiv.org/abs/2509.15476)
*Zhu Li,Xiyuan Gao,Yuqing Zhang,Shekhar Nayak,Matt Coler*

Main category: cs.CL

TL;DR: 本文系统评估了LLMs和多模态LLMs在英语和中文讽刺检测中的表现，发现音频模型在单模态中表现最佳，而文本-音频和音频-视觉组合优于单模态和三模态模型，MLLMs在跨语言音频-视觉-文本讽刺理解方面具有潜力。


<details>
  <summary>Details</summary>
Motivation: 讽刺检测在自然语言理解中仍具挑战性，因为讽刺意图通常依赖于跨越文本、语音和视觉的微妙跨模态线索。现有研究主要关注文本或视觉-文本讽刺，而全面的音频-视觉-文本讽刺理解尚未充分探索。

Method: 在零样本、少样本和LoRA微调设置下，系统评估LLMs和多模态LLMs在英语（MUStARD++）和中文（MCSD 1.0）讽刺检测中的表现。除了直接分类，还探索模型作为特征编码器，通过协作门控融合模块整合其表示。

Result: 实验结果显示，基于音频的模型在单模态中表现最强，而文本-音频和音频-视觉组合优于单模态和三模态模型。此外，MLLMs如Qwen-Omni在零样本和微调性能上表现出竞争力。

Conclusion: 研究结果突显了MLLMs在跨语言、音频-视觉-文本讽刺理解方面的潜力。

Abstract: Sarcasm detection remains a challenge in natural language understanding, as
sarcastic intent often relies on subtle cross-modal cues spanning text, speech,
and vision. While prior work has primarily focused on textual or visual-textual
sarcasm, comprehensive audio-visual-textual sarcasm understanding remains
underexplored. In this paper, we systematically evaluate large language models
(LLMs) and multimodal LLMs for sarcasm detection on English (MUStARD++) and
Chinese (MCSD 1.0) in zero-shot, few-shot, and LoRA fine-tuning settings. In
addition to direct classification, we explore models as feature encoders,
integrating their representations through a collaborative gating fusion module.
Experimental results show that audio-based models achieve the strongest
unimodal performance, while text-audio and audio-vision combinations outperform
unimodal and trimodal models. Furthermore, MLLMs such as Qwen-Omni show
competitive zero-shot and fine-tuned performance. Our findings highlight the
potential of MLLMs for cross-lingual, audio-visual-textual sarcasm
understanding.

</details>


### [15] [Red Teaming Multimodal Language Models: Evaluating Harm Across Prompt Modalities and Models](https://arxiv.org/abs/2509.15478)
*Madison Van Doren,Casey Ford,Emily Dix*

Main category: cs.CL

TL;DR: 本研究评估了四种主流多模态大语言模型（GPT-4o、Claude Sonnet 3.5、Pixtral 12B和Qwen VL Plus）在对抗性提示下的安全性，发现模型间存在显著差异，Pixtral 12B有害响应率最高（约62%），而Claude Sonnet 3.5最安全（约10%）。


<details>
  <summary>Details</summary>
Motivation: 随着多模态大语言模型在现实应用中的广泛部署，其在对抗条件下的安全性尚未得到充分探索，需要系统评估其无害性。

Method: 26名红队成员生成726个针对非法活动、虚假信息和不道德行为的对抗性提示，提交给四个模型，17名标注者对2,904个模型输出进行5级有害性评分。

Result: 不同模型和模态间存在显著安全性差异，文本提示比多模态提示略有效绕过安全机制，模型类型和输入模态都是有害性的显著预测因子。

Conclusion: 研究结果强调了随着MLLM更广泛部署，迫切需要建立稳健的多模态安全基准。

Abstract: Multimodal large language models (MLLMs) are increasingly used in real world
applications, yet their safety under adversarial conditions remains
underexplored. This study evaluates the harmlessness of four leading MLLMs
(GPT-4o, Claude Sonnet 3.5, Pixtral 12B, and Qwen VL Plus) when exposed to
adversarial prompts across text-only and multimodal formats. A team of 26 red
teamers generated 726 prompts targeting three harm categories: illegal
activity, disinformation, and unethical behaviour. These prompts were submitted
to each model, and 17 annotators rated 2,904 model outputs for harmfulness
using a 5-point scale. Results show significant differences in vulnerability
across models and modalities. Pixtral 12B exhibited the highest rate of harmful
responses (~62%), while Claude Sonnet 3.5 was the most resistant (~10%).
Contrary to expectations, text-only prompts were slightly more effective at
bypassing safety mechanisms than multimodal ones. Statistical analysis
confirmed that both model type and input modality were significant predictors
of harmfulness. These findings underscore the urgent need for robust,
multimodal safety benchmarks as MLLMs are deployed more widely.

</details>


### [16] [mucAI at BAREC Shared Task 2025: Towards Uncertainty Aware Arabic Readability Assessment](https://arxiv.org/abs/2509.15485)
*Ahmed Abdou*

Main category: cs.CL

TL;DR: 提出一种模型无关的后处理技术，用于阿拉伯语细粒度可读性分类，通过保形预测生成具有覆盖保证的预测集，并使用加权平均方法提高分类性能。


<details>
  <summary>Details</summary>
Motivation: 解决阿拉伯语可读性分类中高惩罚误分类问题，为教育评估提供统计保证和实际可用性。

Method: 应用保形预测生成预测集，使用softmax重归一化概率计算加权平均值，进行不确定性感知解码。

Result: 在BAREC 2025共享任务中，句子级别测试集QWK达到84.9%，盲测集85.7%，文档级别73.3%，相比基线模型提升1-3个QWK点。

Conclusion: 该方法能有效减少误分类惩罚，让人类评审员只需关注少数可能的可读性级别，结合了统计保证和实际应用价值。

Abstract: We present a simple, model-agnostic post-processing technique for
fine-grained Arabic readability classification in the BAREC 2025 Shared Task
(19 ordinal levels). Our method applies conformal prediction to generate
prediction sets with coverage guarantees, then computes weighted averages using
softmax-renormalized probabilities over the conformal sets. This
uncertainty-aware decoding improves Quadratic Weighted Kappa (QWK) by reducing
high-penalty misclassifications to nearer levels. Our approach shows consistent
QWK improvements of 1-3 points across different base models. In the strict
track, our submission achieves QWK scores of 84.9\%(test) and 85.7\% (blind
test) for sentence level, and 73.3\% for document level. For Arabic educational
assessment, this enables human reviewers to focus on a handful of plausible
levels, combining statistical guarantees with practical usability.

</details>


### [17] [LLM Cache Bandit Revisited: Addressing Query Heterogeneity for Cost-Effective LLM Inference](https://arxiv.org/abs/2509.15515)
*Hantao Yang,Hong Xie,Defu Lian,Enhong Chen*

Main category: cs.CL

TL;DR: 本文重新审视了LLM缓存强盗问题，特别关注处理查询异构性以实现成本效益的LLM推理。通过将最优缓存选择建模为背包问题，并采用基于累积的策略来平衡计算开销和缓存更新，实现了理论上的遗憾界限改进和实际成本降低约12%。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常假设查询大小均匀，但实际中查询大小存在异构性，这为缓存选择引入了组合结构，使得缓存替换过程在计算和统计上更具挑战性。

Method: 将最优缓存选择视为背包问题，采用基于累积的策略来有效平衡计算开销和缓存更新。

Result: 理论分析证明算法遗憾达到O(√MNT)界限，相比Berkeley的O(MN√T)结果改进了√MN系数。实验基于真实数据表明算法将总成本降低约12%。

Conclusion: 提出的方法有效解决了查询异构性带来的挑战，在理论和实验上都取得了显著改进，为成本效益的LLM推理提供了实用解决方案。

Abstract: This paper revisits the LLM cache bandit problem, with a special focus on
addressing the query heterogeneity for cost-effective LLM inference. Previous
works often assume uniform query sizes. Heterogeneous query sizes introduce a
combinatorial structure for cache selection, making the cache replacement
process more computationally and statistically challenging. We treat optimal
cache selection as a knapsack problem and employ an accumulation-based strategy
to effectively balance computational overhead and cache updates. In theoretical
analysis, we prove that the regret of our algorithm achieves an $O(\sqrt{MNT})$
bound, improving the coefficient of $\sqrt{MN}$ compared to the $O(MN\sqrt{T})$
result in Berkeley, where $N$ is the total number of queries and $M$ is the
cache size. Additionally, we also provide a problem-dependent bound, which was
absent in previous works. The experiment rely on real-world data show that our
algorithm reduces the total cost by approximately 12\%.

</details>


### [18] [How do Language Models Generate Slang: A Systematic Comparison between Human and Machine-Generated Slang Usages](https://arxiv.org/abs/2509.15518)
*Siyang Wu,Zhewei Sun*

Main category: cs.CL

TL;DR: 本文系统比较了人类和AI生成的俚语用法，发现LLMs在俚语理解上存在显著偏见，虽然掌握了俚语的创造性特征，但与人类认知存在差距。


<details>
  <summary>Details</summary>
Motivation: 俚语作为非正式语言对NLP系统构成挑战，需要评估LLMs是否掌握了与人类一致的俚语结构知识。

Method: 构建评估框架，从三个核心方面比较在线俚语词典的人类俚语用法与GPT-4o和Llama-3生成的俚语：系统性偏见、创造性和信息性。

Result: 发现LLMs在俚语感知上存在显著偏见，虽然掌握了俚语的创造性方面，但这些知识不足以支持外推性任务如语言分析。

Conclusion: LLMs已掌握俚语的重要知识，但与人类认知的对齐程度不足以使其胜任语言分析等外推任务。

Abstract: Slang is a commonly used type of informal language that poses a daunting
challenge to NLP systems. Recent advances in large language models (LLMs),
however, have made the problem more approachable. While LLM agents are becoming
more widely applied to intermediary tasks such as slang detection and slang
interpretation, their generalizability and reliability are heavily dependent on
whether these models have captured structural knowledge about slang that align
well with human attested slang usages. To answer this question, we contribute a
systematic comparison between human and machine-generated slang usages. Our
evaluative framework focuses on three core aspects: 1) Characteristics of the
usages that reflect systematic biases in how machines perceive slang, 2)
Creativity reflected by both lexical coinages and word reuses employed by the
slang usages, and 3) Informativeness of the slang usages when used as
gold-standard examples for model distillation. By comparing human-attested
slang usages from the Online Slang Dictionary (OSD) and slang generated by
GPT-4o and Llama-3, we find significant biases in how LLMs perceive slang. Our
results suggest that while LLMs have captured significant knowledge about the
creative aspects of slang, such knowledge does not align with humans
sufficiently to enable LLMs for extrapolative tasks such as linguistic
analyses.

</details>


### [19] [A method for improving multilingual quality and diversity of instruction fine-tuning datasets](https://arxiv.org/abs/2509.15549)
*Chunguang Zhao,Yilun Liu,Pufan Zeng,Yuanchang Luo,Shimin Tao,Minggui He,Weibin Meng,Song Xu,Ziang Chen,Chen Liu,Hongxia Ma,Li Zhang,Boxing Chen,Daimeng Wei*

Main category: cs.CL

TL;DR: 本文提出了M-DaQ方法，通过选择高质量和语义多样性的多语言指令微调样本来提升大语言模型的多语言能力，并在18种语言上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 多语言指令微调对于大语言模型在多样化语言和文化环境中的泛化能力至关重要，但高质量多语言训练数据的稀缺和相应构建方法的缺乏是主要瓶颈。

Method: 提出了Multilingual Data Quality and Diversity (M-DaQ)方法，通过选择高质量和语义多样性的多语言指令微调样本来改进模型的多语言能力，并首次系统研究了多语言环境下的Superficial Alignment Hypothesis。

Result: 在18种语言上的实验结果表明，使用M-DaQ方法微调的模型相比基线模型获得了显著的性能提升，胜率超过60%。人工评估进一步验证了这些增益，特别是在文化点表达方面的改进。

Conclusion: M-DaQ方法有效解决了多语言指令微调中的数据质量问题，显著提升了模型的多语言性能，并开源了代码以支持未来研究。

Abstract: Multilingual Instruction Fine-Tuning (IFT) is essential for enabling large
language models (LLMs) to generalize effectively across diverse linguistic and
cultural contexts. However, the scarcity of high-quality multilingual training
data and corresponding building method remains a critical bottleneck. While
data selection has shown promise in English settings, existing methods often
fail to generalize across languages due to reliance on simplistic heuristics or
language-specific assumptions. In this work, we introduce Multilingual Data
Quality and Diversity (M-DaQ), a novel method for improving LLMs
multilinguality, by selecting high-quality and semantically diverse
multilingual IFT samples. We further conduct the first systematic investigation
of the Superficial Alignment Hypothesis (SAH) in multilingual setting.
Empirical results across 18 languages demonstrate that models fine-tuned with
M-DaQ method achieve significant performance gains over vanilla baselines over
60% win rate. Human evaluations further validate these gains, highlighting the
increment of cultural points in the response. We release the M-DaQ code to
support future research.

</details>


### [20] [DNA-DetectLLM: Unveiling AI-Generated Text via a DNA-Inspired Mutation-Repair Paradigm](https://arxiv.org/abs/2509.15550)
*Xiaowei Zhu,Yubing Ren,Fang Fang,Qingfeng Tan,Shi Wang,Yanan Cao*

Main category: cs.CL

TL;DR: 提出DNA-DetectLLM方法，通过DNA启发的修复过程来区分AI生成和人类写作文本，在多个基准数据集上实现5.55%的AUROC和2.08%的F1分数提升。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的快速发展，AI生成文本与人类写作文本的界限日益模糊，带来了错误信息、作者身份模糊和知识产权等社会风险，迫切需要可靠的AI文本检测方法。

Method: 提出DNA启发的视角，通过修复过程直接捕捉人类写作和AI生成文本的内在差异。DNA-DetectLLM为零样本检测方法，为每个输入构建理想的AI生成序列，迭代修复非最优标记，并将累积修复努力量化为可解释的检测信号。

Result: 实证评估表明，该方法实现了最先进的检测性能，对多种对抗攻击和输入长度具有强鲁棒性。在多个公共基准数据集上，AUROC相对提升5.55%，F1分数相对提升2.08%。

Conclusion: DNA-DetectLLM提供了一种有效且可解释的AI文本检测解决方案，为解决AI生成文本带来的社会风险提供了有力工具。

Abstract: The rapid advancement of large language models (LLMs) has blurred the line
between AI-generated and human-written text. This progress brings societal
risks such as misinformation, authorship ambiguity, and intellectual property
concerns, highlighting the urgent need for reliable AI-generated text detection
methods. However, recent advances in generative language modeling have resulted
in significant overlap between the feature distributions of human-written and
AI-generated text, blurring classification boundaries and making accurate
detection increasingly challenging. To address the above challenges, we propose
a DNA-inspired perspective, leveraging a repair-based process to directly and
interpretably capture the intrinsic differences between human-written and
AI-generated text. Building on this perspective, we introduce DNA-DetectLLM, a
zero-shot detection method for distinguishing AI-generated and human-written
text. The method constructs an ideal AI-generated sequence for each input,
iteratively repairs non-optimal tokens, and quantifies the cumulative repair
effort as an interpretable detection signal. Empirical evaluations demonstrate
that our method achieves state-of-the-art detection performance and exhibits
strong robustness against various adversarial attacks and input lengths.
Specifically, DNA-DetectLLM achieves relative improvements of 5.55% in AUROC
and 2.08% in F1 score across multiple public benchmark datasets.

</details>


### [21] [Exploring Polyglot Harmony: On Multilingual Data Allocation for Large Language Models Pretraining](https://arxiv.org/abs/2509.15556)
*Ping Guo,Yubing Ren,Binbin Liu,Fengze Liu,Haobin Lin,Yifan Zhang,Bingni Zhang,Taifeng Wang,Yin Zheng*

Main category: cs.CL

TL;DR: Climb框架通过量化跨语言交互来优化多语言训练数据分配，显著提升LLMs的多语言性能


<details>
  <summary>Details</summary>
Motivation: 由于跨语言交互的复杂性和对数据集规模的敏感性，确定多语言训练语料的最佳语言比例具有挑战性

Method: 提出跨语言交互感知的语言比例，通过两步骤优化程序：先平衡各语言的边际收益，再最大化语言分配向量的幅度

Result: 实验证实Climb能准确测量跨语言交互，使用Climb比例训练的LLMs在多语言性能上达到最先进水平

Conclusion: Climb框架为多语言数据分配提供了系统化解决方案，显著简化了复杂的多语言优化问题

Abstract: Large language models (LLMs) have become integral to a wide range of
applications worldwide, driving an unprecedented global demand for effective
multilingual capabilities. Central to achieving robust multilingual performance
is the strategic allocation of language proportions within training corpora.
However, determining optimal language ratios is highly challenging due to
intricate cross-lingual interactions and sensitivity to dataset scale. This
paper introduces Climb (Cross-Lingual Interaction-aware Multilingual
Balancing), a novel framework designed to systematically optimize multilingual
data allocation. At its core, Climb introduces a cross-lingual
interaction-aware language ratio, explicitly quantifying each language's
effective allocation by capturing inter-language dependencies. Leveraging this
ratio, Climb proposes a principled two-step optimization procedure--first
equalizing marginal benefits across languages, then maximizing the magnitude of
the resulting language allocation vectors--significantly simplifying the
inherently complex multilingual optimization problem. Extensive experiments
confirm that Climb can accurately measure cross-lingual interactions across
various multilingual settings. LLMs trained with Climb-derived proportions
consistently achieve state-of-the-art multilingual performance, even achieving
competitive performance with open-sourced LLMs trained with more tokens.

</details>


### [22] [How important is language for human-like intelligence?](https://arxiv.org/abs/2509.15560)
*Gary Lupyan,Hunter Gentry,Martin Zettersten*

Main category: cs.CL

TL;DR: 语言不仅是思想的表达工具，更在人类认知中扮演变革性角色，可能促进更通用AI系统和人类智能核心方面的出现。


<details>
  <summary>Details</summary>
Motivation: 探讨语言在认知中的根本作用——是单纯表达思想的工具，还是能够产生原本无法拥有的思想的变革性力量。

Method: 分析语言的两个关键特性：提供便于表示和推理抽象概念的紧凑表示；这些压缩表示是集体心智迭代输出的文化演化抽象。

Result: 语言暴露给足够强大的学习系统（无论是生物还是人工的）时，会学习世界的压缩模型，逆向工程支持人类思维的概念和因果结构。

Conclusion: 语言可能是实现更通用AI和人类智能的关键，因为它承载了文化演化的抽象概念，能够压缩和传递复杂的认知结构。

Abstract: We use language to communicate our thoughts. But is language merely the
expression of thoughts, which are themselves produced by other, nonlinguistic
parts of our minds? Or does language play a more transformative role in human
cognition, allowing us to have thoughts that we otherwise could (or would) not
have? Recent developments in artificial intelligence (AI) and cognitive science
have reinvigorated this old question. We argue that language may hold the key
to the emergence of both more general AI systems and central aspects of human
intelligence. We highlight two related properties of language that make it such
a powerful tool for developing domain--general abilities. First, language
offers compact representations that make it easier to represent and reason
about many abstract concepts (e.g., exact numerosity). Second, these compressed
representations are the iterated output of collective minds. In learning a
language, we learn a treasure trove of culturally evolved abstractions. Taken
together, these properties mean that a sufficiently powerful learning system
exposed to language--whether biological or artificial--learns a compressed
model of the world, reverse engineering many of the conceptual and causal
structures that support human (and human-like) thought.

</details>


### [23] [LiteLong: Resource-Efficient Long-Context Data Synthesis for LLMs](https://arxiv.org/abs/2509.15568)
*Junlong Jia,Xing Wu,Chaochen Gao,Ziyang Chen,Zijia Lin,Zhongzhi Li,Weinong Wang,Haotian Xu,Donghui Jin,Debing Zhang,Binghui Guo*

Main category: cs.CL

TL;DR: LiteLong是一种资源高效的长上下文数据合成方法，通过结构化主题组织和多智能体辩论来生成高质量的长上下文训练数据。


<details>
  <summary>Details</summary>
Motivation: 现有基于相关性的聚合方法在计算效率方面面临挑战，高质量长上下文数据对于训练能够处理长文档的大语言模型至关重要。

Method: 利用BISAC图书分类系统提供层次化主题组织，采用多LLM辩论机制生成多样化高质量主题，使用轻量级BM25检索获取相关文档并拼接成128K标记的训练样本。

Result: 在HELMET和Ruler基准测试中，LiteLong实现了具有竞争力的长上下文性能，并能与其他长依赖增强方法无缝集成。

Conclusion: LiteLong通过降低计算和数据工程成本，使高质量长上下文数据合成更加易于实现，促进了长上下文语言训练的进一步研究。

Abstract: High-quality long-context data is essential for training large language
models (LLMs) capable of processing extensive documents, yet existing synthesis
approaches using relevance-based aggregation face challenges of computational
efficiency. We present LiteLong, a resource-efficient method for synthesizing
long-context data through structured topic organization and multi-agent debate.
Our approach leverages the BISAC book classification system to provide a
comprehensive hierarchical topic organization, and then employs a debate
mechanism with multiple LLMs to generate diverse, high-quality topics within
this structure. For each topic, we use lightweight BM25 retrieval to obtain
relevant documents and concatenate them into 128K-token training samples.
Experiments on HELMET and Ruler benchmarks demonstrate that LiteLong achieves
competitive long-context performance and can seamlessly integrate with other
long-dependency enhancement methods. LiteLong makes high-quality long-context
data synthesis more accessible by reducing both computational and data
engineering costs, facilitating further research in long-context language
training.

</details>


### [24] [Relevance to Utility: Process-Supervised Rewrite for RAG](https://arxiv.org/abs/2509.15577)
*Jaeyoung Kim,Jongho Kim,Seung-won Hwang,Seoho Song,Young-In Song*

Main category: cs.CL

TL;DR: 本文提出了R2U方法，通过过程监督直接优化生成正确答案的概率，解决检索增强生成系统中检索相关性与生成效用之间的差距问题。


<details>
  <summary>Details</summary>
Motivation: 现有的检索增强生成系统存在检索相关性优化与生成效用之间的差距：检索到的文档可能在主题上相关，但缺乏生成过程中有效推理所需的内容。现有的"桥接"模块尝试重写检索文本以改善生成效果，但未能捕捉到真正的文档效用。

Method: 提出R2U方法，关键区别在于通过过程监督直接优化生成正确答案的概率。由于直接监督成本高昂，还提出了通过扩展LLM监督来近似高效蒸馏管道，帮助较小的重写模型更好地泛化。

Result: 在多个开放域问答基准上评估该方法，实证结果表明相对于强大的桥接基线方法有持续改进。

Conclusion: R2U方法通过过程监督直接优化生成概率，有效解决了检索增强生成系统中的效用差距问题，在多个基准测试中表现出优于现有方法的性能。

Abstract: Retrieval-Augmented Generation systems often suffer from a gap between
optimizing retrieval relevance and generative utility: retrieved documents may
be topically relevant but still lack the content needed for effective reasoning
during generation. While existing "bridge" modules attempt to rewrite the
retrieved text for better generation, we show how they fail to capture true
document utility. In this work, we propose R2U, with a key distinction of
directly optimizing to maximize the probability of generating a correct answer
through process supervision. As such direct observation is expensive, we also
propose approximating an efficient distillation pipeline by scaling the
supervision from LLMs, which helps the smaller rewriter model generalize
better. We evaluate our method across multiple open-domain question-answering
benchmarks. The empirical results demonstrate consistent improvements over
strong bridging baselines.

</details>


### [25] [Chunk Based Speech Pre-training with High Resolution Finite Scalar Quantization](https://arxiv.org/abs/2509.15579)
*Yun Tang,Cindy Tseng*

Main category: cs.CL

TL;DR: 提出了一种基于分块的自监督学习算法（Chunk SSL），用于流式和离线语音预训练的统一解决方案，通过掩码预测损失和有限标量量化实现高效的语音表示学习。


<details>
  <summary>Details</summary>
Motivation: 随着语音技术的快速发展，低延迟的人机语音通信需求日益增长。现有的自监督学习算法大多基于完整语音假设，在流式应用中处理部分语音时需要妥协，因此需要一种统一的预训练方法。

Method: 使用基于分块的掩码预测损失，通过有限标量量化（FSQ）模块离散化语音特征，采用复制和追加数据增强方法进行高效预训练，并引入分组掩码预测损失来降低大码本带来的计算成本。

Result: 在Librispeech和Must-C数据集上的实验表明，该方法在语音识别和语音翻译任务中，无论是流式还是离线模式都能取得极具竞争力的结果。

Conclusion: Chunk SSL算法为流式和离线语音预训练提供了统一的解决方案，通过分块处理和高效量化方法在保持性能的同时降低了计算成本。

Abstract: Low latency speech human-machine communication is becoming increasingly
necessary as speech technology advances quickly in the last decade. One of the
primary factors behind the advancement of speech technology is self-supervised
learning. Most self-supervised learning algorithms are designed with full
utterance assumption and compromises have to made if partial utterances are
presented, which are common in the streaming applications. In this work, we
propose a chunk based self-supervised learning (Chunk SSL) algorithm as an
unified solution for both streaming and offline speech pre-training. Chunk SSL
is optimized with the masked prediction loss and an acoustic encoder is
encouraged to restore indices of those masked speech frames with help from
unmasked frames in the same chunk and preceding chunks. A copy and append data
augmentation approach is proposed to conduct efficient chunk based
pre-training. Chunk SSL utilizes a finite scalar quantization (FSQ) module to
discretize input speech features and our study shows a high resolution FSQ
codebook, i.e., a codebook with vocabulary size up to a few millions, is
beneficial to transfer knowledge from the pre-training task to the downstream
tasks. A group masked prediction loss is employed during pre-training to
alleviate the high memory and computation cost introduced by the large
codebook. The proposed approach is examined in two speech to text tasks, i.e.,
speech recognition and speech translation. Experimental results on the
\textsc{Librispeech} and \textsc{Must-C} datasets show that the proposed method
could achieve very competitive results for speech to text tasks at both
streaming and offline modes.

</details>


### [26] [DivLogicEval: A Framework for Benchmarking Logical Reasoning Evaluation in Large Language Models](https://arxiv.org/abs/2509.15587)
*Tsz Ting Chung,Lemao Liu,Mo Yu,Dit-Yan Yeung*

Main category: cs.CL

TL;DR: 本文提出了一个新的经典逻辑基准DivLogicEval，通过反直觉方式构建多样化自然语句，并引入新评估指标来减轻LLM中的偏见和随机性影响。


<details>
  <summary>Details</summary>
Motivation: 现有逻辑推理基准存在语言多样性不足、分布偏离理想基准的问题，导致评估结果有偏差，需要更忠实评估LLM逻辑推理能力。

Method: 构建DivLogicEval基准，包含反直觉方式组成的多样化自然语句；设计新评估指标来缓解LLM中的偏见和随机性影响。

Result: 实验验证了DivLogicEval中问题确实需要逻辑推理能力，并比较了不同流行LLM在逻辑推理方面的表现差异。

Conclusion: DivLogicEval提供了更可靠的逻辑推理评估基准，有助于准确衡量LLM的逻辑推理能力。

Abstract: Logic reasoning in natural language has been recognized as an important
measure of human intelligence for Large Language Models (LLMs). Popular
benchmarks may entangle multiple reasoning skills and thus provide unfaithful
evaluations on the logic reasoning skill. Meanwhile, existing logic reasoning
benchmarks are limited in language diversity and their distributions are
deviated from the distribution of an ideal logic reasoning benchmark, which may
lead to biased evaluation results. This paper thereby proposes a new classical
logic benchmark DivLogicEval, consisting of natural sentences composed of
diverse statements in a counterintuitive way. To ensure a more reliable
evaluation, we also introduce a new evaluation metric that mitigates the
influence of bias and randomness inherent in LLMs. Through experiments, we
demonstrate the extent to which logical reasoning is required to answer the
questions in DivLogicEval and compare the performance of different popular LLMs
in conducting logical reasoning.

</details>


### [27] [SciEvent: Benchmarking Multi-domain Scientific Event Extraction](https://arxiv.org/abs/2509.15620)
*Bofu Dong,Pritesh Shah,Sumedh Sonawane,Tiyasha Banerjee,Erin Brady,Xinya Du,Ming Jiang*

Main category: cs.CL

TL;DR: SciEvent是一个新颖的多领域科学事件抽取基准，包含500篇跨5个研究领域的摘要，采用统一的事件抽取模式，旨在解决传统科学信息抽取在跨学科研究中的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统科学信息抽取主要依赖窄领域的实体关系抽取，难以适应跨学科研究需求，且常常产生碎片化或矛盾的信息陈述。

Method: 将科学信息抽取定义为多阶段事件抽取流程：1）将摘要分割为背景、方法、结果和结论等核心科学活动；2）提取相应的触发词和细粒度论元。

Result: 实验显示，当前的事件抽取模型、大语言模型和人工标注者之间存在性能差距，特别是在社会学和人文学科领域表现不佳。

Conclusion: SciEvent作为一个具有挑战性的基准，是朝着可泛化、多领域科学信息抽取迈出的重要一步。

Abstract: Scientific information extraction (SciIE) has primarily relied on
entity-relation extraction in narrow domains, limiting its applicability to
interdisciplinary research and struggling to capture the necessary context of
scientific information, often resulting in fragmented or conflicting
statements. In this paper, we introduce SciEvent, a novel multi-domain
benchmark of scientific abstracts annotated via a unified event extraction (EE)
schema designed to enable structured and context-aware understanding of
scientific content. It includes 500 abstracts across five research domains,
with manual annotations of event segments, triggers, and fine-grained
arguments. We define SciIE as a multi-stage EE pipeline: (1) segmenting
abstracts into core scientific activities--Background, Method, Result, and
Conclusion; and (2) extracting the corresponding triggers and arguments.
Experiments with fine-tuned EE models, large language models (LLMs), and human
annotators reveal a performance gap, with current models struggling in domains
such as sociology and humanities. SciEvent serves as a challenging benchmark
and a step toward generalizable, multi-domain SciIE.

</details>


### [28] [Concept Unlearning in Large Language Models via Self-Constructed Knowledge Triplets](https://arxiv.org/abs/2509.15621)
*Tomoya Yamashita,Yuuki Yamanaka,Masanori Yamada,Takayuki Miura,Toshiki Shibahara,Tomoharu Iwata*

Main category: cs.CL

TL;DR: 该论文提出了概念遗忘（Concept Unlearning）作为LLM遗忘的新需求，通过知识图谱表示LLM内部知识，定义遗忘目标节点和相关边，实现了更直观有效的概念级遗忘方法。


<details>
  <summary>Details</summary>
Motivation: 现有机器遗忘方法需要明确的目标句子，不支持更广泛的概念（如人物、事件）遗忘。为了解决这一局限性，需要开发能够移除更广泛概念的遗忘方法。

Method: 利用知识图谱表示LLM内部知识，通过提示LLM生成关于遗忘目标的知识三元组和解释性句子，并将遗忘过程应用于这些表示，使遗忘过程与LLM内部知识表示对齐。

Result: 在真实世界和合成数据集上的实验表明，该方法能有效实现概念级遗忘，同时保留不相关的知识。

Conclusion: 提出的概念遗忘方法能够更精确和全面地移除概念，为LLM的隐私和版权问题提供了更有效的解决方案。

Abstract: Machine Unlearning (MU) has recently attracted considerable attention as a
solution to privacy and copyright issues in large language models (LLMs).
Existing MU methods aim to remove specific target sentences from an LLM while
minimizing damage to unrelated knowledge. However, these approaches require
explicit target sentences and do not support removing broader concepts, such as
persons or events. To address this limitation, we introduce Concept Unlearning
(CU) as a new requirement for LLM unlearning. We leverage knowledge graphs to
represent the LLM's internal knowledge and define CU as removing the forgetting
target nodes and associated edges. This graph-based formulation enables a more
intuitive unlearning and facilitates the design of more effective methods. We
propose a novel method that prompts the LLM to generate knowledge triplets and
explanatory sentences about the forgetting target and applies the unlearning
process to these representations. Our approach enables more precise and
comprehensive concept removal by aligning the unlearning process with the LLM's
internal knowledge representations. Experiments on real-world and synthetic
datasets demonstrate that our method effectively achieves concept-level
unlearning while preserving unrelated knowledge.

</details>


### [29] [Sparse-Autoencoder-Guided Internal Representation Unlearning for Large Language Models](https://arxiv.org/abs/2509.15631)
*Tomoya Yamashita,Akira Ito,Yuuki Yamanaka,Masanori Yamada,Takayuki Miura,Toshiki Shibahara*

Main category: cs.CL

TL;DR: 提出了一种新的LLM遗忘方法，通过直接干预模型内部激活，将目标实体的激活状态从"已知"调整为"未知"，实现真正的遗忘而非简单的输出抑制。


<details>
  <summary>Details</summary>
Motivation: 现有基于抑制的遗忘方法只能减少不良输出的概率，但无法消除模型内部嵌入的知识，且容易导致模型崩溃。需要一种能真正实现知识遗忘的方法。

Method: 在稀疏自编码器潜在空间中引入遗忘目标函数，将目标实体的激活从已知实体移向未知实体，使模型将目标实体识别为"未知"而非"已知"。

Result: 实验表明该方法能有效对齐被遗忘目标的内部激活，在问答任务中显著降低目标知识的回忆，同时对非目标知识影响较小。

Conclusion: 该方法通过内部激活干预实现了真正的知识遗忘，避免了过度抑制和模型崩溃问题，为LLM隐私保护提供了更有效的手段。

Abstract: As large language models (LLMs) are increasingly deployed across various
applications, privacy and copyright concerns have heightened the need for more
effective LLM unlearning techniques. Many existing unlearning methods aim to
suppress undesirable outputs through additional training (e.g., gradient
ascent), which reduces the probability of generating such outputs. While such
suppression-based approaches can control model outputs, they may not eliminate
the underlying knowledge embedded in the model's internal activations; muting a
response is not the same as forgetting it. Moreover, such suppression-based
methods often suffer from model collapse. To address these issues, we propose a
novel unlearning method that directly intervenes in the model's internal
activations. In our formulation, forgetting is defined as a state in which the
activation of a forgotten target is indistinguishable from that of ``unknown''
entities. Our method introduces an unlearning objective that modifies the
activation of the target entity away from those of known entities and toward
those of unknown entities in a sparse autoencoder latent space. By aligning the
target's internal activation with those of unknown entities, we shift the
model's recognition of the target entity from ``known'' to ``unknown'',
achieving genuine forgetting while avoiding over-suppression and model
collapse. Empirically, we show that our method effectively aligns the internal
activations of the forgotten target, a result that the suppression-based
approaches do not reliably achieve. Additionally, our method effectively
reduces the model's recall of target knowledge in question-answering tasks
without significant damage to the non-target knowledge.

</details>


### [30] [Multilingual LLM Prompting Strategies for Medical English-Vietnamese Machine Translation](https://arxiv.org/abs/2509.15640)
*Nhu Vo,Nu-Uyen-Phuong Le,Dung D. Le,Massimo Piccardi,Wray Buntine*

Main category: cs.CL

TL;DR: 本文系统评估了多语言大语言模型在医学英语-越南语机器翻译中的表现，发现模型规模是主要性能驱动因素，而术语感知提示和嵌入检索能有效提升领域特定翻译质量。


<details>
  <summary>Details</summary>
Motivation: 越南语作为低资源语言在医学机器翻译中研究不足，但医学英语-越南语翻译对越南的医疗保健访问和沟通至关重要。

Method: 在MedEV数据集上评估6个多语言LLM（0.5B-9B参数），比较零样本、少样本和基于Meddict词典增强的提示策略，包括术语感知提示和嵌入检索方法。

Result: 模型规模是主要性能驱动因素：更大的LLM在零样本设置下表现强劲，少样本提示仅带来边际改进；术语感知提示和嵌入检索能持续改进领域特定翻译质量。

Conclusion: 多语言LLM在医学英语-越南语翻译中展现出潜力但仍有局限，需要更多针对低资源语言的优化方法。

Abstract: Medical English-Vietnamese machine translation (En-Vi MT) is essential for
healthcare access and communication in Vietnam, yet Vietnamese remains a
low-resource and under-studied language. We systematically evaluate prompting
strategies for six multilingual LLMs (0.5B-9B parameters) on the MedEV dataset,
comparing zero-shot, few-shot, and dictionary-augmented prompting with Meddict,
an English-Vietnamese medical lexicon. Results show that model scale is the
primary driver of performance: larger LLMs achieve strong zero-shot results,
while few-shot prompting yields only marginal improvements. In contrast,
terminology-aware cues and embedding-based example retrieval consistently
improve domain-specific translation. These findings underscore both the promise
and the current limitations of multilingual LLMs for medical En-Vi MT.

</details>


### [31] [Layer-wise Minimal Pair Probing Reveals Contextual Grammatical-Conceptual Hierarchy in Speech Representations](https://arxiv.org/abs/2509.15655)
*Linyang He,Qiaolin Wang,Xilin Jiang,Nima Mesgarani*

Main category: cs.CL

TL;DR: 本文首次系统评估了不同语音语言模型（SLMs）中上下文句法和语义特征的编码能力，发现所有语音模型对语法特征的编码都比概念特征更稳健。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注语音语言模型对浅层声学和语音特征的编码能力，但对于这些模型是否编码了细微的句法和概念特征仍不清楚。

Method: 通过最小对设计和诊断特征分析，在71个涵盖不同语言层次的任务上进行了层间和时间分辨分析，比较了自监督学习、自动语音识别、语音压缩和听觉大语言模型编码器等多种SLMs。

Result: 研究发现所有语音模型对语法特征的编码都比概念特征更稳健。

Conclusion: 该研究为理解语音语言模型的内部表征提供了新的视角，揭示了不同模型在句法和语义特征编码方面的差异。

Abstract: Transformer-based speech language models (SLMs) have significantly improved
neural speech recognition and understanding. While existing research has
examined how well SLMs encode shallow acoustic and phonetic features, the
extent to which SLMs encode nuanced syntactic and conceptual features remains
unclear. By drawing parallels with linguistic competence assessments for large
language models, this study is the first to systematically evaluate the
presence of contextual syntactic and semantic features across SLMs for
self-supervised learning (S3M), automatic speech recognition (ASR), speech
compression (codec), and as the encoder for auditory large language models
(AudioLLMs). Through minimal pair designs and diagnostic feature analysis
across 71 tasks spanning diverse linguistic levels, our layer-wise and
time-resolved analysis uncovers that 1) all speech encode grammatical features
more robustly than conceptual ones.

</details>


### [32] [VOX-KRIKRI: Unifying Speech and Language through Continuous Fusion](https://arxiv.org/abs/2509.15667)
*Dimitrios Damianos,Leon Voukoutis,Georgios Paraskevopoulos,Vassilis Katsouros*

Main category: cs.CL

TL;DR: 提出了一个多模态融合框架，将预训练的基于解码器的大型语言模型与Whisper等声学编码器-解码器架构相结合，构建支持语音的LLM。通过中间音频条件文本空间进行对齐，在连续文本表示空间中融合Whisper隐藏解码器状态与LLM状态，支持离线和流式模式。


<details>
  <summary>Details</summary>
Motivation: 构建支持语音的LLM，探索更有效的跨模态对齐机制，为多语言和低资源语音LLM提供解决方案。

Method: 使用中间音频条件文本空间作为对齐机制，在连续文本表示空间中通过跨模态注意力融合Whisper的隐藏解码器状态与LLM状态，支持离线和流式处理模式。

Result: 开发了首个希腊语语音LLM VoxKrikri，实现了跨模态表示的有效对齐，在希腊语自动语音识别任务上取得了约20%的相对改进，达到最先进水平。

Conclusion: 连续空间融合是多语言和低资源语音LLM的有前景路径，该方法在希腊语ASR任务上表现出色，为语音LLM的发展提供了有效方案。

Abstract: We present a multimodal fusion framework that bridges pre-trained
decoder-based large language models (LLM) and acoustic encoder-decoder
architectures such as Whisper, with the aim of building speech-enabled LLMs.
Instead of directly using audio embeddings, we explore an intermediate
audio-conditioned text space as a more effective mechanism for alignment. Our
method operates fully in continuous text representation spaces, fusing
Whisper's hidden decoder states with those of an LLM through cross-modal
attention, and supports both offline and streaming modes. We introduce
\textit{VoxKrikri}, the first Greek speech LLM, and show through analysis that
our approach effectively aligns representations across modalities. These
results highlight continuous space fusion as a promising path for multilingual
and low-resource speech LLMs, while achieving state-of-the-art results for
Automatic Speech Recognition in Greek, providing an average $\sim20\%$ relative
improvement across benchmarks.

</details>


### [33] [Fine-Tuning Large Multimodal Models for Automatic Pronunciation Assessment](https://arxiv.org/abs/2509.15701)
*Ke Wang,Wenning Wei,Yan Deng,Lei He,Sheng Zhao*

Main category: cs.CL

TL;DR: 该研究探索了使用大模态模型进行自动发音评估，通过微调在Speechocean762数据集和私有语料库上取得了显著优于零样本设置的性能，在单词和句子级别表现良好，但音素级别评估仍具挑战性。


<details>
  <summary>Details</summary>
Motivation: 自动发音评估在计算机辅助语言学习中至关重要，需要从多个粒度和方面进行评估。大模态模型为APA提供了新机遇，但其在细粒度评估中的有效性尚不确定。

Method: 使用Speechocean762数据集和私有语料库对大模态模型进行微调，并与零样本设置、公共和商业系统进行比较。

Result: 微调显著优于零样本设置，在单粒度任务上达到与公共和商业系统竞争的结果。模型在单词和句子级别表现良好，但音素级别评估仍有挑战。皮尔逊相关系数达到0.9，而斯皮尔曼等级相关系数约为0.6，表明SCC更好地反映了顺序一致性。

Conclusion: 研究结果凸显了大模态模型在APA中的潜力和局限性，指出了未来在细粒度建模和秩感知评估方面的工作方向。

Abstract: Automatic Pronunciation Assessment (APA) is critical for Computer-Assisted
Language Learning (CALL), requiring evaluation across multiple granularities
and aspects. Large Multimodal Models (LMMs) present new opportunities for APA,
but their effectiveness in fine-grained assessment remains uncertain. This work
investigates fine-tuning LMMs for APA using the Speechocean762 dataset and a
private corpus. Fine-tuning significantly outperforms zero-shot settings and
achieves competitive results on single-granularity tasks compared to public and
commercial systems. The model performs well at word and sentence levels, while
phoneme-level assessment remains challenging. We also observe that the Pearson
Correlation Coefficient (PCC) reaches 0.9, whereas Spearman's rank Correlation
Coefficient (SCC) remains around 0.6, suggesting that SCC better reflects
ordinal consistency. These findings highlight both the promise and limitations
of LMMs for APA and point to future work on fine-grained modeling and
rank-aware evaluation.

</details>


### [34] [Once Upon a Time: Interactive Learning for Storytelling with Small Language Models](https://arxiv.org/abs/2509.15714)
*Jonas Mayer Martins,Ali Hamza Bashir,Muhammad Rehan Khalid,Lisa Beinborn*

Main category: cs.CL

TL;DR: 本文研究了通过引入认知启发式的高层反馈来训练语言模型，发现在仅使用100万单词的交互式学习数据下，模型的故事讲述能力提升效果相当于使用4.1亿单词进行传统下一词预测训练的效果。


<details>
  <summary>Details</summary>
Motivation: 儿童通过社交互动高效学习语言，而大型语言模型通常通过海量文本的下一词预测进行训练。这种对比激发了研究动机：是否可以通过引入高层认知反馈来减少语言模型的训练数据需求。

Method: 训练学生模型生成故事，由教师模型对故事的可读性、叙事连贯性和创造性进行评分。通过改变反馈循环前的预训练数据量，评估交互式学习对语言能力的影响。

Result: 高层反馈具有极高的数据效率：在交互式学习中仅使用100万单词的输入，故事讲述能力的提升效果相当于使用4.1亿单词进行下一词预测训练的效果。

Conclusion: 认知启发式的高层反馈可以显著提高语言模型训练的数据效率，为开发更高效的语言学习算法提供了新思路。

Abstract: Children efficiently acquire language not just by listening, but by
interacting with others in their social environment. Conversely, large language
models are typically trained with next-word prediction on massive amounts of
text. Motivated by this contrast, we investigate whether language models can be
trained with less data by learning not only from next-word prediction but also
from high-level, cognitively inspired feedback. We train a student model to
generate stories, which a teacher model rates on readability, narrative
coherence, and creativity. By varying the amount of pretraining before the
feedback loop, we assess the impact of this interactive learning on formal and
functional linguistic competence. We find that the high-level feedback is
highly data efficient: With just 1 M words of input in interactive learning,
storytelling skills can improve as much as with 410 M words of next-word
prediction.

</details>


### [35] [REFER: Mitigating Bias in Opinion Summarisation via Frequency Framed Prompting](https://arxiv.org/abs/2509.15723)
*Nannan Huang,Haytham M. Fayek,Xiuzhen Zhang*

Main category: cs.CL

TL;DR: 本研究提出了一种名为REFER的频率框架提示方法，旨在通过频率表示而非概率表示来减少大语言模型在意见摘要中的偏见，从而提高公平性。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖超参数调整或提供真实分布信息，但实际应用中用户很少修改默认参数，且准确分布信息通常难以获得。受认知科学研究启发，频率表示可以减少人类统计推理中的系统性偏见。

Method: 采用频率框架提示(REFER)技术，将认知科学中改善人类推理的方法应用于语言模型，通过明确参考类别和减少认知负荷来增强信息处理效果。

Result: 实验结果表明REFER方法能有效提高语言模型在意见摘要中的公平性，特别是在更大的语言模型和使用更强推理指令时效果更显著。

Conclusion: 频率框架提示是一种实用的公平性增强方法，无需修改模型参数或依赖外部分布信息，为改善LLM意见摘要的公平性提供了有效途径。

Abstract: Individuals express diverse opinions, a fair summary should represent these
viewpoints comprehensively. Previous research on fairness in opinion
summarisation using large language models (LLMs) relied on hyperparameter
tuning or providing ground truth distributional information in prompts.
However, these methods face practical limitations: end-users rarely modify
default model parameters, and accurate distributional information is often
unavailable. Building upon cognitive science research demonstrating that
frequency-based representations reduce systematic biases in human statistical
reasoning by making reference classes explicit and reducing cognitive load,
this study investigates whether frequency framed prompting (REFER) can
similarly enhance fairness in LLM opinion summarisation. Through systematic
experimentation with different prompting frameworks, we adapted techniques
known to improve human reasoning to elicit more effective information
processing in language models compared to abstract probabilistic
representations.Our results demonstrate that REFER enhances fairness in
language models when summarising opinions. This effect is particularly
pronounced in larger language models and using stronger reasoning instructions.

</details>


### [36] [Can LLMs Judge Debates? Evaluating Non-Linear Reasoning via Argumentation Theory Semantics](https://arxiv.org/abs/2509.15739)
*Reza Sanayei,Srdjan Vesic,Eduardo Blanco,Mihai Surdeanu*

Main category: cs.CL

TL;DR: 该论文评估大型语言模型在非线性的辩论结构推理能力，使用计算论证理论的QuAD语义来评估模型对辩论中论点的排序能力，发现模型表现中等但受输入长度和话语流影响。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在线性推理任务上表现出色，但在非线性结构（如自然辩论中的论证图）上的能力尚未充分探索。研究者希望评估LLMs是否能近似计算论证理论中的结构化推理。

Method: 使用QuAD语义评估LLMs对辩论中论点的排序能力，基于两个NoDE数据集的对话格式辩论，测试多种LLM在Chain-of-Thought和In-Context Learning等高级指令策略下的表现。

Result: 模型与QuAD排序有中等程度的一致性，但性能随输入长度增加或话语流中断而下降。高级提示策略有助于减轻与论点长度和位置相关的偏见。

Conclusion: 研究结果突显了LLMs在建模形式论证语义方面的潜力和局限性，为未来图感知推理研究提供了动力。

Abstract: Large Language Models (LLMs) excel at linear reasoning tasks but remain
underexplored on non-linear structures such as those found in natural debates,
which are best expressed as argument graphs. We evaluate whether LLMs can
approximate structured reasoning from Computational Argumentation Theory (CAT).
Specifically, we use Quantitative Argumentation Debate (QuAD) semantics, which
assigns acceptability scores to arguments based on their attack and support
relations. Given only dialogue-formatted debates from two NoDE datasets, models
are prompted to rank arguments without access to the underlying graph. We test
several LLMs under advanced instruction strategies, including Chain-of-Thought
and In-Context Learning. While models show moderate alignment with QuAD
rankings, performance degrades with longer inputs or disrupted discourse flow.
Advanced prompting helps mitigate these effects by reducing biases related to
argument length and position. Our findings highlight both the promise and
limitations of LLMs in modeling formal argumentation semantics and motivate
future work on graph-aware reasoning.

</details>


### [37] [UniGist: Towards General and Hardware-aligned Sequence-level Long Context Compression](https://arxiv.org/abs/2509.15763)
*Chenlong Deng,Zhisong Zhang,Kelong Mao,Shuaiyi Li,Tianqing Fang,Hongming Zhang,Haitao Mi,Dong Yu,Zhicheng Dou*

Main category: cs.CL

TL;DR: UniGist是一个序列级长上下文压缩框架，通过用特殊压缩标记替换原始标记来高效保留上下文信息，解决KV缓存内存开销问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型处理长上下文输入时，KV缓存的内存开销成为主要瓶颈，现有序列级压缩方法容易丢失重要上下文信息。

Method: 采用无分块训练策略，设计高效内核和gist移位技巧，支持灵活推理，允许实际移除压缩标记实现实时内存节省。

Result: 在多个长上下文任务上的实验表明，UniGist显著提高了压缩质量，在细节回忆任务和长距离依赖建模方面表现尤其出色。

Conclusion: UniGist框架有效解决了长上下文压缩中的信息保留问题，为大规模语言模型的通用部署提供了实用的内存优化方案。

Abstract: Large language models are increasingly capable of handling long-context
inputs, but the memory overhead of key-value (KV) cache remains a major
bottleneck for general-purpose deployment. While various compression strategies
have been explored, sequence-level compression, which drops the full KV caches
for certain tokens, is particularly challenging as it can lead to the loss of
important contextual information. To address this, we introduce UniGist, a
sequence-level long-context compression framework that efficiently preserves
context information by replacing raw tokens with special compression tokens
(gists) in a fine-grained manner. We adopt a chunk-free training strategy and
design an efficient kernel with a gist shift trick, enabling optimized GPU
training. Our scheme also supports flexible inference by allowing the actual
removal of compressed tokens, resulting in real-time memory savings.
Experiments across multiple long-context tasks demonstrate that UniGist
significantly improves compression quality, with especially strong performance
in detail-recalling tasks and long-range dependency modeling.

</details>


### [38] [UPRPRC: Unified Pipeline for Reproducing Parallel Resources -- Corpus from the United Nations](https://arxiv.org/abs/2509.15789)
*Qiuyang Lu,Fangjian Shen,Zhengkai Tang,Qiang Liu,Hexuan Cheng,Hui Liu,Wushao Wen*

Main category: cs.CL

TL;DR: 本文介绍了一个用于构建大规模多语言平行语料库的端到端解决方案，通过网页抓取和新的图辅助段落对齐算法，创建了包含超过7.13亿英文词符的公开语料库，是目前最大的完全由人工翻译内容组成的平行语料库。


<details>
  <summary>Details</summary>
Motivation: 解决之前基于联合国文档构建的语料库存在的流程不透明、难以复现和规模有限等问题，为机器翻译研究提供高质量、可访问的多语言数据集。

Method: 提出了完整的端到端解决方案，包括网页抓取数据获取和文本对齐。核心是新的图辅助段落对齐（GAPA）算法，支持高效灵活的段落级对齐。整个过程完全可复现，提供单机示例和可选的分布式计算步骤。

Result: 构建的语料库包含超过7.13亿英文词符，规模是之前工作的两倍以上，是目前最大的完全由人工翻译、非AI生成内容的公开平行语料库。

Conclusion: 该研究提供了一个高质量、大规模、完全可复现的多语言平行语料库构建方案，代码和语料库在MIT许可下公开可用，将有力促进机器翻译领域的发展。

Abstract: The quality and accessibility of multilingual datasets are crucial for
advancing machine translation. However, previous corpora built from United
Nations documents have suffered from issues such as opaque process, difficulty
of reproduction, and limited scale. To address these challenges, we introduce a
complete end-to-end solution, from data acquisition via web scraping to text
alignment. The entire process is fully reproducible, with a minimalist
single-machine example and optional distributed computing steps for
scalability. At its core, we propose a new Graph-Aided Paragraph Alignment
(GAPA) algorithm for efficient and flexible paragraph-level alignment. The
resulting corpus contains over 713 million English tokens, more than doubling
the scale of prior work. To the best of our knowledge, this represents the
largest publicly available parallel corpus composed entirely of
human-translated, non-AI-generated content. Our code and corpus are accessible
under the MIT License.

</details>


### [39] [RAVE: Retrieval and Scoring Aware Verifiable Claim Detection](https://arxiv.org/abs/2509.15793)
*Yufeng Li,Arkaitz Zubiaga*

Main category: cs.CL

TL;DR: RAVE框架结合证据检索与相关性及来源可信度的结构化信号，用于可验证声明检测，在CT22-test和PoliClaim-test数据集上优于仅基于文本和检索的基线方法。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上错误信息的快速传播需要可扩展的事实核查工具，而现有方法在处理模糊政治言论和多样化格式（如推文）时存在困难。

Method: 提出RAVE（检索和评分感知的可验证声明检测）框架，结合证据检索与结构化信号（相关性和来源可信度）进行声明检测。

Result: 在CT22-test和PoliClaim-test数据集上的实验表明，RAVE在准确率和F1分数上均优于仅基于文本和检索的基线方法。

Conclusion: RAVE框架通过结合证据检索和结构化信号，有效提升了可验证声明检测的性能，为社交媒体事实核查提供了更可靠的工具。

Abstract: The rapid spread of misinformation on social media underscores the need for
scalable fact-checking tools. A key step is claim detection, which identifies
statements that can be objectively verified. Prior approaches often rely on
linguistic cues or claim check-worthiness, but these struggle with vague
political discourse and diverse formats such as tweets. We present RAVE
(Retrieval and Scoring Aware Verifiable Claim Detection), a framework that
combines evidence retrieval with structured signals of relevance and source
credibility. Experiments on CT22-test and PoliClaim-test show that RAVE
consistently outperforms text-only and retrieval-based baselines in both
accuracy and F1.

</details>


### [40] [Best-of-L: Cross-Lingual Reward Modeling for Mathematical Reasoning](https://arxiv.org/abs/2509.15811)
*Sara Rajaee,Rochelle Choenni,Ekaterina Shutova,Christof Monz*

Main category: cs.CL

TL;DR: 该论文研究了多语言大语言模型中推理能力在不同语言间的差异，发现通过跨语言奖励模型可以显著提升数学推理性能，特别是对英语在低采样预算下受益明显。


<details>
  <summary>Details</summary>
Motivation: 探究多语言LLMs中推理能力在不同语言间的差异，以及不同语言是否产生互补的推理路径。

Method: 训练一个奖励模型来对给定问题在不同语言中生成的回答进行排序。

Result: 跨语言奖励模型相比单语言奖励建模显著提升了数学推理性能，即使对高资源语言也有益；英语在多语言模型中通常表现最佳，但跨语言采样在低采样预算下特别有利于英语。

Conclusion: 研究揭示了通过利用不同语言的互补优势来改进多语言推理的新机会。

Abstract: While the reasoning abilities of large language models (LLMs) continue to
advance, it remains unclear how such ability varies across languages in
multilingual LLMs and whether different languages produce reasoning paths that
complement each other. To investigate this question, we train a reward model to
rank generated responses for a given question across languages. Our results
show that our cross-lingual reward model substantially improves mathematical
reasoning performance compared to using reward modeling within a single
language, benefiting even high-resource languages. While English often exhibits
the highest performance in multilingual models, we find that cross-lingual
sampling particularly benefits English under low sampling budgets. Our findings
reveal new opportunities to improve multilingual reasoning by leveraging the
complementary strengths of diverse languages.

</details>


### [41] [The Curious Case of Visual Grounding: Different Effects for Speech- and Text-based Language Encoders](https://arxiv.org/abs/2509.15837)
*Adrian Sauter,Willem Zuidema,Marianne de Heer Kloots*

Main category: cs.CL

TL;DR: 视觉信息对音频和文本深度学习模型语言处理的影响研究，发现视觉基础能增强口语和书面语表示的对齐，但主要改善的是词汇身份编码而非语义编码。


<details>
  <summary>Details</summary>
Motivation: 探索视觉信息在训练中如何影响基于音频和文本的深度学习模型的语言处理能力，特别是视觉基础对模型内部词汇表示的影响。

Method: 通过全局表示比较和针对性聚类分析，研究语音和文本编码器中视觉基础对语音特征与语义可区分性的影响。

Result: 视觉基础增强了口语和书面语表示的对齐，但主要改善词汇身份编码；语音表示仍以语音特征为主，视觉基础未能改善语义可区分性。

Conclusion: 研究结果可为开发更有效的方法来丰富语音模型的视觉语义信息提供指导，特别是在区分词汇身份和语义编码方面。

Abstract: How does visual information included in training affect language processing
in audio- and text-based deep learning models? We explore how such visual
grounding affects model-internal representations of words, and find
substantially different effects in speech- vs. text-based language encoders.
Firstly, global representational comparisons reveal that visual grounding
increases alignment between representations of spoken and written language, but
this effect seems mainly driven by enhanced encoding of word identity rather
than meaning. We then apply targeted clustering analyses to probe for phonetic
vs. semantic discriminability in model representations. Speech-based
representations remain phonetically dominated with visual grounding, but in
contrast to text-based representations, visual grounding does not improve
semantic discriminability. Our findings could usefully inform the development
of more efficient methods to enrich speech-based models with visually-informed
semantics.

</details>


### [42] [Multi-Physics: A Comprehensive Benchmark for Multimodal LLMs Reasoning on Chinese Multi-Subject Physics Problems](https://arxiv.org/abs/2509.15839)
*Zhongze Luo,Zhenshuai Yin,Yongxin Guo,Zhichao Wang,Jionghao Zhu,Xiaoying Tang*

Main category: cs.CL

TL;DR: 提出了Multi-Physics中文物理推理基准，包含5个难度级别、1,412道图像关联选择题，涵盖11个高中物理学科，用于评估多模态大语言模型在科学领域的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有评估基准在专业科学领域（如物理）存在不足：缺乏细粒度学科覆盖、忽视逐步推理过程、以英语为中心、未能系统评估视觉信息的作用。

Method: 采用双评估框架评估20个不同MLLM，分析最终答案准确性和逐步推理链的完整性；通过改变输入模式比较模型性能，系统研究难度级别和视觉信息的影响。

Result: 提供了细粒度资源和方法论，用于剖析最先进MLLM的多模态推理过程。

Conclusion: 该工作不仅为社区提供了细粒度资源，还提供了强大的方法论来剖析最先进MLLM的多模态推理过程，数据集和代码已开源。

Abstract: While multimodal LLMs (MLLMs) demonstrate remarkable reasoning progress,
their application in specialized scientific domains like physics reveals
significant gaps in current evaluation benchmarks. Specifically, existing
benchmarks often lack fine-grained subject coverage, neglect the step-by-step
reasoning process, and are predominantly English-centric, failing to
systematically evaluate the role of visual information. Therefore, we introduce
\textbf {Multi-Physics} for Chinese physics reasoning, a comprehensive
benchmark that includes 5 difficulty levels, featuring 1,412 image-associated,
multiple-choice questions spanning 11 high-school physics subjects. We employ a
dual evaluation framework to evaluate 20 different MLLMs, analyzing both final
answer accuracy and the step-by-step integrity of their chain-of-thought.
Furthermore, we systematically study the impact of difficulty level and visual
information by comparing the model performance before and after changing the
input mode. Our work provides not only a fine-grained resource for the
community but also offers a robust methodology for dissecting the multimodal
reasoning process of state-of-the-art MLLMs, and our dataset and code have been
open-sourced: https://github.com/luozhongze/Multi-Physics.

</details>


### [43] [Distribution-Aligned Decoding for Efficient LLM Task Adaptation](https://arxiv.org/abs/2509.15888)
*Senkang Hu,Xudong Han,Jinqi Jiang,Yihang Tao,Zihan Fang,Sam Tak Wu Kwong,Yuguang Fang*

Main category: cs.CL

TL;DR: 提出Steering Vector Decoding (SVD)方法，通过输出分布对齐而非权重更新来适配下游任务，在解码过程中使用从KL散度梯度提取的转向向量引导模型输出分布。


<details>
  <summary>Details</summary>
Motivation: 适应十亿参数语言模型到下游任务成本高昂，即使使用参数高效微调(PEFT)方法。作者将任务适配重新定义为输出分布对齐问题。

Method: 1. 进行短时预热微调；2. 从预热模型和预训练模型的KL散度梯度中提取任务感知转向向量；3. 在解码过程中使用转向向量引导输出分布；4. 理论证明SVD与全微调的梯度步骤一阶等价。

Result: 在三个任务和九个基准测试中，SVD与四种标准PEFT方法结合，多项选择准确率提升高达5分，开放生成真实性提升2分，常识数据集也有1-2分提升，且不增加可训练参数。

Conclusion: SVD为大型语言模型提供了轻量级、理论基础的强大任务适配路径，通过解码时分布对齐而非权重更新实现高效适配。

Abstract: Adapting billion-parameter language models to a downstream task is still
costly, even with parameter-efficient fine-tuning (PEFT). We re-cast task
adaptation as output-distribution alignment: the objective is to steer the
output distribution toward the task distribution directly during decoding
rather than indirectly through weight updates. Building on this view, we
introduce Steering Vector Decoding (SVD), a lightweight, PEFT-compatible, and
theoretically grounded method. We start with a short warm-start fine-tune and
extract a task-aware steering vector from the Kullback-Leibler (KL) divergence
gradient between the output distribution of the warm-started and pre-trained
models. This steering vector is then used to guide the decoding process to
steer the model's output distribution towards the task distribution. We
theoretically prove that SVD is first-order equivalent to the gradient step of
full fine-tuning and derive a globally optimal solution for the strength of the
steering vector. Across three tasks and nine benchmarks, SVD paired with four
standard PEFT methods improves multiple-choice accuracy by up to 5 points and
open-ended truthfulness by 2 points, with similar gains (1-2 points) on
commonsense datasets without adding trainable parameters beyond the PEFT
adapter. SVD thus offers a lightweight, theoretically grounded path to stronger
task adaptation for large language models.

</details>


### [44] [The Psychology of Falsehood: A Human-Centric Survey of Misinformation Detection](https://arxiv.org/abs/2509.15896)
*Arghodeep Nandi,Megha Sundriyal,Euna Mehnaz Khan,Jikai Sun,Emily Vraga,Jaideep Srivastava,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: 这篇论文综述了传统事实核查方法的局限性，提出需要超越事实准确性评估，采用更以人为本的检测框架，结合心理学概念如认知偏见、社会动态和情绪反应来改进虚假信息检测系统。


<details>
  <summary>Details</summary>
Motivation: 当前自动化事实核查系统主要局限于评估事实准确性，但虚假信息的危害性超越了简单的虚假陈述，它利用了人们对信息的感知、解释和情绪反应方式，因此需要更人性化的检测方法。

Method: 通过分析最先进的虚假信息检测系统，从人类心理学和行为的角度审视传统事实核查方法与心理学概念（如认知偏见、社会动态和情绪反应）之间的相互作用。

Result: 揭示了当前方法的严重局限性，并确定了改进机会，提出了整合技术因素与人类认知和社会影响复杂性的神经行为模型等未来研究方向。

Conclusion: 基于心理学的方法为更有效地检测和减轻虚假信息的社会危害提供了有前景的途径，需要创建更强大和自适应的检测框架。

Abstract: Misinformation remains one of the most significant issues in the digital age.
While automated fact-checking has emerged as a viable solution, most current
systems are limited to evaluating factual accuracy. However, the detrimental
effect of misinformation transcends simple falsehoods; it takes advantage of
how individuals perceive, interpret, and emotionally react to information. This
underscores the need to move beyond factuality and adopt more human-centered
detection frameworks. In this survey, we explore the evolving interplay between
traditional fact-checking approaches and psychological concepts such as
cognitive biases, social dynamics, and emotional responses. By analyzing
state-of-the-art misinformation detection systems through the lens of human
psychology and behavior, we reveal critical limitations of current methods and
identify opportunities for improvement. Additionally, we outline future
research directions aimed at creating more robust and adaptive frameworks, such
as neuro-behavioural models that integrate technological factors with the
complexities of human cognition and social influence. These approaches offer
promising pathways to more effectively detect and mitigate the societal harms
of misinformation.

</details>


### [45] [Re-FRAME the Meeting Summarization SCOPE: Fact-Based Summarization and Personalization via Questions](https://arxiv.org/abs/2509.15901)
*Frederic Kirstein,Sonu Kumar,Terry Ruas,Bela Gipp*

Main category: cs.CL

TL;DR: FRAME是一个模块化管道，将摘要重构为语义丰富任务，通过提取和评分关键事实、主题组织来生成抽象摘要。SCOPE协议通过回答九个问题构建推理轨迹以实现个性化。P-MESA评估框架能可靠识别错误实例。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在会议摘要中容易产生幻觉、遗漏和不相关内容，需要改进控制、忠实性和个性化。

Method: FRAME管道提取和评分关键事实，主题组织后丰富大纲为摘要。SCOPE协议通过回答九个问题构建推理轨迹。P-MESA作为参考无关的多维评估框架。

Result: 在QMSum和FAME数据集上，FRAME将幻觉和遗漏减少2/5点，SCOPE在知识适应性和目标对齐上优于仅提示基线。P-MESA与人类注释达到≥89%平衡准确率。

Conclusion: 研究主张重新思考摘要方法以改进控制、忠实性和个性化。

Abstract: Meeting summarization with large language models (LLMs) remains error-prone,
often producing outputs with hallucinations, omissions, and irrelevancies. We
present FRAME, a modular pipeline that reframes summarization as a semantic
enrichment task. FRAME extracts and scores salient facts, organizes them
thematically, and uses these to enrich an outline into an abstractive summary.
To personalize summaries, we introduce SCOPE, a reason-out-loud protocol that
has the model build a reasoning trace by answering nine questions before
content selection. For evaluation, we propose P-MESA, a multi-dimensional,
reference-free evaluation framework to assess if a summary fits a target
reader. P-MESA reliably identifies error instances, achieving >= 89% balanced
accuracy against human annotations and strongly aligns with human severity
ratings (r >= 0.70). On QMSum and FAME, FRAME reduces hallucination and
omission by 2 out of 5 points (measured with MESA), while SCOPE improves
knowledge fit and goal alignment over prompt-only baselines. Our findings
advocate for rethinking summarization to improve control, faithfulness, and
personalization.

</details>


### [46] [Beyond the Score: Uncertainty-Calibrated LLMs for Automated Essay Assessment](https://arxiv.org/abs/2509.15926)
*Ahmed Karim,Qiao Wang,Zheng Yuan*

Main category: cs.CL

TL;DR: 本文提出使用保形预测方法为自动作文评分系统提供置信度保证，通过微调开源大语言模型并在三个数据集上验证，实现了90%风险水平的可靠评分。


<details>
  <summary>Details</summary>
Motivation: 当前自动作文评分系统在公开基准上已达到接近人类评分的一致性，但在高风险考试中的实际应用仍然有限，主要障碍是大多数模型只输出单一分数而没有置信度或解释。

Method: 使用保形预测作为分布无关的包装器，为任何分类器提供集合值输出和正式覆盖保证。微调两个开源大语言模型（Llama-3 8B和Qwen-2.5 3B）并在三个不同语料库（ASAP、TOEFL11、Cambridge-FCE）上进行校准，风险水平设为90%。

Result: 校准后的模型始终满足覆盖目标，同时保持预测集紧凑，表明开源的中等规模大语言模型已经可以支持教师参与的自动作文评分系统。

Conclusion: 这是首个将保形预测和不确定性感知准确率结合用于作文评分的工作，讨论了扩展和更广泛的用户研究作为未来工作方向。

Abstract: Automated Essay Scoring (AES) systems now reach near human agreement on some
public benchmarks, yet real-world adoption, especially in high-stakes
examinations, remains limited. A principal obstacle is that most models output
a single score without any accompanying measure of confidence or explanation.
We address this gap with conformal prediction, a distribution-free wrapper that
equips any classifier with set-valued outputs and formal coverage guarantees.
Two open-source large language models (Llama-3 8B and Qwen-2.5 3B) are
fine-tuned on three diverse corpora (ASAP, TOEFL11, Cambridge-FCE) and
calibrated at a 90 percent risk level. Reliability is assessed with UAcc, an
uncertainty-aware accuracy that rewards models for being both correct and
concise. To our knowledge, this is the first work to combine conformal
prediction and UAcc for essay scoring. The calibrated models consistently meet
the coverage target while keeping prediction sets compact, indicating that
open-source, mid-sized LLMs can already support teacher-in-the-loop AES; we
discuss scaling and broader user studies as future work.

</details>


### [47] [Localmax dynamics for attention in transformers and its asymptotic behavior](https://arxiv.org/abs/2509.15958)
*Henri Cimetière,Maria Teresa Chiri,Bahman Gharesifard*

Main category: cs.CL

TL;DR: 本文提出了一种新的离散时间注意力模型——localmax dynamics，它在softmax和hardmax动态之间进行插值，通过alignment-sensitivity参数控制邻居交互的松弛程度。


<details>
  <summary>Details</summary>
Motivation: 动机是开发一个介于softmax和hardmax之间的注意力机制，通过引入对齐敏感度参数来提供更灵活的控制，同时保持hardmax的部分特性。

Method: 方法包括定义localmax动态模型，引入quiescent sets来描述token在顶点附近的稳定行为，使用Lyapunov方法分析系统行为，并研究时间变化参数下的渐进行为。

Result: 结果表明localmax动态不会出现有限时间收敛，分析了不同对齐敏感度参数下的渐进行为，并恢复了hardmax的极限行为作为副产品。

Conclusion: 结论是localmax动态提供了更灵活的注意力机制，但Lyapunov方法在非对称设置下存在局限性，为未来研究指明了方向。

Abstract: We introduce a new discrete-time attention model, termed the localmax
dynamics, which interpolates between the classic softmax dynamics and the
hardmax dynamics, where only the tokens that maximize the influence toward a
given token have a positive weight. As in hardmax, uniform weights are
determined by a parameter controlling neighbor influence, but the key extension
lies in relaxing neighborhood interactions through an alignment-sensitivity
parameter, which allows controlled deviations from pure hardmax behavior. As we
prove, while the convex hull of the token states still converges to a convex
polytope, its structure can no longer be fully described by a maximal alignment
set, prompting the introduction of quiescent sets to capture the invariant
behavior of tokens near vertices. We show that these sets play a key role in
understanding the asymptotic behavior of the system, even under time-varying
alignment sensitivity parameters. We further show that localmax dynamics does
not exhibit finite-time convergence and provide results for vanishing, nonzero,
time-varying alignment-sensitivity parameters, recovering the limiting behavior
of hardmax as a by-product. Finally, we adapt Lyapunov-based methods from
classical opinion dynamics, highlighting their limitations in the asymmetric
setting of localmax interactions and outlining directions for future research.

</details>


### [48] [BEFT: Bias-Efficient Fine-Tuning of Language Models](https://arxiv.org/abs/2509.15974)
*Baichuan Huang,Ananth Balashankar,Amir Aminifar*

Main category: cs.CL

TL;DR: 本文提出了一种偏置高效微调方法，通过选择特定的偏置项进行微调，在保持参数效率的同时提升下游任务性能


<details>
  <summary>Details</summary>
Motivation: 现有偏置微调方法缺乏明确的偏置项选择指导，不同偏置项对下游性能的影响尚不明确

Method: 提出基于偏置项选择的偏置高效微调方法，通过系统方法选择query、key或value投影中的特定偏置项进行微调

Result: 在110M到6.7B参数规模的编码器和解码器模型上验证，在分类、多选和生成任务上表现优异

Conclusion: 该方法为偏置微调提供了有效的偏置项选择策略，在参数效率和性能之间取得了良好平衡

Abstract: Fine-tuning all-bias-terms stands out among various parameter-efficient
fine-tuning (PEFT) techniques, owing to its out-of-the-box usability and
competitive performance, especially in low-data regimes. Bias-only fine-tuning
has the potential for unprecedented parameter efficiency. However, the link
between fine-tuning different bias terms (i.e., bias terms in the query, key,
or value projections) and downstream performance remains unclear. The existing
approaches, e.g., based on the magnitude of bias change or empirical Fisher
information, provide limited guidance for selecting the particular bias term
for effective fine-tuning. In this paper, we propose an approach for selecting
the bias term to be fine-tuned, forming the foundation of our bias-efficient
fine-tuning (BEFT). We extensively evaluate our bias-efficient approach against
other bias-selection approaches, across a wide range of large language models
(LLMs) spanning encoder-only and decoder-only architectures from 110M to 6.7B
parameters. Our results demonstrate the effectiveness and superiority of our
bias-efficient approach on diverse downstream tasks, including classification,
multiple-choice, and generation tasks.

</details>


### [49] [Session-Level Spoken Language Assessment with a Multimodal Foundation Model via Multi-Target Learning](https://arxiv.org/abs/2509.16025)
*Hong-Yun Lin,Jhen-Ke Lin,Chung-Chun Wang,Hao-Chien Lu,Berlin Chen*

Main category: cs.CL

TL;DR: 本文提出了一种新颖的多模态基础模型方法，用于会话级别的口语语言评估，通过多目标学习和冻结的Whisper ASR模型进行声学感知校准，实现了端到端的口语能力评估。


<details>
  <summary>Details</summary>
Motivation: 随着L2英语学习者数量的增长，对可靠口语评估的需求日益增加。现有方法存在级联管道错误传播或短音频窗口无法捕捉语篇级证据的问题。

Method: 采用多模态基础模型，结合多目标学习和基于冻结Whisper ASR模型的声学先验进行校准，无需手工特征即可联合学习整体和特质级的口语评估目标。

Result: 在Speak & Improve基准测试中，该方法优于先前最先进的级联系统，并展现出强大的跨部分泛化能力。

Conclusion: 该方法为计算机辅助语言学习应用提供了一个紧凑可部署的评分器，能够连贯处理整个回答会话，在预测整体口语能力方面表现出色。

Abstract: Spoken Language Assessment (SLA) estimates a learner's oral proficiency from
spontaneous speech. The growing population of L2 English speakers has
intensified the demand for reliable SLA, a critical component of Computer
Assisted Language Learning (CALL). Existing efforts often rely on cascaded
pipelines, which are prone to error propagation, or end-to-end models that
often operate on a short audio window, which might miss discourse-level
evidence. This paper introduces a novel multimodal foundation model approach
that performs session-level evaluation in a single pass. Our approach couples
multi-target learning with a frozen, Whisper ASR model-based speech prior for
acoustic-aware calibration, allowing for jointly learning holistic and
trait-level objectives of SLA without resorting to handcrafted features. By
coherently processing the entire response session of an L2 speaker, the model
excels at predicting holistic oral proficiency. Experiments conducted on the
Speak & Improve benchmark demonstrate that our proposed approach outperforms
the previous state-of-the-art cascaded system and exhibits robust cross-part
generalization, producing a compact deployable grader that is tailored for CALL
applications.

</details>


### [50] [Think, Verbalize, then Speak: Bridging Complex Thoughts and Comprehensible Speech](https://arxiv.org/abs/2509.16028)
*Sang Hoon Woo,Sehun Lee,Kang-wook Kim,Gunhee Kim*

Main category: cs.CL

TL;DR: 提出了Think-Verbalize-Speak框架，将推理与语音输出解耦，通过中间verbalizing步骤将思维转换为自然、适合语音的文本，以保留LLMs的完整推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在将LLMs应用于语音对话系统时，由于文本和语音传递方式的不匹配，往往导致次优结果，且对推理性能的影响研究不足。

Method: 提出TVS框架，包含推理、verbalizing和语音输出三个步骤，并引入ReVerT——一种基于增量异步摘要的低延迟verbalizer。

Result: 在多个基准测试中，该方法显著提升了语音的自然性和简洁性，同时对推理性能影响极小。

Conclusion: TVS框架有效解决了LLMs在语音对话系统中的适配问题，在保持推理能力的同时优化了语音输出质量。

Abstract: Spoken dialogue systems increasingly employ large language models (LLMs) to
leverage their advanced reasoning capabilities. However, direct application of
LLMs in spoken communication often yield suboptimal results due to mismatches
between optimal textual and verbal delivery. While existing approaches adapt
LLMs to produce speech-friendly outputs, their impact on reasoning performance
remains underexplored. In this work, we propose Think-Verbalize-Speak, a
framework that decouples reasoning from spoken delivery to preserve the full
reasoning capacity of LLMs. Central to our method is verbalizing, an
intermediate step that translates thoughts into natural, speech-ready text. We
also introduce ReVerT, a latency-efficient verbalizer based on incremental and
asynchronous summarization. Experiments across multiple benchmarks show that
our method enhances speech naturalness and conciseness with minimal impact on
reasoning. The project page with the dataset and the source code is available
at https://yhytoto12.github.io/TVS-ReVerT

</details>


### [51] [Beyond Pointwise Scores: Decomposed Criteria-Based Evaluation of LLM Responses](https://arxiv.org/abs/2509.16093)
*Fangyi Yu,Nabeel Seedat,Dasha Herrmannova,Frank Schilder,Jonathan Richard Schwarz*

Main category: cs.CL

TL;DR: DeCE是一个分解式LLM评估框架，将精度（事实准确性和相关性）和召回率（所需概念覆盖度）分离，使用从黄金答案要求中自动提取的实例特定标准，在专家领域提供可解释和可操作的评估。


<details>
  <summary>Details</summary>
Motivation: 在法学或医学等高风险领域评估长篇答案仍然是一个基本挑战。标准指标如BLEU和ROUGE无法捕捉语义正确性，当前基于LLM的评估器通常将答案质量的细微方面简化为单一未分化的分数。

Method: 引入DeCE框架，分离精度和召回率评估，使用自动从黄金答案要求中提取的实例特定标准，无需预定义分类法或手工制作的评分标准。在真实世界法律QA任务上实例化DeCE，涉及多司法管辖区推理和引用基础。

Result: DeCE与专家判断的相关性显著更强（r=0.78），相比传统指标（r=0.12）、逐点LLM评分（r=0.35）和现代多维评估器（r=0.48）。还揭示了可解释的权衡：通用模型偏向召回率，而专业模型偏向精度。仅11.95%的LLM生成标准需要专家修订。

Conclusion: DeCE在专家领域提供了一个可解释和可操作的LLM评估框架，具有很好的可扩展性。

Abstract: Evaluating long-form answers in high-stakes domains such as law or medicine
remains a fundamental challenge. Standard metrics like BLEU and ROUGE fail to
capture semantic correctness, and current LLM-based evaluators often reduce
nuanced aspects of answer quality into a single undifferentiated score. We
introduce DeCE, a decomposed LLM evaluation framework that separates precision
(factual accuracy and relevance) and recall (coverage of required concepts),
using instance-specific criteria automatically extracted from gold answer
requirements. DeCE is model-agnostic and domain-general, requiring no
predefined taxonomies or handcrafted rubrics. We instantiate DeCE to evaluate
different LLMs on a real-world legal QA task involving multi-jurisdictional
reasoning and citation grounding. DeCE achieves substantially stronger
correlation with expert judgments ($r=0.78$), compared to traditional metrics
($r=0.12$), pointwise LLM scoring ($r=0.35$), and modern multidimensional
evaluators ($r=0.48$). It also reveals interpretable trade-offs: generalist
models favor recall, while specialized models favor precision. Importantly,
only 11.95% of LLM-generated criteria required expert revision, underscoring
DeCE's scalability. DeCE offers an interpretable and actionable LLM evaluation
framework in expert domains.

</details>


### [52] [DiEP: Adaptive Mixture-of-Experts Compression through Differentiable Expert Pruning](https://arxiv.org/abs/2509.16105)
*Sikai Bai,Haoxi Li,Jie Zhang,Zicong Hong,Song Guo*

Main category: cs.CL

TL;DR: DiEP是一种针对MoE模型的自适应非均匀剪枝方法，通过将离散搜索空间转化为连续空间，实现基于梯度的自适应剪枝，在保留92%性能的同时减少一半专家数量。


<details>
  <summary>Details</summary>
Motivation: 现有MoE剪枝方法采用统一的稀疏度会导致性能下降，因为不同MoE层的专家冗余度不同，需要非均匀剪枝策略。

Method: 提出可微分专家剪枝(DiEP)，在层级别自适应调整剪枝率并联合学习层间重要性，将全局离散搜索空间转化为连续空间处理指数增长的非均匀专家组合。

Result: 在5个先进MoE模型上的实验表明，DiEP在Mixtral 8×7B模型上仅用一半专家就保留了约92%的原始性能，在MMLU数据集上比其他剪枝方法高出7.1%。

Conclusion: DiEP方法有效解决了MoE模型剪枝中的非均匀冗余问题，实现了高效的自适应剪枝，显著优于现有方法。

Abstract: Despite the significant breakthrough of Mixture-of-Experts (MoE), the
increasing scale of these MoE models presents huge memory and storage
challenges. Existing MoE pruning methods, which involve reducing parameter size
with a uniform sparsity across all layers, often lead to suboptimal outcomes
and performance degradation due to varying expert redundancy in different MoE
layers. To address this, we propose a non-uniform pruning strategy, dubbed
\textbf{Di}fferentiable \textbf{E}xpert \textbf{P}runing (\textbf{DiEP}), which
adaptively adjusts pruning rates at the layer level while jointly learning
inter-layer importance, effectively capturing the varying redundancy across
different MoE layers. By transforming the global discrete search space into a
continuous one, our method handles exponentially growing non-uniform expert
combinations, enabling adaptive gradient-based pruning. Extensive experiments
on five advanced MoE models demonstrate the efficacy of our method across
various NLP tasks. Notably, \textbf{DiEP} retains around 92\% of original
performance on Mixtral 8$\times$7B with only half the experts, outperforming
other pruning methods by up to 7.1\% on the challenging MMLU dataset.

</details>


### [53] [It Depends: Resolving Referential Ambiguity in Minimal Contexts with Commonsense Knowledge](https://arxiv.org/abs/2509.16107)
*Lukas Ellinger,Georg Groh*

Main category: cs.CL

TL;DR: 本文系统研究了大型语言模型在多轮对话中利用常识解决指代歧义的能力，发现当前LLMs在歧义处理上存在不足，倾向于单一解释或覆盖所有可能，简化提示会进一步削弱其表现，而通过DPO微调可显著改善歧义解决能力。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs是否能够利用常识知识在多轮对话中解决指代歧义问题，特别是在歧义持续存在的情况下，并分析简化语言请求对其能力的影响。

Method: 使用新颖的多语言评估数据集，通过LLM-as-Judge和人工标注测试DeepSeek v3、GPT-4o、Qwen3-32B、GPT-4o-mini和Llama-3.1-8B等模型，并对Llama-3.1-8B进行直接偏好优化(DPO)微调。

Result: 当前LLMs难以有效解决歧义：倾向于单一解释或覆盖所有可能引用，而非采取模糊处理或寻求澄清。简化提示显著减少了常识推理和多样化响应策略的使用。DPO微调显著提高了所有请求类型下的歧义解决能力。

Conclusion: 需要先进的微调技术来改进LLMs处理歧义的能力，确保在不同沟通风格下的鲁棒性能。

Abstract: Ambiguous words or underspecified references require interlocutors to resolve
them, often by relying on shared context and commonsense knowledge. Therefore,
we systematically investigate whether Large Language Models (LLMs) can leverage
commonsense to resolve referential ambiguity in multi-turn conversations and
analyze their behavior when ambiguity persists. Further, we study how requests
for simplified language affect this capacity. Using a novel multilingual
evaluation dataset, we test DeepSeek v3, GPT-4o, Qwen3-32B, GPT-4o-mini, and
Llama-3.1-8B via LLM-as-Judge and human annotations. Our findings indicate that
current LLMs struggle to resolve ambiguity effectively: they tend to commit to
a single interpretation or cover all possible references, rather than hedging
or seeking clarification. This limitation becomes more pronounced under
simplification prompts, which drastically reduce the use of commonsense
reasoning and diverse response strategies. Fine-tuning Llama-3.1-8B with Direct
Preference Optimization substantially improves ambiguity resolution across all
request types. These results underscore the need for advanced fine-tuning to
improve LLMs' handling of ambiguity and to ensure robust performance across
diverse communication styles.

</details>


### [54] [CodeRAG: Finding Relevant and Necessary Knowledge for Retrieval-Augmented Repository-Level Code Completion](https://arxiv.org/abs/2509.16112)
*Sheng Zhang,Yifan Ding,Shuquan Lian,Shun Song,Hui Li*

Main category: cs.CL

TL;DR: CodeRAG是一个用于仓库级代码补全的检索增强框架，通过改进查询构建、代码检索和重排序来解决现有方法的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的仓库级代码补全方法存在查询构建不当、单路径代码检索以及代码检索器与代码大语言模型不对齐等问题。

Method: CodeRAG包含三个核心组件：基于对数概率的查询构建、多路径代码检索以及偏好对齐的BestFit重排序。

Result: 在ReccEval和CCEval基准测试上的广泛实验表明，CodeRAG显著且持续地优于现有最先进方法。

Conclusion: CodeRAG通过识别相关且必要的知识，有效提升了检索增强的仓库级代码补全性能。

Abstract: Repository-level code completion automatically predicts the unfinished code
based on the broader information from the repository. Recent strides in Code
Large Language Models (code LLMs) have spurred the development of
repository-level code completion methods, yielding promising results.
Nevertheless, they suffer from issues such as inappropriate query construction,
single-path code retrieval, and misalignment between code retriever and code
LLM. To address these problems, we introduce CodeRAG, a framework tailored to
identify relevant and necessary knowledge for retrieval-augmented
repository-level code completion. Its core components include log probability
guided query construction, multi-path code retrieval, and preference-aligned
BestFit reranking. Extensive experiments on benchmarks ReccEval and CCEval
demonstrate that CodeRAG significantly and consistently outperforms
state-of-the-art methods. The implementation of CodeRAG is available at
https://github.com/KDEGroup/CodeRAG.

</details>


### [55] [CultureScope: A Dimensional Lens for Probing Cultural Understanding in LLMs](https://arxiv.org/abs/2509.16188)
*Jinghao Zhang,Sihang Jiang,Shiwei Guo,Shisong Chen,Yanghua Xiao,Hongwei Feng,Jiaqing Liang,Minggui HE,Shimin Tao,Hongxia Ma*

Main category: cs.CL

TL;DR: 提出了CultureScope框架，基于文化冰山理论设计三维度140层级的文化知识分类体系，用于自动化构建文化特定知识库和评估数据集，以全面评估大语言模型的文化理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有文化理解评估基准缺乏全面性，难以跨文化扩展，且依赖专家手动标注，需要基于文化理论指导的自动化评估框架。

Method: 基于文化冰山理论设计3层140维度的文化知识分类模式，自动化构建文化特定知识库和评估数据集，支持任意语言和文化的评估。

Result: 实验证明该方法能有效评估文化理解，发现现有大语言模型缺乏全面文化能力，仅增加多语言数据并不能提升文化理解。

Conclusion: CultureScope是迄今最全面的文化理解评估框架，为开发可信赖、文化对齐的AI应用提供了重要工具。

Abstract: As large language models (LLMs) are increasingly deployed in diverse cultural
environments, evaluating their cultural understanding capability has become
essential for ensuring trustworthy and culturally aligned applications.
However, most existing benchmarks lack comprehensiveness and are challenging to
scale and adapt across different cultural contexts, because their frameworks
often lack guidance from well-established cultural theories and tend to rely on
expert-driven manual annotations. To address these issues, we propose
CultureScope, the most comprehensive evaluation framework to date for assessing
cultural understanding in LLMs. Inspired by the cultural iceberg theory, we
design a novel dimensional schema for cultural knowledge classification,
comprising 3 layers and 140 dimensions, which guides the automated construction
of culture-specific knowledge bases and corresponding evaluation datasets for
any given languages and cultures. Experimental results demonstrate that our
method can effectively evaluate cultural understanding. They also reveal that
existing large language models lack comprehensive cultural competence, and
merely incorporating multilingual data does not necessarily enhance cultural
understanding. All code and data files are available at
https://github.com/HoganZinger/Culture

</details>


### [56] [RPG: A Repository Planning Graph for Unified and Scalable Codebase Generation](https://arxiv.org/abs/2509.16198)
*Jane Luo,Xin Zhang,Steven Liu,Jie Wu,Yiming Huang,Yangyu Huang,Chengyu Yin,Ying Xin,Jianfeng Liu,Yuefeng Zhan,Hao Sun,Qi Chen,Scarlett Li,Mao Yang*

Main category: cs.CL

TL;DR: 该论文提出了Repository Planning Graph（RPG）来解决从零生成完整代码仓库的挑战，通过图结构统一规划和实现阶段，并开发了ZeroRepo框架在RepoCraft基准测试中显著优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在函数和文件级代码生成表现出色，但从零生成完整仓库仍面临挑战，需要跨规划和实现阶段的连贯可靠规划，而自然语言由于模糊性和冗长性不适合表示复杂软件结构。

Method: 引入Repository Planning Graph（RPG）作为持久化表示，统一规划和实现阶段，编码能力、文件结构、数据流和函数；开发ZeroRepo框架，包含三个阶段：规划级规划、实现级细化和图引导的代码生成与测试验证。

Result: 在RepoCraft基准（6个真实项目，1052个任务）上，ZeroRepo生成平均近36K行代码的仓库，比最强基线Claude Code多3.9倍，功能覆盖率达81.5%，通过率69.7%，分别比Claude Code高27.3和35.8个百分点。

Conclusion: RPG能有效建模复杂依赖关系，通过近线性扩展实现渐进式复杂规划，增强LLM对仓库的理解，加速智能体定位，为从零生成代码仓库提供了有效解决方案。

Abstract: Large language models excel at function- and file-level code generation, yet
generating complete repositories from scratch remains a fundamental challenge.
This process demands coherent and reliable planning across proposal- and
implementation-level stages, while natural language, due to its ambiguity and
verbosity, is ill-suited for faithfully representing complex software
structures. To address this, we introduce the Repository Planning Graph (RPG),
a persistent representation that unifies proposal- and implementation-level
planning by encoding capabilities, file structures, data flows, and functions
in one graph. RPG replaces ambiguous natural language with an explicit
blueprint, enabling long-horizon planning and scalable repository generation.
Building on RPG, we develop ZeroRepo, a graph-driven framework for repository
generation from scratch. It operates in three stages: proposal-level planning
and implementation-level refinement to construct the graph, followed by
graph-guided code generation with test validation. To evaluate this setting, we
construct RepoCraft, a benchmark of six real-world projects with 1,052 tasks.
On RepoCraft, ZeroRepo produces repositories averaging nearly 36K LOC, roughly
3.9$\times$ the strongest baseline (Claude Code) and about 64$\times$ other
baselines. It attains 81.5% functional coverage and a 69.7% pass rate,
exceeding Claude Code by 27.3 and 35.8 percentage points, respectively. Further
analysis shows that RPG models complex dependencies, enables progressively more
sophisticated planning through near-linear scaling, and enhances LLM
understanding of repositories, thereby accelerating agent localization.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [57] [Fleming-R1: Toward Expert-Level Medical Reasoning via Reinforcement Learning](https://arxiv.org/abs/2509.15279)
*Chi Liu,Derek Li,Yan Shu,Robin Chen,Derek Duan,Teng Fang,Bryan Dai*

Main category: cs.LG

TL;DR: Fleming-R1是一个用于可验证医疗推理的模型，通过三个创新点实现专家级临床推理：推理导向数据策略、思维链冷启动和可验证奖励强化学习框架。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在医疗应用中需要准确答案和透明推理过程的挑战，实现专家级临床推理能力。

Method: 1. RODS数据策略结合医疗QA数据集和知识图谱引导合成；2. CoT冷启动从教师模型提取高质量推理轨迹；3. RLVR框架使用群体相对策略优化进行强化学习。

Result: 7B版本超越更大基线模型，32B版本接近GPT-4o性能，在多个医疗基准测试中表现优异。

Conclusion: 结构化数据设计、推理导向初始化和可验证强化学习可以推动临床推理超越简单准确性优化，促进医疗AI的安全部署。

Abstract: While large language models show promise in medical applications, achieving
expert-level clinical reasoning remains challenging due to the need for both
accurate answers and transparent reasoning processes. To address this
challenge, we introduce Fleming-R1, a model designed for verifiable medical
reasoning through three complementary innovations. First, our
Reasoning-Oriented Data Strategy (RODS) combines curated medical QA datasets
with knowledge-graph-guided synthesis to improve coverage of underrepresented
diseases, drugs, and multi-hop reasoning chains. Second, we employ
Chain-of-Thought (CoT) cold start to distill high-quality reasoning
trajectories from teacher models, establishing robust inference priors. Third,
we implement a two-stage Reinforcement Learning from Verifiable Rewards (RLVR)
framework using Group Relative Policy Optimization, which consolidates core
reasoning skills while targeting persistent failure modes through adaptive
hard-sample mining. Across diverse medical benchmarks, Fleming-R1 delivers
substantial parameter-efficient improvements: the 7B variant surpasses much
larger baselines, while the 32B model achieves near-parity with GPT-4o and
consistently outperforms strong open-source alternatives. These results
demonstrate that structured data design, reasoning-oriented initialization, and
verifiable reinforcement learning can advance clinical reasoning beyond simple
accuracy optimization. We release Fleming-R1 publicly to promote transparent,
reproducible, and auditable progress in medical AI, enabling safer deployment
in high-stakes clinical environments.

</details>


### [58] [Small LLMs with Expert Blocks Are Good Enough for Hyperparamter Tuning](https://arxiv.org/abs/2509.15561)
*Om Naphade,Saksham Bansal,Parikshit Pareek*

Main category: cs.LG

TL;DR: 提出了一种使用小型LLM进行超参数调优的专家块框架，通过轨迹上下文摘要器将原始训练轨迹转换为结构化上下文，使小型LLM在10次试验预算下能达到接近GPT-4的性能。


<details>
  <summary>Details</summary>
Motivation: 传统超参数调优在大模型上计算成本高且不透明，现有LLM方法依赖超过1000亿参数的大模型，需要开发更高效的小型LLM解决方案。

Method: 核心是轨迹上下文摘要器（TCS），这是一个确定性模块，将原始训练轨迹转换为结构化上下文，使小型LLM能够可靠分析优化进度。使用phi4:reasoning14B和qwen2.5-coder:32B两个本地运行的小型LLM。

Result: 在10次试验预算下，TCS增强的HPT管道在六个不同任务上的平均性能与GPT-4相差约0.9个百分点。

Conclusion: 该方法证明小型LLM通过适当的上下文处理可以有效地进行超参数调优，减少对大模型的依赖。

Abstract: Hyper-parameter Tuning (HPT) is a necessary step in machine learning (ML)
pipelines but becomes computationally expensive and opaque with larger models.
Recently, Large Language Models (LLMs) have been explored for HPT, yet most
rely on models exceeding 100 billion parameters. We propose an Expert Block
Framework for HPT using Small LLMs. At its core is the Trajectory Context
Summarizer (TCS), a deterministic block that transforms raw training
trajectories into structured context, enabling small LLMs to analyze
optimization progress with reliability comparable to larger models. Using two
locally-run LLMs (phi4:reasoning14B and qwen2.5-coder:32B) and a 10-trial
budget, our TCS-enabled HPT pipeline achieves average performance within ~0.9
percentage points of GPT-4 across six diverse tasks.

</details>


### [59] [KITE: Kernelized and Information Theoretic Exemplars for In-Context Learning](https://arxiv.org/abs/2509.15676)
*Vaibhav Singh,Soumya Suvra Ghosal,Kapu Nirmal Joshua,Soumyabrata Pal,Sayak Ray Chowdhury*

Main category: cs.LG

TL;DR: 本文提出了一种基于信息理论原理的示例选择方法，用于改进大语言模型中的上下文学习性能，通过优化查询特定的示例选择来最大化预测准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于最近邻的方法（如KATE）在高维嵌入空间中存在泛化能力差和多样性不足的问题，需要一种更原则性的方法来选择最优示例。

Method: 将LLM建模为输入嵌入的线性函数，将示例选择问题形式化为查询特定的优化问题，使用近似子模贪婪算法，并结合核技巧和基于最优设计的正则化器来增强多样性。

Result: 实验证明该方法在一系列分类任务上显著优于标准检索方法，在真实世界标签稀缺场景中表现出色。

Conclusion: 基于信息理论的结构感知、多样性示例选择方法能够有效提升上下文学习的性能，为数据稀缺任务提供了有效的解决方案。

Abstract: In-context learning (ICL) has emerged as a powerful paradigm for adapting
large language models (LLMs) to new and data-scarce tasks using only a few
carefully selected task-specific examples presented in the prompt. However,
given the limited context size of LLMs, a fundamental question arises: Which
examples should be selected to maximize performance on a given user query?
While nearest-neighbor-based methods like KATE have been widely adopted for
this purpose, they suffer from well-known drawbacks in high-dimensional
embedding spaces, including poor generalization and a lack of diversity. In
this work, we study this problem of example selection in ICL from a principled,
information theory-driven perspective. We first model an LLM as a linear
function over input embeddings and frame the example selection task as a
query-specific optimization problem: selecting a subset of exemplars from a
larger example bank that minimizes the prediction error on a specific query.
This formulation departs from traditional generalization-focused learning
theoretic approaches by targeting accurate prediction for a specific query
instance. We derive a principled surrogate objective that is approximately
submodular, enabling the use of a greedy algorithm with an approximation
guarantee. We further enhance our method by (i) incorporating the kernel trick
to operate in high-dimensional feature spaces without explicit mappings, and
(ii) introducing an optimal design-based regularizer to encourage diversity in
the selected examples. Empirically, we demonstrate significant improvements
over standard retrieval methods across a suite of classification tasks,
highlighting the benefits of structure-aware, diverse example selection for ICL
in real-world, label-scarce scenarios.

</details>


### [60] [EmoHeal: An End-to-End System for Personalized Therapeutic Music Retrieval from Fine-grained Emotions](https://arxiv.org/abs/2509.15986)
*Xinchen Wan,Jinhua Liang,Huan Zhang*

Main category: cs.LG

TL;DR: EmoHeal是一个端到端的个性化心理健康系统，通过检测27种细粒度情绪，结合音乐治疗原则生成三段式支持性叙事，显著改善用户情绪状态


<details>
  <summary>Details</summary>
Motivation: 现有数字心理健康工具忽视了日常挑战背后的细微情绪状态，如影响超过15亿人的睡前焦虑问题，当前方法过于静态且缺乏个性化适配

Method: 使用微调的XLM-RoBERTa模型检测用户文本中的27种细粒度情绪，通过基于音乐治疗原则（GEMS、iso-principle）的知识图谱映射到音乐参数，利用CLAMP3模型检索视听内容，采用"匹配-引导-目标"三段式方法

Result: 在40名参与者的组内研究中，参与者报告了显著的情绪改善（M=4.12, p<0.001）和高感知情绪识别准确率（M=4.05, p<0.001），感知准确性与治疗效果呈强相关（r=0.72, p<0.001）

Conclusion: 研究证实了理论驱动、情绪感知的数字健康工具的可行性，为音乐治疗原则的可扩展AI实现提供了蓝图

Abstract: Existing digital mental wellness tools often overlook the nuanced emotional
states underlying everyday challenges. For example, pre-sleep anxiety affects
more than 1.5 billion people worldwide, yet current approaches remain largely
static and "one-size-fits-all", failing to adapt to individual needs. In this
work, we present EmoHeal, an end-to-end system that delivers personalized,
three-stage supportive narratives. EmoHeal detects 27 fine-grained emotions
from user text with a fine-tuned XLM-RoBERTa model, mapping them to musical
parameters via a knowledge graph grounded in music therapy principles (GEMS,
iso-principle). EmoHeal retrieves audiovisual content using the CLAMP3 model to
guide users from their current state toward a calmer one
("match-guide-target"). A within-subjects study (N=40) demonstrated significant
supportive effects, with participants reporting substantial mood improvement
(M=4.12, p<0.001) and high perceived emotion recognition accuracy (M=4.05,
p<0.001). A strong correlation between perceived accuracy and therapeutic
outcome (r=0.72, p<0.001) validates our fine-grained approach. These findings
establish the viability of theory-driven, emotion-aware digital wellness tools
and provides a scalable AI blueprint for operationalizing music therapy
principles.

</details>


### [61] [SABER: Uncovering Vulnerabilities in Safety Alignment via Cross-Layer Residual Connection](https://arxiv.org/abs/2509.16060)
*Maithili Joshi,Palash Nandi,Tanmoy Chakraborty*

Main category: cs.LG

TL;DR: SABER是一种新型的白盒越狱方法，通过在LLM的中间层添加残差连接来绕过安全对齐机制，在HarmBench测试集上比最佳基线提升51%的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs经过安全对齐训练，但它们仍然容易受到越狱攻击。研究发现LLMs的安全机制主要嵌入在中间到后期层中。

Method: SABER方法通过连接两个中间层s和e（s < e）的残差连接来绕过安全对齐，这是一种白盒攻击方法。

Result: 在HarmBench测试集上实现了51%的性能提升，在验证集上仅引起边际困惑度变化。

Conclusion: SABER方法有效证明了LLMs安全机制的脆弱性，为理解和改进LLM安全性提供了重要见解。

Abstract: Large Language Models (LLMs) with safe-alignment training are powerful
instruments with robust language comprehension capabilities. These models
typically undergo meticulous alignment procedures involving human feedback to
ensure the acceptance of safe inputs while rejecting harmful or unsafe ones.
However, despite their massive scale and alignment efforts, LLMs remain
vulnerable to jailbreak attacks, where malicious users manipulate the model to
produce harmful outputs that it was explicitly trained to avoid. In this study,
we find that the safety mechanisms in LLMs are predominantly embedded in the
middle-to-late layers. Building on this insight, we introduce a novel white-box
jailbreak method, SABER (Safety Alignment Bypass via Extra Residuals), which
connects two intermediate layers $s$ and $e$ such that $s < e$, through a
residual connection. Our approach achieves a 51% improvement over the
best-performing baseline on the HarmBench test set. Furthermore, SABER induces
only a marginal shift in perplexity when evaluated on the HarmBench validation
set. The source code is publicly available at
https://github.com/PalGitts/SABER.

</details>


### [62] [Latent learning: episodic memory complements parametric learning by enabling flexible reuse of experiences](https://arxiv.org/abs/2509.16189)
*Andrew Kyle Lampinen,Martin Engelcke,Yuxuan Li,Arslan Chaudhry,James L. McClelland*

Main category: cs.LG

TL;DR: 本文探讨机器学习系统泛化失败的原因，指出其缺乏潜在学习能力（学习与当前任务无关但对未来任务有用的信息），并提出基于情景记忆的检索机制作为解决方案。


<details>
  <summary>Details</summary>
Motivation: 机器学习系统相比自然智能存在数据效率低下的问题，主要原因是无法进行潜在学习——学习与当前任务无关但可能对未来任务有用的信息。

Method: 采用基于情景记忆的检索机制，通过oracle检索系统更灵活地利用学习经验，并强调示例内上下文学习对于跨检索示例使用信息的重要性。

Result: 研究表明，具有检索机制的系统能够在语言建模的反转诅咒和基于代理的导航等挑战中实现更好的泛化性能。

Conclusion: 检索方法可以补充参数化学习，改善机器学习系统的泛化能力，这有助于理解当前机器学习系统相对于自然智能数据效率低下的原因。

Abstract: When do machine learning systems fail to generalize, and what mechanisms
could improve their generalization? Here, we draw inspiration from cognitive
science to argue that one weakness of machine learning systems is their failure
to exhibit latent learning -- learning information that is not relevant to the
task at hand, but that might be useful in a future task. We show how this
perspective links failures ranging from the reversal curse in language modeling
to new findings on agent-based navigation. We then highlight how cognitive
science points to episodic memory as a potential part of the solution to these
issues. Correspondingly, we show that a system with an oracle retrieval
mechanism can use learning experiences more flexibly to generalize better
across many of these challenges. We also identify some of the essential
components for effectively using retrieval, including the importance of
within-example in-context learning for acquiring the ability to use information
across retrieved examples. In summary, our results illustrate one possible
contributor to the relative data inefficiency of current machine learning
systems compared to natural intelligence, and help to understand how retrieval
methods can complement parametric learning to improve generalization.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [63] [Efficient and Versatile Model for Multilingual Information Retrieval of Islamic Text: Development and Deployment in Real-World Scenarios](https://arxiv.org/abs/2509.15380)
*Vera Pavlova,Mohammed Makhlouf*

Main category: cs.IR

TL;DR: 本研究利用古兰经多语言语料库的特性，探索开发伊斯兰领域多语言信息检索系统的最优策略，提出了一种结合跨语言和单语言技术的新混合方法，并在实际部署中验证了单一轻量模型的成本效益。


<details>
  <summary>Details</summary>
Motivation: 当前多语言信息检索研究与实践部署之间存在显著差距，许多研究在孤立环境中评估性能，限制了其在真实场景中的应用。本研究旨在开发满足用户多语言信息需求的伊斯兰领域检索系统。

Method: 准备了11个检索模型，采用四种训练方法：单语言、跨语言、翻译训练全部以及新颖的混合方法（结合跨语言和单语言技术）。

Result: 在领域内数据集上的评估表明，混合方法在各种检索场景下都取得了有希望的结果。详细分析了不同训练配置对嵌入空间的影响及其对多语言检索效果的影响。

Conclusion: 混合方法在多语言信息检索中表现优异，部署单一轻量级模型在实际应用中具有成本效益优势。

Abstract: Despite recent advancements in Multilingual Information Retrieval (MLIR), a
significant gap remains between research and practical deployment. Many studies
assess MLIR performance in isolated settings, limiting their applicability to
real-world scenarios. In this work, we leverage the unique characteristics of
the Quranic multilingual corpus to examine the optimal strategies to develop an
ad-hoc IR system for the Islamic domain that is designed to satisfy users'
information needs in multiple languages. We prepared eleven retrieval models
employing four training approaches: monolingual, cross-lingual,
translate-train-all, and a novel mixed method combining cross-lingual and
monolingual techniques. Evaluation on an in-domain dataset demonstrates that
the mixed approach achieves promising results across diverse retrieval
scenarios. Furthermore, we provide a detailed analysis of how different
training configurations affect the embedding space and their implications for
multilingual retrieval effectiveness. Finally, we discuss deployment
considerations, emphasizing the cost-efficiency of deploying a single
versatile, lightweight model for real-world MLIR applications.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [64] [EHR-MCP: Real-world Evaluation of Clinical Information Retrieval by Large Language Models via Model Context Protocol](https://arxiv.org/abs/2509.15957)
*Kanato Masayoshi,Masahiro Hashimoto,Ryoichi Yokoyama,Naoki Toda,Yoshifumi Uwamino,Shogo Fukuda,Ho Namkoong,Masahiro Jinzaki*

Main category: cs.AI

TL;DR: 本研究评估了通过MCP协议将LLM与医院EHR数据库连接后，在真实医院环境中自主检索临床相关信息的能力。结果显示在简单任务中表现近乎完美，但在复杂任务中存在挑战。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在医疗领域有潜力，但在医院部署受限，主要障碍是难以访问电子健康记录系统。MCP协议为LLM与外部工具集成提供了可能。

Method: 开发了EHR-MCP框架，将自定义MCP工具与医院EHR数据库集成，使用GPT-4.1通过LangGraph ReAct代理进行交互。测试了6个感染控制团队相关任务，回顾性分析了8名患者，与医生生成的金标准进行比较。

Result: LLM能够一致选择和执行正确的MCP工具。除两个任务外，所有任务准确率接近完美。在需要时间相关计算的复杂任务中表现较差。错误主要来自参数不正确或工具结果误解。

Conclusion: LLM可以通过MCP工具从EHR中检索临床数据，在简单任务中表现优异，但在复杂任务中面临挑战。EHR-MCP为医院AI代理提供了安全、一致的数据访问基础设施，未来应扩展到推理、生成和临床影响评估。

Abstract: Background: Large language models (LLMs) show promise in medicine, but their
deployment in hospitals is limited by restricted access to electronic health
record (EHR) systems. The Model Context Protocol (MCP) enables integration
between LLMs and external tools.
  Objective: To evaluate whether an LLM connected to an EHR database via MCP
can autonomously retrieve clinically relevant information in a real hospital
setting.
  Methods: We developed EHR-MCP, a framework of custom MCP tools integrated
with the hospital EHR database, and used GPT-4.1 through a LangGraph ReAct
agent to interact with it. Six tasks were tested, derived from use cases of the
infection control team (ICT). Eight patients discussed at ICT conferences were
retrospectively analyzed. Agreement with physician-generated gold standards was
measured.
  Results: The LLM consistently selected and executed the correct MCP tools.
Except for two tasks, all tasks achieved near-perfect accuracy. Performance was
lower in the complex task requiring time-dependent calculations. Most errors
arose from incorrect arguments or misinterpretation of tool results. Responses
from EHR-MCP were reliable, though long and repetitive data risked exceeding
the context window.
  Conclusions: LLMs can retrieve clinical data from an EHR via MCP tools in a
real hospital setting, achieving near-perfect performance in simple tasks while
highlighting challenges in complex ones. EHR-MCP provides an infrastructure for
secure, consistent data access and may serve as a foundation for hospital AI
agents. Future work should extend beyond retrieval to reasoning, generation,
and clinical impact assessment, paving the way for effective integration of
generative AI into clinical practice.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [65] [SightSound-R1: Cross-Modal Reasoning Distillation from Vision to Audio Language Models](https://arxiv.org/abs/2509.15661)
*Qiaolin Wang,Xilin Jiang,Linyang He,Junkai Wu,Nima Mesgarani*

Main category: cs.SD

TL;DR: SightSound-R1是一个跨模态蒸馏框架，通过视觉语言模型向音频语言模型传递推理能力，解决了音频推理数据不足的问题。


<details>
  <summary>Details</summary>
Motivation: 大型音频语言模型在复杂声音场景中的推理能力仍落后于视觉语言模型，主要瓶颈是缺乏大规模音频思维链数据。

Method: 采用三步蒸馏框架：测试时间缩放生成音频聚焦思维链、基于音频的验证过滤幻觉、监督微调加GRPO优化的蒸馏流程。

Result: SightSound-R1在域内AVQA测试集和未见音频场景中都提升了音频模型的推理性能，超越了预训练和仅标签蒸馏的基线方法。

Conclusion: 视觉推理可以有效地转移到音频模型中，并能通过丰富的音频-视觉数据进行扩展。

Abstract: While large audio-language models (LALMs) have demonstrated state-of-the-art
audio understanding, their reasoning capability in complex soundscapes still
falls behind large vision-language models (LVLMs). Compared to the visual
domain, one bottleneck is the lack of large-scale chain-of-thought audio data
to teach LALM stepwise reasoning. To circumvent this data and modality gap, we
present SightSound-R1, a cross-modal distillation framework that transfers
advanced reasoning from a stronger LVLM teacher to a weaker LALM student on the
same audio-visual question answering (AVQA) dataset. SightSound-R1 consists of
three core steps: (i) test-time scaling to generate audio-focused chains of
thought (CoT) from an LVLM teacher, (ii) audio-grounded validation to filter
hallucinations, and (iii) a distillation pipeline with supervised fine-tuning
(SFT) followed by Group Relative Policy Optimization (GRPO) for the LALM
student. Results show that SightSound-R1 improves LALM reasoning performance
both in the in-domain AVQA test set as well as in unseen auditory scenes and
questions, outperforming both pretrained and label-only distilled baselines.
Thus, we conclude that vision reasoning can be effectively transferred to audio
models and scaled with abundant audio-visual data.

</details>


### [66] [Direct Simultaneous Translation Activation for Large Audio-Language Models](https://arxiv.org/abs/2509.15692)
*Pei Zhang,Yiming Wang,Jialong Tang,Baosong Yang,Rui Wang,Derek F. Wong,Fei Huang*

Main category: cs.SD

TL;DR: 本文提出SimulSA方法，通过利用大型音频语言模型的固有能力，通过随机截断语音和构建部分对齐翻译来获得同步数据，从而在不修改模型架构的情况下激活同步语音到文本翻译能力。


<details>
  <summary>Details</summary>
Motivation: 随着大型音频语言模型的兴起，关键挑战是如何在不进行额外架构修改的情况下直接激活模型的同步语音到文本翻译能力。现有研究通常需要修改模型架构来实现读写策略。

Method: 提出SimulSA（同步自增强）策略，利用LALMs的固有能力，通过随机截断语音和构建部分对齐翻译来获得同步数据，并将其整合到离线监督微调数据中。

Result: 实验结果表明，仅需增强约1%的同步数据（相对于完整离线SFT数据），就能显著激活LALMs的Simul-S2TT能力，且无需修改模型架构或解码策略。

Conclusion: SimulSA方法有效弥合了预训练期间离线翻译与推理期间同步翻译之间的分布差距，为激活大型音频语言模型的同步翻译能力提供了一种高效且无需架构修改的解决方案。

Abstract: Simultaneous speech-to-text translation (Simul-S2TT) aims to translate speech
into target text in real time, outputting translations while receiving source
speech input, rather than waiting for the entire utterance to be spoken.
Simul-S2TT research often modifies model architectures to implement read-write
strategies. However, with the rise of large audio-language models (LALMs), a
key challenge is how to directly activate Simul-S2TT capabilities in base
models without additional architectural changes. In this paper, we introduce
{\bf Simul}taneous {\bf S}elf-{\bf A}ugmentation ({\bf SimulSA}), a strategy
that utilizes LALMs' inherent capabilities to obtain simultaneous data by
randomly truncating speech and constructing partially aligned translation. By
incorporating them into offline SFT data, SimulSA effectively bridges the
distribution gap between offline translation during pretraining and
simultaneous translation during inference. Experimental results demonstrate
that augmenting only about {\bf 1\%} of the simultaneous data, compared to the
full offline SFT data, can significantly activate LALMs' Simul-S2TT
capabilities without modifications to model architecture or decoding strategy.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [67] [Learning Analytics from Spoken Discussion Dialogs in Flipped Classroom](https://arxiv.org/abs/2301.12399)
*Hang Su,Borislav Dzodzo,Changlun Li,Danyang Zhao,Hao Geng,Yunxiang Li,Sidharth Jaggi,Helen Meng*

Main category: cs.CY

TL;DR: 翻转课堂中通过分析小组讨论对话来预测学习成果的研究，使用统计分析和机器学习方法，最高预测准确率达到78.9%。


<details>
  <summary>Details</summary>
Motivation: 翻转课堂中的口语讨论对话蕴含丰富的学习过程和进展信息，需要分析这些对话来了解小组学习过程和成果。

Method: 将课程转为翻转课堂模式，录制课堂小组讨论并手动转录，通过多种工具提取对话特征，进行统计分析找出与学习成果相关的指标，然后应用机器学习算法预测学习成果等级。

Result: 最佳预测准确率达到78.9%，证明了从小组讨论对话自动预测学习成果的可行性。

Conclusion: 研究表明通过分析翻转课堂中的小组讨论对话可以有效预测学习成果，为学习分析提供了新的方法。

Abstract: The flipped classroom is a new pedagogical strategy that has been gaining
increasing importance recently. Spoken discussion dialog commonly occurs in
flipped classroom, which embeds rich information indicating processes and
progression of students' learning. This study focuses on learning analytics
from spoken discussion dialog in the flipped classroom, which aims to collect
and analyze the discussion dialogs in flipped classroom in order to get to know
group learning processes and outcomes. We have recently transformed a course
using the flipped classroom strategy, where students watched video-recorded
lectures at home prior to group-based problem-solving discussions in class. The
in-class group discussions were recorded throughout the semester and then
transcribed manually. After features are extracted from the dialogs by multiple
tools and customized processing techniques, we performed statistical analyses
to explore the indicators that are related to the group learning outcomes from
face-to-face discussion dialogs in the flipped classroom. Then, machine
learning algorithms are applied to the indicators in order to predict the group
learning outcome as High, Mid or Low. The best prediction accuracy reaches
78.9%, which demonstrates the feasibility of achieving automatic learning
outcome prediction from group discussion dialog in flipped classroom.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [68] [Video2Roleplay: A Multimodal Dataset and Framework for Video-Guided Role-playing Agents](https://arxiv.org/abs/2509.15233)
*Xueqiao Zhang,Chao Zhang,Jingtao Xu,Yifan Zhu,Xin Shi,Yi Yang,Yawei Luo*

Main category: cs.MM

TL;DR: 本文提出了一种结合视频模态的动态角色配置文件方法，用于改进角色扮演智能体（RPAs），通过构建包含6万视频和70万对话的大规模数据集Role-playing-Video60k，开发了结合自适应时间采样和动态/静态角色配置的框架。


<details>
  <summary>Details</summary>
Motivation: 现有角色扮演智能体方法主要关注静态角色配置文件，忽视了人类固有的动态感知能力，需要将视频模态融入RPA以弥补这一差距。

Method: 构建Role-playing-Video60k数据集，开发结合自适应时间采样和动态/静态角色配置的RPA框架。动态配置文件通过自适应采样视频帧并按时间顺序输入LLM生成，静态配置文件包含训练视频中的角色对话和推理时输入视频的摘要上下文。

Result: 实验结果表明该框架有效，证明了动态角色配置文件在开发RPA中的重要性。

Conclusion: 动态角色配置文件的引入显著提升了角色扮演智能体的响应质量，为RPA发展提供了重要方向。

Abstract: Role-playing agents (RPAs) have attracted growing interest for their ability
to simulate immersive and interactive characters. However, existing approaches
primarily focus on static role profiles, overlooking the dynamic perceptual
abilities inherent to humans. To bridge this gap, we introduce the concept of
dynamic role profiles by incorporating video modality into RPAs. To support
this, we construct Role-playing-Video60k, a large-scale, high-quality dataset
comprising 60k videos and 700k corresponding dialogues. Based on this dataset,
we develop a comprehensive RPA framework that combines adaptive temporal
sampling with both dynamic and static role profile representations.
Specifically, the dynamic profile is created by adaptively sampling video
frames and feeding them to the LLM in temporal order, while the static profile
consists of (1) character dialogues from training videos during fine-tuning,
and (2) a summary context from the input video during inference. This joint
integration enables RPAs to generate greater responses. Furthermore, we propose
a robust evaluation method covering eight metrics. Experimental results
demonstrate the effectiveness of our framework, highlighting the importance of
dynamic role profiles in developing RPAs.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [69] [ViSpec: Accelerating Vision-Language Models with Vision-Aware Speculative Decoding](https://arxiv.org/abs/2509.15235)
*Jialiang Kang,Han Shu,Wenshuo Li,Yingjie Zhai,Xinghao Chen*

Main category: cs.CV

TL;DR: ViSpec是一种针对视觉语言模型的推测解码框架，通过轻量级视觉适配器压缩图像标记并增强多模态一致性，实现了VLM推测解码的显著加速。


<details>
  <summary>Details</summary>
Motivation: 现有推测解码技术在视觉语言模型中的应用不足，速度提升有限（<1.5倍），而多模态能力在大规模模型中日益重要。作者假设大型VLM能有效过滤冗余图像信息而不影响文本理解，但小型草稿模型难以做到。

Method: ViSpec采用轻量级视觉适配器模块压缩图像标记为紧凑表示，集成到草稿模型的注意力机制中，同时保留原始图像位置信息。提取全局特征向量增强多模态一致性，并通过重新利用现有数据集和生成扩展输出来解决多模态长响应数据稀缺问题。

Result: 实验验证ViSpec实现了VLM推测解码的首次显著加速，达到了实质性的速度提升。

Conclusion: ViSpec框架成功解决了VLM推测解码的挑战，为多模态模型的高效推理提供了有效解决方案。

Abstract: Speculative decoding is a widely adopted technique for accelerating inference
in large language models (LLMs), yet its application to vision-language models
(VLMs) remains underexplored, with existing methods achieving only modest
speedups (<1.5x). This gap is increasingly significant as multimodal
capabilities become central to large-scale models. We hypothesize that large
VLMs can effectively filter redundant image information layer by layer without
compromising textual comprehension, whereas smaller draft models struggle to do
so. To address this, we introduce Vision-Aware Speculative Decoding (ViSpec), a
novel framework tailored for VLMs. ViSpec employs a lightweight vision adaptor
module to compress image tokens into a compact representation, which is
seamlessly integrated into the draft model's attention mechanism while
preserving original image positional information. Additionally, we extract a
global feature vector for each input image and augment all subsequent text
tokens with this feature to enhance multimodal coherence. To overcome the
scarcity of multimodal datasets with long assistant responses, we curate a
specialized training dataset by repurposing existing datasets and generating
extended outputs using the target VLM with modified prompts. Our training
strategy mitigates the risk of the draft model exploiting direct access to the
target model's hidden states, which could otherwise lead to shortcut learning
when training solely on target model outputs. Extensive experiments validate
ViSpec, achieving, to our knowledge, the first substantial speedup in VLM
speculative decoding.

</details>


### [70] [M-PACE: Mother Child Framework for Multimodal Compliance](https://arxiv.org/abs/2509.15241)
*Shreyash Verma,Amit Kesari,Vinayak Trivedi,Anupam Purwar,Ratnesh Jamidar*

Main category: cs.CV

TL;DR: M-PACE是一个多模态合规性评估框架，使用母-子MLLM架构统一处理视觉和文本内容，在广告合规性评估中实现31倍成本降低和实时部署。


<details>
  <summary>Details</summary>
Motivation: 传统合规框架采用分散的多阶段流水线，存在操作复杂、可扩展性差、难以适应动态指南的问题，需要统一的多模态处理方案。

Method: 提出M-PACE框架，采用母-子MLLM设置，让更强的母模型评估较小子模型的输出，实现单次处理视觉语言输入，评估15+合规属性。

Result: 推理成本降低31倍以上，最有效模型每张图像成本0.0005美元，相比Gemini 2.5 Pro的0.0159美元，在保持可比准确性的同时实现实时部署。

Conclusion: M-PACE证明了MLLM在统一多模态合规评估中的有效性，显著减少人工审核依赖，在成本和质量间实现良好平衡。

Abstract: Ensuring that multi-modal content adheres to brand, legal, or
platform-specific compliance standards is an increasingly complex challenge
across domains. Traditional compliance frameworks typically rely on disjointed,
multi-stage pipelines that integrate separate modules for image classification,
text extraction, audio transcription, hand-crafted checks, and rule-based
merges. This architectural fragmentation increases operational overhead,
hampers scalability, and hinders the ability to adapt to dynamic guidelines
efficiently. With the emergence of Multimodal Large Language Models (MLLMs),
there is growing potential to unify these workflows under a single,
general-purpose framework capable of jointly processing visual and textual
content. In light of this, we propose Multimodal Parameter Agnostic Compliance
Engine (M-PACE), a framework designed for assessing attributes across
vision-language inputs in a single pass. As a representative use case, we apply
M-PACE to advertisement compliance, demonstrating its ability to evaluate over
15 compliance-related attributes. To support structured evaluation, we
introduce a human-annotated benchmark enriched with augmented samples that
simulate challenging real-world conditions, including visual obstructions and
profanity injection. M-PACE employs a mother-child MLLM setup, demonstrating
that a stronger parent MLLM evaluating the outputs of smaller child models can
significantly reduce dependence on human reviewers, thereby automating quality
control. Our analysis reveals that inference costs reduce by over 31 times,
with the most efficient models (Gemini 2.0 Flash as child MLLM selected by
mother MLLM) operating at 0.0005 per image, compared to 0.0159 for Gemini 2.5
Pro with comparable accuracy, highlighting the trade-off between cost and
output quality achieved in real time by M-PACE in real life deployment over
advertising data.

</details>


### [71] [Beyond Words: Enhancing Desire, Emotion, and Sentiment Recognition with Non-Verbal Cues](https://arxiv.org/abs/2509.15540)
*Wei Chen,Tongguan Wang,Feiyue Xue,Junkai Li,Hui Liu,Ying Sha*

Main category: cs.CV

TL;DR: 提出了一种对称双向多模态学习框架，用于欲望、情感和情感识别，通过文本和图像模态的相互引导来捕捉意图相关表示。


<details>
  <summary>Details</summary>
Motivation: 当前多模态学习在情感和情绪识别方面取得进展，但专门针对人类欲望理解的多模态方法仍未被充分探索，且现有情感分析方法主要关注语言线索而忽视图像作为补充的非语言线索。

Method: 使用低分辨率图像获取全局视觉表示进行跨模态对齐，高分辨率图像分割为子图像并通过掩码图像建模来增强细粒度局部特征捕捉能力。引入文本引导的图像解码器和图像引导的文本解码器，在图像的局部和全局表示层面促进深度跨模态交互。采用混合尺度图像策略平衡感知增益和计算成本。

Result: 在MSED多模态数据集上的实验结果表明，该方法在欲望理解、情绪识别和情感分析方面均优于现有最先进方法，F1分数分别提高了1.1%、0.6%和0.9%。

Conclusion: 提出的对称双向多模态学习框架有效提升了欲望、情感和情绪识别的性能，验证了文本和图像模态相互引导策略的有效性。

Abstract: Desire, as an intention that drives human behavior, is closely related to
both emotion and sentiment. Multimodal learning has advanced sentiment and
emotion recognition, but multimodal approaches specially targeting human desire
understanding remain underexplored. And existing methods in sentiment analysis
predominantly emphasize verbal cues and overlook images as complementary
non-verbal cues. To address these gaps, we propose a Symmetrical Bidirectional
Multimodal Learning Framework for Desire, Emotion, and Sentiment Recognition,
which enforces mutual guidance between text and image modalities to effectively
capture intention-related representations in the image. Specifically,
low-resolution images are used to obtain global visual representations for
cross-modal alignment, while high resolution images are partitioned into
sub-images and modeled with masked image modeling to enhance the ability to
capture fine-grained local features. A text-guided image decoder and an
image-guided text decoder are introduced to facilitate deep cross-modal
interaction at both local and global representations of image information.
Additionally, to balance perceptual gains with computation cost, a mixed-scale
image strategy is adopted, where high-resolution images are cropped into
sub-images for masked modeling. The proposed approach is evaluated on MSED, a
multimodal dataset that includes a desire understanding benchmark, as well as
emotion and sentiment recognition. Experimental results indicate consistent
improvements over other state-of-the-art methods, validating the effectiveness
of our proposed method. Specifically, our method outperforms existing
approaches, achieving F1-score improvements of 1.1% in desire understanding,
0.6% in emotion recognition, and 0.9% in sentiment analysis. Our code is
available at: https://github.com/especiallyW/SyDES.

</details>


### [72] [Robust Vision-Language Models via Tensor Decomposition: A Defense Against Adversarial Attacks](https://arxiv.org/abs/2509.16163)
*Het Patel,Muzammil Allie,Qian Zhang,Jia Chen,Evangelos E. Papalexakis*

Main category: cs.CV

TL;DR: 提出了一种轻量级防御方法，通过张量分解来保护预训练视觉语言模型免受对抗攻击，无需重新训练或重大架构修改。


<details>
  <summary>Details</summary>
Motivation: 现有的防御方法通常需要昂贵的重新训练或显著的架构更改，而本文旨在提供一种轻量级、即插即用的解决方案。

Method: 使用张量分解技术分解和重建视觉编码器的表示，以过滤对抗噪声同时保留语义信息。

Result: 在Flickr30K上恢复了12.3%的性能损失，Recall@1准确率从7.5%提升到19.8%；在COCO上恢复了8.1%的性能，准确率从3.8%提升到11.9%。

Conclusion: 张量训练分解在低秩（8-32）和低残差强度（α=0.1-0.2）时效果最佳，为现有VLM提供了一种实用的、开销最小的防御方案。

Abstract: Vision language models (VLMs) excel in multimodal understanding but are prone
to adversarial attacks. Existing defenses often demand costly retraining or
significant architecture changes. We introduce a lightweight defense using
tensor decomposition suitable for any pre-trained VLM, requiring no retraining.
By decomposing and reconstructing vision encoder representations, it filters
adversarial noise while preserving meaning. Experiments with CLIP on COCO and
Flickr30K show improved robustness. On Flickr30K, it restores 12.3\%
performance lost to attacks, raising Recall@1 accuracy from 7.5\% to 19.8\%. On
COCO, it recovers 8.1\% performance, improving accuracy from 3.8\% to 11.9\%.
Analysis shows Tensor Train decomposition with low rank (8-32) and low residual
strength ($\alpha=0.1-0.2$) is optimal. This method is a practical,
plug-and-play solution with minimal overhead for existing VLMs.

</details>


### [73] [MANZANO: A Simple and Scalable Unified Multimodal Model with a Hybrid Vision Tokenizer](https://arxiv.org/abs/2509.16197)
*Yanghao Li,Rui Qian,Bowen Pan,Haotian Zhang,Haoshuo Huang,Bowen Zhang,Jialing Tong,Haoxuan You,Xianzhi Du,Zhe Gan,Hyunjik Kim,Chao Jia,Zhenbang Wang,Yinfei Yang,Mingfei Gao,Zi-Yi Dou,Wenze Hu,Chang Gao,Dongxu Li,Philipp Dufter,Zirui Wang,Guoli Yin,Zhengdong Zhang,Chen Chen,Yang Zhao,Ruoming Pang,Zhifeng Chen*

Main category: cs.CV

TL;DR: Manzano是一个统一的多模态大语言模型框架，通过混合图像标记器和精心设计的训练方法，同时实现了图像理解和图像生成能力，在统一模型中达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 现有的开源多模态模型在图像理解和生成能力之间存在性能权衡，需要一个统一的框架来减少这种矛盾。

Method: 使用共享视觉编码器配合两个轻量级适配器，分别产生连续嵌入（用于图像理解）和离散标记（用于图像生成），通过统一的自动回归LLM预测文本和图像标记，辅助扩散解码器将图像标记转换为像素。

Result: Manzano在统一模型中达到最先进水平，与专业模型竞争，在文本丰富的评估中表现优异，显示出最小的任务冲突和随着模型规模扩展的持续增益。

Conclusion: 混合标记器的设计选择得到验证，该框架能够实现图像理解和生成能力的可扩展联合学习。

Abstract: Unified multimodal Large Language Models (LLMs) that can both understand and
generate visual content hold immense potential. However, existing open-source
models often suffer from a performance trade-off between these capabilities. We
present Manzano, a simple and scalable unified framework that substantially
reduces this tension by coupling a hybrid image tokenizer with a well-curated
training recipe. A single shared vision encoder feeds two lightweight adapters
that produce continuous embeddings for image-to-text understanding and discrete
tokens for text-to-image generation within a common semantic space. A unified
autoregressive LLM predicts high-level semantics in the form of text and image
tokens, with an auxiliary diffusion decoder subsequently translating the image
tokens into pixels. The architecture, together with a unified training recipe
over understanding and generation data, enables scalable joint learning of both
capabilities. Manzano achieves state-of-the-art results among unified models,
and is competitive with specialist models, particularly on text-rich
evaluation. Our studies show minimal task conflicts and consistent gains from
scaling model size, validating our design choice of a hybrid tokenizer.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [74] [VoXtream: Full-Stream Text-to-Speech with Extremely Low Latency](https://arxiv.org/abs/2509.15969)
*Nikita Torgashov,Gustav Eje Henter,Gabriel Skantze*

Main category: eess.AS

TL;DR: VoXtream是一个完全自回归的零样本流式文本转语音系统，能够在实时使用中从第一个单词开始说话，实现了102毫秒的初始延迟，是目前公开可用的流式TTS中最低的延迟。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够在实时应用中快速响应的流式文本转语音系统，解决传统TTS系统初始延迟高的问题，实现从第一个单词开始的即时语音合成。

Method: 使用单调对齐方案和动态前瞻机制，构建基于增量音素变换器、时间变换器（预测语义和持续时间标记）和深度变换器（生成声学标记）的三阶段架构。

Result: 在GPU上实现102毫秒的初始延迟，在9k小时的中等规模语料库训练下，在多个指标上匹配或超越更大的基线模型，在输出流式和全流式设置中都表现出竞争力。

Conclusion: VoXtream展示了在中等规模训练数据下实现高质量、低延迟流式TTS的可行性，为实时语音合成应用提供了有效的解决方案。

Abstract: We present VoXtream, a fully autoregressive, zero-shot streaming
text-to-speech (TTS) system for real-time use that begins speaking from the
first word. VoXtream directly maps incoming phonemes to audio tokens using a
monotonic alignment scheme and a dynamic look-ahead that does not delay onset.
Built around an incremental phoneme transformer, a temporal transformer
predicting semantic and duration tokens, and a depth transformer producing
acoustic tokens, VoXtream achieves, to our knowledge, the lowest initial delay
among publicly available streaming TTS: 102 ms on GPU. Despite being trained on
a mid-scale 9k-hour corpus, it matches or surpasses larger baselines on several
metrics, while delivering competitive quality in both output- and
full-streaming settings. Demo and code are available at
https://herimor.github.io/voxtream.

</details>
