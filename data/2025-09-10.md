<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 38]
- [cs.HC](#cs.HC) [Total: 1]
- [cs.AI](#cs.AI) [Total: 5]
- [cs.DC](#cs.DC) [Total: 1]
- [cs.CY](#cs.CY) [Total: 1]
- [cs.CV](#cs.CV) [Total: 4]
- [cs.LG](#cs.LG) [Total: 4]
- [cs.SD](#cs.SD) [Total: 1]
- [cs.IR](#cs.IR) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [MedBench-IT: A Comprehensive Benchmark for Evaluating Large Language Models on Italian Medical Entrance Examinations](https://arxiv.org/abs/2509.07135)
*Ruggero Marino Lazzaroni,Alessandro Angioi,Michelangelo Puliga,Davide Sanna,Roberto Marras*

Main category: cs.CL

TL;DR: MedBench-IT是首个针对意大利医学大学入学考试的综合性基准测试，包含17,410个专家编写的选择题，涵盖6个学科和3个难度级别，用于评估LLM在意大利语医学教育领域的表现。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在教育领域潜力日益增长，但非英语专业领域基准测试稀缺，特别是意大利语医学教育领域缺乏标准化评估工具。

Method: 从领先备考材料出版商获取17,410个选择题，评估包括GPT-4o、Claude系列等专有模型和<30B参数的开源模型，进行准确性、可重复性、排序偏差、推理提示等多维度分析。

Result: 模型响应一致性达88.86%（因学科而异），排序偏差影响极小，问题可读性与模型性能存在统计显著但较小的负相关关系。

Conclusion: MedBench-IT为意大利NLP社区、教育技术开发者和从业者提供了关键资源，揭示了当前模型能力并为这一关键领域提供了标准化评估方法。

Abstract: Large language models (LLMs) show increasing potential in education, yet
benchmarks for non-English languages in specialized domains remain scarce. We
introduce MedBench-IT, the first comprehensive benchmark for evaluating LLMs on
Italian medical university entrance examinations. Sourced from Edizioni Simone,
a leading preparatory materials publisher, MedBench-IT comprises 17,410
expert-written multiple-choice questions across six subjects (Biology,
Chemistry, Logic, General Culture, Mathematics, Physics) and three difficulty
levels. We evaluated diverse models including proprietary LLMs (GPT-4o, Claude
series) and resource-efficient open-source alternatives (<30B parameters)
focusing on practical deployability.
  Beyond accuracy, we conducted rigorous reproducibility tests (88.86% response
consistency, varying by subject), ordering bias analysis (minimal impact), and
reasoning prompt evaluation. We also examined correlations between question
readability and model performance, finding a statistically significant but
small inverse relationship. MedBench-IT provides a crucial resource for Italian
NLP community, EdTech developers, and practitioners, offering insights into
current capabilities and standardized evaluation methodology for this critical
domain.

</details>


### [2] [The ML-SUPERB 2.0 Challenge: Towards Inclusive ASR Benchmarking for All Language Varieties](https://arxiv.org/abs/2509.07139)
*William Chen,Chutong Meng,Jiatong Shi,Martijn Bartelds,Shih-Heng Wang,Hsiu-Hsuan Wang,Rafael Mosquera,Sara Hincapie,Dan Jurafsky,Antonis Anastasopoulos,Hung-yi Lee,Karen Livescu,Shinji Watanabe*

Main category: cs.CL

TL;DR: Interspeech 2025 ML-SUPERB 2.0挑战赛构建了包含200+语言、口音和方言的新测试套件，推动多语言ASR模型发展，最佳提交在LID准确率上提升23%，CER降低18%。


<details>
  <summary>Details</summary>
Motivation: 当前多语言ASR的改进在不同语言和语言变体间分布不均，需要推动技术更加包容和先进。

Method: 构建包含200+语言、口音和方言的新测试套件，基于DynaBench建立在线评估服务器，允许参与者灵活设计模型架构。

Result: 收到3个团队的5份提交，全部超越基线。最佳提交在通用多语言测试集上LID准确率提升23%，CER降低18%；在口音和方言数据上CER降低30.2%，LID准确率提升15.7%。

Conclusion: 社区挑战赛对于使语音技术更加包容具有重要意义，展示了在提升多语言ASR性能方面的显著进展。

Abstract: Recent improvements in multilingual ASR have not been equally distributed
across languages and language varieties. To advance state-of-the-art (SOTA) ASR
models, we present the Interspeech 2025 ML-SUPERB 2.0 Challenge. We construct a
new test suite that consists of data from 200+ languages, accents, and dialects
to evaluate SOTA multilingual speech models. The challenge also introduces an
online evaluation server based on DynaBench, allowing for flexibility in model
design and architecture for participants. The challenge received 5 submissions
from 3 teams, all of which outperformed our baselines. The best-performing
submission achieved an absolute improvement in LID accuracy of 23% and a
reduction in CER of 18% when compared to the best baseline on a general
multilingual test set. On accented and dialectal data, the best submission
obtained 30.2% lower CER and 15.7% higher LID accuracy, showing the importance
of community challenges in making speech technologies more inclusive.

</details>


### [3] [Toward Purpose-oriented Topic Model Evaluation enabled by Large Language Models](https://arxiv.org/abs/2509.07142)
*Zhiyin Tan,Jennifer D'Souza*

Main category: cs.CL

TL;DR: 提出基于大语言模型的动态主题模型自动化评估框架，包含9个LLM指标，覆盖四个质量维度，相比传统指标能更好地识别语义缺陷


<details>
  <summary>Details</summary>
Motivation: 传统主题模型评估指标（如连贯性和多样性）只能捕捉狭窄的统计模式，无法解释实际应用中的语义失败，需要更有效的评估方法

Method: 开发了基于LLM的评估框架，包含9个指标评估四个关键维度：词汇有效性、主题内语义合理性、主题间结构合理性和文档-主题对齐合理性，通过对抗性和采样协议验证

Result: LLM指标提供了可解释、稳健且任务相关的评估，能够发现传统指标忽略的关键弱点（如冗余和语义漂移）

Conclusion: 该框架支持开发可扩展的细粒度评估工具，用于维护动态数据集中的主题相关性

Abstract: This study presents a framework for automated evaluation of dynamically
evolving topic models using Large Language Models (LLMs). Topic modeling is
essential for organizing and retrieving scholarly content in digital library
systems, helping users navigate complex and evolving knowledge domains.
However, widely used automated metrics, such as coherence and diversity, often
capture only narrow statistical patterns and fail to explain semantic failures
in practice. We introduce a purpose-oriented evaluation framework that employs
nine LLM-based metrics spanning four key dimensions of topic quality: lexical
validity, intra-topic semantic soundness, inter-topic structural soundness, and
document-topic alignment soundness. The framework is validated through
adversarial and sampling-based protocols, and is applied across datasets
spanning news articles, scholarly publications, and social media posts, as well
as multiple topic modeling methods and open-source LLMs. Our analysis shows
that LLM-based metrics provide interpretable, robust, and task-relevant
assessments, uncovering critical weaknesses in topic models such as redundancy
and semantic drift, which are often missed by traditional metrics. These
results support the development of scalable, fine-grained evaluation tools for
maintaining topic relevance in dynamic datasets. All code and data supporting
this work are accessible at
https://github.com/zhiyintan/topic-model-LLMjudgment.

</details>


### [4] [Towards EnergyGPT: A Large Language Model Specialized for the Energy Sector](https://arxiv.org/abs/2509.07177)
*Amal Chebbi,Babajide Kolade*

Main category: cs.CL

TL;DR: EnergyGPT是基于LLaMA 3.1-8B微调的专业能源领域语言模型，在能源相关任务上表现优于基础模型


<details>
  <summary>Details</summary>
Motivation: 通用大语言模型在能源等专业领域效果有限，需要深度技术专业知识和精确领域知识

Method: 使用监督微调方法，在高质量能源文本语料上微调LLaMA 3.1-8B模型，包括数据收集整理、模型微调、基准设计和评估部署的完整流程

Result: EnergyGPT在大多数能源相关语言理解和生成任务上超越了基础模型，证明了训练策略的有效性

Conclusion: 通过领域专业化微调，可以在不需要大规模基础设施的情况下提升模型在特定领域的相关性和性能

Abstract: Large Language Models have demonstrated impressive capabilities across
various domains. However, their general-purpose nature often limits their
effectiveness in specialized fields such as energy, where deep technical
expertise and precise domain knowledge are essential. In this paper, we
introduce EnergyGPT, a domain-specialized language model tailored for the
energy sector, developed by fine-tuning LLaMA 3.1-8B model using Supervised
Fine-Tuning on a high-quality, curated corpus of energy-related texts. We
present a complete development pipeline, including data collection and
curation, model fine-tuning, benchmark design and LLM-judge choice, evaluation
and deployment. Through this work, we demonstrate that our training strategy
enables improvements in domain relevance and performance without the need for
large-scale infrastructure. By evaluating the performance of the model using
domain-specific question-answering benchmarks, our results demonstrate that
EnergyGPT outperforms the base model in most of the energy-related language
understanding and generation tasks.

</details>


### [5] [DischargeSim: A Simulation Benchmark for Educational Doctor-Patient Communication at Discharge](https://arxiv.org/abs/2509.07188)
*Zonghai Yao,Michael Sun,Won Seok Jang,Sunjae Kwon,Soie Kwon,Hong Yu*

Main category: cs.CL

TL;DR: DischargeSim是一个新的基准测试，用于评估大型语言模型在出院沟通中作为个性化教育者的能力，通过模拟医患对话来测试模型在对话质量、个性化文档生成和患者理解方面的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM基准测试主要关注诊断推理，但忽视了出院后患者教育这一关键环节。出院沟通对患者护理至关重要，需要评估模型在这方面的能力。

Method: 创建DischargeSim基准，模拟出院后多轮医患对话，使用DoctorAgents和具有不同心理社会特征的PatientAgents进行交互，涵盖六个临床主题，从三个维度进行评估。

Result: 测试18个LLM发现出院教育能力存在显著差距，模型性能因患者特征而异，模型大小并不总是带来更好的教育效果。

Conclusion: DischargeSim为评估LLM在临床后访教育中的表现提供了首个基准，有助于促进公平、个性化的患者支持。

Abstract: Discharge communication is a critical yet underexplored component of patient
care, where the goal shifts from diagnosis to education. While recent large
language model (LLM) benchmarks emphasize in-visit diagnostic reasoning, they
fail to evaluate models' ability to support patients after the visit. We
introduce DischargeSim, a novel benchmark that evaluates LLMs on their ability
to act as personalized discharge educators. DischargeSim simulates post-visit,
multi-turn conversations between LLM-driven DoctorAgents and PatientAgents with
diverse psychosocial profiles (e.g., health literacy, education, emotion).
Interactions are structured across six clinically grounded discharge topics and
assessed along three axes: (1) dialogue quality via automatic and LLM-as-judge
evaluation, (2) personalized document generation including free-text summaries
and structured AHRQ checklists, and (3) patient comprehension through a
downstream multiple-choice exam. Experiments across 18 LLMs reveal significant
gaps in discharge education capability, with performance varying widely across
patient profiles. Notably, model size does not always yield better education
outcomes, highlighting trade-offs in strategy use and content prioritization.
DischargeSim offers a first step toward benchmarking LLMs in post-visit
clinical education and promoting equitable, personalized patient support.

</details>


### [6] [Rule-Based Moral Principles for Explaining Uncertainty in Natural Language Generation](https://arxiv.org/abs/2509.07190)
*Zahra Atf,Peter R Lewis*

Main category: cs.CL

TL;DR: 基于道德原则的框架，通过规则系统处理LLM中的不确定性，提高透明度和可解释性


<details>
  <summary>Details</summary>
Motivation: 在高风险场景中，概率方法往往不透明且与透明期望不一致，需要更透明的不确定性处理方法

Method: 基于道德心理学和美德伦理学，定义预防、尊重、责任等道德规则，并在Prolog引擎中编码，根据不确定性级别触发对应系统动作

Result: 通过场景模拟测试规则覆盖率、公平性和信任校准，在临床和法律领域应用中证明能够提高信任和可解释性

Conclusion: 该方法为社会责任任的自然语言生成提供了一种轻量级、透明的替代方案，适用于需要高透明度的高风险场景

Abstract: Large language models (LLMs) are increasingly used in high-stakes settings,
where explaining uncertainty is both technical and ethical. Probabilistic
methods are often opaque and misaligned with expectations of transparency. We
propose a framework based on rule-based moral principles for handling
uncertainty in LLM-generated text. Using insights from moral psychology and
virtue ethics, we define rules such as precaution, deference, and
responsibility to guide responses under epistemic or aleatoric uncertainty.
These rules are encoded in a lightweight Prolog engine, where uncertainty
levels (low, medium, high) trigger aligned system actions with plain-language
rationales. Scenario-based simulations benchmark rule coverage, fairness, and
trust calibration. Use cases in clinical and legal domains illustrate how moral
reasoning can improve trust and interpretability. Our approach offers a
transparent, lightweight alternative to probabilistic models for socially
responsible natural language generation.

</details>


### [7] [LLM Analysis of 150+ years of German Parliamentary Debates on Migration Reveals Shift from Post-War Solidarity to Anti-Solidarity in the Last Decade](https://arxiv.org/abs/2509.07274)
*Aida Kostikova,Ole Pütz,Steffen Eger,Olga Sabelfeld,Benjamin Paassen*

Main category: cs.CL

TL;DR: 使用大型语言模型自动标注德国议会辩论中的（反）团结子类型，评估模型性能并分析二战后至今德国移民政策辩论中的团结趋势


<details>
  <summary>Details</summary>
Motivation: 传统手动标注方法限制了大规模政治文本分析的深度和广度，需要自动化工具来分析德国议会关于移民的广泛辩论历史

Method: 评估多种大型语言模型在标注德国议会辩论（反）团结子类型方面的表现，比较模型大小、提示差异、微调效果，并与数千个人工标注进行对比

Result: 模型在复杂标注任务上表现良好，数据揭示战后时期对移民的高度团结，以及2015年以来议会中强烈的反团结趋势

Conclusion: 大型语言模型在政治文本分析中具有巨大潜力，德国移民辩论在人口衰退和劳动力短缺背景下呈现日益极化的重要特征

Abstract: Migration has been a core topic in German political debate, from millions of
expellees post World War II over labor migration to refugee movements in the
recent past. Studying political speech regarding such wide-ranging phenomena in
depth traditionally required extensive manual annotations, limiting the scope
of analysis to small subsets of the data. Large language models (LLMs) have the
potential to partially automate even complex annotation tasks. We provide an
extensive evaluation of a multiple LLMs in annotating (anti-)solidarity
subtypes in German parliamentary debates compared to a large set of thousands
of human reference annotations (gathered over a year). We evaluate the
influence of model size, prompting differences, fine-tuning, historical versus
contemporary data; and we investigate systematic errors. Beyond methodological
evaluation, we also interpret the resulting annotations from a social science
lense, gaining deeper insight into (anti-)solidarity trends towards migrants in
the German post-World War II period and recent past. Our data reveals a high
degree of migrant-directed solidarity in the postwar period, as well as a
strong trend towards anti-solidarity in the German parliament since 2015,
motivating further research. These findings highlight the promise of LLMs for
political text analysis and the importance of migration debates in Germany,
where demographic decline and labor shortages coexist with rising polarization.

</details>


### [8] [Causal Attention with Lookahead Keys](https://arxiv.org/abs/2509.07301)
*Zhuoqing Song,Peng Sun,Huizhuo Yuan,Quanquan Gu*

Main category: cs.CL

TL;DR: CASTLE是一种新颖的注意力机制，通过动态更新每个token的key来整合后续信息，同时保持自回归特性，在语言建模任务中表现优于标准因果注意力


<details>
  <summary>Details</summary>
Motivation: 标准因果注意力中每个token的QKV是静态的，只能编码前面的上下文信息，这限制了模型对完整上下文的理解能力

Method: 提出CASTLE机制，持续更新每个token的key（称为lookahead keys），这些key属于较早位置但整合了相对这些位置之后出现的token信息，同时保持自回归特性。通过数学等价性实现高效并行训练

Result: 在语言建模基准测试中，CASTLE在不同模型规模下始终优于标准因果注意力，降低了验证困惑度，并在多个下游任务上表现更好

Conclusion: CASTLE通过动态更新key来整合后续信息的方法有效提升了语言模型的性能，证明了在保持自回归特性的同时整合更多上下文信息的可行性

Abstract: In standard causal attention, each token's query, key, and value (QKV) are
static and encode only preceding context. We introduce CAuSal aTtention with
Lookahead kEys (CASTLE), an attention mechanism that continually updates each
token's keys as the context unfolds. We term these updated keys lookahead keys
because they belong to earlier positions yet integrate information from tokens
that appear later relative to those positions, while strictly preserving the
autoregressive property. Although the mechanism appears sequential, we derive a
mathematical equivalence that avoids explicitly materializing lookahead keys at
each position and enables efficient parallel training. On language modeling
benchmarks, CASTLE consistently outperforms standard causal attention across
model scales, reducing validation perplexity and improving performance on a
range of downstream tasks.

</details>


### [9] [Basis Vector Metric: A Method for Robust Open-Ended State Change Detection](https://arxiv.org/abs/2509.07308)
*David Oprea,Sam Powers*

Main category: cs.CL

TL;DR: BVM方法在图像状态分类中表现最佳，但在形容词区分方面不如逻辑回归模型，但存在改进空间


<details>
  <summary>Details</summary>
Motivation: 测试BVM方法在判断图像状态变化方面的能力，特别是在语言嵌入的背景下

Method: 使用MIT-States数据集（53,000张图像，225个名词和115个形容词），通过BVM方法与余弦相似度、点积、乘积量化、二进制索引、朴素贝叶斯和自定义神经网络进行比较

Result: BVM在名词状态分类方面表现最佳，但在形容词区分方面不如逻辑回归模型

Conclusion: BVM方法在名词分类方面有效，但在形容词区分方面需要进一步改进，存在提升准确性的可能性

Abstract: We test a new method, which we will abbreviate using the acronym BVM (Basis
Vectors Method), in its ability to judge the state changes in images through
using language embeddings. We used the MIT-States dataset, containing about
53,000 images, to gather all of our data, which has 225 nouns and 115
adjectives, with each noun having about 9 different adjectives, forming
approximately 1000 noun-adjective pairs. For our first experiment, we test our
method's ability to determine the state of each noun class separately against
other metrics for comparison. These metrics are cosine similarity, dot product,
product quantization, binary index, Naive Bayes, and a custom neural network.
Among these metrics, we found that our proposed BVM performs the best in
classifying the states for each noun. We then perform a second experiment where
we try using BVM to determine if it can differentiate adjectives from one
another for each adjective separately. We compared the abilities of BVM to
differentiate adjectives against the proposed method the MIT-States paper
suggests: using a logistic regression model. In the end, we did not find
conclusive evidence that our BVM metric could perform better than the logistic
regression model at discerning adjectives. Yet, we were able to find evidence
for possible improvements to our method; this leads to the chance of increasing
our method's accuracy through certain changes in our methodologies.

</details>


### [10] [Instance-level Performance Prediction for Long-form Generation Tasks](https://arxiv.org/abs/2509.07309)
*Chi-Yang Hsu,Alexander Braylan,Yiheng Su,Omar Alonso,Matthew Lease*

Main category: cs.CL

TL;DR: 提出了一个新的长文本生成任务性能预测基准，支持多维度细粒度质量指标，仅需黑盒模型输入输出即可预测连续评估分数，并在11个数据集上验证了有效性


<details>
  <summary>Details</summary>
Motivation: 需要为长文本生成任务建立实例级别的性能预测基准，该基准应该支持多维度细粒度质量指标，且仅依赖黑盒模型的输入输出

Method: 任务、模型和指标无关的框架，仅使用黑盒模型的输入输出来预测连续评估指标分数，同时要求推断预测区间来量化不确定性

Result: 在11个长文本数据集/任务上，使用多个LLM、基线和指标进行评估，结果显示仅需16个训练样本就能有效预测长文本生成任务的分数

Conclusion: 引入了一个新颖且有用的任务，提供了有价值的基准来推动进展，以及可供实际采用的基线方法

Abstract: We motivate and share a new benchmark for instance-level performance
prediction of long-form generation tasks having multi-faceted, fine-grained
quality metrics. Our task-, model- and metric-agnostic formulation predicts
continuous evaluation metric scores given only black-box model inputs and
outputs. Beyond predicting point estimates of metric scores, the benchmark also
requires inferring prediction intervals to quantify uncertainty around point
estimates. Evaluation spans 11 long-form datasets/tasks with multiple LLMs,
baselines, and metrics per task. We show that scores can be effectively
predicted across long-form generation tasks using as few as 16 training
examples. Overall, we introduce a novel and useful task, a valuable benchmark
to drive progress, and baselines ready for practical adoption today.

</details>


### [11] [Does This Look Familiar to You? Knowledge Analysis via Model Internal Representations](https://arxiv.org/abs/2509.07311)
*Sihyun Park*

Main category: cs.CL

TL;DR: KAMIR是一种基于模型内部表示的数据选择方法，通过分析隐藏状态相似度来评估数据对模型训练的价值，相比传统方法更高效且适用于多种任务类型。


<details>
  <summary>Details</summary>
Motivation: 当前SFT训练中缺乏有效的数据选择方法，传统基于知识的选择方法依赖提示工程，成本高且不稳定，需要更高效的数据评估方案。

Method: 提出KAMIR方法，通过计算每层隐藏状态与最终隐藏状态的相似度来评估数据，基于模型对输入的熟悉程度选择训练数据。

Result: 实验表明，使用不太熟悉的数据进行训练能获得更好的泛化性能，方法适用于机器阅读理解、摘要生成等多种任务。

Conclusion: KAMIR提供了一种高效、低成本的数据选择方案，能够提升SFT训练效果，具有广泛的适用性。

Abstract: Recent advances in large language models (LLMs) have been driven by
pretraining, supervised fine tuning (SFT), and alignment tuning. Among these,
SFT plays a crucial role in transforming a model 's general knowledge into
structured responses tailored to specific tasks. However, there is no clearly
established methodology for effective training data selection. Simply
increasing the volume of data does not guarantee performance improvements,
while preprocessing, sampling, and validation require substantial time and
cost.
  To address this issue, a variety of data selection methods have been
proposed. Among them, knowledge based selection approaches identify suitable
training data by analyzing the model 's responses. Nevertheless, these methods
typically rely on prompt engineering, making them sensitive to variations and
incurring additional costs for prompt design.
  In this study, we propose Knowledge Analysis via Model Internal
Representations (KAMIR), a novel approach that overcomes these limitations by
analyzing data based on the model 's internal representations. KAMIR computes
similarities between the hidden states of each layer (block) and the final
hidden states for a given input to assess the data. Unlike prior methods that
were largely limited to multiple choice tasks, KAMIR can be applied to a wide
range of tasks such as machine reading comprehension and summarization.
Moreover, it selects data useful for training based on the model 's familiarity
with the input, even with a small dataset and a simple classifier architecture.
Experiments across diverse task datasets demonstrate that training with less
familiar data leads to better generalization performance.

</details>


### [12] [Mitigating Attention Localization in Small Scale: Self-Attention Refinement via One-step Belief Propagation](https://arxiv.org/abs/2509.07324)
*Nakyung Lee,Yeongoon Kim,Minhae Oh,Suhwan Kim,Jin Woo Koo,Hyewon Jo,Jungwoo Lee*

Main category: cs.CL

TL;DR: 通过伪传播过程注入多跳关系，解决Transformer自注意力局部化问题，提升小规模模型性能


<details>
  <summary>Details</summary>
Motivation: 解决Transformer自注意力机制存在的局部化问题，让注意力集中在少数token上而无法抓取长距离依赖关系

Method: 提出SAOBP（Self-Attention One-step Belief Propagation）精炼框架，通过伪传播过程注入多跳关系，并引入GTD（Global Token Dependency）来量化多跳连接的相对贡献

Result: SAOBP能够防止深层的熵排崩溃，自适应地维持GTD在任务适当水平，小规模模型中表现竞争力强

Conclusion: 该方法有效解决了自注意力局部化问题，特别在资源受限场景下能够提升推理质量，具有实际应用价值

Abstract: Transformer-based self-attention mechanism serves as the core of modern
language models, yet it often suffers from localization, where attentions
collapse onto a limited subset of tokens and fail to capture long-range
dependencies. To address this issue, we propose Self-Attention One-step Belief
Propagation (SAOBP), a refinement framework that injects multi-hop
relationships through a belief propagation process. To interpret and quantify
these interactions, we introduce Global Token Dependency (GTD) that captures
the relative contribution of multihop connections within the attention graph.
Empirical results indicate that SAOBP helps prevent entropy collapse in deeper
layers and adaptively maintains GTD at task-appropriate levels, thereby
supporting improvements in model performance. Importantly, we observe
competitive gains in small-scale models, highlighting its potential for
improving inference quality in resource-constrained scenarios.

</details>


### [13] [PersonaFuse: A Personality Activation-Driven Framework for Enhancing Human-LLM Interactions](https://arxiv.org/abs/2509.07370)
*Yixuan Tang,Yi Yang,Ahmed Abbasi*

Main category: cs.CL

TL;DR: PersonaFuse是一个基于大五人格模型和特质激活理论的LLM后训练框架，通过混合专家架构实现情境化人格表达，显著提升社交情感智能而不损害通用推理能力。


<details>
  <summary>Details</summary>
Motivation: LLM在现实对话中表现出情感感知和社交能力的局限性，无法根据不同社交和任务情境调整沟通风格和情感表达。

Method: 基于特质激活理论和大五人格模型，采用混合专家架构，结合人格适配器和动态路由网络，实现情境化特质表达。

Result: 在社交情感智能多个维度上显著超越基线模型，在下游人本应用（如心理健康咨询和客户服务）中表现一致改善，人类偏好评估显示与领先LLM竞争性响应质量。

Conclusion: PersonaFuse为开发社交情感增强型LLM提供了理论基础和实用方法，是迈向更人本AI系统的重要进展。

Abstract: Recent advancements in Large Language Models (LLMs) demonstrate remarkable
capabilities across various fields. These developments have led to more direct
communication between humans and LLMs in various situations, such as social
companionship and psychological support. However, LLMs often exhibit
limitations in emotional perception and social competence during real-world
conversations. These limitations partly originate from their inability to adapt
their communication style and emotional expression to different social and task
contexts. In this work, we introduce PersonaFuse, a novel LLM post-training
framework that enables LLMs to adapt and express different personalities for
varying situations. Inspired by Trait Activation Theory and the Big Five
personality model, PersonaFuse employs a Mixture-of-Expert architecture that
combines persona adapters with a dynamic routing network, enabling contextual
trait expression. Experimental results show that PersonaFuse substantially
outperforms baseline models across multiple dimensions of social-emotional
intelligence. Importantly, these gains are achieved without sacrificing general
reasoning ability or model safety, which remain common limitations of direct
prompting and supervised fine-tuning approaches. PersonaFuse also delivers
consistent improvements in downstream human-centered applications, such as
mental health counseling and review-based customer service. Finally, human
preference evaluations against leading LLMs, including GPT-4o and DeepSeek,
demonstrate that PersonaFuse achieves competitive response quality despite its
comparatively smaller model size. These findings demonstrate that
PersonaFuse~offers a theoretically grounded and practical approach for
developing social-emotional enhanced LLMs, marking a significant advancement
toward more human-centric AI systems.

</details>


### [14] [Talking with Oompa Loompas: A novel framework for evaluating linguistic acquisition of LLM agents](https://arxiv.org/abs/2509.07389)
*Sankalp Tattwadarshi Swain,Anshika Krishnatray,Dhruv Kumar,Jagat Sesh Challa*

Main category: cs.CL

TL;DR: 大语言模型在通过交互反馈学习新语言方面表现差强，无法在100次回复内建立对话，但学习策略类似人类语言获取方式


<details>
  <summary>Details</summary>
Motivation: 现有研究主要测试语言模型的词汇、语法等能力，缺乏对通过交互反馈学习语言的评估，而这是人类语言获取的核心特征

Method: 设计了一种新的实验框架，让语言模型与只理解新构造语言Tinkatongue的机器人对话，评估其通过模式识别和交互反馈学习语言的能力

Result: 语言模型在100次回复内无法成功建立对话，但它们采用了与人类语言学习相似的策略

Conclusion: 研究为语言模型评测提供了新方向，并为设计更有效学习交互反馈的模型开启了新途径

Abstract: Existing evaluation studies on linguistic competence of large language models
(LLM agents) have focused primarily on vocabulary learning, morphological rule
induction, syntactic generalization, pragmatic inference, and cross-linguistic
transfer. However, none assess whether LLM agents can acquire a language
through pattern recognition and interactive feedback, a central feature of
human language acquisition. We propose a novel experimental framework in which
an LLM agent is evaluated on its ability to acquire and use a newly constructed
language (Tinkatongue) in conversation with a bot that understands only
Tinkatongue. Our findings show that LLM agents fail to establish a conversation
within 100 responses, yet they adopt distinct strategies that mirror human
approaches to language learning. The results suggest a new direction for
evaluation benchmarks and open pathways to model designs that learn more
effectively from interactive feedback.

</details>


### [15] [The Role of Exploration Modules in Small Language Models for Knowledge Graph Question Answering](https://arxiv.org/abs/2509.07399)
*Yi-Jie Cheng,Oscar Chew,Yun-Nung Chen*

Main category: cs.CL

TL;DR: 通过使用轻量级探索模块处理知识图遍历，提升小型语言模型在知识图问答任务中的性能


<details>
  <summary>Details</summary>
Motivation: 解决现有知识图集成方法对于小型语言模型的限制，特别是在知识图遍历和推理能力上的不足

Method: 提出使用简单高效的探索模块来处理知识图遍历，以替代语言模型本身的遍历能力

Result: 实验结果表明这些轻量级模块有效提升了小型语言模型在知识图问答任务中的表现

Conclusion: 通过外部探索模块来处理知识图遍历是一种有效的方法，可以充分发挥小型语言模型在知识图集成任务中的潜力

Abstract: Integrating knowledge graphs (KGs) into the reasoning processes of large
language models (LLMs) has emerged as a promising approach to mitigate
hallucination. However, existing work in this area often relies on proprietary
or extremely large models, limiting accessibility and scalability. In this
study, we investigate the capabilities of existing integration methods for
small language models (SLMs) in KG-based question answering and observe that
their performance is often constrained by their limited ability to traverse and
reason over knowledge graphs. To address this limitation, we propose leveraging
simple and efficient exploration modules to handle knowledge graph traversal in
place of the language model itself. Experiment results demonstrate that these
lightweight modules effectively improve the performance of small language
models on knowledge graph question answering tasks. Source code:
https://github.com/yijie-cheng/SLM-ToG/.

</details>


### [16] [LongEmotion: Measuring Emotional Intelligence of Large Language Models in Long-Context Interaction](https://arxiv.org/abs/2509.07403)
*Weichu Liu,Jing Xiong,Yuxuan Hu,Zixuan Li,Minghuan Tan,Ningning Mao,Chenyang Zhao,Zhongwei Wan,Chaofan Tao,Wendong Xu,Hui Shen,Chengming Li,Lingpeng Kong,Ngai Wong*

Main category: cs.CL

TL;DR: LongEmotion是一个专门为长上下文情感智能任务设计的基准测试，包含6个情感任务，平均输入长度8777个token，提出了RAG和CoEM方法来提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试忽视了长上下文场景下的情感智能评估，特别是在现实、实用的设置中，交互通常冗长、多样且嘈杂。

Method: 提出了Retrieval-Augmented Generation (RAG)方法，利用对话上下文和LLM本身作为检索源；以及Collaborative Emotional Modeling (CoEM)方法，将任务分解为五个阶段，结合检索增强和有限知识注入。

Result: 实验结果表明，RAG和CoEM方法在大多数长上下文任务中持续提升了情感智能相关性能，推动了LLMs向更实用和现实世界的情感智能应用发展。

Conclusion: LongEmotion基准测试填补了长上下文情感智能评估的空白，提出的RAG和CoEM方法有效提升了LLMs在现实场景中的情感智能表现，为实际应用提供了重要参考。

Abstract: Large language models (LLMs) make significant progress in Emotional
Intelligence (EI) and long-context understanding. However, existing benchmarks
tend to overlook certain aspects of EI in long-context scenarios, especially
under realistic, practical settings where interactions are lengthy, diverse,
and often noisy. To move towards such realistic settings, we present
LongEmotion, a benchmark specifically designed for long-context EI tasks. It
covers a diverse set of tasks, including Emotion Classification, Emotion
Detection, Emotion QA, Emotion Conversation, Emotion Summary, and Emotion
Expression. On average, the input length for these tasks reaches 8,777 tokens,
with long-form generation required for Emotion Expression. To enhance
performance under realistic constraints, we incorporate Retrieval-Augmented
Generation (RAG) and Collaborative Emotional Modeling (CoEM), and compare them
with standard prompt-based methods. Unlike conventional approaches, our RAG
method leverages both the conversation context and the large language model
itself as retrieval sources, avoiding reliance on external knowledge bases. The
CoEM method further improves performance by decomposing the task into five
stages, integrating both retrieval augmentation and limited knowledge
injection. Experimental results show that both RAG and CoEM consistently
enhance EI-related performance across most long-context tasks, advancing LLMs
toward more practical and real-world EI applications. Furthermore, we conducted
a comparative case study experiment on the GPT series to demonstrate the
differences among various models in terms of EI. Code is available on GitHub at
https://github.com/LongEmotion/LongEmotion, and the project page can be found
at https://longemotion.github.io/.

</details>


### [17] [AIxcellent Vibes at GermEval 2025 Shared Task on Candy Speech Detection: Improving Model Performance by Span-Level Training](https://arxiv.org/abs/2509.07459)
*Christian Rene Thelen,Patrick Gustav Blaneck,Tobias Bornheim,Niklas Grieger,Stephan Bialonski*

Main category: cs.CL

TL;DR: 多语言XLM-RoBERTa-Large模型在德语YouTube评论中成功检测支持性语言（candy speech），在二元分类和范围检测中都获得最佳性能。


<details>
  <summary>Details</summary>
Motivation: 网络社交媒体中的积极支持性语言（candy speech）能够促进文明沟通，但自动化检测方法研究不足，限制了对其影响的系统分析。

Method: 使用单语言和多语言语言模型（GBERT、Qwen3 Embedding、XLM-RoBERTa）在4.6万条德语YouTube评论中进行支持性语言检测实验。

Result: 多语言XLM-RoBERTa-Large模型在GermEval 2025任务中表现最佳，二元分类F1得分0.8906，范围检测严格F1得分0.6307。

Conclusion: 多语言模型通过范围基训练和表情符号识别能够有效检测积极支持性语言，为网络沟通质量分析提供了有力工具。

Abstract: Positive, supportive online communication in social media (candy speech) has
the potential to foster civility, yet automated detection of such language
remains underexplored, limiting systematic analysis of its impact. We
investigate how candy speech can be reliably detected in a 46k-comment German
YouTube corpus by monolingual and multilingual language models, including
GBERT, Qwen3 Embedding, and XLM-RoBERTa. We find that a multilingual
XLM-RoBERTa-Large model trained to detect candy speech at the span level
outperforms other approaches, ranking first in both binary positive F1: 0.8906)
and categorized span-based detection (strict F1: 0.6307) subtasks at the
GermEval 2025 Shared Task on Candy Speech Detection. We speculate that
span-based training, multilingual capabilities, and emoji-aware tokenizers
improved detection performance. Our results demonstrate the effectiveness of
multilingual models in identifying positive, supportive language.

</details>


### [18] [Understanding Stigmatizing Language Lexicons: A Comparative Analysis in Clinical Contexts](https://arxiv.org/abs/2509.07462)
*Yiliang Zhou,Di Hu,Tianchu Lyu,Jasmine Dhillon,Alexandra L. Beck,Gelareh Sadigh,Kai Zheng*

Main category: cs.CL

TL;DR: 系统文献回顾发现4个污名化语言词典，分析显示它们具有中等语义相似性，大多数污名化术语与临床医生描述负面行为的评判性表达相关，情感分析以负面词汇为主但存在差异，突显了标准化词典的需求和临床文本中定义污名化语言的挑战。


<details>
  <summary>Details</summary>
Motivation: 污名化语言导致医疗不平等，但目前缺乏普遍接受的标准词典来定义医疗环境中的污名化词汇、术语和短语。

Method: 通过系统文献检索识别现有污名化语言词典，进行对比分析：1）词典间的相似性和差异；2）基于既定情感数据集的正面、负面或中性术语分布。

Result: 识别出4个词典，分析显示它们具有中等语义相似性，大多数污名化术语涉及临床医生描述感知负面行为的评判性表达。情感分析显示负面分类术语占主导地位，但各词典间存在差异。

Conclusion: 研究结果强调了标准化词典的必要性，并突显了在临床文本中定义污名化语言所面临的挑战。

Abstract: Stigmatizing language results in healthcare inequities, yet there is no
universally accepted or standardized lexicon defining which words, terms, or
phrases constitute stigmatizing language in healthcare. We conducted a
systematic search of the literature to identify existing stigmatizing language
lexicons and then analyzed them comparatively to examine: 1) similarities and
discrepancies between these lexicons, and 2) the distribution of positive,
negative, or neutral terms based on an established sentiment dataset. Our
search identified four lexicons. The analysis results revealed moderate
semantic similarity among them, and that most stigmatizing terms are related to
judgmental expressions by clinicians to describe perceived negative behaviors.
Sentiment analysis showed a predominant proportion of negatively classified
terms, though variations exist across lexicons. Our findings underscore the
need for a standardized lexicon and highlight challenges in defining
stigmatizing language in clinical texts.

</details>


### [19] [From Scarcity to Efficiency: Investigating the Effects of Data Augmentation on African Machine Translation](https://arxiv.org/abs/2509.07471)
*Mardiyyah Oduwole,Oluwatosin Olajide,Jamiu Suleiman,Faith Hunja,Busayo Awobade,Fatimo Adebanjo,Comfort Akanni,Chinonyelum Igwe,Peace Ododo,Promise Omoigui,Steven Kolawole,Abraham Owodunni*

Main category: cs.CL

TL;DR: 本研究探索了数据增强技术（句子拼接与回译、switch-out）对低资源非洲语言机器翻译的改进效果，在六种语言上BLEU分数至少提升25%


<details>
  <summary>Details</summary>
Motivation: 非洲大陆的语言多样性给机器翻译带来挑战和机遇，需要改进低资源语言的翻译系统

Method: 采用两种数据增强技术：句子拼接与回译、switch-out，在六种非洲语言上进行实验

Result: 所有六种语言的机器翻译性能显著提升，BLEU分数至少增加25%

Conclusion: 这些技术有潜力改善低资源语言的机器翻译系统，有助于为资源不足语言开发更鲁棒的翻译系统

Abstract: The linguistic diversity across the African continent presents different
challenges and opportunities for machine translation. This study explores the
effects of data augmentation techniques in improving translation systems in
low-resource African languages. We focus on two data augmentation techniques:
sentence concatenation with back translation and switch-out, applying them
across six African languages. Our experiments show significant improvements in
machine translation performance, with a minimum increase of 25\% in BLEU score
across all six languages.We provide a comprehensive analysis and highlight the
potential of these techniques to improve machine translation systems for
low-resource languages, contributing to the development of more robust
translation systems for under-resourced languages.

</details>


### [20] [HALT-RAG: A Task-Adaptable Framework for Hallucination Detection with Calibrated NLI Ensembles and Abstention](https://arxiv.org/abs/2509.07475)
*Saumya Goswami,Siddharth Kurra*

Main category: cs.CL

TL;DR: HALT-RAG是一个后验验证系统，使用NLI模型和词汇特征来检测RAG管道输出中的幻觉内容，在多个任务上实现了高F1分数。


<details>
  <summary>Details</summary>
Motivation: 检测生成语言模型输出中与源文本矛盾或不受支持的内容，对于模型的安全部署至关重要。

Method: 使用两个冻结的现成NLI模型和轻量级词汇信号构建通用特征集，训练简单校准的任务适配元分类器，采用5折交叉验证防止数据泄漏。

Result: 在HaluEval基准测试中，摘要、问答和对话任务的OOF F1分数分别达到0.7756、0.9786和0.7391。

Conclusion: 系统经过良好校准的概率实现了实用的弃权机制，为平衡模型性能和安全需求提供了可靠工具。

Abstract: Detecting content that contradicts or is unsupported by a given source text
is a critical challenge for the safe deployment of generative language models.
We introduce HALT-RAG, a post-hoc verification system designed to identify
hallucinations in the outputs of Retrieval-Augmented Generation (RAG)
pipelines. Our flexible and task-adaptable framework uses a universal feature
set derived from an ensemble of two frozen, off-the-shelf Natural Language
Inference (NLI) models and lightweight lexical signals. These features are used
to train a simple, calibrated, and task-adapted meta-classifier. Using a
rigorous 5-fold out-of-fold (OOF) training protocol to prevent data leakage and
produce unbiased estimates, we evaluate our system on the HaluEval benchmark.
By pairing our universal feature set with a lightweight, task-adapted
classifier and a precision-constrained decision policy, HALT-RAG achieves
strong OOF F1-scores of 0.7756, 0.9786, and 0.7391 on the summarization, QA,
and dialogue tasks, respectively. The system's well-calibrated probabilities
enable a practical abstention mechanism, providing a reliable tool for
balancing model performance with safety requirements.

</details>


### [21] [ALLabel: Three-stage Active Learning for LLM-based Entity Recognition using Demonstration Retrieval](https://arxiv.org/abs/2509.07512)
*Zihan Chen,Lei Shi,Weize Wu,Qiji Zhou,Yue Zhang*

Main category: cs.CL

TL;DR: ALLabel是一个三阶段主动学习框架，通过选择最具信息量和代表性的样本来构建LLM的上下文学习演示，在相同标注预算下优于所有基线方法，仅需标注5%-10%的数据即可达到全量标注的性能。


<details>
  <summary>Details</summary>
Motivation: 解决科学领域实体识别任务中LLM微调成本高的问题，寻求性能与成本的最佳平衡

Method: 提出三阶段主动学习框架，依次采用三种不同的主动学习策略选择样本，构建真实检索语料库用于LLM上下文学习

Result: 在三个专业领域数据集上，ALLabel在相同标注预算下始终优于所有基线方法，仅标注5%-10%数据即可达到全量标注性能

Conclusion: ALLabel框架有效且具有通用性，能够显著降低标注成本同时保持高性能

Abstract: Many contemporary data-driven research efforts in the natural sciences, such
as chemistry and materials science, require large-scale, high-performance
entity recognition from scientific datasets. Large language models (LLMs) have
increasingly been adopted to solve the entity recognition task, with the same
trend being observed on all-spectrum NLP tasks. The prevailing entity
recognition LLMs rely on fine-tuned technology, yet the fine-tuning process
often incurs significant cost. To achieve a best performance-cost trade-off, we
propose ALLabel, a three-stage framework designed to select the most
informative and representative samples in preparing the demonstrations for LLM
modeling. The annotated examples are used to construct a ground-truth retrieval
corpus for LLM in-context learning. By sequentially employing three distinct
active learning strategies, ALLabel consistently outperforms all baselines
under the same annotation budget across three specialized domain datasets.
Experimental results also demonstrate that selectively annotating only 5\%-10\%
of the dataset with ALLabel can achieve performance comparable to the method
annotating the entire dataset. Further analyses and ablation studies verify the
effectiveness and generalizability of our proposal.

</details>


### [22] [VeriOS: Query-Driven Proactive Human-Agent-GUI Interaction for Trustworthy OS Agents](https://arxiv.org/abs/2509.07553)
*Zheng Wu,Heyuan Huang,Xingyu Lou,Xiangmou Qu,Pengzhou Cheng,Zongru Wu,Weiwen Liu,Weinan Zhang,Jun Wang,Zhaoxiang Wang,Zhuosheng Zhang*

Main category: cs.CL

TL;DR: 提出VeriOS-Agent，一个可信的操作系统代理，通过查询驱动的人机交互框架在不可信环境下主动询问人类，提高任务执行可靠性


<details>
  <summary>Details</summary>
Motivation: 现有操作系统代理主要针对理想化环境设计，而现实世界环境往往存在不可信条件，需要避免过度执行的风险

Method: 采用两阶段学习范式的查询驱动人机-GUI交互框架，在正常条件下自主执行动作，在不可信场景中主动查询人类

Result: 在不可信场景中平均步骤成功率比最先进方法提高20.64%，且不影响正常性能表现

Conclusion: VeriOS-Agent展现出良好的合理性、泛化性和可扩展性，为可信操作系统代理提供了有效解决方案

Abstract: With the rapid progress of multimodal large language models, operating system
(OS) agents become increasingly capable of automating tasks through on-device
graphical user interfaces (GUIs). However, most existing OS agents are designed
for idealized settings, whereas real-world environments often present
untrustworthy conditions. To mitigate risks of over-execution in such
scenarios, we propose a query-driven human-agent-GUI interaction framework that
enables OS agents to decide when to query humans for more reliable task
completion. Built upon this framework, we introduce VeriOS-Agent, a trustworthy
OS agent trained with a two-stage learning paradigm that falicitate the
decoupling and utilization of meta-knowledge. Concretely, VeriOS-Agent
autonomously executes actions in normal conditions while proactively querying
humans in untrustworthy scenarios. Experiments show that VeriOS-Agent improves
the average step-wise success rate by 20.64\% in untrustworthy scenarios over
the state-of-the-art, without compromising normal performance. Analysis
highlights VeriOS-Agent's rationality, generalizability, and scalability. The
codes, datasets and models are available at
https://github.com/Wuzheng02/VeriOS.

</details>


### [23] [Avoiding Knowledge Edit Skipping in Multi-hop Question Answering with Guided Decomposition](https://arxiv.org/abs/2509.07555)
*Yi Liu,Xiangrong Zhu,Xiangyu Liu,Wei Wei,Wei Hu*

Main category: cs.CL

TL;DR: 本文提出IRAKE方法，通过引导分解和迭代检索来解决多跳问答中知识编辑的"编辑跳过"问题，在保持参数不变的情况下有效更新LLM知识。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的知识快速过时，重新训练成本高昂，需要无需修改参数的知识编辑方法。现有基于检索增强生成的方法在处理多跳问答时存在"编辑跳过"问题，无法有效利用编辑后的知识。

Method: 提出迭代检索增强知识编辑方法(IRAKE)，通过单编辑事实和完整编辑案例的引导进行分解，采用迭代检索机制来解决粒度不匹配和自然语言表达多样性问题。

Result: 实验结果表明IRAKE能够有效缓解编辑跳过导致的编辑失败，在多跳问答知识编辑任务上优于现有最先进方法。

Conclusion: IRAKE方法通过引导分解和迭代检索成功解决了多跳问答中的知识编辑挑战，为无需参数修改的知识更新提供了有效解决方案。

Abstract: In a rapidly evolving world where information updates swiftly, knowledge in
large language models (LLMs) becomes outdated quickly. Retraining LLMs is not a
cost-effective option, making knowledge editing (KE) without modifying
parameters particularly necessary. We find that although existing
retrieval-augmented generation (RAG)-based KE methods excel at editing simple
knowledge, they struggle with KE in multi-hop question answering due to the
issue of "edit skipping", which refers to skipping the relevant edited fact in
inference. In addition to the diversity of natural language expressions of
knowledge, edit skipping also arises from the mismatch between the granularity
of LLMs in problem-solving and the facts in the edited memory. To address this
issue, we propose a novel Iterative Retrieval-Augmented Knowledge Editing
method with guided decomposition (IRAKE) through the guidance from single
edited facts and entire edited cases. Experimental results demonstrate that
IRAKE mitigates the failure of editing caused by edit skipping and outperforms
state-of-the-art methods for KE in multi-hop question answering.

</details>


### [24] [BALI: Enhancing Biomedical Language Representations through Knowledge Graph and Language Model Alignment](https://arxiv.org/abs/2509.07588)
*Andrey Sakhovskiy,Elena Tutubalina*

Main category: cs.CL

TL;DR: BALI是一种新颖的联合语言模型和知识图谱预训练方法，通过同时学习专用KG编码器和对齐LM与图谱表示，将外部知识增强到语言模型中，提升生物医学文本理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有生物医学LLM对复杂领域特定概念结构和生物医学知识图谱中编码的事实信息理解有限，需要更好的方法来整合外部知识。

Method: 提出BALI方法：1）将生物医学概念提及链接到UMLS知识图谱；2）使用局部KG子图作为跨模态正样本；3）同时训练专用KG编码器并对齐LM和图谱表示。

Result: 在PubMedBERT和BioLinkBERT等领先生物医学LM上实施该方法，即使在小规模PubMed摘要对齐数据集上进行最小预训练，也能提升语言理解任务性能和实体表示质量。

Conclusion: BALI方法有效增强了生物医学语言模型的外部知识整合能力，通过知识图谱对齐显著提升了模型在生物医学文本理解任务中的表现。

Abstract: In recent years, there has been substantial progress in using pretrained
Language Models (LMs) on a range of tasks aimed at improving the understanding
of biomedical texts. Nonetheless, existing biomedical LLMs show limited
comprehension of complex, domain-specific concept structures and the factual
information encoded in biomedical Knowledge Graphs (KGs). In this work, we
propose BALI (Biomedical Knowledge Graph and Language Model Alignment), a novel
joint LM and KG pre-training method that augments an LM with external knowledge
by the simultaneous learning of a dedicated KG encoder and aligning the
representations of both the LM and the graph. For a given textual sequence, we
link biomedical concept mentions to the Unified Medical Language System (UMLS)
KG and utilize local KG subgraphs as cross-modal positive samples for these
mentions. Our empirical findings indicate that implementing our method on
several leading biomedical LMs, such as PubMedBERT and BioLinkBERT, improves
their performance on a range of language understanding tasks and the quality of
entity representations, even with minimal pre-training on a small alignment
dataset sourced from PubMed scientific abstracts.

</details>


### [25] [MaLei at MultiClinSUM: Summarisation of Clinical Documents using Perspective-Aware Iterative Self-Prompting with LLMs](https://arxiv.org/abs/2509.07622)
*Libo Ren,Yee Man Ng,Lifeng Han*

Main category: cs.CL

TL;DR: 这篇论文提出了一种迭代自我提示技术，用于大语言模型的临床报呆摘要任务，在MultiClinSUM共享任务中获得了良好的语义类似性结果。


<details>
  <summary>Details</summary>
Motivation: 临床报呆长缠且包含专业术语，影响医生与病人之间的沟通效率和共同决策。需要一种能够高效识别重要信息的摘要方法。

Method: 采用迭代自我提示技术（ISP），让大语言模型通过少量示例学习生成和精炼任务特定提示。使用ROUGE和BERT-score指标指导模型微调。

Result: 在3,396份多学科临床案例报呆上，使用GPT-4和GPT-4o的视角感知ISP方法获得了ROUGE分数（46.53, 24.68, 30.77）和BERTscore（87.84, 83.25, 85.46），表明生成的摘要在语义上与参考摘要高度类似。

Conclusion: 视角感知迭代自我提示技术（PA-ISP）可以有效应用于临床报呆摘要，支持更好的医患沟通，虽然词汇层面的重叠度较低，但语义类似性很高。

Abstract: Efficient communication between patients and clinicians plays an important
role in shared decision-making. However, clinical reports are often lengthy and
filled with clinical jargon, making it difficult for domain experts to identify
important aspects in the document efficiently. This paper presents the
methodology we applied in the MultiClinSUM shared task for summarising clinical
case documents. We used an Iterative Self-Prompting technique on large language
models (LLMs) by asking LLMs to generate task-specific prompts and refine them
via example-based few-shot learning. Furthermore, we used lexical and embedding
space metrics, ROUGE and BERT-score, to guide the model fine-tuning with
epochs. Our submission using perspective-aware ISP on GPT-4 and GPT-4o achieved
ROUGE scores (46.53, 24.68, 30.77) and BERTscores (87.84, 83.25, 85.46) for (P,
R, F1) from the official evaluation on 3,396 clinical case reports from various
specialties extracted from open journals. The high BERTscore indicates that the
model produced semantically equivalent output summaries compared to the
references, even though the overlap at the exact lexicon level is lower, as
reflected in the lower ROUGE scores. This work sheds some light on how
perspective-aware ISP (PA-ISP) can be deployed for clinical report
summarisation and support better communication between patients and clinicians.

</details>


### [26] [MoLoRAG: Bootstrapping Document Understanding via Multi-modal Logic-aware Retrieval](https://arxiv.org/abs/2509.07666)
*Xixi Wu,Yanchao Tan,Nan Hou,Ruiyang Zhang,Hong Cheng*

Main category: cs.CL

TL;DR: MoLoRAG是一个逻辑感知的检索框架，通过构建页面图来捕捉页面间的上下文关系，结合语义和逻辑相关性进行多模态多页文档理解，在DocQA任务上相比基线方法有显著提升。


<details>
  <summary>Details</summary>
Motivation: 传统方法将文档转换为文本处理会丢失多模态信息（如图表），而大型视觉语言模型受限于输入长度无法处理多页文档。现有的检索增强生成方法仅依赖语义相关性，忽略了页面间的逻辑连接，这对于推理至关重要。

Method: 构建页面图捕捉页面间上下文关系，使用轻量级视觉语言模型进行图遍历检索相关页面（包括常被忽略的逻辑连接页面），结合语义和逻辑相关性。提供训练免费和微调两种变体，检索后使用任意LVLM进行问答。

Result: 在四个DocQA数据集上的实验显示，相比LVLM直接推理平均准确率提升9.68%，相比基线方法检索精度提升7.44%。

Conclusion: MoLoRAG通过结合语义和逻辑相关性，有效解决了多模态多页文档理解中的检索问题，显著提升了文档问答的性能。

Abstract: Document Understanding is a foundational AI capability with broad
applications, and Document Question Answering (DocQA) is a key evaluation task.
Traditional methods convert the document into text for processing by Large
Language Models (LLMs), but this process strips away critical multi-modal
information like figures. While Large Vision-Language Models (LVLMs) address
this limitation, their constrained input size makes multi-page document
comprehension infeasible. Retrieval-augmented generation (RAG) methods mitigate
this by selecting relevant pages, but they rely solely on semantic relevance,
ignoring logical connections between pages and the query, which is essential
for reasoning.
  To this end, we propose MoLoRAG, a logic-aware retrieval framework for
multi-modal, multi-page document understanding. By constructing a page graph
that captures contextual relationships between pages, a lightweight VLM
performs graph traversal to retrieve relevant pages, including those with
logical connections often overlooked. This approach combines semantic and
logical relevance to deliver more accurate retrieval. After retrieval, the
top-$K$ pages are fed into arbitrary LVLMs for question answering. To enhance
flexibility, MoLoRAG offers two variants: a training-free solution for easy
deployment and a fine-tuned version to improve logical relevance checking.
Experiments on four DocQA datasets demonstrate average improvements of 9.68% in
accuracy over LVLM direct inference and 7.44% in retrieval precision over
baselines. Codes and datasets are released at
https://github.com/WxxShirley/MoLoRAG.

</details>


### [27] [M-BRe: Discovering Training Samples for Relation Extraction from Unlabeled Texts with Large Language Models](https://arxiv.org/abs/2509.07730)
*Zexuan Li,Hongliang Dai,Piji Li*

Main category: cs.CL

TL;DR: 提出了M-BRe框架，通过关系分组、关系提取和标签决策三个模块，结合多分类和二分类方法的优势，从未标注文本中自动提取高质量的关系抽取训练样本。


<details>
  <summary>Details</summary>
Motivation: 关系抽取中手动标注训练数据成本高昂，且包含目标关系的句子稀少难找。现有LLM方法在多分类设置下难以全面捕捉关系语义，而二分类方法计算开销过大。

Method: 使用三个模块：关系分组模块将关系类别分组，关系提取模块进行多分类关系识别，标签决策模块通过二分类验证和精炼预测结果。

Result: 大量实验证实该框架能够从未标注文本中发现高质量的训练样本，在关系抽取任务上表现出优越性能。

Conclusion: M-BRe框架有效解决了LLM在关系抽取中的语义捕捉不全面和计算复杂度高的问题，为自动提取训练实例提供了实用解决方案。

Abstract: For Relation Extraction (RE), the manual annotation of training data may be
prohibitively expensive, since the sentences that contain the target relations
in texts can be very scarce and difficult to find. It is therefore beneficial
to develop an efficient method that can automatically extract training
instances from unlabeled texts for training RE models. Recently, large language
models (LLMs) have been adopted in various natural language processing tasks,
with RE also benefiting from their advances. However, when leveraging LLMs for
RE with predefined relation categories, two key challenges arise. First, in a
multi-class classification setting, LLMs often struggle to comprehensively
capture the semantics of every relation, leading to suboptimal results. Second,
although employing binary classification for each relation individually can
mitigate this issue, it introduces significant computational overhead,
resulting in impractical time complexity for real-world applications.
Therefore, this paper proposes a framework called M-BRe to extract training
instances from unlabeled texts for RE. It utilizes three modules to combine the
advantages of both of the above classification approaches: Relation Grouping,
Relation Extraction, and Label Decision. Extensive experiments confirm its
superior capability in discovering high-quality training samples from unlabeled
texts for RE.

</details>


### [28] [Factuality Beyond Coherence: Evaluating LLM Watermarking Methods for Medical Texts](https://arxiv.org/abs/2509.07755)
*Rochana Prih Hastuti,Rian Adam Rajagede,Mansour Al Ghanim,Mengxin Zheng,Qian Lou*

Main category: cs.CL

TL;DR: 医学领域水印技术存在事实性风险，现有方法在低熵异情况下会严重影响医学内容的准确性


<details>
  <summary>Details</summary>
Motivation: 大语言模型在医学等敏感领域应用时，流畅性带来了来源和负责风险，水印技术的可靠性在医学情境中未经验证

Method: 提出了一个医学专门评估流程，联合评估事实准确性和连贯性，使用GPT-Judger和人工验证，并引入事实性加权分数(FWS)综合指标

Result: 评估显示当前水印方法严重影响医学事实性，熵异移动导致医学实体表达退化

Conclusion: 医学领域需要域知觉水印方法，以确保医学内容的完整性和准确性

Abstract: As large language models (LLMs) adapted to sensitive domains such as
medicine, their fluency raises safety risks, particularly regarding provenance
and accountability. Watermarking embeds detectable patterns to mitigate these
risks, yet its reliability in medical contexts remains untested. Existing
benchmarks focus on detection-quality tradeoffs, overlooking factual risks
under low-entropy settings often exploited by watermarking's reweighting
strategy. We propose a medical-focused evaluation workflow that jointly
assesses factual accuracy and coherence. Using GPT-Judger and further human
validation, we introduce the Factuality-Weighted Score (FWS), a composite
metric prioritizing factual accuracy beyond coherence to guide watermarking
deployment in medical domains. Our evaluation shows current watermarking
methods substantially compromise medical factuality, with entropy shifts
degrading medical entity representation. These findings underscore the need for
domain-aware watermarking approaches that preserve the integrity of medical
content.

</details>


### [29] [Are LLMs Enough for Hyperpartisan, Fake, Polarized and Harmful Content Detection? Evaluating In-Context Learning vs. Fine-Tuning](https://arxiv.org/abs/2509.07768)
*Michele Joshua Maggini,Dhia Merzougui,Rabiraj Bandyopadhyay,Gaël Dias,Fabrice Maurel,Pablo Gamallo*

Main category: cs.CL

TL;DR: 本研究全面评估了大型语言模型在不同范式下检测虚假新闻、有害内容和政治偏见的性能，发现微调方法通常优于上下文学习，即使是较小的微调模型也能超越大型模型的上下文学习表现。


<details>
  <summary>Details</summary>
Motivation: 在线平台上虚假新闻、极化内容和有害信息的传播已成为严重问题，但目前缺乏对不同大语言模型、使用方法和语言在检测这些内容方面的系统性基准研究。

Method: 研究在10个数据集和5种语言上测试了多种方法，包括参数高效微调、零样本提示、代码本、少样本学习（随机选择和多样性选择）、思维链等不同的上下文学习策略。

Result: 实验发现上下文学习通常表现不如模型微调，即使是较小的微调模型也能超越大型模型（如LlaMA3.1-8b-Instruct、Mistral-Nemo-Instruct-2407和Qwen2.5-7B-Instruct）在上下文学习设置下的表现。

Conclusion: 研究强调了在特定任务设置下对模型进行微调的重要性，即使与最大的上下文学习模型相比，微调较小的模型也能获得更好的性能。

Abstract: The spread of fake news, polarizing, politically biased, and harmful content
on online platforms has been a serious concern. With large language models
becoming a promising approach, however, no study has properly benchmarked their
performance across different models, usage methods, and languages. This study
presents a comprehensive overview of different Large Language Models adaptation
paradigms for the detection of hyperpartisan and fake news, harmful tweets, and
political bias. Our experiments spanned 10 datasets and 5 different languages
(English, Spanish, Portuguese, Arabic and Bulgarian), covering both binary and
multiclass classification scenarios. We tested different strategies ranging
from parameter efficient Fine-Tuning of language models to a variety of
different In-Context Learning strategies and prompts. These included zero-shot
prompts, codebooks, few-shot (with both randomly-selected and
diversely-selected examples using Determinantal Point Processes), and
Chain-of-Thought. We discovered that In-Context Learning often underperforms
when compared to Fine-Tuning a model. This main finding highlights the
importance of Fine-Tuning even smaller models on task-specific settings even
when compared to the largest models evaluated in an In-Context Learning setup -
in our case LlaMA3.1-8b-Instruct, Mistral-Nemo-Instruct-2407 and
Qwen2.5-7B-Instruct.

</details>


### [30] [SciNLP: A Domain-Specific Benchmark for Full-Text Scientific Entity and Relation Extraction in NLP](https://arxiv.org/abs/2509.07801)
*Decheng Duan,Yingyi Zhang,Jitong Peng,Chengzhi Zhang*

Main category: cs.CL

TL;DR: SciNLP是一个专门用于NLP领域全文实体和关系抽取的基准数据集，包含60篇人工标注的全文NLP出版物，涵盖7072个实体和1826个关系，是首个提供NLP领域全文实体关系标注的数据集。


<details>
  <summary>Details</summary>
Motivation: 现有数据集大多局限于特定出版物章节，由于领域复杂性和科学文本标注成本高，缺乏完整的全文标注数据集，限制了结构化信息抽取在科学文献中的应用。

Method: 构建包含60篇NLP全文出版物的人工标注数据集，涵盖7072个实体和1826个关系，并进行对比实验验证数据集有效性，使用最先进的监督模型进行评估。

Result: 实验结果显示现有模型在不同长度学术文本上的抽取能力存在差异，与现有数据集交叉比较表明SciNLP在某些基线模型上实现了显著性能提升，基于SciNLP训练的模型构建的NLP领域知识图谱平均节点度为3.2，具有丰富的语义拓扑信息。

Conclusion: SciNLP填补了NLP领域全文实体关系抽取数据集的空白，为捕获专业领域核心概念和新兴趋势提供了重要资源，增强了下游应用的能力，数据集已公开发布。

Abstract: Structured information extraction from scientific literature is crucial for
capturing core concepts and emerging trends in specialized fields. While
existing datasets aid model development, most focus on specific publication
sections due to domain complexity and the high cost of annotating scientific
texts. To address this limitation, we introduce SciNLP - a specialized
benchmark for full-text entity and relation extraction in the Natural Language
Processing (NLP) domain. The dataset comprises 60 manually annotated full-text
NLP publications, covering 7,072 entities and 1,826 relations. Compared to
existing research, SciNLP is the first dataset providing full-text annotations
of entities and their relationships in the NLP domain. To validate the
effectiveness of SciNLP, we conducted comparative experiments with similar
datasets and evaluated the performance of state-of-the-art supervised models on
this dataset. Results reveal varying extraction capabilities of existing models
across academic texts of different lengths. Cross-comparisons with existing
datasets show that SciNLP achieves significant performance improvements on
certain baseline models. Using models trained on SciNLP, we implemented
automatic construction of a fine-grained knowledge graph for the NLP domain.
Our KG has an average node degree of 3.2 per entity, indicating rich semantic
topological information that enhances downstream applications. The dataset is
publicly available at https://github.com/AKADDC/SciNLP.

</details>


### [31] [Dual Knowledge-Enhanced Two-Stage Reasoner for Multimodal Dialog Systems](https://arxiv.org/abs/2509.07817)
*Xiaolin Chen,Xuemeng Song,Haokun Wen,Weili Guan,Xiangyu Zhao,Liqiang Nie*

Main category: cs.CL

TL;DR: 这篇论文提出了DK2R模型，通过充分利用结构化属性和非结构化评论双重知识，结合大语言模型的两阶段推理机制，提升多模态任务对话系统的文本回应生成能力。


<details>
  <summary>Details</summary>
Motivation: 现有多模态任务对话系统存在两个主要问题：忽视了非结构化评论知识，以及没有充分利用大语言模型的潜力。为了充分利用结构化属性和非结构化评论这双重知识来提升文本回应生成的质量。

Method: 提出DK2R模型：1）从外部知识库提取结构化属性和非结构化评论知识；2）使用LLM分析各种知识类型的有用性（通过生成探测回应）；3）分离总结意图导向的关键线索，作为辅助信号增强LLM的文本回应生成。

Result: 在公开数据集上进行了大量实验，验证了DK2R的优越性。代码和参数已经开源。

Conclusion: DK2R通过有效结合双重知识源和大语言模型的两阶段推理机制，成功解决了动态知识类型选择和意图-回应解耦合这两个关键挑战，显著提升了多模态任务对话系统的文本回应生成性能。

Abstract: Textual response generation is pivotal for multimodal \mbox{task-oriented}
dialog systems, which aims to generate proper textual responses based on the
multimodal context. While existing efforts have demonstrated remarkable
progress, there still exist the following limitations: 1) \textit{neglect of
unstructured review knowledge} and 2) \textit{underutilization of large
language models (LLMs)}. Inspired by this, we aim to fully utilize dual
knowledge (\textit{i.e., } structured attribute and unstructured review
knowledge) with LLMs to promote textual response generation in multimodal
task-oriented dialog systems. However, this task is non-trivial due to two key
challenges: 1) \textit{dynamic knowledge type selection} and 2)
\textit{intention-response decoupling}. To address these challenges, we propose
a novel dual knowledge-enhanced two-stage reasoner by adapting LLMs for
multimodal dialog systems (named DK2R). To be specific, DK2R first extracts
both structured attribute and unstructured review knowledge from external
knowledge base given the dialog context. Thereafter, DK2R uses an LLM to
evaluate each knowledge type's utility by analyzing LLM-generated provisional
probe responses. Moreover, DK2R separately summarizes the intention-oriented
key clues via dedicated reasoning, which are further used as auxiliary signals
to enhance LLM-based textual response generation. Extensive experiments
conducted on a public dataset verify the superiority of DK2R. We have released
the codes and parameters.

</details>


### [32] [Small Open Models Achieve Near Parity with Large Models in Low Resource Literary Translation at a Fraction of the Cost](https://arxiv.org/abs/2509.07829)
*Mihai Nadas,Laura Diosan,Andreea Tomescu,Andrei Piscoran*

Main category: cs.CL

TL;DR: 提出了TINYFABULIST TRANSLATION FRAMEWORK (TF2)，一个用于英罗文学翻译的统一框架，包括数据集创建、微调和评估，并发布了12B参数的微调模型和大型合成平行数据集。


<details>
  <summary>Details</summary>
Motivation: 解决小规模开源模型在文学翻译领域的性能问题，为低资源语言（如罗马尼亚语）提供高质量文学数据集和高效的翻译模型。

Method: 采用两阶段微调过程：首先使用高性能LLM生成15k高质量罗马尼亚语参考译文，然后对12B参数模型进行指令调优以捕捉特定体裁的叙事风格，最后使用适配器压缩实现高效部署。

Result: 微调后的模型在流畅性和准确性方面与顶级专有大模型相竞争，同时具有开源、易获取和显著成本效益的优势。

Conclusion: TF2提供了一个端到端、可复现的流程，用于研究成本效益高的翻译、跨语言叙事生成，以及在低资源环境中广泛采用开源模型处理具有文化意义的文学内容。

Abstract: Literary translation has recently gained attention as a distinct and complex
task in machine translation research. However, the translation by small open
models remains an open problem. We contribute to this ongoing research by
introducing TINYFABULIST TRANSLATION FRAMEWORK (TF2), a unified framework for
dataset creation, fine tuning, and evaluation in English-Romanian literary
translations, centred on the creation and open release of both a compact, fine
tuned language model (TF2-12B) and large scale synthetic parallel datasets
(DS-TF2-EN-RO-3M and DS-TF2-EN-RO-15K). Building on DS-TF1-EN-3M (TF1), the
largest collection of synthetic English fables to date, we address the need for
rich, high quality literary datasets in low resource languages such as
Romanian. Our pipeline first generates 15k high quality Romanian references
from the TF1 pool using a high performing LLM. We then apply a two stage fine
tuning process to a 12B parameter open weight model: (i) instruction tuning to
capture genre specific narrative style, and (ii) adapter compression for
efficient deployment. Evaluation combines corpus level BLEU and a five
dimension LLM based rubric (accuracy, fluency, coherence, style, cultural
adaptation) to provide a nuanced assessment of translation quality. Results
show that our fine tuned model achieves fluency and adequacy competitive with
top performing large proprietary models, while being open, accessible, and
significantly more cost effective. Alongside the fine tuned model and both
datasets, we publicly release all scripts and evaluation prompts. TF2 thus
provides an end-to-end, reproducible pipeline for research on cost efficient
translation, cross lingual narrative generation, and the broad adoption of open
models for culturally significant literary content in low resource settings.

</details>


### [33] [Are Humans as Brittle as Large Language Models?](https://arxiv.org/abs/2509.07869)
*Jiahui Li,Sean Papay,Roman Klinger*

Main category: cs.CL

TL;DR: 本文比较了人类标注者和大型语言模型对提示修改的敏感性，发现两者都对标签集和标签格式的变化表现出脆弱性，但人类对拼写错误和标签顺序反转的敏感性低于LLM。


<details>
  <summary>Details</summary>
Motivation: 研究人类标注者是否与LLM一样对指令变化敏感，探讨LLM的提示脆弱性是否反映了人类标注的固有方差。

Method: 通过文本分类任务，对LLM和人类标注者使用相同的提示变体进行系统比较，分析不同类型提示修改对两者的影响。

Result: 人类和LLM都对替代标签集和标签格式的替换表现出增加的脆弱性，但人类判断受拼写错误和反转标签顺序的影响小于LLM。

Conclusion: 提示脆弱性在一定程度上反映了人类标注的方差，但LLM对某些类型的提示修改比人类更敏感。

Abstract: The output of large language models (LLM) is unstable, due to both
non-determinism of the decoding process as well as to prompt brittleness. While
the intrinsic non-determinism of LLM generation may mimic existing uncertainty
in human annotations through distributional shifts in outputs, it is largely
assumed, yet unexplored, that the prompt brittleness effect is unique to LLMs.
This raises the question: do human annotators show similar sensitivity to
instruction changes? If so, should prompt brittleness in LLMs be considered
problematic? One may alternatively hypothesize that prompt brittleness
correctly reflects human annotation variances. To fill this research gap, we
systematically compare the effects of prompt modifications on LLMs and
identical instruction modifications for human annotators, focusing on the
question of whether humans are similarly sensitive to prompt perturbations. To
study this, we prompt both humans and LLMs for a set of text classification
tasks conditioned on prompt variations. Our findings indicate that both humans
and LLMs exhibit increased brittleness in response to specific types of prompt
modifications, particularly those involving the substitution of alternative
label sets or label formats. However, the distribution of human judgments is
less affected by typographical errors and reversed label order than that of
LLMs.

</details>


### [34] [From Detection to Mitigation: Addressing Gender Bias in Chinese Texts via Efficient Tuning and Voting-Based Rebalancing](https://arxiv.org/abs/2509.07889)
*Chengyan Wu,Yiqiang Cai,Yufei Cheng,Yun Xue*

Main category: cs.CL

TL;DR: 本文提出了基于大语言模型微调和LoRA的句子级性别偏见检测与缓解方法，通过数据平衡、多模型集成和多温度采样机制，在NLPCC-2025共享任务中获得第四名


<details>
  <summary>Details</summary>
Motivation: 促进自然语言生成的公平性和可控性，自动检测、分类和缓解中文句子中的性别偏见

Method: 采用基于大语言模型的微调方法，使用LoRA进行高效适配；构建平衡训练集缓解类别不平衡；引入多源异构样本增强泛化；使用多数投票策略集成多个专家模型；设计多温度采样机制捕捉偏见表达风格变化

Result: 在偏见检测、分类和缓解方面表现出有效性，最终获得47.90%的平均得分，在共享任务中排名第四

Conclusion: 提出的方法在中文性别偏见处理任务中取得了良好效果，证明了基于LLM微调和集成策略的有效性

Abstract: This paper presents our team's solution to Shared Task 7 of NLPCC-2025, which
focuses on sentence-level gender bias detection and mitigation in Chinese. The
task aims to promote fairness and controllability in natural language
generation by automatically detecting, classifying, and mitigating gender bias.
To address this challenge, we adopt a fine-tuning approach based on large
language models (LLMs), efficiently adapt to the bias detection task via
Low-Rank Adaptation (LoRA). In terms of data processing, we construct a more
balanced training set to alleviate class imbalance and introduce heterogeneous
samples from multiple sources to enhance model generalization. For the
detection and classification sub-tasks, we employ a majority voting strategy
that integrates outputs from multiple expert models to boost performance.
Additionally, to improve bias generation detection and mitigation, we design a
multi-temperature sampling mechanism to capture potential variations in bias
expression styles. Experimental results demonstrate the effectiveness of our
approach in bias detection, classification, and mitigation. Our method
ultimately achieves an average score of 47.90%, ranking fourth in the shared
task.

</details>


### [35] [Biased Tales: Cultural and Topic Bias in Generating Children's Stories](https://arxiv.org/abs/2509.07908)
*Donya Rooein,Vilém Zouhar,Debora Nozza,Dirk Hovy*

Main category: cs.CL

TL;DR: Biased Tales数据集分析LLM生成故事中的文化性别偏见，发现女孩主角外貌描述增加55.26%，非西方主角过度强调文化传统主题


<details>
  <summary>Details</summary>
Motivation: 随着家长越来越多使用LLM生成睡前故事，故事中存在的文化和性别刻板印象问题值得关注，需要分析偏见如何影响主角属性和故事元素

Method: 创建Biased Tales综合数据集，分析LLM生成故事中主角性别和文化背景对故事内容的影响

Result: 女孩主角相比男孩主角，外貌相关属性增加55.26%；非西方儿童主角的故事过度强调文化遗产、传统和家庭主题，远超西方儿童主角的故事

Conclusion: 研究结果强调了社会文化偏见在使创意AI使用更加公平和多样化方面的重要作用

Abstract: Stories play a pivotal role in human communication, shaping beliefs and
morals, particularly in children. As parents increasingly rely on large
language models (LLMs) to craft bedtime stories, the presence of cultural and
gender stereotypes in these narratives raises significant concerns. To address
this issue, we present Biased Tales, a comprehensive dataset designed to
analyze how biases influence protagonists' attributes and story elements in
LLM-generated stories. Our analysis uncovers striking disparities. When the
protagonist is described as a girl (as compared to a boy), appearance-related
attributes increase by 55.26%. Stories featuring non-Western children
disproportionately emphasize cultural heritage, tradition, and family themes
far more than those for Western children. Our findings highlight the role of
sociocultural bias in making creative AI use more equitable and diverse.

</details>


### [36] [GENUINE: Graph Enhanced Multi-level Uncertainty Estimation for Large Language Models](https://arxiv.org/abs/2509.07925)
*Tuo Wang,Adithya Kulkarni,Tyler Cody,Peter A. Beling,Yujun Yan,Dawei Zhou*

Main category: cs.CL

TL;DR: GENUINE是一个基于图结构的LLM不确定性估计框架，通过依赖解析树和分层图池化来改进不确定性量化，在NLP任务中比语义熵方法AUROC提升29%，校准误差降低15%


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视语义依赖关系，仅依赖词级概率度量，无法捕捉生成文本中的结构关系，需要更可靠的不确定性估计方法来提高LLM在高风险应用中的可靠性

Method: 提出GENUINE框架，利用依赖解析树和分层图池化技术，结合监督学习来建模语义和结构关系，改进置信度评估

Result: 在NLP任务上的广泛实验显示，GENUINE比基于语义熵的方法AUROC提高29%，校准误差降低超过15%

Conclusion: 基于图结构的不确定性建模方法有效，GENUINE框架显著提升了LLM不确定性估计的性能

Abstract: Uncertainty estimation is essential for enhancing the reliability of Large
Language Models (LLMs), particularly in high-stakes applications. Existing
methods often overlook semantic dependencies, relying on token-level
probability measures that fail to capture structural relationships within the
generated text. We propose GENUINE: Graph ENhanced mUlti-level uncertaINty
Estimation for Large Language Models, a structure-aware framework that
leverages dependency parse trees and hierarchical graph pooling to refine
uncertainty quantification. By incorporating supervised learning, GENUINE
effectively models semantic and structural relationships, improving confidence
assessments. Extensive experiments across NLP tasks show that GENUINE achieves
up to 29% higher AUROC than semantic entropy-based approaches and reduces
calibration errors by over 15%, demonstrating the effectiveness of graph-based
uncertainty modeling. The code is available at
https://github.com/ODYSSEYWT/GUQ.

</details>


### [37] [SimpleQA Verified: A Reliable Factuality Benchmark to Measure Parametric Knowledge](https://arxiv.org/abs/2509.07968)
*Lukas Haas,Gal Yona,Giovanni D'Antonio,Sasha Goldshtein,Dipanjan Das*

Main category: cs.CL

TL;DR: SimpleQA Verified是一个包含1000个提示的基准测试，用于评估大语言模型的短文本事实性，改进了OpenAI SimpleQA基准的标签噪声、主题偏见和问题冗余等问题。


<details>
  <summary>Details</summary>
Motivation: 解决OpenAI SimpleQA基准测试中存在的标签错误、主题偏见和问题冗余等关键限制，为研究社区提供更可靠的事实性评估工具。

Method: 通过多阶段过滤流程创建基准，包括去重、主题平衡和来源核对，同时改进了自动评分提示。

Result: Gemini 2.5 Pro在该基准上取得了55.6的F1分数，优于包括GPT-5在内的其他前沿模型。

Conclusion: 该工作为研究社区提供了更高保真度的工具来跟踪参数模型事实性的真实进展并减少幻觉问题，基准数据集和评估代码已公开。

Abstract: We introduce SimpleQA Verified, a 1,000-prompt benchmark for evaluating Large
Language Model (LLM) short-form factuality based on OpenAI's SimpleQA. It
addresses critical limitations in OpenAI's benchmark, including noisy and
incorrect labels, topical biases, and question redundancy. SimpleQA Verified
was created through a rigorous multi-stage filtering process involving
de-duplication, topic balancing, and source reconciliation to produce a more
reliable and challenging evaluation set, alongside improvements in the
autorater prompt. On this new benchmark, Gemini 2.5 Pro achieves a
state-of-the-art F1-score of 55.6, outperforming other frontier models,
including GPT-5. This work provides the research community with a
higher-fidelity tool to track genuine progress in parametric model factuality
and to mitigate hallucinations. The benchmark dataset, evaluation code, and
leaderboard are available at:
https://www.kaggle.com/benchmarks/deepmind/simpleqa-verified.

</details>


### [38] [Parallel-R1: Towards Parallel Thinking via Reinforcement Learning](https://arxiv.org/abs/2509.07980)
*Tong Zheng,Hongming Zhang,Wenhao Yu,Xiaoyang Wang,Xinyu Yang,Runpeng Dai,Rui Liu,Huiwen Bao,Chengsong Huang,Heng Huang,Dong Yu*

Main category: cs.CL

TL;DR: Parallel-R1是一个强化学习框架，通过渐进式课程训练LLMs的并行思维能力，在数学推理任务上显著提升性能


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖监督微调，鼓励模仿而非探索和泛化，无法有效激活并行思维能力

Method: 采用渐进式课程：先用SFT在简单任务上培养并行思维，然后转向RL在复杂问题上探索和泛化该能力

Result: 在MATH、AMC23、AIME等数学基准上取得8.4%的准确率提升，在AIME25上相比基线提升42.9%

Conclusion: 并行思维可作为训练中的探索支架，临时探索阶段能够解锁更高的性能上限

Abstract: Parallel thinking has emerged as a novel approach for enhancing the reasoning
capabilities of large language models (LLMs) by exploring multiple reasoning
paths concurrently. However, activating such capabilities through training
remains challenging, as existing methods predominantly rely on supervised
fine-tuning (SFT) over synthetic data, which encourages teacher-forced
imitation rather than exploration and generalization. Different from them, we
propose \textbf{Parallel-R1}, the first reinforcement learning (RL) framework
that enables parallel thinking behaviors for complex real-world reasoning
tasks. Our framework employs a progressive curriculum that explicitly addresses
the cold-start problem in training parallel thinking with RL. We first use SFT
on prompt-generated trajectories from easier tasks to instill the parallel
thinking ability, then transition to RL to explore and generalize this skill on
harder problems. Experiments on various math benchmarks, including MATH, AMC23,
and AIME, show that Parallel-R1 successfully instills parallel thinking,
leading to 8.4% accuracy improvements over the sequential thinking model
trained directly on challenging tasks with RL. Further analysis reveals a clear
shift in the model's thinking behavior: at an early stage, it uses parallel
thinking as an exploration strategy, while in a later stage, it uses the same
capability for multi-perspective verification. Most significantly, we validate
parallel thinking as a \textbf{mid-training exploration scaffold}, where this
temporary exploratory phase unlocks a higher performance ceiling after RL,
yielding a 42.9% improvement over the baseline on AIME25. Our model, data, and
code will be open-source at https://github.com/zhengkid/Parallel-R1.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [39] [Neurocognitive Modeling for Text Generation: Deep Learning Architecture for EEG Data](https://arxiv.org/abs/2509.07202)
*Khushiyant*

Main category: cs.HC

TL;DR: 通过结合Gemma 2B大语言模型与RNN编码器的分类器-LLM架构，大幅降低EEG文本生成的数据和计算需求，性能提升10%


<details>
  <summary>Details</summary>
Motivation: 解决EEG基于文本生成需要大量数据和计算资源的挑战，提高辅助技术的可访性和效率

Method: 采用分类器-LLM架构，结合Gemma 2B大语言模型与RNN编码器，实现传边学习

Result: 在大幅减少数据和计算需求的同时，达到了接近最先进方法的性能，整体性能提升10%

Conclusion: 证明了结合LLM与EEG解码在脱离运动限制通信方面的潜力，为脑机接口领域开启了新的研究和应用路径

Abstract: Text generating capabilities have undergone a substantial transformation with
the introduction of large language models (LLMs). Electroencephalography
(EEG)-based text production is still difficult, though, because it requires a
lot of data and processing power. This paper introduces a new method that
combines the use of the Gemma 2B LLM with a classifier-LLM architecture to
incorporate a Recurrent Neural Network (RNN) encoder. Our approach drastically
lowers the amount of data and compute power needed while achieving performance
close to that of cutting-edge methods. Notably, compared to current
methodologies, our methodology delivers an overall performance improvement of
10%. The suggested architecture demonstrates the possibility of effective
transfer learning for EEG-based text production, remaining strong and
functional even in the face of data limits. This work highlights the potential
of integrating LLMs with EEG decoding to improve assistive technologies and
improve independence and communication for those with severe motor limitations.
Our method pushes the limits of present capabilities and opens new paths for
research and application in brain-computer interfaces by efficiently using the
strengths of pre-trained language models. This makes EEG-based text production
more accessible and efficient.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [40] [From Eigenmodes to Proofs: Integrating Graph Spectral Operators with Symbolic Interpretable Reasoning](https://arxiv.org/abs/2509.07017)
*Andrew Kiruluta,Priscilla Burity*

Main category: cs.AI

TL;DR: Spectral NSR是一个完全谱神经符号推理框架，通过图信号处理和拉普拉斯特征结构将逻辑规则嵌入为谱模板，在谱域直接进行推理，统一了符号推理的可解释性和谱学习的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 结合符号推理的可解释性和神经网络的可扩展性，通过谱方法实现高效的神经符号推理，解决传统方法在准确性、推理速度和鲁棒性方面的局限性。

Method: 利用图信号处理和频率选择性滤波器，在知识图谱的拉普拉斯特征结构基础上进行推理。包含动态图学习、有理和扩散滤波器、谱专家混合、证明引导训练、不确定性量化等扩展功能。

Result: 在ProofWriter和CLUTRR等推理基准测试中，相比transformer、消息传递神经网络和神经符号逻辑编程系统，实现了更高的准确性、更快的推理速度、更好的对抗扰动鲁棒性和可解释性。

Conclusion: Spectral NSR为下一代推理系统提供了可扩展的原则性基础，提供了超越传统方法的透明度、鲁棒性和泛化能力。

Abstract: We introduce Spectral NSR, a fully spectral neuro-symbolic reasoning
framework that embeds logical rules as spectral templates and performs
inference directly in the graph spectral domain. By leveraging graph signal
processing (GSP) and frequency-selective filters grounded in the Laplacian
eigenstructure of knowledge graphs, the architecture unifies the
interpretability of symbolic reasoning with the scalability and adaptability of
spectral learning. Beyond the core formulation, we incorporate a comprehensive
set of extensions, including dynamic graph and basis learning, rational and
diffusion filters for sharper spectral selectivity, mixture-of-spectral-experts
for modular specialization, proof-guided training with spectral curricula, and
uncertainty quantification for calibrated confidence. Additional enhancements
such as large language model coupling, co-spectral transfer alignment,
adversarial robustness, efficient GPU kernels, generalized Laplacians, and
causal interventions further expand the versatility of the framework.
  Empirical evaluation on state-of-the-art reasoning benchmarks such as
ProofWriter and CLUTRR demonstrates that Spectral NSR achieves superior
accuracy, faster inference, improved robustness to adversarial perturbations,
and higher interpretability compared to leading baselines including
transformers, message-passing neural networks, and neuro-symbolic logic
programming systems. Spectral attribution and proof-band agreement analyses
confirm that model decisions align closely with symbolic proof structures,
while transfer experiments validate effective domain adaptation through
co-spectral alignment. These results establish Spectral NSR as a scalable and
principled foundation for the next generation of reasoning systems, offering
transparency, robustness, and generalization beyond conventional approaches.

</details>


### [41] [Instruction Agent: Enhancing Agent with Expert Demonstration](https://arxiv.org/abs/2509.07098)
*Yinheng Li,Hailey Hultquist,Justin Wagle,Kazuhito Koishida*

Main category: cs.AI

TL;DR: Instruction Agent是一个GUI代理，通过专家演示学习并严格执行用户意图轨迹，结合验证器和回溯器模块处理意外情况，在复杂任务上达到60%成功率


<details>
  <summary>Details</summary>
Motivation: 当前GUI代理在处理新颖UI元素、长时程动作和个性化轨迹的复杂任务时仍存在困难，需要更可靠的自动化解决方案

Method: 基于单次专家演示提取逐步指令，严格遵循用户意图轨迹执行，使用验证器理解动作结果，回溯器处理意外中断（如弹窗）

Result: 在OSWorld测试集上达到60%成功率，所有顶级代理此前都无法完成这些任务

Conclusion: Instruction Agent提供了一个实用且可扩展的框架，弥合了当前GUI代理与可靠真实世界GUI任务自动化之间的差距

Abstract: Graphical user interface (GUI) agents have advanced rapidly but still
struggle with complex tasks involving novel UI elements, long-horizon actions,
and personalized trajectories. In this work, we introduce Instruction Agent, a
GUI agent that leverages expert demonstrations to solve such tasks, enabling
completion of otherwise difficult workflows. Given a single demonstration, the
agent extracts step-by-step instructions and executes them by strictly
following the trajectory intended by the user, which avoids making mistakes
during execution. The agent leverages the verifier and backtracker modules
further to improve robustness. Both modules are critical to understand the
current outcome from each action and handle unexpected interruptions(such as
pop-up windows) during execution. Our experiments show that Instruction Agent
achieves a 60% success rate on a set of tasks in OSWorld that all top-ranked
agents failed to complete. The Instruction Agent offers a practical and
extensible framework, bridging the gap between current GUI agents and reliable
real-world GUI task automation.

</details>


### [42] [Neuro-Symbolic Frameworks: Conceptual Characterization and Empirical Comparative Analysis](https://arxiv.org/abs/2509.07122)
*Sania Sinha,Tanawan Premsri,Danial Kamali,Parisa Kordjamshidi*

Main category: cs.AI

TL;DR: 本文分析了神经符号框架的技术特征，包括符号表示语言、与神经模型的集成以及底层算法，重点展示了DeepProbLog、Scallop和DomiKnowS三个通用框架，旨在激发社区重新思考神经符号建模问题。


<details>
  <summary>Details</summary>
Motivation: 神经符号框架结合了神经表示学习和符号表示推理的优势，但该领域缺乏用户友好的工具和统一框架，开发者面临学习曲线陡峭的挑战。

Method: 通过分析现有神经符号框架的技术特征，包括符号表示语言、神经模型集成方式和底层算法，重点研究三个通用框架DeepProbLog、Scallop和DomiKnowS。

Result: 识别了各框架在解决不同问题时的表达能力挑战，发现大多数神经符号研究侧重于算法而非提供声明式问题规范的通用框架。

Conclusion: 本文为神经符号建模奠定了基础，旨在激发社区采取变革性行动，以新的方式重新思考这一问题，推动开发更通用的声明式问题解决框架。

Abstract: Neurosymbolic (NeSy) frameworks combine neural representations and learning
with symbolic representations and reasoning. Combining the reasoning
capacities, explainability, and interpretability of symbolic processing with
the flexibility and power of neural computing allows us to solve complex
problems with more reliability while being data-efficient. However, this
recently growing topic poses a challenge to developers with its learning curve,
lack of user-friendly tools, libraries, and unifying frameworks. In this paper,
we characterize the technical facets of existing NeSy frameworks, such as the
symbolic representation language, integration with neural models, and the
underlying algorithms. A majority of the NeSy research focuses on algorithms
instead of providing generic frameworks for declarative problem specification
to leverage problem solving. To highlight the key aspects of Neurosymbolic
modeling, we showcase three generic NeSy frameworks - \textit{DeepProbLog},
\textit{Scallop}, and \textit{DomiKnowS}. We identify the challenges within
each facet that lay the foundation for identifying the expressivity of each
framework in solving a variety of problems. Building on this foundation, we aim
to spark transformative action and encourage the community to rethink this
problem in novel ways.

</details>


### [43] [That's So FETCH: Fashioning Ensemble Techniques for LLM Classification in Civil Legal Intake and Referral](https://arxiv.org/abs/2509.07170)
*Quinten Steenhuis*

Main category: cs.AI

TL;DR: FETCH分类器用于法律问题分类，通过混合LLM/ML集成方法和自动生成后续问题来提高准确性，在真实数据集上达到97.37%的准确率，超越GPT-5模型。


<details>
  <summary>Details</summary>
Motivation: 每年数百万人通过法律援助热线、办公室或律师转介服务寻求法律帮助，准确识别法律问题至关重要，错误引导可能导致严重后果如错过截止日期、遭受身体虐待、失去住房或子女监护权。

Method: 采用混合LLM/ML集成分类方法，结合自动生成后续问题来丰富初始问题叙述，使用包含419个真实查询的新型数据集进行评估。

Result: 分类准确率（hits@2）达到97.37%，使用低成本模型组合超越了当前最先进的GPT-5模型的性能。

Conclusion: 该方法在显著降低法律系统用户引导成本的同时实现了高准确性，有望改善法律援助服务的效率和效果。

Abstract: Each year millions of people seek help for their legal problems by calling a
legal aid program hotline, walking into a legal aid office, or using a lawyer
referral service. The first step to match them to the right help is to identify
the legal problem the applicant is experiencing. Misdirection has consequences.
Applicants may miss a deadline, experience physical abuse, lose housing or lose
custody of children while waiting to connect to the right legal help. We
introduce and evaluate the FETCH classifier for legal issue classification and
describe two methods for improving accuracy: a hybrid LLM/ML ensemble
classification method, and the automatic generation of follow-up questions to
enrich the initial problem narrative. We employ a novel data set of 419
real-world queries to a nonprofit lawyer referral service. Ultimately, we show
classification accuracy (hits@2) of 97.37\% using a mix of inexpensive models,
exceeding the performance of the current state-of-the-art GPT-5 model. Our
approach shows promise in significantly reducing the cost of guiding users of
the legal system to the right resource for their problem while achieving high
accuracy.

</details>


### [44] [Language Self-Play For Data-Free Training](https://arxiv.org/abs/2509.07414)
*Jakub Grudzien Kuba,Mengting Gu,Qi Ma,Yuandong Tian,Vijai Mohan*

Main category: cs.AI

TL;DR: 通过语言自我对弈（LSP）方法，大语言模型可以在不需额外训练数据的情况下，通过自我对弈实现能力的提升


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型进步依赖大量训练数据的基础界领问题，寻找一种无需额外数据的改进方法

Method: 采用游戏论框架下的自我对弈方法（Language Self-Play, LSP），让模型在竞争性游戏中与自身对弈，通过强化学习产生更强的策略

Result: 在Llama-3.2-3B-Instruct模型上的指令跟随测试中显示，通过自我对弈单独就能提升在具有挑战性任务上的表现，效果超过依赖数据的基线方法

Conclusion: 语言自我对弈提供了一种有效的方法，能够在不需要额外训练数据的情况下持续改善大语言模型的能力

Abstract: Large language models (LLMs) have advanced rapidly in recent years, driven by
scale, abundant high-quality training data, and reinforcement learning. Yet
this progress faces a fundamental bottleneck: the need for ever more data from
which models can continue to learn. In this work, we propose a reinforcement
learning approach that removes this dependency by enabling models to improve
without additional data. Our method leverages a game-theoretic framework of
self-play, where a model's capabilities are cast as performance in a
competitive game and stronger policies emerge by having the model play against
itself - a process we call Language Self-Play (LSP). Experiments with
Llama-3.2-3B-Instruct on instruction-following benchmarks show that pretrained
models can not only enhance their performance on challenging tasks through
self-play alone, but can also do so more effectively than data-driven
baselines.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [45] [Astra: A Multi-Agent System for GPU Kernel Performance Optimization](https://arxiv.org/abs/2509.07506)
*Anjiang Wei,Tianran Sun,Yogesh Seenichamy,Hang Song,Anne Ouyang,Azalia Mirhoseini,Ke Wang,Alex Aiken*

Main category: cs.DC

TL;DR: Astra是首个基于LLM的多智能体系统，专门用于GPU内核优化，从现有CUDA实现而非PyTorch模块出发，通过多智能体协作实现代码优化，平均加速比达1.32倍


<details>
  <summary>Details</summary>
Motivation: GPU内核优化对LLM训练和服务至关重要，但传统方法需要大量手动调优。现有编译器系统仍需大量人工设计，而之前的LLM方法主要关注从PyTorch到CUDA的代码转换

Method: Astra采用多智能体LLM系统，从SGLang框架提取现有CUDA实现，通过专门的LLM智能体进行迭代式代码生成、测试、性能分析和规划，实现协作优化

Result: 在SGLang内核上，Astra使用OpenAI o4-mini零样本提示实现了平均1.32倍的加速。案例研究显示系统能自主应用循环变换、优化内存访问模式、利用CUDA内置函数和快速数学运算

Conclusion: 多智能体LLM系统为GPU内核优化提供了有前景的新范式，展示了LLM在自主应用高级优化技术方面的能力

Abstract: GPU kernel optimization has long been a central challenge at the intersection
of high-performance computing and machine learning. Efficient kernels are
crucial for accelerating large language model (LLM) training and serving, yet
attaining high performance typically requires extensive manual tuning.
Compiler-based systems reduce some of this burden, but still demand substantial
manual design and engineering effort. Recently, researchers have explored using
LLMs for GPU kernel generation, though prior work has largely focused on
translating high-level PyTorch modules into CUDA code. In this work, we
introduce Astra, the first LLM-based multi-agent system for GPU kernel
optimization. Unlike previous approaches, Astra starts from existing CUDA
implementations extracted from SGLang, a widely deployed framework for serving
LLMs, rather than treating PyTorch modules as the specification. Within Astra,
specialized LLM agents collaborate through iterative code generation, testing,
profiling, and planning to produce kernels that are both correct and
high-performance. On kernels from SGLang, Astra achieves an average speedup of
1.32x using zero-shot prompting with OpenAI o4-mini. A detailed case study
further demonstrates that LLMs can autonomously apply loop transformations,
optimize memory access patterns, exploit CUDA intrinsics, and leverage fast
math operations to yield substantial performance gains. Our work highlights
multi-agent LLM systems as a promising new paradigm for GPU kernel
optimization.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [46] [ArGen: Auto-Regulation of Generative AI via GRPO and Policy-as-Code](https://arxiv.org/abs/2509.07006)
*Kapil Madan*

Main category: cs.CY

TL;DR: ArGen框架通过自动化奖励评分、GRPO策略优化和OPA治理层，使LLM能够遵守复杂的多维度规则体系，在医疗AI案例中实现了70.9%的领域依从性提升


<details>
  <summary>Details</summary>
Motivation: 超越基于偏好的对齐方法，需要确保LLM能够遵守包含伦理原则、安全协议和法规标准的复杂可配置规则体系

Method: 结合基于原则的自动化奖励评分、Group Relative Policy Optimisation (GRPO) 和Open Policy Agent (OPA) 启发的治理层

Result: 在基于Dharma伦理的医疗AI助手案例中，实现了70.9%的领域范围依从性改进

Conclusion: ArGen为构建技术上熟练、伦理上稳健且可验证合规的'可治理AI'系统提供了可行路径

Abstract: This paper introduces ArGen (Auto-Regulation of Generative AI systems), a
framework for aligning Large Language Models (LLMs) with complex sets of
configurable, machine-readable rules spanning ethical principles, operational
safety protocols, and regulatory compliance standards. Moving beyond just
preference-based alignment, ArGen is designed to ensure LLMs adhere to these
multifaceted policies through a novel synthesis of principle-based automated
reward scoring, Group Relative Policy Optimisation (GRPO), and an Open Policy
Agent (OPA) inspired governance layer. This approach provides the technical
foundation for achieving and demonstrating compliance with diverse and nuanced
governance requirements. To showcase the framework's capability to
operationalize a deeply nuanced and culturally-specific value system, we
present an in-depth case study: the development of a medical AI assistant
guided by principles from Dharmic ethics (such as Ahimsa and Dharma), as
derived from texts like the Bhagavad Gita. This challenging application
demonstrates ArGen's adaptability, achieving a 70.9% improvement in
domain-scope adherence over the baseline. Through our open-source repository,
we show that ArGen's methodology offers a path to 'Governable Al' systems that
are technically proficient, ethically robust, and verifiably compliant for safe
deployment in diverse global contexts.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [47] [VLMs-in-the-Wild: Bridging the Gap Between Academic Benchmarks and Enterprise Reality](https://arxiv.org/abs/2509.06994)
*Srihari Bandraupalli,Anupam Purwar*

Main category: cs.CV

TL;DR: ViLD框架填补了学术评估与企业部署需求之间的鸿沟，通过10个关键业务任务和创新的BlockWeaver算法，在真实数据集上评估开源视觉语言模型。


<details>
  <summary>Details</summary>
Motivation: 当前基准测试主要依赖选择题和合成数据，无法反映企业实际应用场景的复杂性，需要建立更贴近真实业务需求的评估框架。

Method: 提出ViLD框架，定义10个企业关键任务；开发BlockWeaver算法用于无序OCR输出比较；构建包含7500个真实样本的基准数据集；结合语义匹配、传统指标和新方法进行评估。

Result: 在Qwen、MIMO和InternVL等开源VLM上进行了行业基准测试，提供了首个基于任务的VLM能力评估，为企业在实际部署中提供可操作的见解。

Conclusion: ViLD框架成功连接了学术研究与企业需求，通过真实业务场景的评估为开源视觉语言模型的企业级应用提供了实用指导。

Abstract: Open-source Vision-Language Models show immense promise for enterprise
applications, yet a critical disconnect exists between academic evaluation and
enterprise deployment requirements. Current benchmarks rely heavily on
multiple-choice questions and synthetic data, failing to capture the complexity
of real-world business applications like social media content analysis. This
paper introduces VLM-in-the-Wild (ViLD), a comprehensive framework to bridge
this gap by evaluating VLMs on operational enterprise requirements. We define
ten business-critical tasks: logo detection, OCR, object detection, human
presence and demographic analysis, human activity and appearance analysis,
scene detection, camera perspective and media quality assessment, dominant
colors, comprehensive description, and NSFW detection. To this framework, we
bring an innovative BlockWeaver Algorithm that solves the challenging problem
of comparing unordered, variably-grouped OCR outputs from VLMs without relying
on embeddings or LLMs, achieving remarkable speed and reliability. To
demonstrate efficacy of ViLD, we constructed a new benchmark dataset of 7,500
diverse samples, carefully stratified from a corpus of one million real-world
images and videos. ViLD provides actionable insights by combining semantic
matching (both embedding-based and LLM-as-a-judge approaches), traditional
metrics, and novel methods to measure the completeness and faithfulness of
descriptive outputs. By benchmarking leading open-source VLMs (Qwen, MIMO, and
InternVL) against a powerful proprietary baseline as per ViLD framework, we
provide one of the first industry-grounded, task-driven assessment of VLMs
capabilities, offering actionable insights for their deployment in enterprise
environments.

</details>


### [48] [GLEAM: Learning to Match and Explain in Cross-View Geo-Localization](https://arxiv.org/abs/2509.07450)
*Xudong Lu,Zhi Zheng,Yi Wan,Yongxiang Yao,Annan Wang,Renrui Zhang,Panwang Xia,Qiong Wu,Qingyun Li,Weifeng Lin,Xiangyu Zhao,Xue Yang,Hongsheng Li*

Main category: cs.CV

TL;DR: GLEAM-C是一个统一多视角多模态的跨视角地理定位基础模型，通过卫星图像对齐实现高效训练；GLEAM-X结合MLLM提出可解释的跨视角推理新任务，构建双语基准数据集，提升地理定位的透明度和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有CVGL方法局限于单一视角或模态，且缺乏可解释性——仅预测图像是否对应而不解释匹配依据。需要统一多视角多模态并增强模型的可解释推理能力。

Method: GLEAM-C：通过卫星图像对齐统一无人机影像、街景地图、全景视图和地面照片等多模态数据，采用两阶段训练策略；GLEAM-X：利用多模态大语言模型的推理能力，结合GPT-4o和Doubao-1.5构建双语基准数据集进行可解释的跨视角推理。

Result: GLEAM-C实现了与先前模态特定CVGL模型相当的精度，同时通过优化实现提高了训练效率；GLEAM-X构建了经过人工精细修订的测试集，支持系统性的可解释跨视角推理评估。

Conclusion: GLEAM-C和GLEAM-X形成了一个完整的CVGL管道，将多模态多视角对齐与可解释的对应分析相结合，统一了准确的跨视角匹配与可解释推理，通过使模型能够更好地解释和匹配来推进地理定位技术的发展。

Abstract: Cross-View Geo-Localization (CVGL) focuses on identifying correspondences
between images captured from distinct perspectives of the same geographical
location. However, existing CVGL approaches are typically restricted to a
single view or modality, and their direct visual matching strategy lacks
interpretability: they merely predict whether two images correspond, without
explaining the rationale behind the match. In this paper, we present GLEAM-C, a
foundational CVGL model that unifies multiple views and modalities-including
UAV imagery, street maps, panoramic views, and ground photographs-by aligning
them exclusively with satellite imagery. Our framework enhances training
efficiency through optimized implementation while achieving accuracy comparable
to prior modality-specific CVGL models through a two-phase training strategy.
Moreover, to address the lack of interpretability in traditional CVGL methods,
we leverage the reasoning capabilities of multimodal large language models
(MLLMs) to propose a new task, GLEAM-X, which combines cross-view
correspondence prediction with explainable reasoning. To support this task, we
construct a bilingual benchmark using GPT-4o and Doubao-1.5-Thinking-Vision-Pro
to generate training and testing data. The test set is further refined through
detailed human revision, enabling systematic evaluation of explainable
cross-view reasoning and advancing transparency and scalability in
geo-localization. Together, GLEAM-C and GLEAM-X form a comprehensive CVGL
pipeline that integrates multi-modal, multi-view alignment with interpretable
correspondence analysis, unifying accurate cross-view matching with explainable
reasoning and advancing Geo-Localization by enabling models to better Explain
And Match. Code and datasets used in this work will be made publicly accessible
at https://github.com/Lucky-Lance/GLEAM.

</details>


### [49] [Visual-TableQA: Open-Domain Benchmark for Reasoning over Table Images](https://arxiv.org/abs/2509.07966)
*Boammani Aser Lompo,Marc Haraoui*

Main category: cs.CV

TL;DR: Visual-TableQA是一个大规模开放领域多模态数据集，专门用于评估和增强视觉语言模型在复杂表格数据上的视觉推理能力，包含2.5k个表格和6k个QA对，生成成本低于100美元。


<details>
  <summary>Details</summary>
Motivation: 当前基准测试在规模、多样性和推理深度方面存在局限，特别是在渲染表格图像方面，需要更好的数据集来评估视觉语言模型的表格推理能力。

Method: 采用模块化、可扩展的全自动生成流程，使用多个推理LLM在生成、验证和启发等不同角色上协作，通过跨模型提示和LLM陪审团过滤实现多模型协同数据生成。

Result: 在Visual-TableQA上微调的模型能够很好地泛化到外部基准测试，性能超过多个专有模型，尽管数据集是合成的。

Conclusion: Visual-TableQA为视觉表格推理提供了高质量、低成本的数据集生成方案，证明了合成数据在提升模型性能方面的有效性。

Abstract: Visual reasoning over structured data such as tables is a critical capability
for modern vision-language models (VLMs), yet current benchmarks remain limited
in scale, diversity, or reasoning depth, especially when it comes to rendered
table images. Addressing this gap, we introduce Visual-TableQA, a large-scale,
open-domain multimodal dataset specifically designed to evaluate and enhance
visual reasoning over complex tabular data. Our generation pipeline is modular,
scalable, and fully autonomous, involving multiple reasoning LLMs collaborating
across distinct roles: generation, validation, and inspiration. Visual-TableQA
comprises 2.5k richly structured LaTeX-rendered tables and 6k
reasoning-intensive QA pairs, all produced at a cost of under USD 100. To
promote diversity and creativity, our pipeline performs multi-model
collaborative data generation via cross-model prompting ('inspiration') and
LLM-jury filtering. Stronger models seed layouts and topics that weaker models
elaborate, collectively distilling diverse reasoning patterns and visual
structures into the dataset. Empirical results show that models fine-tuned on
Visual-TableQA generalize robustly to external benchmarks, outperforming
several proprietary models despite the dataset's synthetic nature. The full
pipeline and resources are publicly available at
https://github.com/AI-4-Everyone/Visual-TableQA.

</details>


### [50] [Mini-o3: Scaling Up Reasoning Patterns and Interaction Turns for Visual Search](https://arxiv.org/abs/2509.07969)
*Xin Lai,Junyi Li,Wei Li,Tao Liu,Tianjian Li,Hengshuang Zhao*

Main category: cs.CV

TL;DR: 小型o3系统通过扩展多模态模型的工具交互轮数，实现深度多轮推理，在具有挑战性的视觉搜索任务上达到最先进性能


<details>
  <summary>Details</summary>
Motivation: 解决现有开源多模态模型在视觉问题中推理模式单调、交互轮数有限的问题，特别是对需要尝试错误探索的复杂任务

Method: 构建Visual Probe数据集、迭代数据收集流水线获取多样化推理轨迹、重新推导过轮掩码策略以避免过轮回后的惩罚

Result: 模型在训练时仅使用6轮上限，但推理时能自然扩展到数十轮，准确性随轮数增加而提升，产生丰富的推理模式和深度思考路径

Conclusion: 通过扩展工具交互规模和重新推导策略，Mini-o3成功实现了深度多轮推理，有效解决复杂视觉搜索问题，证明了多模态模型在长期推理任务中的潜力

Abstract: Recent advances in large multimodal models have leveraged image-based tools
with reinforcement learning to tackle visual problems. However, existing
open-source approaches often exhibit monotonous reasoning patterns and allow
only a limited number of interaction turns, making them inadequate for
difficult tasks that require trial-and-error exploration. In this work, we
address this limitation by scaling up tool-based interactions and introduce
Mini-o3, a system that executes deep, multi-turn reasoning -- spanning tens of
steps -- and achieves state-of-the-art performance on challenging visual search
tasks. Our recipe for reproducing OpenAI o3-style behaviors comprises three key
components. First, we construct the Visual Probe Dataset, a collection of
thousands of challenging visual search problems designed for exploratory
reasoning. Second, we develop an iterative data collection pipeline to obtain
cold-start trajectories that exhibit diverse reasoning patterns, including
depth-first search, trial-and-error, and goal maintenance. Third, we propose an
over-turn masking strategy that prevents penalization of over-turn responses
(those that hit the maximum number of turns) during reinforcement learning,
thereby balancing training-time efficiency with test-time scalability. Despite
training with an upper bound of only six interaction turns, our model generates
trajectories that naturally scale to tens of turns at inference time, with
accuracy improving as the number of turns increases. Extensive experiments
demonstrate that Mini-o3 produces rich reasoning patterns and deep thinking
paths, effectively solving challenging visual search problems.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [51] [CARE: Decoding Time Safety Alignment via Rollback and Introspection Intervention](https://arxiv.org/abs/2509.06982)
*Xiaomeng Hu,Fei Huang,Chenhan Yuan,Junyang Lin,Tsung-Yi Ho*

Main category: cs.LG

TL;DR: CARE框架通过实时安全监控、回滚机制和自省干预策略，在解码阶段实现安全对齐，在安全性和响应质量之间取得优越平衡


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在现实应用中部署时，确保解码输出的安全性成为关键挑战，现有方法往往在安全性和响应质量之间需要严重权衡

Method: 提出CARE框架，包含三个核心组件：(1)实时安全监控的守卫模型；(2)带令牌缓冲区的回滚机制，早期高效纠正不安全输出；(3)基于自省的干预策略，模型生成对先前输出的自我反思批判，并将这些反思纳入上下文指导后续解码

Result: 实验结果表明该框架在安全性、质量和效率方面达到优越平衡，有害响应率低，对用户体验干扰最小，同时保持高响应质量

Conclusion: CARE框架通过精确干预、及时纠正和有效自校正，实现了安全性和响应质量之间的优越权衡，为解码时安全对齐提供了有效解决方案

Abstract: As large language models (LLMs) are increasingly deployed in real-world
applications, ensuring the safety of their outputs during decoding has become a
critical challenge. However, existing decoding-time interventions, such as
Contrastive Decoding, often force a severe trade-off between safety and
response quality. In this work, we propose CARE, a novel framework for
decoding-time safety alignment that integrates three key components: (1) a
guard model for real-time safety monitoring, enabling detection of potentially
unsafe content; (2) a rollback mechanism with a token buffer to correct unsafe
outputs efficiently at an earlier stage without disrupting the user experience;
and (3) a novel introspection-based intervention strategy, where the model
generates self-reflective critiques of its previous outputs and incorporates
these reflections into the context to guide subsequent decoding steps. The
framework achieves a superior safety-quality trade-off by using its guard model
for precise interventions, its rollback mechanism for timely corrections, and
our novel introspection method for effective self-correction. Experimental
results demonstrate that our framework achieves a superior balance of safety,
quality, and efficiency, attaining a low harmful response rate and minimal
disruption to the user experience while maintaining high response quality.

</details>


### [52] [Measuring Uncertainty in Transformer Circuits with Effective Information Consistency](https://arxiv.org/abs/2509.07149)
*Anatoly A. Krasnovsky*

Main category: cs.LG

TL;DR: 提出了一种名为EICS的新指标，结合了层间不一致性和因果涌现度量，用于单次前向传播中量化Transformer电路的行为一致性和可信度


<details>
  <summary>Details</summary>
Motivation: 当前缺乏形式化的方法来量化Transformer电路中功能子图的行为一致性和可信度，需要一种白盒、单次前向传播的评估指标

Method: 基于层论/上同调和因果涌现理论，结合局部雅可比矩阵和激活值计算归一化的层不一致性，以及基于前向状态的高斯有效信息代理来度量电路级因果涌现

Result: 提出了EICS评分框架，提供了分数解释指南、计算开销分析（快速和精确模式）以及玩具验证分析

Conclusion: EICS为评估Transformer电路的行为一致性提供了理论框架和实用工具，但需要在实际LLM任务中进行实证验证

Abstract: Mechanistic interpretability has identified functional subgraphs within large
language models (LLMs), known as Transformer Circuits (TCs), that appear to
implement specific algorithms. Yet we lack a formal, single-pass way to
quantify when an active circuit is behaving coherently and thus likely
trustworthy. Building on prior systems-theoretic proposals, we specialize a
sheaf/cohomology and causal emergence perspective to TCs and introduce the
Effective-Information Consistency Score (EICS). EICS combines (i) a normalized
sheaf inconsistency computed from local Jacobians and activations, with (ii) a
Gaussian EI proxy for circuit-level causal emergence derived from the same
forward state. The construction is white-box, single-pass, and makes units
explicit so that the score is dimensionless. We further provide practical
guidance on score interpretation, computational overhead (with fast and exact
modes), and a toy sanity-check analysis. Empirical validation on LLM tasks is
deferred.

</details>


### [53] [ALICE: An Interpretable Neural Architecture for Generalization in Substitution Ciphers](https://arxiv.org/abs/2509.07282)
*Jeff Shen,Lindsay Smith*

Main category: cs.LG

TL;DR: 提出了ALICE模型，一个用于解决密码破解任务的编码器Transformer，在少量训练数据下实现了优异的泛化能力，并通过可解释性分析揭示了模型的分层推理过程。


<details>
  <summary>Details</summary>
Motivation: 密码破解任务具有组合复杂性（26!种可能映射），是研究神经网络在复杂组合领域泛化能力的理想测试平台。

Method: 开发了ALICE架构：简单的编码器Transformer，使用新颖的双射解码头通过Gumbel-Sinkhorn方法显式建模排列，支持直接提取学习到的密码映射。

Result: ALICE在仅使用约1500个独特密码训练后就能泛化到未见过的密码，准确率和速度都达到了新的最先进水平，仅覆盖了可能密码空间的极小部分（3.7×10⁻²⁴）。

Conclusion: 该架构和分析方法可扩展到任何具有双射映射和组合结构的领域，为神经网络泛化和可解释性提供了新的见解，模型的分层推理过程模拟了人类解决此类任务的策略。

Abstract: We present cryptogram solving as an ideal testbed for studying neural network
generalization in combinatorially complex domains. In this task, models must
decrypt text encoded with substitution ciphers, choosing from 26! possible
mappings without explicit access to the cipher. We develop ALICE (an
Architecture for Learning Interpretable Cryptogram dEcipherment): a simple
encoder-only Transformer that sets a new state-of-the-art for both accuracy and
speed on this decryption problem. Surprisingly, ALICE generalizes to unseen
ciphers after training on only ${\sim}1500$ unique ciphers, a minute fraction
($3.7 \times 10^{-24}$) of the possible cipher space. To enhance
interpretability, we introduce a novel bijective decoding head that explicitly
models permutations via the Gumbel-Sinkhorn method, enabling direct extraction
of learned cipher mappings. Through early exit analysis, we reveal how ALICE
progressively refines its predictions in a way that appears to mirror common
human strategies for this task: early layers employ frequency-based heuristics,
middle layers form word structures, and final layers correct individual
characters. Our architectural innovations and analysis methods extend beyond
cryptograms to any domain with bijective mappings and combinatorial structure,
offering new insights into neural network generalization and interpretability.

</details>


### [54] [Uncovering Scaling Laws for Large Language Models via Inverse Problems](https://arxiv.org/abs/2509.07909)
*Arun Verma,Zhaoxuan Wu,Zijian Zhou,Xiaoqiang Lin,Zhiliang Chen,Rachael Hwee Ling Sim,Rui Qiao,Jingtan Wang,Nhung Bui,Xinyuan Niu,Wenyang Hu,Gregory Kang Ruey Lau,Zi-Yu Khoo,Zitong Zhao,Xinyi Xu,Apivich Hemachandra,See-Kiong Ng,Bryan Kian Hsiang Low*

Main category: cs.LG

TL;DR: 通过逆问题方法探索LLM的缩放律，提高成本效果


<details>
  <summary>Details</summary>
Motivation: 大语言模型训练成本极高，需要更高效的方法来提升性能

Method: 借鉴逆问题在科学发现中的成功，建议用逆向推理方法探索LLM的缩放规律

Result: 提出了一种更有效的方法论方向，但需要进一步实验验证

Conclusion: 逆问题方法有望在LLM领域实现类似科学发现的效果，提高建模效率

Abstract: Large Language Models (LLMs) are large-scale pretrained models that have
achieved remarkable success across diverse domains. These successes have been
driven by unprecedented complexity and scale in both data and computations.
However, due to the high costs of training such models, brute-force
trial-and-error approaches to improve LLMs are not feasible. Inspired by the
success of inverse problems in uncovering fundamental scientific laws, this
position paper advocates that inverse problems can also efficiently uncover
scaling laws that guide the building of LLMs to achieve the desirable
performance with significantly better cost-effectiveness.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [55] [Competitive Audio-Language Models with Data-Efficient Single-Stage Training on Public Data](https://arxiv.org/abs/2509.07526)
*Gokul Karthik Kumar,Rishabh Saraf,Ludovick Lepauloux,Abdul Muneer,Billel Mokeddem,Hakim Hacid*

Main category: cs.SD

TL;DR: Falcon3-Audio是一个基于指令调优LLM和Whisper编码器的音频-语言模型家族，仅使用不到30K小时公开音频数据就在MMAU基准测试中达到64.14分，与最佳开源模型性能相当，同时具有卓越的数据和参数效率。


<details>
  <summary>Details</summary>
Motivation: 尽管音频在人类交流中至关重要，但大语言模型与音频的整合仍然探索不足，需要开发高效的音频-语言模型。

Method: 基于指令调优的大语言模型和Whisper编码器构建Falcon3-Audio模型家族，采用单阶段训练，避免了课程学习、多音频编码器和复杂交叉注意力连接器等常见复杂性。

Result: 7B模型在MMAU基准测试中获得64.14分，与R1-AQA性能相当；最小的1B模型仍能与2B-13B参数的开源模型竞争，且仅使用不到30K小时数据就达到了使用500K+小时数据训练模型的性能。

Conclusion: 研究表明，复杂的训练策略并非必要，简单的单阶段训练方法结合高效架构设计就能实现强大的音频-语言模型性能，为音频AI领域提供了更高效透明的解决方案。

Abstract: Large language models (LLMs) have transformed NLP, yet their integration with
audio remains underexplored -- despite audio's centrality to human
communication. We introduce Falcon3-Audio, a family of Audio-Language Models
(ALMs) built on instruction-tuned LLMs and Whisper encoders. Using a remarkably
small amount of public audio data -- less than 30K hours (5K unique) --
Falcon3-Audio-7B matches the best reported performance among open-weight models
on the MMAU benchmark, with a score of 64.14, matching R1-AQA, while
distinguishing itself through superior data and parameter efficiency,
single-stage training, and transparency. Notably, our smallest 1B model remains
competitive with larger open models ranging from 2B to 13B parameters. Through
extensive ablations, we find that common complexities -- such as curriculum
learning, multiple audio encoders, and intricate cross-attention connectors --
are not required for strong performance, even compared to models trained on
over 500K hours of data.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [56] [Beyond Sequential Reranking: Reranker-Guided Search Improves Reasoning Intensive Retrieval](https://arxiv.org/abs/2509.07163)
*Haike Xu,Tong Chen*

Main category: cs.IR

TL;DR: Reranker-Guided-Search (RGS) 是一种新的检索方法，通过直接根据重排序器偏好检索文档来规避传统检索-重排序管道的限制，在有限的重排序预算下显著提升检索准确性。


<details>
  <summary>Details</summary>
Motivation: 传统的检索-重排序管道存在两个关键限制：受限于初始检索的top-k文档质量，以及基于LLM的重排序器计算需求增长限制了可处理文档数量。

Method: 使用近似最近邻算法生成的邻近图进行贪婪搜索，基于文档相似性策略性地优先选择有前景的文档进行重排序。

Result: 在多个基准测试中取得显著性能提升：BRIGHT提升3.5分，FollowIR提升2.9分，M-BEIR提升5.1分，且重排序预算限制在100个文档内。

Conclusion: 在固定的嵌入和重排序器模型对下，策略性地选择要重排序的文档可以在有限的重排序预算下显著提高检索准确性。

Abstract: The widely used retrieve-and-rerank pipeline faces two critical limitations:
they are constrained by the initial retrieval quality of the top-k documents,
and the growing computational demands of LLM-based rerankers restrict the
number of documents that can be effectively processed. We introduce
Reranker-Guided-Search (RGS), a novel approach that bypasses these limitations
by directly retrieving documents according to reranker preferences rather than
following the traditional sequential reranking method. Our method uses a greedy
search on proximity graphs generated by approximate nearest neighbor
algorithms, strategically prioritizing promising documents for reranking based
on document similarity. Experimental results demonstrate substantial
performance improvements across multiple benchmarks: 3.5 points on BRIGHT, 2.9
on FollowIR, and 5.1 on M-BEIR, all within a constrained reranker budget of 100
documents. Our analysis suggests that, given a fixed pair of embedding and
reranker models, strategically selecting documents to rerank can significantly
improve retrieval accuracy under limited reranker budget.

</details>


### [57] [Benchmarking Information Retrieval Models on Complex Retrieval Tasks](https://arxiv.org/abs/2509.07253)
*Julian Killingback,Hamed Zamani*

Main category: cs.IR

TL;DR: 该论文构建了一个多样化的复杂检索任务基准，评估了现有检索模型在复杂查询任务上的表现，发现即使是最好模型的表现也较差，并探索了LLM查询重写技术的影响。


<details>
  <summary>Details</summary>
Motivation: 现有检索模型缺乏处理复杂查询（包含多个部分、约束或需求的自然语言查询）的能力，而现有评估资源有限且缺乏现实性，需要构建更全面的复杂检索任务基准来推动下一代检索模型的发展。

Method: 构建了一个多样化和现实化的复杂检索任务集，对代表性的最先进检索模型进行基准测试，并探索基于LLM的查询扩展和重写技术对检索质量的影响。

Result: 即使是最好的模型在复杂检索任务上也表现不佳，平均nDCG@10仅为0.346，R@100仅为0.587。LLM增强技术对较弱模型有帮助，但对最强模型在所有重写技术下所有指标都出现性能下降。

Conclusion: 当前检索模型在处理复杂检索任务方面存在显著不足，需要开发更先进的模型和技术来应对现实世界中复杂的检索需求，LLM查询重写技术对模型性能的影响因模型强弱而异。

Abstract: Large language models (LLMs) are incredible and versatile tools for
text-based tasks that have enabled countless, previously unimaginable,
applications. Retrieval models, in contrast, have not yet seen such capable
general-purpose models emerge. To achieve this goal, retrieval models must be
able to perform complex retrieval tasks, where queries contain multiple parts,
constraints, or requirements in natural language. These tasks represent a
natural progression from the simple, single-aspect queries that are used in the
vast majority of existing, commonly used evaluation sets. Complex queries
naturally arise as people expect search systems to handle more specific and
often ambitious information requests, as is demonstrated by how people use
LLM-based information systems. Despite the growing desire for retrieval models
to expand their capabilities in complex retrieval tasks, there exist limited
resources to assess the ability of retrieval models on a comprehensive set of
diverse complex tasks. The few resources that do exist feature a limited scope
and often lack realistic settings making it hard to know the true capabilities
of retrieval models on complex real-world retrieval tasks. To address this
shortcoming and spur innovation in next-generation retrieval models, we
construct a diverse and realistic set of complex retrieval tasks and benchmark
a representative set of state-of-the-art retrieval models. Additionally, we
explore the impact of LLM-based query expansion and rewriting on retrieval
quality. Our results show that even the best models struggle to produce
high-quality retrieval results with the highest average nDCG@10 of only 0.346
and R@100 of only 0.587 across all tasks. Although LLM augmentation can help
weaker models, the strongest model has decreased performance across all metrics
with all rewriting techniques.

</details>
