<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 42]
- [cs.CR](#cs.CR) [Total: 2]
- [cs.LG](#cs.LG) [Total: 2]
- [eess.AS](#eess.AS) [Total: 2]
- [cs.AI](#cs.AI) [Total: 3]
- [cs.SE](#cs.SE) [Total: 1]
- [cs.IR](#cs.IR) [Total: 1]
- [q-bio.NC](#q-bio.NC) [Total: 1]
- [cs.CV](#cs.CV) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [From Image Captioning to Visual Storytelling](https://arxiv.org/abs/2508.14045)
*Admitos Passadakis,Yingjin Song,Albert Gatt*

Main category: cs.CL

TL;DR: 该论文将视觉叙事视为图像描述的超集，通过先使用视觉-语言模型生成图像描述，再用语言-语言方法转换为连贯故事，在质量、训练效率和可复用性方面取得积极效果


<details>
  <summary>Details</summary>
Motivation: 视觉叙事需要在图像序列的基础上生成既接地气又叙事连贯的故事，现有方法在这两方面难以平衡

Method: 采用两阶段方法：首先使用视觉-语言模型获得输入图像的描述，然后通过语言-语言方法将这些描述转换为连贯的叙事

Result: 集成图像描述和故事叙述的统一框架对生成故事质量有积极影响，加速训练时间，提高框架的可重用性和可复现性

Conclusion: 提出的方法有效平衡了视觉叙事的两个关键方面，并引入了新的ideality度量工具来模拟结果与理想模型的接近程度

Abstract: Visual Storytelling is a challenging multimodal task between Vision &
Language, where the purpose is to generate a story for a stream of images. Its
difficulty lies on the fact that the story should be both grounded to the image
sequence but also narrative and coherent. The aim of this work is to balance
between these aspects, by treating Visual Storytelling as a superset of Image
Captioning, an approach quite different compared to most of prior relevant
studies. This means that we firstly employ a vision-to-language model for
obtaining captions of the input images, and then, these captions are
transformed into coherent narratives using language-to-language methods. Our
multifarious evaluation shows that integrating captioning and storytelling
under a unified framework, has a positive impact on the quality of the produced
stories. In addition, compared to numerous previous studies, this approach
accelerates training time and makes our framework readily reusable and
reproducible by anyone interested. Lastly, we propose a new metric/tool, named
ideality, that can be used to simulate how far some results are from an oracle
model, and we apply it to emulate human-likeness in visual storytelling.

</details>


### [2] [Benchmarking Sociolinguistic Diversity in Swahili NLP: A Taxonomy-Guided Approach](https://arxiv.org/abs/2508.14051)
*Kezia Oketch,John P. Lalor,Ahmed Abbasi*

Main category: cs.CL

TL;DR: 首个斯瓦希里语NLP的分类学指导评估，关注社会语言学多样性差距，基于健康心理测量任务收集了2170个肯尼亚人的自由文本回复数据


<details>
  <summary>Details</summary>
Motivation: 解决斯瓦希里语NLP评估中社会语言学多样性不足的问题，建立文化背景化的评估框架

Method: 收集健康相关心理测量任务的自由文本响应数据，开发结构化分类学，用于分析预训练和指令调优语言模型的预测错误

Result: 数据展现了部落影响、城市方言、代码混合和借词现象，分类学分析揭示了社会语言学变异对模型性能的影响

Conclusion: 研究推进了文化基础评估框架的发展，强调了社会语言学变异在塑造模型性能中的重要作用

Abstract: We introduce the first taxonomy-guided evaluation of Swahili NLP, addressing
gaps in sociolinguistic diversity. Drawing on health-related psychometric
tasks, we collect a dataset of 2,170 free-text responses from Kenyan speakers.
The data exhibits tribal influences, urban vernacular, code-mixing, and
loanwords. We develop a structured taxonomy and use it as a lens for examining
model prediction errors across pre-trained and instruction-tuned language
models. Our findings advance culturally grounded evaluation frameworks and
highlight the role of sociolinguistic variation in shaping model performance.

</details>


### [3] [Contrastive Analysis of Constituent Order Preferences Within Adverbial Roles in English and Chinese News: A Large-Language-Model-Driven Approach](https://arxiv.org/abs/2508.14054)
*Yiran Rex Ma*

Main category: cs.CL

TL;DR: 这篇论文基于LLM注释的英汉新闻语料库，从功能块角度分析了英汉新闻在状语成分顺序上的差异，发现英语偏向核心信息先行、功能块后置，而汉语偏向背景先行、功能块前置的模式。


<details>
  <summary>Details</summary>
Motivation: 通过对比英汉新闻语料中具有状语功能的成分顺序差异的研究，探索两种语言在信息结构和语用目的上的系统性偏好与动态适应性。

Method: 使用大语言模型（LLM）注释的可比英汉新闻语料库，从功能块角度分析具有状语角色的成分顺序差异，重点研究位置偏好和分布模式。

Result: 发现：1）英语新闻偏向核心信息先行的线性叙事，功能块多后置；汉语偏向背景先行的整体呈现，功能块常前置。 2）SVO结构中两者分布差异显著，汉语前置倾向更明显。 3）功能块共现时两者都显示高灵活性，顺序调整受信息和语用驱动。

Conclusion: 词序具有系统性偏好和动态适应性的双重特征，为英汉信息结构对比研究提供了新的实证支持。

Abstract: Based on comparable English-Chinese news corpora annotated by Large Language
Model (LLM), this paper attempts to explore the differences in constituent
order of English-Chinese news from the perspective of functional chunks with
adverbial roles, and analyze their typical positional preferences and
distribution patterns. It is found that: (1) English news prefers linear
narrative of core information first, and functional chunks are mostly
post-positioned, while Chinese news prefers overall presentation mode of
background first, and functional chunks are often pre-positioned; (2) In SVO
structure, both English and Chinese news show differences in the distribution
of functional chunks, but the tendency of Chinese pre-positioning is more
significant, while that of English post-positioning is relatively mild; (3)
When function blocks are co-occurring, both English and Chinese news show high
flexibility, and the order adjustment is driven by information and pragmatic
purposes. The study reveals that word order has both systematic preference and
dynamic adaptability, providing new empirical support for contrastive study of
English-Chinese information structure.

</details>


### [4] [T-REX: Table -- Refute or Entail eXplainer](https://arxiv.org/abs/2508.14055)
*Tim Luka Horstmann,Baptiste Geisenberger,Mehwish Alam*

Main category: cs.CL

TL;DR: T-REX是一个交互式工具，使用指令调优的大型语言模型来验证多模态多语言表格中的文本声明，为非专家提供先进的事实核查技术。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的表格事实核查解决方案对非专家用户不够友好，需要开发一个易于访问的交互式工具来验证结构化表格数据中的文本声明。

Method: 开发了T-REX系统，使用最先进的指令调优推理大语言模型，支持多模态和多语言表格的声明验证，提供实时交互功能。

Result: 成功创建了首个面向非专家的实时交互式表格事实核查工具，该系统已在网上公开可用。

Conclusion: T-REX通过提供准确透明的表格事实核查能力，使非专家用户能够访问先进的事实核查技术，推动了自然语言处理中表格验证任务的可及性。

Abstract: Verifying textual claims against structured tabular data is a critical yet
challenging task in Natural Language Processing with broad real-world impact.
While recent advances in Large Language Models (LLMs) have enabled significant
progress in table fact-checking, current solutions remain inaccessible to
non-experts. We introduce T-REX (T-REX: Table -- Refute or Entail eXplainer),
the first live, interactive tool for claim verification over multimodal,
multilingual tables using state-of-the-art instruction-tuned reasoning LLMs.
Designed for accuracy and transparency, T-REX empowers non-experts by providing
access to advanced fact-checking technology. The system is openly available
online.

</details>


### [5] [Confidence Estimation for Text-to-SQL in Large Language Models](https://arxiv.org/abs/2508.14056)
*Sepideh Entezari Maleki,Mohammadreza Pourreza,Davood Rafiei*

Main category: cs.CL

TL;DR: 本文研究了在无法访问模型权重和梯度的情况下，对大语言模型生成的SQL查询进行置信度估计的方法，比较了黑盒和白盒策略，发现基于一致性的黑盒方法和SQL语法感知的白盒方法效果最好，执行结果可进一步提升性能。


<details>
  <summary>Details</summary>
Motivation: 文本到SQL的置信度估计旨在无需黄金答案的情况下评估模型生成SQL查询的可靠性，特别是在大语言模型环境中，模型权重和梯度访问受限的情况下。

Method: 探索了黑盒和白盒置信度估计策略，包括基于一致性的黑盒方法和SQL语法感知的白盒方法，并利用查询执行结果作为补充信号。

Result: 评估显示基于一致性的黑盒方法表现最佳，SQL语法感知方法在白盒设置中具有优势，执行结果能有效提升两种方法的性能。

Conclusion: 研究为LLM生成的SQL查询提供了有效的置信度估计方案，结合一致性检查和语法分析的方法在跨域文本到SQL基准测试中表现出色。

Abstract: Confidence estimation for text-to-SQL aims to assess the reliability of
model-generated SQL queries without having access to gold answers. We study
this problem in the context of large language models (LLMs), where access to
model weights and gradients is often constrained. We explore both black-box and
white-box confidence estimation strategies, evaluating their effectiveness on
cross-domain text-to-SQL benchmarks. Our evaluation highlights the superior
performance of consistency-based methods among black-box models and the
advantage of SQL-syntax-aware approaches for interpreting LLM logits in
white-box settings. Furthermore, we show that execution-based grounding of
queries provides a valuable supplementary signal, improving the effectiveness
of both approaches.

</details>


### [6] [Assessing and Mitigating Data Memorization Risks in Fine-Tuned Large Language Models](https://arxiv.org/abs/2508.14062)
*Badrinath Ramakrishnan,Akshaya Balaji*

Main category: cs.CL

TL;DR: 本文通过实证分析发现微调LLM会显著增加数据记忆风险（从0-5%增至60-75%），并提出多层级隐私保护框架，成功将数据泄露降至0%同时保持94.7%的模型效用。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在微调过程中容易记忆训练数据，带来严重的隐私风险，需要系统性的隐私保护解决方案。

Method: 提出包含语义数据去重、差分隐私生成、基于熵的过滤和基于模式的内容过滤的四层隐私保护框架，并在GPT-2、Phi-3和Gemma-2等模型上进行实验验证。

Result: 实验显示该框架能将数据泄露率从60-75%降至0%，同时保持94.7%的原始模型效用。

Conclusion: 多层级隐私保护框架能有效解决LLM微调中的数据记忆问题，在保护隐私的同时维持模型性能。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across
diverse natural language processing tasks, but their tendency to memorize
training data poses significant privacy risks, particularly during fine-tuning
processes. This paper presents a comprehensive empirical analysis of data
memorization in fine-tuned LLMs and introduces a novel multi-layered privacy
protection framework. Through controlled experiments on modern LLM
architectures including GPT-2, Phi-3, and Gemma-2, we demonstrate that
fine-tuning with repeated sensitive data increases privacy leakage rates from
baseline levels of 0-5% to 60-75%, representing a 64.2% average increase across
tested models. We propose and rigorously evaluate four complementary privacy
protection methods: semantic data deduplication, differential privacy during
generation, entropy-based filtering, and pattern-based content filtering. Our
experimental results show that these techniques can reduce data leakage to 0%
while maintaining 94.7% of original model utility.

</details>


### [7] [Punctuation and Predicates in Language Models](https://arxiv.org/abs/2508.14067)
*Sonakshi Chauhan,Maheep Chaudhary,Koby Choy,Samuel Nellessen,Nandi Schoots*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型中信息的收集和传播方式，重点关注标点符号的计算重要性以及不同推理规则的处理差异。通过干预实验发现GPT-2对标点符号依赖性强，而DeepSeek和Gemma较弱，且条件语句和全称量化等推理规则的处理方式存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型中信息在层间的收集和传播机制，特别是标点符号作为注意力汇聚点和记忆辅助工具的计算重要性，以及不同推理规则的处理方式差异。

Method: 使用基于干预的技术，在GPT-2、DeepSeek和Gemma模型中进行标点符号的必要性和充分性评估，通过交换干预和层交换实验分析条件语句和全称量化等推理规则的处理方式。

Result: 发现模型间存在显著差异：GPT-2在多个层中对标点符号既必要又充分，DeepSeek较弱，Gemma完全不依赖。不同推理规则（条件语句、全称量化）的处理方式也截然不同。

Conclusion: 研究揭示了LLMs中标点符号使用和推理的内部机制，为模型可解释性提供了新的见解，表明不同模型组件和推理规则的处理存在特异性。

Abstract: In this paper we explore where information is collected and how it is
propagated throughout layers in large language models (LLMs). We begin by
examining the surprising computational importance of punctuation tokens which
previous work has identified as attention sinks and memory aids. Using
intervention-based techniques, we evaluate the necessity and sufficiency (for
preserving model performance) of punctuation tokens across layers in GPT-2,
DeepSeek, and Gemma. Our results show stark model-specific differences: for
GPT-2, punctuation is both necessary and sufficient in multiple layers, while
this holds far less in DeepSeek and not at all in Gemma. Extending beyond
punctuation, we ask whether LLMs process different components of input (e.g.,
subjects, adjectives, punctuation, full sentences) by forming early static
summaries reused across the network, or if the model remains sensitive to
changes in these components across layers. Extending beyond punctuation, we
investigate whether different reasoning rules are processed differently by
LLMs. In particular, through interchange intervention and layer-swapping
experiments, we find that conditional statements (if, then), and universal
quantification (for all) are processed very differently. Our findings offer new
insight into the internal mechanisms of punctuation usage and reasoning in LLMs
and have implications for interpretability.

</details>


### [8] [DLLMQuant: Quantizing Diffusion-based Large Language Models](https://arxiv.org/abs/2508.14090)
*Chen Xu,Dawei Yang*

Main category: cs.CL

TL;DR: DLLMQuant是一个专门为扩散式大语言模型设计的后训练量化框架，通过时间-掩码自适应采样、交互感知激活量化和确定性引导量化三项技术，解决了现有量化方法在DLLMs上的严重性能退化问题。


<details>
  <summary>Details</summary>
Motivation: 扩散式大语言模型在非自回归文本生成方面表现优异，但直接应用现有的后训练量化方法会导致严重的精度下降（如AWQ在W4A4配置下精度下降16%），主要原因是DLLMs的动态掩码、迭代生成和双向注意力机制与量化方法不兼容。

Method: 提出DLLMQuant框架，包含三项核心技术：1) 时间-掩码自适应采样(TMAS)：考虑时间和掩码因素的校准方法，能够捕捉不同时间步的分布；2) 交互感知激活量化(IA-AQ)：利用双向注意力的交互信号动态分配量化资源；3) 确定性引导量化(CGQ)：将掩码状态和token分数作为误差补偿的关键权重标准。

Result: 实验表明DLLMQuant在保持效率的同时实现了显著的性能提升，有效解决了量化误差在迭代过程中的累积和放大问题。

Conclusion: DLLMQuant是针对扩散式大语言模型量化挑战的有效解决方案，通过专门设计的量化技术成功克服了现有方法在DLLMs上的局限性，为DLLMs的高效部署提供了可行路径。

Abstract: Diffusion-based large language models (DLLMs) have shown promise for
non-autoregressive text generation, but their deployment is constrained by
large model sizes and heavy computational costs. Post-training quantization
(PTQ), a widely used method for compressing and accelerating Large Language
Models (LLMs), suffers from severe accuracy degradation and reduced
generalization performance when directly applied to DLLMs (e.g., AWQ suffers a
16% accuracy drop on LLADA under W4A4). This paper explores how DLLMs' key
mechanisms - dynamic masking, iterative generation, bidirectional attention -
clash with quantization. We identify three core issues: 1) Iterative generation
and dynamic masking ratios lead to distinct token distributions across decoding
steps, which are not adequately captured by existing PTQ calibration methods;
2) Quantization errors are accumulated and amplified progressively during
iteration in DLLMs, causing quantized models to perform worse as decoding steps
progress; 3) Unmasked tokens stabilize while masked remain probabilistic,
making overall feature distribution incompatible with existing PTQ methods. To
address these issues, we propose DLLMQuant, a PTQ framework tailored for DLLMs,
which incorporates three novel techniques: 1) Temporal-Mask Adaptive Sampling
(TMAS), a calibration method that accounts for both time and mask factors, with
the capacity to capture distributions across timesteps. 2) Interaction-Aware
Activation Quantization (IA-AQ), which utilizes bidirectional attention's
interaction signals to dynamically allocate quantization resources. 3)
Certainty-Guided Quantization (CGQ), which integrates mask status and token
scores as key weighting criteria into error compensation, making weight
quantization more suitable for DLLMs. Experiments show that DLLMQuant achieves
significant performance gains while enhancing efficiency.

</details>


### [9] [MMReview: A Multidisciplinary and Multimodal Benchmark for LLM-Based Peer Review Automation](https://arxiv.org/abs/2508.14146)
*Xian Gao,Jiacheng Ruan,Zongyun Zhang,Jingsheng Gao,Ting Liu,Yuzhuo Fu*

Main category: cs.CL

TL;DR: MMReview是一个多模态学术论文评审基准，涵盖17个研究领域的240篇论文，包含13个任务来评估LLM和MLLM在生成评审意见方面的能力。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的论文评审缺乏统一的评估基准，特别是在处理包含图表等多模态内容时，无法全面评估模型生成全面、准确且符合人类偏好的评审意见的能力。

Method: 构建包含多模态内容和专家撰写评审意见的基准数据集，设计13个任务分为四个核心类别：逐步评审生成、结果制定、人类偏好对齐和对抗性输入鲁棒性。

Result: 在16个开源模型和5个先进闭源模型上进行了广泛实验，证明了基准的全面性。

Conclusion: MMReview为自动化同行评审系统的开发建立了标准化基础，是迈向该领域标准化的重要一步。

Abstract: With the rapid growth of academic publications, peer review has become an
essential yet time-consuming responsibility within the research community.
Large Language Models (LLMs) have increasingly been adopted to assist in the
generation of review comments; however, current LLM-based review tasks lack a
unified evaluation benchmark to rigorously assess the models' ability to
produce comprehensive, accurate, and human-aligned assessments, particularly in
scenarios involving multimodal content such as figures and tables. To address
this gap, we propose \textbf{MMReview}, a comprehensive benchmark that spans
multiple disciplines and modalities. MMReview includes multimodal content and
expert-written review comments for 240 papers across 17 research domains within
four major academic disciplines: Artificial Intelligence, Natural Sciences,
Engineering Sciences, and Social Sciences. We design a total of 13 tasks
grouped into four core categories, aimed at evaluating the performance of LLMs
and Multimodal LLMs (MLLMs) in step-wise review generation, outcome
formulation, alignment with human preferences, and robustness to adversarial
input manipulation. Extensive experiments conducted on 16 open-source models
and 5 advanced closed-source models demonstrate the thoroughness of the
benchmark. We envision MMReview as a critical step toward establishing a
standardized foundation for the development of automated peer review systems.

</details>


### [10] [DPad: Efficient Diffusion Language Models with Suffix Dropout](https://arxiv.org/abs/2508.14148)
*Xinhua Chen,Sitao Huang,Cong Guo,Chiyue Wei,Yintao He,Jianyi Zhang,Hai "Hellen" Li,Yiran Chen*

Main category: cs.CL

TL;DR: DPad是一种无需训练的方法，通过滑动窗口和距离衰减dropout策略，显著降低基于扩散的大语言模型的计算开销，实现高达61.4倍的加速，同时保持相当的准确性。


<details>
  <summary>Details</summary>
Motivation: 基于扩散的大语言模型(dLLMs)在文本生成时存在高计算开销问题，因为它们在每一步预测所有未来后缀标记但只保留一小部分，造成了大量冗余计算。

Method: 提出Diffusion Scratchpad (DPad)方法，包含两种策略：(i)滑动窗口：保持固定长度的后缀窗口；(ii)距离衰减dropout：在注意力计算前确定性移除远处的后缀标记。该方法与现有优化技术兼容且代码实现简单。

Result: 在LLaDA-1.5和Dream模型上的多基准测试表明，DPad相比原始dLLMs实现了高达61.4倍的加速，同时保持了相当的准确性。

Conclusion: DPad展示了在高效和可扩展的长序列推理方面的巨大潜力，为扩散语言模型的实际应用提供了有效的优化方案。

Abstract: Diffusion-based Large Language Models (dLLMs) parallelize text generation by
framing decoding as a denoising process, but suffer from high computational
overhead since they predict all future suffix tokens at each step while
retaining only a small fraction. We propose Diffusion Scratchpad (DPad), a
training-free method that restricts attention to a small set of nearby suffix
tokens, preserving fidelity while eliminating redundancy. DPad integrates two
strategies: (i) a sliding window, which maintains a fixed-length suffix window,
and (ii) distance-decay dropout, which deterministically removes distant suffix
tokens before attention computation. This simple design is compatible with
existing optimizations such as prefix caching and can be implemented with only
a few lines of code. Comprehensive evaluations across multiple benchmarks on
LLaDA-1.5 and Dream models demonstrate that DPad delivers up to
$\mathbf{61.4\times}$ speedup over vanilla dLLMs while maintaining comparable
accuracy, highlighting its potential for efficient and scalable long-sequence
inference. Our code is available at https://github.com/Crys-Chen/DPad.

</details>


### [11] [Comparing energy consumption and accuracy in text classification inference](https://arxiv.org/abs/2508.14170)
*Johannes Zschache,Tilman Hartwig*

Main category: cs.CL

TL;DR: 本研究系统评估了文本分类推理中模型准确性与能耗的权衡，发现最佳准确率模型同样可以节能，而大型LLM能耗更高但准确率更低，执行时间可作为能耗的有效代理指标。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在NLP任务中的广泛应用，能效和可持续性问题日益突出。现有研究主要关注训练阶段的能耗，推理阶段的能耗研究相对不足。

Method: 通过实证分析，在不同模型架构和硬件配置下系统评估文本分类推理的准确性与能耗关系，分析模型类型、大小和硬件规格对能耗的影响。

Result: 发现最佳准确率模型同样节能，大型LLM能耗显著更高但分类准确率更低；推理能耗存在巨大差异（<mWh到>kWh），与模型运行时间强相关。

Conclusion: 执行时间可作为能耗的实用代理指标，这些发现为可持续AI发展提供了重要见解，有助于研究者和从业者在NLP应用中平衡性能与资源效率。

Abstract: The increasing deployment of large language models (LLMs) in natural language
processing (NLP) tasks raises concerns about energy efficiency and
sustainability. While prior research has largely focused on energy consumption
during model training, the inference phase has received comparatively less
attention. This study systematically evaluates the trade-offs between model
accuracy and energy consumption in text classification inference across various
model architectures and hardware configurations. Our empirical analysis shows
that the best-performing model in terms of accuracy can also be
energy-efficient, while larger LLMs tend to consume significantly more energy
with lower classification accuracy. We observe substantial variability in
inference energy consumption ($<$mWh to $>$kWh), influenced by model type,
model size, and hardware specifications. Additionally, we find a strong
correlation between inference energy consumption and model runtime, indicating
that execution time can serve as a practical proxy for energy usage in settings
where direct measurement is not feasible. These findings have implications for
sustainable AI development, providing actionable insights for researchers,
industry practitioners, and policymakers seeking to balance performance and
resource efficiency in NLP applications.

</details>


### [12] [Let's Use ChatGPT To Write Our Paper! Benchmarking LLMs To Write the Introduction of a Research Paper](https://arxiv.org/abs/2508.14273)
*Krishna Garg,Firoz Shaikh,Sambaran Bandyopadhyay,Cornelia Caragea*

Main category: cs.CL

TL;DR: 本文提出了科学引言生成任务(SciIG)，评估LLMs从标题、摘要和相关工作生成连贯研究论文引言的能力。通过综合评估框架测试了5个先进模型，发现LLLaMA-4 Maverick在语义相似性和忠实度方面表现最佳，三样本提示优于少样本方法。


<details>
  <summary>Details</summary>
Motivation: 随着研究人员越来越多地使用LLMs作为写作助手，生成高质量的研究论文引言仍然具有挑战性且至关重要。需要系统评估LLMs在学术写作中的实际能力。

Method: 从NAACL 2025和ICLR 2025论文中整理新数据集，评估5个最先进模型（包括开源和闭源系统），使用多维度评估框架结合自动化指标和LLM-as-a-judge评估方法。

Result: LLaMA-4 Maverick在大多数指标上表现最优，特别是在语义相似性和忠实度方面。三样本提示方法始终优于少样本方法。

Conclusion: 研究结果为开发有效的研究写作助手提供了实用见解，并为LLM辅助学术写作设定了现实期望。所有代码和数据集将公开发布以促进可重复性和未来研究。

Abstract: As researchers increasingly adopt LLMs as writing assistants, generating
high-quality research paper introductions remains both challenging and
essential. We introduce Scientific Introduction Generation (SciIG), a task that
evaluates LLMs' ability to produce coherent introductions from titles,
abstracts, and related works. Curating new datasets from NAACL 2025 and ICLR
2025 papers, we assess five state-of-the-art models, including both open-source
(DeepSeek-v3, Gemma-3-12B, LLaMA 4-Maverick, MistralAI Small 3.1) and
closed-source GPT-4o systems, across multiple dimensions: lexical overlap,
semantic similarity, content coverage, faithfulness, consistency, citation
correctness, and narrative quality. Our comprehensive framework combines
automated metrics with LLM-as-a-judge evaluations. Results demonstrate LLaMA-4
Maverick's superior performance on most metrics, particularly in semantic
similarity and faithfulness. Moreover, three-shot prompting consistently
outperforms fewer-shot approaches. These findings provide practical insights
into developing effective research writing assistants and set realistic
expectations for LLM-assisted academic writing. To foster reproducibility and
future research, we will publicly release all code and datasets.

</details>


### [13] [Disentangling concept semantics via multilingual averaging in Sparse Autoencoders](https://arxiv.org/abs/2508.14275)
*Cliff O'Reilly,Ernesto Jimenez-Ruiz,Tillman Weyde*

Main category: cs.CL

TL;DR: 通过多语言概念激活平均法，从LLM中提取语义概念表示，提高与本体类真实关系的对齐度


<details>
  <summary>Details</summary>
Motivation: 解决LLM中语义与语法、语言信息纠缠的问题，实现更好的形式化知识表示和推理

Method: 使用稀疏自编码器获取概念激活，对英语、法语、中文版本的概念激活进行平均，得到概念平均表示

Result: 概念平均表示相比单语言版本，与本体类真实关系有更好的对齐效果

Conclusion: 该方法为机制解释内部网络状态提供了新技术，能更准确地提取语义概念

Abstract: Connecting LLMs with formal knowledge representation and reasoning is a
promising approach to address their shortcomings. Embeddings and sparse
autoencoders are widely used to represent textual content, but the semantics
are entangled with syntactic and language-specific information. We propose a
method that isolates concept semantics in Large Langue Models by averaging
concept activations derived via Sparse Autoencoders. We create English text
representations from OWL ontology classes, translate the English into French
and Chinese and then pass these texts as prompts to the Gemma 2B LLM. Using the
open source Gemma Scope suite of Sparse Autoencoders, we obtain concept
activations for each class and language version. We average the different
language activations to derive a conceptual average. We then correlate the
conceptual averages with a ground truth mapping between ontology classes. Our
results give a strong indication that the conceptual average aligns to the true
relationship between classes when compared with a single language by itself.
The result hints at a new technique which enables mechanistic interpretation of
internal network states with higher accuracy.

</details>


### [14] [GRILE: A Benchmark for Grammar Reasoning and Explanation in Romanian LLMs](https://arxiv.org/abs/2508.14279)
*Adrian-Marius Dumitran,Alexandra-Mihaela Danila,Angela-Liliana Dumitran*

Main category: cs.CL

TL;DR: GRILE是首个罗马尼亚语教育基准测试，包含1151道选择题，用于评估LLM在低资源语言中的答题准确性和解释生成能力。研究发现大多数开源模型表现不佳，解释中存在大量事实性错误。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型在低资源语言（罗马尼亚语）教育场景中的实际价值，特别是答题准确性和生成语言学解释的能力。

Method: 构建GRILE基准测试，包含来自罗马尼亚高利害考试的1151道选择题，评估7个多语言和罗马尼亚专用LLM的答题准确性和解释质量，并由专家评审解释的准确性。

Result: Gemini 2.5 Pro达到83%准确率，但大多数开源模型低于65%，48%的解释存在事实性或教学性错误。错误主要集中在形态学和最新正字法规范应用方面。

Conclusion: GRILE揭示了低资源教育NLP的开放挑战，为可控解释生成和评估提供了新的测试平台，所有数据和代码已公开以促进未来研究。

Abstract: LLMs (Large language models) have revolutionized NLP (Natural Language
Processing), yet their pedagogical value for low-resource languages remains
unclear. We present GRILE (Grammar Romanian Inference and Language
Explanations) , the first open benchmark of 1,151 multiple-choice questions
harvested from Romanian high-stakes exams (National Evaluation, Baccalaureate,
university admissions). GRILE enables us to probe two complementary abilities
of seven state-of-the-art multilingual and Romanian-specific LLMs: (i)
selecting the correct answer, and (ii) producing linguistically accurate
explanations. While Gemini 2.5 Pro reaches 83% accuracy, most open-weight
models stay below 65%, and 48% of their explanations contain factual or
pedagogical flaws according to expert review. A detailed error analysis
pinpoints systematic weaknesses in morphology and in applying the latest DOOM3
orthographic norms. All data, code and a public web demo are released to
catalyze future research. Our findings expose open challenges for trustworthy
educational NLP in low-resource settings and establish GRILE as a new test-bed
for controllable explanation generation and evaluation.

</details>


### [15] [Tokens with Meaning: A Hybrid Tokenization Approach for NLP](https://arxiv.org/abs/2508.14292)
*M. Ali Bayram,Ali Arda Fincan,Ahmet Semih Gümüş,Sercan Karakaş,Banu Diri,Savaş Yıldırım,Demircan Çelik*

Main category: cs.CL

TL;DR: 提出了一种结合规则形态分析和统计子词分割的混合分词框架，针对形态丰富语言的分词问题，在土耳其语上取得了最佳性能


<details>
  <summary>Details</summary>
Motivation: 传统子词分词方法（如BPE、WordPiece）主要依赖频率统计，在处理形态丰富和粘着语时效果不佳，因为它们忽略了语言结构信息

Method: 结合基于规则的形态分析和统计子词分割，使用音位规范化、词根-词缀词典和新算法来平衡语素保留与词汇效率，为音位变体词缀和变化词根形式分配共享标识符

Result: 在TR-MMLU基准测试中，该分词器获得了最高的土耳其语分词百分比（90.29%）和纯分词百分比（85.8%），相比LLaMA、Gemma和GPT的分词器产生了更具语言学意义和连贯的分词结果

Conclusion: 该方法虽然以土耳其语为演示，但具有语言无关性，可适应其他语言，为实现更可解释和有效的多语言NLP系统提供了实用路径

Abstract: Tokenization plays a pivotal role in natural language processing (NLP),
shaping how text is segmented and interpreted by language models. While subword
methods such as Byte Pair Encoding (BPE) and WordPiece have been effective,
they often struggle with morphologically rich and agglutinative languages
because they rely on frequency rather than linguistic structure. We introduce a
hybrid tokenization framework that combines rule-based morphological analysis
with statistical subword segmentation. The method uses phonological
normalization, root-affix dictionaries, and a novel algorithm that balances
morpheme preservation with vocabulary efficiency. It assigns shared identifiers
to phonologically variant affixes (e.g., -ler and -lar) and altered root forms
(e.g., kitap vs. kitab{\i}), reducing redundancy while maintaining semantic
integrity. Special tokens are added for whitespace and case, including an
UPPERCASE marker to avoid vocabulary inflation from capitalization. BPE is
integrated for out-of-vocabulary coverage without harming morphological
coherence. On the TR-MMLU benchmark, the tokenizer achieves the highest Turkish
Token Percentage (90.29\%) and Pure Token Percentage (85.8\%). Comparisons with
tokenizers from LLaMA, Gemma, and GPT show more linguistically meaningful and
coherent tokens. Although demonstrated on Turkish, the approach is
language-independent and adaptable to other languages, offering a practical
path toward more interpretable and effective multilingual NLP systems.

</details>


### [16] [A Joint Multitask Model for Morpho-Syntactic Parsing](https://arxiv.org/abs/2508.14307)
*Demian Inostroza,Mel Mistica,Ekaterina Vylomova,Chris Guest,Kemal Kurniawan*

Main category: cs.CL

TL;DR: 提出了一个联合多任务模型用于UniDive 2025形态句法分析共享任务，在九种类型学多样语言上取得了最佳性能，平均MSLAS得分78.7%。


<details>
  <summary>Details</summary>
Motivation: 解决多语言形态句法分析任务，预测形态和句法分析，遵循新的UD标注方案。

Method: 使用共享的XLM-RoBERTa编码器和三个专门解码器：内容词识别、依存句法分析和形态句法特征预测。

Result: 在九种语言上获得最佳整体性能：MSLAS 78.7%、LAS 80.1%、Feats F1 90.3%。消融研究表明任务的金牌分词和内容词识别对性能至关重要。

Conclusion: 模型在多语言形态句法分析方面表现优异，但在核心语法格（特别是Nom-Acc）和名词特征方面仍存在挑战。

Abstract: We present a joint multitask model for the UniDive 2025 Morpho-Syntactic
Parsing shared task, where systems predict both morphological and syntactic
analyses following novel UD annotation scheme. Our system uses a shared
XLM-RoBERTa encoder with three specialized decoders for content word
identification, dependency parsing, and morphosyntactic feature prediction. Our
model achieves the best overall performance on the shared task's leaderboard
covering nine typologically diverse languages, with an average MSLAS score of
78.7 percent, LAS of 80.1 percent, and Feats F1 of 90.3 percent. Our ablation
studies show that matching the task's gold tokenization and content word
identification are crucial to model performance. Error analysis reveals that
our model struggles with core grammatical cases (particularly Nom-Acc) and
nominal features across languages.

</details>


### [17] [Zero-knowledge LLM hallucination detection and mitigation through fine-grained cross-model consistency](https://arxiv.org/abs/2508.14314)
*Aman Goel,Daniel Schwartz,Yanjun Qi*

Main category: cs.CL

TL;DR: Finch-Zk是一个黑盒框架，通过跨模型一致性检查来检测和缓解LLM幻觉，无需外部知识源，显著提升事实可靠性


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然能力强大，但容易产生看似合理但包含事实错误的幻觉内容，需要有效的检测和缓解方法

Method: 1) 跨模型一致性检查策略：通过语义等效提示比较不同模型的响应来发现细粒度错误；2) 针对性缓解技术：对问题片段进行精确修正同时保留准确内容

Result: 在FELM数据集上幻觉检测F1分数提升6-39%，在GPQA-diamond数据集上答案准确率绝对提升7-8个百分点

Conclusion: Finch-Zk为生产LLM系统提供了实用、可部署的安全保障，显著增强了事实可靠性

Abstract: Large language models (LLMs) have demonstrated impressive capabilities across
diverse tasks, but they remain susceptible to hallucinations--generating
content that appears plausible but contains factual inaccuracies. We present
Finch-Zk, a black-box framework that leverages FINe-grained Cross-model
consistency to detect and mitigate Hallucinations in LLM outputs without
requiring external knowledge sources. Finch-Zk introduces two key innovations:
1) a cross-model consistency checking strategy that reveals fine-grained
inaccuracies by comparing responses generated by diverse models from
semantically-equivalent prompts, and 2) a targeted mitigation technique that
applies precise corrections to problematic segments while preserving accurate
content. Experiments on the FELM dataset show Finch-Zk improves hallucination
detection F1 scores by 6-39\% compared to existing approaches. For mitigation,
Finch-Zk achieves 7-8 absolute percentage points improvement in answer accuracy
on the GPQA-diamond dataset when applied to state-of-the-art models like Llama
4 Maverick and Claude 4 Sonnet. Extensive evaluation across multiple models
demonstrates that Finch-Zk provides a practical, deployment-ready safeguard for
enhancing factual reliability in production LLM systems.

</details>


### [18] [SurveyGen-I: Consistent Scientific Survey Generation with Evolving Plans and Memory-Guided Writing](https://arxiv.org/abs/2508.14317)
*Jing Chen,Zhiheng Yang,Yixian Shen,Jie Liu,Adam Belloum,Chrysa Papagainni,Paola Grosso*

Main category: cs.CL

TL;DR: SurveyGen-I是一个自动生成综述论文的框架，通过粗到细检索、自适应规划和记忆引导生成技术，解决了现有LLM方法在长篇幅综述中的连贯性和引用覆盖问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的综述生成方法在保持长篇多章节综述的连贯性和提供全面引用覆盖方面存在困难，需要新的解决方案。

Method: 采用粗到细检索策略，先进行综述级别的检索构建初始大纲和写作计划，然后通过记忆机制动态优化，在检测到上下文不足时触发细粒度子章节检索，利用记忆机制保持子章节间的连贯性。

Result: 在四个科学领域的实验中，SurveyGen-I在内容质量、一致性和引用覆盖方面均优于先前的工作。

Conclusion: SurveyGen-I框架通过创新的检索和生成机制，有效提升了自动综述生成的质量和实用性，为科学文献综述自动化提供了可靠解决方案。

Abstract: Survey papers play a critical role in scientific communication by
consolidating progress across a field. Recent advances in Large Language Models
(LLMs) offer a promising solution by automating key steps in the
survey-generation pipeline, such as retrieval, structuring, and summarization.
However, existing LLM-based approaches often struggle with maintaining
coherence across long, multi-section surveys and providing comprehensive
citation coverage. To address these limitations, we introduce SurveyGen-I, an
automatic survey generation framework that combines coarse-to-fine retrieval,
adaptive planning, and memory-guided generation. SurveyGen-I first performs
survey-level retrieval to construct the initial outline and writing plan, and
then dynamically refines both during generation through a memory mechanism that
stores previously written content and terminology, ensuring coherence across
subsections. When the system detects insufficient context, it triggers
fine-grained subsection-level retrieval. During generation, SurveyGen-I
leverages this memory mechanism to maintain coherence across subsections.
Experiments across four scientific domains demonstrate that SurveyGen-I
consistently outperforms previous works in content quality, consistency, and
citation coverage.

</details>


### [19] [Beyond Semantic Similarity: Reducing Unnecessary API Calls via Behavior-Aligned Retriever](https://arxiv.org/abs/2508.14323)
*Yixin Chen,Ying Xiong,Shangyu Wu,Yufei Cui,Xue Liu,Nan Guan,Chun Jason Xue*

Main category: cs.CL

TL;DR: 本文提出了一种行为对齐检索器(BAR)，通过提供行为一致的演示样本来帮助LLM做出更准确的工具使用决策，显著减少错误函数调用。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过微调LLM或基于演示的提示来解决工具增强LLM中不准确函数调用的问题，但存在训练开销高和演示样本不一致导致模型调用行为误导的局限性。

Method: 构建包含不同函数调用行为（调用/不调用）的语料库，使用对比学习框架训练BAR，采用定制化的正负样本对和双负对比损失函数来确保行为一致示例的鲁棒检索。

Result: 实验表明该方法显著减少了错误函数调用，同时保持了高任务性能，为工具增强LLM提供了成本效益高且高效的解决方案。

Conclusion: 行为对齐检索器(BAR)通过提供行为一致的演示样本，有效解决了工具增强LLM中函数调用不准确的问题，是一种实用且高效的改进方法。

Abstract: Tool-augmented large language models (LLMs) leverage external functions to
extend their capabilities, but inaccurate function calls can lead to
inefficiencies and increased costs.Existing methods address this challenge by
fine-tuning LLMs or using demonstration-based prompting, yet they often suffer
from high training overhead and fail to account for inconsistent demonstration
samples, which misguide the model's invocation behavior. In this paper, we
trained a behavior-aligned retriever (BAR), which provides behaviorally
consistent demonstrations to help LLMs make more accurate tool-using decisions.
To train the BAR, we construct a corpus including different function-calling
behaviors, i.e., calling or non-calling.We use the contrastive learning
framework to train the BAR with customized positive/negative pairs and a
dual-negative contrastive loss, ensuring robust retrieval of behaviorally
consistent examples.Experiments demonstrate that our approach significantly
reduces erroneous function calls while maintaining high task performance,
offering a cost-effective and efficient solution for tool-augmented LLMs.

</details>


### [20] [ISCA: A Framework for Interview-Style Conversational Agents](https://arxiv.org/abs/2508.14344)
*Charles Welch,Allison Lahnala,Vasudha Varadarajan,Lucie Flek,Rada Mihalcea,J. Lomax Boyd,João Sedoc*

Main category: cs.CL

TL;DR: 提出了一种低计算量的非生成式对话系统，用于实现访谈式对话代理，支持定性数据收集和定量分析，可通过在线管理面板轻松调整，并提供了两个案例研究和开源代码。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够通过受控交互促进定性数据收集和定量分析的低计算量系统，适用于跟踪态度形成或行为变化等需要标准化对话流程的应用场景。

Method: 使用非生成式系统实现访谈式对话代理，通过在线管理面板进行配置和调整，无需编码即可创建新的访谈流程。

Result: 开发了可轻松调整的系统，并展示了两个成功案例：COVID-19表达性访谈系统和神经技术公众意见半结构化访谈。

Conclusion: 该系统为定性研究提供了实用的工具，开源代码允许其他研究者在此基础上进行扩展和功能开发。

Abstract: We present a low-compute non-generative system for implementing
interview-style conversational agents which can be used to facilitate
qualitative data collection through controlled interactions and quantitative
analysis. Use cases include applications to tracking attitude formation or
behavior change, where control or standardization over the conversational flow
is desired. We show how our system can be easily adjusted through an online
administrative panel to create new interviews, making the tool accessible
without coding. Two case studies are presented as example applications, one
regarding the Expressive Interviewing system for COVID-19 and the other a
semi-structured interview to survey public opinion on emerging neurotechnology.
Our code is open-source, allowing others to build off of our work and develop
extensions for additional functionality.

</details>


### [21] [ZPD-SCA: Unveiling the Blind Spots of LLMs in Assessing Students' Cognitive Abilities](https://arxiv.org/abs/2508.14377)
*Wenhan Dong,Zhen Sun,Yuemeng Zhao,Zifan Peng,Jun Wu,Jingyi Zheng,Yule Liu,Xinlei He,Yu Wang,Ruiming Wang,Xinyi Huang,Lei Mo*

Main category: cs.CL

TL;DR: 该研究提出了ZPD-SCA基准来评估大语言模型在判断中文阅读理解材料与学生认知能力匹配度方面的表现，发现LLMs在零样本学习下表现较差，但在上下文学习后性能显著提升，但仍存在系统性偏差。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型在教育应用中显示出潜力，但其准确评估阅读材料与学生认知发展阶段匹配度的能力尚未充分探索，特别是在中文教育背景下缺乏针对不同年龄段学生的阅读理解难度评估研究。

Method: 引入ZPD-SCA基准，由60位特级教师（全国前0.15%的在职教师）进行标注，专门用于评估阶段级中文阅读理解难度，通过零样本学习和上下文学习两种场景测试LLMs的表现。

Result: LLMs在零样本学习中表现不佳（Qwen-max和GLM甚至低于随机猜测概率），但在提供上下文示例后性能大幅提升，部分模型准确率接近零样本基线的两倍。最佳模型仍存在系统性方向偏差，且不同文体间性能差异显著。

Conclusion: LLMs具备评估阅读难度的新兴能力，但在教育对齐判断方面存在局限性。ZPD-SCA基准可为评估和改进LLMs在认知对齐教育应用中的表现提供基础。

Abstract: Large language models (LLMs) have demonstrated potential in educational
applications, yet their capacity to accurately assess the cognitive alignment
of reading materials with students' developmental stages remains insufficiently
explored. This gap is particularly critical given the foundational educational
principle of the Zone of Proximal Development (ZPD), which emphasizes the need
to match learning resources with Students' Cognitive Abilities (SCA). Despite
the importance of this alignment, there is a notable absence of comprehensive
studies investigating LLMs' ability to evaluate reading comprehension
difficulty across different student age groups, especially in the context of
Chinese language education. To fill this gap, we introduce ZPD-SCA, a novel
benchmark specifically designed to assess stage-level Chinese reading
comprehension difficulty. The benchmark is annotated by 60 Special Grade
teachers, a group that represents the top 0.15% of all in-service teachers
nationwide. Experimental results reveal that LLMs perform poorly in zero-shot
learning scenarios, with Qwen-max and GLM even falling below the probability of
random guessing. When provided with in-context examples, LLMs performance
improves substantially, with some models achieving nearly double the accuracy
of their zero-shot baselines. These results reveal that LLMs possess emerging
abilities to assess reading difficulty, while also exposing limitations in
their current training for educationally aligned judgment. Notably, even the
best-performing models display systematic directional biases, suggesting
difficulties in accurately aligning material difficulty with SCA. Furthermore,
significant variations in model performance across different genres underscore
the complexity of task. We envision that ZPD-SCA can provide a foundation for
evaluating and improving LLMs in cognitively aligned educational applications.

</details>


### [22] [Credence Calibration Game? Calibrating Large Language Models through Structured Play](https://arxiv.org/abs/2508.14390)
*Ke Fang,Tianyi Zhao,Lu Cheng*

Main category: cs.CL

TL;DR: 提出基于Credence Calibration Game的提示校准框架，通过反馈驱动的结构化交互循环来改善大语言模型的置信度校准，无需额外监督或参数更新。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在关键决策领域部署时，需要确保其置信度估计与实际正确性相符。现有校准方法多需额外监督或参数更新，存在局限性。

Method: 建立结构化交互循环，通过基于预测置信度与正确性对齐的反馈，结合反馈驱动提示和先前性能的自然语言总结，动态改进模型校准。

Result: 跨模型和游戏配置的广泛实验显示，评估指标持续改善，证明了基于游戏的提示策略对LLM校准的有效性。

Conclusion: 游戏化提示是一种有效的LLM校准策略，能够动态提升模型置信度校准性能，为关键决策应用提供更可靠的置信度估计。

Abstract: As Large Language Models (LLMs) are increasingly deployed in
decision-critical domains, it becomes essential to ensure that their confidence
estimates faithfully correspond to their actual correctness. Existing
calibration methods have primarily focused on post-hoc adjustments or auxiliary
model training; however, many of these approaches necessitate additional
supervision or parameter updates. In this work, we propose a novel prompt-based
calibration framework inspired by the Credence Calibration Game. Our method
establishes a structured interaction loop wherein LLMs receive feedback based
on the alignment of their predicted confidence with correctness. Through
feedback-driven prompting and natural language summaries of prior performance,
our framework dynamically improves model calibration. Extensive experiments
across models and game configurations demonstrate consistent improvements in
evaluation metrics. Our results highlight the potential of game-based prompting
as an effective strategy for LLM calibration. Code and data are available at
https://anonymous.4open.science/r/LLM-Calibration/.

</details>


### [23] [DEPTH: Hallucination-Free Relation Extraction via Dependency-Aware Sentence Simplification and Two-tiered Hierarchical Refinement](https://arxiv.org/abs/2508.14391)
*Yupei Yang,Fan Feng,Lin Yang,Wanxi Deng,Lin Qu,Biwei Huang,Shikui Tu,Lei Xu*

Main category: cs.CL

TL;DR: DEPTH框架通过依赖感知的句子简化和两级分层精炼，有效减少关系抽取中的幻觉问题，在六个基准测试中平均幻觉率降至7.0%，F1分数提升17.2%。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在关系抽取中经常产生虚假预测，特别是在复杂句子结构和语义情况下，这会污染知识图谱的完整性并影响下游应用的可靠性。

Method: DEPTH框架包含两个阶段：1）Grouding模块利用最短依赖路径提取关系，将句子蒸馏为最小但连贯的关系上下文；2）Refinement模块聚合所有局部预测并基于句子整体理解进行修正。还引入了因果驱动的奖励模型来缓解奖励黑客问题。

Result: 在六个基准测试中，DEPTH将平均幻觉率降低到7.0%，平均F1分数相比最先进的基线方法提高了17.2%。

Conclusion: DEPTH框架通过依赖感知的句子简化和分层精炼机制，有效解决了关系抽取中的幻觉问题，显著提升了抽取的准确性和可靠性。

Abstract: Relation extraction enables the construction of structured knowledge for many
downstream applications. While large language models (LLMs) have shown great
promise in this domain, most existing methods concentrate on relation
classification, which predicts the semantic relation type between a related
entity pair. However, we observe that LLMs often struggle to reliably determine
whether a relation exists, especially in cases involving complex sentence
structures or intricate semantics, which leads to spurious predictions. Such
hallucinations can introduce noisy edges in knowledge graphs, compromising the
integrity of structured knowledge and downstream reliability. To address these
challenges, we propose DEPTH, a framework that integrates Dependency-aware
sEntence simPlification and Two-tiered Hierarchical refinement into the
relation extraction pipeline. Given a sentence and its candidate entity pairs,
DEPTH operates in two stages: (1) the Grounding module extracts relations for
each pair by leveraging their shortest dependency path, distilling the sentence
into a minimal yet coherent relational context that reduces syntactic noise
while preserving key semantics; (2) the Refinement module aggregates all local
predictions and revises them based on a holistic understanding of the sentence,
correcting omissions and inconsistencies. We further introduce a
causality-driven reward model that mitigates reward hacking by disentangling
spurious correlations, enabling robust fine-tuning via reinforcement learning
with human feedback. Experiments on six benchmarks demonstrate that DEPTH
reduces the average hallucination rate to 7.0\% while achieving a 17.2\%
improvement in average F1 score over state-of-the-art baselines.

</details>


### [24] [Cognitive Surgery: The Awakening of Implicit Territorial Awareness in LLMs](https://arxiv.org/abs/2508.14408)
*Yinghan Zhou,Weifeng Zhu,Juan Wen,Wanli Peng,Zhengxian Wu,Yiming Xue*

Main category: cs.CL

TL;DR: 大语言模型在成对文本呈现范式(PPP)下能较好识别自身生成文本，但在单独文本呈现范式(IPP)下表现显著下降。本文提出认知外科(CoSur)框架，通过唤醒模型的隐式领域意识(ITA)来提升IPP下的自我识别能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究发现LLMs在IPP范式下难以区分自身生成文本与他人生成文本，但这一现象的原因尚未得到系统分析。本文旨在探究LLMs在IPP下表现不佳的根本原因，并提出解决方案。

Method: 提出认知外科(CoSur)框架，包含四个主要模块：表示提取、领域构建、作者判别和认知编辑。该方法旨在唤醒LLMs的隐式领域意识(ITA)，即模型在表示空间中区分自他文本的潜在能力。

Result: 实验结果显示，CoSur方法显著提升了三种不同LLMs在IPP场景下的性能，平均准确率分别达到83.25%、66.19%和88.01%。

Conclusion: LLMs具备隐式区分自他文本的能力，但该能力在输出行为中未得到表达。通过CoSur框架可以成功唤醒这种隐式领域意识，有效提升模型在单独文本呈现范式下的自我识别性能。

Abstract: Large language models (LLMs) have been shown to possess a degree of
self-recognition capability-the ability to identify whether a given text was
generated by themselves. Prior work has demonstrated that this capability is
reliably expressed under the Pair Presentation Paradigm (PPP), where the model
is presented with two texts and asked to choose which one it authored. However,
performance deteriorates sharply under the Individual Presentation Paradigm
(IPP), where the model is given a single text to judge authorship. Although
this phenomenon has been observed, its underlying causes have not been
systematically analyzed. In this paper, we first replicate existing findings to
confirm that LLMs struggle to distinguish self- from other-generated text under
IPP. We then investigate the reasons for this failure and attribute it to a
phenomenon we term Implicit Territorial Awareness (ITA)-the model's latent
ability to distinguish self- and other-texts in representational space, which
remains unexpressed in its output behavior. To awaken the ITA of LLMs, we
propose Cognitive Surgery (CoSur), a novel framework comprising four main
modules: representation extraction, territory construction, authorship
discrimination and cognitive editing. Experimental results demonstrate that our
proposed method improves the performance of three different LLMs in the IPP
scenario, achieving average accuracies of 83.25%, 66.19%, and 88.01%,
respectively.

</details>


### [25] [Knowledge Graph-Infused Fine-Tuning for Structured Reasoning in Large Language Models](https://arxiv.org/abs/2508.14427)
*Wuyang Zhang,Yexin Tian,Xiandong Meng,Mengjie Wang,Junliang Du*

Main category: cs.CL

TL;DR: 提出基于知识图谱注入的微调算法框架，通过图神经网络编码实体关系，设计融合机制联合建模知识图谱嵌入和语言模型上下文表示，使用门控机制动态平衡语言语义和结构化知识的贡献，提升大语言模型在结构化知识任务中的推理能力和实体级语义理解。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在处理需要结构化知识的任务时缺乏推理链和实体级语义理解不足的问题。

Method: 基于预训练语言模型，引入结构化图信息进行辅助学习，使用图神经网络编码实体及其关系，构建基于图的语义表示，设计融合机制联合建模知识图谱嵌入和语言模型上下文表示，引入门控机制动态平衡语言语义和结构化知识的贡献，构建联合损失函数同时考虑任务性能和结构对齐目标。

Result: 实验结果表明，所提出的结构感知微调框架显著增强了模型表示复杂语义单元的能力，在涉及结构化推理和实体提取的场景中表现出更好的语义一致性和上下文逻辑建模能力。

Conclusion: 该方法通过知识图谱注入和图神经网络的有效融合，成功提升了大语言模型在实体识别、问答和语言生成等任务中的准确性和推理能力，验证了方法的有效性和稳定性。

Abstract: This paper addresses the problems of missing reasoning chains and
insufficient entity-level semantic understanding in large language models when
dealing with tasks that require structured knowledge. It proposes a fine-tuning
algorithm framework based on knowledge graph injection. The method builds on
pretrained language models and introduces structured graph information for
auxiliary learning. A graph neural network is used to encode entities and their
relations, constructing a graph-based semantic representation. A fusion
mechanism is then designed to jointly model the knowledge graph embeddings with
the contextual representations from the language model. To enhance the
robustness of knowledge integration, a gating mechanism is introduced to
dynamically balance the contributions of linguistic semantics and structural
knowledge. This effectively mitigates conflicts between different
representational spaces. During training, a joint loss function is constructed
to account for both task performance and structural alignment objectives. This
helps improve the accuracy of entity prediction and semantic reasoning. The
study also includes a series of systematic sensitivity experiments. It
evaluates the effects of learning rate, graph coverage, and structural
perturbations on model performance. The results further validate the
effectiveness and stability of the proposed method across tasks such as entity
recognition, question answering, and language generation. Experimental findings
show that the proposed structure-aware fine-tuning framework significantly
enhances the model's ability to represent complex semantic units. It
demonstrates better semantic consistency and contextual logic modeling in
scenarios involving structural reasoning and entity extraction.

</details>


### [26] [NVIDIA Nemotron Nano 2: An Accurate and Efficient Hybrid Mamba-Transformer Reasoning Model](https://arxiv.org/abs/2508.14444)
*NVIDIA,:,Aarti Basant,Abhijit Khairnar,Abhijit Paithankar,Abhinav Khattar,Adi Renduchintala,Adithya Renduchintala,Aditya Malte,Akhiad Bercovich,Akshay Hazare,Alejandra Rico,Aleksander Ficek,Alex Kondratenko,Alex Shaposhnikov,Ali Taghibakhshi,Amelia Barton,Ameya Sunil Mahabaleshwarkar,Amy Shen,Andrew Tao,Ann Guan,Anna Shors,Anubhav Mandarwal,Arham Mehta,Arun Venkatesan,Ashton Sharabiani,Ashwath Aithal,Ashwin Poojary,Ayush Dattagupta,Balaram Buddharaju,Banghua Zhu,Barnaby Simkin,Bilal Kartal,Bita Darvish Rouhani,Bobby Chen,Boris Ginsburg,Brandon Norick,Brian Yu,Bryan Catanzaro,Charles Wang,Charlie Truong,Chetan Mungekar,Chintan Patel,Chris Alexiuk,Christian Munley,Christopher Parisien,Dan Su,Daniel Afrimi,Daniel Korzekwa,Daniel Rohrer,Daria Gitman,David Mosallanezhad,Deepak Narayanan,Dima Rekesh,Dina Yared,Dmytro Pykhtar,Dong Ahn,Duncan Riach,Eileen Long,Elliott Ning,Eric Chung,Erick Galinkin,Evelina Bakhturina,Gargi Prasad,Gerald Shen,Haim Elisha,Harsh Sharma,Hayley Ross,Helen Ngo,Herman Sahota,Hexin Wang,Hoo Chang Shin,Hua Huang,Iain Cunningham,Igor Gitman,Ivan Moshkov,Jaehun Jung,Jan Kautz,Jane Polak Scowcroft,Jared Casper,Jimmy Zhang,Jinze Xue,Jocelyn Huang,Joey Conway,John Kamalu,Jonathan Cohen,Joseph Jennings,Julien Veron Vialard,Junkeun Yi,Jupinder Parmar,Kari Briski,Katherine Cheung,Katherine Luna,Keith Wyss,Keshav Santhanam,Kezhi Kong,Krzysztof Pawelec,Kumar Anik,Kunlun Li,Kushan Ahmadian,Lawrence McAfee,Laya Sleiman,Leon Derczynski,Luis Vega,Maer Rodrigues de Melo,Makesh Narsimhan Sreedhar,Marcin Chochowski,Mark Cai,Markus Kliegl,Marta Stepniewska-Dziubinska,Matvei Novikov,Mehrzad Samadi,Meredith Price,Meriem Boubdir,Michael Boone,Michael Evans,Michal Bien,Michal Zawalski,Miguel Martinez,Mike Chrzanowski,Mohammad Shoeybi,Mostofa Patwary,Namit Dhameja,Nave Assaf,Negar Habibi,Nidhi Bhatia,Nikki Pope,Nima Tajbakhsh,Nirmal Kumar Juluru,Oleg Rybakov,Oleksii Hrinchuk,Oleksii Kuchaiev,Oluwatobi Olabiyi,Pablo Ribalta,Padmavathy Subramanian,Parth Chadha,Pavlo Molchanov,Peter Dykas,Peter Jin,Piotr Bialecki,Piotr Januszewski,Pradeep Thalasta,Prashant Gaikwad,Prasoon Varshney,Pritam Gundecha,Przemek Tredak,Rabeeh Karimi Mahabadi,Rajen Patel,Ran El-Yaniv,Ranjit Rajan,Ria Cheruvu,Rima Shahbazyan,Ritika Borkar,Ritu Gala,Roger Waleffe,Ruoxi Zhang,Russell J. Hewett,Ryan Prenger,Sahil Jain,Samuel Kriman,Sanjeev Satheesh,Saori Kaji,Sarah Yurick,Saurav Muralidharan,Sean Narenthiran,Seonmyeong Bak,Sepehr Sameni,Seungju Han,Shanmugam Ramasamy,Shaona Ghosh,Sharath Turuvekere Sreenivas,Shelby Thomas,Shizhe Diao,Shreya Gopal,Shrimai Prabhumoye,Shubham Toshniwal,Shuoyang Ding,Siddharth Singh,Siddhartha Jain,Somshubra Majumdar,Stefania Alborghetti,Syeda Nahida Akter,Terry Kong,Tim Moon,Tomasz Hliwiak,Tomer Asida,Tony Wang,Twinkle Vashishth,Tyler Poon,Udi Karpas,Vahid Noroozi,Venkat Srinivasan,Vijay Korthikanti,Vikram Fugro,Vineeth Kalluru,Vitaly Kurin,Vitaly Lavrukhin,Wasi Uddin Ahmad,Wei Du,Wonmin Byeon,Ximing Lu,Xin Dong,Yashaswi Karnati,Yejin Choi,Yian Zhang,Ying Lin,Yonggan Fu,Yoshi Suhara,Zhen Dong,Zhiyu Li,Zhongbo Zhu,Zijia Chen*

Main category: cs.CL

TL;DR: Nemotron-Nano-9B-v2是一个混合Mamba-Transformer语言模型，通过替换大部分自注意力层为Mamba-2层，在推理任务中实现了6倍吞吐量提升，同时保持与同类模型相当的准确率。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统Transformer模型在长序列推理任务中计算效率低下的问题，设计一个既能保持高准确率又能显著提升推理速度的混合架构模型。

Method: 采用Nemotron-H架构，将大部分自注意力层替换为Mamba-2层；先预训练120亿参数模型，然后通过Minitron策略进行压缩和蒸馏，支持在单GPU上处理128k tokens。

Result: 在推理基准测试中达到与Qwen3-8B等同类模型相当或更好的准确率，同时在8k输入16k输出的推理场景中实现高达6倍的推理吞吐量提升。

Conclusion: Nemotron-Nano-9B-v2成功证明了混合Mamba-Transformer架构在提升推理效率方面的有效性，为高效推理模型的发展提供了新方向，相关模型和数据集已在Hugging Face发布。

Abstract: We introduce Nemotron-Nano-9B-v2, a hybrid Mamba-Transformer language model
designed to increase throughput for reasoning workloads while achieving
state-of-the-art accuracy compared to similarly-sized models.
Nemotron-Nano-9B-v2 builds on the Nemotron-H architecture, in which the
majority of the self-attention layers in the common Transformer architecture
are replaced with Mamba-2 layers, to achieve improved inference speed when
generating the long thinking traces needed for reasoning. We create
Nemotron-Nano-9B-v2 by first pre-training a 12-billion-parameter model
(Nemotron-Nano-12B-v2-Base) on 20 trillion tokens using an FP8 training recipe.
After aligning Nemotron-Nano-12B-v2-Base, we employ the Minitron strategy to
compress and distill the model with the goal of enabling inference on up to
128k tokens on a single NVIDIA A10G GPU (22GiB of memory, bfloat16 precision).
Compared to existing similarly-sized models (e.g., Qwen3-8B), we show that
Nemotron-Nano-9B-v2 achieves on-par or better accuracy on reasoning benchmarks
while achieving up to 6x higher inference throughput in reasoning settings like
8k input and 16k output tokens. We are releasing Nemotron-Nano-9B-v2,
Nemotron-Nano12B-v2-Base, and Nemotron-Nano-9B-v2-Base checkpoints along with
the majority of our pre- and post-training datasets on Hugging Face.

</details>


### [27] [In2x at WMT25 Translation Task](https://arxiv.org/abs/2508.14472)
*Lei Pang,Hanyi Mao,Quanjia Xiao,HaiXiao Liu,Xiangyi Li*

Main category: cs.CL

TL;DR: In2x团队为WMT25机器翻译任务提交的开放系统方案，专注于日语相关翻译，探索将大语言模型扩展到其他语言的通用范式


<details>
  <summary>Details</summary>
Motivation: 旨在探索一种通用范式，使大语言模型系统能够在低资源或较少使用语言中实现卓越性能

Method: 包含数据构建方法和奖励模型设计等方面的综合范式

Result: 论文提出了一个面向日语翻译任务的开放系统提交方案

Conclusion: 该研究为扩展大语言模型到其他语言提供了一种可行的通用范式

Abstract: This paper presents the open-system submission by the In2x research team for
the WMT25 General Machine Translation Shared Task. Our submission focuses on
Japanese-related translation tasks, aiming to explore a generalizable paradigm
for extending large language models (LLMs) to other languages. This paradigm
encompasses aspects such as data construction methods and reward model design.
The ultimate goal is to enable large language model systems to achieve
exceptional performance in low-resource or less commonly spoken languages.

</details>


### [28] [Reasoning is about giving reasons](https://arxiv.org/abs/2508.14488)
*Krunal Shah,Dan Roth*

Main category: cs.CL

TL;DR: 本文提出了一种中间表示方法（RLS）来理解自然语言论证的逻辑结构，包括逻辑原子和推理规则，从而支持多种形式的推理任务。


<details>
  <summary>Details</summary>
Motivation: 当前Transformer模型虽然能够进行简单的规则链式推理，但在解释性和扩展性方面存在局限，无法支持溯因推理或矛盾识别等任务。

Method: 提出Representation of the Logical Structure (RLS)作为中间表示，捕捉自然语言论证中的逻辑原子和推理规则，使推理过程变得确定性和易于计算。

Result: 在三个流行的推理数据集上，该方法能够以高准确率识别和提取自然语言论证的逻辑结构，支持解释生成并显著扩展推理能力。

Conclusion: RLS表示方法有效解决了当前推理模型的局限性，支持任意深度的推理、实时错误修正和交互式讨论等多种推理任务。

Abstract: Convincing someone of the truth value of a premise requires understanding and
articulating the core logical structure of the argument which proves or
disproves the premise. Understanding the logical structure of an argument
refers to understanding the underlying "reasons" which make up the proof or
disproof of the premise - as a function of the "logical atoms" in the argument.
While it has been shown that transformers can "chain" rules to derive simple
arguments, the challenge of articulating the "reasons" remains. Not only do
current approaches to chaining rules suffer in terms of their interpretability,
they are also quite constrained in their ability to accommodate extensions to
theoretically equivalent reasoning tasks - a model trained to chain rules
cannot support abduction or identify contradictions. In this work we suggest
addressing these shortcomings by identifying an intermediate representation
(which we call the Representation of the Logical Structure (RLS) of the
argument) that possesses an understanding of the logical structure of a natural
language argument - the logical atoms in the argument and the rules
incorporating them. Given the logical structure, reasoning is deterministic and
easy to compute. Therefore, our approach supports all forms of reasoning that
depend on the logical structure of the natural language argument, including
arbitrary depths of reasoning, on-the-fly mistake rectification and interactive
discussion with respect to an argument. We show that we can identify and
extract the logical structure of natural language arguments in three popular
reasoning datasets with high accuracies, thus supporting explanation generation
and extending the reasoning capabilities significantly.

</details>


### [29] [EmoTale: An Enacted Speech-emotion Dataset in Danish](https://arxiv.org/abs/2508.14548)
*Maja J. Hjuler,Harald V. Skat-Rørdam,Line H. Clemmensen,Sneha Das*

Main category: cs.CL

TL;DR: 本文介绍了EmoTale语料库，这是一个包含丹麦语和英语情感语音的数据集，填补了小语种情感语音数据的空白，并通过语音情感识别模型验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 目前虽然存在多种常用语言的情感语音语料库，但对于丹麦语等小语种缺乏功能性数据集。1997年发布的DES是唯一的丹麦语情感语音数据库，需要新的数据集来支持相关研究。

Method: 使用自监督语音模型(SSLM)嵌入和openSMILE特征提取器开发语音情感识别(SER)模型，对EmoTale和参考数据集进行建模分析。

Result: 研究发现嵌入特征优于手工制作的特征。最佳模型在使用留一说话人交叉验证时，在EmoTale语料库上达到了64.1%的未加权平均召回率(UAR)，与DES的性能相当。

Conclusion: EmoTale语料库为丹麦语情感语音研究提供了有效的资源，其预测能力通过SER模型得到验证，嵌入特征在情感识别任务中表现出优越性。

Abstract: While multiple emotional speech corpora exist for commonly spoken languages,
there is a lack of functional datasets for smaller (spoken) languages, such as
Danish. To our knowledge, Danish Emotional Speech (DES), published in 1997, is
the only other database of Danish emotional speech. We present EmoTale; a
corpus comprising Danish and English speech recordings with their associated
enacted emotion annotations. We demonstrate the validity of the dataset by
investigating and presenting its predictive power using speech emotion
recognition (SER) models. We develop SER models for EmoTale and the reference
datasets using self-supervised speech model (SSLM) embeddings and the openSMILE
feature extractor. We find the embeddings superior to the hand-crafted
features. The best model achieves an unweighted average recall (UAR) of 64.1%
on the EmoTale corpus using leave-one-speaker-out cross-validation, comparable
to the performance on DES.

</details>


### [30] [Towards Skeletal and Signer Noise Reduction in Sign Language Production via Quaternion-Based Pose Encoding and Contrastive Learning](https://arxiv.org/abs/2508.14574)
*Guilhem Fauré,Mostafa Sadeghi,Sam Bigeard,Slim Ouni*

Main category: cs.CL

TL;DR: 提出了两种改进神经手语生成的方法：四元数空间骨骼旋转编码和对比损失，在Phoenix14T数据集上显著提升了关键点准确率和骨骼角度误差


<details>
  <summary>Details</summary>
Motivation: 解决手语生成中由于手语者形态和风格变化导致的高类内变异性问题，提高模型对这类变化的鲁棒性

Method: 1. 使用四元数空间中的骨骼旋转编码姿势，采用测地线损失提高关节角度运动的准确性；2. 引入对比损失，基于gloss重叠或SBERT句子相似度来结构化解码器嵌入，过滤不相关的解剖和风格特征

Result: 对比损失单独使用使关键点正确概率比基线提升16%；结合四元数姿势编码后，平均骨骼角度误差降低6%

Conclusion: 将骨骼结构建模和语义引导的对比目标整合到基于Transformer的手语生成模型训练中具有显著优势

Abstract: One of the main challenges in neural sign language production (SLP) lies in
the high intra-class variability of signs, arising from signer morphology and
stylistic variety in the training data. To improve robustness to such
variations, we propose two enhancements to the standard Progressive
Transformers (PT) architecture (Saunders et al., 2020). First, we encode poses
using bone rotations in quaternion space and train with a geodesic loss to
improve the accuracy and clarity of angular joint movements. Second, we
introduce a contrastive loss to structure decoder embeddings by semantic
similarity, using either gloss overlap or SBERT-based sentence similarity,
aiming to filter out anatomical and stylistic features that do not convey
relevant semantic information. On the Phoenix14T dataset, the contrastive loss
alone yields a 16% improvement in Probability of Correct Keypoint over the PT
baseline. When combined with quaternion-based pose encoding, the model achieves
a 6% reduction in Mean Bone Angle Error. These results point to the benefit of
incorporating skeletal structure modeling and semantically guided contrastive
objectives on sign pose representations into the training of Transformer-based
SLP models.

</details>


### [31] [Filling the Gap for Uzbek: Creating Translation Resources for Southern Uzbek](https://arxiv.org/abs/2508.14586)
*Mukhammadsaid Mamasaidov,Azizullah Aral,Abror Shopulatov,Mironshoh Inomjonov*

Main category: cs.CL

TL;DR: 本文为南乌兹别克语开发了新的机器翻译资源，包括测试集、平行语料库和微调模型，并提出了阿拉伯文字符后处理方法。


<details>
  <summary>Details</summary>
Motivation: 南乌兹别克语在阿富汗有约500万使用者，但在自然语言处理领域代表性不足，与北乌兹别克语在音系、词汇和正字法上差异显著。

Method: 构建了997句FLORES+开发集和39,994句平行语料，微调NLLB-200模型，并提出阿拉伯文字符半空格恢复的后处理方法。

Result: 开发了完整的机器翻译资源包，包括数据集、模型和工具，后处理方法改善了形态边界处理。

Conclusion: 所有资源公开释放，支持南乌兹别克语和其他低资源语言的未来研究工作。

Abstract: Southern Uzbek (uzs) is a Turkic language variety spoken by around 5 million
people in Afghanistan and differs significantly from Northern Uzbek (uzn) in
phonology, lexicon, and orthography. Despite the large number of speakers,
Southern Uzbek is underrepresented in natural language processing. We present
new resources for Southern Uzbek machine translation, including a 997-sentence
FLORES+ dev set, 39,994 parallel sentences from dictionary, literary, and web
sources, and a fine-tuned NLLB-200 model (lutfiy). We also propose a
post-processing method for restoring Arabic-script half-space characters, which
improves handling of morphological boundaries. All datasets, models, and tools
are released publicly to support future work on Southern Uzbek and other
low-resource languages.

</details>


### [32] [Continuous sentiment scores for literary and multilingual contexts](https://arxiv.org/abs/2508.14620)
*Laurits Lyngbaek,Pascale Feldkamp,Yuri Bizzoni,Kristoffer Nielbo,Kenneth Enevoldsen*

Main category: cs.CL

TL;DR: 提出了一种基于概念向量投影的连续情感评分方法，用于文学文本情感分析，在多语言文学数据上训练，能更好地捕捉跨体裁、语言和历史时期的细腻情感表达。


<details>
  <summary>Details</summary>
Motivation: 传统词典工具在文学文本情感分析中表现不佳，特别是对低资源语言；而transformer模型通常输出粗粒度的分类标签，限制了细粒度分析。文学文本中的比喻语言、风格模糊性和情感唤起策略带来了独特挑战。

Method: 基于概念向量投影的连续情感评分方法，在多语言文学数据上进行训练，通过向量投影技术生成连续的情感分数而非分类标签。

Result: 在英语和丹麦语文本上优于现有工具，生成的情感分数分布与人类评分高度匹配，能够实现更准确的文学分析和情感弧线建模。

Conclusion: 该方法为文学文本情感分析提供了更有效的解决方案，能够捕捉跨语言、体裁和历史时期的细腻情感表达，为文学研究提供了更精确的分析工具。

Abstract: Sentiment Analysis is widely used to quantify sentiment in text, but its
application to literary texts poses unique challenges due to figurative
language, stylistic ambiguity, as well as sentiment evocation strategies.
Traditional dictionary-based tools often underperform, especially for
low-resource languages, and transformer models, while promising, typically
output coarse categorical labels that limit fine-grained analysis. We introduce
a novel continuous sentiment scoring method based on concept vector projection,
trained on multilingual literary data, which more effectively captures nuanced
sentiment expressions across genres, languages, and historical periods. Our
approach outperforms existing tools on English and Danish texts, producing
sentiment scores whose distribution closely matches human ratings, enabling
more accurate analysis and sentiment arc modeling in literature.

</details>


### [33] [Improving in-context learning with a better scoring function](https://arxiv.org/abs/2508.14685)
*Omar Naim,Swarnadeep Bhar,Jérôme Bolte,Nicholas Asher*

Main category: cs.CL

TL;DR: 论文提出SSA方法替代Softmax，显著提升大语言模型在量化词和线性函数任务中的类比学习能力


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽然表现出强大的类比学习能力，但近期研究发现其在处理一阶量词和线性函数等任务时存在局限性，Softmax评分函数被认为是导致这些限制的因素之一

Method: 提出scaled signed averaging (SSA)方法作为Softmax的替代方案，并在编码器和解码器Transformer模型中进行评估

Result: SSA在目标任务上显著提升性能，在各种语言探测任务中匹配或超越基于Softmax的对应模型

Conclusion: SSA是一种有效的Softmax替代方案，能够改善大语言模型在特定任务中的类比学习能力

Abstract: Large language models (LLMs) exhibit a remarkable capacity to learn by
analogy, known as in-context learning (ICL). However, recent studies have
revealed limitations in this ability. In this paper, we examine these
limitations on tasks involving first-order quantifiers such as {\em all} and
{\em some}, as well as on ICL with linear functions. We identify Softmax, the
scoring function in attention mechanism, as a contributing factor to these
constraints. To address this, we propose \textbf{scaled signed averaging
(SSA)}, a novel alternative to Softmax. Empirical results show that SSA
dramatically improves performance on our target tasks. Furthermore, we evaluate
both encoder-only and decoder-only transformers models with SSA, demonstrating
that they match or exceed their Softmax-based counterparts across a variety of
linguistic probing tasks.

</details>


### [34] [ShizhenGPT: Towards Multimodal LLMs for Traditional Chinese Medicine](https://arxiv.org/abs/2508.14706)
*Junying Chen,Zhenyang Cai,Zhiheng Liu,Yunjin Yang,Rongsheng Wang,Qingying Xiao,Xiangyi Feng,Zhan Su,Jing Guo,Xiang Wan,Guangjun Yu,Haizhou Li,Benyou Wang*

Main category: cs.CL

TL;DR: ShizhenGPT是首个针对中医的多模态大语言模型，通过构建大规模多模态数据集和专门训练，解决了中医数据稀缺和多模态诊断的挑战，在中医资格考试和视觉诊断任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统大语言模型在中医领域应用受限，主要因为高质量中医数据稀缺以及中医诊断固有的多模态特性（望闻问切），这些感官丰富的模态超出了传统LLMs的处理范围。

Method: 构建了迄今为止最大的中医数据集（100GB+文本和200GB+多模态数据），包括120万张图像、200小时音频和生理信号。ShizhenGPT经过预训练和指令微调，实现了深度中医知识和多模态推理能力。

Result: 实验表明，ShizhenGPT在可比规模的LLMs中表现最优，甚至能与更大的专有模型竞争。在中医视觉理解方面领先现有多模态LLMs，并在声音、脉搏、气味和视觉等多模态感知方面展现统一能力。

Conclusion: 该研究为中医领域的整体多模态感知和诊断开辟了新途径，所有数据集、模型和代码均已公开，希望激发该领域的进一步探索。

Abstract: Despite the success of large language models (LLMs) in various domains, their
potential in Traditional Chinese Medicine (TCM) remains largely underexplored
due to two critical barriers: (1) the scarcity of high-quality TCM data and (2)
the inherently multimodal nature of TCM diagnostics, which involve looking,
listening, smelling, and pulse-taking. These sensory-rich modalities are beyond
the scope of conventional LLMs. To address these challenges, we present
ShizhenGPT, the first multimodal LLM tailored for TCM. To overcome data
scarcity, we curate the largest TCM dataset to date, comprising 100GB+ of text
and 200GB+ of multimodal data, including 1.2M images, 200 hours of audio, and
physiological signals. ShizhenGPT is pretrained and instruction-tuned to
achieve deep TCM knowledge and multimodal reasoning. For evaluation, we collect
recent national TCM qualification exams and build a visual benchmark for
Medicinal Recognition and Visual Diagnosis. Experiments demonstrate that
ShizhenGPT outperforms comparable-scale LLMs and competes with larger
proprietary models. Moreover, it leads in TCM visual understanding among
existing multimodal LLMs and demonstrates unified perception across modalities
like sound, pulse, smell, and vision, paving the way toward holistic multimodal
perception and diagnosis in TCM. Datasets, models, and code are publicly
available. We hope this work will inspire further exploration in this field.

</details>


### [35] [The Digital Sous Chef -- A Comparative Study on Fine-Tuning Language Models for Recipe Generation](https://arxiv.org/abs/2508.14718)
*Shubham Pundhir,Ganesh Bagler*

Main category: cs.CL

TL;DR: 提出了一个严格的基于文本的食谱生成基准，通过定制化的分词策略增强词汇表，显著提升了大型Transformer模型在食谱生成任务上的性能表现


<details>
  <summary>Details</summary>
Motivation: 解决通用分词器在食谱生成任务中的局限性，特别是保持食谱结构和精确数值量的需求，提升领域特异性

Method: 使用定制化分词策略（添加23个常见分数标记和自定义结构标记），对比微调的GPT-2大型模型(774M)与GPT-2小型模型(124M)以及传统LSTM/RNN基线模型在RecipeDB的5种菜系语料库上的表现

Result: 大型Transformer方法相比最佳循环基线在BERTScore(F1)上获得>20%的相对提升(0.92 vs 0.72)，困惑度降低69.8%，在流畅性、连贯性、语义相关性和多样性等7个自动指标上表现优异

Conclusion: 该研究为整合现实世界约束和多模态输入的高级食谱生成研究奠定了基础，但仍需解决事实准确性等挑战

Abstract: We established a rigorous benchmark for text-based recipe generation, a
fundamental task in natural language generation. We present a comprehensive
comparative study contrasting a fine-tuned GPT-2 large (774M) model against the
GPT-2 small (124M) model and traditional LSTM/RNN baselines on the 5-cuisine
corpus from RecipeDB. Our key contribution is a targeted tokenization strategy
that augments the vocabulary with 23 common fraction tokens and custom
structural markers. This approach addresses a critical limitation of generic
tokenizers by preserving essential recipe structures and precise numerical
quantities, thereby enhancing domain specificity. Performance is evaluated
using a comprehensive suite of seven automatic metrics spanning fluency
(BLEU-4, METEOR), coherence (ROUGE-L), semantic relevance (BERTScore), and
diversity. Our experiments show that the large transformer-based approach
yields a >20% relative improvement in BERTScore (F1) (0.92 vs 0.72) over the
best recurrent baseline, while reducing perplexity by 69.8%. We conclude with a
discussion of remaining challenges, particularly regarding factual accuracy,
and outline how this foundational study paves the way for integrating
real-world constraints and multi-modal inputs in advanced recipe generation
research.

</details>


### [36] [Transplant Then Regenerate: A New Paradigm for Text Data Augmentation](https://arxiv.org/abs/2508.14723)
*Guangzhan Wang,Hongyu Zhang,Beijun Shen,Xiaodong Gu*

Main category: cs.CL

TL;DR: LMTransplant是一种新的文本增强方法，通过将种子文本移植到LLM扩展的上下文中，然后让LLM基于扩展上下文重新生成变体，从而产生更多样化和创造性的内容级变体。


<details>
  <summary>Details</summary>
Motivation: 传统的数据增强方法主要关注词汇层面的改写，产生语义相同的变体。虽然大语言模型通过"知识涌现"能力增强了文本增强，但控制输出风格和结构仍然具有挑战性，需要精细的提示工程。

Method: 提出LMTransplant范式，采用"移植-再生成"策略：将种子文本融入LLM扩展的上下文中，然后要求LLM基于扩展上下文重新生成变体。

Result: 在各种文本相关任务中评估LMTransplant，证明其性能优于现有文本增强方法，并且在增强数据规模增大时表现出卓越的可扩展性。

Conclusion: LMTransplant通过充分利用LLM中嵌入的知识，能够产生更多样化和创造性的内容级变体，同时保留原始文本的核心属性，为文本增强提供了有效的新方法。

Abstract: Data augmentation is a critical technique in deep learning. Traditional
methods like Back-translation typically focus on lexical-level rephrasing,
which primarily produces variations with the same semantics. While large
language models (LLMs) have enhanced text augmentation by their "knowledge
emergence" capability, controlling the style and structure of these outputs
remains challenging and requires meticulous prompt engineering. In this paper,
we propose LMTransplant, a novel text augmentation paradigm leveraging LLMs.
The core idea of LMTransplant is transplant-then-regenerate: incorporating seed
text into a context expanded by LLM, and asking the LLM to regenerate a variant
based on the expanded context. This strategy allows the model to create more
diverse and creative content-level variants by fully leveraging the knowledge
embedded in LLMs, while preserving the core attributes of the original text. We
evaluate LMTransplant across various text-related tasks, demonstrating its
superior performance over existing text augmentation methods. Moreover,
LMTransplant demonstrates exceptional scalability as the size of augmented data
grows.

</details>


### [37] [Evaluating Multilingual and Code-Switched Alignment in LLMs via Synthetic Natural Language Inference](https://arxiv.org/abs/2508.14735)
*Samir Abdaljalil,Erchin Serpedin,Khalid Qaraqe,Hasan Kurban*

Main category: cs.CL

TL;DR: 这篇论文提出了一种多语言自然语言推理评估框架，通过生成逻辑基础的合成数据并翻译到多种语言，发现代码切换不仅不会降低性能，还可能提高多语言健壮性。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型在多语言环境中应用越来越多，但它们在不同语言间的一致性和逻辑基础对齐能力仍然研究不涵。

Method: 开发了一种受控的多语言NLI评估框架，生成合成的逻辑基础前提-假设对，并将其翻译到语言类型学多样的语言中，在单语言和混合语言条件下进行测试。

Result: 惊奇地发现代码切换不会降低性能，反而可能提高性能，表明翻译引起的词汇变化可能作为正则化信号。通过嵌入相似性分析和跨语言对齐可视化验证了翻译对的保真度。

Conclusion: 研究揭示了当前LLM跨语言推理的潜力和脆弱性，并确认代码切换是改善多语言健壮性的有前景手段。

Abstract: Large language models (LLMs) are increasingly applied in multilingual
contexts, yet their capacity for consistent, logically grounded alignment
across languages remains underexplored. We present a controlled evaluation
framework for multilingual natural language inference (NLI) that generates
synthetic, logic-based premise-hypothesis pairs and translates them into a
typologically diverse set of languages. This design enables precise control
over semantic relations and allows testing in both monolingual and
mixed-language (code-switched) conditions. Surprisingly, code-switching does
not degrade, and can even improve, performance, suggesting that
translation-induced lexical variation may serve as a regularization signal. We
validate semantic preservation through embedding-based similarity analyses and
cross-lingual alignment visualizations, confirming the fidelity of translated
pairs. Our findings expose both the potential and the brittleness of current
LLM cross-lingual reasoning, and identify code-switching as a promising lever
for improving multilingual robustness. Code available at:
https://github.com/KurbanIntelligenceLab/nli-stress-testing

</details>


### [38] [TransLLM: A Unified Multi-Task Foundation Framework for Urban Transportation via Learnable Prompting](https://arxiv.org/abs/2508.14782)
*Jiaming Leng,Yunying Bi,Chuan Qin,Bing Yin,Yanyong Zhang,Chao Wang*

Main category: cs.CL

TL;DR: TransLLM是一个统一的基础框架，通过可学习提示组合将时空建模与大型语言模型集成，解决了城市交通系统中多任务处理的挑战，在监督和零样本设置下都表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在两个关键局限：小规模深度学习模型任务特定且数据需求大，限制了跨场景泛化能力；大型语言模型虽然通过自然语言接口提供灵活性，但在结构化时空数据和交通领域数值推理方面表现不佳。

Method: 采用轻量级时空编码器（扩张时间卷积和双邻接图注意力网络）捕获复杂依赖关系，通过结构化嵌入与LLMs无缝接口。新颖的实例级提示路由机制通过强化学习训练，基于输入特征动态个性化提示。

Result: 在7个数据集和3个任务上的实验表明，TransLLM在监督和零样本设置下都具有卓越效果。相比10个基线模型，在回归和规划问题上都表现出竞争性性能，显示出强大的泛化和跨任务适应能力。

Conclusion: TransLLM成功整合了时空建模与大型语言模型，通过动态个性化提示机制有效解决了城市交通多任务处理的挑战，为交通系统智能化提供了统一的基础框架解决方案。

Abstract: Urban transportation systems encounter diverse challenges across multiple
tasks, such as traffic forecasting, electric vehicle (EV) charging demand
prediction, and taxi dispatch. Existing approaches suffer from two key
limitations: small-scale deep learning models are task-specific and
data-hungry, limiting their generalizability across diverse scenarios, while
large language models (LLMs), despite offering flexibility through natural
language interfaces, struggle with structured spatiotemporal data and numerical
reasoning in transportation domains. To address these limitations, we propose
TransLLM, a unified foundation framework that integrates spatiotemporal
modeling with large language models through learnable prompt composition. Our
approach features a lightweight spatiotemporal encoder that captures complex
dependencies via dilated temporal convolutions and dual-adjacency graph
attention networks, seamlessly interfacing with LLMs through structured
embeddings. A novel instance-level prompt routing mechanism, trained via
reinforcement learning, dynamically personalizes prompts based on input
characteristics, moving beyond fixed task-specific templates. The framework
operates by encoding spatiotemporal patterns into contextual representations,
dynamically composing personalized prompts to guide LLM reasoning, and
projecting the resulting representations through specialized output layers to
generate task-specific predictions. Experiments across seven datasets and three
tasks demonstrate the exceptional effectiveness of TransLLM in both supervised
and zero-shot settings. Compared to ten baseline models, it delivers
competitive performance on both regression and planning problems, showing
strong generalization and cross-task adaptability. Our code is available at
https://github.com/BiYunying/TransLLM.

</details>


### [39] [Evaluating Retrieval-Augmented Generation vs. Long-Context Input for Clinical Reasoning over EHRs](https://arxiv.org/abs/2508.14817)
*Skatje Myers,Dmitriy Dligach,Timothy A. Miller,Samantha Barr,Yanjun Gao,Matthew Churpek,Anoop Mayampurath,Majid Afshar*

Main category: cs.CL

TL;DR: RAG方法在电子病历分析中表现优异，通过检索相关段落显著减少输入token数量，在三个临床任务上接近或超越使用完整上下文的效果


<details>
  <summary>Details</summary>
Motivation: 电子病历长、噪声大且冗余，传统大语言模型难以处理超长上下文，需要更高效的解决方案

Method: 提出三个可复现的临床任务，使用三种先进LLM测试不同上下文量，比较目标文本检索与最近临床笔记的效果

Result: RAG方法在减少输入token的同时，性能接近或超过使用最近笔记的方法，接近完整上下文效果

Conclusion: RAG是一种竞争性强且高效的临床文本处理方法，即使新模型能处理更长文本，该方法仍然有效

Abstract: Electronic health records (EHRs) are long, noisy, and often redundant, posing
a major challenge for the clinicians who must navigate them. Large language
models (LLMs) offer a promising solution for extracting and reasoning over this
unstructured text, but the length of clinical notes often exceeds even
state-of-the-art models' extended context windows. Retrieval-augmented
generation (RAG) offers an alternative by retrieving task-relevant passages
from across the entire EHR, potentially reducing the amount of required input
tokens. In this work, we propose three clinical tasks designed to be replicable
across health systems with minimal effort: 1) extracting imaging procedures, 2)
generating timelines of antibiotic use, and 3) identifying key diagnoses. Using
EHRs from actual hospitalized patients, we test three state-of-the-art LLMs
with varying amounts of provided context, using either targeted text retrieval
or the most recent clinical notes. We find that RAG closely matches or exceeds
the performance of using recent notes, and approaches the performance of using
the models' full context while requiring drastically fewer input tokens. Our
results suggest that RAG remains a competitive and efficient approach even as
newer models become capable of handling increasingly longer amounts of text.

</details>


### [40] [Long Chain-of-Thought Reasoning Across Languages](https://arxiv.org/abs/2508.14828)
*Josh Barua,Seun Eisape,Kayo Yin,Alane Suhr*

Main category: cs.CL

TL;DR: 本文研究了长链思维推理在不同语言间的迁移效果，发现英语作为枢纽语言的效果因语言而异，多语言预训练能缩小但无法消除跨语言性能差距，数据质量与规模的权衡具有语言依赖性。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型的推理过程主要基于英语，缺乏对其他语言推理能力的研究。本文旨在系统研究长链思维推理在法语、日语、拉脱维亚语和斯瓦希里语等不同语言间的迁移效果。

Method: 构建了两个流行英语推理数据集的翻译版本，对Qwen 2.5 (7B)和Qwen 3 (8B)模型进行微调，系统研究了法语、日语、拉脱维亚语和斯瓦希里语的长链思维生成。

Result: 1) 英语作为枢纽语言的效果因语言而异：对法语无益，对日语和拉脱维亚语有改善，对斯瓦希里语效果不佳；2) Qwen 3的多语言预训练缩小了跨语言性能差距但未消除；3) 数据质量与规模的权衡具有语言依赖性。

Conclusion: 研究结果阐明了长链思维推理何时以及为何能在不同语言间迁移，并提供了翻译数据集以促进公平的多语言推理研究，轻量级微调能显著改善低资源语言的性能。

Abstract: Scaling inference through long chains-of-thought (CoTs) has unlocked
impressive reasoning capabilities in large language models (LLMs), yet the
reasoning process remains almost exclusively English-centric. We construct
translated versions of two popular English reasoning datasets, fine-tune Qwen
2.5 (7B) and Qwen 3 (8B) models, and present a systematic study of long CoT
generation across French, Japanese, Latvian, and Swahili. Our experiments
reveal three key findings. First, the efficacy of using English as a pivot
language varies by language: it provides no benefit for French, improves
performance when used as the reasoning language for Japanese and Latvian, and
proves insufficient for Swahili where both task comprehension and reasoning
remain poor. Second, extensive multilingual pretraining in Qwen 3 narrows but
does not eliminate the cross-lingual performance gap. A lightweight fine-tune
using only 1k traces still improves performance by over 30\% in Swahili. Third,
data quality versus scale trade-offs are language dependent: small, carefully
curated datasets suffice for English and French, whereas larger but noisier
corpora prove more effective for Swahili and Latvian. Together, these results
clarify when and why long CoTs transfer across languages and provide translated
datasets to foster equitable multilingual reasoning research.

</details>


### [41] [MedReseacher-R1: Expert-Level Medical Deep Researcher via A Knowledge-Informed Trajectory Synthesis Framework](https://arxiv.org/abs/2508.14880)
*Ailing Yu,Lan Yao,Jingnan Liu,Zhe Chen,Jiajun Yin,Yuan Wang,Xinhao Liao,Zhiling Ye,Ji Li,Yun Yue,Hansong Xiao,Hualei Zhou,Chunxiao Guo,Peng Wei,Jinjie Gu*

Main category: cs.CL

TL;DR: 提出了MedResearcher医疗深度研究智能体，通过医学知识图谱数据合成和专用检索工具，解决了LLM在医疗领域的知识不足问题，在医疗基准测试中达到新SOTA


<details>
  <summary>Details</summary>
Motivation: 现有通用深度研究智能体在医疗领域表现不佳，主要问题是缺乏密集医学知识和专用检索工具，需要针对医疗领域进行专门优化

Method: 1) 使用医学知识图谱提取最长链生成复杂多跳问答对的数据合成框架；2) 结合通用工具和专用医疗检索引擎；3) 两阶段训练：监督微调+在线强化学习

Result: 生成2100+条多样化轨迹，覆盖12个医学专科，平均4.2次工具交互。MedResearcher-R1-32B模型在医疗基准测试中达到新SOTA，同时在通用任务上保持竞争力

Conclusion: 通过领域特定的架构创新、工具设计和训练数据构建，较小的开源模型可以在专业领域超越更大的专有系统

Abstract: Recent developments in Large Language Model (LLM)-based agents have shown
impressive capabilities spanning multiple domains, exemplified by deep research
systems that demonstrate superior performance on complex information-seeking
and synthesis tasks. While general-purpose deep research agents have shown
impressive capabilities, they struggle significantly with medical domain
challenges, as evidenced by leading proprietary systems achieving limited
accuracy on complex medical benchmarks. The key limitations are: (1) the model
lacks sufficient dense medical knowledge for clinical reasoning, and (2) the
framework is constrained by the absence of specialized retrieval tools tailored
for medical contexts.We present a medical deep research agent that addresses
these challenges through two core innovations. First, we develop a novel data
synthesis framework using medical knowledge graphs, extracting the longest
chains from subgraphs around rare medical entities to generate complex
multi-hop question-answer pairs. Second, we integrate a custom-built private
medical retrieval engine alongside general-purpose tools, enabling accurate
medical information synthesis. Our approach generates 2100+ diverse
trajectories across 12 medical specialties, each averaging 4.2 tool
interactions.Through a two-stage training paradigm combining supervised
fine-tuning and online reinforcement learning with composite rewards, our
MedResearcher-R1-32B model demonstrates exceptional performance, establishing
new state-of-the-art results on medical benchmarks while maintaining
competitive performance on general deep research tasks. Our work demonstrates
that strategic domain-specific innovations in architecture, tool design, and
training data construction can enable smaller open-source models to outperform
much larger proprietary systems in specialized domains.

</details>


### [42] [Quantization Meets dLLMs: A Systematic Study of Post-training Quantization for Diffusion LLMs](https://arxiv.org/abs/2508.14896)
*Haokun Lin,Haobo Xu,Yichen Wu,Ziyu Guo,Renrui Zhang,Zhichao Lu,Ying Wei,Qingfu Zhang,Zhenan Sun*

Main category: cs.CL

TL;DR: 首次系统性研究双向语言模型的量化技术，识别激活值异常值问题，并通过多维度评估提供实用的量化实践见解


<details>
  <summary>Details</summary>
Motivation: 双向语言模型在边缘设备上部署遇到参数规模大、资源需求高的挑战，而现有的量化技术主要面向自回归模型，对双向模型的量化研究缺乏

Method: 识别激活值异常值问题，应用最新的训练后量化方法，从四个关键维度（比特宽度、量化方法、任务类型、模型类型）进行全面评估

Result: 提供了双向语言模型在不同量化配置下的行为见解，为高效部署提供了实践基础

Conclusion: 该研究为双向语言模型的量化压缩开启了新方向，所有代码和实验设置将开源以支持社区进一步研究

Abstract: Recent advances in diffusion large language models (dLLMs) have introduced a
promising alternative to autoregressive (AR) LLMs for natural language
generation tasks, leveraging full attention and denoising-based decoding
strategies. However, the deployment of these models on edge devices remains
challenging due to their massive parameter scale and high resource demands.
While post-training quantization (PTQ) has emerged as a widely adopted
technique for compressing AR LLMs, its applicability to dLLMs remains largely
unexplored. In this work, we present the first systematic study on quantizing
diffusion-based language models. We begin by identifying the presence of
activation outliers, characterized by abnormally large activation values that
dominate the dynamic range. These outliers pose a key challenge to low-bit
quantization, as they make it difficult to preserve precision for the majority
of values. More importantly, we implement state-of-the-art PTQ methods and
conduct a comprehensive evaluation across multiple task types and model
variants. Our analysis is structured along four key dimensions: bit-width,
quantization method, task category, and model type. Through this
multi-perspective evaluation, we offer practical insights into the quantization
behavior of dLLMs under different configurations. We hope our findings provide
a foundation for future research in efficient dLLM deployment. All codes and
experimental setups will be released to support the community.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [43] [Two Birds with One Stone: Multi-Task Detection and Attribution of LLM-Generated Text](https://arxiv.org/abs/2508.14190)
*Zixin Rao,Youssef Mohamed,Shang Liu,Zeyan Liu*

Main category: cs.CR

TL;DR: DA-MTL是一个多任务学习框架，同时处理AI文本检测和作者归属识别，在多种语言和LLM源上表现优异，并能抵抗对抗性混淆技术。


<details>
  <summary>Details</summary>
Motivation: 现有检测方法主要关注区分AI生成与人类撰写文本，且多数针对英语，而作者归属识别研究相对较少，但在法证分析中很重要。

Method: 提出多任务学习框架DA-MTL，同时处理文本检测和作者归属两个任务，通过任务间知识共享提升性能，在9个数据集和4个骨干模型上进行评估。

Result: DA-MTL在多个语言和LLM源上表现出色，能够有效捕获每个任务的独特特征并通过任务间共享提升性能，对对抗性混淆技术具有鲁棒性。

Conclusion: 该框架为LLM行为分析和检测/作者归属任务的泛化提供了宝贵见解，证明了多任务学习在AI文本分析中的有效性。

Abstract: Large Language Models (LLMs), such as GPT-4 and Llama, have demonstrated
remarkable abilities in generating natural language. However, they also pose
security and integrity challenges. Existing countermeasures primarily focus on
distinguishing AI-generated content from human-written text, with most
solutions tailored for English. Meanwhile, authorship attribution--determining
which specific LLM produced a given text--has received comparatively little
attention despite its importance in forensic analysis. In this paper, we
present DA-MTL, a multi-task learning framework that simultaneously addresses
both text detection and authorship attribution. We evaluate DA-MTL on nine
datasets and four backbone models, demonstrating its strong performance across
multiple languages and LLM sources. Our framework captures each task's unique
characteristics and shares insights between them, which boosts performance in
both tasks. Additionally, we conduct a thorough analysis of cross-modal and
cross-lingual patterns and assess the framework's robustness against
adversarial obfuscation techniques. Our findings offer valuable insights into
LLM behavior and the generalization of both detection and authorship
attribution.

</details>


### [44] [MultiFuzz: A Dense Retrieval-based Multi-Agent System for Network Protocol Fuzzing](https://arxiv.org/abs/2508.14300)
*Youssef Maklad,Fares Wael,Ali Hamdi,Wael Elsersy,Khaled Shaban*

Main category: cs.CR

TL;DR: MultiFuzz是一个基于密集检索的多智能体协议模糊测试系统，通过语义感知的上下文检索、专用智能体和结构化工具辅助推理，解决了传统模糊测试和ChatAFL的局限性，显著提高了分支覆盖率和协议状态探索能力。


<details>
  <summary>Details</summary>
Motivation: 传统协议模糊测试技术（如AFL）由于对复杂协议语法的语义理解有限和种子变异策略僵化而效果不佳。ChatAFL虽然引入了大语言模型，但仍面临输出不可靠、幻觉问题以及假设LLM了解协议规范等问题。

Method: 使用协议文档（RFC文档）构建向量数据库嵌入，实现检索增强生成（RAG）管道；将模糊测试过程分解为模块化的智能体组，通过思维链推理协作，基于检索到的上下文知识动态调整模糊测试策略。

Result: 在实时流协议（RTSP）上的实验评估表明，MultiFuzz相比最先进的模糊测试工具（NSFuzz、AFLNet、ChatAFL）显著提高了分支覆盖率，探索了更深的协议状态和转换。

Conclusion: 通过结合密集检索、智能体协调和语言模型推理，MultiFuzz建立了自主协议模糊测试的新范式，为未来智能体化模糊测试系统研究提供了可扩展和可扩展的基础。

Abstract: Traditional protocol fuzzing techniques, such as those employed by AFL-based
systems, often lack effectiveness due to a limited semantic understanding of
complex protocol grammars and rigid seed mutation strategies. Recent works,
such as ChatAFL, have integrated Large Language Models (LLMs) to guide protocol
fuzzing and address these limitations, pushing protocol fuzzers to wider
exploration of the protocol state space. But ChatAFL still faces issues like
unreliable output, LLM hallucinations, and assumptions of LLM knowledge about
protocol specifications. This paper introduces MultiFuzz, a novel dense
retrieval-based multi-agent system designed to overcome these limitations by
integrating semantic-aware context retrieval, specialized agents, and
structured tool-assisted reasoning. MultiFuzz utilizes agentic chunks of
protocol documentation (RFC Documents) to build embeddings in a vector database
for a retrieval-augmented generation (RAG) pipeline, enabling agents to
generate more reliable and structured outputs, enhancing the fuzzer in mutating
protocol messages with enhanced state coverage and adherence to syntactic
constraints. The framework decomposes the fuzzing process into modular groups
of agents that collaborate through chain-of-thought reasoning to dynamically
adapt fuzzing strategies based on the retrieved contextual knowledge.
Experimental evaluations on the Real-Time Streaming Protocol (RTSP) demonstrate
that MultiFuzz significantly improves branch coverage and explores deeper
protocol states and transitions over state-of-the-art (SOTA) fuzzers such as
NSFuzz, AFLNet, and ChatAFL. By combining dense retrieval, agentic
coordination, and language model reasoning, MultiFuzz establishes a new
paradigm in autonomous protocol fuzzing, offering a scalable and extensible
foundation for future research in intelligent agentic-based fuzzing systems.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [45] [GLASS: Test-Time Acceleration for LLMs via Global-Local Neural Importance Aggregation](https://arxiv.org/abs/2508.14302)
*Amirmohsen Sattarifard,Sepehr Lavasani,Ehsan Imani,Kunlin Zhang,Hanlin Xu,Fengyu Sun,Negar Hassanpour,Chao Gao*

Main category: cs.LG

TL;DR: GLASS是一种无需训练的动态剪枝方法，通过结合局部激活和全局重要性统计来动态选择FFN单元，在边缘设备上高效部署大语言模型，特别在长文本生成场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 在边缘硬件上部署大语言模型需要动态剪枝来减少计算量，但现有方法要么固定稀疏模式，要么增加运行时开销，零-shot方法在短提示/长生成场景中效果不佳。

Method: 提出A/I-GLASS方法：基于激活和影响的全局-局部神经重要性聚合，使用排名聚合结合提示局部统计和模型固有全局统计来动态选择FFN单元，无需训练或辅助预测器。

Result: 在多个LLM和基准测试中，GLASS显著优于先前的无训练方法，特别是在具有挑战性的长文本生成场景中，且不增加推理开销。

Conclusion: GLASS提供了一种高效的无训练动态剪枝方案，能够在不牺牲质量的情况下显著减少计算量，特别适合边缘设备上的LLM部署。

Abstract: Deploying Large Language Models (LLMs) on edge hardware demands aggressive,
prompt-aware dynamic pruning to reduce computation without degrading quality.
Static or predictor-based schemes either lock in a single sparsity pattern or
incur extra runtime overhead, and recent zero-shot methods that rely on
statistics from a single prompt fail on short prompt and/or long generation
scenarios. We introduce A/I-GLASS: Activation- and Impact-based Global-Local
neural importance Aggregation for feed-forward network SparSification, two
training-free methods that dynamically select FFN units using a
rank-aggregation of prompt local and model-intrinsic global neuron statistics.
Empirical results across multiple LLMs and benchmarks demonstrate that GLASS
significantly outperforms prior training-free methods, particularly in
challenging long-form generation scenarios, without relying on auxiliary
predictors or adding any inference overhead.

</details>


### [46] [DuPO: Enabling Reliable LLM Self-Verification via Dual Preference Optimization](https://arxiv.org/abs/2508.14460)
*Shuaijie She,Yu Bao,Yu Lu,Lu Xu,Tao Li,Wenhao Zhu,Shujian Huang,Shanbo Cheng,Lu Lu,Yuxuan Wang*

Main category: cs.LG

TL;DR: DuPO是一个基于对偶学习的偏好优化框架，通过广义对偶性生成无需标注的反馈，解决了RLVR对昂贵标签的依赖和传统对偶学习仅限于严格对偶任务对的限制。


<details>
  <summary>Details</summary>
Motivation: 解决强化学习需要验证奖励(RLVR)依赖昂贵标注标签且仅适用于可验证任务的局限性，以及传统对偶学习仅限于严格对偶任务对(如翻译和回译)的问题。

Method: 将原始任务输入分解为已知和未知组件，构建对偶任务来使用原始输出和已知信息重建未知部分(如反转数学解恢复隐藏变量)，将重建质量作为自监督奖励来优化原始任务。

Result: 在756个翻译方向上平均提升2.13 COMET分数，在三个数学推理挑战基准上平均提升6.4个百分点，作为推理时重排序器性能提升9.3个百分点。

Conclusion: DuPO是一个可扩展、通用且无需标注的大语言模型优化范式，通过广义对偶学习实现了有效的自监督优化。

Abstract: We present DuPO, a dual learning-based preference optimization framework that
generates annotation-free feedback via a generalized duality. DuPO addresses
two key limitations: Reinforcement Learning with Verifiable Rewards (RLVR)'s
reliance on costly labels and applicability restricted to verifiable tasks, and
traditional dual learning's restriction to strictly dual task pairs (e.g.,
translation and back-translation). Specifically, DuPO decomposes a primal
task's input into known and unknown components, then constructs its dual task
to reconstruct the unknown part using the primal output and known information
(e.g., reversing math solutions to recover hidden variables), broadening
applicability to non-invertible tasks. The quality of this reconstruction
serves as a self-supervised reward to optimize the primal task, synergizing
with LLMs' ability to instantiate both tasks via a single model. Empirically,
DuPO achieves substantial gains across diverse tasks: it enhances the average
translation quality by 2.13 COMET over 756 directions, boosts the mathematical
reasoning accuracy by an average of 6.4 points on three challenge benchmarks,
and enhances performance by 9.3 points as an inference-time reranker (trading
computation for accuracy). These results position DuPO as a scalable, general,
and annotation-free paradigm for LLM optimization.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [47] [RAG-Boost: Retrieval-Augmented Generation Enhanced LLM-based Speech Recognition](https://arxiv.org/abs/2508.14048)
*Pengcheng Wang,Sheng Li,Takahiro Shinozaki*

Main category: eess.AS

TL;DR: RAG-Boost系统通过在实时ASR过程中集成检索增强生成模块，利用音频-文本对和领域术语的向量存储来修正识别错误，提升语音识别性能


<details>
  <summary>Details</summary>
Motivation: 解决传统ASR系统在实时语音识别中可能出现的错误，通过检索相关上下文信息来增强识别准确性

Method: 在基线LLM-based ASR系统基础上添加RAG模块，使用部分ASR假设查询向量存储，将检索结果与实时ASR假设融合后传递给LLM

Result: 系统能够有效修正识别错误，产生改进的识别响应

Conclusion: RAG-Boost通过检索增强生成技术成功提升了实时ASR系统的性能，为语音识别提供了有效的错误修正机制

Abstract: In this paper, we propose RAG-Boost (ST-ShinozakiLab Task I system), which
enhances the baseline LLM-based ASR system of the MLC-SLM Challenge (task I)
with a retrieval-augmented generation (RAG) module on the fly. Each partial ASR
hypothesis queries a vector store of audio-text pairs and domain terms, and the
retrieved results are fused with the live ASR hypotheses to fix recognition
errors. The fused hypotheses are passed to the LLM, yielding improved
responses.

</details>


### [48] [MahaTTS: A Unified Framework for Multilingual Text-to-Speech Synthesis](https://arxiv.org/abs/2508.14049)
*Jaskaran Singh,Amartya Roy Chowdhury,Raghav Prabhakar,Varshul C. W*

Main category: eess.AS

TL;DR: MahaTTS-v2是一个专注于印度语言的多语言多说话人文本转语音系统，在20K小时印度语言数据上训练，使用Wav2Vec2.0语义提取和条件流模型进行语义到梅尔频谱图生成。


<details>
  <summary>Details</summary>
Motivation: 当前TTS模型主要关注英语和欧洲语言，限制了信息获取的普及性，特别是在印度语言方面存在巨大空白。

Method: 采用Wav2Vec2.0 token进行语义提取，语言模型进行文本到语义建模，条件流模型(CFM)进行语义到梅尔频谱图生成。

Result: 实验结果表明该方法比其他框架更有效，在印度语言上表现出优秀的多语言表达能力。

Conclusion: MahaTTS-v2成功填补了印度语言TTS系统的空白，为更广泛的语言群体提供了信息获取途径。

Abstract: Current Text-to-Speech models pose a multilingual challenge, where most of
the models traditionally focus on English and European languages, thereby
hurting the potential to provide access to information to many more people. To
address this gap, we introduce MahaTTS-v2 a Multilingual Multi-speaker
Text-To-Speech (TTS) system that has excellent multilingual expressive
capabilities in Indic languages. The model has been trained on around 20K hours
of data specifically focused on Indian languages. Our approach leverages
Wav2Vec2.0 tokens for semantic extraction, and a Language Model (LM) for
text-to-semantic modeling. Additionally, we have used a Conditional Flow Model
(CFM) for semantics to melspectogram generation. The experimental results
indicate the effectiveness of the proposed approach over other frameworks. Our
code is available at https://github.com/dubverse-ai/MahaTTSv2

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [49] [Who Sees What? Structured Thought-Action Sequences for Epistemic Reasoning in LLMs](https://arxiv.org/abs/2508.14564)
*Luca Annese,Sabrina Patania,Silvia Serino,Tom Foulsham,Silvia Rossi,Azzurra Ruggeri,Dimitri Ognibene*

Main category: cs.AI

TL;DR: 该研究探索使用规划器生成的结构化示例来提升LLM智能体的视角采择能力，发现虽然能减少澄清请求和行动步骤，但结构化示例本身不足以实现稳健的视角采择


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在需要主动感知、协作推理和视角采择的任务中仍面临挑战，研究旨在通过结构化示例改进基于LLM的智能体性能

Method: 提出结构化解决方案处理流程，从Fast Downward规划器生成的转换解图中提取三类示例：最优目标路径(G型)、信息节点路径(E型)和对比替代行动的最优决策序列(L型)，并将其转换为"思考-行动"示例

Result: L型示例略微减少了澄清请求和总体行动步骤，但未带来一致改进。智能体在基本注意力过滤任务中成功，但在需要心理化遮挡空间或权衡认知行动成本的场景中表现不佳

Conclusion: 仅靠结构化示例不足以实现稳健的视角采择，需要明确的信念追踪、成本建模和更丰富的环境来支持基于LLM智能体的社会性协作

Abstract: Recent advances in large language models (LLMs) and reasoning frameworks have
opened new possibilities for improving the perspective -taking capabilities of
autonomous agents. However, tasks that involve active perception, collaborative
reasoning, and perspective taking (understanding what another agent can see or
knows) pose persistent challenges for current LLM-based systems. This study
investigates the potential of structured examples derived from transformed
solution graphs generated by the Fast Downward planner to improve the
performance of LLM-based agents within a ReAct framework. We propose a
structured solution-processing pipeline that generates three distinct
categories of examples: optimal goal paths (G-type), informative node paths
(E-type), and step-by-step optimal decision sequences contrasting alternative
actions (L-type). These solutions are further converted into ``thought-action''
examples by prompting an LLM to explicitly articulate the reasoning behind each
decision. While L-type examples slightly reduce clarification requests and
overall action steps, they do not yield consistent improvements. Agents are
successful in tasks requiring basic attentional filtering but struggle in
scenarios that required mentalising about occluded spaces or weighing the costs
of epistemic actions. These findings suggest that structured examples alone are
insufficient for robust perspective-taking, underscoring the need for explicit
belief tracking, cost modelling, and richer environments to enable socially
grounded collaboration in LLM-based agents.

</details>


### [50] [MCP-Universe: Benchmarking Large Language Models with Real-World Model Context Protocol Servers](https://arxiv.org/abs/2508.14704)
*Ziyang Luo,Zhiqi Shen,Wenzhuo Yang,Zirui Zhao,Prathyusha Jwalapuram,Amrita Saha,Doyen Sahoo,Silvio Savarese,Caiming Xiong,Junnan Li*

Main category: cs.AI

TL;DR: MCP-Universe是首个专门为评估LLM与真实MCP服务器交互能力而设计的综合基准测试，涵盖6个核心领域11个服务器，发现即使是SOTA模型也存在显著性能限制


<details>
  <summary>Details</summary>
Motivation: 现有基准测试过于简单，无法捕捉真实应用挑战，如长时程推理和大规模不熟悉工具空间，需要更全面的评估标准

Method: 构建包含6个领域11个MCP服务器的基准测试，采用执行式评估器（格式评估器、静态评估器、动态评估器）进行严格评估

Result: 顶级模型如GPT-5(43.72%)、Grok-4(33.33%)和Claude-4.0-Sonnet(29.44%)表现显著受限，面临长上下文和未知工具挑战

Conclusion: MCP-Universe填补了关键空白，提供了可扩展的评估框架，促进MCP生态系统的创新发展

Abstract: The Model Context Protocol has emerged as a transformative standard for
connecting large language models to external data sources and tools, rapidly
gaining adoption across major AI providers and development platforms. However,
existing benchmarks are overly simplistic and fail to capture real application
challenges such as long-horizon reasoning and large, unfamiliar tool spaces. To
address this critical gap, we introduce MCP-Universe, the first comprehensive
benchmark specifically designed to evaluate LLMs in realistic and hard tasks
through interaction with real-world MCP servers. Our benchmark encompasses 6
core domains spanning 11 different MCP servers: Location Navigation, Repository
Management, Financial Analysis, 3D Design, Browser Automation, and Web
Searching. To ensure rigorous evaluation, we implement execution-based
evaluators, including format evaluators for agent format compliance, static
evaluators for time-invariant content matching, and dynamic evaluators that
automatically retrieve real-time ground truth for temporally sensitive tasks.
Through extensive evaluation of leading LLMs, we find that even SOTA models
such as GPT-5 (43.72%), Grok-4 (33.33%) and Claude-4.0-Sonnet (29.44%) exhibit
significant performance limitations. In addition, our benchmark poses a
significant long-context challenge for LLM agents, as the number of input
tokens increases rapidly with the number of interaction steps. Moreover, it
introduces an unknown-tools challenge, as LLM agents often lack familiarity
with the precise usage of the MCP servers. Notably, enterprise-level agents
like Cursor cannot achieve better performance than standard ReAct frameworks.
Beyond evaluation, we open-source our extensible evaluation framework with UI
support, enabling researchers and practitioners to seamlessly integrate new
agents and MCP servers while fostering innovation in the rapidly evolving MCP
ecosystem.

</details>


### [51] [Privileged Self-Access Matters for Introspection in AI](https://arxiv.org/abs/2508.14802)
*Siyuan Song,Harvey Lederman,Jennifer Hu,Kyle Mahowald*

Main category: cs.AI

TL;DR: 论文探讨AI模型是否具备内省能力，提出比现有"轻量级"定义更"厚重"的内省定义，并通过LLM温度参数推理实验证明模型表面具备轻量级内省但实际缺乏真正内省能力


<details>
  <summary>Details</summary>
Motivation: AI模型能否内省已成为重要实践问题，但缺乏统一的内省定义标准，需要建立更严格的内省评估框架

Method: 提出新的内省定义：通过比第三方更可靠且计算成本相当或更低的过程获取内部状态信息；使用LLM推理自身温度参数的实验进行验证

Result: 实验显示LLM表面上具备轻量级内省能力，但按照作者提出的更严格定义，它们实际上缺乏有意义的内省能力

Conclusion: 需要采用更严格的内省定义来准确评估AI模型的内省能力，当前LLM的内省表现可能只是表面现象而非真正的内省

Abstract: Whether AI models can introspect is an increasingly important practical
question. But there is no consensus on how introspection is to be defined.
Beginning from a recently proposed ''lightweight'' definition, we argue instead
for a thicker one. According to our proposal, introspection in AI is any
process which yields information about internal states through a process more
reliable than one with equal or lower computational cost available to a third
party. Using experiments where LLMs reason about their internal temperature
parameters, we show they can appear to have lightweight introspection while
failing to meaningfully introspect per our proposed definition.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [52] [Measuring LLM Code Generation Stability via Structural Entropy](https://arxiv.org/abs/2508.14288)
*Yewei Song,Tiezhu Sun,Xunzhu Tang,Prateek Rajput,Tegawende F. Bissyande,Jacques Klein*

Main category: cs.SE

TL;DR: 本文提出了一种基于抽象语法树(AST)的结构熵方法，用于评估大语言模型代码生成的稳定性，无需参考代码或执行测试。


<details>
  <summary>Details</summary>
Motivation: 评估大语言模型代码生成的稳定性对于判断其在真实开发环境中的可靠性至关重要，现有指标如pass@k、BLEU等存在局限性。

Method: 将结构熵概念扩展到程序领域，通过分析AST的深度受限子树的多重集，计算Jensen-Shannon散度和结构交叉熵比来度量稳定性。

Result: 在标准代码生成任务上对多个领先LLM进行基准测试，证明AST驱动的结构熵能够揭示模型一致性和鲁棒性的细微差别。

Conclusion: 该方法时间复杂度为O(n,d)，无需外部测试，为代码生成评估工具包提供了一个轻量级的补充方案。

Abstract: Assessing the stability of code generation from large language models (LLMs)
is essential for judging their reliability in real-world development. We extend
prior "structural-entropy concepts" to the program domain by pairing entropy
with abstract syntax tree (AST) analysis. For any fixed prompt, we collect the
multiset of depth-bounded subtrees of AST in each generated program and treat
their relative frequencies as a probability distribution. We then measure
stability in two complementary ways: (i) Jensen-Shannon divergence, a
symmetric, bounded indicator of structural overlap, and (ii) a Structural
Cross-Entropy ratio that highlights missing high-probability patterns. Both
metrics admit structural-only and token-aware variants, enabling separate views
on control-flow shape and identifier-level variability. Unlike pass@k, BLEU, or
CodeBLEU, our metrics are reference-free, language-agnostic, and
execution-independent. We benchmark several leading LLMs on standard code
generation tasks, demonstrating that AST-driven structural entropy reveals
nuances in model consistency and robustness. The method runs in O(n,d) time
with no external tests, providing a lightweight addition to the code-generation
evaluation toolkit.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [53] [FinAgentBench: A Benchmark Dataset for Agentic Retrieval in Financial Question Answering](https://arxiv.org/abs/2508.14052)
*Chanyeol Choi,Jihoon Kwon,Alejandro Lopez-Lira,Chaewoon Kim,Minjae Kim,Juneha Hwang,Jaeseon Ha,Hojun Choi,Suyeol Yun,Yongjin Kim,Yongjae Lee*

Main category: cs.IR

TL;DR: 提出了FinAgentBench，这是金融领域首个用于评估多步推理检索的大规模基准测试，包含3429个专家标注的案例，评估LLM代理在金融文档检索中的能力。


<details>
  <summary>Details</summary>
Motivation: 传统的信息检索方法在金融领域往往检索准确性不足，需要同时捕获语义相似性和对文档结构及领域知识进行细粒度推理。虽然LLMs为多步推理检索提供了新机会，但金融领域缺乏相应的评估基准。

Method: 构建了包含3429个专家标注案例的基准测试，评估LLM代理在两个推理步骤上的能力：(1)从候选文档类型中识别最相关类型，(2)在选定文档中精确定位关键段落。评估框架明确分离这两个推理步骤以解决上下文限制。

Result: 评估了一系列最先进的模型，并证明针对性的微调可以显著提高代理检索性能。

Conclusion: 该基准为研究在复杂、领域特定的金融任务中检索导向的LLM行为提供了基础，将公开发布数据集并计划扩展到整个S&P 500及更广范围。

Abstract: Accurate information retrieval (IR) is critical in the financial domain,
where investors must identify relevant information from large collections of
documents. Traditional IR methods-whether sparse or dense-often fall short in
retrieval accuracy, as it requires not only capturing semantic similarity but
also performing fine-grained reasoning over document structure and
domain-specific knowledge. Recent advances in large language models (LLMs) have
opened up new opportunities for retrieval with multi-step reasoning, where the
model ranks passages through iterative reasoning about which information is
most relevant to a given query. However, there exists no benchmark to evaluate
such capabilities in the financial domain. To address this gap, we introduce
FinAgentBench, the first large-scale benchmark for evaluating retrieval with
multi-step reasoning in finance -- a setting we term agentic retrieval. The
benchmark consists of 3,429 expert-annotated examples on S&P-100 listed firms
and assesses whether LLM agents can (1) identify the most relevant document
type among candidates, and (2) pinpoint the key passage within the selected
document. Our evaluation framework explicitly separates these two reasoning
steps to address context limitations. This design enables to provide a
quantitative basis for understanding retrieval-centric LLM behavior in finance.
We evaluate a suite of state-of-the-art models and further demonstrated how
targeted fine-tuning can significantly improve agentic retrieval performance.
Our benchmark provides a foundation for studying retrieval-centric LLM behavior
in complex, domain-specific tasks for finance. We will release the dataset
publicly upon acceptance of the paper and plan to expand and share dataset for
the full S&P 500 and beyond.

</details>


<div id='q-bio.NC'></div>

# q-bio.NC [[Back]](#toc)

### [54] [The Prompting Brain: Neurocognitive Markers of Expertise in Guiding Large Language Models](https://arxiv.org/abs/2508.14869)
*Hend Al-Khalifa,Raneem Almansour,Layan Abdulrahman Alhuasini,Alanood Alsaleh,Mohamad-Hani Temsah,Mohamad-Hani_Temsah,Ashwag Rafea S Alruwaili*

Main category: q-bio.NC

TL;DR: fMRI研究揭示提示工程专家与中级人员在脑功能连接和网络活动上的差异，发现左侧颞中回和额极等脑区功能连接增强，为理解提示工程能力的神经基础提供了初步证据


<details>
  <summary>Details</summary>
Motivation: 探索提示工程专业技能的认知和神经基础，了解人类与大型语言模型交互时的神经机制，为设计更直观的人机界面提供科学依据

Method: 采用横断面fMRI研究，比较专家和中级提示工程师的脑功能连接和网络活动差异

Result: 发现提示工程能力与左侧颞中回、左侧额极等脑区功能连接增强相关，关键认知网络的功率-频率动态发生变化

Conclusion: 研究揭示了提示工程熟练度的神经生物学基础，为理解人类与AI系统交互的认知机制提供了新视角，有助于开发更符合人类认知工作流程的AI系统

Abstract: Prompt engineering has rapidly emerged as a critical skill for effective
interaction with large language models (LLMs). However, the cognitive and
neural underpinnings of this expertise remain largely unexplored. This paper
presents findings from a cross-sectional pilot fMRI study investigating
differences in brain functional connectivity and network activity between
experts and intermediate prompt engineers. Our results reveal distinct neural
signatures associated with higher prompt engineering literacy, including
increased functional connectivity in brain regions such as the left middle
temporal gyrus and the left frontal pole, as well as altered power-frequency
dynamics in key cognitive networks. These findings offer initial insights into
the neurobiological basis of prompt engineering proficiency. We discuss the
implications of these neurocognitive markers in Natural Language Processing
(NLP). Understanding the neural basis of human expertise in interacting with
LLMs can inform the design of more intuitive human-AI interfaces, contribute to
cognitive models of LLM interaction, and potentially guide the development of
AI systems that better align with human cognitive workflows. This
interdisciplinary approach aims to bridge the gap between human cognition and
machine intelligence, fostering a deeper understanding of how humans learn and
adapt to complex AI systems.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [55] [Virtual Community: An Open World for Humans, Robots, and Society](https://arxiv.org/abs/2508.14893)
*Qinhong Zhou,Hongxin Zhang,Xiangye Lin,Zheyuan Zhang,Yutian Chen,Wenjun Liu,Zunzhe Zhang,Sunli Chen,Lixing Fang,Qiushi Lyu,Xinyu Sun,Jincheng Yang,Zeyuan Wang,Bao Chi Dang,Zhehuan Chen,Daksha Ladia,Jiageng Liu,Chuang Gan*

Main category: cs.CV

TL;DR: Virtual Community是一个基于物理引擎的开放世界平台，用于研究人类与机器人在真实3D场景中的社会共存，提出了社区规划和社区机器人两大挑战任务。


<details>
  <summary>Details</summary>
Motivation: 随着AI和机器人技术的快速发展，人类与机器人将在共享社区中共存，这既带来机遇也带来挑战。需要研究具身社会智能、人机协作与竞争、以及开放世界中的人机共存问题。

Method: 构建了开源的多人物理模拟器，支持机器人和人类在社会中的交互；开发了大规模真实世界对齐的社区生成流水线，包括户外空间、室内场景和具有丰富特征的智能体。

Result: 提出了社区规划挑战（评估多智能体在开放世界中的推理规划能力）和社区机器人挑战（要求异构机器人协作解决复杂任务），并评估了各种基线方法，展示了在高层任务规划和底层协作控制方面的挑战。

Conclusion: Virtual Community平台有望推动开放世界环境中人机共存研究的进一步发展，为解决人机社会交互的复杂问题提供了重要工具和测试平台。

Abstract: The rapid progress in AI and Robotics may lead to a profound societal
transformation, as humans and robots begin to coexist within shared
communities, introducing both opportunities and challenges. To explore this
future, we present Virtual Community-an open-world platform for humans, robots,
and society-built on a universal physics engine and grounded in real-world 3D
scenes. With Virtual Community, we aim to study embodied social intelligence at
scale: 1) How robots can intelligently cooperate or compete; 2) How humans
develop social relations and build community; 3) More importantly, how
intelligent robots and humans can co-exist in an open world. To support these,
Virtual Community features: 1) An open-source multi-agent physics simulator
that supports robots, humans, and their interactions within a society; 2) A
large-scale, real-world aligned community generation pipeline, including vast
outdoor space, diverse indoor scenes, and a community of grounded agents with
rich characters and appearances. Leveraging Virtual Community, we propose two
novel challenges. The Community Planning Challenge evaluates multi-agent
reasoning and planning ability in open-world settings, such as cooperating to
help agents with daily activities and efficiently connecting other agents. The
Community Robot Challenge requires multiple heterogeneous robots to collaborate
in solving complex open-world tasks. We evaluate various baselines on these
tasks and demonstrate the challenges in both high-level open-world task
planning and low-level cooperation controls. We hope that Virtual Community
will unlock further study of human-robot coexistence within open-world
environments.

</details>
