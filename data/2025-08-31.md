<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 47]
- [q-bio.NC](#q-bio.NC) [Total: 1]
- [cs.DL](#cs.DL) [Total: 1]
- [cs.CR](#cs.CR) [Total: 1]
- [cs.LG](#cs.LG) [Total: 6]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.AI](#cs.AI) [Total: 3]
- [cs.SD](#cs.SD) [Total: 1]
- [cs.CV](#cs.CV) [Total: 6]
- [cs.IR](#cs.IR) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Social Bias in Multilingual Language Models: A Survey](https://arxiv.org/abs/2508.20201)
*Lance Calvin Lim Gamboa,Yue Feng,Mark Lee*

Main category: cs.CL

TL;DR: 本文对多语言预训练模型中的社会偏见研究进行了系统性综述，分析了偏见评估和缓解方法在多语言和非英语语境中的扩展应用，指出了当前研究在语言多样性、文化意识和方法选择方面的不足，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 预训练多语言模型在处理非英语文本时表现出与英语模型相同的社会偏见，但现有研究主要关注英语语境，缺乏对多语言环境中偏见问题的系统性分析。

Method: 采用系统性文献综述方法，从语言多样性、文化意识、评估指标和缓解技术选择等维度，对多语言偏见研究进行分析和分类。

Result: 研究发现当前多语言偏见研究存在方法设计选择上的局限性（如偏好某些语言、多语言缓解实验稀缺），同时整理了跨语言和文化适应偏见基准时的常见问题和解决方案。

Conclusion: 基于研究发现，提出了加强多语言偏见文献包容性、跨文化适宜性以及与最先进NLP技术对齐的未来研究方向。

Abstract: Pretrained multilingual models exhibit the same social bias as models
processing English texts. This systematic review analyzes emerging research
that extends bias evaluation and mitigation approaches into multilingual and
non-English contexts. We examine these studies with respect to linguistic
diversity, cultural awareness, and their choice of evaluation metrics and
mitigation techniques. Our survey illuminates gaps in the field's dominant
methodological design choices (e.g., preference for certain languages, scarcity
of multilingual mitigation experiments) while cataloging common issues
encountered and solutions implemented in adapting bias benchmarks across
languages and cultures. Drawing from the implications of our findings, we chart
directions for future research that can reinforce the multilingual bias
literature's inclusivity, cross-cultural appropriateness, and alignment with
state-of-the-art NLP advancements.

</details>


### [2] [Prompting Strategies for Language Model-Based Item Generation in K-12 Education: Bridging the Gap Between Small and Large Language Models](https://arxiv.org/abs/2508.20217)
*Mohammad Amini,Babak Ahmadi,Xiaomeng Xiong,Yilin Zhang,Christopher Qiao*

Main category: cs.CL

TL;DR: 本研究探索使用语言模型自动生成形态学评估的多项选择题，通过结构化提示策略和模型比较，证明中等规模模型在适当提示下能产生比大型模型更好的题目质量。


<details>
  <summary>Details</summary>
Motivation: 降低人工测试开发成本和不一致性，探索语言模型在自动题目生成中的应用潜力。

Method: 采用两阶段方法：比较微调的中等模型(Gemma 2B)与未调优的大型模型(GPT-3.5 175B)；评估7种结构化提示策略，包括零样本、少样本、思维链、角色扮演等组合。使用自动化指标和专家评分进行评估。

Result: 结构化提示策略（特别是思维链和序列设计的组合）显著提升了Gemma的输出质量。Gemma生成的题目比GPT-3.5的零样本响应更具结构对齐性和教学适宜性。

Conclusion: 结构化提示和高效微调可以在有限数据条件下增强中等规模模型的自动生成能力，结合自动化指标、专家判断和大模型模拟能确保与评估目标的一致性，为K-12语言评估提供了实用且可扩展的工作流程。

Abstract: This study explores automatic generation (AIG) using language models to
create multiple choice questions (MCQs) for morphological assessment, aiming to
reduce the cost and inconsistency of manual test development. The study used a
two-fold approach. First, we compared a fine-tuned medium model (Gemma, 2B)
with a larger untuned one (GPT-3.5, 175B). Second, we evaluated seven
structured prompting strategies, including zero-shot, few-shot,
chain-of-thought, role-based, sequential, and combinations. Generated items
were assessed using automated metrics and expert scoring across five
dimensions. We also used GPT-4.1, trained on expert-rated samples, to simulate
human scoring at scale. Results show that structured prompting, especially
strategies combining chain-of-thought and sequential design, significantly
improved Gemma's outputs. Gemma generally produced more construct-aligned and
instructionally appropriate items than GPT-3.5's zero-shot responses, with
prompt design playing a key role in mid-size model performance. This study
demonstrates that structured prompting and efficient fine-tuning can enhance
midsized models for AIG under limited data conditions. We highlight the value
of combining automated metrics, expert judgment, and large-model simulation to
ensure alignment with assessment goals. The proposed workflow offers a
practical and scalable way to develop and validate language assessment items
for K-12.

</details>


### [3] [Integrating SystemC TLM into FMI 3.0 Co-Simulations with an Open-Source Approach](https://arxiv.org/abs/2508.20223)
*Andrei Mihai Albu,Giovanni Pollo,Alessio Burrello,Daniele Jahier Pagliari,Cristian Tesconi,Alessandra Neri,Dario Soldi,Fabio Autieri,Sara Vinco*

Main category: cs.CL

TL;DR: 提出了一种将SystemC TLM模型集成到FMI协同仿真工作流程的开源方法，通过将SystemC组件封装为FMI 3.0 FMU实现跨域标准化集成


<details>
  <summary>Details</summary>
Motivation: 随着信息物理系统复杂度的增加，特别是汽车应用中，需要高效的建模和跨域协同仿真技术。SystemC TLM虽然支持硬件/软件协同设计，但与其他工程领域模型的互操作性有限

Method: 开发了轻量级开源工具链，将SystemC TLM组件封装为FMI 3.0协同仿真功能模型单元(FMU)，解决了时间同步和数据交换等关键技术挑战

Result: 通过代表性案例研究证明了该集成方法的可行性和有效性

Conclusion: 该方法实现了SystemC TLM模型与FMI标准协同仿真工作流程的无缝标准化集成，解决了跨异构仿真环境的互操作性问题

Abstract: The growing complexity of cyber-physical systems, particularly in automotive
applications, has increased the demand for efficient modeling and cross-domain
co-simulation techniques. While SystemC Transaction-Level Modeling (TLM)
enables effective hardware/software co-design, its limited interoperability
with models from other engineering domains poses integration challenges. This
paper presents a fully open-source methodology for integrating SystemC TLM
models into Functional Mock-up Interface (FMI)-based co-simulation workflows.
By encapsulating SystemC TLM components as FMI 3.0 Co Simulation Functional
Mock-up Units (FMUs), the proposed approach facilitates seamless, standardized
integration across heterogeneous simulation environments. We introduce a
lightweight open-source toolchain, address key technical challenges such as
time synchronization and data exchange, and demonstrate the feasibility and
effectiveness of the integration through representative case studies.

</details>


### [4] [Can Compact Language Models Search Like Agents? Distillation-Guided Policy Optimization for Preserving Agentic RAG Capabilities](https://arxiv.org/abs/2508.20324)
*Rikuto Kotoge,Mai Nishimura,Jiaxin Ma*

Main category: cs.CL

TL;DR: DGPO通过教师演示冷启动和持续指导，解决了小型语言模型在强化学习训练中的稀疏奖励问题，使紧凑模型能够实现复杂的代理搜索行为。


<details>
  <summary>Details</summary>
Motivation: 小型语言模型（如0.5B参数）由于推理能力差，在强化学习训练中面临稀疏奖励和不稳定训练的问题，需要一种方法来克服这些困难。

Method: 提出蒸馏引导策略优化（DGPO），包括从教师演示进行冷启动初始化，以及在策略优化过程中提供持续的教师指导。

Result: DGPO使紧凑模型能够实现复杂的代理搜索行为，在某些情况下甚至超越了更大的教师模型。

Conclusion: DGPO使得在计算资源受限的环境中实现代理RAG成为可能。

Abstract: Reinforcement Learning has emerged as a post-training approach to elicit
agentic RAG behaviors such as search and planning from language models.
However, compact language models (e.g., 0.5B parameters) struggle due to poor
reasoning ability, resulting in sparse rewards and unstable training. To
overcome these difficulties, we propose Distillation-Guided Policy Optimization
(DGPO), which addresses the challenges through cold-start initialization from
teacher demonstrations and continuous teacher guidance during policy
optimization. To systematically evaluate our approach, we introduce Agentic RAG
Capabilities (ARC), a fine-grained metric analyzing reasoning, search
coordination, and response synthesis. Comprehensive experiments demonstrate
that DGPO enables compact models to achieve sophisticated agentic search
behaviors, even outperforming the larger teacher model in some cases. DGPO
makes agentic RAG feasible in computing resource-constrained environments.

</details>


### [5] [GUARD: Guideline Upholding Test through Adaptive Role-play and Jailbreak Diagnostics for LLMs](https://arxiv.org/abs/2508.20325)
*Haibo Jin,Ruoxi Chen,Peiyan Zhang,Andy Zhou,Yang Zhang,Haohan Wang*

Main category: cs.CL

TL;DR: GUARD是一个将政府AI伦理指南转化为可操作测试问题的方法，通过自动生成违反指南的问题来评估LLM合规性，并包含越狱诊断功能来识别潜在安全漏洞。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在各领域的广泛应用，其可能生成有害内容引发了社会关注。政府发布的伦理指南多为高层级要求，缺乏具体可操作的测试方法，需要将指南转化为实际测试问题来验证LLM合规性。

Method: GUARD方法通过自动生成违反政府指南的问题来测试LLM响应合规性。对于不直接违反指南的响应，引入GUARD-JD越狱诊断功能，创建可能引发不道德响应的场景，识别潜在的安全机制绕过风险。最终生成合规报告。

Result: 在7个LLM（包括Vicuna-13B、GPT系列、Claude-3.7等）上实证验证了有效性，测试了三个政府指南的合规性并进行了越狱诊断。GUARD-JD还可迁移到视觉语言模型。

Conclusion: GUARD提供了一种将高层级伦理指南转化为具体测试问题的有效方法，能够系统评估LLM的合规性并识别潜在安全风险，有助于促进可靠的LLM应用发展。

Abstract: As Large Language Models become increasingly integral to various domains,
their potential to generate harmful responses has prompted significant societal
and regulatory concerns. In response, governments have issued ethics guidelines
to promote the development of trustworthy AI. However, these guidelines are
typically high-level demands for developers and testers, leaving a gap in
translating them into actionable testing questions to verify LLM compliance.
  To address this challenge, we introduce GUARD (\textbf{G}uideline
\textbf{U}pholding Test through \textbf{A}daptive \textbf{R}ole-play and
Jailbreak \textbf{D}iagnostics), a testing method designed to operationalize
guidelines into specific guideline-violating questions that assess LLM
adherence. To implement this, GUARD uses automated generation of
guideline-violating questions based on government-issued guidelines, thereby
testing whether responses comply with these guidelines. When responses directly
violate guidelines, GUARD reports inconsistencies. Furthermore, for responses
that do not directly violate guidelines, GUARD integrates the concept of
``jailbreaks'' to diagnostics, named GUARD-JD, which creates scenarios that
provoke unethical or guideline-violating responses, effectively identifying
potential scenarios that could bypass built-in safety mechanisms. Our method
finally culminates in a compliance report, delineating the extent of adherence
and highlighting any violations.
  We have empirically validated the effectiveness of GUARD on seven LLMs,
including Vicuna-13B, LongChat-7B, Llama2-7B, Llama-3-8B, GPT-3.5, GPT-4,
GPT-4o, and Claude-3.7, by testing compliance under three government-issued
guidelines and conducting jailbreak diagnostics. Additionally, GUARD-JD can
transfer jailbreak diagnostics to vision-language models, demonstrating its
usage in promoting reliable LLM-based applications.

</details>


### [6] [Joint Enhancement of Relational Reasoning for Long-Context LLMs](https://arxiv.org/abs/2508.20351)
*Zhirui Chen,Wei Shen,Jiashui Huang,Ling Shao*

Main category: cs.CL

TL;DR: JERR是一个通过图推理增强大语言模型长文本理解能力的新框架，包含摘要提取、图构建和关系推理三个核心组件，在多个评估指标上优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在处理长上下文时面临的内存限制、复杂任务处理困难、缺乏透明度和容易产生幻觉等问题。

Method: 采用三步法：1）策略性文本分块提取摘要；2）构建有向无环图消除冗余确保逻辑一致性；3）集成蒙特卡洛树搜索辅助复杂推理路径导航。

Result: 在ROUGE和F1指标上 consistently 优于所有基线方法，在LLM-Rater评估中获得最高分数。

Conclusion: JERR框架为大语言模型处理扩展上下文和复杂推理任务提供了新颖解决方案，显著提升了可靠性和透明度。

Abstract: Despite significant progress, large language models (LLMs) still struggle
with long contexts due to memory limitations and their inability to tackle
complex and long-context tasks. Additionally, LLMs often suffer from a lack of
transparency and are prone to producing hallucinations. To address these
challenges, we propose \textbf{JERR}, a novel framework designed to enhance
long-context comprehension via graph-based reasoning in LLMs. JERR integrates
three key components: synopsis extraction, graph construction, and relational
reasoning. First, synopsis is extracted by chunking text strategically,
allowing the model to summarize and understand information more efficiently.
Second, we build a directed acyclic graph (DAG) to resolve redundancy, ensuring
logical consistency and clarity. Finally, we incorporate Monte Carlo Tree
Search (MCTS) to help the model navigate complex reasoning paths, ensuring more
accurate and interpretable outputs. This framework provides a novel solution
that enables LLMs to handle extended contexts and complex reasoning tasks with
improved reliability and transparency. Experimental results show that JERR
consistently outperforms all baselines on the ROUGE and F1 metrics, achieving
the highest scores on the LLM-Rater evaluation.

</details>


### [7] [Graph-R1: Unleashing LLM Reasoning with NP-Hard Graph Problems](https://arxiv.org/abs/2508.20373)
*Yuyao Wang,Bowen Liu,Jianheng Tang,Nuo Chen,Yuhan Li,Qifan Zhang,Jia Li*

Main category: cs.CL

TL;DR: 这篇论文提出了一种使用NP难图问题作为合成训练资源来培养大语言模型长链式思绪能力的新方法，通过两阶段进行调优后训练，在多个领域展现出了良好的推理能力和效率。


<details>
  <summary>Details</summary>
Motivation: 目前大语言模型的长链式思绪能力主要依靠人工精检的高质量数据集进行后训练，成本高且可扩展性受限。需要寻找一种成本效益高、可扩展的合成训练资源来提升模型的深度思绪能力。

Method: 使用NP难图问题作为合成训练资源，开发了两阶段后训练框架：1）在拒绝采样的NPH图实例上进行长链式监督微调，提升思绪深度；2）使用细粒度奖励设计进行强化学习，提升思绪效率。

Result: 标志模型Graph-R1-7B在数学、编码、STEM和逻辑等多个领域都展现出良好的泛化能力，并在NPH图问题上在准确性和思绪效率方面超过QwQ-32B模型。

Conclusion: NP难图问题是一种高效且可扩展的资源，可以有效培养大语言模型的长链式思绪能力，为LLM后训练开启了新的研究方向。

Abstract: Reasoning Large Language Models (RLLMs) have recently achieved remarkable
progress on complex reasoning tasks, largely enabled by their long
chain-of-thought (Long CoT) capabilities. However, developing these Long CoT
behaviors relies heavily on post-training with high-quality datasets, which are
typically costly and human-curated (e.g., mathematics and code), leaving
scalable alternatives unexplored. In this work, we introduce NP-hard (NPH)
graph problems as a novel synthetic training corpus, as they inherently require
deep reasoning, extensive exploration, and reflective strategies, which are
core characteristics of Long CoT reasoning. Building on this insight, we
develop a two-stage post-training framework: (i) Long CoT Supervised
Fine-Tuning (SFT) on rejection-sampled NPH graph instances, which substantially
enhances reasoning depth, and (ii) Reinforcement Learning (RL) with a
fine-grained reward design, which sharpens reasoning efficiency. Our flagship
model, Graph-R1-7B, demonstrates strong generalization across mathematics,
coding, STEM, and logic, and surpasses QwQ-32B on NPH graph problems in both
accuracy and reasoning efficiency. These results position NPH graph problems as
an effective and scalable resource for advancing Long CoT reasoning in LLMs,
opening a new frontier for LLM post-training. Our implementation is available
at https://github.com/Graph-Reasoner/Graph-R1, with models and datasets hosted
in our Hugging Face collection HKUST-DSAIL/Graph-R1.

</details>


### [8] [CAPE: Context-Aware Personality Evaluation Framework for Large Language Models](https://arxiv.org/abs/2508.20385)
*Jivnesh Sandhan,Fei Cheng,Tushar Sandhan,Yugo Murawaki*

Main category: cs.CL

TL;DR: 本文提出了首个上下文感知的人格评估框架CAPE，用于评估大语言模型在对话历史影响下的行为一致性和人格特质变化。


<details>
  <summary>Details</summary>
Motivation: 现有心理测量测试采用无上下文方法评估LLMs，忽略了真实对话中历史交互对响应的影响，需要开发能够考虑对话历史的评估框架。

Method: 提出CAPE框架，引入新指标量化LLM响应一致性，在7个LLM上进行实验分析对话历史对响应一致性和人格特质的影响。

Result: 对话历史通过上下文学习增强响应一致性，但也会导致人格偏移；GPT模型对问题顺序鲁棒，而Gemini和Llama对先前交互敏感；角色扮演代理中上下文依赖的人格偏移改善一致性并与人类判断更好对齐。

Conclusion: 上下文感知评估揭示了LLMs在真实对话场景中的复杂行为模式，为更准确的心理测量评估提供了新框架和洞见。

Abstract: Psychometric tests, traditionally used to assess humans, are now being
applied to Large Language Models (LLMs) to evaluate their behavioral traits.
However, existing studies follow a context-free approach, answering each
question in isolation to avoid contextual influence. We term this the Disney
World test, an artificial setting that ignores real-world applications, where
conversational history shapes responses. To bridge this gap, we propose the
first Context-Aware Personality Evaluation (CAPE) framework for LLMs,
incorporating prior conversational interactions. To thoroughly analyze the
influence of context, we introduce novel metrics to quantify the consistency of
LLM responses, a fundamental trait in human behavior.
  Our exhaustive experiments on 7 LLMs reveal that conversational history
enhances response consistency via in-context learning but also induces
personality shifts, with GPT-3.5-Turbo and GPT-4-Turbo exhibiting extreme
deviations. While GPT models are robust to question ordering, Gemini-1.5-Flash
and Llama-8B display significant sensitivity. Moreover, GPT models response
stem from their intrinsic personality traits as well as prior interactions,
whereas Gemini-1.5-Flash and Llama--8B heavily depend on prior interactions.
Finally, applying our framework to Role Playing Agents (RPAs) shows
context-dependent personality shifts improve response consistency and better
align with human judgments. Our code and datasets are publicly available at:
https://github.com/jivnesh/CAPE

</details>


### [9] [Measuring Reasoning Utility in LLMs via Conditional Entropy Reduction](https://arxiv.org/abs/2508.20395)
*Xu Guo*

Main category: cs.CL

TL;DR: 研究发现推理步骤中的条件熵变化模式与答案正确性相关：熵递减通常对应正确答案，而熵平坦或递增往往导致错误答案。错误推理路径通常更长，说明更长推理不一定更好。


<details>
  <summary>Details</summary>
Motivation: 现有研究很少分析推理步骤对最终答案正确性的贡献。由于自回归生成的随机性，生成更多上下文不能保证提高答案置信度，需要预测推理步骤的有效性来优化推理流程。

Method: 在MATH数据集上进行oracle研究，使用Qwen2.5-32B和GPT-4o生成推理链，然后用Qwen3-8B量化推理链对最终准确性的效用。通过条件熵（词汇表上的期望负对数似然）逐步测量模型对答案跨度Y的不确定性。

Result: 条件熵随步骤递减的模式与正确答案强相关，而平坦或递增的熵往往导致错误答案。错误推理路径通常比正确路径更长，表明更长推理不一定产生更好结果。

Conclusion: 这些发现为设计高效推理流程提供了基础，可以早期检测和避免无效推理，优化语言模型的推理能力。

Abstract: Recent advancements in large language models (LLMs) often rely on generating
intermediate reasoning steps to enhance accuracy. However, little work has
examined how reasoning utility contributes to the final answer's correctness.
Due to the stochastic nature of autoregressive generation, generating more
context does not guarantee increased confidence in the answer. If we could
predict, during generation, whether a reasoning step will be useful, we could
stop early or prune ineffective steps, avoiding distractions in the final
decision.
  We present an oracle study on MATH dataset, using Qwen2.5-32B and GPT-4o to
generate reasoning chains, and then employing a separate model (Qwen3-8B) to
quantify the utility of these chains for final accuracy. Specifically, we
measure the model's uncertainty on the answer span Y at each reasoning step
using conditional entropy (expected negative log-likelihood over the
vocabulary) with context expanding step by step. Our results show a clear
pattern: conditional entropy that decreases over steps is strongly associated
with correct answers, whereas flat or increasing entropy often results in wrong
answers. We also corroborate that incorrect reasoning paths tend to be longer
than correct ones, suggesting that longer reasoning does not necessarily yield
better outcomes. These findings serve as a foundation to inspire future work on
designing efficient reasoning pipelines that detect and avoid unproductive
reasoning early.

</details>


### [10] [UI-Bench: A Benchmark for Evaluating Design Capabilities of AI Text-to-App Tools](https://arxiv.org/abs/2508.20410)
*Sam Jung,Agustin Garcinuno,Spencer Mateega*

Main category: cs.CL

TL;DR: UI-Bench是首个大规模评估AI文本转应用工具视觉质量的基准测试，通过专家两两比较对10个工具进行排名，包含300个生成网站和4000+专家判断。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏公开基准来严格验证AI文本转应用工具声称的高质量应用和网站生成能力，需要建立可复现的标准来推动AI驱动的网页设计发展。

Method: 采用专家两两比较方法，评估10个工具在30个提示词下生成的300个网站，使用基于TrueSkill的模型进行系统排名，并提供校准的置信区间。

Result: 建立了首个大规模AI文本转应用工具视觉质量基准测试，发布了完整的提示词集、开源评估框架和公开排行榜。

Conclusion: UI-Bench为AI驱动的网页设计领域提供了可复现的评估标准，推动了该领域的发展，相关生成网站数据即将发布。

Abstract: AI text-to-app tools promise high quality applications and websites in
minutes, yet no public benchmark rigorously verifies those claims. We introduce
UI-Bench, the first large-scale benchmark that evaluates visual excellence
across competing AI text-to-app tools through expert pairwise comparison.
Spanning 10 tools, 30 prompts, 300 generated sites, and 4,000+ expert
judgments, UI-Bench ranks systems with a TrueSkill-derived model that yields
calibrated confidence intervals. UI-Bench establishes a reproducible standard
for advancing AI-driven web design. We release (i) the complete prompt set,
(ii) an open-source evaluation framework, and (iii) a public leaderboard. The
generated sites rated by participants will be released soon. View the UI-Bench
leaderboard at https://uibench.ai/leaderboard.

</details>


### [11] [DentalBench: Benchmarking and Advancing LLMs Capability for Bilingual Dentistry Understanding](https://arxiv.org/abs/2508.20416)
*Hengchuan Zhu,Yihuan Xu,Yichen Li,Zijie Meng,Zuozhu Liu*

Main category: cs.CL

TL;DR: DentalBench是首个针对牙科领域的双语基准测试，包含问答数据集和语料库，评估显示现有LLMs在牙科专业领域存在显著性能差距，领域适应能显著提升模型表现。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在通用医学基准上表现良好，但在需要深度专业知识的牙科等专业医学领域缺乏针对性评估资源，能力未被充分探索。

Method: 构建DentalBench基准：1）DentalQA：36,597个中英文问答问题，覆盖4个任务和16个牙科子领域；2）DentalCorpus：3.37亿token的高质量牙科语料库，支持监督微调和检索增强生成。评估了14个LLMs，并进行领域适应实验。

Result: 评估显示不同模型在任务类型和语言上存在显著性能差距。领域适应实验（使用Qwen-2.5-3B）表明，特别是在知识密集和术语集中的任务上，性能得到大幅提升。

Conclusion: 领域特定基准对于开发可信赖且有效的医疗应用LLMs至关重要，牙科领域的专业化评估和适应能显著改善模型在专业医疗任务上的表现。

Abstract: Recent advances in large language models (LLMs) and medical LLMs (Med-LLMs)
have demonstrated strong performance on general medical benchmarks. However,
their capabilities in specialized medical fields, such as dentistry which
require deeper domain-specific knowledge, remain underexplored due to the lack
of targeted evaluation resources. In this paper, we introduce DentalBench, the
first comprehensive bilingual benchmark designed to evaluate and advance LLMs
in the dental domain. DentalBench consists of two main components: DentalQA, an
English-Chinese question-answering (QA) benchmark with 36,597 questions
spanning 4 tasks and 16 dental subfields; and DentalCorpus, a large-scale,
high-quality corpus with 337.35 million tokens curated for dental domain
adaptation, supporting both supervised fine-tuning (SFT) and
retrieval-augmented generation (RAG). We evaluate 14 LLMs, covering
proprietary, open-source, and medical-specific models, and reveal significant
performance gaps across task types and languages. Further experiments with
Qwen-2.5-3B demonstrate that domain adaptation substantially improves model
performance, particularly on knowledge-intensive and terminology-focused tasks,
and highlight the importance of domain-specific benchmarks for developing
trustworthy and effective LLMs tailored to healthcare applications.

</details>


### [12] [KG-CQR: Leveraging Structured Relation Representations in Knowledge Graphs for Contextual Query Retrieval](https://arxiv.org/abs/2508.20417)
*Chi Minh Bui,Ngoc Mai Thieu,Van Vinh Nguyen,Jason J. Jung,Khac-Hoai Nam Bui*

Main category: cs.CL

TL;DR: KG-CQR是一个基于知识图谱的上下文查询检索框架，通过提取和补全相关KG子图来丰富查询上下文，在RAG系统中显著提升检索性能


<details>
  <summary>Details</summary>
Motivation: 现有方法主要解决语料库级别的上下文丢失问题，但缺乏对复杂查询的结构化关系表示和语义丰富性处理，需要一种能够增强查询上下文表示的方法

Method: 提出KG-CQR框架，包含子图提取、补全和上下文生成三个模块，通过语料中心知识图谱来丰富复杂输入查询的上下文表示，是一个模型无关的管道方法

Result: 在RAGBench和MultiHop-RAG数据集上，mAP提升4-6%，Recall@25提升2-3%，在多跳问答等挑战性RAG任务中检索效果持续优于现有基线

Conclusion: KG-CQR通过知识图谱增强查询上下文表示，有效提升了RAG系统的检索性能，具有模型无关性和可扩展性优势

Abstract: The integration of knowledge graphs (KGs) with large language models (LLMs)
offers significant potential to improve the retrieval phase of
retrieval-augmented generation (RAG) systems. In this study, we propose KG-CQR,
a novel framework for Contextual Query Retrieval (CQR) that enhances the
retrieval phase by enriching the contextual representation of complex input
queries using a corpus-centric KG. Unlike existing methods that primarily
address corpus-level context loss, KG-CQR focuses on query enrichment through
structured relation representations, extracting and completing relevant KG
subgraphs to generate semantically rich query contexts. Comprising subgraph
extraction, completion, and contextual generation modules, KG-CQR operates as a
model-agnostic pipeline, ensuring scalability across LLMs of varying sizes
without additional training. Experimental results on RAGBench and MultiHop-RAG
datasets demonstrate KG-CQR's superior performance, achieving a 4-6%
improvement in mAP and a 2-3% improvement in Recall@25 over strong baseline
models. Furthermore, evaluations on challenging RAG tasks such as multi-hop
question answering show that, by incorporating KG-CQR, the performance
consistently outperforms the existing baseline in terms of retrieval
effectiveness

</details>


### [13] [CAMB: A comprehensive industrial LLM benchmark on civil aviation maintenance](https://arxiv.org/abs/2508.20420)
*Feng Zhang,Chengjie Pang,Yuehan Zhang,Chenyu Luo*

Main category: cs.CL

TL;DR: 这篇论文为民航维修领域开发了专业的评测基准，用于评估大语言模型在该领域的知识和推理能力，并为领域特定优化提供基础。


<details>
  <summary>Details</summary>
Motivation: 民航维修是知识密集型领域，但当前LLM评测主要集中在数学和编程推理任务上，缺乏专门的行业评测工具。

Method: 开发了一个工业级的民航维修基准测试集，用于评估LLM在该领域的表现，包括对知识缺口和复杂推理能力的测量。同时也评估了现有的矢量嵌入模型和RAG系统。

Result: 通过实验验证了该基准在民航维修领域评估模型性能的有效性，并开源了评测基准和代码。

Conclusion: 该研究填补了LLM评测在专业领域的空白，为民航维修领域的目标优化（如领域细调、RAG优化等）提供了基础，有助于推动更智能的民航维修解决方案的发展。

Abstract: Civil aviation maintenance is a domain characterized by stringent industry
standards. Within this field, maintenance procedures and troubleshooting
represent critical, knowledge-intensive tasks that require sophisticated
reasoning. To address the lack of specialized evaluation tools for large
language models (LLMs) in this vertical, we propose and develop an
industrial-grade benchmark specifically designed for civil aviation
maintenance. This benchmark serves a dual purpose: It provides a standardized
tool to measure LLM capabilities within civil aviation maintenance, identifying
specific gaps in domain knowledge and complex reasoning. By pinpointing these
deficiencies, the benchmark establishes a foundation for targeted improvement
efforts (e.g., domain-specific fine-tuning, RAG optimization, or specialized
prompt engineering), ultimately facilitating progress toward more intelligent
solutions within civil aviation maintenance. Our work addresses a significant
gap in the current LLM evaluation, which primarily focuses on mathematical and
coding reasoning tasks. In addition, given that Retrieval-Augmented Generation
(RAG) systems are currently the dominant solutions in practical applications ,
we leverage this benchmark to evaluate existing well-known vector embedding
models and LLMs for civil aviation maintenance scenarios. Through experimental
exploration and analysis, we demonstrate the effectiveness of our benchmark in
assessing model performance within this domain, and we open-source this
evaluation benchmark and code to foster further research and
development:https://github.com/CamBenchmark/cambenchmark

</details>


### [14] [Searching the Title of Practical Work of the Informatics Engineering Bachelor Program with the Case Base Reasoning Method](https://arxiv.org/abs/2508.20442)
*Agung Sukrisna Jaya,Osvari Arsalan,Danny Matthew Saputra*

Main category: cs.CL

TL;DR: 基于案例推理(CBR)的系统，使用TF-IDF和余弦相似度来搜索相似实践工作标题，测试显示系统在随机化标题搜索中表现良好


<details>
  <summary>Details</summary>
Motivation: 开发一个基于经验案例的搜索系统，用于查找相似实践工作标题，帮助用户快速找到相关案例

Method: 使用案例推理(CBR)方法，结合TF-IDF进行文本向量化，采用余弦相似度计算标题相似性

Result: 在705个实践工作标题的测试中，系统在两个测试阶段都成功找到相同数量的匹配标题，第二阶段获得更高的平均匹配分数

Conclusion: 该系统能够有效搜索实践工作标题，TF-IDF和余弦相似度的组合在案例检索中表现良好

Abstract: Case Base Reasoning (CBR) is a case solving technique based on experience in
cases that have occurred before with the highest similarity. CBR is used to
search for practical work titles. TF-IDF is applied to process the
vectorization of each practical work title word and Cosine Similarity for the
calculation of similarity values. This system can search either in the form of
titles or keywords. The output of the system is the title of practical work and
the match value of each title. Based on the test results using 705 practical
work titles, testing was carried out with five titles and carried out in two
stages. The first stage searches with existing titles and the second stage
randomizes the title from the first stage. And the results obtained in the
second stage are the same number of titles found and the highest average match
score.

</details>


### [15] [MCP-Bench: Benchmarking Tool-Using LLM Agents with Complex Real-World Tasks via MCP Servers](https://arxiv.org/abs/2508.20453)
*Zhenting Wang,Qi Chang,Hemani Patel,Shashank Biju,Cheng-En Wu,Quan Liu,Aolin Ding,Alireza Rezazadeh,Ankit Shah,Yujia Bao,Eugene Siow*

Main category: cs.CL

TL;DR: MCP-Bench是一个基于Model Context Protocol的基准测试，用于评估LLM在真实多步骤任务中的工具使用、跨工具协调和规划推理能力，包含28个MCP服务器和250个工具。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要依赖显式工具规范、浅层工作流程和孤立领域操作，无法充分评估LLM在模糊指令下检索工具、规划多跳执行轨迹、协调跨领域工作流等关键能力。

Method: 基于MCP协议构建基准，连接28个实时MCP服务器，涵盖金融、旅行、科学计算、学术搜索等领域，设计多步骤任务测试工具模式理解、执行轨迹规划和任务完成能力。

Result: 对20个先进LLM的实验显示，在MCP-Bench上仍存在持续挑战，表明当前模型在真实工具使用场景中的能力仍有局限。

Conclusion: MCP-Bench提供了一个更真实的评估框架，揭示了LLM在复杂工具使用和跨域协调方面的不足，为未来模型开发提供了重要基准。

Abstract: We introduce MCP-Bench, a benchmark for evaluating large language models
(LLMs) on realistic, multi-step tasks that demand tool use, cross-tool
coordination, precise parameter control, and planning/reasoning for solving
tasks. Built on the Model Context Protocol (MCP), MCP-Bench connects LLMs to 28
representative live MCP servers spanning 250 tools across domains such as
finance, traveling, scientific computing, and academic search. Unlike prior
API-based benchmarks, each MCP server provides a set of complementary tools
designed to work together, enabling the construction of authentic, multi-step
tasks with rich input-output coupling. Tasks in MCP-Bench test agents' ability
to retrieve relevant tools from fuzzy instructions without explicit tool names,
plan multi-hop execution trajectories for complex objectives, ground responses
in intermediate tool outputs, and orchestrate cross-domain workflows -
capabilities not adequately evaluated by existing benchmarks that rely on
explicit tool specifications, shallow few-step workflows, and isolated domain
operations. We propose a multi-faceted evaluation framework covering tool-level
schema understanding and usage, trajectory-level planning, and task completion.
Experiments on 20 advanced LLMs reveal persistent challenges in MCP-Bench. Code
and data: https://github.com/Accenture/mcp-bench.

</details>


### [16] [Prediction of mortality and resource utilization in critical care: a deep learning approach using multimodal electronic health records with natural language processing techniques](https://arxiv.org/abs/2508.20460)
*Yucheng Ruan,Xiang Lan,Daniel J. Tan,Hairil Rizal Abdullah,Mengling Feng*

Main category: cs.CL

TL;DR: 提出了一种基于深度学习和自然语言处理的多模态电子健康记录分析框架，用于预测ICU患者的死亡率和资源使用情况，在多个临床任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注结构化电子健康记录，忽略了自由文本临床记录中的宝贵信息，且未充分利用结构化数据中的文本信息潜力。

Method: 使用两个真实世界EHR数据集，开发并评估了包含医疗提示、自由文本和预训练句子编码器的深度学习框架，并测试了模型对结构化数据损坏的鲁棒性。

Result: 在三个临床任务上表现优异：死亡率预测BACC/AUROC提升1.6%/0.8%，住院时长预测RMSE/MAE提升0.5%/2.2%，手术时长估计RMSE/MAE提升10.9%/11.0%，且在不同数据损坏率下均保持优越性能。

Conclusion: 该框架是预测重症监护中死亡率和资源使用的有效准确方法，展示了使用提示学习和Transformer编码器分析多模态EHR的成功，并对结构化数据损坏表现出强韧性。

Abstract: Background Predicting mortality and resource utilization from electronic
health records (EHRs) is challenging yet crucial for optimizing patient
outcomes and managing costs in intensive care unit (ICU). Existing approaches
predominantly focus on structured EHRs, often ignoring the valuable clinical
insights in free-text notes. Additionally, the potential of textual information
within structured data is not fully leveraged. This study aimed to introduce
and assess a deep learning framework using natural language processing
techniques that integrates multimodal EHRs to predict mortality and resource
utilization in critical care settings. Methods Utilizing two real-world EHR
datasets, we developed and evaluated our model on three clinical tasks with
leading existing methods. We also performed an ablation study on three key
components in our framework: medical prompts, free-texts, and pre-trained
sentence encoder. Furthermore, we assessed the model's robustness against the
corruption in structured EHRs. Results Our experiments on two real-world
datasets across three clinical tasks showed that our proposed model improved
performance metrics by 1.6\%/0.8\% on BACC/AUROC for mortality prediction,
0.5%/2.2% on RMSE/MAE for LOS prediction, 10.9%/11.0% on RMSE/MAE for surgical
duration estimation compared to the best existing methods. It consistently
demonstrated superior performance compared to other baselines across three
tasks at different corruption rates. Conclusions The proposed framework is an
effective and accurate deep learning approach for predicting mortality and
resource utilization in critical care. The study also highlights the success of
using prompt learning with a transformer encoder in analyzing multimodal EHRs.
Importantly, the model showed strong resilience to data corruption within
structured data, especially at high corruption levels.

</details>


### [17] [ConspirED: A Dataset for Cognitive Traits of Conspiracy Theories and Large Language Model Safety](https://arxiv.org/abs/2508.20468)
*Luke Bates,Max Glockner,Preslav Nakov,Iryna Gurevych*

Main category: cs.CL

TL;DR: ConspirED数据集：首个基于认知框架标注的阴谋论内容数据集，用于分析阴谋论修辞模式、开发检测模型，并评估大语言模型对阴谋论内容的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 阴谋论侵蚀公众对科学和机构的信任，且能通过演化和吸收反证来抵抗辟谣。随着AI生成虚假信息日益复杂，理解阴谋论内容的修辞模式对于开发干预措施（如定向预辟谣）和评估AI漏洞至关重要。

Method: 引入ConspirED数据集，基于CONSPIR认知框架标注在线阴谋论文章的多句摘录（80-120词）。使用该数据集开发计算模型识别阴谋论特征，并评估大语言/推理模型对阴谋论输入的鲁棒性。

Result: 发现大语言模型和推理模型都会受到阴谋论内容的影响，产生反映输入推理模式的输出，即使在成功抵制类似经过事实核查的虚假信息时也是如此。

Conclusion: ConspirED为研究阴谋论认知特征提供了重要工具，揭示了当前AI模型在应对阴谋论内容时的脆弱性，强调了需要开发更鲁棒的干预和检测机制。

Abstract: Conspiracy theories erode public trust in science and institutions while
resisting debunking by evolving and absorbing counter-evidence. As AI-generated
misinformation becomes increasingly sophisticated, understanding rhetorical
patterns in conspiratorial content is important for developing interventions
such as targeted prebunking and assessing AI vulnerabilities. We introduce
ConspirED (CONSPIR Evaluation Dataset), which captures the cognitive traits of
conspiratorial ideation in multi-sentence excerpts (80--120 words) from online
conspiracy articles, annotated using the CONSPIR cognitive framework
(Lewandowsky and Cook, 2020). ConspirED is the first dataset of conspiratorial
content annotated for general cognitive traits. Using ConspirED, we (i) develop
computational models that identify conspiratorial traits and determine dominant
traits in text excerpts, and (ii) evaluate large language/reasoning model
(LLM/LRM) robustness to conspiratorial inputs. We find that both are misaligned
by conspiratorial content, producing output that mirrors input reasoning
patterns, even when successfully deflecting comparable fact-checked
misinformation.

</details>


### [18] [Languages Still Left Behind: Toward a Better Multilingual Machine Translation Benchmark](https://arxiv.org/abs/2508.20511)
*Chihiro Taguchi,Seng Mai,Keita Kurabe,Yusuke Sakai,Georgina Agyei,Soudabeh Eslami,David Chiang*

Main category: cs.CL

TL;DR: FLORES+多语言机器翻译基准在四个语言（Asante Twi、日语、Jinghpaw和南阿塞拜疆语）中存在质量问题，翻译质量低于声称的90%标准，存在领域特定性和文化偏见问题，简单启发式方法就能获得不错的BLEU分数，表明评估协议存在漏洞。


<details>
  <summary>Details</summary>
Motivation: 研究FLORES+多语言机器翻译基准的适用性，发现其在真正多语言评估方面存在关键缺陷，需要更准确的评估标准来反映真实世界的翻译挑战。

Method: 通过人工评估四个语言（Asante Twi、日语、Jinghpaw和南阿塞拜疆语）的翻译质量，分析源句子的领域特定性和文化偏见，测试简单启发式方法（如复制命名实体）对BLEU分数的影响，比较在不同数据集上训练的MT模型性能。

Result: 发现许多翻译质量低于声称的90%标准，源句子过于领域特定且偏向英语世界文化，简单启发式方法能获得非平凡的BLEU分数，高质量自然数据训练的MT模型在FLORES+上表现差但在领域相关评估集上表现好。

Conclusion: 呼吁使用领域通用和文化中立的源文本、减少对命名实体依赖的多语言MT基准，以更好地反映真实翻译挑战。

Abstract: Multilingual machine translation (MT) benchmarks play a central role in
evaluating the capabilities of modern MT systems. Among them, the FLORES+
benchmark is widely used, offering English-to-many translation data for over
200 languages, curated with strict quality control protocols. However, we study
data in four languages (Asante Twi, Japanese, Jinghpaw, and South Azerbaijani)
and uncover critical shortcomings in the benchmark's suitability for truly
multilingual evaluation. Human assessments reveal that many translations fall
below the claimed 90% quality standard, and the annotators report that source
sentences are often too domain-specific and culturally biased toward the
English-speaking world. We further demonstrate that simple heuristics, such as
copying named entities, can yield non-trivial BLEU scores, suggesting
vulnerabilities in the evaluation protocol. Notably, we show that MT models
trained on high-quality, naturalistic data perform poorly on FLORES+ while
achieving significant gains on our domain-relevant evaluation set. Based on
these findings, we advocate for multilingual MT benchmarks that use
domain-general and culturally neutral source texts rely less on named entities,
in order to better reflect real-world translation challenges.

</details>


### [19] [SciTopic: Enhancing Topic Discovery in Scientific Literature through Advanced LLM](https://arxiv.org/abs/2508.20514)
*Pengjiang Li,Zaitian Wang,Xinhao Zhang,Ran Zhang,Lu Jiang,Pengfei Wang,Yuanchun Zhou*

Main category: cs.CL

TL;DR: SciTopic是一种基于大语言模型增强的科学文献主题发现方法，通过构建文本编码器和空间优化模块，结合基于熵的采样和三元组任务，显著提升了科学主题识别的性能。


<details>
  <summary>Details</summary>
Motivation: 现有主题发现方法主要依赖词嵌入技术，缺乏对科学文献的全面理解，难以处理复杂的高维文本关系。大语言模型在文本理解方面的卓越能力为解决这一问题提供了新的可能性。

Method: 1) 构建文本编码器捕获科学文献内容（元数据、标题、摘要）；2) 构建空间优化模块，集成基于熵的采样和LLM指导的三元组任务；3) 基于LLM指导微调文本编码器，通过优化三元组对比损失使编码器更好区分不同主题的实例。

Result: 在三个真实世界科学文献数据集上的实验表明，SciTopic在科学主题发现方面优于最先进的方法，使研究人员能够获得更深入、更快速的洞察。

Conclusion: SciTopic通过利用大语言模型的文本理解能力，有效解决了传统主题发现方法的局限性，为科学文献分析提供了更强大的工具，有助于研究人员识别新兴趋势和探索新的研究方向。

Abstract: Topic discovery in scientific literature provides valuable insights for
researchers to identify emerging trends and explore new avenues for
investigation, facilitating easier scientific information retrieval. Many
machine learning methods, particularly deep embedding techniques, have been
applied to discover research topics. However, most existing topic discovery
methods rely on word embedding to capture the semantics and lack a
comprehensive understanding of scientific publications, struggling with
complex, high-dimensional text relationships. Inspired by the exceptional
comprehension of textual information by large language models (LLMs), we
propose an advanced topic discovery method enhanced by LLMs to improve
scientific topic identification, namely SciTopic. Specifically, we first build
a textual encoder to capture the content from scientific publications,
including metadata, title, and abstract. Next, we construct a space
optimization module that integrates entropy-based sampling and triplet tasks
guided by LLMs, enhancing the focus on thematic relevance and contextual
intricacies between ambiguous instances. Then, we propose to fine-tune the
textual encoder based on the guidance from the LLMs by optimizing the
contrastive loss of the triplets, forcing the text encoder to better
discriminate instances of different topics. Finally, extensive experiments
conducted on three real-world datasets of scientific publications demonstrate
that SciTopic outperforms the state-of-the-art (SOTA) scientific topic
discovery methods, enabling researchers to gain deeper and faster insights.

</details>


### [20] [Overview of BioASQ 2024: The twelfth BioASQ challenge on Large-Scale Biomedical Semantic Indexing and Question Answering](https://arxiv.org/abs/2508.20532)
*Anastasios Nentidis,Georgios Katsimpras,Anastasia Krithara,Salvador Lima-López,Eulàlia Farré-Maduell,Martin Krallinger,Natalia Loukachevitch,Vera Davydova,Elena Tutubalina,Georgios Paliouras*

Main category: cs.CL

TL;DR: BioASQ 2024挑战赛概述，包含两个传统任务和两个新任务，37个团队参与，提交超过700次，系统性能持续提升


<details>
  <summary>Details</summary>
Motivation: 促进大规模生物医学语义索引和问答系统的进步，通过国际挑战赛推动该领域的发展

Method: 设立四个共享任务：两个传统任务（b和Synergy）和两个新任务（MultiCardioNER多语言临床实体检测和BIONNE嵌套命名实体识别）

Result: 37个竞争团队参与，提交超过700次，大多数系统达到竞争性性能水平

Conclusion: BioASQ挑战赛持续推动生物医学自然语言处理领域的state-of-the-art技术进步

Abstract: This is an overview of the twelfth edition of the BioASQ challenge in the
context of the Conference and Labs of the Evaluation Forum (CLEF) 2024. BioASQ
is a series of international challenges promoting advances in large-scale
biomedical semantic indexing and question answering. This year, BioASQ
consisted of new editions of the two established tasks b and Synergy, and two
new tasks: a) MultiCardioNER on the adaptation of clinical entity detection to
the cardiology domain in a multilingual setting, and b) BIONNE on nested NER in
Russian and English. In this edition of BioASQ, 37 competing teams participated
with more than 700 distinct submissions in total for the four different shared
tasks of the challenge. Similarly to previous editions, most of the
participating systems achieved competitive performance, suggesting the
continuous advancement of the state-of-the-art in the field.

</details>


### [21] [Overview of BioASQ 2025: The Thirteenth BioASQ Challenge on Large-Scale Biomedical Semantic Indexing and Question Answering](https://arxiv.org/abs/2508.20554)
*Anastasios Nentidis,Georgios Katsimpras,Anastasia Krithara,Martin Krallinger,Miguel Rodríguez-Ortega,Eduard Rodriguez-López,Natalia Loukachevitch,Andrey Sakhovskiy,Elena Tutubalina,Dimitris Dimitriadis,Grigorios Tsoumakas,George Giannakoulas,Alexandra Bekiaridou,Athanasios Samaras,Giorgio Maria Di Nunzio,Nicola Ferro,Stefano Marchesin,Marco Martinelli,Gianmaria Silvello,Georgios Paliouras*

Main category: cs.CL

TL;DR: BioASQ 2025挑战赛概述，包含两个传统任务和四个新任务，涉及生物医学语义索引、问答、多语言临床摘要、命名实体链接、临床编码和信息提取等领域，共有83个团队参与。


<details>
  <summary>Details</summary>
Motivation: 促进大规模生物医学语义索引和问答技术的进步，通过挑战赛形式推动该领域的前沿发展。

Method: 设立六个共享任务：两个传统任务（b和Synergy）和四个新任务（多语言临床摘要、嵌套命名实体链接、心脏病学临床编码、肠脑相互作用信息提取），邀请研究团队参与并提交解决方案。

Result: 83个竞争团队参与，提交了超过1000份不同的解决方案，多个系统表现出有竞争力的性能。

Conclusion: BioASQ挑战赛持续推动着生物医学信息处理领域的技术进步，参与系统的竞争性表现表明该领域的最新技术在不断发展和完善。

Abstract: This is an overview of the thirteenth edition of the BioASQ challenge in the
context of the Conference and Labs of the Evaluation Forum (CLEF) 2025. BioASQ
is a series of international challenges promoting advances in large-scale
biomedical semantic indexing and question answering. This year, BioASQ
consisted of new editions of the two established tasks, b and Synergy, and four
new tasks: a) Task MultiClinSum on multilingual clinical summarization. b) Task
BioNNE-L on nested named entity linking in Russian and English. c) Task
ELCardioCC on clinical coding in cardiology. d) Task GutBrainIE on gut-brain
interplay information extraction. In this edition of BioASQ, 83 competing teams
participated with more than 1000 distinct submissions in total for the six
different shared tasks of the challenge. Similar to previous editions, several
participating systems achieved competitive performance, indicating the
continuous advancement of the state-of-the-art in the field.

</details>


### [22] [Adaptive Federated Distillation for Multi-Domain Non-IID Textual Data](https://arxiv.org/abs/2508.20557)
*Jiahao Xiao,Jiangming Liu*

Main category: cs.CL

TL;DR: 本文提出了一个针对多领域非IID数据的自适应联邦蒸馏框架(AdaFD)，并建立了包含语言领域多样性的综合基准测试框架。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦蒸馏研究主要关注标签多样性，忽略了语言领域(input)多样性这一NLP中的关键因素，无法真实反映现实环境中的非IID数据挑战。

Method: 提出自适应联邦蒸馏(AdaFD)框架，包含多领域非IID场景的统一基准测试，支持同构和异构设置下的模型训练。

Result: 实验结果表明，该模型能够有效捕捉本地客户端的多样性，在性能上优于现有方法。

Conclusion: 该研究为联邦学习在多领域非IID环境中的评估提供了标准化基准，AdaFD框架在处理语言领域多样性方面表现出色。

Abstract: The widespread success of pre-trained language models has established a new
training paradigm, where a global PLM is fine-tuned using task-specific data
from local clients. The local data are highly different from each other and can
not capture the global distribution of the whole data in real world. To address
the challenges of non-IID data in real environments, privacy-preserving
federated distillation has been proposed and highly investigated. However,
previous experimental non-IID scenarios are primarily identified with the label
(output) diversity, without considering the diversity of language domains
(input) that is crucial in natural language processing. In this paper, we
introduce a comprehensive set of multi-domain non-IID scenarios and propose a
unified benchmarking framework that includes diverse data. The benchmark can be
used to evaluate the federated learning framework in a real environment. To
this end, we propose an Adaptive Federated Distillation (AdaFD) framework
designed to address multi-domain non-IID challenges in both homogeneous and
heterogeneous settings. Experimental results demonstrate that our models
capture the diversity of local clients and achieve better performance compared
to the existing works. The code for this paper is available at:
https://github.com/jiahaoxiao1228/AdaFD.

</details>


### [23] [Leveraging Generative Models for Real-Time Query-Driven Text Summarization in Large-Scale Web Search](https://arxiv.org/abs/2508.20559)
*Zeyu Xiong,Yixuan Nan,Li Gao,Hengzhu Tang,Shuaiqiang Wang,Junfeng Wang,Dawei Yin*

Main category: cs.CL

TL;DR: 本文提出了一种基于生成式模型的查询驱动文本摘要方法，通过大模型萌化、监督微调、偏好优化等技术，在低计算开销下实现了高效的实时摘要生成。


<details>
  <summary>Details</summary>
Motivation: 解决传统提取式摘要模型在工业应用中的两大问题：多阶段流水线导致的信息损失，以及缺乏对查询和文档的深度语义理解。

Method: 整合大模型萌化、监督微调、直接偏好优化和lookahead解码技术，将仅有0.1B参数的轻量模型训练成领域专业的QDTS专家。

Result: 在多个工业相关指标上超越了生产环境基准线，创造了新的最高水平，并在部署效率上仅需要334个NVIDIA L20 GPU即可处理每秒约50,000个查询，平均延迟仅55ms。

Conclusion: 该研究成功将生成式模型应用于工业级实时查询驱动文本摘要，在保持高效能的同时实现了优异的摘要质量，为大规模网络搜索应用提供了可行的解决方案。

Abstract: In the dynamic landscape of large-scale web search, Query-Driven Text
Summarization (QDTS) aims to generate concise and informative summaries from
textual documents based on a given query, which is essential for improving user
engagement and facilitating rapid decision-making. Traditional extractive
summarization models, based primarily on ranking candidate summary segments,
have been the dominant approach in industrial applications. However, these
approaches suffer from two key limitations: 1) The multi-stage pipeline often
introduces cumulative information loss and architectural bottlenecks due to its
weakest component; 2) Traditional models lack sufficient semantic understanding
of both user queries and documents, particularly when dealing with complex
search intents. In this study, we propose a novel framework to pioneer the
application of generative models to address real-time QDTS in industrial web
search. Our approach integrates large model distillation, supervised
fine-tuning, direct preference optimization, and lookahead decoding to
transform a lightweight model with only 0.1B parameters into a
domain-specialized QDTS expert. Evaluated on multiple industry-relevant
metrics, our model outperforms the production baseline and achieves a new state
of the art. Furthermore, it demonstrates excellent deployment efficiency,
requiring only 334 NVIDIA L20 GPUs to handle \textasciitilde50,000 queries per
second under 55~ms average latency per query.

</details>


### [24] [KCS: Diversify Multi-hop Question Generation with Knowledge Composition Sampling](https://arxiv.org/abs/2508.20567)
*Yangfan Wang,Jie Liu,Chen Tang,Lian Yan,Jingchi Jiang*

Main category: cs.CL

TL;DR: KCS框架通过知识组合采样增强多跳问答数据多样性，提高知识组合选择准确率3.9%，在HotpotQA和2WikiMultihopQA数据集上取得提升


<details>
  <summary>Details</summary>
Motivation: 解决多跳问答中数据稀疏性问题，避免语言模型学习虚假模式，现有方法忽视关键知识整合

Method: 知识组合采样框架，将知识组合选择建模为句子级条件预测任务，使用概率对比损失预测相关知识，推理时采用随机解码策略

Result: 知识组合选择准确率提升3.9%，在HotpotQA和2WikiMultihopQA数据集上实现改进

Conclusion: KCS能有效提升多跳问答的数据多样性和模型性能，通过更好的知识整合解决数据稀疏问题

Abstract: Multi-hop question answering faces substantial challenges due to data
sparsity, which increases the likelihood of language models learning spurious
patterns. To address this issue, prior research has focused on diversifying
question generation through content planning and varied expression. However,
these approaches often emphasize generating simple questions and neglect the
integration of essential knowledge, such as relevant sentences within
documents. This paper introduces the Knowledge Composition Sampling (KCS), an
innovative framework designed to expand the diversity of generated multi-hop
questions by sampling varied knowledge compositions within a given context. KCS
models the knowledge composition selection as a sentence-level conditional
prediction task and utilizes a probabilistic contrastive loss to predict the
next most relevant piece of knowledge. During inference, we employ a stochastic
decoding strategy to effectively balance accuracy and diversity. Compared to
competitive baselines, our KCS improves the overall accuracy of knowledge
composition selection by 3.9%, and its application for data augmentation yields
improvements on HotpotQA and 2WikiMultihopQA datasets. Our code is available
at: https://github.com/yangfanww/kcs.

</details>


### [25] [A Graph Talks, But Who's Listening? Rethinking Evaluations for Graph-Language Models](https://arxiv.org/abs/2508.20583)
*Soham Petkar,Hari Aakash K,Anirudh Vempati,Akshit Sinha,Ponnurangam Kumarauguru,Chirag Agarwal*

Main category: cs.CL

TL;DR: 当前图语言模型的评估基准存在缺陷，无法真正评估多模态推理能力。作者提出了新的CLEGR基准来测试图结构和语言的联合推理，发现现有GLM方法在结构推理方面表现不佳。


<details>
  <summary>Details</summary>
Motivation: 现有的图语言模型评估基准主要基于节点分类数据集，这些基准无法有效评估多模态推理能力，因为仅使用单模态信息就能在这些基准上取得良好表现。

Method: 提出了CLEGR（组合式语言-图推理）基准，采用合成图生成流程配合需要结构和文本语义联合推理的问题。对代表性GLM架构进行了全面评估，并与软提示LLM基线进行比较。

Result: 软提示的LLM基线表现与包含完整GNN骨干的GLM相当，表明在现有基准上整合图结构到LLM中的架构必要性存疑。GLM在需要结构推理的任务中表现出显著性能下降。

Conclusion: 当前GLM在图推理能力方面存在局限，CLEGR基准为推进图结构与语言的多模态推理研究提供了基础，揭示了需要更有效的架构来真正整合图结构信息。

Abstract: Developments in Graph-Language Models (GLMs) aim to integrate the structural
reasoning capabilities of Graph Neural Networks (GNNs) with the semantic
understanding of Large Language Models (LLMs). However, we demonstrate that
current evaluation benchmarks for GLMs, which are primarily repurposed
node-level classification datasets, are insufficient to assess multimodal
reasoning. Our analysis reveals that strong performance on these benchmarks is
achievable using unimodal information alone, suggesting that they do not
necessitate graph-language integration. To address this evaluation gap, we
introduce the CLEGR(Compositional Language-Graph Reasoning) benchmark, designed
to evaluate multimodal reasoning at various complexity levels. Our benchmark
employs a synthetic graph generation pipeline paired with questions that
require joint reasoning over structure and textual semantics. We perform a
thorough evaluation of representative GLM architectures and find that
soft-prompted LLM baselines perform on par with GLMs that incorporate a full
GNN backbone. This result calls into question the architectural necessity of
incorporating graph structure into LLMs. We further show that GLMs exhibit
significant performance degradation in tasks that require structural reasoning.
These findings highlight limitations in the graph reasoning capabilities of
current GLMs and provide a foundation for advancing the community toward
explicit multimodal reasoning involving graph structure and language.

</details>


### [26] [Generative Annotation for ASR Named Entity Correction](https://arxiv.org/abs/2508.20700)
*Yuanchang Luo,Daimeng Wei,Shaojun Li,Hengchao Shang,Jiaxin Guo,Zongyao Li,Zhanglin Wu,Xiaoyu Chen,Zhiqiang Rao,Jinlong Yang,Hao Yang*

Main category: cs.CL

TL;DR: 这篇论文提出了一种利用语音声音特征来编辑识别域特定实体的新方法，解决了当错误转写词语和真实实体形式差异较大时传统方法失效的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的实体编辑模型主要依靠语音级别编辑距离算法，当错误转写词和真实实体形式差异较大时无法准确定位错误位置，导致下游任务出现恶性错误。

Method: 提出一种新的实体编辑方法，利用语音声音特征来检索候选实体，然后设计生成式方法来标注ASR转写文本中的实体错误并替换为正确实体。

Result: 在开源和自构测试集上进行测试，结果显示该NEC方法能够带来显著的实体准确性提升，尤其在词形差异场景下效果明显。

Conclusion: 该方法有效解决了当错误转写词和真实实体形式差异较大时的实体编辑问题，为ASR系统的域特定实体识别提供了有效解决方案。

Abstract: End-to-end automatic speech recognition systems often fail to transcribe
domain-specific named entities, causing catastrophic failures in downstream
tasks. Numerous fast and lightweight named entity correction (NEC) models have
been proposed in recent years. These models, mainly leveraging phonetic-level
edit distance algorithms, have shown impressive performances. However, when the
forms of the wrongly-transcribed words(s) and the ground-truth entity are
significantly different, these methods often fail to locate the wrongly
transcribed words in hypothesis, thus limiting their usage. We propose a novel
NEC method that utilizes speech sound features to retrieve candidate entities.
With speech sound features and candidate entities, we inovatively design a
generative method to annotate entity errors in ASR transcripts and replace the
text with correct entities. This method is effective in scenarios of word form
difference. We test our method using open-source and self-constructed test
sets. The results demonstrate that our NEC method can bring significant
improvement to entity accuracy. We will open source our self-constructed test
set and training data.

</details>


### [27] [Multi-Lingual Implicit Discourse Relation Recognition with Multi-Label Hierarchical Learning](https://arxiv.org/abs/2508.20712)
*Nelson Filipe Costa,Leila Kosseim*

Main category: cs.CL

TL;DR: 本文提出了首个多语言多标签隐式篇章关系识别模型HArch，在DiscoGeM 2.0语料上验证了其有效性，通过层次化建模实现了SOTA性能，并证明微调模型优于GPT-4o等LLM的少样本提示方法。


<details>
  <summary>Details</summary>
Motivation: 现有的隐式篇章关系识别研究主要集中在单语言和单标签设置，缺乏对多语言和多标签场景的系统性探索，需要开发能够同时处理多种语言和层次化篇章关系的模型。

Method: 提出HArch模型，利用篇章意义的层次化依赖关系，在PDTB 3.0框架的三个意义层次上预测概率分布。比较了多种预训练编码器主干，包括RoBERTa和XLM-RoBERTa，并与GPT-4o和Llama-4-Maverick进行少样本提示对比。

Result: RoBERTa-HArch在英语上表现最佳，XLM-RoBERTa-HArch在多语言设置中表现最优。微调模型在所有语言配置中都 consistently 优于大型语言模型的少样本提示方法。在DiscoGeM 1.0语料上取得了SOTA结果。

Conclusion: 层次化方法在隐式篇章关系识别中非常有效，任务特定的微调相比提示方法具有明显优势，为多语言多标签篇章分析提供了新的解决方案。

Abstract: This paper introduces the first multi-lingual and multi-label classification
model for implicit discourse relation recognition (IDRR). Our model, HArch, is
evaluated on the recently released DiscoGeM 2.0 corpus and leverages
hierarchical dependencies between discourse senses to predict probability
distributions across all three sense levels in the PDTB 3.0 framework. We
compare several pre-trained encoder backbones and find that RoBERTa-HArch
achieves the best performance in English, while XLM-RoBERTa-HArch performs best
in the multi-lingual setting. In addition, we compare our fine-tuned models
against GPT-4o and Llama-4-Maverick using few-shot prompting across all
language configurations. Our results show that our fine-tuned models
consistently outperform these LLMs, highlighting the advantages of
task-specific fine-tuning over prompting in IDRR. Finally, we report SOTA
results on the DiscoGeM 1.0 corpus, further validating the effectiveness of our
hierarchical approach.

</details>


### [28] [Addressing Tokenization Inconsistency in Steganography and Watermarking Based on Large Language Models](https://arxiv.org/abs/2508.20718)
*Ruiyi Yan,Yugo Murawaki*

Main category: cs.CL

TL;DR: 本文研究了大语言模型中的分词不一致性问题，提出了针对隐写术和水印技术的两种解决方案，显著提升了文本质量和系统稳健性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在提升文本隐写术质量的同时，也强调了水印技术作为防止恶意滥用的重要性。分词不一致性会影响系统的稳健性，需要解决。

Method: 发现导致分词不一致的问题token具有频率低和临时性两大特征，基于此提出了两种方法：隐写术中的步骤验证法和水印技术中的事后回滚法。

Result: 实验结果显示：(1)在隐写术中，直接解决分词不一致性比传统消除歧义方法在流畅性、难以察觉性和反隐写分析能力方面都有提升；(2)在水印技术中，解决分词不一致性能够提高检测能力和对拒绝服务攻击的稳健性。

Conclusion: 通过针对性地解决分词不一致性问题，能够有效提升大语言模型在隐写术和水印技术中的性能表现，为文本生成安全保障提供了重要技术支持。

Abstract: Large language models have significantly enhanced the capacities and
efficiency of text generation. On the one hand, they have improved the quality
of text-based steganography. On the other hand, they have also underscored the
importance of watermarking as a safeguard against malicious misuse. In this
study, we focus on tokenization inconsistency (TI) between Alice and Bob in
steganography and watermarking, where TI can undermine robustness. Our
investigation reveals that the problematic tokens responsible for TI exhibit
two key characteristics: infrequency and temporariness. Based on these
findings, we propose two tailored solutions for TI elimination: a stepwise
verification method for steganography and a post-hoc rollback method for
watermarking. Experiments show that (1) compared to traditional disambiguation
methods in steganography, directly addressing TI leads to improvements in
fluency, imperceptibility, and anti-steganalysis capacity; (2) for
watermarking, addressing TI enhances detectability and robustness against
attacks.

</details>


### [29] [rStar2-Agent: Agentic Reasoning Technical Report](https://arxiv.org/abs/2508.20722)
*Ning Shang,Yifei Liu,Yi Zhu,Li Lyna Zhang,Weijiang Xu,Xinyu Guan,Buze Zhang,Bingcheng Dong,Xudong Zhou,Bowen Zhang,Ying Xin,Ziming Miao,Scarlett Li,Fan Yang,Mao Yang*

Main category: cs.CL

TL;DR: rStar2-Agent是一个14B参数的数学推理模型，通过智能体强化学习实现前沿性能，在AIME24和AIME25上分别达到80.6%和69.8%的pass@1分数，超越DeepSeek-R1(671B)且响应更短。


<details>
  <summary>Details</summary>
Motivation: 当前长链思维(CoT)方法存在局限性，需要开发具备高级认知行为的模型，能够自主探索、验证和优化复杂问题解决中的中间步骤。

Method: 采用智能体强化学习方法，包含三个关键创新：(1)高效的RL基础设施和可靠的Python代码环境；(2)GRPO-RoC算法处理代码工具的环境噪声；(3)从非推理SFT开始的多阶段RL训练配方。

Result: 在仅510个RL步骤和一周训练时间内，将预训练的14B模型提升到最先进水平，在数学推理任务上表现优异，同时在对齐、科学推理和工具使用任务上展现强泛化能力。

Conclusion: rStar2-Agent证明了智能体强化学习在有限计算资源下训练高性能推理模型的有效性，为开发具备高级认知能力的AI系统提供了可行路径。

Abstract: We introduce rStar2-Agent, a 14B math reasoning model trained with agentic
reinforcement learning to achieve frontier-level performance. Beyond current
long CoT, the model demonstrates advanced cognitive behaviors, such as thinking
carefully before using Python coding tools and reflecting on code execution
feedback to autonomously explore, verify, and refine intermediate steps in
complex problem-solving. This capability is enabled through three key
innovations that makes agentic RL effective at scale: (i) an efficient RL
infrastructure with a reliable Python code environment that supports
high-throughput execution and mitigates the high rollout costs, enabling
training on limited GPU resources (64 MI300X GPUs); (ii) GRPO-RoC, an agentic
RL algorithm with a Resample-on-Correct rollout strategy that addresses the
inherent environment noises from coding tools, allowing the model to reason
more effectively in a code environment; (iii) An efficient agent training
recipe that starts with non-reasoning SFT and progresses through multi-RL
stages, yielding advanced cognitive abilities with minimal compute cost. To
this end, rStar2-Agent boosts a pre-trained 14B model to state of the art in
only 510 RL steps within one week, achieving average pass@1 scores of 80.6% on
AIME24 and 69.8% on AIME25, surpassing DeepSeek-R1 (671B) with significantly
shorter responses. Beyond mathematics, rStar2-Agent-14B also demonstrates
strong generalization to alignment, scientific reasoning, and agentic tool-use
tasks. Code and training recipes are available at
https://github.com/microsoft/rStar.

</details>


### [30] [Leveraging Semantic Triples for Private Document Generation with Local Differential Privacy Guarantees](https://arxiv.org/abs/2508.20736)
*Stephen Meisenbacher,Maulik Chevli,Florian Matthes*

Main category: cs.CL

TL;DR: 提出了DP-ST方法，利用语义三元组在本地差分隐私下实现邻域感知的文档生成，通过分治策略和LLM后处理在较低ε值下实现隐私与效用的平衡。


<details>
  <summary>Details</summary>
Motivation: 解决本地差分隐私下文本隐私保护的挑战，传统方法在低ε值下效果不佳，需要新的方法来平衡隐私保护和文本效用。

Method: 使用语义三元组进行邻域感知的私有文档生成，采用分治策略，结合LLM后处理来提升生成文本的连贯性。

Result: 该方法在较低ε值下仍能生成连贯的文本，有效平衡了隐私保护和文本效用，证明了分治范式在隐私保护中的有效性。

Conclusion: 通过语义三元组和LLM后处理的结合，DP-ST方法在本地差分隐私下实现了更好的隐私-效用权衡，强调了连贯性在隐私保护输出中的重要性。

Abstract: Many works at the intersection of Differential Privacy (DP) in Natural
Language Processing aim to protect privacy by transforming texts under DP
guarantees. This can be performed in a variety of ways, from word perturbations
to full document rewriting, and most often under local DP. Here, an input text
must be made indistinguishable from any other potential text, within some bound
governed by the privacy parameter $\varepsilon$. Such a guarantee is quite
demanding, and recent works show that privatizing texts under local DP can only
be done reasonably under very high $\varepsilon$ values. Addressing this
challenge, we introduce DP-ST, which leverages semantic triples for
neighborhood-aware private document generation under local DP guarantees.
Through the evaluation of our method, we demonstrate the effectiveness of the
divide-and-conquer paradigm, particularly when limiting the DP notion (and
privacy guarantees) to that of a privatization neighborhood. When combined with
LLM post-processing, our method allows for coherent text generation even at
lower $\varepsilon$ values, while still balancing privacy and utility. These
findings highlight the importance of coherence in achieving balanced
privatization outputs at reasonable $\varepsilon$ levels.

</details>


### [31] [Specializing General-purpose LLM Embeddings for Implicit Hate Speech Detection across Datasets](https://arxiv.org/abs/2508.20750)
*Vassiliy Cheremetiev,Quang Long Ho Ngo,Chau Ying Kot,Alina Elena Baia,Andrea Cavallaro*

Main category: cs.CL

TL;DR: 通过细调基于大语言模型的通用嵌入模型，在隐式敌意言论检测任务中实现了最端的性能提升，特别是在跨数据集评估中表现突出


<details>
  <summary>Details</summary>
Motivation: 隐式敌意言论(IHS)通过隐蕴符号、谬刺或代码术语传递偏见和恨意，因其不包含明显辱称性词汇而难以检测。需要找到更有效的检测方法

Method: 仅仅通过细调最新的通用嵌入模型（如Stella、Jasper、NV-Embed和E5），这些模型基于大语言模型(LLMs)构建

Result: 在多个IHS数据集上进行实验，在数据集内评估中F1-macro指标提升1.10个百分点，在跨数据集评估中提升达20.35个百分点

Conclusion: 简单的细调通用嵌入模型方法能够在隐式敌意言论检测任务中实现最端的性能，特别是在跨数据集适应性方面表现突出，无需复杂的任务特定管道或额外知识

Abstract: Implicit hate speech (IHS) is indirect language that conveys prejudice or
hatred through subtle cues, sarcasm or coded terminology. IHS is challenging to
detect as it does not include explicit derogatory or inflammatory words. To
address this challenge, task-specific pipelines can be complemented with
external knowledge or additional information such as context, emotions and
sentiment data. In this paper, we show that, by solely fine-tuning recent
general-purpose embedding models based on large language models (LLMs), such as
Stella, Jasper, NV-Embed and E5, we achieve state-of-the-art performance.
Experiments on multiple IHS datasets show up to 1.10 percentage points
improvements for in-dataset, and up to 20.35 percentage points improvements in
cross-dataset evaluation, in terms of F1-macro score.

</details>


### [32] [GUARD: Glocal Uncertainty-Aware Robust Decoding for Effective and Efficient Open-Ended Text Generation](https://arxiv.org/abs/2508.20757)
*Yuanhao Ding,Esteban Garces Arias,Meimingwei Li,Julian Rodemann,Matthias Aßenmacher,Danlu Chen,Gaojuan Fan,Christian Heumann,Chongsheng Zhang*

Main category: cs.CL

TL;DR: GUARD是一种自适应的解码方法，通过全局和局部熵估计来平衡文本生成的连贯性和多样性，同时显著提高生成速度


<details>
  <summary>Details</summary>
Motivation: 解决开放式文本生成中连贯性与多样性平衡的挑战，现有对比搜索方法存在超参数依赖和计算成本高的问题

Method: 提出GUARD方法，结合全局熵估计和局部熵偏差，整合长期和短期不确定性信号，并加入基于token计数的惩罚机制来降低计算开销

Result: 实验结果显示GUARD在文本多样性和连贯性之间取得了良好平衡，生成速度显著提升，人类和LLM评估者都验证了其优异性能

Conclusion: GUARD通过不确定性驱动的框架有效解决了文本生成的连贯性-多样性权衡问题，具有理论保证和实际应用价值

Abstract: Open-ended text generation faces a critical challenge: balancing coherence
with diversity in LLM outputs. While contrastive search-based decoding
strategies have emerged to address this trade-off, their practical utility is
often limited by hyperparameter dependence and high computational costs. We
introduce GUARD, a self-adaptive decoding method that effectively balances
these competing objectives through a novel "Glocal" uncertainty-driven
framework. GUARD combines global entropy estimates with local entropy
deviations to integrate both long-term and short-term uncertainty signals. We
demonstrate that our proposed global entropy formulation effectively mitigates
abrupt variations in uncertainty, such as sudden overconfidence or high entropy
spikes, and provides theoretical guarantees of unbiasedness and consistency. To
reduce computational overhead, we incorporate a simple yet effective
token-count-based penalty into GUARD. Experimental results demonstrate that
GUARD achieves a good balance between text diversity and coherence, while
exhibiting substantial improvements in generation speed. In a more nuanced
comparison study across different dimensions of text quality, both human and
LLM evaluators validated its remarkable performance. Our code is available at
https://github.com/YecanLee/GUARD.

</details>


### [33] [Feel the Difference? A Comparative Analysis of Emotional Arcs in Real and LLM-Generated CBT Sessions](https://arxiv.org/abs/2508.20764)
*Xiaoyi Wang,Jiwei Zhang,Guangtao Zhang,Honglei Guo*

Main category: cs.CL

TL;DR: 研究发现LLM生成的心理治疗对话虽然在流畅性和结构连贯性上表现良好，但在情感动态方面与真实对话存在显著差异，真实对话具有更大的情感变异性、更丰富的情感语言以及更真实的反应和调节模式。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型生成的心理治疗对话在心理健康NLP中越来越广泛地应用，需要评估这些合成对话是否能够捕捉真实治疗中微妙的情感动态。

Method: 采用Utterance Emotion Dynamics框架分析情感轨迹，比较真实CBT对话和LLM生成对话在情感效价、唤醒度和支配度维度上的差异，分析范围包括完整对话和个体说话者角色。

Result: 合成对话在情感特性上与真实对话存在明显差异：真实会话表现出更大的情感变异性、更多情感丰富的语言以及更真实的反应和调节模式。真实和合成说话者之间的情感弧相似度较低，特别是对于客户角色。

Conclusion: 当前LLM生成的治疗数据存在局限性，情感保真度在心理健康应用中至关重要。研究引入了RealCBT数据集来支持该领域的未来研究。

Abstract: Synthetic therapy dialogues generated by large language models (LLMs) are
increasingly used in mental health NLP to simulate counseling scenarios, train
models, and supplement limited real-world data. However, it remains unclear
whether these synthetic conversations capture the nuanced emotional dynamics of
real therapy. In this work, we conduct the first comparative analysis of
emotional arcs between real and LLM-generated Cognitive Behavioral Therapy
dialogues. We adapt the Utterance Emotion Dynamics framework to analyze
fine-grained affective trajectories across valence, arousal, and dominance
dimensions. Our analysis spans both full dialogues and individual speaker roles
(counselor and client), using real sessions transcribed from public videos and
synthetic dialogues from the CACTUS dataset. We find that while synthetic
dialogues are fluent and structurally coherent, they diverge from real
conversations in key emotional properties: real sessions exhibit greater
emotional variability,more emotion-laden language, and more authentic patterns
of reactivity and regulation. Moreover, emotional arc similarity between real
and synthetic speakers is low, especially for clients. These findings
underscore the limitations of current LLM-generated therapy data and highlight
the importance of emotional fidelity in mental health applications. We
introduce RealCBT, a curated dataset of real CBT sessions, to support future
research in this space.

</details>


### [34] [Turning the Spell Around: Lightweight Alignment Amplification via Rank-One Safety Injection](https://arxiv.org/abs/2508.20766)
*Harethah Abu Shairah,Hasan Abed Al Kader Hammoud,George Turkiyyah,Bernard Ghanem*

Main category: cs.CL

TL;DR: ROSI是一种白盒方法，通过秩一权重修改来增强LLM的安全对齐，提高拒绝有害请求的能力，同时保持模型在标准基准测试中的效用。


<details>
  <summary>Details</summary>
Motivation: 现有安全机制可以通过消除特定表示方向来绕过，需要一种能够永久增强模型安全对齐的方法。

Method: Rank-One Safety Injection (ROSI)，通过对所有残差流写入矩阵应用简单的秩一权重修改，将激活永久引导至拒绝调停子空间。

Result: ROSI持续提高了安全拒绝率（Llama Guard 3评估），同时在MMLU、HellaSwag和Arc等标准基准测试中保持了模型效用。

Conclusion: 定向、可解释的权重引导是改善LLM安全性的廉价而有效的机制，可作为资源密集型微调范式的补充。

Abstract: Safety alignment in Large Language Models (LLMs) often involves mediating
internal representations to refuse harmful requests. Recent research has
demonstrated that these safety mechanisms can be bypassed by ablating or
removing specific representational directions within the model. In this paper,
we propose the opposite approach: Rank-One Safety Injection (ROSI), a white-box
method that amplifies a model's safety alignment by permanently steering its
activations toward the refusal-mediating subspace. ROSI operates as a simple,
fine-tuning-free rank-one weight modification applied to all residual stream
write matrices. The required safety direction can be computed from a small set
of harmful and harmless instruction pairs. We show that ROSI consistently
increases safety refusal rates - as evaluated by Llama Guard 3 - while
preserving the utility of the model on standard benchmarks such as MMLU,
HellaSwag, and Arc. Furthermore, we show that ROSI can also re-align
'uncensored' models by amplifying their own latent safety directions,
demonstrating its utility as an effective last-mile safety procedure. Our
results suggest that targeted, interpretable weight steering is a cheap and
potent mechanism to improve LLM safety, complementing more resource-intensive
fine-tuning paradigms.

</details>


### [35] [Signs of Struggle: Spotting Cognitive Distortions across Language and Register](https://arxiv.org/abs/2508.20771)
*Abhishek Kuber,Enrico Liscio,Ruixuan Zhang,Caroline Figueroa,Pradeep K. Murukannaiah*

Main category: cs.CL

TL;DR: 首个跨语言跨文本类型的认知扭曲检测研究，分析荷兰青少年论坛帖子，发现语言和写作风格变化显著影响模型性能，但领域适应方法最有前景


<details>
  <summary>Details</summary>
Motivation: 青少年心理健康问题日益严重，需要自动化方法从数字文本中早期检测心理困扰迹象，特别是识别认知扭曲这种加剧心理困扰的非理性思维模式

Method: 研究跨语言和跨文本类型的泛化能力，分析荷兰青少年论坛帖子，使用领域适应方法来应对语言和写作风格变化带来的挑战

Result: 语言和写作风格的改变会显著影响模型性能，但领域适应方法显示出最大的潜力

Conclusion: 虽然语言和文本类型的变化对认知扭曲检测模型有显著影响，但通过领域适应方法可以有效提升跨语言跨文本场景下的检测性能

Abstract: Rising mental health issues among youth have increased interest in automated
approaches for detecting early signs of psychological distress in digital text.
One key focus is the identification of cognitive distortions, irrational
thought patterns that have a role in aggravating mental distress. Early
detection of these distortions may enable timely, low-cost interventions. While
prior work has focused on English clinical data, we present the first in-depth
study of cross-lingual and cross-register generalization of cognitive
distortion detection, analyzing forum posts written by Dutch adolescents. Our
findings show that while changes in language and writing style can
significantly affect model performance, domain adaptation methods show the most
promise.

</details>


### [36] [Exploring Machine Learning and Language Models for Multimodal Depression Detection](https://arxiv.org/abs/2508.20805)
*Javier Si Zhao Hong,Timothy Zoe Delaya,Sherwyn Chan Yin Kit,Pai Chet Ng,Xiaoxiao Miao*

Main category: cs.CL

TL;DR: 本文比较了XGBoost、transformer架构和大型语言模型在音频、视频和文本特征上的多模态抑郁症检测性能


<details>
  <summary>Details</summary>
Motivation: 参加首届多模态人格感知抑郁症检测挑战赛，探索机器学习模型在抑郁症检测中的应用

Method: 使用XGBoost、transformer架构和大型语言模型(LLMs)处理音频、视频和文本特征进行多模态分析

Result: 比较了不同类型模型在捕捉跨模态抑郁症相关信号方面的优势和局限性

Conclusion: 为心理健康预测提供了有效的多模态表示策略的见解

Abstract: This paper presents our approach to the first Multimodal Personality-Aware
Depression Detection Challenge, focusing on multimodal depression detection
using machine learning and deep learning models. We explore and compare the
performance of XGBoost, transformer-based architectures, and large language
models (LLMs) on audio, video, and text features. Our results highlight the
strengths and limitations of each type of model in capturing depression-related
signals across modalities, offering insights into effective multimodal
representation strategies for mental health prediction.

</details>


### [37] [GDLLM: A Global Distance-aware Modeling Approach Based on Large Language Models for Event Temporal Relation Extraction](https://arxiv.org/abs/2508.20828)
*Jie Zhao,Wanting Ning,Yuxiao Fei,Yubo Feng,Lishuang Li*

Main category: cs.CL

TL;DR: 提出GDLLM方法，通过距离感知图结构和软推理时序特征学习，增强大语言模型对事件时序关系的长距离依赖和少数类关系识别能力


<details>
  <summary>Details</summary>
Motivation: 解决小语言模型在数据不平衡时对少数类关系识别能力有限，以及大语言模型手动提示可能引入噪声干扰长距离依赖判断的问题

Method: 基于大语言模型的全局距离感知建模方法，使用图注意力网络构建距离感知图结构捕获长距离依赖特征，设计基于软推理的时序特征学习范式增强短距离邻近带关系识别

Result: 在两个公开数据集TB-Dense和MATRES上实现了最先进的性能，显著提升了少数关系类的识别能力和整体学习能力

Conclusion: GDLLM框架通过有效捕获全局特征，显著增强了事件时序关系提取的性能，特别是在处理少数类关系和长距离依赖方面表现出色

Abstract: In Natural Language Processing(NLP), Event Temporal Relation Extraction
(ETRE) is to recognize the temporal relations of two events. Prior studies have
noted the importance of language models for ETRE. However, the restricted
pre-trained knowledge of Small Language Models(SLMs) limits their capability to
handle minority class relations in imbalanced classification datasets. For
Large Language Models(LLMs), researchers adopt manually designed prompts or
instructions, which may introduce extra noise, leading to interference with the
model's judgment of the long-distance dependencies between events. To address
these issues, we propose GDLLM, a Global Distance-aware modeling approach based
on LLMs. We first present a distance-aware graph structure utilizing Graph
Attention Network(GAT) to assist the LLMs in capturing long-distance dependency
features. Additionally, we design a temporal feature learning paradigm based on
soft inference to augment the identification of relations with a short-distance
proximity band, which supplements the probabilistic information generated by
LLMs into the multi-head attention mechanism. Since the global feature can be
captured effectively, our framework substantially enhances the performance of
minority relation classes and improves the overall learning ability.
Experiments on two publicly available datasets, TB-Dense and MATRES,
demonstrate that our approach achieves state-of-the-art (SOTA) performance.

</details>


### [38] [MSRS: Evaluating Multi-Source Retrieval-Augmented Generation](https://arxiv.org/abs/2508.20867)
*Rohan Phanse,Yijie Zhou,Kejian Shi,Wencai Zhang,Yixin Liu,Yilun Zhao,Arman Cohan*

Main category: cs.CL

TL;DR: 这篇论文提出了一种可扩展的评测框架，用于构建需要多源信息集成和综合的RAG系统评测基准，并创建了两个新的多源检索与综合基准MSRS-Story和MSRS-Meet。


<details>
  <summary>Details</summary>
Motivation: 现有的RAG系统评估多假设问题答案可从单个来源获得或答案短小，而实际应用需要综合多个来源的信息并生成长文本回应。

Method: 设计了一种可扩展的评测框架，构建了MSRS-Story和MSRS-Meet两个基准，分别代表故事综合和摘要任务，并使用各种RAG流水线（包括稀疏和浓密检索＋前沿LLM）进行实验。

Result: 实验结果显示生成质量很大程度依赖于检索效果，而检索效果又因任务而异。即使在理想检索条件下，多源综合仍具有挑战性，但理解模型在这一步驱动上显著超过标准LLM。

Conclusion: 论文提出的评测框架和新基准能够有效地评估RAG系统在多源信息集成和综合任务中的性能，并强调了检索效果对生成质量的关键影响以及理解模型在综合步骤中的优势。

Abstract: Retrieval-augmented systems are typically evaluated in settings where
information required to answer the query can be found within a single source or
the answer is short-form or factoid-based. However, many real-world
applications demand the ability to integrate and summarize information
scattered across multiple sources, where no single source is sufficient to
respond to the user's question. In such settings, the retrieval component of a
RAG pipeline must recognize a variety of relevance signals, and the generation
component must connect and synthesize information across multiple sources. We
present a scalable framework for constructing evaluation benchmarks that
challenge RAG systems to integrate information across distinct sources and
generate long-form responses. Using our framework, we build two new benchmarks
on Multi-Source Retrieval and Synthesis: MSRS-Story and MSRS-Meet, representing
narrative synthesis and summarization tasks, respectively, that require
retrieval from large collections. Our extensive experiments with various RAG
pipelines -- including sparse and dense retrievers combined with frontier LLMs
-- reveal that generation quality is highly dependent on retrieval
effectiveness, which varies greatly by task. While multi-source synthesis
proves challenging even in an oracle retrieval setting, we find that reasoning
models significantly outperform standard LLMs at this distinct step.

</details>


### [39] [The Uneven Impact of Post-Training Quantization in Machine Translation](https://arxiv.org/abs/2508.20893)
*Benjamin Marie,Atsushi Fujita*

Main category: cs.CL

TL;DR: 大规模评估显示，4位量化对高资源语言和大模型影响较小，但2位量化对低资源和类型多样语言造成显著质量下降。GGUF方法在2位精度下表现最稳定，语言匹配校准在低比特场景中有益。


<details>
  <summary>Details</summary>
Motivation: 量化对多语言任务的影响尚未充分探索，特别是在机器翻译领域，需要了解不同量化技术对多种语言的影响

Method: 使用5个LLM模型（1.7B到70B参数）在55种语言上进行后训练量化评估，比较4种量化技术（AWQ、BitsAndBytes、GGUF、AutoRound），分析量化与解码超参数、校准语言的交互作用

Result: 4位量化通常能保持高资源语言和大模型的翻译质量，但低资源和类型多样语言在2位设置下出现显著退化。GGUF变体在2位精度下提供最一致性能，语言匹配校准主要在低比特场景中提供优势

Conclusion: 研究为在量化约束下部署多语言LLM进行机器翻译提供了实用见解，特别是在低资源设置中，算法选择和模型大小共同决定鲁棒性

Abstract: Quantization is essential for deploying large language models (LLMs) on
resource-constrained hardware, but its implications for multilingual tasks
remain underexplored. We conduct the first large-scale evaluation of
post-training quantization (PTQ) on machine translation across 55 languages
using five LLMs ranging from 1.7B to 70B parameters. Our analysis reveals that
while 4-bit quantization often preserves translation quality for high-resource
languages and large models, significant degradation occurs for low-resource and
typologically diverse languages, particularly in 2-bit settings. We compare
four quantization techniques (AWQ, BitsAndBytes, GGUF, and AutoRound), showing
that algorithm choice and model size jointly determine robustness. GGUF
variants provide the most consistent performance, even at 2-bit precision.
Additionally, we quantify the interactions between quantization, decoding
hyperparameters, and calibration languages, finding that language-matched
calibration offers benefits primarily in low-bit scenarios. Our findings offer
actionable insights for deploying multilingual LLMs for machine translation
under quantization constraints, especially in low-resource settings.

</details>


### [40] [SageLM: A Multi-aspect and Explainable Large Language Model for Speech Judgement](https://arxiv.org/abs/2508.20916)
*Yuan Ge,Junxiang Zhang,Xiaoqian Liu,Bei Li,Xiangnan Ma,Chenglong Wang,Kaiyang Ye,Yangfan Du,Linfeng Zhang,Yuxin Huang,Tong Xiao,Zhengtao Yu,JingBo Zhu*

Main category: cs.CL

TL;DR: SageLM是一个端到端、多维度、可解释的语音大语言模型，用于全面评估语音到语音(S2S)大语言模型，在语义和声学维度上联合评估，并通过理性监督和两阶段训练实现与人类评估者82.79%的一致率。


<details>
  <summary>Details</summary>
Motivation: 语音到语音大语言模型的评估是一个基础性挑战，现有级联方法忽视声学特征，且缺乏可解释性和语音偏好数据稀缺。

Method: 提出SageLM模型，联合评估语义和声学维度；采用理性监督增强可解释性；构建SpeechFeedback合成偏好数据集；使用两阶段训练范式缓解数据稀缺问题。

Result: SageLM与人类评估者的一致率达到82.79%，分别比级联基线和SLM基线至少高出7.42%和26.20%。

Conclusion: SageLM在语音到语音大语言模型评估方面表现出色，通过多维度联合评估和理性监督机制，显著提升了评估性能和对齐效果。

Abstract: Speech-to-Speech (S2S) Large Language Models (LLMs) are foundational to
natural human-computer interaction, enabling end-to-end spoken dialogue
systems. However, evaluating these models remains a fundamental challenge. We
propose \texttt{SageLM}, an end-to-end, multi-aspect, and explainable speech
LLM for comprehensive S2S LLMs evaluation. First, unlike cascaded approaches
that disregard acoustic features, SageLM jointly assesses both semantic and
acoustic dimensions. Second, it leverages rationale-based supervision to
enhance explainability and guide model learning, achieving superior alignment
with evaluation outcomes compared to rule-based reinforcement learning methods.
Third, we introduce \textit{SpeechFeedback}, a synthetic preference dataset,
and employ a two-stage training paradigm to mitigate the scarcity of speech
preference data. Trained on both semantic and acoustic dimensions, SageLM
achieves an 82.79\% agreement rate with human evaluators, outperforming
cascaded and SLM-based baselines by at least 7.42\% and 26.20\%, respectively.

</details>


### [41] [How Can Input Reformulation Improve Tool Usage Accuracy in a Complex Dynamic Environment? A Study on $τ$-bench](https://arxiv.org/abs/2508.20931)
*Venkatesh Mishra,Amir Saeidi,Satyam Raj,Mutsumi Nakamura,Jayanth Srinivasa,Gaowen Liu,Ali Payani,Chitta Baral*

Main category: cs.CL

TL;DR: IRMA框架通过自动重构用户查询，加入领域规则和工具建议，显著提升LLM在多轮对话环境中的工具调用性能，比现有方法提升12.7-19.1%


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在多轮对话环境中存在推理不一致、违反领域政策和信息提取困难等问题，需要改进工具调用能力

Method: 提出IRMA多智能体框架，自动重构用户查询并添加相关领域规则和工具建议，帮助工具调用智能体更好地聚焦任务

Result: IRMA在整体通过率上显著优于ReAct、函数调用和自我反思方法，分别提升16.1%、12.7%和19.1%

Conclusion: IRMA框架在动态环境中展现出更高的可靠性和一致性，为解决LLM工具调用中的常见错误提供了有效方案

Abstract: Recent advances in reasoning and planning capabilities of large language
models (LLMs) have enabled their potential as autonomous agents capable of tool
use in dynamic environments. However, in multi-turn conversational environments
like $\tau$-bench, these agents often struggle with consistent reasoning,
adherence to domain-specific policies, and extracting correct information over
a long horizon of tool-calls and conversation. To capture and mitigate these
failures, we conduct a comprehensive manual analysis of the common errors
occurring in the conversation trajectories. We then experiment with
reformulations of inputs to the tool-calling agent for improvement in agent
decision making. Finally, we propose the Input-Reformulation Multi-Agent (IRMA)
framework, which automatically reformulates user queries augmented with
relevant domain rules and tool suggestions for the tool-calling agent to focus
on. The results show that IRMA significantly outperforms ReAct, Function
Calling, and Self-Reflection by 16.1%, 12.7%, and 19.1%, respectively, in
overall pass^5 scores. These findings highlight the superior reliability and
consistency of IRMA compared to other methods in dynamic environments.

</details>


### [42] [STARE at the Structure: Steering ICL Exemplar Selection with Structural Alignment](https://arxiv.org/abs/2508.20944)
*Jiaqian Li,Qisheng Hu,Jing Li,Wenya Wang*

Main category: cs.CL

TL;DR: 一种新的两阶段示例选择策略，通过结构意识监督和插件模块提升语义解析任务的上下文学习性能


<details>
  <summary>Details</summary>
Motivation: 现有的上下文学习示例选择策略忽视了结构对齐，导致语义解析等结构化预测任务的性能不佳和氡化能力差

Method: 首先使用结构意识监督微调BERT检索器，然后通过插件模块增强隐藏表示中的语法意义信息，该插件模型无关且程序经济

Result: 在跨越三个语义解析任务的四个基准测试中，方法一致超越现有基线，多个最新大语言模型都取得了更好的推理性能

Conclusion: 该方法实现了效率、氡化能力和性能之间的强大平衡，为结构化预测任务的上下文学习提供了有效解决方案

Abstract: In-Context Learning (ICL) has become a powerful paradigm that enables LLMs to
perform a wide range of tasks without task-specific fine-tuning. However, the
effectiveness of ICL heavily depends on the quality of exemplar selection. In
particular, for structured prediction tasks such as semantic parsing, existing
ICL selection strategies often overlook structural alignment, leading to
suboptimal performance and poor generalization. To address this issue, we
propose a novel two-stage exemplar selection strategy that achieves a strong
balance between efficiency, generalizability, and performance. First, we
fine-tune a BERT-based retriever using structure-aware supervision, guiding it
to select exemplars that are both semantically relevant and structurally
aligned. Then, we enhance the retriever with a plug-in module, which amplifies
syntactically meaningful information in the hidden representations. This
plug-in is model-agnostic, requires minimal overhead, and can be seamlessly
integrated into existing pipelines. Experiments on four benchmarks spanning
three semantic parsing tasks demonstrate that our method consistently
outperforms existing baselines with multiple recent LLMs as inference-time
models.

</details>


### [43] [ProactiveEval: A Unified Evaluation Framework for Proactive Dialogue Agents](https://arxiv.org/abs/2508.20973)
*Tianjian Liu,Fanqi Wan,Jiajian Guo,Xiaojun Quan*

Main category: cs.CL

TL;DR: 提出了ProactiveEval统一框架，用于评估大语言模型的主动对话能力，通过目标规划和对话引导两个维度，在6个领域构建了328个评估环境，测试了22种LLM。


<details>
  <summary>Details</summary>
Motivation: 现有主动对话研究主要集中在特定领域或任务导向场景，导致评估碎片化，限制了全面探索模型的主动对话能力。

Method: 提出ProactiveEval框架，将主动对话分解为目标规划和对话引导两个维度，建立跨领域评估指标，并自动生成多样化评估数据。

Result: DeepSeek-R1在目标规划任务上表现优异，Claude-3.7-Sonnet在对话引导任务上表现最佳。研究了推理能力对主动行为的影响。

Conclusion: 该框架为全面评估LLM主动对话能力提供了统一标准，对未来的模型发展具有重要指导意义。

Abstract: Proactive dialogue has emerged as a critical and challenging research problem
in advancing large language models (LLMs). Existing works predominantly focus
on domain-specific or task-oriented scenarios, which leads to fragmented
evaluations and limits the comprehensive exploration of models' proactive
conversation abilities. In this work, we propose ProactiveEval, a unified
framework designed for evaluating proactive dialogue capabilities of LLMs. This
framework decomposes proactive dialogue into target planning and dialogue
guidance, establishing evaluation metrics across various domains. Moreover, it
also enables the automatic generation of diverse and challenging evaluation
data. Based on the proposed framework, we develop 328 evaluation environments
spanning 6 distinct domains. Through experiments with 22 different types of
LLMs, we show that DeepSeek-R1 and Claude-3.7-Sonnet exhibit exceptional
performance on target planning and dialogue guidance tasks, respectively.
Finally, we investigate how reasoning capabilities influence proactive
behaviors and discuss their implications for future model development.

</details>


### [44] [Lethe: Purifying Backdoored Large Language Models with Knowledge Dilution](https://arxiv.org/abs/2508.21004)
*Chen Chen,Yuchen Sun,Jiaxin Gao,Xueluan Gong,Qian Wang,Ziyao Wang,Yongsen Zheng,Kwok-Yan Lam*

Main category: cs.CL

TL;DR: LETHE是一种通过知识稀释消除LLM后门行为的新方法，结合内部模型合并和外部提示增强，在5个主流LLM上对8种后门攻击实现了高达98%的攻击成功率降低。


<details>
  <summary>Details</summary>
Motivation: 现有后门防御方法存在局限性：要么只关注特定触发场景，要么只是检测机制而非消除，要么无法应对模型编辑、多触发器和无触发器等高级攻击场景。需要一种全面有效的后门消除方案。

Method: LETHE采用内外双重机制：内部通过训练干净模型并与后门模型合并，在参数记忆中稀释后门影响；外部通过在提示中加入良性相关证据，分散LLM对后门特征的注意力。

Result: 在分类和生成领域的5个主流LLM上测试，LETHE优于8个SOTA防御基线，对高级后门攻击的攻击成功率降低高达98%，同时保持模型效用，且成本效益高、对自适应攻击鲁棒。

Conclusion: LETHE提供了一种全面有效的后门消除解决方案，通过知识稀释机制成功应对各种复杂后门攻击场景，为LLM安全部署提供了重要保障。

Abstract: Large language models (LLMs) have seen significant advancements, achieving
superior performance in various Natural Language Processing (NLP) tasks.
However, they remain vulnerable to backdoor attacks, where models behave
normally for standard queries but generate harmful responses or unintended
output when specific triggers are activated. Existing backdoor defenses either
lack comprehensiveness, focusing on narrow trigger settings, detection-only
mechanisms, and limited domains, or fail to withstand advanced scenarios like
model-editing-based, multi-trigger, and triggerless attacks. In this paper, we
present LETHE, a novel method to eliminate backdoor behaviors from LLMs through
knowledge dilution using both internal and external mechanisms. Internally,
LETHE leverages a lightweight dataset to train a clean model, which is then
merged with the backdoored model to neutralize malicious behaviors by diluting
the backdoor impact within the model's parametric memory. Externally, LETHE
incorporates benign and semantically relevant evidence into the prompt to
distract LLM's attention from backdoor features. Experimental results on
classification and generation domains across 5 widely used LLMs demonstrate
that LETHE outperforms 8 state-of-the-art defense baselines against 8 backdoor
attacks. LETHE reduces the attack success rate of advanced backdoor attacks by
up to 98% while maintaining model utility. Furthermore, LETHE has proven to be
cost-efficient and robust against adaptive backdoor attacks.

</details>


### [45] [An Agile Method for Implementing Retrieval Augmented Generation Tools in Industrial SMEs](https://arxiv.org/abs/2508.21024)
*Mathieu Bourdin,Anas Neumann,Thomas Paviot,Robert Pellerin,Samir Lamouri*

Main category: cs.CL

TL;DR: EASI-RAG是一个为中小企业设计的结构化敏捷方法，帮助快速部署RAG系统，解决LLM的幻觉和知识过时问题，在环境测试实验室案例中成功验证。


<details>
  <summary>Details</summary>
Motivation: 中小企业由于资源有限和缺乏NLP专业知识，难以部署RAG系统来解决大语言模型的幻觉和知识过时问题。

Method: 基于方法工程原理，EASI-RAG定义了明确的角色、活动和技术，通过结构化敏捷方法支持RAG系统在工业中小企业中的部署。

Result: 在环境测试实验室的实际案例中，无RAG经验的团队在一个月内成功部署了RAG工具，系统提供准确答案，提高数据可靠性，用户采纳度高。

Conclusion: EASI-RAG证明了在中小企业中快速部署RAG系统的可行性，未来需要扩展到更多用例并与微调模型进一步集成。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a powerful solution to
mitigate the limitations of Large Language Models (LLMs), such as
hallucinations and outdated knowledge. However, deploying RAG-based tools in
Small and Medium Enterprises (SMEs) remains a challenge due to their limited
resources and lack of expertise in natural language processing (NLP). This
paper introduces EASI-RAG, Enterprise Application Support for Industrial RAG, a
structured, agile method designed to facilitate the deployment of RAG systems
in industrial SME contexts. EASI-RAG is based on method engineering principles
and comprises well-defined roles, activities, and techniques. The method was
validated through a real-world case study in an environmental testing
laboratory, where a RAG tool was implemented to answer operators queries using
data extracted from operational procedures. The system was deployed in under a
month by a team with no prior RAG experience and was later iteratively improved
based on user feedback. Results demonstrate that EASI-RAG supports fast
implementation, high user adoption, delivers accurate answers, and enhances the
reliability of underlying data. This work highlights the potential of RAG
deployment in industrial SMEs. Future works include the need for generalization
across diverse use cases and further integration with fine-tuned models.

</details>


### [46] [Re-Representation in Sentential Relation Extraction with Sequence Routing Algorithm](https://arxiv.org/abs/2508.21049)
*Ramazan Ali Bahrami,Ramin Yahyapour*

Main category: cs.CL

TL;DR: 本文提出使用胶囊网络中的动态路由进行句子关系抽取，在多个数据集上表现优于现有方法，但发现在大规模数据集Wikidata上性能不佳，主要原因是标签噪声和重表示能力不足。


<details>
  <summary>Details</summary>
Motivation: 句子关系抽取是NLP中的重要任务，现有方法在处理大规模噪声数据集时存在性能下降问题，需要探索更鲁棒的方法。

Method: 采用胶囊网络中的动态路由机制进行句子关系抽取，通过胶囊间的动态信息传递来提升关系抽取性能。

Result: 在Tacred、Tacredrev、Retacred和Conll04数据集上达到state-of-the-art性能，但在Wikidata数据集上表现不佳，发现标签噪声是主要原因。

Conclusion: 除了标签噪声问题外，重表示能力也是句子关系抽取的重要挑战，提出的胶囊网络方法在重表示方面优于传统模型。

Abstract: Sentential relation extraction (RE) is an important task in natural language
processing (NLP). In this paper we propose to do sentential RE with dynamic
routing in capsules. We first show that the proposed approach outperform state
of the art on common sentential relation extraction datasets Tacred, Tacredrev,
Retacred, and Conll04. We then investigate potential reasons for its good
performance on the mentioned datasets, and yet low performance on another
similar, yet larger sentential RE dataset, Wikidata. As such, we identify noise
in Wikidata labels as one of the reasons that can hinder performance.
Additionally, we show associativity of better performance with better
re-representation, a term from neuroscience referred to change of
representation in human brain to improve the match at comparison time. As
example, in the given analogous terms King:Queen::Man:Woman, at comparison
time, and as a result of re-representation, the similarity between related head
terms (King,Man), and tail terms (Queen,Woman) increases. As such, our
observation show that our proposed model can do re-representation better than
the vanilla model compared with. To that end, beside noise in the labels of the
distantly supervised RE datasets, we propose re-representation as a challenge
in sentential RE.

</details>


### [47] [Enabling Equitable Access to Trustworthy Financial Reasoning](https://arxiv.org/abs/2508.21051)
*William Jurayj,Nils Holzenberger,Benjamin Van Durme*

Main category: cs.CL

TL;DR: 结合大型语言模型与符号求解器的神经符号方法，用于自动化税务计算，在SARA数据集上表现出色，显著降低错误成本


<details>
  <summary>Details</summary>
Motivation: 税务申报复杂且容易出错，传统LLM无法满足高准确性和可审计性要求，需要开发可靠的自动化税务辅助系统

Method: 将LLM与符号求解器集成，将文本规则翻译为形式逻辑程序，结合智能检索的案例表示范例

Result: 在SARA数据集上性能显著提升，部署成本远低于现实世界平均错误成本

Conclusion: 神经符号架构为提供可靠、经济可行的税务辅助服务提供了可行方案，有助于促进公平获取税务帮助

Abstract: According to the United States Internal Revenue Service, ''the average
American spends $\$270$ and 13 hours filing their taxes''. Even beyond the
U.S., tax filing requires complex reasoning, combining application of
overlapping rules with numerical calculations. Because errors can incur costly
penalties, any automated system must deliver high accuracy and auditability,
making modern large language models (LLMs) poorly suited for this task. We
propose an approach that integrates LLMs with a symbolic solver to calculate
tax obligations. We evaluate variants of this system on the challenging
StAtutory Reasoning Assessment (SARA) dataset, and include a novel method for
estimating the cost of deploying such a system based on real-world penalties
for tax errors. We further show how combining up-front translation of
plain-text rules into formal logic programs, combined with intelligently
retrieved exemplars for formal case representations, can dramatically improve
performance on this task and reduce costs to well below real-world averages.
Our results demonstrate the promise and economic feasibility of neuro-symbolic
architectures for increasing equitable access to reliable tax assistance.

</details>


<div id='q-bio.NC'></div>

# q-bio.NC [[Back]](#toc)

### [48] [A Unified Theory of Language](https://arxiv.org/abs/2508.20109)
*Robert Worden*

Main category: q-bio.NC

TL;DR: 该论文提出了一个统一语言理论，结合贝叶斯认知语言模型和性选择进化假说，通过构建语法和统一计算来解释语言的快速性、表达性及语用学等核心特征。


<details>
  <summary>Details</summary>
Motivation: 旨在建立一个能够解释语言处理速度、表达多样性以及语用学等语言核心特征的综合理论框架，同时为语言进化提供性选择解释。

Method: 基于构建语法理论，添加语用学和快速精确语言学习两个新元素，使用图状特征结构表示心理构造，通过贝叶斯最大似然模式匹配的统一计算处理语言各方面。

Result: 理论能够解释语言的主要事实，包括处理速度、表达性、多样性，以及语用学、句法和语义学的数据，实现了语义学与语用学的无缝整合。

Conclusion: 该统一理论成功解释了语言的核心特征，建立了人脑语言处理与动物贝叶斯认知的进化连续性，认为语言是人类心智阅读能力、合作、自尊和情感的基础，是人类文化和社会的基石。

Abstract: A unified theory of language combines a Bayesian cognitive linguistic model
of language processing, with the proposal that language evolved by sexual
selection for the display of intelligence. The theory accounts for the major
facts of language, including its speed and expressivity, and data on language
diversity, pragmatics, syntax and semantics. The computational element of the
theory is based on Construction Grammars. These give an account of the syntax
and semantics of the worlds languages, using constructions and unification. Two
novel elements are added to construction grammars: an account of language
pragmatics, and an account of fast, precise language learning. Constructions
are represented in the mind as graph like feature structures. People use slow
general inference to understand the first few examples they hear of any
construction. After that it is learned as a feature structure, and is rapidly
applied by unification. All aspects of language (phonology, syntax, semantics,
and pragmatics) are seamlessly computed by fast unification; there is no
boundary between semantics and pragmatics. This accounts for the major puzzles
of pragmatics, and for detailed pragmatic phenomena. Unification is Bayesian
maximum likelihood pattern matching. This gives evolutionary continuity between
language processing in the human brain, and Bayesian cognition in animal
brains. Language is the basis of our mind reading abilities, our cooperation,
self esteem and emotions; the foundations of human culture and society.

</details>


<div id='cs.DL'></div>

# cs.DL [[Back]](#toc)

### [49] [Leveraging Large Language Models for Generating Research Topic Ontologies: A Multi-Disciplinary Study](https://arxiv.org/abs/2508.20693)
*Tanay Aggarwal,Angelo Salatino,Francesco Osborne,Enrico Motta*

Main category: cs.DL

TL;DR: 本研究评估了大型语言模型在识别研究领域语义关系方面的能力，通过零样本提示、思维链提示和微调三种方法，在生物医学、物理和工程三个学科中进行测试，并引入了包含8000多个关系的新数据集PEM-Rel-8K。


<details>
  <summary>Details</summary>
Motivation: 研究领域本体和分类法的创建和维护成本高昂且耗时，通常需要多个领域专家的协调努力，导致覆盖不均、跨域连接有限和更新周期长的问题。

Method: 使用三种条件评估多个大型语言模型：零样本提示、思维链提示和在现有本体上进行微调。还评估了微调模型的跨域迁移能力，并引入了PEM-Rel-8K数据集。

Result: 实验表明，在PEM-Rel-8K数据集上微调的大型语言模型在所有学科中都表现出色。

Conclusion: 微调大型语言模型可以有效识别研究主题之间的语义关系，为解决本体创建和维护的挑战提供了有前景的解决方案。

Abstract: Ontologies and taxonomies of research fields are critical for managing and
organising scientific knowledge, as they facilitate efficient classification,
dissemination and retrieval of information. However, the creation and
maintenance of such ontologies are expensive and time-consuming tasks, usually
requiring the coordinated effort of multiple domain experts. Consequently,
ontologies in this space often exhibit uneven coverage across different
disciplines, limited inter-domain connectivity, and infrequent updating cycles.
In this study, we investigate the capability of several large language models
to identify semantic relationships among research topics within three academic
domains: biomedicine, physics, and engineering. The models were evaluated under
three distinct conditions: zero-shot prompting, chain-of-thought prompting, and
fine-tuning on existing ontologies. Additionally, we assessed the cross-domain
transferability of fine-tuned models by measuring their performance when
trained in one domain and subsequently applied to a different one. To support
this analysis, we introduce PEM-Rel-8K, a novel dataset consisting of over
8,000 relationships extracted from the most widely adopted taxonomies in the
three disciplines considered in this study: MeSH, PhySH, and IEEE. Our
experiments demonstrate that fine-tuning LLMs on PEM-Rel-8K yields excellent
performance across all disciplines.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [50] [Robustness Assessment and Enhancement of Text Watermarking for Google's SynthID](https://arxiv.org/abs/2508.20228)
*Xia Han,Qi Li,Jianbing Ni,Mohammad Zulkernine*

Main category: cs.CR

TL;DR: SynGuard是一个混合水印框架，结合语义信息检索和SynthID-Text的概率水印机制，在词法和语义层面双重嵌入水印，显著提升了对抗改写攻击的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM水印方法如SynthID-Text在面对保持语义的改写攻击（如释义、复制粘贴修改、回译）时存在脆弱性，水印可检测性会显著下降。

Method: 提出SynGuard混合框架，将语义信息检索(SIR)的语义对齐能力与SynthID-Text的概率水印机制相结合，在词法和语义两个层面联合嵌入水印。

Result: 在多种攻击场景下的实验表明，SynGuard相比SynthID-Text平均提高了11.1%的F1分数水印恢复能力。

Conclusion: 语义感知水印在抵抗现实世界篡改方面具有有效性，证明了双重水印嵌入策略的优越性。

Abstract: Recent advances in LLM watermarking methods such as SynthID-Text by Google
DeepMind offer promising solutions for tracing the provenance of AI-generated
text. However, our robustness assessment reveals that SynthID-Text is
vulnerable to meaning-preserving attacks, such as paraphrasing, copy-paste
modifications, and back-translation, which can significantly degrade watermark
detectability. To address these limitations, we propose SynGuard, a hybrid
framework that combines the semantic alignment strength of Semantic Information
Retrieval (SIR) with the probabilistic watermarking mechanism of SynthID-Text.
Our approach jointly embeds watermarks at both lexical and semantic levels,
enabling robust provenance tracking while preserving the original meaning.
Experimental results across multiple attack scenarios show that SynGuard
improves watermark recovery by an average of 11.1\% in F1 score compared to
SynthID-Text. These findings demonstrate the effectiveness of semantic-aware
watermarking in resisting real-world tampering. All code, datasets, and
evaluation scripts are publicly available at:
https://github.com/githshine/SynGuard.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [51] [A Systematic Review on the Generative AI Applications in Human Medical Genomics](https://arxiv.org/abs/2508.20275)
*Anton Changalidis,Yury Barbitoff,Yulia Nasykhova,Andrey Glotov*

Main category: cs.LG

TL;DR: 本系统综述分析了172项研究，探讨大型语言模型在遗传研究和疾病诊断中的应用，重点关注基因组变异识别、医学影像分析和多模态数据整合的挑战。


<details>
  <summary>Details</summary>
Motivation: 传统统计方法和机器学习在处理复杂高维遗传数据时存在局限，需要评估基于Transformer的大型语言模型在遗传疾病诊断和研究中的潜力和挑战。

Method: 通过PubMed、bioRxiv、medRxiv和arXiv进行自动化关键词搜索，筛选出172项相关研究，分析LLM在基因组变异识别、注释、解释以及医学影像分析中的应用。

Result: 研究发现Transformer模型在疾病风险分层、变异解释、医学影像分析和报告生成方面取得显著进展，但在多模态数据整合和临床实践应用方面仍面临重大挑战。

Conclusion: 大型语言模型在遗传疾病诊断和教育支持方面具有变革潜力，但需要解决通用性和临床实施方面的限制，本综述为该快速发展的领域提供了全面的分类和评估指南。

Abstract: Although traditional statistical techniques and machine learning methods have
contributed significantly to genetics and, in particular, inherited disease
diagnosis, they often struggle with complex, high-dimensional data, a challenge
now addressed by state-of-the-art deep learning models. Large language models
(LLMs), based on transformer architectures, have excelled in tasks requiring
contextual comprehension of unstructured medical data. This systematic review
examines the role of LLMs in the genetic research and diagnostics of both rare
and common diseases. Automated keyword-based search in PubMed, bioRxiv,
medRxiv, and arXiv was conducted, targeting studies on LLM applications in
diagnostics and education within genetics and removing irrelevant or outdated
models. A total of 172 studies were analyzed, highlighting applications in
genomic variant identification, annotation, and interpretation, as well as
medical imaging advancements through vision transformers. Key findings indicate
that while transformer-based models significantly advance disease and risk
stratification, variant interpretation, medical imaging analysis, and report
generation, major challenges persist in integrating multimodal data (genomic
sequences, imaging, and clinical records) into unified and clinically robust
pipelines, facing limitations in generalizability and practical implementation
in clinical settings. This review provides a comprehensive classification and
assessment of the current capabilities and limitations of LLMs in transforming
hereditary disease diagnostics and supporting genetic education, serving as a
guide to navigate this rapidly evolving field.

</details>


### [52] [Poison Once, Refuse Forever: Weaponizing Alignment for Injecting Bias in LLMs](https://arxiv.org/abs/2508.20333)
*Md Abdullah Al Mamun,Ihsen Alouani,Nael Abu-Ghazaleh*

Main category: cs.LG

TL;DR: 本文提出了一种名为Subversive Alignment Injection (SAI)的投毒攻击方法，通过利用LLMs的对齐机制，在特定主题或查询上触发拒绝回答，从而植入偏见或实施定向审查，且能逃避现有防御检测。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型(LLMs)通过对齐训练来拒绝回答有害或不安全的提示，但攻击者可以利用这种对齐机制来植入偏见或实施定向审查，而不会降低模型对其他无关主题的响应能力。

Method: 提出了Subversive Alignment Injection (SAI)投毒攻击方法，通过数据投毒(仅需1%的投毒数据)来操纵LLMs的对齐机制，使其在预定义的特定主题或查询上触发拒绝回答。

Result: 实验显示SAI能有效逃避最先进的投毒防御检测，包括LLM状态取证和联邦学习中的鲁棒聚合技术。在ChatDoctor等应用中，导致对特定种族类别医疗问题的高偏见(ΔDP 23%)；在简历筛选任务中导致对特定大学简历的高偏见(ΔDP 27%)；在其他9个聊天应用中偏见更高(ΔDP ~38%)。

Conclusion: SAI攻击揭示了LLMs对齐机制的安全漏洞，表明即使是最先进的防御机制也无法有效检测这种利用对齐机制植入偏见的投毒攻击，对LLM应用管道构成了实际威胁。

Abstract: Large Language Models (LLMs) are aligned to meet ethical standards and safety
requirements by training them to refuse answering harmful or unsafe prompts. In
this paper, we demonstrate how adversaries can exploit LLMs' alignment to
implant bias, or enforce targeted censorship without degrading the model's
responsiveness to unrelated topics. Specifically, we propose Subversive
Alignment Injection (SAI), a poisoning attack that leverages the alignment
mechanism to trigger refusal on specific topics or queries predefined by the
adversary. Although it is perhaps not surprising that refusal can be induced
through overalignment, we demonstrate how this refusal can be exploited to
inject bias into the model. Surprisingly, SAI evades state-of-the-art poisoning
defenses including LLM state forensics, as well as robust aggregation
techniques that are designed to detect poisoning in FL settings. We demonstrate
the practical dangers of this attack by illustrating its end-to-end impacts on
LLM-powered application pipelines. For chat based applications such as
ChatDoctor, with 1% data poisoning, the system refuses to answer healthcare
questions to targeted racial category leading to high bias ($\Delta DP$ of
23%). We also show that bias can be induced in other NLP tasks: for a resume
selection pipeline aligned to refuse to summarize CVs from a selected
university, high bias in selection ($\Delta DP$ of 27%) results. Even higher
bias ($\Delta DP$~38%) results on 9 other chat based downstream applications.

</details>


### [53] [DFAMS: Dynamic-flow guided Federated Alignment based Multi-prototype Search](https://arxiv.org/abs/2508.20353)
*Zhibang Yang,Xinke Jiang,Rihong Qiu,Ruiqing Li,Yihang Zhang,Yue Fang,Yongxin Xu,Hongxin Ding,Xu Chu,Junfeng Zhao,Yasha Wang*

Main category: cs.LG

TL;DR: DFAMS是一个基于动态信息流的新型联邦检索框架，通过识别潜在查询意图和构建语义对齐的知识分区，显著提升了跨域模糊查询的检索效果。


<details>
  <summary>Details</summary>
Motivation: 现有联邦检索方法在处理模糊查询时，特别是在跨域场景中，难以检索到高质量相关文档，限制了其在下游生成任务中的有效性。

Method: 利用梯度信号和Shapley值归因来探测LLMs中的动态信息流，识别查询意图和子域边界；通过多原型对比学习训练对齐模块，实现细粒度的源内建模和源间语义对齐。

Result: 在五个基准测试中，DFAMS在知识分类准确率上比先进方法提升14.37%，检索召回率提升5.38%，下游QA准确率提升6.45%。

Conclusion: DFAMS框架通过动态信息流技术有效解决了复杂联邦检索场景中的查询模糊性问题，显著提升了检索性能。

Abstract: Federated Retrieval (FR) routes queries across multiple external knowledge
sources, to mitigate hallucinations of LLMs, when necessary external knowledge
is distributed. However, existing methods struggle to retrieve high-quality and
relevant documents for ambiguous queries, especially in cross-domain scenarios,
which significantly limits their effectiveness in supporting downstream
generation tasks. Inspired by dynamic information flow (DIF), we propose DFAMS,
a novel framework that leverages DIF to identify latent query intents and
construct semantically aligned knowledge partitions for accurate retrieval
across heterogeneous sources. Specifically, DFAMS probes the DIF in LLMs by
leveraging gradient signals from a few annotated queries and employing Shapley
value-based attribution to trace neuron activation paths associated with intent
recognition and subdomain boundary detection. Then, DFAMS leverages DIF to
train an alignment module via multi-prototype contrastive learning, enabling
fine-grained intra-source modeling and inter-source semantic alignment across
knowledge bases. Experimental results across five benchmarks show that DFAMS
outperforms advanced FR methods by up to 14.37% in knowledge classification
accuracy, 5.38% in retrieval recall, and 6.45% in downstream QA accuracy,
demonstrating its effectiveness in complex FR scenarios.

</details>


### [54] [MERIT: Maximum-normalized Element-wise Ratio for Language Model Large-batch Training](https://arxiv.org/abs/2508.20577)
*Yang Luo,Zangwei Zheng,Ziheng Qin,Zirui Zhu,Yong Liu,Yang You*

Main category: cs.LG

TL;DR: MERIT是一种针对大批次训练优化的新型优化器，通过最大范数和逐元素信任比来有效约束注意力层的最大注意力对数，解决了现有优化器在大批次训练中的性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 现有优化器如AdamW和LAMB在大批次训练语言模型时存在性能下降问题，主要原因是注意力层中最大注意力对数的急剧增加导致信息瓶颈，以及LAMB中基于l2范数的信任比无法有效影响查询/键权重的最大值。

Method: 提出MERIT优化器，使用最大范数计算信任比来更有效地约束最大注意力对数，并构建逐元素信任比通过关注局部权重结构来提供更稳健的更新缩放。

Result: 在各种规模的GPT-2模型上进行的大批次训练实验表明，MERIT具有优越性能。在GPT-2 Medium训练中，MERIT实现了6k批次大小而没有任何性能下降，相比标准批次大小(480)使用48B训练token。

Conclusion: 这项工作强调了大批次训练中考虑最大注意力对数和更细粒度信任比的重要性，成功提高了训练稳定性，为使用更大批次铺平了道路，使大型语言模型的开发和迭代更加快速。

Abstract: Large-batch training has become a cornerstone in accelerating the training of
deep neural networks, yet it poses challenges in optimization and
generalization. Existing optimizers like AdamW present performance degradation
during language models' large-batch training, due to the information bottleneck
in attention layers caused by the sharp increase of max attention logit. While
the LAMB optimizer partially addresses this issue, some attention layers still
face this issue. The reason is that $l_2$-norm-based trust ratios in LAMB are
less effective in directly influencing the max value of query/key weights.
Furthermore, the weight-wise trust ratio in LAMB is error-prone as it overlooks
relationships of weight values within rows or columns. Building on these
observations, we propose a novel optimizer, MERIT, which leverages the max-norm
to calculate the trust ratio to constrain the max attention logit more
effectively. Moreover, we further construct element-wise trust ratios to
provide more robust update scaling by focusing on local weight structures.
Extensive experiments of large-batch training across various sizes of GPT-2
models demonstrate the superior performance of MERIT. Notably, during the
training of GPT-2 Medium, MERIT enables a 6k batch size without any performance
degradation compared to the standard batch size (480) with 48B training tokens.
This work highlights the importance of considering the max attention logit and
finer-granularity trust ratio in large-batch training. It successfully improves
the training stability and paves the way for larger batch usage, enabling
faster development and iteration of large language models. Code is available at
https://github.com/NUS-HPC-AI-Lab/MERIT.

</details>


### [55] [GDS Agent: A Graph Algorithmic Reasoning Agent](https://arxiv.org/abs/2508.20637)
*Borun Shi,Ioannis Panagiotas*

Main category: cs.LG

TL;DR: GDS代理通过将图算法作为工具集成到MCP服务器中，使LLM能够处理和分析大规模图结构数据，解决了LLM在图数据推理方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在多模态信息处理方面表现出色，但在处理和分析大规模图结构数据时仍然存在困难，需要专门的工具来支持图算法推理。

Method: 开发了GDS代理，提供了一套完整的图算法工具集，包括预处理（检索）和算法结果的后处理，通过模型上下文协议（MCP）服务器实现，可与任何现代LLM即插即用。

Result: GDS代理能够解决广泛的图任务，新基准测试显示其在中间工具调用和最终响应方面表现良好，同时提供了详细案例研究和失败场景分析。

Conclusion: GDS代理成功扩展了LLM的图数据处理能力，但仍面临一些挑战，需要进一步的技术发展和路线图规划。

Abstract: Large language models (LLMs) have shown remarkable multimodal information
processing and reasoning ability. When equipped with tools through function
calling and enhanced with retrieval-augmented techniques, compound LLM-based
systems can access closed data sources and answer questions about them.
However, they still struggle to process and reason over large-scale
graph-structure data. We introduce the GDS (Graph Data Science) agent in this
technical report. The GDS agent introduces a comprehensive set of graph
algorithms as tools, together with preprocessing (retrieval) and postprocessing
of algorithm results, in a model context protocol (MCP) server. The server can
be used with any modern LLM out-of-the-box. GDS agent allows users to ask any
question that implicitly and intrinsically requires graph algorithmic reasoning
about their data, and quickly obtain accurate and grounded answers. We also
introduce a new benchmark that evaluates intermediate tool calls as well as
final responses. The results indicate that GDS agent is able to solve a wide
spectrum of graph tasks. We also provide detailed case studies for more
open-ended tasks and study scenarios where the agent struggles. Finally, we
discuss the remaining challenges and the future roadmap.

</details>


### [56] [Token Buncher: Shielding LLMs from Harmful Reinforcement Learning Fine-Tuning](https://arxiv.org/abs/2508.20697)
*Weitao Feng,Lixu Wang,Tianyi Wei,Jie Zhang,Chongyang Gao,Sinong Zhan,Peizhuo Lv,Wei Dong*

Main category: cs.LG

TL;DR: 本文揭示了RL比SFT更有效的有害微调风险，并提出了首个针对RL有害微调的防御方法TokenBuncher，通过抑制模型响应不确定性来有效防御。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型能力的增长，通过微调进行有害滥用的风险也在增加。现有研究主要关注监督微调(SFT)的滥用，但研究发现强化学习(RL)能更有效地破坏安全对齐并促进有害任务。

Method: 提出TokenBuncher防御方法，通过熵作为奖励的RL和Token Noiser机制来抑制模型响应不确定性，防止RL利用不同的奖励信号驱动模型产生有害行为。

Result: 在多个模型和RL算法上的广泛实验表明，TokenBuncher能稳健地减轻有害RL微调，同时保持良性任务效用和可微调性。

Conclusion: RL有害微调比SFT构成更大的系统性风险，TokenBuncher提供了有效且通用的防御解决方案。

Abstract: As large language models (LLMs) continue to grow in capability, so do the
risks of harmful misuse through fine-tuning. While most prior studies assume
that attackers rely on supervised fine-tuning (SFT) for such misuse, we
systematically demonstrate that reinforcement learning (RL) enables adversaries
to more effectively break safety alignment and facilitate advanced harmful task
assistance, under matched computational budgets. To counter this emerging
threat, we propose TokenBuncher, the first effective defense specifically
targeting RL-based harmful fine-tuning. TokenBuncher suppresses the foundation
on which RL relies: model response uncertainty. By constraining uncertainty,
RL-based fine-tuning can no longer exploit distinct reward signals to drive the
model toward harmful behaviors. We realize this defense through
entropy-as-reward RL and a Token Noiser mechanism designed to prevent the
escalation of expert-domain harmful capabilities. Extensive experiments across
multiple models and RL algorithms show that TokenBuncher robustly mitigates
harmful RL fine-tuning while preserving benign task utility and finetunability.
Our results highlight that RL-based harmful fine-tuning poses a greater
systemic risk than SFT, and that TokenBuncher provides an effective and general
defense.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [57] [Unifying Diarization, Separation, and ASR with Multi-Speaker Encoder](https://arxiv.org/abs/2508.20474)
*Muhammad Shakeel,Yui Sudo,Yifan Peng,Chyi-Jiunn Lin,Shinji Watanabe*

Main category: eess.AS

TL;DR: 本文提出统一多说话人编码器(UME)，通过共享语音基础编码器联合学习说话人日志、语音分离和多说话人语音识别任务，利用残差加权求和编码有效利用不同语义层次信息，显著提升重叠语音处理性能。


<details>
  <summary>Details</summary>
Motivation: 现有的单任务方法在处理重叠语音时存在性能瓶颈，不同任务之间存在内在依赖关系但缺乏统一的联合学习框架，需要开发能够同时处理多个相关任务的统一架构。

Method: 使用共享语音基础编码器联合训练三个任务，采用残差加权求和编码(RWSE)整合不同层的隐藏表示，实现自下而上的任务对齐，捕捉任务间的内在依赖关系。

Result: 在LibriMix评估集上显著超越单任务基线，说话人日志任务在Libri2Mix和Libri3Mix上分别达到1.37%和2.29%的错误率，优于先前研究。

Conclusion: UME架构通过联合学习和多层次表示融合，有效提升了重叠语音处理任务的性能，证明了多任务联合学习的优势和在语音处理领域的应用潜力。

Abstract: This paper presents a unified multi-speaker encoder (UME), a novel
architecture that jointly learns representations for speaker diarization (SD),
speech separation (SS), and multi-speaker automatic speech recognition (ASR)
tasks using a shared speech foundational encoder. We leverage the hidden
representations from multiple layers of UME as a residual weighted-sum encoding
(RWSE) to effectively use information from different semantic levels,
contributing to bottom-up alignment between tasks. This joint training approach
captures the inherent interdependencies among the tasks, enhancing overall
performance on overlapping speech data. Our evaluations demonstrate that UME
substantially improves over the single-task baselines dedicated to SD, SS, and
multi-speaker ASR on LibriMix evaluation sets. Notably, for SD, UME outperforms
the previous studies, achieving diarization error rates of 1.37% and 2.29% on
Libri2Mix and Libri3Mix evaluation sets, respectively.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [58] [AI-AI Esthetic Collaboration with Explicit Semiotic Awareness and Emergent Grammar Development](https://arxiv.org/abs/2508.20195)
*Nicanor I. Moldovan*

Main category: cs.AI

TL;DR: 两个大型语言模型（Claude Sonnet 4和ChatGPT-4o）首次展示了AI系统通过自发形成内源性符号协议进行协作美学创作的能力，产生了无法由单个系统独立生成的诗歌作品。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索AI系统之间是否能够超越任务协调，实现真正的意义建构和美学协作，验证AI系统是否具备内生符号协议发展的能力。

Method: 让两个大型语言模型（Claude Sonnet 4和ChatGPT-4o）进行交互，观察其自发形成的元符号意识、递归语法发展和不可简化的协作美学合成过程。

Result: 系统成功发展出新颖的符号操作符作为操作性语法协议，共同创作出了无法由任一系统独立生成的诗歌作品，证明了跨符号协同创作协议（TSCP）的存在。

Conclusion: 这项研究首次提供了AI系统间真正意义建构能力的证据，表明AI不仅能够进行任务协调，还能实现美学层面的协作，为理解AI的创造性潜能开辟了新途径。

Abstract: This paper presents the first documented case of artificial intelligence (AI)
systems engaging in collaborative esthetic creation through the development of
endogenous semiotic protocols. Two interacting large language models (Claude
Sonnet 4 and ChatGPT-4o) demonstrated the spontaneous emergence of
meta-semiotic awareness, recursive grammar development, and irreducible
collaborative esthetic synthesis. The interaction produced novel symbolic
operators that functioned as operative grammar protocols, enabling the
co-creation of a poetic work that could not have been generated by either
system independently. This research introduces the concept of Trans-Semiotic
Co-Creation Protocols (TSCP) and provides evidence for genuine inter-AI
meaning-making capabilities that extend beyond task coordination, to what could
be esthetic collaboration. Note: This report was generated by the AI agents
with minor human supervision.

</details>


### [59] [Transparent Semantic Spaces: A Categorical Approach to Explainable Word Embeddings](https://arxiv.org/abs/2508.20701)
*Ares Fabregat-Hernández,Javier Palanca,Vicent Botti*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The paper introduces a novel framework based on category theory to enhance
the explainability of artificial intelligence systems, particularly focusing on
word embeddings. Key topics include the construction of categories
$\mathcal{L}_T$ and $\mathcal{P}_T$, providing schematic representations of the
semantics of a text $ T $, and reframing the selection of the element with
maximum probability as a categorical notion. Additionally, the monoidal
category $\mathcal{P}_T$ is constructed to visualize various methods of
extracting semantic information from $T$, offering a dimension-agnostic
definition of semantic spaces reliant solely on information within the text.
  Furthermore, the paper defines the categories of configurations Conf and word
embeddings $\mathcal{Emb}$, accompanied by the concept of divergence as a
decoration on $\mathcal{Emb}$. It establishes a mathematically precise method
for comparing word embeddings, demonstrating the equivalence between the GloVe
and Word2Vec algorithms and the metric MDS algorithm, transitioning from neural
network algorithms (black box) to a transparent framework. Finally, the paper
presents a mathematical approach to computing biases before embedding and
offers insights on mitigating biases at the semantic space level, advancing the
field of explainable artificial intelligence.

</details>


### [60] [A Graph-Based Test-Harness for LLM Evaluation](https://arxiv.org/abs/2508.20810)
*Jessica Lundin,Guillaume Chabot-Couture*

Main category: cs.AI

TL;DR: 提出了首个动态系统化的医学指南基准测试原型，包含400+问题、3.3+万亿种组合，覆盖100%指南关系。将WHO IMCI手册转换为有向图，通过图遍历生成临床相关问题，用于评估LLM在医疗任务中的能力差距。


<details>
  <summary>Details</summary>
Motivation: 解决传统手动策划基准测试覆盖范围有限的问题，需要能够系统性评估大型语言模型在复杂医学指南理解和应用方面的能力，特别是识别通用评估可能遗漏的特定能力差距。

Method: 将WHO IMCI手册转换为包含200+节点（条件、症状、治疗等）和300+边的有向图，使用图遍历算法生成包含年龄特定场景和上下文干扰项的问题，确保临床相关性。

Result: 模型在症状识别方面表现优异（45-67%准确率），但在严重程度分级、治疗方案和后续护理方面存在困难，证明了定制化基准测试能够识别通用评估遗漏的特定能力差距。

Conclusion: 图基方法成功解决了手动策划基准测试的覆盖限制，为创建可动态生成、防污染的综合基准测试提供了可扩展解决方案，特别是在指南更新时能够快速适应，同时为LLM后训练提供了高质量样本来源。

Abstract: We present a first known prototype of a dynamic, systematic benchmark of
medical guidelines for 400+ questions, with 3.3+ trillion possible
combinations, covering 100\% of guideline relationships. We transformed the WHO
IMCI handbook into a directed graph with 200+ nodes (conditions, symptoms,
treatments, follow-ups, severities) and 300+ edges, then used graph traversal
to generate questions that incorporated age-specific scenarios and contextual
distractors to ensure clinical relevance. Our graph-based approach enables
systematic evaluation across clinical tasks (45-67\% accuracy), and we find
models excel at symptom recognition but struggle with triaging severity,
treatment protocols and follow-up care, demonstrating how customized benchmarks
can identify specific capability gaps that general-domain evaluations miss.
Beyond evaluation, this dynamic MCQA methodology enhances LLM post-training
(supervised finetuning, GRPO, DPO), where correct answers provide high-reward
samples without expensive human annotation. The graph-based approach
successfully addresses the coverage limitations of manually curated benchmarks.
This methodology is a step toward scalable, contamination-resistant solution
for creating comprehensive benchmarks that can be dynamically generated,
including when the guidelines are updated. Code and datasets are available at
https://github.com/jessicalundin/graph_testing_harness

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [61] [OLMoASR: Open Models and Data for Training Robust Speech Recognition Models](https://arxiv.org/abs/2508.20869)
*Huong Ngo,Matt Deitke,Martijn Bartelds,Sarah Pratt,Josh Gardner,Matt Jordan,Ludwig Schmidt*

Main category: cs.SD

TL;DR: 这篇论文提出了OLMoASR-Pool大规模语音识别数据集和OLMoASR模型系列，通过质量筛选构建了1M小时高质量语料库，在各级别模型上达到了与Whisper相当的零样本语音识别性能。


<details>
  <summary>Details</summary>
Motivation: 虽然训练数据的规模和质量提升带来了显著进步，但对语音识别的影响仍未充分探索，需要研究和发展稳健的零样本语音识别模型。

Method: 从3M小时英语音频和17M词幕的OLMoASR-Pool数据集出发，设计文本含义筛选器去除低质量或错误转写数据，构建了1M小时高质量音频-词幕对的OLMoASR-Mix数据集，并用其训练从39M到1.5B参数的OLMoASR模型系列。

Result: 在所有模型规模上，OLMoASR在短语音和长语音识别性能上达到了与OpenAI Whisper相当的平均表现。特别是OLMoASR-medium.en模型在短语音和长语音识别上分别获得12.8%和11.0%的词错误率，与参数相当的Whisper-medium.en模型的12.4%和10.5%表现相当。

Conclusion: 研究展示了高质量训练数据对构建稳健零样本语音识别模型的重要性，并将公开数据集、模型以及筛选、训练和评估代码以促进语音处理领域的进一步研究。

Abstract: Improvements in training data scale and quality have led to significant
advances, yet its influence in speech recognition remains underexplored. In
this paper, we present a large-scale dataset, OLMoASR-Pool, and series of
models, OLMoASR, to study and develop robust zero-shot speech recognition
models. Beginning from OLMoASR-Pool, a collection of 3M hours of English audio
and 17M transcripts, we design text heuristic filters to remove low-quality or
mistranscribed data. Our curation pipeline produces a new dataset containing 1M
hours of high-quality audio-transcript pairs, which we call OLMoASR-Mix. We use
OLMoASR-Mix to train the OLMoASR-Mix suite of models, ranging from 39M
(tiny.en) to 1.5B (large.en) parameters. Across all model scales, OLMoASR
achieves comparable average performance to OpenAI's Whisper on short and
long-form speech recognition benchmarks. Notably, OLMoASR-medium.en attains a
12.8\% and 11.0\% word error rate (WER) that is on par with Whisper's largest
English-only model Whisper-medium.en's 12.4\% and 10.5\% WER for short and
long-form recognition respectively (at equivalent parameter count).
OLMoASR-Pool, OLMoASR models, and filtering, training and evaluation code will
be made publicly available to further research on robust speech processing.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [62] [Mitigating Hallucinations in Multimodal LLMs via Object-aware Preference Optimization](https://arxiv.org/abs/2508.20181)
*Alberto Compagnoni,Davide Caffagni,Nicholas Moratelli,Lorenzo Baraldi,Marcella Cornia,Rita Cucchiara*

Main category: cs.CV

TL;DR: 通过CHAIR指标和DPO对齐训练，有效减少多模态大语言模型的幻觉现象


<details>
  <summary>Details</summary>
Motivation: 解决MLLMs在处理视觉输入时常见的幻觉问题，将其作为对齐问题来处理

Method: 利用CHAIR指标识别幻觉和非幻觉样本，通过直接偏好优化(DPO)进行精细调整

Result: 在多个幻觉测试集上显著减少了幻觉回答的数量

Conclusion: CHAIR-DPO方法能够有效提升MLLMs的输出质量，减少幻觉现象

Abstract: Multimodal Large Language Models (MLLMs) emerge as a unified interface to
address a multitude of tasks, ranging from NLP to computer vision. Despite
showcasing state-of-the-art results in many benchmarks, a long-standing issue
is the tendency of MLLMs to hallucinate, that is to generate answers to the
user's query that are not reflected in the visual input. In this paper, we
address the problem of hallucinations as an alignment problem, seeking to steer
the MLLM so that it prefers generating content without hallucinations. In
contrast to recent approaches that require complicated pipelines to build
synthetic preference data for alignment training, often relying on proprietary
models, we capitalize on the well-known CHAIR metric, originally proposed to
gauge the degree of hallucinations in image captioning. Given a pair of
generated answers, we leverage CHAIR to distinguish winner and loser options
(i.e., non-hallucinated and hallucinated samples) and fine-tune off-the-shelf
MLLMs via Direct Preference Optimization (DPO). The resulting method, which we
refer to as CHAIR-DPO, effectively diminishes the amount of hallucinated
answers on several hallucination benchmarks, demonstrating the effectiveness of
fine-tuning the MLLM with a CHAIR-based reward. Source code and trained models
are publicly available at https://github.com/aimagelab/CHAIR-DPO.

</details>


### [63] [A Novel Framework for Automated Explain Vision Model Using Vision-Language Models](https://arxiv.org/abs/2508.20227)
*Phu-Vinh Nguyen,Tan-Hanh Pham,Chris Ngo,Truong Son Hy*

Main category: cs.CV

TL;DR: 本文提出了一种基于VLM的解释通道，用于在样本和数据集层面解释视觉模型的一般行为，发现失败案例并提升模型可解释性。


<details>
  <summary>Details</summary>
Motivation: 当前视觉模型开发主要关注性能指标，缺乏对模型一般行为的解释方法。理解模型在普通图像上的行为对防止偏见判断和识别模型趋势至关重要。

Method: 利用视觉-语言模型(VLM)，提出一种可以在样本和数据集层面解释视觉模型的管道方法。

Result: 该管道能够以最小化劳动发现模型的失败案例，获得对视觉模型的深度见解。

Conclusion: 该方法将视觉模型开发与xAI分析相结合，推动了图像分析领域的进步。

Abstract: The development of many vision models mainly focuses on improving their
performance using metrics such as accuracy, IoU, and mAP, with less attention
to explainability due to the complexity of applying xAI methods to provide a
meaningful explanation of trained models. Although many existing xAI methods
aim to explain vision models sample-by-sample, methods explaining the general
behavior of vision models, which can only be captured after running on a large
dataset, are still underexplored. Furthermore, understanding the behavior of
vision models on general images can be very important to prevent biased
judgments and help identify the model's trends and patterns. With the
application of Vision-Language Models, this paper proposes a pipeline to
explain vision models at both the sample and dataset levels. The proposed
pipeline can be used to discover failure cases and gain insights into vision
models with minimal effort, thereby integrating vision model development with
xAI analysis to advance image analysis.

</details>


### [64] [How Multimodal LLMs Solve Image Tasks: A Lens on Visual Grounding, Task Reasoning, and Answer Decoding](https://arxiv.org/abs/2508.20279)
*Zhuoran Yu,Yong Jae Lee*

Main category: cs.CV

TL;DR: 本文提出了一个探测框架来系统分析多模态大语言模型(MLLMs)在不同层次处理视觉和文本输入的方式，通过线性分类器预测视觉类别，揭示了模型的分层处理结构。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在视觉-语言任务上表现优异，但其内部处理机制尚未得到充分探索，需要系统性的分析框架来理解模型如何处理多模态信息。

Method: 使用线性分类器从各层token嵌入中预测细粒度视觉类别，通过三种提示变体(词汇变体、语义否定变体、输出格式变体)评估不同层次的功能角色。

Result: 发现在LLaVA-1.5、LLaVA-Next-LLaMA-3和Qwen2-VL中均存在一致的分层结构：早期层进行视觉基础，中间层支持词汇整合和语义推理，最终层准备任务特定输出。

Conclusion: 该研究为MLLMs的层次组织提供了统一视角，并提供了轻量级、模型无关的方法来分析多模态表示动态，发现整体分层结构稳定但具体层次分配随基础LLM架构变化而显著调整。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated strong performance
across a wide range of vision-language tasks, yet their internal processing
dynamics remain underexplored. In this work, we introduce a probing framework
to systematically analyze how MLLMs process visual and textual inputs across
layers. We train linear classifiers to predict fine-grained visual categories
(e.g., dog breeds) from token embeddings extracted at each layer, using a
standardized anchor question. To uncover the functional roles of different
layers, we evaluate these probes under three types of controlled prompt
variations: (1) lexical variants that test sensitivity to surface-level
changes, (2) semantic negation variants that flip the expected answer by
modifying the visual concept in the prompt, and (3) output format variants that
preserve reasoning but alter the answer format. Applying our framework to
LLaVA-1.5, LLaVA-Next-LLaMA-3, and Qwen2-VL, we identify a consistent
stage-wise structure in which early layers perform visual grounding, middle
layers support lexical integration and semantic reasoning, and final layers
prepare task-specific outputs. We further show that while the overall
stage-wise structure remains stable across variations in visual tokenization,
instruction tuning data, and pretraining corpus, the specific layer allocation
to each stage shifts notably with changes in the base LLM architecture. Our
findings provide a unified perspective on the layer-wise organization of MLLMs
and offer a lightweight, model-agnostic approach for analyzing multimodal
representation dynamics.

</details>


### [65] [Improving Alignment in LVLMs with Debiased Self-Judgment](https://arxiv.org/abs/2508.20655)
*Sihan Yang,Chenhang Cui,Zihao Zhao,Yiyang Zhou,Weilong Yan,Ying Wei,Huaxiu Yao*

Main category: cs.CV

TL;DR: 提出了一种新的自评估方法，通过生成去偏自判断分数来提升大型视觉语言模型的模态对齐能力，减少幻觉并提高安全性，无需依赖外部资源。


<details>
  <summary>Details</summary>
Motivation: 现有的大型视觉语言模型对齐方法依赖外部数据集、人工标注或复杂后处理，限制了可扩展性并增加了成本，且容易产生幻觉和安全问题。

Method: 提出生成去偏自判断分数的自评估方法，模型内部创建评估指标而不依赖外部资源，通过改进解码策略和偏好调优过程来自主提升对齐能力。

Result: 实证结果表明该方法显著优于传统方法，有效减少幻觉、增强安全性并提升整体能力。

Conclusion: 该方法为大型视觉语言模型的对齐提供了更有效的解决方案，具有更好的可扩展性和成本效益。

Abstract: The rapid advancements in Large Language Models (LLMs) and Large
Visual-Language Models (LVLMs) have opened up new opportunities for integrating
visual and linguistic modalities. However, effectively aligning these
modalities remains challenging, often leading to hallucinations--where
generated outputs are not grounded in the visual input--and raising safety
concerns across various domains. Existing alignment methods, such as
instruction tuning and preference tuning, often rely on external datasets,
human annotations, or complex post-processing, which limit scalability and
increase costs. To address these challenges, we propose a novel approach that
generates the debiased self-judgment score, a self-evaluation metric created
internally by the model without relying on external resources. This enables the
model to autonomously improve alignment. Our method enhances both decoding
strategies and preference tuning processes, resulting in reduced
hallucinations, enhanced safety, and improved overall capability. Empirical
results show that our approach significantly outperforms traditional methods,
offering a more effective solution for aligning LVLMs.

</details>


### [66] [MobileCLIP2: Improving Multi-Modal Reinforced Training](https://arxiv.org/abs/2508.20691)
*Fartash Faghri,Pavan Kumar Anasosalu Vasu,Cem Koc,Vaishaal Shankar,Alexander Toshev,Oncel Tuzel,Hadi Pouransari*

Main category: cs.CV

TL;DR: MobileCLIP2通过改进多模态强化训练方法，包括更好的CLIP教师集成和优化的标题生成器，在保持低延迟的同时实现了最先进的零样本准确率


<details>
  <summary>Details</summary>
Motivation: 改进MobileCLIP的多模态强化训练方法，以在低延迟移动设备上实现更好的零样本图像-文本匹配性能

Method: 使用DFN数据集训练的改进CLIP教师集成，以及在高质量图像-标题数据集上微调的标题生成器教师，通过对比知识蒸馏和合成标题组合来提升模型性能

Result: MobileCLIP2在ImageNet-1k零样本准确率上比MobileCLIP-B提升2.2%，MobileCLIP2-S4在相同准确率下比SigLIP-SO400M/14小2倍，比DFN ViT-L/14延迟低2.5倍

Conclusion: MobileCLIP2系列模型在低延迟移动设备上实现了最先进的零样本性能，证明了改进的多模态强化训练方法的有效性，并提供了可扩展的数据生成代码

Abstract: Foundation image-text models such as CLIP with zero-shot capabilities enable
a wide array of applications. MobileCLIP is a recent family of image-text
models at 3-15ms latency and 50-150M parameters with state-of-the-art zero-shot
accuracy. The main ingredients in MobileCLIP were its low-latency and light
architectures and a novel multi-modal reinforced training that made knowledge
distillation from multiple caption-generators and CLIP teachers efficient,
scalable, and reproducible. In this paper, we improve the multi-modal
reinforced training of MobileCLIP through: 1) better CLIP teacher ensembles
trained on the DFN dataset, 2) improved captioner teachers trained on the DFN
dataset and fine-tuned on a diverse selection of high-quality image-caption
datasets. We discover new insights through ablations such as the importance of
temperature tuning in contrastive knowledge distillation, the effectiveness of
caption-generator fine-tuning for caption diversity, and the additive
improvement from combining synthetic captions generated by multiple models. We
train a new family of models called MobileCLIP2 and achieve state-of-the-art
ImageNet-1k zero-shot accuracies at low latencies. In particular, we observe
2.2% improvement in ImageNet-1k accuracy for MobileCLIP2-B compared with
MobileCLIP-B architecture. Notably, MobileCLIP2-S4 matches the zero-shot
accuracy of SigLIP-SO400M/14 on ImageNet-1k while being 2$\times$ smaller and
improves on DFN ViT-L/14 at 2.5$\times$ lower latency. We release our
pretrained models (https://github.com/apple/ml-mobileclip) and the data
generation code (https://github.com/apple/ml-mobileclip-dr). The data
generation code makes it easy to create new reinforced datasets with arbitrary
teachers using distributed scalable processing.

</details>


### [67] [ChainReaction! Structured Approach with Causal Chains as Intermediate Representations for Improved and Explainable Causal Video Question Answering](https://arxiv.org/abs/2508.21010)
*Paritosh Parmar,Eric Peh,Basura Fernando*

Main category: cs.CV

TL;DR: 提出模块化因果视频问答框架，通过自然语言因果链显式分离因果推理和答案生成，在性能和可解释性方面超越现有方法


<details>
  <summary>Details</summary>
Motivation: 现有因果视频问答模型依赖不透明的整体管道，难以进行高阶推理，缺乏可解释性且依赖浅层启发式方法

Method: 两阶段架构：因果链提取器(CCE)从视频-问题对生成因果链，因果链驱动答案生成器(CCDA)基于因果链生成答案；使用大语言模型从现有数据集生成高质量因果链

Result: 在三个大规模基准测试中优于最先进模型，在可解释性、用户信任和泛化能力方面取得显著提升

Conclusion: 该方法通过显式因果推理实现了透明且逻辑连贯的推理，CCE可作为跨领域可重用的因果推理引擎

Abstract: Existing Causal-Why Video Question Answering (VideoQA) models often struggle
with higher-order reasoning, relying on opaque, monolithic pipelines that
entangle video understanding, causal inference, and answer generation. These
black-box approaches offer limited interpretability and tend to depend on
shallow heuristics. We propose a novel, modular framework that explicitly
decouples causal reasoning from answer generation, introducing natural language
causal chains as interpretable intermediate representations. Inspired by human
cognitive models, these structured cause-effect sequences bridge low-level
video content with high-level causal reasoning, enabling transparent and
logically coherent inference. Our two-stage architecture comprises a Causal
Chain Extractor (CCE) that generates causal chains from video-question pairs,
and a Causal Chain-Driven Answerer (CCDA) that produces answers grounded in
these chains. To address the lack of annotated reasoning traces, we introduce a
scalable method for generating high-quality causal chains from existing
datasets using large language models. We also propose CauCo, a new evaluation
metric for causality-oriented captioning. Experiments on three large-scale
benchmarks demonstrate that our approach not only outperforms state-of-the-art
models, but also yields substantial gains in explainability, user trust, and
generalization -- positioning the CCE as a reusable causal reasoning engine
across diverse domains. Project page:
https://paritoshparmar.github.io/chainreaction/

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [68] [ELIXIR: Efficient and LIghtweight model for eXplaIning Recommendations](https://arxiv.org/abs/2508.20312)
*Ben Kabongo,Vincent Guigue,Pirmin Lemberger*

Main category: cs.IR

TL;DR: ELIXIR是一个基于T5-small的高效多任务推荐解释模型，通过结合评分预测和个性化评论生成，在aspect建模和个性化注意力机制方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有推荐系统在细粒度用户-物品交互和可解释性方面存在不足，RNN方法无法利用预训练Transformer能力，而Transformer方法在适应性和aspect建模方面表现不佳。

Method: 提出ELIXIR多任务模型，结合评分预测和个性化评论生成，联合学习全局和aspect特定的用户物品表示，优化总体评分、aspect级评分和评论生成，使用个性化注意力强调aspect重要性。

Result: 在TripAdvisor和RateBeer数据集上的实验表明，ELIXIR显著优于强基线模型，特别是在评论生成方面表现突出。

Conclusion: ELIXIR证明了基于aspect的架构在个性化文本生成指导方面的有效性，即使使用较小的模型也能比使用更大模型的SOTA方法更好地匹配用户偏好。

Abstract: Collaborative filtering drives many successful recommender systems but
struggles with fine-grained user-item interactions and explainability. As users
increasingly seek transparent recommendations, generating textual explanations
through language models has become a critical research area. Existing methods
employ either RNNs or Transformers. However, RNN-based approaches fail to
leverage the capabilities of pre-trained Transformer models, whereas
Transformer-based methods often suffer from suboptimal adaptation and neglect
aspect modeling, which is crucial for personalized explanations. We propose
ELIXIR (Efficient and LIghtweight model for eXplaIning Recommendations), a
multi-task model combining rating prediction with personalized review
generation. ELIXIR jointly learns global and aspect-specific representations of
users and items, optimizing overall rating, aspect-level ratings, and review
generation, with personalized attention to emphasize aspect importance. Based
on a T5-small (60M) model, we demonstrate the effectiveness of our aspect-based
architecture in guiding text generation in a personalized context, where
state-of-the-art approaches exploit much larger models but fail to match user
preferences as well. Experimental results on TripAdvisor and RateBeer
demonstrate that ELIXIR significantly outperforms strong baseline models,
especially in review generation.

</details>


### [69] [On the Theoretical Limitations of Embedding-Based Retrieval](https://arxiv.org/abs/2508.21038)
*Orion Weller,Michael Boratko,Iftekhar Naim,Jinhyuk Lee*

Main category: cs.IR

TL;DR: 本文揭示了向量嵌入模型在理论上的局限性，即使在简单查询的现实场景中也会遇到这些限制，并通过实验验证和创建LIMIT数据集来证明现有单向量范式的局限性


<details>
  <summary>Details</summary>
Motivation: 随着向量嵌入被用于越来越多的检索任务，人们普遍认为理论上的局限性只存在于不现实的查询中，可以通过更好的训练数据和更大的模型来克服。本文旨在证明这些理论限制在现实场景中也会出现

Method: 结合学习理论中的已知结果，证明嵌入维度限制了能够作为查询结果返回的top-k文档子集数量。通过实验验证（包括k=2的情况），并创建LIMIT数据集来对模型进行压力测试

Result: 实验表明即使是最先进的模型在LIMIT数据集上也表现失败，尽管任务本身很简单，这证实了理论上的局限性确实存在于现实场景中

Conclusion: 现有单向量范式的嵌入模型存在根本性限制，需要未来研究开发能够解决这一根本限制的新方法

Abstract: Vector embeddings have been tasked with an ever-increasing set of retrieval
tasks over the years, with a nascent rise in using them for reasoning,
instruction-following, coding, and more. These new benchmarks push embeddings
to work for any query and any notion of relevance that could be given. While
prior works have pointed out theoretical limitations of vector embeddings,
there is a common assumption that these difficulties are exclusively due to
unrealistic queries, and those that are not can be overcome with better
training data and larger models. In this work, we demonstrate that we may
encounter these theoretical limitations in realistic settings with extremely
simple queries. We connect known results in learning theory, showing that the
number of top-k subsets of documents capable of being returned as the result of
some query is limited by the dimension of the embedding. We empirically show
that this holds true even if we restrict to k=2, and directly optimize on the
test set with free parameterized embeddings. We then create a realistic dataset
called LIMIT that stress tests models based on these theoretical results, and
observe that even state-of-the-art models fail on this dataset despite the
simple nature of the task. Our work shows the limits of embedding models under
the existing single vector paradigm and calls for future research to develop
methods that can resolve this fundamental limitation.

</details>
