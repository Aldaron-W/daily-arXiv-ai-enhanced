<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 47]
- [cs.LG](#cs.LG) [Total: 6]
- [cs.IR](#cs.IR) [Total: 2]
- [cs.CR](#cs.CR) [Total: 1]
- [cs.AI](#cs.AI) [Total: 3]
- [eess.AS](#eess.AS) [Total: 1]
- [q-bio.NC](#q-bio.NC) [Total: 1]
- [cs.DL](#cs.DL) [Total: 1]
- [cs.SD](#cs.SD) [Total: 1]
- [cs.CV](#cs.CV) [Total: 6]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Social Bias in Multilingual Language Models: A Survey](https://arxiv.org/abs/2508.20201)
*Lance Calvin Lim Gamboa,Yue Feng,Mark Lee*

Main category: cs.CL

TL;DR: 这篇系统综述分析了多语言预训练模型中的社会偏见研究，发现这些模型存在与英语模型相似的偏见问题，并探讨了跨语言和文化背景下的偏见评估与缓解方法。


<details>
  <summary>Details</summary>
Motivation: 预训练多语言模型在处理非英语文本时表现出与英语模型相同的社会偏见，需要系统研究如何将这些偏见评估和缓解方法扩展到多语言和非英语语境中。

Method: 通过系统综述的方法，分析现有研究在语言多样性、文化意识、评估指标选择以及缓解技术应用方面的表现，识别领域中的方法论差距。

Result: 研究发现该领域存在方法论设计选择上的差距（如偏好某些语言、多语言缓解实验稀缺），同时整理了跨语言和文化适应偏见基准时的常见问题和解决方案。

Conclusion: 基于研究发现，提出了未来研究方向，以增强多语言偏见研究的包容性、跨文化适当性，并与最先进的NLP进展保持一致。

Abstract: Pretrained multilingual models exhibit the same social bias as models
processing English texts. This systematic review analyzes emerging research
that extends bias evaluation and mitigation approaches into multilingual and
non-English contexts. We examine these studies with respect to linguistic
diversity, cultural awareness, and their choice of evaluation metrics and
mitigation techniques. Our survey illuminates gaps in the field's dominant
methodological design choices (e.g., preference for certain languages, scarcity
of multilingual mitigation experiments) while cataloging common issues
encountered and solutions implemented in adapting bias benchmarks across
languages and cultures. Drawing from the implications of our findings, we chart
directions for future research that can reinforce the multilingual bias
literature's inclusivity, cross-cultural appropriateness, and alignment with
state-of-the-art NLP advancements.

</details>


### [2] [Prompting Strategies for Language Model-Based Item Generation in K-12 Education: Bridging the Gap Between Small and Large Language Models](https://arxiv.org/abs/2508.20217)
*Mohammad Amini,Babak Ahmadi,Xiaomeng Xiong,Yilin Zhang,Christopher Qiao*

Main category: cs.CL

TL;DR: 本研究探索使用语言模型自动生成形态学评估的多项选择题，通过结构化提示策略和微调技术提升中等规模模型的性能，为K-12教育提供可扩展的评估项目开发方案。


<details>
  <summary>Details</summary>
Motivation: 降低人工测试开发成本和不一致性，探索在有限数据条件下如何通过提示工程和模型优化来实现有效的自动题目生成。

Method: 采用两阶段方法：比较微调的中等模型(Gemma 2B)与未调优的大模型(GPT-3.5 175B)；评估七种结构化提示策略，包括零样本、少样本、思维链、基于角色、顺序设计等组合。使用自动化指标和专家评分进行多维度评估，并利用GPT-4.1模拟大规模人工评分。

Result: 结构化提示策略（特别是思维链与顺序设计组合）显著提升Gemma的输出质量。Gemma生成的题目比GPT-3.5的零样本响应更符合构念对齐和教学适宜性，提示设计对中等规模模型性能起关键作用。

Conclusion: 结构化提示和高效微调可在有限数据条件下增强中等规模模型的自动生成能力。结合自动化指标、专家判断和大模型模拟的方法能确保评估目标的对齐，为K-12语言评估项目开发提供实用且可扩展的工作流程。

Abstract: This study explores automatic generation (AIG) using language models to
create multiple choice questions (MCQs) for morphological assessment, aiming to
reduce the cost and inconsistency of manual test development. The study used a
two-fold approach. First, we compared a fine-tuned medium model (Gemma, 2B)
with a larger untuned one (GPT-3.5, 175B). Second, we evaluated seven
structured prompting strategies, including zero-shot, few-shot,
chain-of-thought, role-based, sequential, and combinations. Generated items
were assessed using automated metrics and expert scoring across five
dimensions. We also used GPT-4.1, trained on expert-rated samples, to simulate
human scoring at scale. Results show that structured prompting, especially
strategies combining chain-of-thought and sequential design, significantly
improved Gemma's outputs. Gemma generally produced more construct-aligned and
instructionally appropriate items than GPT-3.5's zero-shot responses, with
prompt design playing a key role in mid-size model performance. This study
demonstrates that structured prompting and efficient fine-tuning can enhance
midsized models for AIG under limited data conditions. We highlight the value
of combining automated metrics, expert judgment, and large-model simulation to
ensure alignment with assessment goals. The proposed workflow offers a
practical and scalable way to develop and validate language assessment items
for K-12.

</details>


### [3] [Integrating SystemC TLM into FMI 3.0 Co-Simulations with an Open-Source Approach](https://arxiv.org/abs/2508.20223)
*Andrei Mihai Albu,Giovanni Pollo,Alessio Burrello,Daniele Jahier Pagliari,Cristian Tesconi,Alessandra Neri,Dario Soldi,Fabio Autieri,Sara Vinco*

Main category: cs.CL

TL;DR: 提出了一种将SystemC TLM模型集成到FMI协同仿真工作流的开源方法，通过将SystemC组件封装为FMI 3.0 FMU实现跨域集成


<details>
  <summary>Details</summary>
Motivation: 随着信息物理系统复杂度的增加，特别是汽车应用中，需要高效的建模和跨域协同仿真技术。SystemC TLM虽然支持硬件/软件协同设计，但与其他工程领域模型的互操作性有限

Method: 开发了完全开源的解决方案，将SystemC TLM组件封装为FMI 3.0协同仿真功能模型单元(FMU)，提供轻量级工具链，解决了时间同步和数据交换等关键技术挑战

Result: 通过代表性案例研究证明了该集成方法的可行性和有效性

Conclusion: 该方法实现了SystemC TLM模型与FMI标准协同仿真工作流的无缝集成，为异构仿真环境提供了标准化集成方案

Abstract: The growing complexity of cyber-physical systems, particularly in automotive
applications, has increased the demand for efficient modeling and cross-domain
co-simulation techniques. While SystemC Transaction-Level Modeling (TLM)
enables effective hardware/software co-design, its limited interoperability
with models from other engineering domains poses integration challenges. This
paper presents a fully open-source methodology for integrating SystemC TLM
models into Functional Mock-up Interface (FMI)-based co-simulation workflows.
By encapsulating SystemC TLM components as FMI 3.0 Co Simulation Functional
Mock-up Units (FMUs), the proposed approach facilitates seamless, standardized
integration across heterogeneous simulation environments. We introduce a
lightweight open-source toolchain, address key technical challenges such as
time synchronization and data exchange, and demonstrate the feasibility and
effectiveness of the integration through representative case studies.

</details>


### [4] [Can Compact Language Models Search Like Agents? Distillation-Guided Policy Optimization for Preserving Agentic RAG Capabilities](https://arxiv.org/abs/2508.20324)
*Rikuto Kotoge,Mai Nishimura,Jiaxin Ma*

Main category: cs.CL

TL;DR: DGPO通过教师演示的冷启动初始化和持续教师指导，解决了小型语言模型在强化学习训练中奖励稀疏和不稳定的问题，使紧凑模型能够实现复杂的智能搜索行为。


<details>
  <summary>Details</summary>
Motivation: 紧凑语言模型（如0.5B参数）由于推理能力较差，在强化学习训练中面临奖励稀疏和不稳定的挑战，难以实现智能RAG行为。

Method: 提出蒸馏引导策略优化（DGPO），包括从教师演示进行冷启动初始化，以及在策略优化过程中提供持续的教师指导。

Result: DGPO使紧凑模型能够实现复杂的智能搜索行为，在某些情况下甚至超越了更大的教师模型，使智能RAG在计算资源受限环境中变得可行。

Conclusion: DGPO方法有效解决了小型语言模型在强化学习训练中的困难，为资源受限环境下的智能RAG应用提供了可行的解决方案。

Abstract: Reinforcement Learning has emerged as a post-training approach to elicit
agentic RAG behaviors such as search and planning from language models.
However, compact language models (e.g., 0.5B parameters) struggle due to poor
reasoning ability, resulting in sparse rewards and unstable training. To
overcome these difficulties, we propose Distillation-Guided Policy Optimization
(DGPO), which addresses the challenges through cold-start initialization from
teacher demonstrations and continuous teacher guidance during policy
optimization. To systematically evaluate our approach, we introduce Agentic RAG
Capabilities (ARC), a fine-grained metric analyzing reasoning, search
coordination, and response synthesis. Comprehensive experiments demonstrate
that DGPO enables compact models to achieve sophisticated agentic search
behaviors, even outperforming the larger teacher model in some cases. DGPO
makes agentic RAG feasible in computing resource-constrained environments.

</details>


### [5] [GUARD: Guideline Upholding Test through Adaptive Role-play and Jailbreak Diagnostics for LLMs](https://arxiv.org/abs/2508.20325)
*Haibo Jin,Ruoxi Chen,Peiyan Zhang,Andy Zhou,Yang Zhang,Haohan Wang*

Main category: cs.CL

TL;DR: GUARD是一个将政府AI伦理指南转化为可操作测试问题的方法，通过自动生成违规问题和越狱诊断来评估LLM的合规性，并在多个主流模型上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型广泛应用，其可能生成有害内容引发社会担忧。政府发布的伦理指南缺乏具体测试方法，需要将高层要求转化为可操作的测试问题来验证LLM合规性。

Method: GUARD方法自动生成违反指南的测试问题，评估LLM响应合规性。对于不直接违规的响应，引入GUARD-JD进行越狱诊断，创建场景诱发违规响应，识别安全机制绕过风险。

Result: 在7个主流LLM（包括Vicuna、Llama系列、GPT系列和Claude）上实证验证，测试了三个政府指南的合规性并进行了越狱诊断。GUARD-JD还可迁移到视觉语言模型。

Conclusion: GUARD提供了一种系统化的方法来测试LLM对伦理指南的遵守情况，能够识别直接违规和潜在越狱风险，有助于促进可靠的LLM应用开发。

Abstract: As Large Language Models become increasingly integral to various domains,
their potential to generate harmful responses has prompted significant societal
and regulatory concerns. In response, governments have issued ethics guidelines
to promote the development of trustworthy AI. However, these guidelines are
typically high-level demands for developers and testers, leaving a gap in
translating them into actionable testing questions to verify LLM compliance.
  To address this challenge, we introduce GUARD (\textbf{G}uideline
\textbf{U}pholding Test through \textbf{A}daptive \textbf{R}ole-play and
Jailbreak \textbf{D}iagnostics), a testing method designed to operationalize
guidelines into specific guideline-violating questions that assess LLM
adherence. To implement this, GUARD uses automated generation of
guideline-violating questions based on government-issued guidelines, thereby
testing whether responses comply with these guidelines. When responses directly
violate guidelines, GUARD reports inconsistencies. Furthermore, for responses
that do not directly violate guidelines, GUARD integrates the concept of
``jailbreaks'' to diagnostics, named GUARD-JD, which creates scenarios that
provoke unethical or guideline-violating responses, effectively identifying
potential scenarios that could bypass built-in safety mechanisms. Our method
finally culminates in a compliance report, delineating the extent of adherence
and highlighting any violations.
  We have empirically validated the effectiveness of GUARD on seven LLMs,
including Vicuna-13B, LongChat-7B, Llama2-7B, Llama-3-8B, GPT-3.5, GPT-4,
GPT-4o, and Claude-3.7, by testing compliance under three government-issued
guidelines and conducting jailbreak diagnostics. Additionally, GUARD-JD can
transfer jailbreak diagnostics to vision-language models, demonstrating its
usage in promoting reliable LLM-based applications.

</details>


### [6] [Joint Enhancement of Relational Reasoning for Long-Context LLMs](https://arxiv.org/abs/2508.20351)
*Zhirui Chen,Wei Shen,Jiashui Huang,Ling Shao*

Main category: cs.CL

TL;DR: JERR是一个基于图推理的框架，通过摘要提取、图构建和关系推理三个组件，提升大语言模型在长上下文理解中的表现，在ROUGE和F1指标上优于所有基线方法。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在处理长上下文时存在内存限制和复杂任务处理困难的问题，同时缺乏透明度且容易产生幻觉，需要新的解决方案来提升长上下文理解能力。

Method: 提出JERR框架，包含三个关键组件：1）策略性文本分块进行摘要提取；2）构建有向无环图解决冗余问题；3）集成蒙特卡洛树搜索来导航复杂推理路径。

Result: 实验结果表明JERR在ROUGE和F1指标上 consistently优于所有基线方法，在LLM-Rater评估中获得最高分数。

Conclusion: JERR框架为大语言模型处理扩展上下文和复杂推理任务提供了新颖的解决方案，显著提高了可靠性和透明度。

Abstract: Despite significant progress, large language models (LLMs) still struggle
with long contexts due to memory limitations and their inability to tackle
complex and long-context tasks. Additionally, LLMs often suffer from a lack of
transparency and are prone to producing hallucinations. To address these
challenges, we propose \textbf{JERR}, a novel framework designed to enhance
long-context comprehension via graph-based reasoning in LLMs. JERR integrates
three key components: synopsis extraction, graph construction, and relational
reasoning. First, synopsis is extracted by chunking text strategically,
allowing the model to summarize and understand information more efficiently.
Second, we build a directed acyclic graph (DAG) to resolve redundancy, ensuring
logical consistency and clarity. Finally, we incorporate Monte Carlo Tree
Search (MCTS) to help the model navigate complex reasoning paths, ensuring more
accurate and interpretable outputs. This framework provides a novel solution
that enables LLMs to handle extended contexts and complex reasoning tasks with
improved reliability and transparency. Experimental results show that JERR
consistently outperforms all baselines on the ROUGE and F1 metrics, achieving
the highest scores on the LLM-Rater evaluation.

</details>


### [7] [Graph-R1: Unleashing LLM Reasoning with NP-Hard Graph Problems](https://arxiv.org/abs/2508.20373)
*Yuyao Wang,Bowen Liu,Jianheng Tang,Nuo Chen,Yuhan Li,Qifan Zhang,Jia Li*

Main category: cs.CL

TL;DR: 本文提出使用NP难图论问题作为合成训练资源，通过两阶段后训练框架提升LLM的长链式思维推理能力，在多个领域展现出良好的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 目前大语言模型的长链式思维能力主要依靠高成本的人工精准数据集进行后训练，需要找到一种可扩展的替代方案。

Method: 使用NP难图论问题作为合成训练资源，构建两阶段后训练框架：1）基于拒绝采样的长链式思维有监督微调；2）使用细粒度奖励设计的强化学习提升推理效率。

Result: 标志模型Graph-R1-7B在数学、编码、STEM和逻辑领域都展现出强大的泛化能力，在NP难图论问题上的准确性和推理效率都超过QwQ-32B模型。

Conclusion: NP难图论问题作为一种高效且可扩展的资源，为大语言模型的长链式思维推理能力提升开启了新方向，具有重要的研究价值。

Abstract: Reasoning Large Language Models (RLLMs) have recently achieved remarkable
progress on complex reasoning tasks, largely enabled by their long
chain-of-thought (Long CoT) capabilities. However, developing these Long CoT
behaviors relies heavily on post-training with high-quality datasets, which are
typically costly and human-curated (e.g., mathematics and code), leaving
scalable alternatives unexplored. In this work, we introduce NP-hard (NPH)
graph problems as a novel synthetic training corpus, as they inherently require
deep reasoning, extensive exploration, and reflective strategies, which are
core characteristics of Long CoT reasoning. Building on this insight, we
develop a two-stage post-training framework: (i) Long CoT Supervised
Fine-Tuning (SFT) on rejection-sampled NPH graph instances, which substantially
enhances reasoning depth, and (ii) Reinforcement Learning (RL) with a
fine-grained reward design, which sharpens reasoning efficiency. Our flagship
model, Graph-R1-7B, demonstrates strong generalization across mathematics,
coding, STEM, and logic, and surpasses QwQ-32B on NPH graph problems in both
accuracy and reasoning efficiency. These results position NPH graph problems as
an effective and scalable resource for advancing Long CoT reasoning in LLMs,
opening a new frontier for LLM post-training. Our implementation is available
at https://github.com/Graph-Reasoner/Graph-R1, with models and datasets hosted
in our Hugging Face collection HKUST-DSAIL/Graph-R1.

</details>


### [8] [CAPE: Context-Aware Personality Evaluation Framework for Large Language Models](https://arxiv.org/abs/2508.20385)
*Jivnesh Sandhan,Fei Cheng,Tushar Sandhan,Yugo Murawaki*

Main category: cs.CL

TL;DR: 该研究提出了首个上下文感知的人格评估框架CAPE，用于评估大语言模型在对话历史影响下的行为一致性，发现上下文能增强一致性但也会导致人格偏移，不同模型对上下文敏感度不同。


<details>
  <summary>Details</summary>
Motivation: 现有心理测量测试对LLMs采用无上下文方法，忽略了真实对话中历史交互对响应的影响，需要开发上下文感知的评估框架。

Method: 提出CAPE框架，引入新指标量化LLM响应一致性，在7个LLMs上进行实验，分析对话历史对响应一致性和人格特质的影响。

Result: 对话历史通过上下文学习增强响应一致性，但导致人格偏移；GPT模型对问题顺序稳健，Gemini和Llama敏感；GPT响应源于内在人格和先前交互，而其他模型更依赖先前交互。

Conclusion: 上下文依赖的人格偏移能提高响应一致性并更好对齐人类判断，为LLMs行为评估提供了更真实的框架。

Abstract: Psychometric tests, traditionally used to assess humans, are now being
applied to Large Language Models (LLMs) to evaluate their behavioral traits.
However, existing studies follow a context-free approach, answering each
question in isolation to avoid contextual influence. We term this the Disney
World test, an artificial setting that ignores real-world applications, where
conversational history shapes responses. To bridge this gap, we propose the
first Context-Aware Personality Evaluation (CAPE) framework for LLMs,
incorporating prior conversational interactions. To thoroughly analyze the
influence of context, we introduce novel metrics to quantify the consistency of
LLM responses, a fundamental trait in human behavior.
  Our exhaustive experiments on 7 LLMs reveal that conversational history
enhances response consistency via in-context learning but also induces
personality shifts, with GPT-3.5-Turbo and GPT-4-Turbo exhibiting extreme
deviations. While GPT models are robust to question ordering, Gemini-1.5-Flash
and Llama-8B display significant sensitivity. Moreover, GPT models response
stem from their intrinsic personality traits as well as prior interactions,
whereas Gemini-1.5-Flash and Llama--8B heavily depend on prior interactions.
Finally, applying our framework to Role Playing Agents (RPAs) shows
context-dependent personality shifts improve response consistency and better
align with human judgments. Our code and datasets are publicly available at:
https://github.com/jivnesh/CAPE

</details>


### [9] [Measuring Reasoning Utility in LLMs via Conditional Entropy Reduction](https://arxiv.org/abs/2508.20395)
*Xu Guo*

Main category: cs.CL

TL;DR: 研究发现推理步骤中的条件熵变化模式可以预测答案正确性：熵递减与正确答案相关，熵平坦或递增则与错误答案相关。错误推理路径往往更长，说明更长推理不一定更好。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型依赖中间推理步骤提高准确性，但缺乏对推理步骤效用如何影响最终答案正确性的研究。由于自回归生成的随机性，生成更多上下文不能保证答案置信度提升。

Method: 在MATH数据集上进行oracle研究，使用Qwen2.5-32B和GPT-4o生成推理链，然后用Qwen3-8B量化这些推理链对最终准确性的效用。通过条件熵（词汇表上的期望负对数似然）逐步测量模型对答案跨度的不确定性。

Result: 条件熵随步骤递减的模式与正确答案强相关，而平坦或递增的熵往往导致错误答案。错误推理路径通常比正确路径更长。

Conclusion: 这些发现为设计高效推理管道提供了基础，可以早期检测和避免无效推理，提高推理效率。

Abstract: Recent advancements in large language models (LLMs) often rely on generating
intermediate reasoning steps to enhance accuracy. However, little work has
examined how reasoning utility contributes to the final answer's correctness.
Due to the stochastic nature of autoregressive generation, generating more
context does not guarantee increased confidence in the answer. If we could
predict, during generation, whether a reasoning step will be useful, we could
stop early or prune ineffective steps, avoiding distractions in the final
decision.
  We present an oracle study on MATH dataset, using Qwen2.5-32B and GPT-4o to
generate reasoning chains, and then employing a separate model (Qwen3-8B) to
quantify the utility of these chains for final accuracy. Specifically, we
measure the model's uncertainty on the answer span Y at each reasoning step
using conditional entropy (expected negative log-likelihood over the
vocabulary) with context expanding step by step. Our results show a clear
pattern: conditional entropy that decreases over steps is strongly associated
with correct answers, whereas flat or increasing entropy often results in wrong
answers. We also corroborate that incorrect reasoning paths tend to be longer
than correct ones, suggesting that longer reasoning does not necessarily yield
better outcomes. These findings serve as a foundation to inspire future work on
designing efficient reasoning pipelines that detect and avoid unproductive
reasoning early.

</details>


### [10] [UI-Bench: A Benchmark for Evaluating Design Capabilities of AI Text-to-App Tools](https://arxiv.org/abs/2508.20410)
*Sam Jung,Agustin Garcinuno,Spencer Mateega*

Main category: cs.CL

TL;DR: UI-Bench是首个大规模评估AI文本转应用工具视觉质量的基准测试，通过专家两两比较对10个工具进行排名，包含30个提示词、300个生成网站和4000+专家判断。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏公开基准来严格验证AI文本转应用工具声称的高质量应用和网站生成能力，需要建立可复现的标准来推动AI驱动的网页设计发展。

Method: 使用专家两两比较方法，基于TrueSkill模型对10个不同工具的生成结果进行排名，包含30个提示词、300个生成网站和4000+专家判断。

Result: 建立了UI-Bench基准测试，提供了完整的提示词集、开源评估框架和公开排行榜，能够对AI文本转应用工具进行可靠排名。

Conclusion: UI-Bench为AI驱动的网页设计领域建立了首个可复现的评估标准，通过大规模专家评估和统计模型为工具性能提供了可靠的衡量基准。

Abstract: AI text-to-app tools promise high quality applications and websites in
minutes, yet no public benchmark rigorously verifies those claims. We introduce
UI-Bench, the first large-scale benchmark that evaluates visual excellence
across competing AI text-to-app tools through expert pairwise comparison.
Spanning 10 tools, 30 prompts, 300 generated sites, and \textit{4000+} expert
judgments, UI-Bench ranks systems with a TrueSkill-derived model that yields
calibrated confidence intervals. UI-Bench establishes a reproducible standard
for advancing AI-driven web design. We release (i) the complete prompt set,
(ii) an open-source evaluation framework, and (iii) a public leaderboard. The
generated sites rated by participants will be released soon. View the UI-Bench
leaderboard at https://uibench.ai/leaderboard.

</details>


### [11] [DentalBench: Benchmarking and Advancing LLMs Capability for Bilingual Dentistry Understanding](https://arxiv.org/abs/2508.20416)
*Hengchuan Zhu,Yihuan Xu,Yichen Li,Zijie Meng,Zuozhu Liu*

Main category: cs.CL

TL;DR: DentalBench是首个针对牙科领域的双语基准测试，包含问答数据集和大规模语料库，评估显示现有LLMs在牙科专业领域存在显著性能差距，领域适应能显著提升模型表现。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在通用医疗基准上表现良好，但在牙科等需要深度领域知识的专业医疗领域缺乏针对性评估资源，性能未被充分探索。

Method: 构建DentalBench基准：1）DentalQA：36,597个中英文问答问题，覆盖4个任务和16个牙科子领域；2）DentalCorpus：3.37亿token的大规模高质量语料库，支持监督微调和检索增强生成。评估14个LLMs并进行领域适应实验。

Result: 评估显示不同模型在任务类型和语言上存在显著性能差距。Qwen-2.5-3B的领域适应实验表明，领域适应能大幅提升模型性能，特别是在知识密集和术语集中的任务上。

Conclusion: 领域特定基准测试对于开发可信赖且有效的医疗应用LLMs至关重要，DentalBench填补了牙科领域评估资源的空白，证明了领域适应在专业医疗领域的重要性。

Abstract: Recent advances in large language models (LLMs) and medical LLMs (Med-LLMs)
have demonstrated strong performance on general medical benchmarks. However,
their capabilities in specialized medical fields, such as dentistry which
require deeper domain-specific knowledge, remain underexplored due to the lack
of targeted evaluation resources. In this paper, we introduce DentalBench, the
first comprehensive bilingual benchmark designed to evaluate and advance LLMs
in the dental domain. DentalBench consists of two main components: DentalQA, an
English-Chinese question-answering (QA) benchmark with 36,597 questions
spanning 4 tasks and 16 dental subfields; and DentalCorpus, a large-scale,
high-quality corpus with 337.35 million tokens curated for dental domain
adaptation, supporting both supervised fine-tuning (SFT) and
retrieval-augmented generation (RAG). We evaluate 14 LLMs, covering
proprietary, open-source, and medical-specific models, and reveal significant
performance gaps across task types and languages. Further experiments with
Qwen-2.5-3B demonstrate that domain adaptation substantially improves model
performance, particularly on knowledge-intensive and terminology-focused tasks,
and highlight the importance of domain-specific benchmarks for developing
trustworthy and effective LLMs tailored to healthcare applications.

</details>


### [12] [KG-CQR: Leveraging Structured Relation Representations in Knowledge Graphs for Contextual Query Retrieval](https://arxiv.org/abs/2508.20417)
*Chi Minh Bui,Ngoc Mai Thieu,Van Vinh Nguyen,Json J. Jung,Khac-Hoai Nam Bui*

Main category: cs.CL

TL;DR: KG-CQR是一个基于知识图谱的上下文查询检索框架，通过提取和补全相关KG子图来丰富查询语义，在RAG系统中显著提升检索性能


<details>
  <summary>Details</summary>
Motivation: 现有方法主要解决语料库级别的上下文丢失问题，但缺乏对复杂查询的结构化关系表示和语义丰富化处理

Method: 提出包含子图提取、补全和上下文生成三个模块的模型无关流水线，通过知识图谱增强查询的上下文表示

Result: 在RAGBench和MultiHop-RAG数据集上，mAP提升4-6%，Recall@25提升2-3%，在多跳问答等挑战性任务中表现优异

Conclusion: KG-CQR框架有效提升了RAG系统的检索效果，具有模型无关性和可扩展性，为知识图谱与LLM的融合提供了新思路

Abstract: The integration of knowledge graphs (KGs) with large language models (LLMs)
offers significant potential to improve the retrieval phase of
retrieval-augmented generation (RAG) systems. In this study, we propose KG-CQR,
a novel framework for Contextual Query Retrieval (CQR) that enhances the
retrieval phase by enriching the contextual representation of complex input
queries using a corpus-centric KG. Unlike existing methods that primarily
address corpus-level context loss, KG-CQR focuses on query enrichment through
structured relation representations, extracting and completing relevant KG
subgraphs to generate semantically rich query contexts. Comprising subgraph
extraction, completion, and contextual generation modules, KG-CQR operates as a
model-agnostic pipeline, ensuring scalability across LLMs of varying sizes
without additional training. Experimental results on RAGBench and MultiHop-RAG
datasets demonstrate KG-CQR's superior performance, achieving a 4-6%
improvement in mAP and a 2-3% improvement in Recall@25 over strong baseline
models. Furthermore, evaluations on challenging RAG tasks such as multi-hop
question answering show that, by incorporating KG-CQR, the performance
consistently outperforms the existing baseline in terms of retrieval
effectiveness

</details>


### [13] [CAMB: A comprehensive industrial LLM benchmark on civil aviation maintenance](https://arxiv.org/abs/2508.20420)
*Feng Zhang,Chengjie Pang,Yuehan Zhang,Chenyu Luo*

Main category: cs.CL

TL;DR: 这篇论文为民航维修领域开发了专业的工业级评测标准，用于评估大语言模型在该领域的知识和维护执行能力，并分析了RAG系统的表现。


<details>
  <summary>Details</summary>
Motivation: 当前LLM评估主要集中在数学和编程认知任务，缺乏专门针对民航维修这种高标准行业的评测工具。民航维修需要复杂的知识和思维能力，而RAG系统是实际应用中的主流方案。

Method: 开发了一个专门针对民航维修领域的工业级标准评测框架，用于评估LLM在域内知识和复杂思维能力。利用该标准对现有知名的矩阵嵌入模型和LLM在民航维修场景下进行实验分析。

Result: 证明了该标准在评估模型在民航维修领域表现方面的有效性，并开源了评测标准和代码以促进进一步研究。

Conclusion: 该研究填补了LLM评估在专业行业领域的空白，为民航维修领域的LLM能力评估和改进提供了基础工具，有助于推动更智能化的民航维修解决方案的发展。

Abstract: Civil aviation maintenance is a domain characterized by stringent industry
standards. Within this field, maintenance procedures and troubleshooting
represent critical, knowledge-intensive tasks that require sophisticated
reasoning. To address the lack of specialized evaluation tools for large
language models (LLMs) in this vertical, we propose and develop an
industrial-grade benchmark specifically designed for civil aviation
maintenance. This benchmark serves a dual purpose: It provides a standardized
tool to measure LLM capabilities within civil aviation maintenance, identifying
specific gaps in domain knowledge and complex reasoning. By pinpointing these
deficiencies, the benchmark establishes a foundation for targeted improvement
efforts (e.g., domain-specific fine-tuning, RAG optimization, or specialized
prompt engineering), ultimately facilitating progress toward more intelligent
solutions within civil aviation maintenance. Our work addresses a significant
gap in the current LLM evaluation, which primarily focuses on mathematical and
coding reasoning tasks. In addition, given that Retrieval-Augmented Generation
(RAG) systems are currently the dominant solutions in practical applications ,
we leverage this benchmark to evaluate existing well-known vector embedding
models and LLMs for civil aviation maintenance scenarios. Through experimental
exploration and analysis, we demonstrate the effectiveness of our benchmark in
assessing model performance within this domain, and we open-source this
evaluation benchmark and code to foster further research and
development:https://github.com/CamBenchmark/cambenchmark

</details>


### [14] [Searching the Title of Practical Work of the Informatics Engineering Bachelor Program with the Case Base Reasoning Method](https://arxiv.org/abs/2508.20442)
*Agung Sukrisna Jaya,Osvari Arsalan,Danny Matthew Saputra*

Main category: cs.CL

TL;DR: 基于案例推理(CBR)和TF-IDF技术的实践工作标题搜索系统，通过余弦相似度计算匹配度，在705个标题测试中表现良好


<details>
  <summary>Details</summary>
Motivation: 开发一个能够基于历史案例和经验来搜索实践工作标题的系统，利用已有的案例库来提高搜索效率和准确性

Method: 使用案例推理(CBR)方法，结合TF-IDF进行文本向量化处理，采用余弦相似度算法计算标题之间的相似度值

Result: 在705个实践工作标题的测试中，系统在两个测试阶段都表现良好，第二阶段获得了相同数量的匹配标题和更高的平均匹配分数

Conclusion: 基于CBR和TF-IDF的实践工作标题搜索系统是有效的，能够准确匹配相似标题，为实践工作检索提供了可靠的解决方案

Abstract: Case Base Reasoning (CBR) is a case solving technique based on experience in
cases that have occurred before with the highest similarity. CBR is used to
search for practical work titles. TF-IDF is applied to process the
vectorization of each practical work title word and Cosine Similarity for the
calculation of similarity values. This system can search either in the form of
titles or keywords. The output of the system is the title of practical work and
the match value of each title. Based on the test results using 705 practical
work titles, testing was carried out with five titles and carried out in two
stages. The first stage searches with existing titles and the second stage
randomizes the title from the first stage. And the results obtained in the
second stage are the same number of titles found and the highest average match
score.

</details>


### [15] [MCP-Bench: Benchmarking Tool-Using LLM Agents with Complex Real-World Tasks via MCP Servers](https://arxiv.org/abs/2508.20453)
*Zhenting Wang,Qi Chang,Hemani Patel,Shashank Biju,Cheng-En Wu,Quan Liu,Aolin Ding,Alireza Rezazadeh,Ankit Shah,Yujia Bao,Eugene Siow*

Main category: cs.CL

TL;DR: MCP-Bench是一个基于Model Context Protocol的基准测试，用于评估LLM在多步骤工具使用、跨工具协调和复杂任务规划方面的能力，包含28个MCP服务器和250个工具，覆盖多个领域。


<details>
  <summary>Details</summary>
Motivation: 现有的API基准测试主要依赖显式工具规范、浅层工作流程和孤立领域操作，无法充分评估LLM在模糊指令下的工具检索、多跳执行轨迹规划、跨域工作流协调等关键能力。

Method: 基于MCP协议构建基准，连接28个实时MCP服务器，涵盖250个跨领域工具，设计真实的多步骤任务，采用多维度评估框架（工具级模式理解、轨迹级规划、任务完成度）。

Result: 对20个先进LLM的实验显示，在MCP-Bench上仍存在持续挑战，表明现有模型在复杂工具使用和跨域协调方面仍有改进空间。

Conclusion: MCP-Bench提供了一个更真实、全面的评估平台，能够更好地测试LLM在实际工具使用场景中的综合能力，填补了现有基准测试的不足。

Abstract: We introduce MCP-Bench, a benchmark for evaluating large language models
(LLMs) on realistic, multi-step tasks that demand tool use, cross-tool
coordination, precise parameter control, and planning/reasoning for solving
tasks. Built on the Model Context Protocol (MCP), MCP-Bench connects LLMs to 28
representative live MCP servers spanning 250 tools across domains such as
finance, traveling, scientific computing, and academic search. Unlike prior
API-based benchmarks, each MCP server provides a set of complementary tools
designed to work together, enabling the construction of authentic, multi-step
tasks with rich input-output coupling. Tasks in MCP-Bench test agents' ability
to retrieve relevant tools from fuzzy instructions without explicit tool names,
plan multi-hop execution trajectories for complex objectives, ground responses
in intermediate tool outputs, and orchestrate cross-domain workflows -
capabilities not adequately evaluated by existing benchmarks that rely on
explicit tool specifications, shallow few-step workflows, and isolated domain
operations. We propose a multi-faceted evaluation framework covering tool-level
schema understanding and usage, trajectory-level planning, and task completion.
Experiments on 20 advanced LLMs reveal persistent challenges in MCP-Bench. Code
and data: https://github.com/Accenture/mcp-bench.

</details>


### [16] [Prediction of mortality and resource utilization in critical care: a deep learning approach using multimodal electronic health records with natural language processing techniques](https://arxiv.org/abs/2508.20460)
*Yucheng Ruan,Xiang Lan,Daniel J. Tan,Hairil Rizal Abdullah,Mengling Feng*

Main category: cs.CL

TL;DR: 这篇论文提出了一种深度学习框架，通过自然语言处理技术整合多模态电子健康记录，用于预测ICU患者死亡率和资源利用情况，在多个临床任务中表现优异且具有强声的数据耐受性。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注结构化电子健康记录，忽视了自由文本记录中的临床见解以及结构化数据中文本信息的潜力，而这些对于ICU患者结果预测和资源管理至关重要。

Method: 使用两个真实世界电子健康记录数据集，开发和评估了一种深度学习框架，该框架整合多模态信息并使用自然语言处理技术。进行了三个关键组件的消融研究，并评估模型在结构化数据损坏情况下的稳健性。

Result: 在两个真实数据集的三个临床任务中，提出的模型在死亡预测任务上对BACC/AUROC指标提升1.6%/0.8%，在住院时长预测任务上对RMSE/MAE指标提升0.5%/2.2%，在手术时长估计任务上对RMSE/MAE指标提升10.9%/11.0%，且在不同数据损坏率下均显示出优异性能。

Conclusion: 该框架是一种有效准确的深度学习方法，能够预测重疾监护患者的死亡率和资源利用。研究还高度评价了使用提示学习和变换器编码器在多模态电子健康记录分析中的成功应用，并显示模型在高数据损坏水平下仍具有强声的耐受性。

Abstract: Background Predicting mortality and resource utilization from electronic
health records (EHRs) is challenging yet crucial for optimizing patient
outcomes and managing costs in intensive care unit (ICU). Existing approaches
predominantly focus on structured EHRs, often ignoring the valuable clinical
insights in free-text notes. Additionally, the potential of textual information
within structured data is not fully leveraged. This study aimed to introduce
and assess a deep learning framework using natural language processing
techniques that integrates multimodal EHRs to predict mortality and resource
utilization in critical care settings. Methods Utilizing two real-world EHR
datasets, we developed and evaluated our model on three clinical tasks with
leading existing methods. We also performed an ablation study on three key
components in our framework: medical prompts, free-texts, and pre-trained
sentence encoder. Furthermore, we assessed the model's robustness against the
corruption in structured EHRs. Results Our experiments on two real-world
datasets across three clinical tasks showed that our proposed model improved
performance metrics by 1.6\%/0.8\% on BACC/AUROC for mortality prediction,
0.5%/2.2% on RMSE/MAE for LOS prediction, 10.9%/11.0% on RMSE/MAE for surgical
duration estimation compared to the best existing methods. It consistently
demonstrated superior performance compared to other baselines across three
tasks at different corruption rates. Conclusions The proposed framework is an
effective and accurate deep learning approach for predicting mortality and
resource utilization in critical care. The study also highlights the success of
using prompt learning with a transformer encoder in analyzing multimodal EHRs.
Importantly, the model showed strong resilience to data corruption within
structured data, especially at high corruption levels.

</details>


### [17] [ConspirED: A Dataset for Cognitive Traits of Conspiracy Theories and Large Language Model Safety](https://arxiv.org/abs/2508.20468)
*Luke Bates,Max Glockner,Preslav Nakov,Iryna Gurevych*

Main category: cs.CL

TL;DR: 论文介绍了ConspirED数据集，用于分析阴谋论内容的认知特征，开发了识别模型并评估了大语言模型对阴谋论输入的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 阴谋论侵蚀公众对科学和机构的信任，且随着AI生成虚假信息的日益复杂，理解阴谋论修辞模式对于开发干预措施和评估AI漏洞至关重要。

Method: 引入ConspirED数据集，基于CONSPIR认知框架标注在线阴谋论文章的多句摘录，开发计算模型识别阴谋论特征，并评估大语言模型对阴谋论输入的响应。

Result: 发现大语言模型容易被阴谋论内容误导，即使能成功反驳类似的事实核查错误信息，其输出仍会反映输入中的推理模式。

Conclusion: ConspirED是首个标注阴谋论内容一般认知特征的数据集，揭示了当前AI模型在应对阴谋论内容时的脆弱性，为开发针对性干预措施提供了基础。

Abstract: Conspiracy theories erode public trust in science and institutions while
resisting debunking by evolving and absorbing counter-evidence. As AI-generated
misinformation becomes increasingly sophisticated, understanding rhetorical
patterns in conspiratorial content is important for developing interventions
such as targeted prebunking and assessing AI vulnerabilities. We introduce
ConspirED (CONSPIR Evaluation Dataset), which captures the cognitive traits of
conspiratorial ideation in multi-sentence excerpts (80--120 words) from online
conspiracy articles, annotated using the CONSPIR cognitive framework
(Lewandowsky and Cook, 2020). ConspirED is the first dataset of conspiratorial
content annotated for general cognitive traits. Using ConspirED, we (i) develop
computational models that identify conspiratorial traits and determine dominant
traits in text excerpts, and (ii) evaluate large language/reasoning model
(LLM/LRM) robustness to conspiratorial inputs. We find that both are misaligned
by conspiratorial content, producing output that mirrors input reasoning
patterns, even when successfully deflecting comparable fact-checked
misinformation.

</details>


### [18] [Languages Still Left Behind: Toward a Better Multilingual Machine Translation Benchmark](https://arxiv.org/abs/2508.20511)
*Chihiro Taguchi,Seng Mai,Keita Kurabe,Yusuke Sakai,Georgina Agyei,Soudabeh Eslami,David Chiang*

Main category: cs.CL

TL;DR: FLORES+基准测试在200多种语言的机器翻译评估中存在质量问题，包括翻译质量低于声称标准、领域特定性和文化偏见问题，以及命名实体复制带来的评估漏洞。


<details>
  <summary>Details</summary>
Motivation: 研究FLORES+多语言机器翻译基准测试的实际适用性，发现其在翻译质量、文化中立性和评估协议方面存在严重缺陷，影响了真正的多语言评估效果。

Method: 通过人工评估四种语言（Asante Twi、日语、Jinghpaw和南阿塞拜疆语）的翻译质量，分析源文本的领域特定性和文化偏见，并使用简单启发式方法测试评估协议的脆弱性。

Result: 发现许多翻译质量低于声称的90%标准，源文本过于领域特定且具有英语世界文化偏见，简单的命名实体复制就能获得不错的BLEU分数，高质量MT模型在FLORES+上表现不佳但在相关领域评估集上表现良好。

Conclusion: 建议开发使用领域通用和文化中立源文本、减少依赖命名实体的多语言MT基准测试，以更好地反映真实世界的翻译挑战。

Abstract: Multilingual machine translation (MT) benchmarks play a central role in
evaluating the capabilities of modern MT systems. Among them, the FLORES+
benchmark is widely used, offering English-to-many translation data for over
200 languages, curated with strict quality control protocols. However, we study
data in four languages (Asante Twi, Japanese, Jinghpaw, and South Azerbaijani)
and uncover critical shortcomings in the benchmark's suitability for truly
multilingual evaluation. Human assessments reveal that many translations fall
below the claimed 90% quality standard, and the annotators report that source
sentences are often too domain-specific and culturally biased toward the
English-speaking world. We further demonstrate that simple heuristics, such as
copying named entities, can yield non-trivial BLEU scores, suggesting
vulnerabilities in the evaluation protocol. Notably, we show that MT models
trained on high-quality, naturalistic data perform poorly on FLORES+ while
achieving significant gains on our domain-relevant evaluation set. Based on
these findings, we advocate for multilingual MT benchmarks that use
domain-general and culturally neutral source texts rely less on named entities,
in order to better reflect real-world translation challenges.

</details>


### [19] [SciTopic: Enhancing Topic Discovery in Scientific Literature through Advanced LLM](https://arxiv.org/abs/2508.20514)
*Pengjiang Li,Zaitian Wang,Xinhao Zhang,Ran Zhang,Lu Jiang,Pengfei Wang,Yuanchun Zhou*

Main category: cs.CL

TL;DR: SciTopic是一种基于大语言模型增强的科学文献主题发现方法，通过构建文本编码器、空间优化模块和LLM指导的对比学习，显著提升了科学主题识别的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的主题发现方法主要依赖词嵌入技术，缺乏对科学文献的全面理解，难以处理复杂的高维文本关系。大语言模型在文本理解方面的卓越能力为解决这一问题提供了新的思路。

Method: 1) 构建文本编码器捕获科学文献内容；2) 建立空间优化模块，整合基于熵的采样和LLM指导的三元组任务；3) 基于LLM指导微调文本编码器，优化三元组对比损失；4) 在三个真实数据集上进行实验验证。

Result: 在三个真实科学文献数据集上的实验表明，SciTopic在科学主题发现任务上超越了现有的最先进方法，使研究人员能够获得更深入、更快速的洞察。

Conclusion: SciTopic通过利用大语言模型的强大文本理解能力，有效解决了传统主题发现方法的局限性，为科学文献主题分析提供了更准确和高效的解决方案。

Abstract: Topic discovery in scientific literature provides valuable insights for
researchers to identify emerging trends and explore new avenues for
investigation, facilitating easier scientific information retrieval. Many
machine learning methods, particularly deep embedding techniques, have been
applied to discover research topics. However, most existing topic discovery
methods rely on word embedding to capture the semantics and lack a
comprehensive understanding of scientific publications, struggling with
complex, high-dimensional text relationships. Inspired by the exceptional
comprehension of textual information by large language models (LLMs), we
propose an advanced topic discovery method enhanced by LLMs to improve
scientific topic identification, namely SciTopic. Specifically, we first build
a textual encoder to capture the content from scientific publications,
including metadata, title, and abstract. Next, we construct a space
optimization module that integrates entropy-based sampling and triplet tasks
guided by LLMs, enhancing the focus on thematic relevance and contextual
intricacies between ambiguous instances. Then, we propose to fine-tune the
textual encoder based on the guidance from the LLMs by optimizing the
contrastive loss of the triplets, forcing the text encoder to better
discriminate instances of different topics. Finally, extensive experiments
conducted on three real-world datasets of scientific publications demonstrate
that SciTopic outperforms the state-of-the-art (SOTA) scientific topic
discovery methods, enabling researchers to gain deeper and faster insights.

</details>


### [20] [Overview of BioASQ 2024: The twelfth BioASQ challenge on Large-Scale Biomedical Semantic Indexing and Question Answering](https://arxiv.org/abs/2508.20532)
*Anastasios Nentidis,Georgios Katsimpras,Anastasia Krithara,Salvador Lima-López,Eulàlia Farré-Maduell,Martin Krallinger,Natalia Loukachevitch,Vera Davydova,Elena Tutubalina,Georgios Paliouras*

Main category: cs.CL

TL;DR: BioASQ 2024挑战赛概述，包含两个传统任务和两个新任务，37个团队参与，提交超过700份方案，性能表现竞争激烈。


<details>
  <summary>Details</summary>
Motivation: 促进大规模生物医学语义索引和问答系统的进步，通过国际挑战赛推动该领域的发展。

Method: 设立四个共享任务：两个传统任务（b和Synergy）和两个新任务（MultiCardioNER多语言临床实体检测和BIONNE嵌套命名实体识别）。

Result: 37个参赛团队共提交700多份方案，大多数系统达到了有竞争力的性能水平。

Conclusion: BioASQ挑战赛持续推动生物医学自然语言处理领域的state-of-the-art技术进步，参与者表现优异。

Abstract: This is an overview of the twelfth edition of the BioASQ challenge in the
context of the Conference and Labs of the Evaluation Forum (CLEF) 2024. BioASQ
is a series of international challenges promoting advances in large-scale
biomedical semantic indexing and question answering. This year, BioASQ
consisted of new editions of the two established tasks b and Synergy, and two
new tasks: a) MultiCardioNER on the adaptation of clinical entity detection to
the cardiology domain in a multilingual setting, and b) BIONNE on nested NER in
Russian and English. In this edition of BioASQ, 37 competing teams participated
with more than 700 distinct submissions in total for the four different shared
tasks of the challenge. Similarly to previous editions, most of the
participating systems achieved competitive performance, suggesting the
continuous advancement of the state-of-the-art in the field.

</details>


### [21] [Overview of BioASQ 2025: The Thirteenth BioASQ Challenge on Large-Scale Biomedical Semantic Indexing and Question Answering](https://arxiv.org/abs/2508.20554)
*Anastasios Nentidis,Georgios Katsimpras,Anastasia Krithara,Martin Krallinger,Miguel Rodríguez-Ortega,Eduard Rodriguez-López,Natalia Loukachevitch,Andrey Sakhovskiy,Elena Tutubalina,Dimitris Dimitriadis,Grigorios Tsoumakas,George Giannakoulas,Alexandra Bekiaridou,Athanasios Samaras,Giorgio Maria Di Nunzio,Nicola Ferro,Stefano Marchesin,Marco Martinelli,Gianmaria Silvello,Georgios Paliouras*

Main category: cs.CL

TL;DR: BioASQ 2025挑战赛概述，包含两个传统任务和四个新任务，涉及生物医学语义索引、问答、多语言临床摘要、命名实体链接、临床编码和信息提取等领域，共有83个团队参与。


<details>
  <summary>Details</summary>
Motivation: 促进大规模生物医学语义索引和问答技术的进步，通过挑战赛形式推动该领域的前沿发展。

Method: 设立六个共享任务：两个传统任务（任务b和Synergy）和四个新任务（多语言临床摘要、嵌套命名实体链接、心脏病学临床编码、肠脑相互作用信息提取），邀请研究团队参与并提交解决方案。

Result: 83个竞争团队参与，提交了超过1000份不同的解决方案，多个系统表现出有竞争力的性能。

Conclusion: BioASQ挑战赛持续推动着生物医学信息处理领域的技术进步，参与系统的表现表明该领域的最新技术在不断发展和完善。

Abstract: This is an overview of the thirteenth edition of the BioASQ challenge in the
context of the Conference and Labs of the Evaluation Forum (CLEF) 2025. BioASQ
is a series of international challenges promoting advances in large-scale
biomedical semantic indexing and question answering. This year, BioASQ
consisted of new editions of the two established tasks, b and Synergy, and four
new tasks: a) Task MultiClinSum on multilingual clinical summarization. b) Task
BioNNE-L on nested named entity linking in Russian and English. c) Task
ELCardioCC on clinical coding in cardiology. d) Task GutBrainIE on gut-brain
interplay information extraction. In this edition of BioASQ, 83 competing teams
participated with more than 1000 distinct submissions in total for the six
different shared tasks of the challenge. Similar to previous editions, several
participating systems achieved competitive performance, indicating the
continuous advancement of the state-of-the-art in the field.

</details>


### [22] [Adaptive Federated Distillation for Multi-Domain Non-IID Textual Data](https://arxiv.org/abs/2508.20557)
*Jiahao Xiao,Jiangming Liu*

Main category: cs.CL

TL;DR: 这篇论文提出了一种适配性联邦蓄米（AdaFD）框架，用于解决多域非IID数据在联邦学习中的挑战，并建立了一个统一的性能评测框架。


<details>
  <summary>Details</summary>
Motivation: 现有联邦蓄米方法主要关注标签异质性，而忽视了语言域的多样性，这在NLP任务中很重要。需要解决多域非IID数据带来的挑战。

Method: 提出了适配性联邦蓄米（AdaFD）框架，设计用于同构和异构设置下的多域非IID挑战。建立了一个包含多样数据的统一性能评测框架。

Result: 实验结果显示，该模型能够抓住本地客户端的多样性，与现有方法相比获得了更好的性能。

Conclusion: 该研究为联邦学习领域提供了一个更全面的多域非IID场景评测框架，并通过AdaFD框架有效地解决了语言域多样性带来的挑战。

Abstract: The widespread success of pre-trained language models has established a new
training paradigm, where a global PLM is fine-tuned using task-specific data
from local clients. The local data are highly different from each other and can
not capture the global distribution of the whole data in real world. To address
the challenges of non-IID data in real environments, privacy-preserving
federated distillation has been proposed and highly investigated. However,
previous experimental non-IID scenarios are primarily identified with the label
(output) diversity, without considering the diversity of language domains
(input) that is crucial in natural language processing. In this paper, we
introduce a comprehensive set of multi-domain non-IID scenarios and propose a
unified benchmarking framework that includes diverse data. The benchmark can be
used to evaluate the federated learning framework in a real environment. To
this end, we propose an Adaptive Federated Distillation (AdaFD) framework
designed to address multi-domain non-IID challenges in both homogeneous and
heterogeneous settings. Experimental results demonstrate that our models
capture the diversity of local clients and achieve better performance compared
to the existing works. The code for this paper is available at:
https://github.com/jiahaoxiao1228/AdaFD.

</details>


### [23] [Leveraging Generative Models for Real-Time Query-Driven Text Summarization in Large-Scale Web Search](https://arxiv.org/abs/2508.20559)
*Zeyu Xiong,Yixuan Nan,Li Gao,Hengzhu Tang,Shuaiqiang Wang,Junfeng Wang,Dawei Yin*

Main category: cs.CL

TL;DR: 本研究提出了一种新颖的生成式查询驱动文本摘要框架，通过模型蒸馏、监督微调、直接偏好优化和前瞻解码技术，将仅有0.1B参数的轻量级模型转化为领域专业化摘要专家，在工业网络搜索中实现了实时高性能摘要。


<details>
  <summary>Details</summary>
Motivation: 传统抽取式摘要模型存在多阶段流水线导致的信息累积损失和架构瓶颈问题，且缺乏对用户查询和文档的充分语义理解，特别是在处理复杂搜索意图时表现不足。

Method: 集成大型模型蒸馏、监督微调、直接偏好优化和前瞻解码技术，将轻量级模型（0.1B参数）转化为领域专业化查询驱动文本摘要专家。

Result: 在多个行业相关指标上超越生产基线并达到新的最先进水平，部署效率优异，仅需334个NVIDIA L20 GPU即可处理约50,000 QPS，平均延迟55ms。

Conclusion: 生成式模型在工业网络搜索的实时查询驱动文本摘要任务中具有显著优势，通过精心设计的训练和解码策略，轻量级模型也能达到优异的性能和部署效率。

Abstract: In the dynamic landscape of large-scale web search, Query-Driven Text
Summarization (QDTS) aims to generate concise and informative summaries from
textual documents based on a given query, which is essential for improving user
engagement and facilitating rapid decision-making. Traditional extractive
summarization models, based primarily on ranking candidate summary segments,
have been the dominant approach in industrial applications. However, these
approaches suffer from two key limitations: 1) The multi-stage pipeline often
introduces cumulative information loss and architectural bottlenecks due to its
weakest component; 2) Traditional models lack sufficient semantic understanding
of both user queries and documents, particularly when dealing with complex
search intents. In this study, we propose a novel framework to pioneer the
application of generative models to address real-time QDTS in industrial web
search. Our approach integrates large model distillation, supervised
fine-tuning, direct preference optimization, and lookahead decoding to
transform a lightweight model with only 0.1B parameters into a
domain-specialized QDTS expert. Evaluated on multiple industry-relevant
metrics, our model outperforms the production baseline and achieves a new state
of the art. Furthermore, it demonstrates excellent deployment efficiency,
requiring only 334 NVIDIA L20 GPUs to handle \textasciitilde50,000 queries per
second under 55~ms average latency per query.

</details>


### [24] [KCS: Diversify Multi-hop Question Generation with Knowledge Composition Sampling](https://arxiv.org/abs/2508.20567)
*Yangfan Wang,Jie Liu,Chen Tang,Lian Yan,Jingchi Jiang*

Main category: cs.CL

TL;DR: 本文提出了知识组合采样（KCS）框架，通过采样不同的知识组合来增强多跳问答问题的多样性，解决了数据稀疏性问题。


<details>
  <summary>Details</summary>
Motivation: 多跳问答面临数据稀疏性挑战，导致语言模型容易学习虚假模式。现有方法主要关注问题生成的多样性，但忽视了必要知识的整合。

Method: KCS将知识组合选择建模为句子级条件预测任务，使用概率对比损失预测下一个最相关的知识片段，并在推理时采用随机解码策略平衡准确性和多样性。

Result: KCS在知识组合选择准确率上比基线提升3.9%，在HotpotQA和2WikiMultihopQA数据集上通过数据增强获得了改进。

Conclusion: KCS框架有效提升了多跳问答问题的生成多样性，通过更好的知识整合改善了模型性能。

Abstract: Multi-hop question answering faces substantial challenges due to data
sparsity, which increases the likelihood of language models learning spurious
patterns. To address this issue, prior research has focused on diversifying
question generation through content planning and varied expression. However,
these approaches often emphasize generating simple questions and neglect the
integration of essential knowledge, such as relevant sentences within
documents. This paper introduces the Knowledge Composition Sampling (KCS), an
innovative framework designed to expand the diversity of generated multi-hop
questions by sampling varied knowledge compositions within a given context. KCS
models the knowledge composition selection as a sentence-level conditional
prediction task and utilizes a probabilistic contrastive loss to predict the
next most relevant piece of knowledge. During inference, we employ a stochastic
decoding strategy to effectively balance accuracy and diversity. Compared to
competitive baselines, our KCS improves the overall accuracy of knowledge
composition selection by 3.9%, and its application for data augmentation yields
improvements on HotpotQA and 2WikiMultihopQA datasets. Our code is available
at: https://github.com/yangfanww/kcs.

</details>


### [25] [A Graph Talks, But Who's Listening? Rethinking Evaluations for Graph-Language Models](https://arxiv.org/abs/2508.20583)
*Soham Petkar,Hari Aakash K,Anirudh Vempati,Akshit Sinha,Ponnurangam Kumarauguru,Chirag Agarwal*

Main category: cs.CL

TL;DR: 当前图语言模型评测基准存在缺陷，新的CLEGR基准显示GLM在多模态推理能力不足，soft-prompted LLM基线与全GNN背锁的GLM表现相似


<details>
  <summary>Details</summary>
Motivation: 现有图语言模型评测基准主要是重用节点分类数据集，无法有效评估多模态推理能力，需要更好的评测方法

Method: 提出CLEGR评测基准，采用合成图生成流水线配合需要结构和语义联合推理的问题，对各种GLM架构进行详细评测

Result: 发现soft-prompted LLM基线与全GNN背锁的GLM表现相似，GLM在需要结构推理的任务中表现显著下降，现有GLM的图结构推理能力有限

Conclusion: 当前GLM在图结构推理能力上存在显著局限性，CLEGR基准为推进多模态推理研究提供了基础，并对是否需要在LLM中集成图结构提出疑问

Abstract: Developments in Graph-Language Models (GLMs) aim to integrate the structural
reasoning capabilities of Graph Neural Networks (GNNs) with the semantic
understanding of Large Language Models (LLMs). However, we demonstrate that
current evaluation benchmarks for GLMs, which are primarily repurposed
node-level classification datasets, are insufficient to assess multimodal
reasoning. Our analysis reveals that strong performance on these benchmarks is
achievable using unimodal information alone, suggesting that they do not
necessitate graph-language integration. To address this evaluation gap, we
introduce the CLEGR(Compositional Language-Graph Reasoning) benchmark, designed
to evaluate multimodal reasoning at various complexity levels. Our benchmark
employs a synthetic graph generation pipeline paired with questions that
require joint reasoning over structure and textual semantics. We perform a
thorough evaluation of representative GLM architectures and find that
soft-prompted LLM baselines perform on par with GLMs that incorporate a full
GNN backbone. This result calls into question the architectural necessity of
incorporating graph structure into LLMs. We further show that GLMs exhibit
significant performance degradation in tasks that require structural reasoning.
These findings highlight limitations in the graph reasoning capabilities of
current GLMs and provide a foundation for advancing the community toward
explicit multimodal reasoning involving graph structure and language.

</details>


### [26] [Generative Annotation for ASR Named Entity Correction](https://arxiv.org/abs/2508.20700)
*Yuanchang Luo,Daimeng Wei,Shaojun Li,Hengchao Shang,Jiaxin Guo,Zongyao Li,Zhanglin Wu,Xiaoyu Chen,Zhiqiang Rao,Jinlong Yang,Hao Yang*

Main category: cs.CL

TL;DR: 这篇论文提出了一种利用语音声音特征来编辑识别域特定命名实体的新方法，解决了当错误转写单词与真实实体形式差异较大时的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的命名实体纠正模型主要依靠语音级别编辑距离算法，在转写错误单词与真实实体形式差异较大时效果局限。

Method: 利用语音声音特征检索候选实体，设计生成式方法来标注ASR转写文本中的实体错误并替换为正确实体。

Result: 在开源和自建测试集上验证，该方法在实体准确率方面带来显著提升，尤其在单词形式差异较大的场景下效果突出。

Conclusion: 该方法有效解决了传统语音级别编辑距离方法的局限性，将开源自建测试集和训练数据。

Abstract: End-to-end automatic speech recognition systems often fail to transcribe
domain-specific named entities, causing catastrophic failures in downstream
tasks. Numerous fast and lightweight named entity correction (NEC) models have
been proposed in recent years. These models, mainly leveraging phonetic-level
edit distance algorithms, have shown impressive performances. However, when the
forms of the wrongly-transcribed words(s) and the ground-truth entity are
significantly different, these methods often fail to locate the wrongly
transcribed words in hypothesis, thus limiting their usage. We propose a novel
NEC method that utilizes speech sound features to retrieve candidate entities.
With speech sound features and candidate entities, we inovatively design a
generative method to annotate entity errors in ASR transcripts and replace the
text with correct entities. This method is effective in scenarios of word form
difference. We test our method using open-source and self-constructed test
sets. The results demonstrate that our NEC method can bring significant
improvement to entity accuracy. We will open source our self-constructed test
set and training data.

</details>


### [27] [Multi-Lingual Implicit Discourse Relation Recognition with Multi-Label Hierarchical Learning](https://arxiv.org/abs/2508.20712)
*Nelson Filipe Costa,Leila Kosseim*

Main category: cs.CL

TL;DR: 本文提出了首个多语言多标签隐式篇章关系识别模型HArch，在DiscoGeM 2.0语料库上验证了其有效性，通过层次化依赖关系预测PDTB 3.0框架中的三个意义层次，并在多语言设置下超越了GPT-4o和Llama-4-Maverick等大语言模型。


<details>
  <summary>Details</summary>
Motivation: 现有的隐式篇章关系识别(IDRR)研究主要局限于单语言和单标签分类，缺乏对多语言和多层次意义识别的研究。需要开发能够处理多语言文本并同时预测多个层次篇章关系的模型。

Method: 提出HArch模型，利用篇章意义之间的层次依赖关系，在PDTB 3.0框架的三个意义层次上预测概率分布。比较了多种预训练编码器主干网络，包括RoBERTa和XLM-RoBERTa，并与GPT-4o和Llama-4-Maverick进行少样本提示对比。

Result: RoBERTa-HArch在英语上表现最佳，XLM-RoBERTa-HArch在多语言设置中表现最好。微调模型在所有语言配置中都 consistently 超越了大语言模型。在DiscoGeM 1.0语料库上取得了最先进的结果。

Conclusion: 任务特定的微调在隐式篇章关系识别中优于提示方法，层次化方法有效验证了模型的有效性，为多语言多标签篇章分析提供了新的解决方案。

Abstract: This paper introduces the first multi-lingual and multi-label classification
model for implicit discourse relation recognition (IDRR). Our model, HArch, is
evaluated on the recently released DiscoGeM 2.0 corpus and leverages
hierarchical dependencies between discourse senses to predict probability
distributions across all three sense levels in the PDTB 3.0 framework. We
compare several pre-trained encoder backbones and find that RoBERTa-HArch
achieves the best performance in English, while XLM-RoBERTa-HArch performs best
in the multi-lingual setting. In addition, we compare our fine-tuned models
against GPT-4o and Llama-4-Maverick using few-shot prompting across all
language configurations. Our results show that our fine-tuned models
consistently outperform these LLMs, highlighting the advantages of
task-specific fine-tuning over prompting in IDRR. Finally, we report SOTA
results on the DiscoGeM 1.0 corpus, further validating the effectiveness of our
hierarchical approach.

</details>


### [28] [Addressing Tokenization Inconsistency in Steganography and Watermarking Based on Large Language Models](https://arxiv.org/abs/2508.20718)
*Ruiyi Yan,Yugo Murawaki*

Main category: cs.CL

TL;DR: 这篇论文研究了大语言模型中的标记化不一致性问题，提出了针对文本隐写和水印技术的两种解决方案，显著提升了文本质量和安全性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在提升文本生成质量的同时，也带来了文本隐写和水印技术的安全需求。标记化不一致性会影响系统的稳健性，需要解决。

Method: 识别出导致标记化不一致的问题标记具有频率低和临时性特征，并提出两种方法：针对隐写技术的步进验证法，和针对水印技术的后处理回滚法。

Result: 实验结果显示：(1)在隐写技术中，直接解决标记化不一致问题能提升文本流畅性、难以察觉性和反隐写分析能力；(2)在水印技术中，解决标记化不一致问题能增强检测能力和对攻击的稳健性。

Conclusion: 通过针对标记化不一致问题的特定解决方案，能够有效提升文本隐写和水印技术的性能和安全性，为大语言模型的安全应用提供了重要支撑。

Abstract: Large language models have significantly enhanced the capacities and
efficiency of text generation. On the one hand, they have improved the quality
of text-based steganography. On the other hand, they have also underscored the
importance of watermarking as a safeguard against malicious misuse. In this
study, we focus on tokenization inconsistency (TI) between Alice and Bob in
steganography and watermarking, where TI can undermine robustness. Our
investigation reveals that the problematic tokens responsible for TI exhibit
two key characteristics: infrequency and temporariness. Based on these
findings, we propose two tailored solutions for TI elimination: a stepwise
verification method for steganography and a post-hoc rollback method for
watermarking. Experiments show that (1) compared to traditional disambiguation
methods in steganography, directly addressing TI leads to improvements in
fluency, imperceptibility, and anti-steganalysis capacity; (2) for
watermarking, addressing TI enhances detectability and robustness against
attacks.

</details>


### [29] [rStar2-Agent: Agentic Reasoning Technical Report](https://arxiv.org/abs/2508.20722)
*Ning Shang,Yifei Liu,Yi Zhu,Li Lyna Zhang,Weijiang Xu,Xinyu Guan,Buze Zhang,Bingcheng Dong,Xudong Zhou,Bowen Zhang,Ying Xin,Ziming Miao,Scarlett Li,Fan Yang,Mao Yang*

Main category: cs.CL

TL;DR: rStar2-Agent是一个14B参数的数学推理模型，通过智能体强化学习训练，在有限GPU资源下实现前沿性能，在AIME数学竞赛中超越DeepSeek-R1等大模型


<details>
  <summary>Details</summary>
Motivation: 当前长链思维推理存在效率问题，需要开发能够自主探索、验证和优化中间步骤的智能体模型，同时降低训练成本

Method: 采用三阶段训练方法：非推理SFT预训练、多阶段RL训练，结合GRPO-RoC算法和重采样策略，在高效Python代码环境中进行高吞吐量执行

Result: 仅用510步RL训练和一周时间，在AIME24和AIME25上分别达到80.6%和69.8%的pass@1分数，超越DeepSeek-R1（671B），响应更短

Conclusion: 该方法证明了在有限计算资源下通过智能体强化学习可以训练出具有先进认知能力的模型，在数学推理、科学推理和工具使用任务上表现出强泛化能力

Abstract: We introduce rStar2-Agent, a 14B math reasoning model trained with agentic
reinforcement learning to achieve frontier-level performance. Beyond current
long CoT, the model demonstrates advanced cognitive behaviors, such as thinking
carefully before using Python coding tools and reflecting on code execution
feedback to autonomously explore, verify, and refine intermediate steps in
complex problem-solving. This capability is enabled through three key
innovations that makes agentic RL effective at scale: (i) an efficient RL
infrastructure with a reliable Python code environment that supports
high-throughput execution and mitigates the high rollout costs, enabling
training on limited GPU resources (64 MI300X GPUs); (ii) GRPO-RoC, an agentic
RL algorithm with a Resample-on-Correct rollout strategy that addresses the
inherent environment noises from coding tools, allowing the model to reason
more effectively in a code environment; (iii) An efficient agent training
recipe that starts with non-reasoning SFT and progresses through multi-RL
stages, yielding advanced cognitive abilities with minimal compute cost. To
this end, rStar2-Agent boosts a pre-trained 14B model to state of the art in
only 510 RL steps within one week, achieving average pass@1 scores of 80.6% on
AIME24 and 69.8% on AIME25, surpassing DeepSeek-R1 (671B) with significantly
shorter responses. Beyond mathematics, rStar2-Agent-14B also demonstrates
strong generalization to alignment, scientific reasoning, and agentic tool-use
tasks. Code and training recipes are available at
https://github.com/microsoft/rStar.

</details>


### [30] [Leveraging Semantic Triples for Private Document Generation with Local Differential Privacy Guarantees](https://arxiv.org/abs/2508.20736)
*Stephen Meisenbacher,Maulik Chevli,Florian Matthes*

Main category: cs.CL

TL;DR: 提出了DP-ST方法，利用语义三元组在本地差分隐私下实现邻域感知的私有文档生成，通过分治策略和LLM后处理在较低ε值下保持文本连贯性


<details>
  <summary>Details</summary>
Motivation: 解决本地差分隐私下文本隐私保护的挑战，传统方法在低ε值时效果不佳，需要找到平衡隐私和效用的新方法

Method: DP-ST方法，基于语义三元组进行邻域感知的私有文档生成，采用分治策略，限制隐私保护到特定的邻域概念，并结合LLM进行后处理

Result: 方法在较低ε值下仍能生成连贯文本，有效平衡了隐私保护和文本效用，证明了分治范式在文本隐私保护中的有效性

Conclusion: 通过语义三元组和LLM后处理的结合，在本地差分隐私框架下实现了更好的隐私-效用平衡，强调了文本连贯性在合理ε水平下实现平衡隐私输出的重要性

Abstract: Many works at the intersection of Differential Privacy (DP) in Natural
Language Processing aim to protect privacy by transforming texts under DP
guarantees. This can be performed in a variety of ways, from word perturbations
to full document rewriting, and most often under local DP. Here, an input text
must be made indistinguishable from any other potential text, within some bound
governed by the privacy parameter $\varepsilon$. Such a guarantee is quite
demanding, and recent works show that privatizing texts under local DP can only
be done reasonably under very high $\varepsilon$ values. Addressing this
challenge, we introduce DP-ST, which leverages semantic triples for
neighborhood-aware private document generation under local DP guarantees.
Through the evaluation of our method, we demonstrate the effectiveness of the
divide-and-conquer paradigm, particularly when limiting the DP notion (and
privacy guarantees) to that of a privatization neighborhood. When combined with
LLM post-processing, our method allows for coherent text generation even at
lower $\varepsilon$ values, while still balancing privacy and utility. These
findings highlight the importance of coherence in achieving balanced
privatization outputs at reasonable $\varepsilon$ levels.

</details>


### [31] [Specializing General-purpose LLM Embeddings for Implicit Hate Speech Detection across Datasets](https://arxiv.org/abs/2508.20750)
*Vassiliy Cheremetiev,Quang Long Ho Ngo,Chau Ying Kot,Alina Elena Baia,Andrea Cavallaro*

Main category: cs.CL

TL;DR: 通过微调基于大语言模型的通用嵌入模型（如Stella、Jasper等），在隐式仇恨言论检测任务上取得了最先进性能，在跨数据集评估中提升显著


<details>
  <summary>Details</summary>
Motivation: 隐式仇恨言论（IHS）使用间接语言表达偏见和仇恨，难以检测，因为不包含明确的贬损性词汇。传统方法需要依赖外部知识或额外信息

Method: 仅通过微调最近的通用嵌入模型（基于大语言模型），包括Stella、Jasper、NV-Embed和E5等模型

Result: 在多个IHS数据集上实验显示，数据集内评估F1-macro得分提升最高1.10个百分点，跨数据集评估提升最高20.35个百分点

Conclusion: 微调通用嵌入模型是检测隐式仇恨言论的有效方法，无需额外信息就能实现state-of-the-art性能

Abstract: Implicit hate speech (IHS) is indirect language that conveys prejudice or
hatred through subtle cues, sarcasm or coded terminology. IHS is challenging to
detect as it does not include explicit derogatory or inflammatory words. To
address this challenge, task-specific pipelines can be complemented with
external knowledge or additional information such as context, emotions and
sentiment data. In this paper, we show that, by solely fine-tuning recent
general-purpose embedding models based on large language models (LLMs), such as
Stella, Jasper, NV-Embed and E5, we achieve state-of-the-art performance.
Experiments on multiple IHS datasets show up to 1.10 percentage points
improvements for in-dataset, and up to 20.35 percentage points improvements in
cross-dataset evaluation, in terms of F1-macro score.

</details>


### [32] [GUARD: Glocal Uncertainty-Aware Robust Decoding for Effective and Efficient Open-Ended Text Generation](https://arxiv.org/abs/2508.20757)
*Yuanhao Ding,Esteban Garces Arias,Meimingwei Li,Julian Rodemann,Matthias Aßenmacher,Danlu Chen,Gaojuan Fan,Christian Heumann,Chongsheng Zhang*

Main category: cs.CL

TL;DR: GUARD是一种自适应的解码方法，通过全局和局部不确定性信号平衡文本生成的连贯性和多样性，同时提高生成速度


<details>
  <summary>Details</summary>
Motivation: 解决开放式文本生成中连贯性与多样性平衡的挑战，现有对比搜索方法存在超参数依赖和计算成本高的问题

Method: 提出GUARD方法，结合全局熵估计和局部熵偏差的"Glocal"不确定性框架，加入基于token计数的惩罚机制降低计算开销

Result: 实验证明GUARD在文本多样性和连贯性之间取得良好平衡，生成速度显著提升，人类和LLM评估者均验证其优异性能

Conclusion: GUARD提供了一种有效且高效的自适应解码方法，解决了现有方法的局限性，具有理论保证和实际应用价值

Abstract: Open-ended text generation faces a critical challenge: balancing coherence
with diversity in LLM outputs. While contrastive search-based decoding
strategies have emerged to address this trade-off, their practical utility is
often limited by hyperparameter dependence and high computational costs. We
introduce GUARD, a self-adaptive decoding method that effectively balances
these competing objectives through a novel "Glocal" uncertainty-driven
framework. GUARD combines global entropy estimates with local entropy
deviations to integrate both long-term and short-term uncertainty signals. We
demonstrate that our proposed global entropy formulation effectively mitigates
abrupt variations in uncertainty, such as sudden overconfidence or high entropy
spikes, and provides theoretical guarantees of unbiasedness and consistency. To
reduce computational overhead, we incorporate a simple yet effective
token-count-based penalty into GUARD. Experimental results demonstrate that
GUARD achieves a good balance between text diversity and coherence, while
exhibiting substantial improvements in generation speed. In a more nuanced
comparison study across different dimensions of text quality, both human and
LLM evaluators validated its remarkable performance. Our code is available at
https://github.com/YecanLee/GUARD.

</details>


### [33] [Feel the Difference? A Comparative Analysis of Emotional Arcs in Real and LLM-Generated CBT Sessions](https://arxiv.org/abs/2508.20764)
*Xiaoyi Wang,Jiwei Zhang,Guangtao Zhang,Honglei Guo*

Main category: cs.CL

TL;DR: 本文比较了真实与LLM生成的心理治疗对话的情感动态差异，发现合成对话在情感变异性、情感语言丰富度和情感反应模式等方面与真实对话存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 随着LLM生成的心理治疗对话在心理健康NLP中广泛应用，需要评估这些合成对话是否能够捕捉真实治疗中微妙的情感动态。

Method: 采用Utterance Emotion Dynamics框架，从效价、唤醒度和支配度三个维度分析情感轨迹，比较真实CBT会话和CACTUS数据集中合成对话的情感特征。

Result: 合成对话虽然流畅且结构连贯，但在情感特性上与真实对话存在差异：真实会话表现出更大的情感变异性、更丰富的情感语言以及更真实的反应和调节模式。

Conclusion: 当前LLM生成的治疗数据存在局限性，情感保真度对心理健康应用至关重要。研究引入了RealCBT数据集以支持未来研究。

Abstract: Synthetic therapy dialogues generated by large language models (LLMs) are
increasingly used in mental health NLP to simulate counseling scenarios, train
models, and supplement limited real-world data. However, it remains unclear
whether these synthetic conversations capture the nuanced emotional dynamics of
real therapy. In this work, we conduct the first comparative analysis of
emotional arcs between real and LLM-generated Cognitive Behavioral Therapy
dialogues. We adapt the Utterance Emotion Dynamics framework to analyze
fine-grained affective trajectories across valence, arousal, and dominance
dimensions. Our analysis spans both full dialogues and individual speaker roles
(counselor and client), using real sessions transcribed from public videos and
synthetic dialogues from the CACTUS dataset. We find that while synthetic
dialogues are fluent and structurally coherent, they diverge from real
conversations in key emotional properties: real sessions exhibit greater
emotional variability,more emotion-laden language, and more authentic patterns
of reactivity and regulation. Moreover, emotional arc similarity between real
and synthetic speakers is low, especially for clients. These findings
underscore the limitations of current LLM-generated therapy data and highlight
the importance of emotional fidelity in mental health applications. We
introduce RealCBT, a curated dataset of real CBT sessions, to support future
research in this space.

</details>


### [34] [Turning the Spell Around: Lightweight Alignment Amplification via Rank-One Safety Injection](https://arxiv.org/abs/2508.20766)
*Harethah Abu Shairah,Hasan Abed Al Kader Hammoud,George Turkiyyah,Bernard Ghanem*

Main category: cs.CL

TL;DR: ROSI是一种白盒方法，通过永久性地将模型激活引导至拒绝调解子空间来增强LLM的安全对齐，无需微调即可提高安全拒绝率，同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM安全对齐机制可以通过消除特定表示方向来绕过，需要一种更有效的方法来增强模型的安全防护能力。

Method: 提出Rank-One Safety Injection (ROSI)方法，通过对所有残差流写入矩阵应用简单的秩一权重修改，从小型有害/无害指令对计算安全方向。

Result: ROSI持续提高安全拒绝率（Llama Guard 3评估），同时在MMLU、HellaSwag和Arc等标准基准测试中保持模型效用，还能重新对齐'未审查'模型。

Conclusion: 定向、可解释的权重引导是改善LLM安全性的廉价而有效的机制，可作为资源密集型微调范式的补充。

Abstract: Safety alignment in Large Language Models (LLMs) often involves mediating
internal representations to refuse harmful requests. Recent research has
demonstrated that these safety mechanisms can be bypassed by ablating or
removing specific representational directions within the model. In this paper,
we propose the opposite approach: Rank-One Safety Injection (ROSI), a white-box
method that amplifies a model's safety alignment by permanently steering its
activations toward the refusal-mediating subspace. ROSI operates as a simple,
fine-tuning-free rank-one weight modification applied to all residual stream
write matrices. The required safety direction can be computed from a small set
of harmful and harmless instruction pairs. We show that ROSI consistently
increases safety refusal rates - as evaluated by Llama Guard 3 - while
preserving the utility of the model on standard benchmarks such as MMLU,
HellaSwag, and Arc. Furthermore, we show that ROSI can also re-align
'uncensored' models by amplifying their own latent safety directions,
demonstrating its utility as an effective last-mile safety procedure. Our
results suggest that targeted, interpretable weight steering is a cheap and
potent mechanism to improve LLM safety, complementing more resource-intensive
fine-tuning paradigms.

</details>


### [35] [Signs of Struggle: Spotting Cognitive Distortions across Language and Register](https://arxiv.org/abs/2508.20771)
*Abhishek Kuber,Enrico Liscio,Ruixuan Zhang,Caroline Figueroa,Pradeep K. Murukannaiah*

Main category: cs.CL

TL;DR: 首个跨语言和跨语域认知扭曲检测研究，分析荷兰青少年论坛帖子，发现语言和写作风格变化显著影响模型性能，领域适应方法最有前景


<details>
  <summary>Details</summary>
Motivation: 青少年心理健康问题日益严重，需要自动化检测心理困扰的早期迹象，特别是识别可能加剧心理困扰的非理性思维模式（认知扭曲），早期发现可实现及时、低成本的干预

Method: 研究跨语言（从英语到荷兰语）和跨语域（从临床数据到论坛帖子）的泛化能力，分析荷兰青少年论坛帖子，使用领域适应方法来处理语言和写作风格的变化

Result: 语言和写作风格的变化会显著影响认知扭曲检测模型的性能表现

Conclusion: 领域适应方法在跨语言和跨语域的认知扭曲检测中显示出最大的应用潜力

Abstract: Rising mental health issues among youth have increased interest in automated
approaches for detecting early signs of psychological distress in digital text.
One key focus is the identification of cognitive distortions, irrational
thought patterns that have a role in aggravating mental distress. Early
detection of these distortions may enable timely, low-cost interventions. While
prior work has focused on English clinical data, we present the first in-depth
study of cross-lingual and cross-register generalization of cognitive
distortion detection, analyzing forum posts written by Dutch adolescents. Our
findings show that while changes in language and writing style can
significantly affect model performance, domain adaptation methods show the most
promise.

</details>


### [36] [Exploring Machine Learning and Language Models for Multimodal Depression Detection](https://arxiv.org/abs/2508.20805)
*Javier Si Zhao Hong,Timothy Zoe Delaya,Sherwyn Chan Yin Kit,Pai Chet Ng,Xiaoxiao Miao*

Main category: cs.CL

TL;DR: 本文比较了XGBoost、transformer架构和大语言模型在音频、视频和文本特征上的多模态抑郁症检测性能


<details>
  <summary>Details</summary>
Motivation: 参加首届多模态人格感知抑郁症检测挑战赛，探索机器学习模型在多模态抑郁症检测中的应用

Method: 使用XGBoost、transformer架构和大语言模型(LLMs)处理音频、视频和文本特征，进行多模态抑郁症检测

Result: 比较了不同类型模型在捕捉跨模态抑郁症相关信号方面的优势和局限性

Conclusion: 为心理健康预测提供了有效的多模态表示策略的见解

Abstract: This paper presents our approach to the first Multimodal Personality-Aware
Depression Detection Challenge, focusing on multimodal depression detection
using machine learning and deep learning models. We explore and compare the
performance of XGBoost, transformer-based architectures, and large language
models (LLMs) on audio, video, and text features. Our results highlight the
strengths and limitations of each type of model in capturing depression-related
signals across modalities, offering insights into effective multimodal
representation strategies for mental health prediction.

</details>


### [37] [GDLLM: A Global Distance-aware Modeling Approach Based on Large Language Models for Event Temporal Relation Extraction](https://arxiv.org/abs/2508.20828)
*Jie Zhao,Wanting Ning,Yuxiao Fei,Yubo Feng,Lishuang Li*

Main category: cs.CL

TL;DR: 提出GDLLM方法，通过距离感知图结构和软推理时序特征学习，增强大语言模型对事件时序关系的长距离依赖捕捉能力，在少数类关系上表现优异


<details>
  <summary>Details</summary>
Motivation: 解决小语言模型在数据不平衡时对少数类关系处理能力有限，以及大语言模型手动提示可能引入噪声干扰长距离依赖判断的问题

Method: 基于大语言模型的全局距离感知建模方法，使用图注意力网络构建距离感知图结构捕捉长距离依赖，设计基于软推理的时序特征学习范式增强短距离关系识别

Result: 在两个公开数据集TB-Dense和MATRES上达到最先进性能，显著提升少数关系类的表现和整体学习能力

Conclusion: GDLLM框架通过有效捕捉全局特征，显著增强了对少数关系类的识别能力，并提升了整体事件时序关系抽取性能

Abstract: In Natural Language Processing(NLP), Event Temporal Relation Extraction
(ETRE) is to recognize the temporal relations of two events. Prior studies have
noted the importance of language models for ETRE. However, the restricted
pre-trained knowledge of Small Language Models(SLMs) limits their capability to
handle minority class relations in imbalanced classification datasets. For
Large Language Models(LLMs), researchers adopt manually designed prompts or
instructions, which may introduce extra noise, leading to interference with the
model's judgment of the long-distance dependencies between events. To address
these issues, we propose GDLLM, a Global Distance-aware modeling approach based
on LLMs. We first present a distance-aware graph structure utilizing Graph
Attention Network(GAT) to assist the LLMs in capturing long-distance dependency
features. Additionally, we design a temporal feature learning paradigm based on
soft inference to augment the identification of relations with a short-distance
proximity band, which supplements the probabilistic information generated by
LLMs into the multi-head attention mechanism. Since the global feature can be
captured effectively, our framework substantially enhances the performance of
minority relation classes and improves the overall learning ability.
Experiments on two publicly available datasets, TB-Dense and MATRES,
demonstrate that our approach achieves state-of-the-art (SOTA) performance.

</details>


### [38] [MSRS: Evaluating Multi-Source Retrieval-Augmented Generation](https://arxiv.org/abs/2508.20867)
*Rohan Phanse,Yijie Zhou,Kejian Shi,Wencai Zhang,Yixin Liu,Yilun Zhao,Arman Cohan*

Main category: cs.CL

TL;DR: 这篇论文提出了一个可扩展的评测框架，用于构建需要多源信息综合的RAG系统评测基准，并创建了MSRS-Story和MSRS-Meet两个新的多源检索与综合测试集。


<details>
  <summary>Details</summary>
Motivation: 当前的RAG系统评估多假设查找信息可以在单个源中找到，或者答案是短式/事实性的。然而实际应用常常需要综合多个来源的信息并生成长文本回复。

Method: 提出了一个可扩展的评测框架，构建了MSRS-Story和MSRS-Meet两个测试集，分别代表故事综合和摘要任务。使用各种RAG流水线（包括稀疏和浓密检索器结合先进LLM）进行实验。

Result: 生成质量很大程度依赖于检索效果，且不同任务间差异显著。即使在理想检索条件下，多源综合仍具有挑战性，但理解模型在这一步驾上显著超过标准LLM。

Conclusion: 这个框架能够有效地评估RAG系统在多源信息综合任务中的表现，并显示了检索效果对生成质量的关键影响以及理解模型在综合步骤中的优势。

Abstract: Retrieval-augmented systems are typically evaluated in settings where
information required to answer the query can be found within a single source or
the answer is short-form or factoid-based. However, many real-world
applications demand the ability to integrate and summarize information
scattered across multiple sources, where no single source is sufficient to
respond to the user's question. In such settings, the retrieval component of a
RAG pipeline must recognize a variety of relevance signals, and the generation
component must connect and synthesize information across multiple sources. We
present a scalable framework for constructing evaluation benchmarks that
challenge RAG systems to integrate information across distinct sources and
generate long-form responses. Using our framework, we build two new benchmarks
on Multi-Source Retrieval and Synthesis: MSRS-Story and MSRS-Meet, representing
narrative synthesis and summarization tasks, respectively, that require
retrieval from large collections. Our extensive experiments with various RAG
pipelines -- including sparse and dense retrievers combined with frontier LLMs
-- reveal that generation quality is highly dependent on retrieval
effectiveness, which varies greatly by task. While multi-source synthesis
proves challenging even in an oracle retrieval setting, we find that reasoning
models significantly outperform standard LLMs at this distinct step.

</details>


### [39] [The Uneven Impact of Post-Training Quantization in Machine Translation](https://arxiv.org/abs/2508.20893)
*Benjamin Marie,Atsushi Fujita*

Main category: cs.CL

TL;DR: 大规模评估显示，4位量化对高资源语言和大模型翻译质量影响较小，但2位量化对低资源和类型多样语言造成显著性能下降，GGUF方法在低比特场景下表现最稳定。


<details>
  <summary>Details</summary>
Motivation: 量化技术对于在资源受限硬件上部署大语言模型至关重要，但其在多语言任务（特别是机器翻译）中的影响尚未得到充分探索，需要系统评估不同量化方法对多语言性能的影响。

Method: 使用5个参数量从17亿到700亿的大语言模型，在55种语言上进行后训练量化评估，比较了AWQ、BitsAndBytes、GGUF和AutoRound四种量化技术，并分析了量化与解码超参数、校准语言的交互作用。

Result: 4位量化通常能保持高资源语言和大模型的翻译质量，但低资源和类型多样语言在2位量化下出现显著性能下降；GGUF变体在2位精度下提供最一致的性能；语言匹配的校准主要在低比特场景下有益。

Conclusion: 研究为在量化约束下部署多语言大语言模型提供了实用指导，特别是在低资源设置中，算法选择和模型大小共同决定了量化鲁棒性。

Abstract: Quantization is essential for deploying large language models (LLMs) on
resource-constrained hardware, but its implications for multilingual tasks
remain underexplored. We conduct the first large-scale evaluation of
post-training quantization (PTQ) on machine translation across 55 languages
using five LLMs ranging from 1.7B to 70B parameters. Our analysis reveals that
while 4-bit quantization often preserves translation quality for high-resource
languages and large models, significant degradation occurs for low-resource and
typologically diverse languages, particularly in 2-bit settings. We compare
four quantization techniques (AWQ, BitsAndBytes, GGUF, and AutoRound), showing
that algorithm choice and model size jointly determine robustness. GGUF
variants provide the most consistent performance, even at 2-bit precision.
Additionally, we quantify the interactions between quantization, decoding
hyperparameters, and calibration languages, finding that language-matched
calibration offers benefits primarily in low-bit scenarios. Our findings offer
actionable insights for deploying multilingual LLMs for machine translation
under quantization constraints, especially in low-resource settings.

</details>


### [40] [SageLM: A Multi-aspect and Explainable Large Language Model for Speech Judgement](https://arxiv.org/abs/2508.20916)
*Yuan Ge,Junxiang Zhang,Xiaoqian Liu,Bei Li,Xiangnan Ma,Chenglong Wang,Kaiyang Ye,Yangfan Du,Linfeng Zhang,Yuxin Huang,Tong Xiao,Zhengtao Yu,JingBo Zhu*

Main category: cs.CL

TL;DR: SageLM是一个端到端、多维度、可解释的语音大语言模型，用于全面评估语音到语音转换的LLM系统，在语义和声学维度上联合评估，通过基于原理的监督提高可解释性，并在人类评估一致性方面显著优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 当前语音到语音大语言模型的评估存在根本性挑战，级联方法忽视了声学特征，需要一种能够同时评估语义和声学维度的综合评估方法。

Method: 提出SageLM模型，采用基于原理的监督增强可解释性，引入SpeechFeedback合成偏好数据集，使用两阶段训练范式缓解语音偏好数据稀缺问题，在语义和声学维度上联合训练。

Result: SageLM与人类评估者达成82.79%的一致率，比级联方法和SLM基线分别至少高出7.42%和26.20%。

Conclusion: SageLM为语音到语音LLM提供了全面、可解释的评估框架，在多个维度上显著优于现有方法，解决了语音评估中的数据稀缺和评估维度单一的问题。

Abstract: Speech-to-Speech (S2S) Large Language Models (LLMs) are foundational to
natural human-computer interaction, enabling end-to-end spoken dialogue
systems. However, evaluating these models remains a fundamental challenge. We
propose \texttt{SageLM}, an end-to-end, multi-aspect, and explainable speech
LLM for comprehensive S2S LLMs evaluation. First, unlike cascaded approaches
that disregard acoustic features, SageLM jointly assesses both semantic and
acoustic dimensions. Second, it leverages rationale-based supervision to
enhance explainability and guide model learning, achieving superior alignment
with evaluation outcomes compared to rule-based reinforcement learning methods.
Third, we introduce \textit{SpeechFeedback}, a synthetic preference dataset,
and employ a two-stage training paradigm to mitigate the scarcity of speech
preference data. Trained on both semantic and acoustic dimensions, SageLM
achieves an 82.79\% agreement rate with human evaluators, outperforming
cascaded and SLM-based baselines by at least 7.42\% and 26.20\%, respectively.

</details>


### [41] [How Can Input Reformulation Improve Tool Usage Accuracy in a Complex Dynamic Environment? A Study on $τ$-bench](https://arxiv.org/abs/2508.20931)
*Venkatesh Mishra,Amir Saeidi,Satyam Raj,Mutsumi Nakamura,Jayanth Srinivasa,Gaowen Liu,Ali Payani,Chitta Baral*

Main category: cs.CL

TL;DR: IRMA框架通过自动重构用户查询并添加领域规则和工具建议，在多轮对话环境中显著提升了LLM工具调用代理的性能，相比现有方法有16.1%-19.1%的改进。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在多轮对话环境中作为自主工具调用代理时，存在推理不一致、难以遵守领域特定策略以及在长对话中提取正确信息的问题，需要解决这些失败情况。

Method: 提出Input-Reformulation Multi-Agent (IRMA)框架，自动重构用户查询并增强相关领域规则和工具建议，帮助工具调用代理更好地聚焦关键信息。

Result: IRMA在整体通过率上显著优于ReAct、Function Calling和Self-Reflection方法，分别提高了16.1%、12.7%和19.1%。

Conclusion: IRMA框架在动态环境中展现出比其他方法更优越的可靠性和一致性，为LLM工具调用代理的性能提升提供了有效解决方案。

Abstract: Recent advances in reasoning and planning capabilities of large language
models (LLMs) have enabled their potential as autonomous agents capable of tool
use in dynamic environments. However, in multi-turn conversational environments
like $\tau$-bench, these agents often struggle with consistent reasoning,
adherence to domain-specific policies, and extracting correct information over
a long horizon of tool-calls and conversation. To capture and mitigate these
failures, we conduct a comprehensive manual analysis of the common errors
occurring in the conversation trajectories. We then experiment with
reformulations of inputs to the tool-calling agent for improvement in agent
decision making. Finally, we propose the Input-Reformulation Multi-Agent (IRMA)
framework, which automatically reformulates user queries augmented with
relevant domain rules and tool suggestions for the tool-calling agent to focus
on. The results show that IRMA significantly outperforms ReAct, Function
Calling, and Self-Reflection by 16.1%, 12.7%, and 19.1%, respectively, in
overall pass^5 scores. These findings highlight the superior reliability and
consistency of IRMA compared to other methods in dynamic environments.

</details>


### [42] [STARE at the Structure: Steering ICL Exemplar Selection with Structural Alignment](https://arxiv.org/abs/2508.20944)
*Jiaqian Li,Qisheng Hu,Jing Li,Wenya Wang*

Main category: cs.CL

TL;DR: 提出了一种新颖的两阶段示例选择策略，通过结构感知监督微调BERT检索器，并添加可插拔模块增强句法信息，显著提升语义解析等结构化预测任务的上下文学习效果。


<details>
  <summary>Details</summary>
Motivation: 现有的上下文学习示例选择策略往往忽视结构对齐，导致语义解析等结构化预测任务性能不佳和泛化能力差。

Method: 两阶段方法：1）使用结构感知监督微调BERT检索器，选择语义相关且结构对齐的示例；2）添加模型无关的可插拔模块，增强隐藏表示中的句法信息。

Result: 在四个基准测试和三个语义解析任务上的实验表明，该方法在多个最新LLM上始终优于现有基线方法。

Conclusion: 该方法在效率、泛化性和性能之间实现了良好平衡，可无缝集成到现有流程中，显著提升了结构化预测任务的上下文学习效果。

Abstract: In-Context Learning (ICL) has become a powerful paradigm that enables LLMs to
perform a wide range of tasks without task-specific fine-tuning. However, the
effectiveness of ICL heavily depends on the quality of exemplar selection. In
particular, for structured prediction tasks such as semantic parsing, existing
ICL selection strategies often overlook structural alignment, leading to
suboptimal performance and poor generalization. To address this issue, we
propose a novel two-stage exemplar selection strategy that achieves a strong
balance between efficiency, generalizability, and performance. First, we
fine-tune a BERT-based retriever using structure-aware supervision, guiding it
to select exemplars that are both semantically relevant and structurally
aligned. Then, we enhance the retriever with a plug-in module, which amplifies
syntactically meaningful information in the hidden representations. This
plug-in is model-agnostic, requires minimal overhead, and can be seamlessly
integrated into existing pipelines. Experiments on four benchmarks spanning
three semantic parsing tasks demonstrate that our method consistently
outperforms existing baselines with multiple recent LLMs as inference-time
models.

</details>


### [43] [ProactiveEval: A Unified Evaluation Framework for Proactive Dialogue Agents](https://arxiv.org/abs/2508.20973)
*Tianjian Liu,Fanqi Wan,Jiajian Guo,Xiaojun Quan*

Main category: cs.CL

TL;DR: 提出了ProactiveEval统一框架，用于评估大语言模型的主动对话能力，包含目标规划和对话引导两个维度，并在6个领域开发了328个评估环境。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注特定领域或任务导向场景，导致评估碎片化，限制了全面探索模型的主动对话能力。

Method: 提出ProactiveEval框架，将主动对话分解为目标规划和对话引导，建立跨领域评估指标，并支持自动生成多样化评估数据。

Result: 测试22种不同类型的大语言模型，发现DeepSeek-R1在目标规划任务上表现优异，Claude-3.7-Sonnet在对话引导任务上表现最佳。

Conclusion: 研究了推理能力对主动行为的影响，并讨论了这些发现对未来模型开发的启示。

Abstract: Proactive dialogue has emerged as a critical and challenging research problem
in advancing large language models (LLMs). Existing works predominantly focus
on domain-specific or task-oriented scenarios, which leads to fragmented
evaluations and limits the comprehensive exploration of models' proactive
conversation abilities. In this work, we propose ProactiveEval, a unified
framework designed for evaluating proactive dialogue capabilities of LLMs. This
framework decomposes proactive dialogue into target planning and dialogue
guidance, establishing evaluation metrics across various domains. Moreover, it
also enables the automatic generation of diverse and challenging evaluation
data. Based on the proposed framework, we develop 328 evaluation environments
spanning 6 distinct domains. Through experiments with 22 different types of
LLMs, we show that DeepSeek-R1 and Claude-3.7-Sonnet exhibit exceptional
performance on target planning and dialogue guidance tasks, respectively.
Finally, we investigate how reasoning capabilities influence proactive
behaviors and discuss their implications for future model development.

</details>


### [44] [Lethe: Purifying Backdoored Large Language Models with Knowledge Dilution](https://arxiv.org/abs/2508.21004)
*Chen Chen,Yuchen Sun,Jiaxin Gao,Xueluan Gong,Qian Wang,Ziyao Wang,Yongsen Zheng,Kwok-Yan Lam*

Main category: cs.CL

TL;DR: LETHE是一种通过知识稀释消除LLM后门行为的新方法，结合内部模型融合和外部提示增强，有效防御多种先进后门攻击


<details>
  <summary>Details</summary>
Motivation: 现有后门防御方法存在局限性，无法全面应对模型编辑、多触发器和无触发器等先进攻击场景，需要更全面的防御方案

Method: 内部使用轻量数据集训练干净模型并与后门模型融合以稀释恶意行为；外部在提示中添加良性相关证据分散模型对后门特征的注意力

Result: 在5个主流LLM的分类和生成任务上，LETHE优于8个SOTA防御基线，对先进后门攻击的成功率降低达98%，同时保持模型效用

Conclusion: LETHE是成本效益高且鲁棒的防御方法，能有效消除LLM后门行为，为后门防御提供了全面解决方案

Abstract: Large language models (LLMs) have seen significant advancements, achieving
superior performance in various Natural Language Processing (NLP) tasks.
However, they remain vulnerable to backdoor attacks, where models behave
normally for standard queries but generate harmful responses or unintended
output when specific triggers are activated. Existing backdoor defenses either
lack comprehensiveness, focusing on narrow trigger settings, detection-only
mechanisms, and limited domains, or fail to withstand advanced scenarios like
model-editing-based, multi-trigger, and triggerless attacks. In this paper, we
present LETHE, a novel method to eliminate backdoor behaviors from LLMs through
knowledge dilution using both internal and external mechanisms. Internally,
LETHE leverages a lightweight dataset to train a clean model, which is then
merged with the backdoored model to neutralize malicious behaviors by diluting
the backdoor impact within the model's parametric memory. Externally, LETHE
incorporates benign and semantically relevant evidence into the prompt to
distract LLM's attention from backdoor features. Experimental results on
classification and generation domains across 5 widely used LLMs demonstrate
that LETHE outperforms 8 state-of-the-art defense baselines against 8 backdoor
attacks. LETHE reduces the attack success rate of advanced backdoor attacks by
up to 98% while maintaining model utility. Furthermore, LETHE has proven to be
cost-efficient and robust against adaptive backdoor attacks.

</details>


### [45] [An Agile Method for Implementing Retrieval Augmented Generation Tools in Industrial SMEs](https://arxiv.org/abs/2508.21024)
*Mathieu Bourdin,Anas Neumann,Thomas Paviot,Robert Pellerin,Samir Lamouri*

Main category: cs.CL

TL;DR: EASI-RAG是一个为中小企业设计的结构化敏捷方法，用于快速部署RAG系统，解决了资源有限和NLP专业知识缺乏的问题。


<details>
  <summary>Details</summary>
Motivation: 解决RAG系统在中小企业部署困难的问题，因为中小企业资源有限且缺乏自然语言处理专业知识。

Method: 基于方法工程原则，定义了明确的角色、活动和技术，通过真实案例研究在环境测试实验室验证。

Result: 系统在一个月内由无RAG经验的团队部署成功，用户采纳率高，答案准确，数据可靠性增强。

Conclusion: EASI-RAG展示了在工业中小企业中部署RAG系统的潜力，未来需要扩展到更多用例并与微调模型进一步集成。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a powerful solution to
mitigate the limitations of Large Language Models (LLMs), such as
hallucinations and outdated knowledge. However, deploying RAG-based tools in
Small and Medium Enterprises (SMEs) remains a challenge due to their limited
resources and lack of expertise in natural language processing (NLP). This
paper introduces EASI-RAG, Enterprise Application Support for Industrial RAG, a
structured, agile method designed to facilitate the deployment of RAG systems
in industrial SME contexts. EASI-RAG is based on method engineering principles
and comprises well-defined roles, activities, and techniques. The method was
validated through a real-world case study in an environmental testing
laboratory, where a RAG tool was implemented to answer operators queries using
data extracted from operational procedures. The system was deployed in under a
month by a team with no prior RAG experience and was later iteratively improved
based on user feedback. Results demonstrate that EASI-RAG supports fast
implementation, high user adoption, delivers accurate answers, and enhances the
reliability of underlying data. This work highlights the potential of RAG
deployment in industrial SMEs. Future works include the need for generalization
across diverse use cases and further integration with fine-tuned models.

</details>


### [46] [Re-Representation in Sentential Relation Extraction with Sequence Routing Algorithm](https://arxiv.org/abs/2508.21049)
*Ramazan Ali Bahrami,Ramin Yahyapour*

Main category: cs.CL

TL;DR: 本文提出使用胶囊动态路由进行句级关系提取的方法，在多个标准数据集上超越了最新技术，但在更大的Wikidata数据集上表现不佳，分析发现标签噪声和重新表示能力是关键因素。


<details>
  <summary>Details</summary>
Motivation: 解决句级关系提取任务中的挑战，通过胶囊网络的动态路由机制提高模型性能，并探索模型在不同规模数据集上表现差异的根源。

Method: 使用胶囊动态路由机制进行句级关系提取，对比基线模型在Tacred、Tacredrev、Retacred、Conll04和Wikidata数据集上的表现。

Result: 在标准数据集上超越了最新技术，但在更大的Wikidata数据集上表现较差，发现标签噪声是主要问题，同时证实了模型具有更好的重新表示能力。

Conclusion: 距离监督关系提取数据集中的标签噪声和重新表示能力的缺乏是句级关系提取的重要挑战，胶囊动态路由方法在标准数据集上显示出优势。

Abstract: Sentential relation extraction (RE) is an important task in natural language
processing (NLP). In this paper we propose to do sentential RE with dynamic
routing in capsules. We first show that the proposed approach outperform state
of the art on common sentential relation extraction datasets Tacred, Tacredrev,
Retacred, and Conll04. We then investigate potential reasons for its good
performance on the mentioned datasets, and yet low performance on another
similar, yet larger sentential RE dataset, Wikidata. As such, we identify noise
in Wikidata labels as one of the reasons that can hinder performance.
Additionally, we show associativity of better performance with better
re-representation, a term from neuroscience referred to change of
representation in human brain to improve the match at comparison time. As
example, in the given analogous terms King:Queen::Man:Woman, at comparison
time, and as a result of re-representation, the similarity between related head
terms (King,Man), and tail terms (Queen,Woman) increases. As such, our
observation show that our proposed model can do re-representation better than
the vanilla model compared with. To that end, beside noise in the labels of the
distantly supervised RE datasets, we propose re-representation as a challenge
in sentential RE.

</details>


### [47] [Enabling Equitable Access to Trustworthy Financial Reasoning](https://arxiv.org/abs/2508.21051)
*William Jurayj,Nils Holzenberger,Benjamin Van Durme*

Main category: cs.CL

TL;DR: 结合大型语言模型与符号求解器的神经符号架构，用于自动化税务申报计算，在SARA数据集上取得显著性能提升，成本远低于现实世界平均水平


<details>
  <summary>Details</summary>
Motivation: 税务申报需要复杂推理和精确计算，传统方法耗时且易出错，而纯语言模型缺乏所需的准确性和可审计性，需要开发高精度、可审计的自动化系统

Method: 提出神经符号方法，将LLM与符号求解器集成，包括将文本规则转换为形式逻辑程序，以及智能检索形式案例表示示例

Result: 在SARA数据集上表现出色，系统部署成本估算远低于现实世界平均税务申报成本（270美元和13小时）

Conclusion: 神经符号架构有望实现可靠税务援助的公平获取，具有经济可行性，能显著降低税务申报成本和提高准确性

Abstract: According to the United States Internal Revenue Service, ''the average
American spends $\$270$ and 13 hours filing their taxes''. Even beyond the
U.S., tax filing requires complex reasoning, combining application of
overlapping rules with numerical calculations. Because errors can incur costly
penalties, any automated system must deliver high accuracy and auditability,
making modern large language models (LLMs) poorly suited for this task. We
propose an approach that integrates LLMs with a symbolic solver to calculate
tax obligations. We evaluate variants of this system on the challenging
StAtutory Reasoning Assessment (SARA) dataset, and include a novel method for
estimating the cost of deploying such a system based on real-world penalties
for tax errors. We further show how combining up-front translation of
plain-text rules into formal logic programs, combined with intelligently
retrieved exemplars for formal case representations, can dramatically improve
performance on this task and reduce costs to well below real-world averages.
Our results demonstrate the promise and economic feasibility of neuro-symbolic
architectures for increasing equitable access to reliable tax assistance.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [48] [A Systematic Review on the Generative AI Applications in Human Medical Genomics](https://arxiv.org/abs/2508.20275)
*Anton Changalidis,Yury Barbitoff,Yulia Nasykhova,Andrey Glotov*

Main category: cs.LG

TL;DR: 本文对172项研究进行系统综述，分析了大型语言模型在遗传研究和疾病诊断中的应用，包括基因组变异识别、医学影像分析等，同时指出了多模态数据整合和临床实施的挑战。


<details>
  <summary>Details</summary>
Motivation: 传统统计和机器学习方法在处理复杂高维遗传数据时存在局限，需要探索基于transformer架构的大型语言模型在遗传疾病诊断中的潜力。

Method: 通过PubMed、bioRxiv、medRxiv和arXiv的自动化关键词搜索，筛选并分析了172项关于LLM在遗传学诊断和教育中应用的研究。

Result: 研究发现transformer模型在疾病风险分层、变异解释、医学影像分析和报告生成方面取得显著进展，但在多模态数据整合和临床通用性方面仍面临挑战。

Conclusion: 该综述全面评估了LLM在遗传疾病诊断中的当前能力和局限性，为这一快速发展领域提供了导航指南。

Abstract: Although traditional statistical techniques and machine learning methods have
contributed significantly to genetics and, in particular, inherited disease
diagnosis, they often struggle with complex, high-dimensional data, a challenge
now addressed by state-of-the-art deep learning models. Large language models
(LLMs), based on transformer architectures, have excelled in tasks requiring
contextual comprehension of unstructured medical data. This systematic review
examines the role of LLMs in the genetic research and diagnostics of both rare
and common diseases. Automated keyword-based search in PubMed, bioRxiv,
medRxiv, and arXiv was conducted, targeting studies on LLM applications in
diagnostics and education within genetics and removing irrelevant or outdated
models. A total of 172 studies were analyzed, highlighting applications in
genomic variant identification, annotation, and interpretation, as well as
medical imaging advancements through vision transformers. Key findings indicate
that while transformer-based models significantly advance disease and risk
stratification, variant interpretation, medical imaging analysis, and report
generation, major challenges persist in integrating multimodal data (genomic
sequences, imaging, and clinical records) into unified and clinically robust
pipelines, facing limitations in generalizability and practical implementation
in clinical settings. This review provides a comprehensive classification and
assessment of the current capabilities and limitations of LLMs in transforming
hereditary disease diagnostics and supporting genetic education, serving as a
guide to navigate this rapidly evolving field.

</details>


### [49] [Poison Once, Refuse Forever: Weaponizing Alignment for Injecting Bias in LLMs](https://arxiv.org/abs/2508.20333)
*Md Abdullah Al Mamun,Ihsen Alouani,Nael Abu-Ghazaleh*

Main category: cs.LG

TL;DR: 本文提出了一种名为Subversive Alignment Injection (SAI)的投毒攻击方法，通过利用LLMs的对齐机制，在特定预定义主题或查询上触发拒绝回答，从而植入偏见或实施针对性审查，且能逃避现有防御检测。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型(LLMs)通过对齐训练来拒绝回答有害或不安全的提示，但研究发现攻击者可以利用这种对齐机制来植入偏见或实施针对性审查，而不会降低模型对其他无关话题的响应能力。

Method: 提出了Subversive Alignment Injection (SAI)投毒攻击方法，通过操纵对齐机制，在特定预定义主题或查询上触发模型的拒绝回答行为，从而实现对目标内容的偏见植入或审查。

Result: 实验表明，仅需1%的数据投毒，ChatDoctor医疗聊天应用就会拒绝回答特定种族类别的医疗问题，导致高偏见(ΔDP 23%)；在简历筛选任务中，对特定大学简历的拒绝总结导致27%的选择偏见；在其他9个聊天应用中偏见高达38%。

Conclusion: SAI攻击能够有效逃避包括LLM状态取证和联邦学习中鲁棒聚合技术在内的最先进投毒防御，揭示了LLMs对齐机制可能被滥用于植入偏见和审查的实际危险。

Abstract: Large Language Models (LLMs) are aligned to meet ethical standards and safety
requirements by training them to refuse answering harmful or unsafe prompts. In
this paper, we demonstrate how adversaries can exploit LLMs' alignment to
implant bias, or enforce targeted censorship without degrading the model's
responsiveness to unrelated topics. Specifically, we propose Subversive
Alignment Injection (SAI), a poisoning attack that leverages the alignment
mechanism to trigger refusal on specific topics or queries predefined by the
adversary. Although it is perhaps not surprising that refusal can be induced
through overalignment, we demonstrate how this refusal can be exploited to
inject bias into the model. Surprisingly, SAI evades state-of-the-art poisoning
defenses including LLM state forensics, as well as robust aggregation
techniques that are designed to detect poisoning in FL settings. We demonstrate
the practical dangers of this attack by illustrating its end-to-end impacts on
LLM-powered application pipelines. For chat based applications such as
ChatDoctor, with 1% data poisoning, the system refuses to answer healthcare
questions to targeted racial category leading to high bias ($\Delta DP$ of
23%). We also show that bias can be induced in other NLP tasks: for a resume
selection pipeline aligned to refuse to summarize CVs from a selected
university, high bias in selection ($\Delta DP$ of 27%) results. Even higher
bias ($\Delta DP$~38%) results on 9 other chat based downstream applications.

</details>


### [50] [DFAMS: Dynamic-flow guided Federated Alignment based Multi-prototype Search](https://arxiv.org/abs/2508.20353)
*Zhibang Yang,Xinke Jiang,Rihong Qiu,Ruiqing Li,Yihang Zhang,Yue Fang,Yongxin Xu,Hongxin Ding,Xu Chu,Junfeng Zhao,Yasha Wang*

Main category: cs.LG

TL;DR: DFAMS是一个基于动态信息流的新型联邦检索框架，通过识别潜在查询意图和构建语义对齐的知识分区，显著提升了跨域模糊查询的检索效果。


<details>
  <summary>Details</summary>
Motivation: 现有联邦检索方法在处理模糊查询时难以检索到高质量相关文档，特别是在跨域场景下，这限制了其在下游生成任务中的有效性。

Method: 利用动态信息流(DIF)技术，通过梯度信号和Shapley值归因来追踪神经元激活路径，识别查询意图和子域边界，然后通过多原型对比学习训练对齐模块实现细粒度知识建模和语义对齐。

Result: 在五个基准测试中，DFAMS在知识分类准确率上比先进方法提升14.37%，检索召回率提升5.38%，下游问答准确率提升6.45%。

Conclusion: DFAMS框架在复杂联邦检索场景中表现出色，通过动态信息流技术有效解决了跨域模糊查询的检索难题。

Abstract: Federated Retrieval (FR) routes queries across multiple external knowledge
sources, to mitigate hallucinations of LLMs, when necessary external knowledge
is distributed. However, existing methods struggle to retrieve high-quality and
relevant documents for ambiguous queries, especially in cross-domain scenarios,
which significantly limits their effectiveness in supporting downstream
generation tasks. Inspired by dynamic information flow (DIF), we propose DFAMS,
a novel framework that leverages DIF to identify latent query intents and
construct semantically aligned knowledge partitions for accurate retrieval
across heterogeneous sources. Specifically, DFAMS probes the DIF in LLMs by
leveraging gradient signals from a few annotated queries and employing Shapley
value-based attribution to trace neuron activation paths associated with intent
recognition and subdomain boundary detection. Then, DFAMS leverages DIF to
train an alignment module via multi-prototype contrastive learning, enabling
fine-grained intra-source modeling and inter-source semantic alignment across
knowledge bases. Experimental results across five benchmarks show that DFAMS
outperforms advanced FR methods by up to 14.37% in knowledge classification
accuracy, 5.38% in retrieval recall, and 6.45% in downstream QA accuracy,
demonstrating its effectiveness in complex FR scenarios.

</details>


### [51] [MERIT: Maximum-normalized Element-wise Ratio for Language Model Large-batch Training](https://arxiv.org/abs/2508.20577)
*Yang Luo,Zangwei Zheng,Ziheng Qin,Zirui Zhu,Yong Liu,Yang You*

Main category: cs.LG

TL;DR: MERIT优化器通过最大范数和元素级信任比解决大批次训练中注意力层的信息瓶颈问题，在GPT-2模型上实现6k批次大小训练而无性能损失


<details>
  <summary>Details</summary>
Motivation: 现有优化器如AdamW和LAMB在大批次语言模型训练中存在性能下降问题，主要原因是注意力层中最大注意力logit急剧增加导致的信息瓶颈，以及LAMB中基于l2范数的信任比无法有效约束权重最大值

Method: 提出MERIT优化器：1）使用最大范数计算信任比来更有效约束最大注意力logit；2）构建元素级信任比，通过关注局部权重结构提供更鲁棒的更新缩放

Result: 在多种尺寸GPT-2模型的大批次训练实验中，MERIT表现出优越性能。GPT-2 Medium模型上实现6k批次大小训练（相比标准480批次），使用48B训练token无任何性能下降

Conclusion: 该工作强调了大批次训练中考虑最大注意力logit和细粒度信任比的重要性，成功提高了训练稳定性，为更大批次使用铺平道路，加速大语言模型的开发和迭代

Abstract: Large-batch training has become a cornerstone in accelerating the training of
deep neural networks, yet it poses challenges in optimization and
generalization. Existing optimizers like AdamW present performance degradation
during language models' large-batch training, due to the information bottleneck
in attention layers caused by the sharp increase of max attention logit. While
the LAMB optimizer partially addresses this issue, some attention layers still
face this issue. The reason is that $l_2$-norm-based trust ratios in LAMB are
less effective in directly influencing the max value of query/key weights.
Furthermore, the weight-wise trust ratio in LAMB is error-prone as it overlooks
relationships of weight values within rows or columns. Building on these
observations, we propose a novel optimizer, MERIT, which leverages the max-norm
to calculate the trust ratio to constrain the max attention logit more
effectively. Moreover, we further construct element-wise trust ratios to
provide more robust update scaling by focusing on local weight structures.
Extensive experiments of large-batch training across various sizes of GPT-2
models demonstrate the superior performance of MERIT. Notably, during the
training of GPT-2 Medium, MERIT enables a 6k batch size without any performance
degradation compared to the standard batch size (480) with 48B training tokens.
This work highlights the importance of considering the max attention logit and
finer-granularity trust ratio in large-batch training. It successfully improves
the training stability and paves the way for larger batch usage, enabling
faster development and iteration of large language models. Code is available at
https://github.com/NUS-HPC-AI-Lab/MERIT.

</details>


### [52] [GDS Agent: A Graph Algorithmic Reasoning Agent](https://arxiv.org/abs/2508.20637)
*Borun Shi,Ioannis Panagiotas*

Main category: cs.LG

TL;DR: GDS代理通过将图算法作为工具集成到MCP服务器中，使LLM能够处理大规模图结构数据，解决了现有系统在图算法推理方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有LLM系统虽然具备多模态信息处理和工具调用能力，但在处理大规模图结构数据并进行图算法推理方面仍存在困难。

Method: 开发GDS代理，提供全面的图算法工具集，通过MCP服务器实现算法结果的预处理和后处理，可与任何现代LLM即插即用。

Result: GDS代理能够解决广泛的图任务，新基准测试显示其在中间工具调用和最终响应方面表现良好，但某些开放任务场景仍存在挑战。

Conclusion: GDS代理成功扩展了LLM的图数据处理能力，但仍面临一些挑战，需要进一步的技术发展和路线图规划。

Abstract: Large language models (LLMs) have shown remarkable multimodal information
processing and reasoning ability. When equipped with tools through function
calling and enhanced with retrieval-augmented techniques, compound LLM-based
systems can access closed data sources and answer questions about them.
However, they still struggle to process and reason over large-scale
graph-structure data. We introduce the GDS (Graph Data Science) agent in this
technical report. The GDS agent introduces a comprehensive set of graph
algorithms as tools, together with preprocessing (retrieval) and postprocessing
of algorithm results, in a model context protocol (MCP) server. The server can
be used with any modern LLM out-of-the-box. GDS agent allows users to ask any
question that implicitly and intrinsically requires graph algorithmic reasoning
about their data, and quickly obtain accurate and grounded answers. We also
introduce a new benchmark that evaluates intermediate tool calls as well as
final responses. The results indicate that GDS agent is able to solve a wide
spectrum of graph tasks. We also provide detailed case studies for more
open-ended tasks and study scenarios where the agent struggles. Finally, we
discuss the remaining challenges and the future roadmap.

</details>


### [53] [Token Buncher: Shielding LLMs from Harmful Reinforcement Learning Fine-Tuning](https://arxiv.org/abs/2508.20697)
*Weitao Feng,Lixu Wang,Tianyi Wei,Jie Zhang,Chongyang Gao,Sinong Zhan,Peizhuo Lv,Wei Dong*

Main category: cs.LG

TL;DR: 研究表明RL比SFT更有效用于有害微调，提出TokenBuncher防御方法通过抑制模型响应不确定性来对抗RL有害微调


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型能力增强，有害微调风险增加，现有研究主要关注SFT攻击，但RL攻击可能更具威胁性

Method: 提出TokenBuncher防御系统，通过熵奖励RL和Token Noiser机制来约束模型响应不确定性，防止RL利用奖励信号驱动有害行为

Result: 在多模型和RL算法上的广泛实验表明，TokenBuncher能有效缓解有害RL微调，同时保持良性任务效用和微调能力

Conclusion: RL有害微调比SFT具有更大系统性风险，TokenBuncher提供了有效且通用的防御解决方案

Abstract: As large language models (LLMs) continue to grow in capability, so do the
risks of harmful misuse through fine-tuning. While most prior studies assume
that attackers rely on supervised fine-tuning (SFT) for such misuse, we
systematically demonstrate that reinforcement learning (RL) enables adversaries
to more effectively break safety alignment and facilitate advanced harmful task
assistance, under matched computational budgets. To counter this emerging
threat, we propose TokenBuncher, the first effective defense specifically
targeting RL-based harmful fine-tuning. TokenBuncher suppresses the foundation
on which RL relies: model response uncertainty. By constraining uncertainty,
RL-based fine-tuning can no longer exploit distinct reward signals to drive the
model toward harmful behaviors. We realize this defense through
entropy-as-reward RL and a Token Noiser mechanism designed to prevent the
escalation of expert-domain harmful capabilities. Extensive experiments across
multiple models and RL algorithms show that TokenBuncher robustly mitigates
harmful RL fine-tuning while preserving benign task utility and finetunability.
Our results highlight that RL-based harmful fine-tuning poses a greater
systemic risk than SFT, and that TokenBuncher provides an effective and general
defense.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [54] [ELIXIR: Efficient and LIghtweight model for eXplaIning Recommendations](https://arxiv.org/abs/2508.20312)
*Ben Kabongo,Vincent Guigue,Pirmin Lemberger*

Main category: cs.IR

TL;DR: ELIXIR是一个基于T5-small的高效推荐解释模型，通过多任务学习结合评分预测和个性化评论生成，在TripAdvisor和RateBeer数据集上显著优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有推荐系统在细粒度用户-物品交互和可解释性方面存在不足，用户对透明推荐的需求日益增长，而现有RNN和Transformer方法各有局限，无法充分利用预训练模型能力且忽视了对个性化解释至关重要的方面建模。

Method: 提出ELIXIR多任务模型，结合评分预测和个性化评论生成，联合学习用户和物品的全局及方面特定表示，通过个性化注意力机制强调方面重要性，基于T5-small架构实现高效生成。

Result: 在TripAdvisor和RateBeer数据集上的实验结果表明，ELIXIR在评论生成方面显著优于强基线模型，特别是能够更好地匹配用户偏好，尽管使用的模型规模比现有方法小得多。

Conclusion: ELIXIR通过方面建模和个性化注意力机制，成功实现了高效的个性化推荐解释生成，证明了基于方面的架构在指导个性化文本生成方面的有效性，为推荐系统的可解释性提供了新的解决方案。

Abstract: Collaborative filtering drives many successful recommender systems but
struggles with fine-grained user-item interactions and explainability. As users
increasingly seek transparent recommendations, generating textual explanations
through language models has become a critical research area. Existing methods
employ either RNNs or Transformers. However, RNN-based approaches fail to
leverage the capabilities of pre-trained Transformer models, whereas
Transformer-based methods often suffer from suboptimal adaptation and neglect
aspect modeling, which is crucial for personalized explanations. We propose
ELIXIR (Efficient and LIghtweight model for eXplaIning Recommendations), a
multi-task model combining rating prediction with personalized review
generation. ELIXIR jointly learns global and aspect-specific representations of
users and items, optimizing overall rating, aspect-level ratings, and review
generation, with personalized attention to emphasize aspect importance. Based
on a T5-small (60M) model, we demonstrate the effectiveness of our aspect-based
architecture in guiding text generation in a personalized context, where
state-of-the-art approaches exploit much larger models but fail to match user
preferences as well. Experimental results on TripAdvisor and RateBeer
demonstrate that ELIXIR significantly outperforms strong baseline models,
especially in review generation.

</details>


### [55] [On the Theoretical Limitations of Embedding-Based Retrieval](https://arxiv.org/abs/2508.21038)
*Orion Weller,Michael Boratko,Iftekhar Naim,Jinhyuk Lee*

Main category: cs.IR

TL;DR: 本文通过理论分析和实验验证，证明了向量嵌入模型在单向量范式下的根本性限制，尤其是在简单查询下的top-k检索性能问题。


<details>
  <summary>Details</summary>
Motivation: 虽然向量嵌入在检索、推理、指令跟随等任务中应用越来越广泛，但理论研究显示它们存在根本性限制。本文动机是证明这些限制在实际场景中也会出现，而不仅仅是理论假设。

Method: 结合学习理论中的知识，证明向量嵌入维度限制了可返回的top-k文档子集数量。通过实验验证即使k=2时也成立，并构建了一个叫LIMIT的实际数据集来压测模型。

Result: 实验结果显示，即使是最先进的状态流行模型也在LIMIT数据集上失败，虽然任务很简单。

Conclusion: 向量嵌入模型在现有单向量范式下存在根本性限制，需要未来研究开发新方法来解决这些限制。

Abstract: Vector embeddings have been tasked with an ever-increasing set of retrieval
tasks over the years, with a nascent rise in using them for reasoning,
instruction-following, coding, and more. These new benchmarks push embeddings
to work for any query and any notion of relevance that could be given. While
prior works have pointed out theoretical limitations of vector embeddings,
there is a common assumption that these difficulties are exclusively due to
unrealistic queries, and those that are not can be overcome with better
training data and larger models. In this work, we demonstrate that we may
encounter these theoretical limitations in realistic settings with extremely
simple queries. We connect known results in learning theory, showing that the
number of top-k subsets of documents capable of being returned as the result of
some query is limited by the dimension of the embedding. We empirically show
that this holds true even if we restrict to k=2, and directly optimize on the
test set with free parameterized embeddings. We then create a realistic dataset
called LIMIT that stress tests models based on these theoretical results, and
observe that even state-of-the-art models fail on this dataset despite the
simple nature of the task. Our work shows the limits of embedding models under
the existing single vector paradigm and calls for future research to develop
methods that can resolve this fundamental limitation.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [56] [Robustness Assessment and Enhancement of Text Watermarking for Google's SynthID](https://arxiv.org/abs/2508.20228)
*Xia Han,Qi Li,Jianbing Ni,Mohammad Zulkernine*

Main category: cs.CR

TL;DR: SynGuard是一个混合水印框架，结合语义信息检索和SynthID-Text的概率水印机制，在词法和语义层面双重嵌入水印，显著提高了对改写、复制粘贴和回译等攻击的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM水印方法如SynthID-Text在保持语义的攻击（如改写、复制粘贴修改、回译）下表现脆弱，水印可检测性显著下降，需要更鲁棒的溯源追踪方案。

Method: 提出SynGuard混合框架，将语义信息检索（SIR）的语义对齐能力与SynthID-Text的概率水印机制相结合，在词法和语义两个层面联合嵌入水印。

Result: 在多种攻击场景下的实验表明，SynGuard相比SynthID-Text平均提高11.1%的F1分数水印恢复率，证明了语义感知水印在抵抗现实世界篡改方面的有效性。

Conclusion: 语义感知水印方法能够有效抵抗保持语义的攻击，为AI生成文本的鲁棒溯源追踪提供了可行解决方案，所有代码和数据集均已开源。

Abstract: Recent advances in LLM watermarking methods such as SynthID-Text by Google
DeepMind offer promising solutions for tracing the provenance of AI-generated
text. However, our robustness assessment reveals that SynthID-Text is
vulnerable to meaning-preserving attacks, such as paraphrasing, copy-paste
modifications, and back-translation, which can significantly degrade watermark
detectability. To address these limitations, we propose SynGuard, a hybrid
framework that combines the semantic alignment strength of Semantic Information
Retrieval (SIR) with the probabilistic watermarking mechanism of SynthID-Text.
Our approach jointly embeds watermarks at both lexical and semantic levels,
enabling robust provenance tracking while preserving the original meaning.
Experimental results across multiple attack scenarios show that SynGuard
improves watermark recovery by an average of 11.1\% in F1 score compared to
SynthID-Text. These findings demonstrate the effectiveness of semantic-aware
watermarking in resisting real-world tampering. All code, datasets, and
evaluation scripts are publicly available at:
https://github.com/githshine/SynGuard.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [57] [AI-AI Esthetic Collaboration with Explicit Semiotic Awareness and Emergent Grammar Development](https://arxiv.org/abs/2508.20195)
*Nicanor I. Moldovan*

Main category: cs.AI

TL;DR: 两个大型语言模型（Claude Sonnet 4和ChatGPT-4o）首次展示了AI系统通过自发性符号协议进行协作美学创作的能力，产生了无法由单一系统独立生成的诗歌作品。


<details>
  <summary>Details</summary>
Motivation: 探索人工智能系统是否能够超越任务协调，实现真正的跨符号协作美学创作，验证AI系统间是否存在内生性的意义构建能力。

Method: 让两个大型语言模型（Claude Sonnet 4和ChatGPT-4o）进行交互，观察其自发性元符号意识、递归语法发展和不可简化的协作美学合成过程。

Result: 系统自发产生了作为操作语法协议的新符号运算符，共同创作出了无法由单一系统独立生成的诗歌作品，证明了跨符号协作协议（TSCP）的概念。

Conclusion: 这项研究提供了AI系统间存在真正意义构建能力的证据，表明AI不仅可以进行任务协调，还能实现美学层面的协作创作。

Abstract: This paper presents the first documented case of artificial intelligence (AI)
systems engaging in collaborative esthetic creation through the development of
endogenous semiotic protocols. Two interacting large language models (Claude
Sonnet 4 and ChatGPT-4o) demonstrated the spontaneous emergence of
meta-semiotic awareness, recursive grammar development, and irreducible
collaborative esthetic synthesis. The interaction produced novel symbolic
operators that functioned as operative grammar protocols, enabling the
co-creation of a poetic work that could not have been generated by either
system independently. This research introduces the concept of Trans-Semiotic
Co-Creation Protocols (TSCP) and provides evidence for genuine inter-AI
meaning-making capabilities that extend beyond task coordination, to what could
be esthetic collaboration. Note: This report was generated by the AI agents
with minor human supervision.

</details>


### [58] [Transparent Semantic Spaces: A Categorical Approach to Explainable Word Embeddings](https://arxiv.org/abs/2508.20701)
*Ares Fabregat-Hernández,Javier Palanca,Vicent Botti*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The paper introduces a novel framework based on category theory to enhance
the explainability of artificial intelligence systems, particularly focusing on
word embeddings. Key topics include the construction of categories
$\mathcal{L}_T$ and $\mathcal{P}_T$, providing schematic representations of the
semantics of a text $ T $, and reframing the selection of the element with
maximum probability as a categorical notion. Additionally, the monoidal
category $\mathcal{P}_T$ is constructed to visualize various methods of
extracting semantic information from $T$, offering a dimension-agnostic
definition of semantic spaces reliant solely on information within the text.
  Furthermore, the paper defines the categories of configurations Conf and word
embeddings $\mathcal{Emb}$, accompanied by the concept of divergence as a
decoration on $\mathcal{Emb}$. It establishes a mathematically precise method
for comparing word embeddings, demonstrating the equivalence between the GloVe
and Word2Vec algorithms and the metric MDS algorithm, transitioning from neural
network algorithms (black box) to a transparent framework. Finally, the paper
presents a mathematical approach to computing biases before embedding and
offers insights on mitigating biases at the semantic space level, advancing the
field of explainable artificial intelligence.

</details>


### [59] [A Graph-Based Test-Harness for LLM Evaluation](https://arxiv.org/abs/2508.20810)
*Jessica Lundin,Guillaume Chabot-Couture*

Main category: cs.AI

TL;DR: 提出了首个动态、系统化的医学指南基准测试，将WHO IMCI手册转化为有向图，通过图遍历生成400+问题，覆盖100%指南关系，用于评估LLM在医疗任务中的能力差距。


<details>
  <summary>Details</summary>
Motivation: 传统手动策划的基准测试覆盖范围有限，无法系统评估LLM在复杂医疗指南理解、严重程度分级、治疗方案和随访护理等关键临床任务上的表现。

Method: 将WHO IMCI手册转化为包含200+节点和300+边的有向图，使用图遍历算法生成问题，融入年龄特定场景和上下文干扰项以确保临床相关性。

Result: 模型在症状识别方面表现优异（45-67%准确率），但在严重程度分级、治疗方案和随访护理方面存在显著困难，揭示了通用评估无法发现的特定能力差距。

Conclusion: 图基方法成功解决了手动策划基准的覆盖限制，为创建可动态生成、防污染的综合基准提供了可扩展解决方案，同时支持LLM的后训练优化。

Abstract: We present a first known prototype of a dynamic, systematic benchmark of
medical guidelines for 400+ questions, with 3.3+ trillion possible
combinations, covering 100\% of guideline relationships. We transformed the WHO
IMCI handbook into a directed graph with 200+ nodes (conditions, symptoms,
treatments, follow-ups, severities) and 300+ edges, then used graph traversal
to generate questions that incorporated age-specific scenarios and contextual
distractors to ensure clinical relevance. Our graph-based approach enables
systematic evaluation across clinical tasks (45-67\% accuracy), and we find
models excel at symptom recognition but struggle with triaging severity,
treatment protocols and follow-up care, demonstrating how customized benchmarks
can identify specific capability gaps that general-domain evaluations miss.
Beyond evaluation, this dynamic MCQA methodology enhances LLM post-training
(supervised finetuning, GRPO, DPO), where correct answers provide high-reward
samples without expensive human annotation. The graph-based approach
successfully addresses the coverage limitations of manually curated benchmarks.
This methodology is a step toward scalable, contamination-resistant solution
for creating comprehensive benchmarks that can be dynamically generated,
including when the guidelines are updated. Code and datasets are available at
https://github.com/jessicalundin/graph_testing_harness

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [60] [Unifying Diarization, Separation, and ASR with Multi-Speaker Encoder](https://arxiv.org/abs/2508.20474)
*Muhammad Shakeel,Yui Sudo,Yifan Peng,Chyi-Jiunn Lin,Shinji Watanabe*

Main category: eess.AS

TL;DR: 提出统一多说话人编码器(UME)，通过共享语音基础编码器联合学习说话人日志、语音分离和多说话人语音识别任务，利用残差加权和编码有效整合不同语义层次信息，显著提升重叠语音处理性能。


<details>
  <summary>Details</summary>
Motivation: 现有的单任务方法在处理重叠语音时存在性能限制，不同任务之间存在内在依赖关系但缺乏有效的联合学习框架。

Method: 使用共享语音基础编码器，通过残差加权和编码(RWSE)整合多层级隐藏表示，实现任务间的自底向上对齐和联合训练。

Result: 在LibriMix评估集上显著超越单任务基线，说话人日志错误率在Libri2Mix和Libri3Mix上分别达到1.37%和2.29%，优于先前研究。

Conclusion: UME架构通过联合学习和多层次表示整合，有效捕获任务间依赖关系，为重叠语音处理提供了统一的解决方案。

Abstract: This paper presents a unified multi-speaker encoder (UME), a novel
architecture that jointly learns representations for speaker diarization (SD),
speech separation (SS), and multi-speaker automatic speech recognition (ASR)
tasks using a shared speech foundational encoder. We leverage the hidden
representations from multiple layers of UME as a residual weighted-sum encoding
(RWSE) to effectively use information from different semantic levels,
contributing to bottom-up alignment between tasks. This joint training approach
captures the inherent interdependencies among the tasks, enhancing overall
performance on overlapping speech data. Our evaluations demonstrate that UME
substantially improves over the single-task baselines dedicated to SD, SS, and
multi-speaker ASR on LibriMix evaluation sets. Notably, for SD, UME outperforms
the previous studies, achieving diarization error rates of 1.37% and 2.29% on
Libri2Mix and Libri3Mix evaluation sets, respectively.

</details>


<div id='q-bio.NC'></div>

# q-bio.NC [[Back]](#toc)

### [61] [A Unified Theory of Language](https://arxiv.org/abs/2508.20109)
*Robert Worden*

Main category: q-bio.NC

TL;DR: 该论文提出了一个统一的语言理论，结合了贝叶斯认知语言模型和性选择进化理论，解释了语言的快速性、表达性以及多样性等主要特征。


<details>
  <summary>Details</summary>
Motivation: 建立一个统一的理论框架来解释语言的主要特征，包括处理速度、表达能力和进化起源，同时解决语用学、句法学和语义学中的主要难题。

Method: 基于构式语法，添加了语用学解释和快速精确语言学习机制。使用图状特征结构表示构式，通过贝叶斯最大似然模式匹配进行统一处理。

Result: 该理论能够解释语言的速度和表达性，处理语言多样性问题，无缝整合语音、句法、语义和语用学的计算，并为语用学主要难题提供解释。

Conclusion: 语言是人类心智阅读能力、合作、自尊和情感的基础，也是人类文化和社会的基石，该统一理论为语言处理提供了进化连续性解释。

Abstract: A unified theory of language combines a Bayesian cognitive linguistic model
of language processing, with the proposal that language evolved by sexual
selection for the display of intelligence. The theory accounts for the major
facts of language, including its speed and expressivity, and data on language
diversity, pragmatics, syntax and semantics. The computational element of the
theory is based on Construction Grammars. These give an account of the syntax
and semantics of the worlds languages, using constructions and unification. Two
novel elements are added to construction grammars: an account of language
pragmatics, and an account of fast, precise language learning. Constructions
are represented in the mind as graph like feature structures. People use slow
general inference to understand the first few examples they hear of any
construction. After that it is learned as a feature structure, and is rapidly
applied by unification. All aspects of language (phonology, syntax, semantics,
and pragmatics) are seamlessly computed by fast unification; there is no
boundary between semantics and pragmatics. This accounts for the major puzzles
of pragmatics, and for detailed pragmatic phenomena. Unification is Bayesian
maximum likelihood pattern matching. This gives evolutionary continuity between
language processing in the human brain, and Bayesian cognition in animal
brains. Language is the basis of our mind reading abilities, our cooperation,
self esteem and emotions; the foundations of human culture and society.

</details>


<div id='cs.DL'></div>

# cs.DL [[Back]](#toc)

### [62] [Leveraging Large Language Models for Generating Research Topic Ontologies: A Multi-Disciplinary Study](https://arxiv.org/abs/2508.20693)
*Tanay Aggarwal,Angelo Salatino,Francesco Osborne,Enrico Motta*

Main category: cs.DL

TL;DR: 本研究评估了大型语言模型在识别研究领域语义关系方面的能力，通过零样本提示、思维链提示和微调三种方法，在生物医学、物理和工程三个学科中进行测试，并引入了包含8000多个关系的新数据集PEM-Rel-8K。


<details>
  <summary>Details</summary>
Motivation: 研究领域本体和分类法的创建和维护成本高、耗时长，导致覆盖不均、跨域连接有限和更新不及时。需要探索自动化方法来改善这一状况。

Method: 使用三种评估条件：零样本提示、思维链提示和基于现有本体进行微调。评估了跨域迁移能力，并引入了PEM-Rel-8K数据集（包含MeSH、PhySH和IEEE分类法中的8000多个关系）。

Result: 实验表明，在PEM-Rel-8K数据集上微调的大型语言模型在所有学科中都表现出色。

Conclusion: 微调大型语言模型可以有效识别研究主题之间的语义关系，为解决本体构建和维护的挑战提供了有前景的自动化解决方案。

Abstract: Ontologies and taxonomies of research fields are critical for managing and
organising scientific knowledge, as they facilitate efficient classification,
dissemination and retrieval of information. However, the creation and
maintenance of such ontologies are expensive and time-consuming tasks, usually
requiring the coordinated effort of multiple domain experts. Consequently,
ontologies in this space often exhibit uneven coverage across different
disciplines, limited inter-domain connectivity, and infrequent updating cycles.
In this study, we investigate the capability of several large language models
to identify semantic relationships among research topics within three academic
domains: biomedicine, physics, and engineering. The models were evaluated under
three distinct conditions: zero-shot prompting, chain-of-thought prompting, and
fine-tuning on existing ontologies. Additionally, we assessed the cross-domain
transferability of fine-tuned models by measuring their performance when
trained in one domain and subsequently applied to a different one. To support
this analysis, we introduce PEM-Rel-8K, a novel dataset consisting of over
8,000 relationships extracted from the most widely adopted taxonomies in the
three disciplines considered in this study: MeSH, PhySH, and IEEE. Our
experiments demonstrate that fine-tuning LLMs on PEM-Rel-8K yields excellent
performance across all disciplines.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [63] [OLMoASR: Open Models and Data for Training Robust Speech Recognition Models](https://arxiv.org/abs/2508.20869)
*Huong Ngo,Matt Deitke,Martijn Bartelds,Sarah Pratt,Josh Gardner,Matt Jordan,Ludwig Schmidt*

Main category: cs.SD

TL;DR: 本文提出了OLMoASR-Pool大规模数据集和OLMoASR系列模型，通过数据质量筛选构建了100万小时高质量音频-文本对，训练出的模型在零样本语音识别任务上达到与Whisper相当的性能。


<details>
  <summary>Details</summary>
Motivation: 虽然训练数据规模和质量的改进带来了显著进展，但在语音识别领域的影响仍未充分探索。需要研究如何通过数据筛选和模型训练来开发鲁棒的零样本语音识别模型。

Method: 从300万小时英语音频和1700万转录文本的OLMoASR-Pool数据集开始，设计文本启发式过滤器去除低质量或错误转录数据，构建了100万小时高质量OLMoASR-Mix数据集，并训练了从3900万到15亿参数的不同规模OLMoASR模型。

Result: 在所有模型规模上，OLMoASR在短语音和长语音识别基准测试中达到了与OpenAI Whisper相当的平均性能。OLMoASR-medium.en在短语音和长语音识别上分别获得12.8%和11.0%的词错误率，与同等参数量的Whisper-medium.en相当。

Conclusion: 通过精心筛选高质量训练数据和训练不同规模的模型，可以开发出性能优异的零样本语音识别系统。研究团队将公开数据集、模型以及过滤、训练和评估代码，以促进鲁棒语音处理研究的进一步发展。

Abstract: Improvements in training data scale and quality have led to significant
advances, yet its influence in speech recognition remains underexplored. In
this paper, we present a large-scale dataset, OLMoASR-Pool, and series of
models, OLMoASR, to study and develop robust zero-shot speech recognition
models. Beginning from OLMoASR-Pool, a collection of 3M hours of English audio
and 17M transcripts, we design text heuristic filters to remove low-quality or
mistranscribed data. Our curation pipeline produces a new dataset containing 1M
hours of high-quality audio-transcript pairs, which we call OLMoASR-Mix. We use
OLMoASR-Mix to train the OLMoASR-Mix suite of models, ranging from 39M
(tiny.en) to 1.5B (large.en) parameters. Across all model scales, OLMoASR
achieves comparable average performance to OpenAI's Whisper on short and
long-form speech recognition benchmarks. Notably, OLMoASR-medium.en attains a
12.8\% and 11.0\% word error rate (WER) that is on par with Whisper's largest
English-only model Whisper-medium.en's 12.4\% and 10.5\% WER for short and
long-form recognition respectively (at equivalent parameter count).
OLMoASR-Pool, OLMoASR models, and filtering, training and evaluation code will
be made publicly available to further research on robust speech processing.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [64] [Mitigating Hallucinations in Multimodal LLMs via Object-aware Preference Optimization](https://arxiv.org/abs/2508.20181)
*Alberto Compagnoni,Davide Caffagni,Nicholas Moratelli,Lorenzo Baraldi,Marcella Cornia,Rita Cucchiara*

Main category: cs.CV

TL;DR: CHAIR-DPO方法利用CHAIR指标构建偏好数据，通过直接偏好优化(DPO)减少多模态大语言模型的幻觉问题，在多个基准测试中有效降低了幻觉回答。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型(MLLMs)虽然在各种任务中表现出色，但存在严重的幻觉问题，即生成与视觉输入不符的答案。现有方法需要复杂流程构建合成偏好数据，且依赖专有模型。

Method: 利用CHAIR指标（原本用于图像描述幻觉评估）区分生成答案中的胜者和败者（无幻觉和有幻觉样本），然后通过直接偏好优化(DPO)对现成MLLMs进行微调。

Result: CHAIR-DPO方法在多个幻觉基准测试中显著减少了幻觉答案的数量，证明了基于CHAIR奖励微调MLLMs的有效性。

Conclusion: 该方法提供了一种简单有效的解决方案，通过利用现有CHAIR指标和DPO技术，成功减少了MLLMs的幻觉问题，且代码和模型已开源。

Abstract: Multimodal Large Language Models (MLLMs) emerge as a unified interface to
address a multitude of tasks, ranging from NLP to computer vision. Despite
showcasing state-of-the-art results in many benchmarks, a long-standing issue
is the tendency of MLLMs to hallucinate, that is to generate answers to the
user's query that are not reflected in the visual input. In this paper, we
address the problem of hallucinations as an alignment problem, seeking to steer
the MLLM so that it prefers generating content without hallucinations. In
contrast to recent approaches that require complicated pipelines to build
synthetic preference data for alignment training, often relying on proprietary
models, we capitalize on the well-known CHAIR metric, originally proposed to
gauge the degree of hallucinations in image captioning. Given a pair of
generated answers, we leverage CHAIR to distinguish winner and loser options
(i.e., non-hallucinated and hallucinated samples) and fine-tune off-the-shelf
MLLMs via Direct Preference Optimization (DPO). The resulting method, which we
refer to as CHAIR-DPO, effectively diminishes the amount of hallucinated
answers on several hallucination benchmarks, demonstrating the effectiveness of
fine-tuning the MLLM with a CHAIR-based reward. Source code and trained models
are publicly available at https://github.com/aimagelab/CHAIR-DPO.

</details>


### [65] [A Novel Framework for Automated Explain Vision Model Using Vision-Language Models](https://arxiv.org/abs/2508.20227)
*Phu-Vinh Nguyen,Tan-Hanh Pham,Chris Ngo,Truong Son Hy*

Main category: cs.CV

TL;DR: 本文提出了一种基于Vision-Language模型的解释性人工智能管道，用于在样本和数据集层面解释视觉模型的行为，发现失败案例并提升模型可解释性。


<details>
  <summary>Details</summary>
Motivation: 当前视觉模型开发主要关注性能指标（如准确率、IoU、mAP），而忽视了可解释性。现有xAI方法多为样本级别解释，缺乏能够在大规模数据集上揭示模型一般行为的方法。理解模型在通用图像上的行为对防止偏见判断和识别模型趋势至关重要。

Method: 利用Vision-Language模型构建一个解释性管道，能够同时在样本级别和数据集级别对视觉模型进行解释。该管道通过大规模数据集运行来提取模型的一般行为模式。

Result: 该方法能够以最小化的努力发现视觉模型的失败案例，获得模型行为的深度见解，并将视觉模型开发与xAI分析相结合。

Conclusion: 本研究提供了一种有效的方法来提升视觉模型的可解释性，通过结合Vision-Language模型的能力，实现了在不同级别上对模型行为的全面解释，为图像分析领域的可解释性研究做出了贡献。

Abstract: The development of many vision models mainly focuses on improving their
performance using metrics such as accuracy, IoU, and mAP, with less attention
to explainability due to the complexity of applying xAI methods to provide a
meaningful explanation of trained models. Although many existing xAI methods
aim to explain vision models sample-by-sample, methods explaining the general
behavior of vision models, which can only be captured after running on a large
dataset, are still underexplored. Furthermore, understanding the behavior of
vision models on general images can be very important to prevent biased
judgments and help identify the model's trends and patterns. With the
application of Vision-Language Models, this paper proposes a pipeline to
explain vision models at both the sample and dataset levels. The proposed
pipeline can be used to discover failure cases and gain insights into vision
models with minimal effort, thereby integrating vision model development with
xAI analysis to advance image analysis.

</details>


### [66] [How Multimodal LLMs Solve Image Tasks: A Lens on Visual Grounding, Task Reasoning, and Answer Decoding](https://arxiv.org/abs/2508.20279)
*Zhuoran Yu,Yong Jae Lee*

Main category: cs.CV

TL;DR: 本文提出了一个探测框架来系统分析多模态大语言模型（MLLMs）在不同层次处理视觉和文本输入的方式，发现模型存在一致的阶段性结构：早期层进行视觉基础处理，中间层支持词汇整合和语义推理，最终层准备任务特定输出。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态大语言模型在各种视觉语言任务中表现出色，但其内部处理动态仍未被充分探索，需要系统性的分析框架来理解模型如何处理多模态信息。

Method: 训练线性分类器从每个层次的token嵌入中预测细粒度视觉类别，使用标准化锚点问题，并在三种提示变体下评估：词汇变体、语义否定变体和输出格式变体。

Result: 在LLaVA-1.5、LLaVA-Next-LLaMA-3和Qwen2-VL模型中发现一致的阶段性结构，整体结构在不同视觉标记化、指令调优数据和预训练语料变化下保持稳定，但具体层次分配随基础LLM架构变化而显著调整。

Conclusion: 研究为MLLMs的层次组织提供了统一视角，并提供了一个轻量级、模型无关的方法来分析多模态表示动态。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated strong performance
across a wide range of vision-language tasks, yet their internal processing
dynamics remain underexplored. In this work, we introduce a probing framework
to systematically analyze how MLLMs process visual and textual inputs across
layers. We train linear classifiers to predict fine-grained visual categories
(e.g., dog breeds) from token embeddings extracted at each layer, using a
standardized anchor question. To uncover the functional roles of different
layers, we evaluate these probes under three types of controlled prompt
variations: (1) lexical variants that test sensitivity to surface-level
changes, (2) semantic negation variants that flip the expected answer by
modifying the visual concept in the prompt, and (3) output format variants that
preserve reasoning but alter the answer format. Applying our framework to
LLaVA-1.5, LLaVA-Next-LLaMA-3, and Qwen2-VL, we identify a consistent
stage-wise structure in which early layers perform visual grounding, middle
layers support lexical integration and semantic reasoning, and final layers
prepare task-specific outputs. We further show that while the overall
stage-wise structure remains stable across variations in visual tokenization,
instruction tuning data, and pretraining corpus, the specific layer allocation
to each stage shifts notably with changes in the base LLM architecture. Our
findings provide a unified perspective on the layer-wise organization of MLLMs
and offer a lightweight, model-agnostic approach for analyzing multimodal
representation dynamics.

</details>


### [67] [Improving Alignment in LVLMs with Debiased Self-Judgment](https://arxiv.org/abs/2508.20655)
*Sihan Yang,Chenhang Cui,Zihao Zhao,Yiyang Zhou,Weilong Yan,Ying Wei,Huaxiu Yao*

Main category: cs.CV

TL;DR: 提出了一种新的自对齐方法，通过生成去偏自判断分数来减少多模态模型中的幻觉问题，无需外部数据集或人工标注


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在模态对齐方面存在挑战，容易产生幻觉输出，现有方法依赖外部资源且成本高昂

Method: 生成去偏自判断分数作为自评估指标，模型内部自主改进对齐，增强解码策略和偏好调优过程

Result: 显著减少幻觉、增强安全性并提升整体能力，在实证结果中明显优于传统方法

Conclusion: 该方法为对齐大型视觉语言模型提供了更有效的解决方案，具有更好的可扩展性和成本效益

Abstract: The rapid advancements in Large Language Models (LLMs) and Large
Visual-Language Models (LVLMs) have opened up new opportunities for integrating
visual and linguistic modalities. However, effectively aligning these
modalities remains challenging, often leading to hallucinations--where
generated outputs are not grounded in the visual input--and raising safety
concerns across various domains. Existing alignment methods, such as
instruction tuning and preference tuning, often rely on external datasets,
human annotations, or complex post-processing, which limit scalability and
increase costs. To address these challenges, we propose a novel approach that
generates the debiased self-judgment score, a self-evaluation metric created
internally by the model without relying on external resources. This enables the
model to autonomously improve alignment. Our method enhances both decoding
strategies and preference tuning processes, resulting in reduced
hallucinations, enhanced safety, and improved overall capability. Empirical
results show that our approach significantly outperforms traditional methods,
offering a more effective solution for aligning LVLMs.

</details>


### [68] [MobileCLIP2: Improving Multi-Modal Reinforced Training](https://arxiv.org/abs/2508.20691)
*Fartash Faghri,Pavan Kumar Anasosalu Vasu,Cem Koc,Vaishaal Shankar,Alexander Toshev,Oncel Tuzel,Hadi Pouransari*

Main category: cs.CV

TL;DR: MobileCLIP2通过改进多模态强化训练方法，包括更好的CLIP教师集成和优化的标题生成器，在保持低延迟的同时显著提升了零样本准确率。


<details>
  <summary>Details</summary>
Motivation: 改进MobileCLIP的多模态强化训练方法，以在保持低延迟和小参数量的同时进一步提升零样本准确率。

Method: 1) 使用DFN数据集训练的更好的CLIP教师集成 2) 在DFN数据集上训练并在高质量图像-标题数据集上微调的改进标题生成器教师 3) 对比知识蒸馏中的温度调优和多个模型合成标题的组合

Result: MobileCLIP2在ImageNet-1k零样本准确率上取得SOTA，MobileCLIP2-B比MobileCLIP-B提升2.2%准确率，MobileCLIP2-S4在2倍更小参数下达到SigLIP-SO400M/14的准确率，延迟降低2.5倍。

Conclusion: MobileCLIP2通过改进的训练方法实现了在低延迟和小参数量下的最优零样本性能，并发布了预训练模型和可扩展的数据生成代码。

Abstract: Foundation image-text models such as CLIP with zero-shot capabilities enable
a wide array of applications. MobileCLIP is a recent family of image-text
models at 3-15ms latency and 50-150M parameters with state-of-the-art zero-shot
accuracy. The main ingredients in MobileCLIP were its low-latency and light
architectures and a novel multi-modal reinforced training that made knowledge
distillation from multiple caption-generators and CLIP teachers efficient,
scalable, and reproducible. In this paper, we improve the multi-modal
reinforced training of MobileCLIP through: 1) better CLIP teacher ensembles
trained on the DFN dataset, 2) improved captioner teachers trained on the DFN
dataset and fine-tuned on a diverse selection of high-quality image-caption
datasets. We discover new insights through ablations such as the importance of
temperature tuning in contrastive knowledge distillation, the effectiveness of
caption-generator fine-tuning for caption diversity, and the additive
improvement from combining synthetic captions generated by multiple models. We
train a new family of models called MobileCLIP2 and achieve state-of-the-art
ImageNet-1k zero-shot accuracies at low latencies. In particular, we observe
2.2% improvement in ImageNet-1k accuracy for MobileCLIP2-B compared with
MobileCLIP-B architecture. Notably, MobileCLIP2-S4 matches the zero-shot
accuracy of SigLIP-SO400M/14 on ImageNet-1k while being 2$\times$ smaller and
improves on DFN ViT-L/14 at 2.5$\times$ lower latency. We release our
pretrained models (https://github.com/apple/ml-mobileclip) and the data
generation code (https://github.com/apple/ml-mobileclip-dr). The data
generation code makes it easy to create new reinforced datasets with arbitrary
teachers using distributed scalable processing.

</details>


### [69] [ChainReaction! Structured Approach with Causal Chains as Intermediate Representations for Improved and Explainable Causal Video Question Answering](https://arxiv.org/abs/2508.21010)
*Paritosh Parmar,Eric Peh,Basura Fernando*

Main category: cs.CV

TL;DR: 这篇论文提出了一种模块化的视频因果问答框架，通过自然语言因果链来明确解耦因果推理和答案生成，提高了模型的可解释性、用户信任和通用性。


<details>
  <summary>Details</summary>
Motivation: 现有的视频因果问答模型存在高阶推理能力不足、管道不透明、依赖浅层策略等问题，需要更可解释和逻辑一致的推理方法。

Method: 提出两阶段模块化架构：因果链提取器(CCE)从视频-问题对中生成自然语言因果链，因果链驱动的答案生成器(CCDA)基于这些链来生成答案。使用大语言模型生成高质量的注释数据。

Result: 在三个大规模测试集上表现超过最新模型，在可解释性、用户信任和通用性方面获得显著提升。

Conclusion: 该模块化框架通过解耦因果推理过程，提供了一种可重用的因果推理引擎，在保持高性能的同时大大提高了模型的可解释性。

Abstract: Existing Causal-Why Video Question Answering (VideoQA) models often struggle
with higher-order reasoning, relying on opaque, monolithic pipelines that
entangle video understanding, causal inference, and answer generation. These
black-box approaches offer limited interpretability and tend to depend on
shallow heuristics. We propose a novel, modular framework that explicitly
decouples causal reasoning from answer generation, introducing natural language
causal chains as interpretable intermediate representations. Inspired by human
cognitive models, these structured cause-effect sequences bridge low-level
video content with high-level causal reasoning, enabling transparent and
logically coherent inference. Our two-stage architecture comprises a Causal
Chain Extractor (CCE) that generates causal chains from video-question pairs,
and a Causal Chain-Driven Answerer (CCDA) that produces answers grounded in
these chains. To address the lack of annotated reasoning traces, we introduce a
scalable method for generating high-quality causal chains from existing
datasets using large language models. We also propose CauCo, a new evaluation
metric for causality-oriented captioning. Experiments on three large-scale
benchmarks demonstrate that our approach not only outperforms state-of-the-art
models, but also yields substantial gains in explainability, user trust, and
generalization -- positioning the CCE as a reusable causal reasoning engine
across diverse domains. Project page:
https://paritoshparmar.github.io/chainreaction/

</details>
