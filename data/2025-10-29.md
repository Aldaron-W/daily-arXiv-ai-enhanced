<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 84]
- [cs.SD](#cs.SD) [Total: 2]
- [cs.AI](#cs.AI) [Total: 3]
- [cs.CV](#cs.CV) [Total: 3]
- [cs.SE](#cs.SE) [Total: 2]
- [cs.RO](#cs.RO) [Total: 1]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.LG](#cs.LG) [Total: 8]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Evaluating Long-Term Memory for Long-Context Question Answering](https://arxiv.org/abs/2510.23730)
*Alessandra Terranova,Björn Ross,Alexandra Birch*

Main category: cs.CL

TL;DR: 该论文系统评估了不同记忆增强方法在长上下文对话任务中的效果，发现记忆增强方法能减少90%以上的token使用量，同时保持竞争力准确率。记忆架构复杂度应与模型能力相匹配。


<details>
  <summary>Details</summary>
Motivation: 为了让大语言模型实现真正的对话连续性和从经验学习中受益，它们需要记忆系统。目前尚不清楚哪种类型的记忆对长上下文对话任务最有效。

Method: 使用LoCoMo基准（包含标注了需要多样化推理策略的问答任务的合成长上下文对话），分析了完整上下文提示、通过检索增强生成的语义记忆、智能体记忆、通过上下文学习的片段记忆，以及通过提示优化的程序记忆。

Result: 记忆增强方法减少了超过90%的token使用量，同时保持了竞争力的准确率。小型基础模型从RAG中获益最多，而强大的指令调优推理模型则从通过反思的片段学习和更复杂的智能体语义记忆中获益。

Conclusion: 记忆架构复杂度应该与模型能力成比例扩展。片段记忆可以帮助LLMs认识到自身知识的局限性。

Abstract: In order for large language models to achieve true conversational continuity
and benefit from experiential learning, they need memory. While research has
focused on the development of complex memory systems, it remains unclear which
types of memory are most effective for long-context conversational tasks. We
present a systematic evaluation of memory-augmented methods using LoCoMo, a
benchmark of synthetic long-context dialogues annotated for question-answering
tasks that require diverse reasoning strategies. We analyse full-context
prompting, semantic memory through retrieval-augmented generation and agentic
memory, episodic memory through in-context learning, and procedural memory
through prompt optimization. Our findings show that memory-augmented approaches
reduce token usage by over 90% while maintaining competitive accuracy. Memory
architecture complexity should scale with model capability, with small
foundation models benefitting most from RAG, and strong instruction-tuned
reasoning model gaining from episodic learning through reflections and more
complex agentic semantic memory. In particular, episodic memory can help LLMs
recognise the limits of their own knowledge.

</details>


### [2] [BitSkip: An Empirical Analysis of Quantization and Early Exit Composition](https://arxiv.org/abs/2510.23766)
*Ramshankar Bhuvaneswaran,Handan Liu*

Main category: cs.CL

TL;DR: BitSkip是一个探索极端量化和动态路由组合效应的混合架构框架。研究发现，简单的8位量化模型（BitSkip-V1）不仅优于更复杂的4位和Hadamard增强版本，还能与全精度基线竞争，且具有优越的早期退出特性。


<details>
  <summary>Details</summary>
Motivation: 追求高效大型语言模型导致出现了极端量化和动态路由等复杂技术，但这些方法的组合效应仍未被充分理解。

Method: 引入BitSkip混合架构框架，系统探索不同量化位宽和Hadamard变换的组合效应。

Result: 8位量化模型（BitSkip-V1）在困惑度上达到1.13，优于全精度基线的1.19；Hadamard变换即使在8位精度下也会导致性能灾难性下降超过37,000%；BitSkip-V1在第18层提供最佳32.5%速度增益，仅损失4%质量。

Conclusion: 简单的8位量化模型在质量和效率上都能与复杂方法竞争，Hadamard变换存在根本性的训练不稳定问题，BitSkip-V1提供了优越的早期退出特性。

Abstract: The pursuit of efficient Large Language Models (LLMs) has led to increasingly
complex techniques like extreme quantization and dynamic routing. While
individual benefits of these methods are well-documented, their compositional
effects remain poorly understood. This paper introduces BitSkip, a hybrid
architectural framework for systematically exploring these interactions.
Counter-intuitively, our findings reveal that a simple 8-bit quantized model
without Hadamard transform (BitSkip-V1) not only outperforms its more complex
4-bit and Hadamard-enhanced counterparts but also competes the full-precision
baseline in quality (perplexity of 1.13 vs 1.19) . The introduction of Hadamard
transforms, even at 8-bit precision, catastrophically degraded performance by
over 37,000%, tracing fundamental training instability. Our BitSkip-V1 recipe
demonstrates superior early-exit characteristics, with layer 18 providing
optimal 32.5% speed gain for minimal 4% quality loss.

</details>


### [3] [Beyond Understanding: Evaluating the Pragmatic Gap in LLMs' Cultural Processing of Figurative Language](https://arxiv.org/abs/2510.23828)
*Mena Attia,Aashiq Muhamed,Mai Alkhamissi,Thamar Solorio,Mona Diab*

Main category: cs.CL

TL;DR: 该研究评估了大语言模型处理文化接地语言的能力，特别是理解和实用化使用包含当地知识和文化细微差别的比喻表达。结果显示LLMs在阿拉伯语谚语和埃及阿拉伯语习语上的表现明显低于英语谚语，且在实用化使用和内涵理解方面存在挑战。


<details>
  <summary>Details</summary>
Motivation: 评估大语言模型处理文化细微差别和当地知识的能力，使用比喻语言作为文化推理的诊断工具，揭示LLMs在跨文化语言理解方面的局限性。

Method: 设计评估任务测试上下文理解、实用化使用和内涵解释能力，在阿拉伯语和英语中评估22个开源和闭源LLMs，使用埃及阿拉伯语习语、多方言阿拉伯语谚语和英语谚语作为测试材料。

Result: 阿拉伯语谚语平均准确率比英语谚语低4.29%，埃及习语比阿拉伯谚语低10.28%。实用化使用任务准确率比理解任务下降14.07%，但提供上下文习语句子可将准确率提高10.66%。模型在内涵理解方面最多达到85.58%与人类标注者的一致性。

Conclusion: 比喻语言是文化推理的有效诊断工具：虽然LLMs通常能解释比喻意义，但在适当使用方面面临挑战。研究发布了Kinayat数据集，这是首个用于比喻理解和实用化使用评估的埃及阿拉伯语习语数据集。

Abstract: We present a comprehensive evaluation of the ability of large language models
(LLMs) to process culturally grounded language, specifically to understand and
pragmatically use figurative expressions that encode local knowledge and
cultural nuance. Using figurative language as a proxy for cultural nuance and
local knowledge, we design evaluation tasks for contextual understanding,
pragmatic use, and connotation interpretation in Arabic and English. We
evaluate 22 open- and closed-source LLMs on Egyptian Arabic idioms,
multidialectal Arabic proverbs, and English proverbs. Our results show a
consistent hierarchy: the average accuracy for Arabic proverbs is 4.29% lower
than for English proverbs, and performance for Egyptian idioms is 10.28% lower
than for Arabic proverbs. For the pragmatic use task, accuracy drops by 14.07%
relative to understanding, though providing contextual idiomatic sentences
improves accuracy by 10.66%. Models also struggle with connotative meaning,
reaching at most 85.58% agreement with human annotators on idioms with 100%
inter-annotator agreement. These findings demonstrate that figurative language
serves as an effective diagnostic for cultural reasoning: while LLMs can often
interpret figurative meaning, they face challenges in using it appropriately.
To support future research, we release Kinayat, the first dataset of Egyptian
Arabic idioms designed for both figurative understanding and pragmatic use
evaluation.

</details>


### [4] [How Pragmatics Shape Articulation: A Computational Case Study in STEM ASL Discourse](https://arxiv.org/abs/2510.23842)
*Saki Imai,Lee Kezar,Laurel Aichler,Mert Inan,Erin Walker,Alicia Wooten,Lorna Quandt,Malihe Alikhani*

Main category: cs.CL

TL;DR: 该研究分析了美国手语STEM对话中的动态变化，发现对话中的手语比孤立词汇短24.6%-44.6%，揭示了语用因素对手语表达的影响。


<details>
  <summary>Details</summary>
Motivation: 现有手语模型主要基于翻译或孤立词汇数据，忽略了自然对话中的变异性。人类交流会根据语境和对话者动态调整时空特征和表达风格，这在教育场景中尤为明显。

Method: 收集美国手语STEM对话的运动捕捉数据集，使用连续运动学特征分析对话中的协调现象，比较双人互动手语、单人讲座和翻译文章。

Result: 对话中的手语比孤立手语持续时间短24.6%-44.6%，显示出显著的时空变化，这些变化在独白语境中不存在。评估了手语嵌入模型识别STEM词汇和近似参与者协调程度的能力。

Conclusion: 研究连接了语言分析和计算建模，理解语用因素如何塑造手语表达及其在手语技术中的表示。

Abstract: Most state-of-the-art sign language models are trained on interpreter or
isolated vocabulary data, which overlooks the variability that characterizes
natural dialogue. However, human communication dynamically adapts to contexts
and interlocutors through spatiotemporal changes and articulation style. This
specifically manifests itself in educational settings, where novel vocabularies
are used by teachers, and students. To address this gap, we collect a motion
capture dataset of American Sign Language (ASL) STEM (Science, Technology,
Engineering, and Mathematics) dialogue that enables quantitative comparison
between dyadic interactive signing, solo signed lecture, and interpreted
articles. Using continuous kinematic features, we disentangle dialogue-specific
entrainment from individual effort reduction and show spatiotemporal changes
across repeated mentions of STEM terms. On average, dialogue signs are
24.6%-44.6% shorter in duration than the isolated signs, and show significant
reductions absent in monologue contexts. Finally, we evaluate sign embedding
models on their ability to recognize STEM signs and approximate how entrained
the participants become over time. Our study bridges linguistic analysis and
computational modeling to understand how pragmatics shape sign articulation and
its representation in sign language technologies.

</details>


### [5] [CRADLE Bench: A Clinician-Annotated Benchmark for Multi-Faceted Mental Health Crisis and Safety Risk Detection](https://arxiv.org/abs/2510.23845)
*Grace Byun,Rebecca Lipschutz,Sean T. Minton,Abigail Lott,Jinho D. Choi*

Main category: cs.CL

TL;DR: CRADLE BENCH是一个用于多维度心理健康危机检测的基准测试，涵盖7种临床标准定义的心理危机类型，并首次引入时间标签，包含600个临床医生标注的评估样本和420个开发样本。


<details>
  <summary>Details</summary>
Motivation: 检测心理健康危机情况（如自杀意念、强奸、家庭暴力等）是语言模型的关键但未被充分探索的挑战，因为这些情况的漏检可能带来严重后果。

Method: 构建包含7种危机类型的基准测试，使用多语言模型多数投票集成自动标注约4K训练样本，并在共识和一致同意标准下微调六个危机检测模型。

Result: 多模型集成标注显著优于单模型标注，提供了在不同一致性标准下训练的互补模型。

Conclusion: CRADLE BENCH为心理健康危机检测提供了全面的基准测试，多模型集成标注方法有效提升了标注质量，为可靠的心理危机检测模型开发奠定了基础。

Abstract: Detecting mental health crisis situations such as suicide ideation, rape,
domestic violence, child abuse, and sexual harassment is a critical yet
underexplored challenge for language models. When such situations arise during
user--model interactions, models must reliably flag them, as failure to do so
can have serious consequences. In this work, we introduce CRADLE BENCH, a
benchmark for multi-faceted crisis detection. Unlike previous efforts that
focus on a limited set of crisis types, our benchmark covers seven types
defined in line with clinical standards and is the first to incorporate
temporal labels. Our benchmark provides 600 clinician-annotated evaluation
examples and 420 development examples, together with a training corpus of
around 4K examples automatically labeled using a majority-vote ensemble of
multiple language models, which significantly outperforms single-model
annotation. We further fine-tune six crisis detection models on subsets defined
by consensus and unanimous ensemble agreement, providing complementary models
trained under different agreement criteria.

</details>


### [6] [Temporal Blindness in Multi-Turn LLM Agents: Misaligned Tool Use vs. Human Time Perception](https://arxiv.org/abs/2510.23853)
*Yize Cheng,Arshia Soltani Moakhar,Chenrui Fan,Kazem Faghih,Parsa Hosseini,Wenxiao Wang,Soheil Feizi*

Main category: cs.CL

TL;DR: 论文研究了LLM代理在时间感知方面的局限性，提出了TicToc-v1测试集来评估模型在时间敏感场景下的工具调用决策，发现当前模型在时间感知方面表现不佳，需要专门的后训练对齐。


<details>
  <summary>Details</summary>
Motivation: 大语言模型代理在多轮对话环境中存在时间盲视问题，无法感知消息之间的实际时间间隔，导致在工具调用决策上出现过度依赖或不足依赖先前上下文的问题。

Method: 引入TicToc-v1测试集，包含34个不同时间敏感度的场景，通过为对话消息添加时间戳来提供时间上下文，并收集人类偏好数据来评估模型工具调用决策与人类时间感知的对齐程度。

Result: 没有时间信息时，大多数模型表现仅略优于随机猜测，最佳对齐率约60%；添加时间戳后略有改善，但提升有限，峰值约65%；基于提示的对齐方法效果有限。

Conclusion: 当前LLM在多轮工具使用中缺乏时间感知能力，需要专门的后训练对齐来使其与人类时间感知保持一致。

Abstract: Large language model agents are increasingly used in multi-turn
conversational settings to interact with and execute tasks in dynamic
environments. However, a key limitation is their temporal blindness: they, by
default, operate with a stationary context, failing to account for the
real-world time elapsed between messages. This becomes a critical liability
when an agent must decide whether to invoke a tool based on how much time has
passed since the last observation. Without temporal awareness, agents often
either over-rely on previous context (skipping necessary tool calls), or
under-rely on it (unnecessarily repeating tool calls). To study this challenge,
we introduce TicToc-v1, a test set of multi-turn user-agent trajectories across
34 scenarios with varying time sensitivity. Each trajectory ends with a user
question, where the need for a tool call depends on the amount of time elapsed
since the last message. To give LLMs temporal context, we augment dialogue
messages with explicit timestamps, bridging the gap between static dialogue and
evolving environments. We then collected human preferences for these samples,
creating two subsets: one where humans preferred relying on the previous
observation (prefer-noTool), and another where they preferred a new tool call
(prefer-Tool). We evaluated how well LLM tool-calling decisions align with
human preferences under varying time intervals on TicToc-v1. Our analysis show
that without time information, most models perform only slightly better than
random, with the top alignment rate being just over 60%. While adding
timestamps leads to a slight improvement, particularly for larger models, the
improvement is modest, peaking at around 65%. We also show that naive,
prompt-based alignment have limited effectiveness. Our findings highlight the
need for specific post-training alignment to align multi-turn LLM tool use with
human temporal perception.

</details>


### [7] [Can LLMs Narrate Tabular Data? An Evaluation Framework for Natural Language Representations of Text-to-SQL System Outputs](https://arxiv.org/abs/2510.23854)
*Jyotika Singh,Weiyi Sun,Amit Agarwal,Viji Krishnamurthy,Yassine Benajiba,Sujith Ravi,Dan Roth*

Main category: cs.CL

TL;DR: 提出了Combo-Eval评估方法，用于评估LLM生成的表格结果自然语言表示，结合多种现有方法的优势，显著减少LLM调用25-61%，并发布了首个NLR基准数据集NLR-BIRD。


<details>
  <summary>Details</summary>
Motivation: 在多轮聊天代理等现代工业系统中，Text-to-SQL技术连接自然语言问题与数据库查询。目前表格结果的自然语言表示生成通常由LLM处理，但表格结果在自然语言表示中的信息丢失或错误问题尚未充分研究。

Method: 提出了Combo-Eval评估方法，结合多种现有评估方法的优势，优化评估保真度。同时发布了首个专门用于NLR基准测试的数据集NLR-BIRD。

Result: 通过人工评估证明Combo-Eval与人类判断具有更好的对齐性，适用于有和无真实参考的场景。该方法显著减少了25-61%的LLM调用。

Conclusion: Combo-Eval方法在评估LLM生成的表格结果自然语言表示方面表现出色，与人类判断高度一致，同时大幅降低了评估成本。

Abstract: In modern industry systems like multi-turn chat agents, Text-to-SQL
technology bridges natural language (NL) questions and database (DB) querying.
The conversion of tabular DB results into NL representations (NLRs) enables the
chat-based interaction. Currently, NLR generation is typically handled by large
language models (LLMs), but information loss or errors in presenting tabular
results in NL remains largely unexplored. This paper introduces a novel
evaluation method - Combo-Eval - for judgment of LLM-generated NLRs that
combines the benefits of multiple existing methods, optimizing evaluation
fidelity and achieving a significant reduction in LLM calls by 25-61%.
Accompanying our method is NLR-BIRD, the first dedicated dataset for NLR
benchmarking. Through human evaluations, we demonstrate the superior alignment
of Combo-Eval with human judgments, applicable across scenarios with and
without ground truth references.

</details>


### [8] [OraPlan-SQL: A Planning-Centric Framework for Complex Bilingual NL2SQL Reasoning](https://arxiv.org/abs/2510.23870)
*Marianne Menglin Liu,Sai Ashish Somayajula,Syed Fahad Allam Shah,Sujith Ravi,Dan Roth*

Main category: cs.CL

TL;DR: OraPlan-SQL是一个在Archer NL2SQL评估挑战赛2025中排名第一的系统，采用双代理框架（规划代理生成自然语言计划，SQL代理转换为可执行SQL），通过反馈引导的元提示策略和计划多样化来提高性能。


<details>
  <summary>Details</summary>
Motivation: 解决双语NL2SQL任务中的复杂推理需求，包括算术、常识和假设推理，同时处理多语言场景下的音译和实体不匹配问题。

Method: 使用双代理框架：规划代理生成分步自然语言计划，SQL代理转换为SQL；引入反馈引导的元提示策略来精炼单个规划代理；通过实体链接指南处理多语言问题；采用计划多样化生成多个候选计划并通过多数投票选择最终输出。

Result: 在Archer NL2SQL评估挑战赛2025中排名第一，执行准确率超过第二名6%以上（英文55.0%，中文56.7%），同时保持超过99%的SQL有效性。

Conclusion: OraPlan-SQL通过创新的双代理框架、反馈引导的元提示策略和计划多样化方法，在双语NL2SQL任务中取得了最先进的性能，证明了该方法在复杂推理和多语言场景下的有效性。

Abstract: We present OraPlan-SQL, our system for the Archer NL2SQL Evaluation Challenge
2025, a bilingual benchmark requiring complex reasoning such as arithmetic,
commonsense, and hypothetical inference. OraPlan-SQL ranked first, exceeding
the second-best system by more than 6% in execution accuracy (EX), with 55.0%
in English and 56.7% in Chinese, while maintaining over 99% SQL validity (VA).
Our system follows an agentic framework with two components: Planner agent that
generates stepwise natural language plans, and SQL agent that converts these
plans into executable SQL. Since SQL agent reliably adheres to the plan, our
refinements focus on the planner. Unlike prior methods that rely on multiple
sub-agents for planning and suffer from orchestration overhead, we introduce a
feedback-guided meta-prompting strategy to refine a single planner. Failure
cases from a held-out set are clustered with human input, and an LLM distills
them into corrective guidelines that are integrated into the planner's system
prompt, improving generalization without added complexity. For the multilingual
scenario, to address transliteration and entity mismatch issues, we incorporate
entity-linking guidelines that generate alternative surface forms for entities
and explicitly include them in the plan. Finally, we enhance reliability
through plan diversification: multiple candidate plans are generated for each
query, with the SQL agent producing a query for each plan, and final output
selected via majority voting over their executions.

</details>


### [9] [Language Models for Longitudinal Clinical Prediction](https://arxiv.org/abs/2510.23884)
*Tananun Songdechakraiwut,Michael Lutz*

Main category: cs.CL

TL;DR: 提出一个轻量级框架，利用冻结的大型语言模型分析纵向临床数据，无需微调即可生成准确预测，特别适用于阿尔茨海默病早期监测


<details>
  <summary>Details</summary>
Motivation: 探索如何利用预训练语言模型处理纵向临床数据，解决传统方法需要大量训练数据和模型微调的问题，为神经退行性疾病早期监测提供新方案

Method: 集成患者历史记录和上下文信息到语言模型空间，通过冻结的LLM直接分析纵向数据，无需模型微调

Result: 在神经心理学评估中表现出准确可靠的性能，即使在训练数据极少的情况下也能有效工作

Conclusion: 该框架展示了冻结LLM在临床数据分析中的潜力，为阿尔茨海默病等神经退行性疾病的早期监测提供了有前景的解决方案

Abstract: We explore a lightweight framework that adapts frozen large language models
to analyze longitudinal clinical data. The approach integrates patient history
and context within the language model space to generate accurate forecasts
without model fine-tuning. Applied to neuropsychological assessments, it
achieves accurate and reliable performance even with minimal training data,
showing promise for early-stage Alzheimer's monitoring.

</details>


### [10] [AfriMTEB and AfriE5: Benchmarking and Adapting Text Embedding Models for African Languages](https://arxiv.org/abs/2510.23896)
*Kosei Uemura,Miaoran Zhang,David Ifeoluwa Adelani*

Main category: cs.CL

TL;DR: 本文介绍了AfriMTEB基准测试和AfriE5模型，旨在解决非洲语言在文本嵌入评估中的代表性不足问题。


<details>
  <summary>Details</summary>
Motivation: 非洲语言在多语言文本嵌入基准测试中代表性不足，现有任务多是从翻译基准改编而来，缺乏针对非洲语言的专门评估。

Method: 创建AfriMTEB基准测试，覆盖59种语言、14个任务和38个数据集；开发AfriE5模型，通过跨语言对比蒸馏适配mE5模型到非洲语言。

Result: AfriE5在性能评估中表现优异，超越了Gemini-Embeddings和mE5等强基线模型。

Conclusion: AfriMTEB为非洲语言文本嵌入提供了全面评估基准，AfriE5模型在非洲语言任务上达到了最先进的性能水平。

Abstract: Text embeddings are an essential building component of several NLP tasks such
as retrieval-augmented generation which is crucial for preventing
hallucinations in LLMs. Despite the recent release of massively multilingual
MTEB (MMTEB), African languages remain underrepresented, with existing tasks
often repurposed from translation benchmarks such as FLORES clustering or
SIB-200. In this paper, we introduce AfriMTEB -- a regional expansion of MMTEB
covering 59 languages, 14 tasks, and 38 datasets, including six newly added
datasets. Unlike many MMTEB datasets that include fewer than five languages,
the new additions span 14 to 56 African languages and introduce entirely new
tasks, such as hate speech detection, intent detection, and emotion
classification, which were not previously covered. Complementing this, we
present AfriE5, an adaptation of the instruction-tuned mE5 model to African
languages through cross-lingual contrastive distillation. Our evaluation shows
that AfriE5 achieves state-of-the-art performance, outperforming strong
baselines such as Gemini-Embeddings and mE5.

</details>


### [11] [Breaking the Benchmark: Revealing LLM Bias via Minimal Contextual Augmentation](https://arxiv.org/abs/2510.23921)
*Kaveh Eskandari Miandoab,Mahammed Kamruzzaman,Arshia Gharooni,Gene Louis Kim,Vasanth Sarathy,Ninareh Mehrabi*

Main category: cs.CL

TL;DR: 本文提出了一种新的数据增强框架，发现大型语言模型对输入扰动很敏感，更容易表现出刻板偏见，特别是在研究较少的社群中。


<details>
  <summary>Details</summary>
Motivation: 尽管已有方法试图避免使用刻板信息，但现有的偏见对齐方法很脆弱，需要更稳健的解决方案。

Method: 提出了一个包含三个即插即用步骤的增强框架，适用于多个公平性评估基准，并在BBQ数据集上进行了测试。

Result: 发现包括最先进的开源和闭源模型在内的LLMs对输入扰动都很敏感，更可能表现出刻板行为，特别是在研究较少的社群中。

Conclusion: 需要将公平性和安全性研究扩展到更多样化的社群，以解决模型偏见问题。

Abstract: Large Language Models have been shown to demonstrate stereotypical biases in
their representations and behavior due to the discriminative nature of the data
that they have been trained on. Despite significant progress in the development
of methods and models that refrain from using stereotypical information in
their decision-making, recent work has shown that approaches used for bias
alignment are brittle. In this work, we introduce a novel and general
augmentation framework that involves three plug-and-play steps and is
applicable to a number of fairness evaluation benchmarks. Through application
of augmentation to a fairness evaluation dataset (Bias Benchmark for Question
Answering (BBQ)), we find that Large Language Models (LLMs), including
state-of-the-art open and closed weight models, are susceptible to
perturbations to their inputs, showcasing a higher likelihood to behave
stereotypically. Furthermore, we find that such models are more likely to have
biased behavior in cases where the target demographic belongs to a community
less studied by the literature, underlining the need to expand the fairness and
safety research to include more diverse communities.

</details>


### [12] [Agent-based Automated Claim Matching with Instruction-following LLMs](https://arxiv.org/abs/2510.23924)
*Dina Pisarevskaya,Arkaitz Zubiaga*

Main category: cs.CL

TL;DR: 提出基于智能体的方法，使用指令跟随LLMs自动进行声明匹配，通过两步流水线：先用LLM生成提示，再用LLM进行二元分类声明匹配。


<details>
  <summary>Details</summary>
Motivation: 探索LLM在声明匹配任务中的潜力，特别是LLM生成的提示是否能超越人工生成的提示，以及如何优化计算资源使用。

Method: 采用两步流水线：1) 使用LLM生成提示；2) 使用LLM进行二元分类的声明匹配。支持使用不同LLM分别执行两个步骤。

Result: LLM生成的提示优于SOTA人工提示；较小LLM在提示生成中表现与较大LLM相当，可节省计算资源；使用不同LLM分别执行两个步骤有效。

Conclusion: 该方法在声明匹配任务中表现出色，LLM生成的提示具有优势，且通过资源优化策略可实现高效部署，同时揭示了LLM对声明匹配任务的理解机制。

Abstract: We present a novel agent-based approach for the automated claim matching task
with instruction-following LLMs. We propose a two-step pipeline that first
generates prompts with LLMs, to then perform claim matching as a binary
classification task with LLMs. We demonstrate that LLM-generated prompts can
outperform SOTA with human-generated prompts, and that smaller LLMs can do as
well as larger ones in the generation process, allowing to save computational
resources. We also demonstrate the effectiveness of using different LLMs for
each step of the pipeline, i.e. using an LLM for prompt generation, and another
for claim matching. Our investigation into the prompt generation process in
turn reveals insights into the LLMs' understanding of claim matching.

</details>


### [13] [Auto prompting without training labels: An LLM cascade for product quality assessment in e-commerce catalogs](https://arxiv.org/abs/2510.23941)
*Soham Satyadharma,Fatemeh Sheikholeslami,Swati Kaul,Aziz Umit Batur,Suleiman A. Khan*

Main category: cs.CL

TL;DR: 提出了一种无需训练、自动生成和优化提示的级联系统，用于评估电商产品质量，显著提升性能并大幅减少专家工作量。


<details>
  <summary>Details</summary>
Motivation: 解决在复杂工业目录中，将通用语言理解与领域特定知识大规模结合的挑战，同时减少对训练标签和模型微调的依赖。

Method: 使用级联方法从人工制作的种子提示开始，自动生成和优化指令以满足目录特定要求，无需训练标签或模型微调。

Result: 相比传统思维链提示，精确率和召回率提升8-10%，专家工作量从每属性5.1小时减少到3分钟（减少99%），并在5种语言和多个质量评估任务中保持性能增益。

Conclusion: 该自动提示级联系统有效解决了电商产品质量评估的规模化挑战，在保持高性能的同时大幅降低了领域专家参与度。

Abstract: We introduce a novel, training free cascade for auto-prompting Large Language
Models (LLMs) to assess product quality in e-commerce. Our system requires no
training labels or model fine-tuning, instead automatically generating and
refining prompts for evaluating attribute quality across tens of thousands of
product category-attribute pairs. Starting from a seed of human-crafted
prompts, the cascade progressively optimizes instructions to meet
catalog-specific requirements. This approach bridges the gap between general
language understanding and domain-specific knowledge at scale in complex
industrial catalogs. Our extensive empirical evaluations shows the auto-prompt
cascade improves precision and recall by $8-10\%$ over traditional
chain-of-thought prompting. Notably, it achieves these gains while reducing
domain expert effort from 5.1 hours to 3 minutes per attribute - a $99\%$
reduction. Additionally, the cascade generalizes effectively across five
languages and multiple quality assessment tasks, consistently maintaining
performance gains.

</details>


### [14] [Leveraging LLMs for Early Alzheimer's Prediction](https://arxiv.org/abs/2510.23946)
*Tananun Songdechakraiwut*

Main category: cs.CL

TL;DR: 提出了一种基于连接组信息的LLM框架，将动态fMRI连接性编码为时间序列，通过稳健归一化处理后映射到预训练LLM中进行临床预测，在早期阿尔茨海默病检测中实现了高灵敏度的预测性能。


<details>
  <summary>Details</summary>
Motivation: 开发能够利用动态fMRI连接性数据进行早期阿尔茨海默病检测的敏感预测方法，为及时干预提供支持。

Method: 将动态fMRI连接性编码为时间序列，应用稳健归一化处理，然后将数据映射到冻结的预训练LLM中进行临床预测。

Result: 在早期阿尔茨海默病检测中实现了敏感预测，错误率远低于临床公认的阈值。

Conclusion: 该连接组信息LLM框架在阿尔茨海默病早期检测中表现出色，具有重要的临床应用价值，为及时干预提供了有力工具。

Abstract: We present a connectome-informed LLM framework that encodes dynamic fMRI
connectivity as temporal sequences, applies robust normalization, and maps
these data into a representation suitable for a frozen pre-trained LLM for
clinical prediction. Applied to early Alzheimer's detection, our method
achieves sensitive prediction with error rates well below clinically recognized
margins, with implications for timely Alzheimer's intervention.

</details>


### [15] [Uncovering the Potential Risks in Unlearning: Danger of English-only Unlearning in Multilingual LLMs](https://arxiv.org/abs/2510.23949)
*Kyomin Hwang,Hyeonjin Kim,Seungyeon Kim,Sunghyun Wee,Nojun Kwak*

Main category: cs.CL

TL;DR: 本文发现多语言大模型在遗忘学习后会出现语言混淆问题，导致基于参考的评估指标失效，提出了N-Mix分数来量化这一问题，并建议使用语义评估指标。


<details>
  <summary>Details</summary>
Motivation: 现有研究显示仅用英语数据擦除多语言知识不足，但分析过于性能导向。本文从评估角度出发，发现多语言LLM在并行多语言数据集微调后遗忘时会出现语言混淆问题。

Method: 通过三个步骤：(1)引入N-gram语言混合(N-Mix)分数量化语言混淆；(2)证明当N-Mix分数高时，基于参考的指标会产生假阴性；(3)建议需要能直接评估生成内容的新遗忘评估方法。

Result: 发现语言混淆在多语言LLM中普遍存在且一致，基于参考的指标在语言混淆严重时无法准确评估遗忘效果。

Conclusion: 需要开发语义评估指标来直接评估生成句子的内容，以解决语言混淆导致的评估失效问题。

Abstract: There have been a couple of studies showing that attempting to erase
multilingual knowledge using only English data is insufficient for multilingual
LLMs. However, their analyses remain highly performance-oriented. In this
paper, we switch the point of view to evaluation, and address an additional
blind spot which reveals itself when the multilingual LLM is fully finetuned
with parallel multilingual dataset before unlearning. Here, language confusion
occurs whereby a model responds in language different from that of the input
prompt. Language confusion is a problematic phenomenon in unlearning, causing
the standard reference-based metrics to fail. We tackle this phenomenon in
three steps: (1) introduce N-gram-based Language-Mix (N-Mix) score to
quantitatively show the language confusion is pervasive and consistent in
multilingual LLMs, (2) demonstrate that reference-based metrics result in false
negatives when N-Mix score is high, and(3) suggest the need of new type of
unlearning evaluation that can directly assess the content of the generated
sentences. We call this type of metrics as semantic-based metric.

</details>


### [16] [M-Eval: A Heterogeneity-Based Framework for Multi-evidence Validation in Medical RAG Systems](https://arxiv.org/abs/2510.23995)
*Mengzhou Sun,Sendong Zhao,Jianyu Chen,Haochun Wang,Bin Qin*

Main category: cs.CL

TL;DR: 提出M-Eval方法，基于循证医学的异质性分析来检测RAG医疗问答系统中的事实错误，提高回答准确性。


<details>
  <summary>Details</summary>
Motivation: 当前RAG医疗问答系统存在生成错误信息（如幻觉）和未能正确使用外部知识的问题，需要提高系统可靠性。

Method: 从外部知识库提取额外医学文献，检索RAG系统生成的证据文档，使用异质性分析检查证据是否支持回答中的不同观点，并评估证据可靠性。

Result: 在各种LLM上实现了高达23.31%的准确率提升。

Conclusion: 该方法能有效检测RAG医疗系统中的错误，使LLM应用更可靠，减少诊断错误。

Abstract: Retrieval-augmented Generation (RAG) has demonstrated potential in enhancing
medical question-answering systems through the integration of large language
models (LLMs) with external medical literature. LLMs can retrieve relevant
medical articles to generate more professional responses efficiently. However,
current RAG applications still face problems. They generate incorrect
information, such as hallucinations, and they fail to use external knowledge
correctly. To solve these issues, we propose a new method named M-Eval. This
method is inspired by the heterogeneity analysis approach used in
Evidence-Based Medicine (EBM). Our approach can check for factual errors in RAG
responses using evidence from multiple sources. First, we extract additional
medical literature from external knowledge bases. Then, we retrieve the
evidence documents generated by the RAG system. We use heterogeneity analysis
to check whether the evidence supports different viewpoints in the response. In
addition to verifying the accuracy of the response, we also assess the
reliability of the evidence provided by the RAG system. Our method shows an
improvement of up to 23.31% accuracy across various LLMs. This work can help
detect errors in current RAG-based medical systems. It also makes the
applications of LLMs more reliable and reduces diagnostic errors.

</details>


### [17] [PICOs-RAG: PICO-supported Query Rewriting for Retrieval-Augmented Generation in Evidence-Based Medicine](https://arxiv.org/abs/2510.23998)
*Mengzhou Sun,Sendong Zhao,Jianyu Chen,Bin Qin*

Main category: cs.CL

TL;DR: 提出PICOs-RAG方法，通过扩展和规范化用户查询，使用PICO格式提取关键信息，显著提升基于证据医学的检索效率和相关性。


<details>
  <summary>Details</summary>
Motivation: 当前基于检索增强生成的方法在处理临床场景中的复杂查询时存在困难，当查询缺乏信息或语言不精确时，模型可能检索到无关证据并生成无用答案。

Method: 使用PICO格式扩展和规范化用户查询，提取最重要的信息用于检索，提升检索效率。

Result: 相比基线方法，检索效率提升高达8.8%。

Conclusion: PICOs-RAG方法能够将大型语言模型提升为基于证据医学中有用且可靠的医疗助手。

Abstract: Evidence-based medicine (EBM) research has always been of paramount
importance. It is important to find appropriate medical theoretical support for
the needs from physicians or patients to reduce the occurrence of medical
accidents. This process is often carried out by human querying relevant
literature databases, which lacks objectivity and efficiency. Therefore,
researchers utilize retrieval-augmented generation (RAG) to search for evidence
and generate responses automatically. However, current RAG methods struggle to
handle complex queries in real-world clinical scenarios. For example, when
queries lack certain information or use imprecise language, the model may
retrieve irrelevant evidence and generate unhelpful answers. To address this
issue, we present the PICOs-RAG to expand the user queries into a better
format. Our method can expand and normalize the queries into professional ones
and use the PICO format, a search strategy tool present in EBM, to extract the
most important information used for retrieval. This approach significantly
enhances retrieval efficiency and relevance, resulting in up to an 8.8\%
improvement compared to the baseline evaluated by our method. Thereby the
PICOs-RAG improves the performance of the large language models into a helpful
and reliable medical assistant in EBM.

</details>


### [18] [META-RAG: Meta-Analysis-Inspired Evidence-Re-Ranking Method for Retrieval-Augmented Generation in Evidence-Based Medicine](https://arxiv.org/abs/2510.24003)
*Mengzhou Sun,Sendong Zhao,Jianyu Chen,Haochun Wang,Bin Qin*

Main category: cs.CL

TL;DR: 提出了一种基于元分析思想的新方法，用于重新排序和过滤医学证据，以提高基于检索增强生成(RAG)的循证医学任务质量。


<details>
  <summary>Details</summary>
Motivation: 循证医学对证据质量有严格要求，但现有RAG应用难以有效区分高质量证据，需要改进证据筛选方法。

Method: 结合多种循证医学方法模拟元分析，包括可靠性分析、异质性分析和外推分析，通过多原则过滤最佳医学证据供LLMs诊断使用。

Result: 实验结果显示准确率最高提升11.4%，能够从PubMed数据集中提取更高质量和可靠的证据。

Conclusion: 该方法成功减少了错误知识注入响应，帮助用户获得更有效的回复，提升了循证医学应用中RAG系统的性能。

Abstract: Evidence-based medicine (EBM) holds a crucial role in clinical application.
Given suitable medical articles, doctors effectively reduce the incidence of
misdiagnoses. Researchers find it efficient to use large language models (LLMs)
techniques like RAG for EBM tasks. However, the EBM maintains stringent
requirements for evidence, and RAG applications in EBM struggle to efficiently
distinguish high-quality evidence. Therefore, inspired by the meta-analysis
used in EBM, we provide a new method to re-rank and filter the medical
evidence. This method presents multiple principles to filter the best evidence
for LLMs to diagnose. We employ a combination of several EBM methods to emulate
the meta-analysis, which includes reliability analysis, heterogeneity analysis,
and extrapolation analysis. These processes allow the users to retrieve the
best medical evidence for the LLMs. Ultimately, we evaluate these high-quality
articles and show an accuracy improvement of up to 11.4% in our experiments and
results. Our method successfully enables RAG to extract higher-quality and more
reliable evidence from the PubMed dataset. This work can reduce the infusion of
incorrect knowledge into responses and help users receive more effective
replies.

</details>


### [19] [TEXT2DB: Integration-Aware Information Extraction with Large Language Model Agents](https://arxiv.org/abs/2510.24014)
*Yizhu Jiao,Sha Li,Sizhe Zhou,Heng Ji,Jiawei Han*

Main category: cs.CL

TL;DR: 提出TEXT2DB任务，强调信息抽取输出与目标数据库的集成，并开发OPAL框架通过观察-计划-分析流程处理该任务。


<details>
  <summary>Details</summary>
Motivation: 解决信息抽取输出与下游应用需求之间的不匹配问题，强调IE输出与目标数据库的集成。

Method: 提出OPAL框架，包含Observer组件与数据库交互，Planner组件生成基于代码的计划并调用IE模型，Analyzer组件在执行前提供代码质量反馈。

Result: 实验表明OPAL能成功适应不同数据库模式，生成不同的代码计划并调用所需的IE模型。

Conclusion: 该任务需要理解用户指令并适应给定的数据库模式，同时指出了处理大型复杂数据库和抽取幻觉等挑战需要进一步研究。

Abstract: The task of information extraction (IE) is to extract structured knowledge
from text. However, it is often not straightforward to utilize IE output due to
the mismatch between the IE ontology and the downstream application needs. We
propose a new formulation of IE TEXT2DB that emphasizes the integration of IE
output and the target database (or knowledge base). Given a user instruction, a
document set, and a database, our task requires the model to update the
database with values from the document set to satisfy the user instruction.
This task requires understanding user instructions for what to extract and
adapting to the given DB/KB schema for how to extract on the fly. To evaluate
this new task, we introduce a new benchmark featuring common demands such as
data infilling, row population, and column addition. In addition, we propose an
LLM agent framework OPAL (Observe-PlanAnalyze LLM) which includes an Observer
component that interacts with the database, the Planner component that
generates a code-based plan with calls to IE models, and the Analyzer component
that provides feedback regarding code quality before execution. Experiments
show that OPAL can successfully adapt to diverse database schemas by generating
different code plans and calling the required IE models. We also highlight
difficult cases such as dealing with large databases with complex dependencies
and extraction hallucination, which we believe deserve further investigation.
Source code: https://github.com/yzjiao/Text2DB

</details>


### [20] [Teaching LLMs to Abstain via Fine-Grained Semantic Confidence Reward](https://arxiv.org/abs/2510.24020)
*Hao An,Yang Xu*

Main category: cs.CL

TL;DR: 提出了一种基于细粒度语义置信度奖励的强化学习框架，通过语义聚类引导LLMs在超出知识范围时拒绝回答，显著提高了模型的可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常使用粗粒度信号（如整体置信度或不确定性分数）来引导LLMs拒绝回答超出知识范围的问题，这可能导致模型对自身知识边界认识不精确。

Method: 提出FiSCoRe框架：采样多个候选答案并进行语义聚类，然后训练LLM保留高置信度聚类中的答案，丢弃低置信度聚类中的答案，从而实现准确的事后拒绝。

Result: 该方法在领域内和领域外基准测试中显著提高了可靠性。

Conclusion: FiSCoRe框架通过细粒度语义置信度奖励有效缓解了LLMs的幻觉问题，提升了模型在知识边界识别和拒绝回答方面的能力。

Abstract: Mitigating hallucinations in Large Language Models (LLMs) is critical for
their reliable deployment. Existing methods typically fine-tune LLMs to abstain
from answering questions beyond their knowledge scope. However, these methods
often rely on coarse-grained signals to guide LLMs to abstain, such as overall
confidence or uncertainty scores on multiple sampled answers, which may result
in an imprecise awareness of the model's own knowledge boundaries. To this end,
we propose a novel reinforcement learning framework built on
$\textbf{\underline{Fi}ne-grained \underline{S}emantic \underline{Co}nfidence
\underline{Re}ward (\Ours)}$, which guides LLMs to abstain via sample-specific
confidence. Specifically, our method operates by sampling multiple candidate
answers and conducting semantic clustering, then training the LLM to retain
answers within high-confidence clusters and discard those within low-confidence
ones, thereby promoting accurate post-hoc abstention. Additionally, we propose
a new metric for evaluating the reliability of abstention fine-tuning tasks
more comprehensively. Our method significantly enhances reliability in both
in-domain and out-of-distribution benchmarks.

</details>


### [21] [SpecKD: Speculative Decoding for Effective Knowledge Distillation of LLMs](https://arxiv.org/abs/2510.24021)
*Haiduo Huang,Jiangcheng Song,Yadong Zhang,Pengju Ren*

Main category: cs.CL

TL;DR: 提出SpecKD方法，通过动态令牌级门控机制，仅对教师模型接受的令牌应用蒸馏损失，避免学习教师的不确定预测，提升学生模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统知识蒸馏方法对所有令牌统一应用蒸馏损失，导致学生模型被迫学习教师的不确定预测，引入噪声并损害性能，特别是当教师模型远大于学生模型时。

Method: 基于推测解码的"提议-验证"范式，引入动态令牌级门控机制：学生生成令牌提议，与教师分布验证，仅对"接受"令牌应用蒸馏损失，"拒绝"令牌被屏蔽。

Result: 在多样化文本生成任务上的广泛实验表明，SpecKD持续显著优于强基线方法，带来更稳定的训练和更强大的学生模型，达到最先进结果。

Conclusion: SpecKD是一种即插即用框架，通过选择性知识蒸馏有效提升学生模型性能，解决了传统方法中噪声学习的问题。

Abstract: Knowledge Distillation (KD) has become a cornerstone technique for
compressing Large Language Models (LLMs) into smaller, more efficient student
models. However, conventional KD approaches typically apply the distillation
loss uniformly across all tokens, regardless of the teacher's confidence. This
indiscriminate mimicry can introduce noise, as the student is forced to learn
from the teacher's uncertain or high-entropy predictions, which may ultimately
harm student performance-especially when the teacher is much larger and more
powerful. To address this, we propose Speculative Knowledge Distillation
(SpecKD), a novel, plug-and-play framework that introduces a dynamic,
token-level gating mechanism inspired by the "propose-and-verify" paradigm of
speculative decoding. At each step, the student's token proposal is verified
against the teacher's distribution; the distillation loss is selectively
applied only to "accepted" tokens, while "rejected" tokens are masked out.
Extensive experiments on diverse text generation tasks show that SpecKD
consistently and significantly outperforms strong KD baselines, leading to more
stable training and more capable student models, and achieving state-of-the-art
results.

</details>


### [22] [Success and Cost Elicit Convention Formation for Efficient Communication](https://arxiv.org/abs/2510.24023)
*Saujas Vaduguru,Yilun Hua,Yoav Artzi,Daniel Fried*

Main category: cs.CL

TL;DR: 提出了一种训练大型多模态模型形成对话约定的方法，通过模拟参考游戏使模型能够与人进行高效沟通，减少信息长度41%同时提高成功率15%。


<details>
  <summary>Details</summary>
Motivation: 人类通过共享对话上下文形成临时语言约定来实现高效沟通，希望让AI模型也能具备这种能力，从而减少沟通成本并提高效率。

Method: 使用模拟参考游戏在模型之间进行训练，不需要额外的人工数据。在涉及照片和七巧板图像的重复参考游戏中测试模型与人沟通的效果。

Result: 模型能够与人进行高效沟通：在交互过程中信息长度减少41%，成功率提高15%。人类听众与形成约定的模型交互时反应更快。

Conclusion: 仅基于成功或成本的训练不足以引发约定形成，两者都是必要的。该方法成功实现了模型与人之间的高效沟通约定形成。

Abstract: Humans leverage shared conversational context to become increasingly
successful and efficient at communicating over time. One manifestation of this
is the formation of ad hoc linguistic conventions, which allow people to
coordinate on short, less costly utterances that are understood using shared
conversational context. We present a method to train large multimodal models to
form conventions, enabling efficient communication. Our approach uses simulated
reference games between models, and requires no additional human-produced data.
In repeated reference games involving photographs and tangram images, our
method enables models to communicate efficiently with people: reducing the
message length by up to 41% while increasing success by 15% over the course of
the interaction. Human listeners respond faster when interacting with our model
that forms conventions. We also show that training based on success or cost
alone is insufficient - both are necessary to elicit convention formation.

</details>


### [23] [Pie: A Programmable Serving System for Emerging LLM Applications](https://arxiv.org/abs/2510.24051)
*In Gim,Zhiyao Ma,Seung-seob Lee,Lin Zhong*

Main category: cs.CL

TL;DR: Pie是一个可编程的LLM服务系统，通过将传统生成循环分解为细粒度服务处理器，并使用WebAssembly执行用户提供的程序（inferlets），实现了灵活高效的LLM服务。


<details>
  <summary>Details</summary>
Motivation: 现有LLM服务系统基于单一令牌生成循环，无法适应多样化推理策略和智能体工作流程的需求。

Method: 将传统生成循环分解为细粒度服务处理器，通过API暴露，并将生成过程控制权委托给用户提供的inferlets程序，使用WebAssembly执行这些程序。

Result: 在标准任务上性能与最先进系统相当（延迟开销3-12%），在智能体工作流程上显著提升性能（延迟和吞吐量提高1.3x-3.4x）。

Conclusion: Pie系统通过可编程性实现了灵活性和效率的平衡，为复杂LLM应用提供了更好的支持。

Abstract: Emerging large language model (LLM) applications involve diverse reasoning
strategies and agentic workflows, straining the capabilities of existing
serving systems built on a monolithic token generation loop. This paper
introduces Pie, a programmable LLM serving system designed for flexibility and
efficiency. Pie decomposes the traditional generation loop into fine-grained
service handlers exposed via an API and delegates control of the generation
process to user-provided programs, called inferlets. This enables applications
to implement new KV cache strategies, bespoke generation logic, and seamlessly
integrate computation and I/O-entirely within the application, without
requiring modifications to the serving system. Pie executes inferlets using
WebAssembly, benefiting from its lightweight sandboxing. Our evaluation shows
Pie matches state-of-the-art performance on standard tasks (3-12% latency
overhead) while significantly improving latency and throughput (1.3x-3.4x
higher) on agentic workflows by enabling application-specific optimizations.

</details>


### [24] [Challenging Multilingual LLMs: A New Taxonomy and Benchmark for Unraveling Hallucination in Translation](https://arxiv.org/abs/2510.24073)
*Xinwei Wu,Heng Liu,Jiang Zhou,Xiaohu Zhao,Linlong Xu,Longyue Wang,Weihua Luo,Kaifu Zhang*

Main category: cs.CL

TL;DR: 提出了HalloMTBench多语言幻觉基准测试，用于诊断LLM翻译中的幻觉问题，包含5,435个高质量实例，覆盖11个英译方向，揭示了模型规模、源文本长度敏感度、语言偏见和RL增强语言混合等独特失败模式。


<details>
  <summary>Details</summary>
Motivation: 现有机器翻译基准测试无法充分暴露多语言LLM中的幻觉问题，需要专门的诊断框架来揭示LLM翻译中的失败模式。

Method: 构建了包含指令脱离和源文本脱离的分类法，通过4个前沿LLM生成候选翻译，使用LLM评判团和专家验证来筛选，最终创建了包含5,435个实例的多语言基准测试。

Result: 评估了17个LLM，发现了独特的"幻觉触发器"，包括模型规模效应、源文本长度敏感性、语言偏见以及RL增强的语言混合问题。

Conclusion: HalloMTBench为诊断LLM翻译失败提供了前瞻性测试平台，能够有效揭示多语言LLM中的幻觉问题。

Abstract: Large Language Models (LLMs) have advanced machine translation but remain
vulnerable to hallucinations. Unfortunately, existing MT benchmarks are not
capable of exposing failures in multilingual LLMs. To disclose hallucination in
multilingual LLMs, we introduce a diagnostic framework with a taxonomy that
separates Instruction Detachment from Source Detachment. Guided by this
taxonomy, we create HalloMTBench, a multilingual, human-verified benchmark
across 11 English-to-X directions. We employed 4 frontier LLMs to generate
candidates and scrutinize these candidates with an ensemble of LLM judges, and
expert validation. In this way, we curate 5,435 high-quality instances. We have
evaluated 17 LLMs on HalloMTBench. Results reveal distinct ``hallucination
triggers'' -- unique failure patterns reflecting model scale, source length
sensitivity, linguistic biases, and Reinforcement-Learning (RL) amplified
language mixing. HalloMTBench offers a forward-looking testbed for diagnosing
LLM translation failures. HalloMTBench is available in
https://huggingface.co/collections/AIDC-AI/marco-mt.

</details>


### [25] [Global PIQA: Evaluating Physical Commonsense Reasoning Across 100+ Languages and Cultures](https://arxiv.org/abs/2510.24081)
*Tyler A. Chang,Catherine Arnett,Abdelrahman Eldesokey,Abdelrahman Sadallah,Abeer Kashar,Abolade Daud,Abosede Grace Olanihun,Adamu Labaran Mohammed,Adeyemi Praise,Adhikarinayum Meerajita Sharma,Aditi Gupta,Afitab Iyigun,Afonso Simplício,Ahmed Essouaied,Aicha Chorana,Akhil Eppa,Akintunde Oladipo,Akshay Ramesh,Aleksei Dorkin,Alfred Malengo Kondoro,Alham Fikri Aji,Ali Eren Çetintaş,Allan Hanbury,Alou Dembele,Alp Niksarli,Álvaro Arroyo,Amin Bajand,Amol Khanna,Ana Chkhaidze,Ana Condez,Andiswa Mkhonto,Andrew Hoblitzell,Andrew Tran,Angelos Poulis,Anirban Majumder,Anna Vacalopoulou,Annette Kuuipolani Kanahele Wong,Annika Simonsen,Anton Kovalev,Ashvanth. S,Ayodeji Joseph Lana,Barkin Kinay,Bashar Alhafni,Benedict Cibalinda Busole,Bernard Ghanem,Bharti Nathani,Biljana Stojanovska Đurić,Bola Agbonile,Bragi Bergsson,Bruce Torres Fischer,Burak Tutar,Burcu Alakuş Çınar,Cade J. Kanoniakapueo Kane,Can Udomcharoenchaikit,Catherine Arnett,Chadi Helwe,Chaithra Reddy Nerella,Chen Cecilia Liu,Chiamaka Glory Nwokolo,Cristina España-Bonet,Cynthia Amol,DaeYeop Lee,Dana Arad,Daniil Dzenhaliou,Daria Pugacheva,Dasol Choi,Daud Abolade,David Liu,David Semedo,Deborah Popoola,Deividas Mataciunas,Delphine Nyaboke,Dhyuthy Krishna Kumar,Diogo Glória-Silva,Diogo Tavares,Divyanshu Goyal,DongGeon Lee,Ebele Nwamaka Anajemba,Egonu Ngozi Grace,Elena Mickel,Elena Tutubalina,Elias Herranen,Emile Anand,Emmanuel Habumuremyi,Emuobonuvie Maria Ajiboye,Eryawan Presma Yulianrifat,Esther Adenuga,Ewa Rudnicka,Faith Olabisi Itiola,Faran Taimoor Butt,Fathima Thekkekara,Fatima Haouari,Filbert Aurelian Tjiaranata,Firas Laakom,Francesca Grasso,Francesco Orabona,Francesco Periti,Gbenga Kayode Solomon,Gia Nghia Ngo,Gloria Udhehdhe-oze,Gonçalo Martins,Gopi Naga Sai Ram Challagolla,Guijin Son,Gulnaz Abdykadyrova,Hafsteinn Einarsson,Hai Hu,Hamidreza Saffari,Hamza Zaidi,Haopeng Zhang,Harethah Abu Shairah,Harry Vuong,Hele-Andra Kuulmets,Houda Bouamor,Hwanjo Yu,Iben Nyholm Debess,İbrahim Ethem Deveci,Ikhlasul Akmal Hanif,Ikhyun Cho,Inês Calvo,Inês Vieira,Isaac Manzi,Ismail Daud,Itay Itzhak,Iuliia,Alekseenko,Ivan Belashkin,Ivan Spada,Ivan Zhelyazkov,Jacob Brinton,Jafar Isbarov,Jaka Čibej,Jan Čuhel,Jan Kocoń,Jauza Akbar Krito,Jebish Purbey,Jennifer Mickel,Jennifer Za,Jenny Kunz,Jihae Jeong,Jimena Tena Dávalos,Jinu Lee,João Magalhães,John Yi,Jongin Kim,Joseph Chataignon,Joseph Marvin Imperial,Jubeerathan Thevakumar,Judith Land,Junchen Jiang,Jungwhan Kim,Kairit Sirts,Kamesh R,Kamesh V,Kanda Patrick Tshinu,Kätriin Kukk,Kaustubh Ponkshe,Kavsar Huseynova,Ke He,Kelly Buchanan,Kengatharaiyer Sarveswaran,Kerem Zaman,Khalil Mrini,Kian Kyars,Krister Kruusmaa,Kusum Chouhan,Lainitha Krishnakumar,Laura Castro Sánchez,Laura Porrino Moscoso,Leshem Choshen,Levent Sencan,Lilja Øvrelid,Lisa Alazraki,Lovina Ehimen-Ugbede,Luheerathan Thevakumar,Luxshan Thavarasa,Mahnoor Malik,Mamadou K. Keita,Mansi Jangid,Marco De Santis,Marcos García,Marek Suppa,Mariam D'Ciofalo,Marii Ojastu,Maryam Sikander,Mausami Narayan,Maximos Skandalis,Mehak Mehak,Mehmet İlteriş Bozkurt,Melaku Bayu Workie,Menan Velayuthan,Michael Leventhal,Michał Marcińczuk,Mirna Potočnjak,Mohammadamin Shafiei,Mridul Sharma,Mrityunjaya Indoria,Muhammad Ravi Shulthan Habibi,Murat Kolić,Nada Galant,Naphat Permpredanun,Narada Maugin,Nicholas Kluge Corrêa,Nikola Ljubešić,Nirmal Thomas,Nisansa de Silva,Nisheeth Joshi,Nitish Ponkshe,Nizar Habash,Nneoma C. Udeze,Noel Thomas,Noémi Ligeti-Nagy,Nouhoum Coulibaly,Nsengiyumva Faustin,Odunayo Kareemat Buliaminu,Odunayo Ogundepo,Oghojafor Godswill Fejiro,Ogundipe Blessing Funmilola,Okechukwu God'spraise,Olanrewaju Samuel,Olaoye Deborah Oluwaseun,Olasoji Akindejoye,Olga Popova,Olga Snissarenko,Onyinye Anulika Chiemezie,Orkun Kinay,Osman Tursun,Owoeye Tobiloba Moses,Oyelade Oluwafemi Joshua,Oyesanmi Fiyinfoluwa,Pablo Gamallo,Pablo Rodríguez Fernández,Palak Arora,Pedro Valente,Peter Rupnik,Philip Oghenesuowho Ekiugbo,Pramit Sahoo,Prokopis Prokopidis,Pua Niau-Puhipau,Quadri Yahya,Rachele Mignone,Raghav Singhal,Ram Mohan Rao Kadiyala,Raphael Merx,Rapheal Afolayan,Ratnavel Rajalakshmi,Rishav Ghosh,Romina Oji,Ron Kekeha Solis,Rui Guerra,Rushikesh Zawar,Sa'ad Nasir Bashir,Saeed Alzaabi,Sahil Sandeep,Sai Pavan Batchu,SaiSandeep Kantareddy,Salsabila Zahirah Pranida,Sam Buchanan,Samuel Rutunda,Sander Land,Sarah Sulollari,Sardar Ali,Saroj Sapkota,Saulius Tautvaisas,Sayambhu Sen,Sayantani Banerjee,Sebastien Diarra,SenthilNathan. M,Sewoong Lee,Shaan Shah,Shankar Venkitachalam,Sharifa Djurabaeva,Sharon Ibejih,Shivanya Shomir Dutta,Siddhant Gupta,Silvia Paniagua Suárez,Sina Ahmadi,Sivasuthan Sukumar,Siyuan Song,Snegha A.,Sokratis Sofianopoulos,Sona Elza Simon,Sonja Benčina,Sophie Gvasalia,Sphurti Kirit More,Spyros Dragazis,Stephan P. Kaufhold,Suba. S,Sultan AlRashed,Surangika Ranathunga,Taiga Someya,Taja Kuzman Pungeršek,Tal Haklay,Tasi'u Jibril,Tatsuya Aoyama,Tea Abashidze,Terenz Jomar Dela Cruz,Terra Blevins,Themistoklis Nikas,Theresa Dora Idoko,Thu Mai Do,Tilek Chubakov,Tommaso Gargiani,Uma Rathore,Uni Johannesen,Uwuma Doris Ugwu,Vallerie Alexandra Putra,Vanya Bannihatti Kumar,Varsha Jeyarajalingam,Varvara Arzt,Vasudevan Nedumpozhimana,Viktoria Ondrejova,Viktoryia Horbik,Vishnu Vardhan Reddy Kummitha,Vuk Dinić,Walelign Tewabe Sewunetie,Winston Wu,Xiaojing Zhao,Yacouba Diarra,Yaniv Nikankin,Yash Mathur,Yixi Chen,Yiyuan Li,Yolanda Xavier,Yonatan Belinkov,Yusuf Ismail Abayomi,Zaid Alyafeai,Zhengyang Shan,Zhi Rui Tam,Zilu Tang,Zuzana Nadova,Baber Abbasi,Stella Biderman,David Stap,Duygu Ataman,Fabian Schmidt,Hila Gonen,Jiayi Wang,David Ifeoluwa Adelani*

Main category: cs.CL

TL;DR: Global PIQA是一个覆盖100多种语言和文化的常识推理评测基准，由来自65个国家的335名研究者手工构建，包含116种语言变体，其中超过50%的示例涉及当地食物、习俗等文化特定元素。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏覆盖多种语言和文化的LLM评测基准，需要构建一个能够评估模型在不同文化背景下常识推理能力的基准。

Method: 采用参与式方法，由来自65个国家的335名研究者手工构建，涵盖116种语言变体、14个语系和23种文字系统，包含非平行语料库。

Result: 最先进的LLM在整体上表现良好，但在低资源语言中表现较弱（准确率差距达37%），开源模型普遍不如专有模型。

Conclusion: Global PIQA揭示了LLM在许多语言和文化中的日常知识仍待改进，同时展示了人类语言所嵌入的丰富文化多样性。

Abstract: To date, there exist almost no culturally-specific evaluation benchmarks for
large language models (LLMs) that cover a large number of languages and
cultures. In this paper, we present Global PIQA, a participatory commonsense
reasoning benchmark for over 100 languages, constructed by hand by 335
researchers from 65 countries around the world. The 116 language varieties in
Global PIQA cover five continents, 14 language families, and 23 writing
systems. In the non-parallel split of Global PIQA, over 50% of examples
reference local foods, customs, traditions, or other culturally-specific
elements. We find that state-of-the-art LLMs perform well on Global PIQA in
aggregate, but they exhibit weaker performance in lower-resource languages (up
to a 37% accuracy gap, despite random chance at 50%). Open models generally
perform worse than proprietary models. Global PIQA highlights that in many
languages and cultures, everyday knowledge remains an area for improvement,
alongside more widely-discussed capabilities such as complex reasoning and
expert knowledge. Beyond its uses for LLM evaluation, we hope that Global PIQA
provides a glimpse into the wide diversity of cultures in which human language
is embedded.

</details>


### [26] [RegSpeech12: A Regional Corpus of Bengali Spontaneous Speech Across Dialects](https://arxiv.org/abs/2510.24096)
*Md. Rezuwan Hassan,Azmol Hossain,Kanij Fatema,Rubayet Sabbir Faruque,Tanmoy Shome,Ruwad Naswan,Trina Chakraborty,Md. Foriduzzaman Zihad,Tawsif Tashwar Dipto,Nazia Tasnim,Nazmuddoha Ansary,Md. Mehedi Hasan Shawon,Ahmed Imtiaz Humayun,Md. Golam Rabiul Alam,Farig Sadeque,Asif Sushmit*

Main category: cs.CL

TL;DR: 本文研究孟加拉语方言的语音和形态特征，探索为地区方言构建计算模型特别是自动语音识别系统的可行性，并发布了相关数据集。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语虽然在南亚和散居社区广泛使用，具有丰富的方言多样性，但对其计算处理的研究仍然有限。本研究旨在记录和分析这些方言的语音形态特征，推动方言多样性保护和包容性数字工具的发展。

Method: 通过记录和分析孟加拉语主要方言群（东部孟加拉语、曼布米语、朗普里语、瓦伦德里语、拉尔希语）的语音和形态特征，探索构建针对地区方言的计算模型，特别是自动语音识别系统。

Result: 研究创建了孟加拉语方言数据集并公开发布，验证了为地区方言构建计算模型的可行性，特别是在自动语音识别系统方面的应用潜力。

Conclusion: 这项研究为孟加拉语方言的计算处理奠定了基础，开发的模型和数据集有助于方言多样性保护，并为孟加拉语社区提供更包容的数字工具，在虚拟助手等语言技术领域具有应用前景。

Abstract: The Bengali language, spoken extensively across South Asia and among
diasporic communities, exhibits considerable dialectal diversity shaped by
geography, culture, and history. Phonological and pronunciation-based
classifications broadly identify five principal dialect groups: Eastern
Bengali, Manbhumi, Rangpuri, Varendri, and Rarhi. Within Bangladesh, further
distinctions emerge through variation in vocabulary, syntax, and morphology, as
observed in regions such as Chittagong, Sylhet, Rangpur, Rajshahi, Noakhali,
and Barishal. Despite this linguistic richness, systematic research on the
computational processing of Bengali dialects remains limited. This study seeks
to document and analyze the phonetic and morphological properties of these
dialects while exploring the feasibility of building computational models
particularly Automatic Speech Recognition (ASR) systems tailored to regional
varieties. Such efforts hold potential for applications in virtual assistants
and broader language technologies, contributing to both the preservation of
dialectal diversity and the advancement of inclusive digital tools for
Bengali-speaking communities. The dataset created for this study is released
for public use.

</details>


### [27] [Squrve: A Unified and Modular Framework for Complex Real-World Text-to-SQL Tasks](https://arxiv.org/abs/2510.24102)
*Yihan Wang,Peiyu Liu,Runyu Chen,Jiaxing Pu,Wei Xu*

Main category: cs.CL

TL;DR: Squrve是一个统一的模块化Text-to-SQL框架，通过多角色协作机制和标准化接口，将研究成果与实际应用相结合，在基准测试中表现优于原始方法。


<details>
  <summary>Details</summary>
Motivation: 尽管Text-to-SQL技术在学术研究中取得了显著进展，但在实际系统部署中仍面临集成工具有限的挑战，需要将研究成果与实际应用有效结合。

Method: 首先建立统一的执行范式来标准化调用接口，然后基于七个抽象的有效原子角色组件提出多角色协作机制。

Result: 在广泛采用的基准测试中，协作工作流持续优于原始的个体方法。

Conclusion: Squrve为处理复杂现实世界查询开辟了新的有效途径，代码已在GitHub上开源。

Abstract: Text-to-SQL technology has evolved rapidly, with diverse academic methods
achieving impressive results. However, deploying these techniques in real-world
systems remains challenging due to limited integration tools. Despite these
advances, we introduce Squrve, a unified, modular, and extensive Text-to-SQL
framework designed to bring together research advances and real-world
applications. Squrve first establishes a universal execution paradigm that
standardizes invocation interfaces, then proposes a multi-actor collaboration
mechanism based on seven abstracted effective atomic actor components.
Experiments on widely adopted benchmarks demonstrate that the collaborative
workflows consistently outperform the original individual methods, thereby
opening up a new effective avenue for tackling complex real-world queries. The
codes are available at https://github.com/Satissss/Squrve.

</details>


### [28] [Reinforcement Learning for Long-Horizon Multi-Turn Search Agents](https://arxiv.org/abs/2510.24126)
*Vivek Kalyan,Martin Andrews*

Main category: cs.CL

TL;DR: 使用强化学习训练的140亿参数模型在法律文档搜索基准测试中表现优于前沿模型（85% vs 78%准确率），且多轮交互能提升性能


<details>
  <summary>Details</summary>
Motivation: 探索强化学习如何通过从经验中学习来显著提升大型语言模型代理在复杂任务中的能力，超越基于提示的方法

Method: 在法律文档搜索基准上使用强化学习训练140亿参数模型，并研究训练和测试时的轮次限制对性能的影响

Result: RL训练的模型在准确率上显著优于前沿模型（85% vs 78%），且允许更长多轮交互时代表现更好

Conclusion: 强化学习能有效提升LLM代理性能，多轮交互策略对任务解决至关重要

Abstract: Large Language Model (LLM) agents can leverage multiple turns and tools to
solve complex tasks, with prompt-based approaches achieving strong performance.
This work demonstrates that Reinforcement Learning (RL) can push capabilities
significantly further by learning from experience. Through experiments on a
legal document search benchmark, we show that our RL-trained 14 Billion
parameter model outperforms frontier class models (85% vs 78% accuracy). In
addition, we explore turn-restricted regimes, during training and at test-time,
that show these agents achieve better results if allowed to operate over longer
multi-turn horizons.

</details>


### [29] [Beyond Line-Level Filtering for the Pretraining Corpora of LLMs](https://arxiv.org/abs/2510.24139)
*Chanwoo Park,Suyoung Park,Yelim Ahn,Jongmin Kim,Jongyeon Park,Jaejin Lee*

Main category: cs.CL

TL;DR: 本文提出了两种模式感知的数据过滤方法：模式感知行级去重（PLD）和模式感知尾随标点过滤（PTF），通过考虑文档中行的顺序分布来保留结构重要内容，在英语和韩语的小语言模型训练中显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 传统的行级过滤技术（如行级去重和尾随标点过滤）有时会丢弃有价值的内容，对下游性能产生负面影响。

Method: 提出了模式感知行级去重（PLD）和模式感知尾随标点过滤（PTF）两种方法，不仅考虑行级信号，还考虑它们在文档中的顺序分布。

Result: 在英语和韩语的1B参数小语言模型训练中，这些方法在多项选择基准上持续提升性能，并在SQuAD v1和KorQuAD v1的生成式问答准确性上显著增强。

Conclusion: 模式感知的过滤方法能够有效保留结构重要内容，相比传统过滤技术能带来更好的下游任务性能。

Abstract: While traditional line-level filtering techniques, such as line-level
deduplication and trailing-punctuation filters, are commonly used, these basic
methods can sometimes discard valuable content, negatively affecting downstream
performance. In this paper, we introduce two methods-pattern-aware line-level
deduplication (PLD) and pattern-aware trailing punctuation filtering (PTF)-by
enhancing the conventional filtering techniques. Our approach not only
considers line-level signals but also takes into account their sequential
distribution across documents, enabling us to retain structurally important
content that might otherwise be removed. We evaluate these proposed methods by
training small language models (1 B parameters) in both English and Korean. The
results demonstrate that our methods consistently improve performance on
multiple-choice benchmarks and significantly enhance generative
question-answering accuracy on both SQuAD v1 and KorQuAD v1.

</details>


### [30] [Ko-MuSR: A Multistep Soft Reasoning Benchmark for LLMs Capable of Understanding Korean](https://arxiv.org/abs/2510.24150)
*Chanwoo Park,Suyoung Park,JiA Kang,Jongyeon Park,Sangho Kim,Hyunji M. Park,Sumin Bae,Mingyu Kang,Jaejin Lee*

Main category: cs.CL

TL;DR: Ko-MuSR是首个全面评估韩语长篇叙事中多步软推理能力的基准，通过精心设计的提示策略，多语言模型在韩语推理任务中表现优于韩语专用模型。


<details>
  <summary>Details</summary>
Motivation: 构建首个专门针对韩语长篇叙事的推理基准，最小化数据污染，系统评估韩语NLP中的长上下文推理能力。

Method: 基于MuSR框架构建，包含全韩语叙事、推理链和多选题，经人工标注验证逻辑一致性和可回答性，评估四种大语言模型并设计提示策略。

Result: 多语言模型在韩语推理任务中表现优于韩语专用模型，显示推理能力的跨语言泛化；精心设计的提示策略显著提升准确率，接近人类水平。

Conclusion: Ko-MuSR为推进韩语NLP提供了坚实基础，能够系统评估长上下文推理和提示策略。

Abstract: We present Ko-MuSR, the first benchmark to comprehensively evaluate
multistep, soft reasoning in long Korean narratives while minimizing data
contamination. Built following MuSR, Ko-MuSR features fully Korean narratives,
reasoning chains, and multiple-choice questions verified by human annotators
for logical consistency and answerability. Evaluations of four large language
models -- two multilingual and two Korean-specialized -- show that multilingual
models outperform Korean-focused ones even in Korean reasoning tasks,
indicating cross-lingual generalization of reasoning ability. Carefully
designed prompting strategies, which combine few-shot examples, reasoning
traces, and task-specific hints, further boost accuracy, approaching
human-level performance. Ko-MuSR offers a solid foundation for advancing Korean
NLP by enabling systematic evaluation of long-context reasoning and prompting
strategies.

</details>


### [31] [MuSaG: A Multimodal German Sarcasm Dataset with Full-Modal Annotations](https://arxiv.org/abs/2510.24178)
*Aaron Scott,Maike Züfle,Jan Niehues*

Main category: cs.CL

TL;DR: 提出了MuSaG，首个德语多模态讽刺检测数据集，包含来自德国电视节目的33分钟手动选择和人工标注的语句，涵盖文本、音频和视频模态，并比较了9个开源和商业模型与人类标注的性能。


<details>
  <summary>Details</summary>
Motivation: 讽刺是一种复杂的比喻语言形式，在社交媒体和流行文化中普遍存在，对自然语言理解、情感分析和内容审核构成持续挑战。随着多模态大语言模型的出现，讽刺检测需要整合来自音频和视觉的线索。

Method: 构建了MuSaG数据集，包含33分钟来自德国电视节目的语句，每个实例提供对齐的文本、音频和视频模态，分别由人类标注，支持单模态和多模态设置下的评估。对9个开源和商业模型进行了基准测试。

Result: 结果显示，人类在对话设置中严重依赖音频，而模型在文本上表现最佳。这突显了当前多模态模型的差距，并激励使用MuSaG开发更适合现实场景的模型。

Conclusion: MuSaG数据集公开发布，以支持未来多模态讽刺检测和人类模型对齐的研究，强调需要开发更好地整合多模态信息的模型来应对现实世界的讽刺检测挑战。

Abstract: Sarcasm is a complex form of figurative language in which the intended
meaning contradicts the literal one. Its prevalence in social media and popular
culture poses persistent challenges for natural language understanding,
sentiment analysis, and content moderation. With the emergence of multimodal
large language models, sarcasm detection extends beyond text and requires
integrating cues from audio and vision. We present MuSaG, the first German
multimodal sarcasm detection dataset, consisting of 33 minutes of manually
selected and human-annotated statements from German television shows. Each
instance provides aligned text, audio, and video modalities, annotated
separately by humans, enabling evaluation in unimodal and multimodal settings.
We benchmark nine open-source and commercial models, spanning text, audio,
vision, and multimodal architectures, and compare their performance to human
annotations. Our results show that while humans rely heavily on audio in
conversational settings, models perform best on text. This highlights a gap in
current multimodal models and motivates the use of MuSaG for developing models
better suited to realistic scenarios. We release MuSaG publicly to support
future research on multimodal sarcasm detection and human-model alignment.

</details>


### [32] [Exploring the Influence of Relevant Knowledge for Natural Language Generation Interpretability](https://arxiv.org/abs/2510.24179)
*Iván Martínez-Murillo,Paloma Moreda,Elena Lloret*

Main category: cs.CL

TL;DR: 该研究探讨了外部知识整合对自然语言生成的影响，通过创建KITGI基准测试，发现完整外部知识能显著提升生成句子的常识合理性和概念覆盖率。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索外部知识在自然语言生成中的作用，特别是对常识生成任务的影响，旨在设计可解释的知识增强NLG系统。

Method: 采用三阶段方法：(1)识别并移除关键知识，(2)重新生成句子，(3)人工评估输出的常识合理性和概念覆盖率，使用T5-Large模型进行对比实验。

Result: 完整外部知识条件下生成的句子正确率达到91%，而过滤掉高度相关关系后性能急剧下降至6%，表明相关知识对保持生成质量至关重要。

Conclusion: 相关外部知识对于维持NLG的连贯性和概念覆盖率至关重要，需要设计可解释的知识增强系统和超越表面指标的评价框架。

Abstract: This paper explores the influence of external knowledge integration in
Natural Language Generation (NLG), focusing on a commonsense generation task.
We extend the CommonGen dataset by creating KITGI, a benchmark that pairs input
concept sets with retrieved semantic relations from ConceptNet and includes
manually annotated outputs. Using the T5-Large model, we compare sentence
generation under two conditions: with full external knowledge and with filtered
knowledge where highly relevant relations were deliberately removed. Our
interpretability benchmark follows a three-stage method: (1) identifying and
removing key knowledge, (2) regenerating sentences, and (3) manually assessing
outputs for commonsense plausibility and concept coverage. Results show that
sentences generated with full knowledge achieved 91\% correctness across both
criteria, while filtering reduced performance drastically to 6\%. These
findings demonstrate that relevant external knowledge is critical for
maintaining both coherence and concept coverage in NLG. This work highlights
the importance of designing interpretable, knowledge-enhanced NLG systems and
calls for evaluation frameworks that capture the underlying reasoning beyond
surface-level metrics.

</details>


### [33] [Beyond Neural Incompatibility: Easing Cross-Scale Knowledge Transfer in Large Language Models through Latent Semantic Alignment](https://arxiv.org/abs/2510.24208)
*Jian Gu,Aldeida Aleti,Chunyang Chen,Hongyu Zhang*

Main category: cs.CL

TL;DR: 提出了一种基于潜在空间语义对齐的LLM跨尺度知识迁移方法，通过激活值而非层参数实现更有效的知识迁移


<details>
  <summary>Details</summary>
Motivation: 解决LLM在不同规模模型间进行细粒度参数知识迁移的难题，克服神经网络不兼容性带来的限制

Method: 使用激活值作为层间知识迁移媒介，利用潜在空间语义对齐实现跨尺度知识迁移

Result: 在四个基准测试中表现优于现有方法，能更好地在不同规模模型间对齐模型行为

Conclusion: 潜在空间语义对齐是LLM跨尺度知识迁移的关键因素，为理解潜在语义对齐本质提供了见解

Abstract: Large Language Models (LLMs) encode vast amounts of knowledge in their
massive parameters, which is accessible to locate, trace, and analyze. Despite
advances in neural interpretability, it is still not clear how to transfer
knowledge in a fine-grained manner, namely parametric knowledge transfer (PKT).
A key problem is enabling effective and efficient knowledge transfer across
LLMs of different scales, which is essential for achieving greater flexibility
and broader applicability in transferring knowledge between LLMs. Due to neural
incompatibility, referring to the architectural and parametric differences
between LLMs of varying scales, existing methods that directly reuse layer
parameters are severely limited. In this paper, we identify the semantic
alignment in latent space as the fundamental prerequisite for LLM cross-scale
knowledge transfer. Instead of directly using the layer parameters, our
approach takes activations as the medium of layer-wise knowledge transfer.
Leveraging the semantics in latent space, our approach is simple and
outperforms prior work, better aligning model behaviors across varying scales.
Evaluations on four benchmarks demonstrate the efficacy of our method. Further
analysis reveals the key factors easing cross-scale knowledge transfer and
provides insights into the nature of latent semantic alignment.

</details>


### [34] [HACK: Hallucinations Along Certainty and Knowledge Axes](https://arxiv.org/abs/2510.24222)
*Adi Simhi,Jonathan Herzig,Itay Itzhak,Dana Arad,Zorik Gekhman,Roi Reichart,Fazl Barez,Gabriel Stanovsky,Idan Szpektor,Yonatan Belinkov*

Main category: cs.CL

TL;DR: 提出了一个基于知识和确定性两个维度的LLM幻觉分类框架，通过模型特定的数据集构建和验证方法，揭示了不同类型幻觉需要针对性缓解策略的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常基于幻觉的外部特征进行分类，而忽略了其内在机制，这导致无法针对不同类型幻觉制定有效的缓解策略。

Method: 提出了基于知识和确定性两个维度的幻觉分类框架，包括模型特定的数据集构建过程，并使用激活操控技术来验证知识维度的分类。

Result: 验证了知识维度分类的有效性，揭示了不同模型间知识和幻觉模式的差异，并识别出模型具有正确知识但仍自信产生幻觉的严重情况。

Conclusion: 强调在幻觉分析中同时考虑知识和确定性的重要性，呼吁开发考虑幻觉内在因素的针对性缓解方法。

Abstract: Hallucinations in LLMs present a critical barrier to their reliable usage.
Existing research usually categorizes hallucination by their external
properties rather than by the LLMs' underlying internal properties. This
external focus overlooks that hallucinations may require tailored mitigation
strategies based on their underlying mechanism. We propose a framework for
categorizing hallucinations along two axes: knowledge and certainty. Since
parametric knowledge and certainty may vary across models, our categorization
method involves a model-specific dataset construction process that
differentiates between those types of hallucinations. Along the knowledge axis,
we distinguish between hallucinations caused by a lack of knowledge and those
occurring despite the model having the knowledge of the correct response. To
validate our framework along the knowledge axis, we apply steering mitigation,
which relies on the existence of parametric knowledge to manipulate model
activations. This addresses the lack of existing methods to validate knowledge
categorization by showing a significant difference between the two
hallucination types. We further analyze the distinct knowledge and
hallucination patterns between models, showing that different hallucinations do
occur despite shared parametric knowledge. Turning to the certainty axis, we
identify a particularly concerning subset of hallucinations where models
hallucinate with certainty despite having the correct knowledge internally. We
introduce a new evaluation metric to measure the effectiveness of mitigation
methods on this subset, revealing that while some methods perform well on
average, they fail disproportionately on these critical cases. Our findings
highlight the importance of considering both knowledge and certainty in
hallucination analysis and call for targeted mitigation approaches that
consider the hallucination underlying factors.

</details>


### [35] [Towards Transparent Reasoning: What Drives Faithfulness in Large Language Models?](https://arxiv.org/abs/2510.24236)
*Teague McMillan,Gabriele Dominici,Martin Gjoreski,Marc Langheinrich*

Main category: cs.CL

TL;DR: 研究LLMs在医疗等敏感领域中解释的忠实性问题，探讨推理和训练选择如何影响解释忠实性，发现few-shot示例数量质量、提示设计和指令调优对忠实性有显著影响。


<details>
  <summary>Details</summary>
Motivation: LLMs生成的解释常常不能忠实反映其预测驱动因素，在医疗环境中这种不忠实性尤其危险，可能削弱临床医生信任并导致不安全的决策支持。

Method: 评估三个LLM模型在BBQ和MedQA数据集上的表现，操纵few-shot示例的数量和类型、提示策略以及训练过程，分析这些因素对解释忠实性的影响。

Result: few-shot示例的数量和质量显著影响模型忠实性；忠实性对提示设计敏感；指令调优阶段提高了MedQA上的忠实性测量。

Conclusion: 这些发现为在敏感领域中增强LLMs可解释性和可信度提供了策略见解。

Abstract: Large Language Models (LLMs) often produce explanations that do not
faithfully reflect the factors driving their predictions. In healthcare
settings, such unfaithfulness is especially problematic: explanations that omit
salient clinical cues or mask spurious shortcuts can undermine clinician trust
and lead to unsafe decision support. We study how inference and training-time
choices shape explanation faithfulness, focusing on factors practitioners can
control at deployment. We evaluate three LLMs (GPT-4.1-mini, LLaMA 70B, LLaMA
8B) on two datasets-BBQ (social bias) and MedQA (medical licensing questions),
and manipulate the number and type of few-shot examples, prompting strategies,
and training procedure. Our results show: (i) both the quantity and quality of
few-shot examples significantly impact model faithfulness; (ii) faithfulness is
sensitive to prompting design; (iii) the instruction-tuning phase improves
measured faithfulness on MedQA. These findings offer insights into strategies
for enhancing the interpretability and trustworthiness of LLMs in sensitive
domains.

</details>


### [36] [Abjad AI at NADI 2025: CATT-Whisper: Multimodal Diacritic Restoration Using Text and Speech Representations](https://arxiv.org/abs/2510.24247)
*Ahmad Ghannam,Naif Alharthi,Faris Alasmary,Kholood Al Tabash,Shouq Sadah,Lahouari Ghouti*

Main category: cs.CL

TL;DR: 本文提出了一种多模态方法，结合文本和语音信息来解决阿拉伯语方言的变音符号恢复任务，使用CATT预训练模型的编码器和OpenAI Whisper基础模型的编码器模块，通过早期融合和交叉注意力两种策略集成多模态信息。


<details>
  <summary>Details</summary>
Motivation: 解决阿拉伯语方言句子中变音符号恢复的挑战，传统方法主要依赖文本信息，而语音信息可能提供额外的上下文线索来改善恢复效果。

Method: 使用CATT预训练模型的编码器处理文本模态，OpenAI Whisper基础模型的编码器处理语音模态。采用两种集成策略：早期融合（将语音token与文本token合并）和交叉注意力（融合文本和语音嵌入）。在训练期间随机停用语音输入以提高模型鲁棒性。

Result: 在开发集上，模型实现了0.25的词错误率（WER）和0.9的字符错误率（CER）。在测试集上，模型实现了0.55的WER和0.13的CER。

Conclusion: 提出的多模态方法在阿拉伯语方言变音符号恢复任务中表现良好，证明了结合文本和语音信息的有效性，且模型在有无语音输入的情况下都能稳定工作。

Abstract: In this work, we tackle the Diacritic Restoration (DR) task for Arabic
dialectal sentences using a multimodal approach that combines both textual and
speech information. We propose a model that represents the text modality using
an encoder extracted from our own pre-trained model named CATT. The speech
component is handled by the encoder module of the OpenAI Whisper base model.
Our solution is designed following two integration strategies. The former
consists of fusing the speech tokens with the input at an early stage, where
the 1500 frames of the audio segment are averaged over 10 consecutive frames,
resulting in 150 speech tokens. To ensure embedding compatibility, these
averaged tokens are processed through a linear projection layer prior to
merging them with the text tokens. Contextual encoding is guaranteed by the
CATT encoder module. The latter strategy relies on cross-attention, where text
and speech embeddings are fused. The cross-attention output is then fed to the
CATT classification head for token-level diacritic prediction. To further
improve model robustness, we randomly deactivate the speech input during
training, allowing the model to perform well with or without speech. Our
experiments show that the proposed approach achieves a word error rate (WER) of
0.25 and a character error rate (CER) of 0.9 on the development set. On the
test set, our model achieved WER and CER scores of 0.55 and 0.13, respectively.

</details>


### [37] [Evaluating LLMs on Generating Age-Appropriate Child-Like Conversations](https://arxiv.org/abs/2510.24250)
*Syed Zohaib Hassan,Pål Halvorsen,Miriam S. Johnson,Pierre Lison*

Main category: cs.CL

TL;DR: 比较5种LLM生成挪威儿童对话的能力，发现大多数模型生成的语言比目标年龄组更高级，GPT-4和NorBloom-7b表现相对较好。


<details>
  <summary>Details</summary>
Motivation: LLM主要在成人对话数据上训练，难以生成真实、儿童化的对话，特别是在挪威语等低资源语言中缺乏适龄词汇资源。

Method: 通过盲评由11名教育专业人员评估5种LLM生成的5岁和9岁挪威儿童对话的真实性和发展适宜性，并与真实儿童访谈数据对比。

Result: 评估者具有强评分者间信度(ICC=0.75)，对5岁儿童的年龄预测准确率高于9岁儿童。大多数模型生成的语言被认为比目标年龄组更高级。

Conclusion: 开发面向儿童的LLM系统面临关键的数据相关挑战，特别是在低资源语言中适龄词汇资源稀缺的问题。

Abstract: Large Language Models (LLMs), predominantly trained on adult conversational
data, face significant challenges when generating authentic, child-like
dialogue for specialized applications. We present a comparative study
evaluating five different LLMs (GPT-4, RUTER-LLAMA-2-13b, GPTSW, NorMistral-7b,
and NorBloom-7b) to generate age-appropriate Norwegian conversations for
children aged 5 and 9 years. Through a blind evaluation by eleven education
professionals using both real child interview data and LLM-generated text
samples, we assessed authenticity and developmental appropriateness. Our
results show that evaluators achieved strong inter-rater reliability (ICC=0.75)
and demonstrated higher accuracy in age prediction for younger children
(5-year-olds) compared to older children (9-year-olds). While GPT-4 and
NorBloom-7b performed relatively well, most models generated language perceived
as more linguistically advanced than the target age groups. These findings
highlight critical data-related challenges in developing LLM systems for
specialized applications involving children, particularly in low-resource
languages where comprehensive age-appropriate lexical resources are scarce.

</details>


### [38] [From Memorization to Reasoning in the Spectrum of Loss Curvature](https://arxiv.org/abs/2510.24256)
*Jack Merullo,Srihita Vatsavaya,Lucius Bushnaq,Owen Lewis*

Main category: cs.CL

TL;DR: 本文提出了一种基于损失景观曲率的权重分解方法，能够从语言模型和视觉transformer中分离出记忆化表示，并通过权重编辑有效抑制记忆化数据的复现，同时保持较低困惑度。


<details>
  <summary>Details</summary>
Motivation: 基于理论和实证研究显示，记忆化训练点的损失景观曲率比非记忆化点更尖锐，这启发了通过曲率排序权重分量来区分记忆化内容，而无需显式标签。

Method: 使用损失景观曲率分解模型权重，开发权重编辑程序来抑制记忆化数据的复现，并与BalancedSubnet方法进行比较。

Result: 权重编辑方法比BalancedSubnet更有效地减少非目标记忆化数据的复现，同时保持较低困惑度。事实检索和算术任务性能显著下降，而开放书事实检索和一般逻辑推理能力得以保留。

Conclusion: 研究加深了对神经网络中记忆化的理解，提供了去除记忆化的实用方法，并证明数学和事实检索等任务依赖于权重空间中的特殊方向而非通用机制。

Abstract: We characterize how memorization is represented in transformer models and
show that it can be disentangled in the weights of both language models (LMs)
and vision transformers (ViTs) using a decomposition based on the loss
landscape curvature. This insight is based on prior theoretical and empirical
work showing that the curvature for memorized training points is much sharper
than non memorized, meaning ordering weight components from high to low
curvature can reveal a distinction without explicit labels. This motivates a
weight editing procedure that suppresses far more recitation of untargeted
memorized data more effectively than a recent unlearning method
(BalancedSubnet), while maintaining lower perplexity. Since the basis of
curvature has a natural interpretation for shared structure in model weights,
we analyze the editing procedure extensively on its effect on downstream tasks
in LMs, and find that fact retrieval and arithmetic are specifically and
consistently negatively affected, even though open book fact retrieval and
general logical reasoning is conserved. We posit these tasks rely heavily on
specialized directions in weight space rather than general purpose mechanisms,
regardless of whether those individual datapoints are memorized. We support
this by showing a correspondence between task data's activation strength with
low curvature components that we edit out, and the drop in task performance
after the edit. Our work enhances the understanding of memorization in neural
networks with practical applications towards removing it, and provides evidence
for idiosyncratic, narrowly-used structures involved in solving tasks like math
and fact retrieval.

</details>


### [39] [Can LLMs Translate Human Instructions into a Reinforcement Learning Agent's Internal Emergent Symbolic Representation?](https://arxiv.org/abs/2510.24259)
*Ziqi Ma,Sao Mai Nguyen,Philippe Xu*

Main category: cs.CL

TL;DR: 评估LLMs将自然语言指令转换为分层强化学习产生的内部符号表示的能力，发现其性能受分区粒度和任务复杂度影响显著


<details>
  <summary>Details</summary>
Motivation: 研究LLMs是否能将人类自然语言指令转换为分层强化学习过程中出现的内部符号表示，这对于发展性学习代理的规划和任务泛化至关重要

Method: 在Ant Maze和Ant Fall环境中，使用结构化评估框架测试GPT、Claude、Deepseek和Grok等常见LLMs在不同内部符号分区上的翻译性能

Result: LLMs展现出将自然语言转换为环境动态符号表示的一定能力，但性能对分区粒度和任务复杂度高度敏感

Conclusion: 当前LLMs在表示对齐方面存在局限性，需要进一步研究语言与内部代理表示之间的鲁棒对齐

Abstract: Emergent symbolic representations are critical for enabling developmental
learning agents to plan and generalize across tasks. In this work, we
investigate whether large language models (LLMs) can translate human natural
language instructions into the internal symbolic representations that emerge
during hierarchical reinforcement learning. We apply a structured evaluation
framework to measure the translation performance of commonly seen LLMs -- GPT,
Claude, Deepseek and Grok -- across different internal symbolic partitions
generated by a hierarchical reinforcement learning algorithm in the Ant Maze
and Ant Fall environments. Our findings reveal that although LLMs demonstrate
some ability to translate natural language into a symbolic representation of
the environment dynamics, their performance is highly sensitive to partition
granularity and task complexity. The results expose limitations in current LLMs
capacity for representation alignment, highlighting the need for further
research on robust alignment between language and internal agent
representations.

</details>


### [40] [MERGE: Minimal Expression-Replacement GEneralization Test for Natural Language Inference](https://arxiv.org/abs/2510.24295)
*Mădălina Zgreabăn,Tejaswini Deoskar,Lasha Abzianidze*

Main category: cs.CL

TL;DR: 提出了MERGE方法，通过替换开放类词汇自动生成保持推理逻辑的NLI问题变体，评估模型在最小修改问题上的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 手动创建NLI泛化基准成本高，自动生成高质量变体困难，需要一种能保持原始问题推理逻辑的自动生成方法。

Method: 通过替换开放类词汇生成NLI问题变体，同时保持底层推理逻辑不变，构建MERGE泛化测试集。

Result: NLI模型在变体问题上的性能下降4-20%，表明即使在最小修改的问题上泛化能力也较差。分析了替换词类别、词概率和合理性对性能的影响。

Conclusion: MERGE方法能有效评估NLI模型的泛化能力，揭示了当前模型在保持推理逻辑的最小修改问题上泛化能力不足的问题。

Abstract: In recent years, many generalization benchmarks have shown language models'
lack of robustness in natural language inference (NLI). However, manually
creating new benchmarks is costly, while automatically generating high-quality
ones, even by modifying existing benchmarks, is extremely difficult. In this
paper, we propose a methodology for automatically generating high-quality
variants of original NLI problems by replacing open-class words, while
crucially preserving their underlying reasoning. We dub our generalization test
as MERGE (Minimal Expression-Replacements GEneralization), which evaluates the
correctness of models' predictions across reasoning-preserving variants of the
original problem. Our results show that NLI models' perform 4-20% worse on
variants, suggesting low generalizability even on such minimally altered
problems. We also analyse how word class of the replacements, word probability,
and plausibility influence NLI models' performance.

</details>


### [41] [Lookahead Tree-Based Rollouts for Enhanced Trajectory-Level Exploration in Reinforcement Learning with Verifiable Rewards](https://arxiv.org/abs/2510.24302)
*Shangyu Xing,Siyuan Wang,Chenyuan Yang,Xinyu Dai,Xiang Ren*

Main category: cs.CL

TL;DR: 提出了LATR方法来解决强化学习中轨迹多样性不足的问题，通过前瞻树搜索策略显式促进轨迹级多样性，显著加速策略学习并提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习管道中，组rollout期间采样的轨迹多样性有限，同质化的轨迹和奖励会削弱策略更新的回报信号，阻碍有效策略学习。这种多样性缺乏主要源于token级随机采样，局部变化容易坍缩为几乎相同的推理路径。

Method: LATR是一种新颖的rollout策略，通过强制分支到可能产生不同延续的候选token来显式促进轨迹级多样性。具体包括三个迭代阶段：(1)在高不确定性生成步骤进行分支，(2)对每个新分支执行前瞻模拟，(3)在模拟期间剪除表现出持续相似性的分支。

Result: 相比随机采样，LATR平均加速策略学习131%，并在GRPO和DAPO算法上，在不同推理任务中提升最终pass@1性能4.2%。

Conclusion: LATR通过增强轨迹多样性有效解决了强化学习中的瓶颈问题，显著提升了策略学习效率和最终性能。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR), particularly with
algorithms like Group Relative Policy Optimization (GRPO), has proven highly
effective in enhancing the reasoning capabilities of large language models.
However, a critical bottleneck in current pipelines lies in the limited
diversity of sampled trajectories during group rollouts. Homogeneous
trajectories and their associated rewards would diminish the return signals for
policy updates, thereby hindering effective policy learning. This lack of
diversity stems primarily from token-level stochastic sampling, where local
variations are likely to collapse into near-identical reasoning paths. To
address this limitation, we propose Lookahead Tree-Based Rollouts (LATR), a
novel rollout strategy designed to explicitly promotes trajectory-level
diversity by enforcing branching into different candidate tokens likely to
yield distinct continuations. Specifically, LATR iteratively operates in three
stages: (1) branching at high-uncertainty generation steps, (2) performing
lookahead simulation for each new branch, and (3) pruning branches that
exhibits prolonged similarity during simulation. Compared with stochastic
Sampling, LATR accelerates policy learning by 131% on average and improves
final pass@1 performance by 4.2% on both GRPO and Dynamic sAmpling Policy
Optimization (DAPO) algorithms across different reasoning tasks. Our code and
data are publicly available at https://github.com/starreeze/latr.

</details>


### [42] [Critique-RL: Training Language Models for Critiquing through Two-Stage Reinforcement Learning](https://arxiv.org/abs/2510.24320)
*Zhiheng Xi,Jixuan Huang,Xin Guo,Boyang Hong,Dingwen Yang,Xiaoran Fan,Shuo Li,Zehui Chen,Junjie Ye,Siyu Yuan,Zhengyin Du,Xuesong Yao,Yufei Xu,Jiecao Chen,Rui Zheng,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.CL

TL;DR: 提出Critique-RL方法，无需强监督训练评论语言模型，通过两阶段优化策略提升评论者的判别能力和帮助性。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖强监督标注评论数据，限制了评论语言模型的发展。

Method: 采用两玩家范式：执行者生成响应，评论者提供反馈，执行者据此优化响应。使用两阶段优化：阶段I通过规则奖励增强判别能力，阶段II引入间接奖励提升帮助性。

Result: 在多个任务和模型上取得显著性能提升，Qwen2.5-7B在域内任务提升9.02%，域外任务提升5.70%。

Conclusion: Critique-RL展示了无需强监督开发评论语言模型的潜力，能有效提升模型性能。

Abstract: Training critiquing language models to assess and provide feedback on model
outputs is a promising way to improve LLMs for complex reasoning tasks.
However, existing approaches typically rely on stronger supervisors for
annotating critique data. To address this, we propose Critique-RL, an online RL
approach for developing critiquing language models without stronger
supervision. Our approach operates on a two-player paradigm: the actor
generates a response, the critic provides feedback, and the actor refines the
response accordingly. We first reveal that relying solely on indirect reward
signals from the actor's outputs for RL optimization often leads to
unsatisfactory critics: while their helpfulness (i.e., providing constructive
feedback) improves, the discriminability (i.e., determining whether a response
is high-quality or not) remains poor, resulting in marginal performance gains.
To overcome this, Critique-RL adopts a two-stage optimization strategy. In
stage I, it reinforces the discriminability of the critic with direct
rule-based reward signals; in stage II, it introduces indirect rewards based on
actor refinement to improve the critic's helpfulness, while maintaining its
discriminability via appropriate regularization. Extensive experiments across
various tasks and models show that Critique-RL delivers substantial performance
improvements. For example, it achieves a 9.02% gain on in-domain tasks and a
5.70% gain on out-of-domain tasks for Qwen2.5-7B, highlighting its potential.

</details>


### [43] [Beyond MCQ: An Open-Ended Arabic Cultural QA Benchmark with Dialect Variants](https://arxiv.org/abs/2510.24328)
*Hunzalah Hassan Bhatti,Firoj Alam*

Main category: cs.CL

TL;DR: 本文提出了一种评估LLMs在阿拉伯语方言和文化内容上表现的方法，包括翻译、转换问题格式、基准测试和思维链微调，发现模型在方言上表现不佳，阿拉伯语模型在开放式问题上表现较差，思维链能提升判断正确性但n-gram指标表现不一。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在日常问题回答中应用日益广泛，但在文化基础和方言内容上的表现存在语言间的不均衡，需要评估和改进模型在阿拉伯语方言和文化内容上的能力。

Method: 将现代标准阿拉伯语多选题翻译成英语和多种阿拉伯语方言，转换为开放式问题，对零样本和微调LLMs进行基准测试，生成思维链理由来微调模型进行逐步推理。

Result: 模型在阿拉伯语方言上表现不佳，揭示文化基础和方言知识的持续差距；阿拉伯语中心模型在多选题上表现良好但在开放式问题上表现挣扎；思维链提高了判断正确性但n-gram指标表现不一。

Conclusion: 开发的数据集将公开发布以支持文化和语言包容性评估的进一步研究，揭示了LLMs在方言和文化内容评估方面的不足，需要更多关注多语言和跨文化能力。

Abstract: Large Language Models (LLMs) are increasingly used to answer everyday
questions, yet their performance on culturally grounded and dialectal content
remains uneven across languages. We propose a comprehensive method that (i)
translates Modern Standard Arabic (MSA) multiple-choice questions (MCQs) into
English and several Arabic dialects, (ii) converts them into open-ended
questions (OEQs), (iii) benchmarks a range of zero-shot and fine-tuned LLMs
under both MCQ and OEQ settings, and (iv) generates chain-of-thought (CoT)
rationales to fine-tune models for step-by-step reasoning. Using this method,
we extend an existing dataset in which QAs are parallelly aligned across
multiple language varieties, making it, to our knowledge, the first of its
kind. We conduct extensive experiments with both open and closed models. Our
findings show that (i) models underperform on Arabic dialects, revealing
persistent gaps in culturally grounded and dialect-specific knowledge; (ii)
Arabic-centric models perform well on MCQs but struggle with OEQs; and (iii)
CoT improves judged correctness while yielding mixed n-gram-based metrics. The
developed dataset will be publicly released to support further research on
culturally and linguistically inclusive evaluation.

</details>


### [44] [LongWeave: A Long-Form Generation Benchmark Bridging Real-World Relevance and Verifiability](https://arxiv.org/abs/2510.24345)
*Zikai Xiao,Fei Huang,Jianhong Tu,Jianhui Wei,Wen Ma,Yuxuan Zhou,Jian Wu,Bowen Yu,Zuozhu Liu,Junyang Lin*

Main category: cs.CL

TL;DR: LongWeave是一个新的长文本生成基准，通过约束验证评估(CoV-Eval)方法平衡真实性和可验证性，评估LLM在长文本生成中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有长文本生成基准要么使用难以验证的真实世界查询，要么使用忽略真实世界复杂性的合成设置，需要一种平衡真实性和可验证性的评估方法。

Method: 提出约束验证评估(CoV-Eval)方法：首先在真实场景中定义可验证目标，然后系统生成相应查询、文本材料和约束，确保任务既真实又可客观评估。

Result: 在23个LLM上的评估显示，即使最先进的模型在真实世界复杂性和输出长度增加时，长文本生成仍面临显著挑战。

Conclusion: LongWeave提供了可定制输入/输出长度(最高64K/8K tokens)的七个任务，能够严格评估模型在满足复杂真实世界约束方面的能力。

Abstract: Generating long, informative, and factual outputs remains a major challenge
for Large Language Models (LLMs). Existing benchmarks for long-form generation
typically assess real-world queries with hard-to-verify metrics or use
synthetic setups that ease evaluation but overlook real-world intricacies. In
this paper, we introduce \textbf{LongWeave}, which balances real-world and
verifiable assessment with Constraint-Verifier Evaluation (CoV-Eval). CoV-Eval
constructs tasks by first defining verifiable targets within real-world
scenarios, then systematically generating corresponding queries, textual
materials, and constraints based on these targets. This ensures that tasks are
both realistic and objectively assessable, enabling rigorous assessment of
model capabilities in meeting complex real-world constraints. LongWeave
supports customizable input/output lengths (up to 64K/8K tokens) across seven
distinct tasks. Evaluation on 23 LLMs shows that even state-of-the-art models
encounter significant challenges in long-form generation as real-world
complexity and output length increase.

</details>


### [45] [Text Simplification with Sentence Embeddings](https://arxiv.org/abs/2510.24365)
*Matthew Shardlow*

Main category: cs.CL

TL;DR: 该论文探索了通过句子嵌入空间转换实现文本简化的方法，使用小型前馈神经网络学习高复杂度与低复杂度文本嵌入之间的转换，在小型学习设置中取得了与Seq2Seq和LLM方法相媲美的结果。


<details>
  <summary>Details</summary>
Motivation: 探索句子嵌入可以解码还原原始文本的特性，研究在文本简化任务中，重构的文本嵌入如何保持复杂度水平，为开发小型但强大的文本生成模型提供新方向。

Method: 使用小型前馈神经网络学习高复杂度与低复杂度句子嵌入之间的转换，并与Seq2Seq和基于LLM的方法进行比较。

Result: 在未见过的简化数据集(MedEASI)以及训练数据之外的语言(西班牙语、德语)上展示了转换的适用性，在小规模学习设置中取得了令人鼓舞的结果。

Conclusion: 在句子嵌入空间中学习转换是未来研究的有前景方向，有潜力开发出小型但强大的文本简化及其他自然语言生成任务模型。

Abstract: Sentence embeddings can be decoded to give approximations of the original
texts used to create them. We explore this effect in the context of text
simplification, demonstrating that reconstructed text embeddings preserve
complexity levels. We experiment with a small feed forward neural network to
effectively learn a transformation between sentence embeddings representing
high-complexity and low-complexity texts. We provide comparison to a Seq2Seq
and LLM-based approach, showing encouraging results in our much smaller
learning setting. Finally, we demonstrate the applicability of our
transformation to an unseen simplification dataset (MedEASI), as well as
datasets from languages outside the training data (ES,DE). We conclude that
learning transformations in sentence embedding space is a promising direction
for future research and has potential to unlock the ability to develop small,
but powerful models for text simplification and other natural language
generation tasks.

</details>


### [46] [Comprehensive and Efficient Distillation for Lightweight Sentiment Analysis Models](https://arxiv.org/abs/2510.24425)
*Guangyu Xie,Yice Zhang,Jianzhu Bao,Qianlong Wang,Yang Sun,Bingbing Wang,Ruifeng Xu*

Main category: cs.CL

TL;DR: COMPEFFDIST是一个用于情感分析的综合高效蒸馏框架，通过属性自动指令构建和难度数据过滤解决现有方法的两个关键挑战：指令多样性不足和大规模数据计算成本高。


<details>
  <summary>Details</summary>
Motivation: 现有基于知识蒸馏的情感分析方法存在两个问题：(1)人工编写的指令在多样性和数量上有限，无法确保蒸馏知识的全面覆盖；(2)大规模用户文本计算成本高，影响方法实用性。

Method: 提出COMPEFFDIST框架，包含两个关键模块：基于属性的自动指令构建和基于难度的数据过滤，分别解决指令多样性不足和数据效率问题。

Result: 在多个模型系列(Llama-3、Qwen-3、Gemma-3)上应用该方法，使3B学生模型在大多数任务上达到20倍大教师模型的性能水平，且在数据效率上大幅优于基线方法，仅用10%数据即可达到相同性能。

Conclusion: COMPEFFDIST框架有效解决了情感分析知识蒸馏中的指令多样性和数据效率问题，实现了高效且全面的模型蒸馏。

Abstract: Recent efforts leverage knowledge distillation techniques to develop
lightweight and practical sentiment analysis models. These methods are grounded
in human-written instructions and large-scale user texts. Despite the promising
results, two key challenges remain: (1) manually written instructions are
limited in diversity and quantity, making them insufficient to ensure
comprehensive coverage of distilled knowledge; (2) large-scale user texts incur
high computational cost, hindering the practicality of these methods. To this
end, we introduce COMPEFFDIST, a comprehensive and efficient distillation
framework for sentiment analysis. Our framework consists of two key modules:
attribute-based automatic instruction construction and difficulty-based data
filtering, which correspondingly tackle the aforementioned challenges. Applying
our method across multiple model series (Llama-3, Qwen-3, and Gemma-3), we
enable 3B student models to match the performance of 20x larger teacher models
on most tasks. In addition, our approach greatly outperforms baseline methods
in data efficiency, attaining the same performance level with only 10% of the
data.

</details>


### [47] [SynthWorlds: Controlled Parallel Worlds for Disentangling Reasoning and Knowledge in Language Models](https://arxiv.org/abs/2510.24427)
*Ken Gu,Advait Bhat,Mike A Merrill,Robert West,Xin Liu,Daniel McDuff,Tim Althoff*

Main category: cs.CL

TL;DR: SynthWorlds框架通过构建平行语料库来分离语言模型的任务推理能力和事实知识记忆，其中真实映射世界允许模型利用参数知识，而合成映射世界则使这种知识无效。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以清晰区分语言模型的推理能力和事实记忆能力，因为基准测试表现往往反映的是事实回忆而非真正的推理。

Method: 构建两个结构相同但内容不同的平行世界语料库，设计镜像任务（多跳问答和页面导航），在参数化设置和知识增强设置下进行实验。

Result: 实验显示存在持续的知识优势差距，知识获取和整合机制可以减少但无法消除这一差距。

Conclusion: SynthWorlds提供了一个可控环境，能够精确评估语言模型的推理和记忆能力，为系统改进指明了方向。

Abstract: Evaluating the reasoning ability of language models (LMs) is complicated by
their extensive parametric world knowledge, where benchmark performance often
reflects factual recall rather than genuine reasoning. Existing datasets and
approaches (e.g., temporal filtering, paraphrasing, adversarial substitution)
cannot cleanly separate the two. We present SynthWorlds, a framework that
disentangles task reasoning complexity from factual knowledge. In SynthWorlds,
we construct parallel corpora representing two worlds with identical
interconnected structure: a real-mapped world, where models may exploit
parametric knowledge, and a synthetic-mapped world, where such knowledge is
meaningless. On top of these corpora, we design two mirrored tasks as case
studies: multi-hop question answering and page navigation, which maintain equal
reasoning difficulty across worlds. Experiments in parametric-only (e.g.,
closed-book QA) and knowledge-augmented (e.g., retrieval-augmented) LM settings
reveal a persistent knowledge advantage gap, defined as the performance boost
models gain from memorized parametric world knowledge. Knowledge acquisition
and integration mechanisms reduce but do not eliminate this gap, highlighting
opportunities for system improvements. Fully automatic and scalable,
SynthWorlds provides a controlled environment for evaluating LMs in ways that
were previously challenging, enabling precise and testable comparisons of
reasoning and memorization.

</details>


### [48] [LuxIT: A Luxembourgish Instruction Tuning Dataset from Monolingual Seed Data](https://arxiv.org/abs/2510.24434)
*Julian Valline,Cedric Lothritz,Jordi Cabot*

Main category: cs.CL

TL;DR: LuxIT是一个针对卢森堡语的新型单语指令调优数据集，通过合成原生文本和LLM质量保证流程开发，但在实际应用中不同模型的性能表现差异显著。


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言环境下指令调优大语言模型因缺乏高质量训练数据而效果受限的问题，特别是针对卢森堡语。

Method: 从原生卢森堡语语料库合成数据集，使用DeepSeek-R1-0528生成内容，并采用LLM-as-a-judge方法进行质量保证。随后在多个小规模LLM上进行微调。

Result: 在卢森堡语能力测试中，不同模型的性能表现差异显著，结果好坏参半。

Conclusion: LuxIT对卢森堡语自然语言处理做出了重要贡献，并提供了可复制的单语方法，但需要进一步研究来优化其应用效果。

Abstract: The effectiveness of instruction-tuned Large Language Models (LLMs) is often
limited in low-resource linguistic settings due to a lack of high-quality
training data. We introduce LuxIT, a novel, monolingual instruction tuning
dataset for Luxembourgish developed to mitigate this challenge. We synthesize
the dataset from a corpus of native Luxembourgish texts, utilizing
DeepSeek-R1-0528, chosen for its shown proficiency in Luxembourgish. Following
generation, we apply a quality assurance process, employing an LLM-as-a-judge
approach. To investigate the practical utility of the dataset, we fine-tune
several smaller-scale LLMs on LuxIT. Subsequent benchmarking against their base
models on Luxembourgish language proficiency examinations, however, yields
mixed results, with performance varying significantly across different models.
LuxIT represents a critical contribution to Luxembourgish natural language
processing and offers a replicable monolingual methodology, though our findings
highlight the need for further research to optimize its application.

</details>


### [49] [Can LLMs Write Faithfully? An Agent-Based Evaluation of LLM-generated Islamic Content](https://arxiv.org/abs/2510.24438)
*Abdullah Mushtaq,Rafay Naeem,Ezieddin Elmahjub,Ibrahim Ghaznavi,Shawqi Al-Maliki,Mohamed Abdallah,Ala Al-Fuqaha,Junaid Qadir*

Main category: cs.CL

TL;DR: 评估GPT-4o、Ansari AI和Fanar在伊斯兰指导任务中的表现，发现GPT-4o在伊斯兰准确性和引用方面表现最佳，但所有模型在可靠生成准确伊斯兰内容和引用方面仍有不足。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型越来越多地用于伊斯兰指导，但存在误引文本、错误应用法学或产生文化不一致回答的风险，需要评估其可靠性。

Method: 使用双代理框架：定量代理进行引用验证和六维度评分，定性代理进行五维度并排比较。评估GPT-4o、Ansari AI和Fanar在真实伊斯兰博客提示上的表现。

Result: GPT-4o在伊斯兰准确性(3.93)和引用(3.38)方面得分最高，Ansari AI次之(3.68, 3.32)，Fanar最差(2.76, 1.82)。GPT-4o定量平均分最高(3.90/5)，Ansari AI在定性比较中获胜最多(116/200)。

Conclusion: 尽管相对表现较好，模型在可靠生成准确伊斯兰内容和引用方面仍有不足。研究强调需要以穆斯林视角为中心的社区驱动基准，为伊斯兰知识和其他高风险领域提供更可靠的AI。

Abstract: Large language models are increasingly used for Islamic guidance, but risk
misquoting texts, misapplying jurisprudence, or producing culturally
inconsistent responses. We pilot an evaluation of GPT-4o, Ansari AI, and Fanar
on prompts from authentic Islamic blogs. Our dual-agent framework uses a
quantitative agent for citation verification and six-dimensional scoring (e.g.,
Structure, Islamic Consistency, Citations) and a qualitative agent for
five-dimensional side-by-side comparison (e.g., Tone, Depth, Originality).
GPT-4o scored highest in Islamic Accuracy (3.93) and Citation (3.38), Ansari AI
followed (3.68, 3.32), and Fanar lagged (2.76, 1.82). Despite relatively strong
performance, models still fall short in reliably producing accurate Islamic
content and citations -- a paramount requirement in faith-sensitive writing.
GPT-4o had the highest mean quantitative score (3.90/5), while Ansari AI led
qualitative pairwise wins (116/200). Fanar, though trailing, introduces
innovations for Islamic and Arabic contexts. This study underscores the need
for community-driven benchmarks centering Muslim perspectives, offering an
early step toward more reliable AI in Islamic knowledge and other high-stakes
domains such as medicine, law, and journalism.

</details>


### [50] [SPARTA: Evaluating Reasoning Segmentation Robustness through Black-Box Adversarial Paraphrasing in Text Autoencoder Latent Space](https://arxiv.org/abs/2510.24446)
*Viktoriia Zinkovich,Anton Antonov,Andrei Spiridonov,Denis Shepelev,Andrey Moskalenko,Daria Pugacheva,Elena Tutubalina,Andrey Kuznetsov,Vlad Shakhuro*

Main category: cs.CL

TL;DR: 本文提出SPARTA方法，通过生成语义等价但语法正确的对抗性改写来攻击多模态大语言模型的推理分割能力，并开发了自动评估协议验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注图像输入的扰动，而语义等价的文本改写在实际应用中很常见但研究不足，需要评估模型对此类攻击的鲁棒性。

Method: 提出SPARTA方法，在文本自编码器的低维语义潜在空间中进行黑盒句子级优化，使用强化学习指导生成对抗性改写。

Result: SPARTA在ReasonSeg和LLMSeg-40k数据集上取得了显著更高的成功率，比之前方法高出最多2倍，揭示了先进推理分割模型对对抗性改写的脆弱性。

Conclusion: 即使有严格的语义和语法约束，推理分割模型仍然容易受到对抗性改写的攻击，这凸显了提高模型鲁棒性的重要性。

Abstract: Multimodal large language models (MLLMs) have shown impressive capabilities
in vision-language tasks such as reasoning segmentation, where models generate
segmentation masks based on textual queries. While prior work has primarily
focused on perturbing image inputs, semantically equivalent textual
paraphrases-crucial in real-world applications where users express the same
intent in varied ways-remain underexplored. To address this gap, we introduce a
novel adversarial paraphrasing task: generating grammatically correct
paraphrases that preserve the original query meaning while degrading
segmentation performance. To evaluate the quality of adversarial paraphrases,
we develop a comprehensive automatic evaluation protocol validated with human
studies. Furthermore, we introduce SPARTA-a black-box, sentence-level
optimization method that operates in the low-dimensional semantic latent space
of a text autoencoder, guided by reinforcement learning. SPARTA achieves
significantly higher success rates, outperforming prior methods by up to 2x on
both the ReasonSeg and LLMSeg-40k datasets. We use SPARTA and competitive
baselines to assess the robustness of advanced reasoning segmentation models.
We reveal that they remain vulnerable to adversarial paraphrasing-even under
strict semantic and grammatical constraints. All code and data will be released
publicly upon acceptance.

</details>


### [51] [Charting the European LLM Benchmarking Landscape: A New Taxonomy and a Set of Best Practices](https://arxiv.org/abs/2510.24450)
*Špela Vintar,Taja Kuzman Pungeršek,Mojca Brglez,Nikola Ljubešić*

Main category: cs.CL

TL;DR: 提出了一个针对多语言或非英语场景的基准测试分类法，并推荐了欧洲语言基准测试开发的最佳实践和质量标准。


<details>
  <summary>Details</summary>
Motivation: 当前LLM基准测试主要关注英语，非英语语言的评估仍然是一个未被充分探索的领域，需要更协调的基准测试开发方法。

Method: 回顾了LLM基准测试的最新发展，提出了专门针对多语言或非英语使用场景的基准测试分类法。

Result: 建立了一个新的基准测试分类框架，并提出了促进欧洲语言基准测试协调发展的具体建议。

Conclusion: 需要提高评估方法的语言和文化敏感性，以更好地支持多语言LLM的开发和评估。

Abstract: While new benchmarks for large language models (LLMs) are being developed
continuously to catch up with the growing capabilities of new models and AI in
general, using and evaluating LLMs in non-English languages remains a
little-charted landscape. We give a concise overview of recent developments in
LLM benchmarking, and then propose a new taxonomy for the categorization of
benchmarks that is tailored to multilingual or non-English use scenarios. We
further propose a set of best practices and quality standards that could lead
to a more coordinated development of benchmarks for European languages. Among
other recommendations, we advocate for a higher language and culture
sensitivity of evaluation methods.

</details>


### [52] [Iterative Critique-Refine Framework for Enhancing LLM Personalization](https://arxiv.org/abs/2510.24469)
*Durga Prasad Maram,Dhruvin Gandhi,Zonghai Yao,Gayathri Akkinapalli,Franck Dernoncourt,Yu Wang,Ryan A. Rossi,Nesreen K. Ahmed*

Main category: cs.CL

TL;DR: PerFine是一个无需训练的个性化文本生成框架，通过基于用户档案的迭代反馈和精炼来增强个性化，在多个数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强方法如LaMP和PGraphRAG虽然能生成文本，但在语气、主题和风格上容易偏离目标用户的特征，需要更好的个性化对齐方法。

Method: 提出训练免费的PerFine框架：LLM生成器基于检索档案生成初稿，批评LLM基于相同档案提供结构化反馈（语气、词汇、句子结构、主题性），生成器进行修订，并通过淘汰策略保留更好的版本。还研究了Best-of-N和主题提取等推理策略。

Result: 在Yelp、Goodreads和Amazon数据集上，PerFine相比PGraphRAG在GEval指标上提升7-13%，在3-5次精炼迭代中持续改进，且随着批评模型规模增大而扩展性良好。

Conclusion: 基于档案感知的后验反馈为个性化LLM生成提供了强大范式，既无需训练又模型无关。

Abstract: Personalized text generation requires models not only to produce coherent
text but also to align with a target user's style, tone, and topical focus.
Existing retrieval-augmented approaches such as LaMP and PGraphRAG enrich
profiles with user and neighbor histories, but they stop at generation and
often yield outputs that drift in tone, topic, or style. We present PerFine, a
unified, training-free critique-refine framework that enhances personalization
through iterative, profile-grounded feedback. In each iteration, an LLM
generator produces a draft conditioned on the retrieved profile, and a critic
LLM - also conditioned on the same profile - provides structured feedback on
tone, vocabulary, sentence structure, and topicality. The generator then
revises, while a novel knockout strategy retains the stronger draft across
iterations. We further study additional inference-time strategies such as
Best-of-N and Topic Extraction to balance quality and efficiency. Across Yelp,
Goodreads, and Amazon datasets, PerFine consistently improves personalization
over PGraphRAG, with GEval gains of +7-13%, steady improvements over 3-5
refinement iterations, and scalability with increasing critic size. These
results highlight that post-hoc, profile-aware feedback offers a powerful
paradigm for personalized LLM generation that is both training-free and
model-agnostic.

</details>


### [53] [Mitigating Hallucination in Large Language Models (LLMs): An Application-Oriented Survey on RAG, Reasoning, and Agentic Systems](https://arxiv.org/abs/2510.24476)
*Yihan Li,Xiyuan Fu,Ghanshyam Verma,Paul Buitelaar,Mingming Liu*

Main category: cs.CL

TL;DR: 本综述系统分析了RAG和推理增强在缓解LLM幻觉方面的协同作用，提出了基于知识和基于逻辑的幻觉分类，并提供了统一框架。


<details>
  <summary>Details</summary>
Motivation: 幻觉是LLM可靠部署的主要障碍，RAG和推理增强是最有效的缓解方法，但它们的协同机制尚未被系统研究。

Method: 采用应用导向的能力增强视角，提出幻觉分类法，系统分析RAG和推理如何分别处理知识型和逻辑型幻觉，建立统一框架。

Result: 提供了由实际应用、评估和基准支持的统一框架，展示了RAG和推理增强在缓解幻觉方面的协同潜力。

Conclusion: RAG、推理增强及其在智能体系统中的整合为缓解LLM幻觉提供了有效途径，从单纯抑制幻觉转向平衡创造性和可靠性。

Abstract: Hallucination remains one of the key obstacles to the reliable deployment of
large language models (LLMs), particularly in real-world applications. Among
various mitigation strategies, Retrieval-Augmented Generation (RAG) and
reasoning enhancement have emerged as two of the most effective and widely
adopted approaches, marking a shift from merely suppressing hallucinations to
balancing creativity and reliability. However, their synergistic potential and
underlying mechanisms for hallucination mitigation have not yet been
systematically examined. This survey adopts an application-oriented perspective
of capability enhancement to analyze how RAG, reasoning enhancement, and their
integration in Agentic Systems mitigate hallucinations. We propose a taxonomy
distinguishing knowledge-based and logic-based hallucinations, systematically
examine how RAG and reasoning address each, and present a unified framework
supported by real-world applications, evaluations, and benchmarks.

</details>


### [54] [Talk2Ref: A Dataset for Reference Prediction from Scientific Talks](https://arxiv.org/abs/2510.24478)
*Frederik Broy,Maike Züfle,Jan Niehues*

Main category: cs.CL

TL;DR: 提出了从科学演讲中预测参考文献的新任务RPT，并发布了首个大规模数据集Talk2Ref，包含6,279个演讲和43,429篇引用论文。通过评估最先进的文本嵌入模型和提出的双编码器架构，证明了在Talk2Ref上微调能显著提高引用预测性能。


<details>
  <summary>Details</summary>
Motivation: 科学演讲是传播研究的重要媒介，自动识别能够支撑或丰富演讲内容的相关文献对研究人员和学生具有重要价值。

Method: 提出了RPT任务，构建了Talk2Ref数据集，评估了零样本检索场景下的文本嵌入模型，设计了双编码器架构，并探索了处理长文本和领域适应的策略。

Result: 在Talk2Ref数据集上微调显著提高了引用预测性能，证明了该任务具有挑战性，同时数据集能够有效从口语科学内容中学习语义表示。

Conclusion: 该研究展示了将口语科学交流整合到引用推荐系统中的潜力，并开源了数据集和训练模型以促进未来研究。

Abstract: Scientific talks are a growing medium for disseminating research, and
automatically identifying relevant literature that grounds or enriches a talk
would be highly valuable for researchers and students alike. We introduce
Reference Prediction from Talks (RPT), a new task that maps long, and
unstructured scientific presentations to relevant papers. To support research
on RPT, we present Talk2Ref, the first large-scale dataset of its kind,
containing 6,279 talks and 43,429 cited papers (26 per talk on average), where
relevance is approximated by the papers cited in the talk's corresponding
source publication. We establish strong baselines by evaluating
state-of-the-art text embedding models in zero-shot retrieval scenarios, and
propose a dual-encoder architecture trained on Talk2Ref. We further explore
strategies for handling long transcripts, as well as training for domain
adaptation. Our results show that fine-tuning on Talk2Ref significantly
improves citation prediction performance, demonstrating both the challenges of
the task and the effectiveness of our dataset for learning semantic
representations from spoken scientific content. The dataset and trained models
are released under an open license to foster future research on integrating
spoken scientific communication into citation recommendation systems.

</details>


### [55] [A word association network methodology for evaluating implicit biases in LLMs compared to humans](https://arxiv.org/abs/2510.24488)
*Katherine Abramski,Giulio Rossetti,Massimo Stella*

Main category: cs.CL

TL;DR: 提出了一种基于词关联网络的新方法，用于评估大语言模型中的隐性偏见，通过模拟语义启动效应来量化模型偏见，并与人类认知进行比较。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型日益融入生活，其内在的社会偏见问题亟待解决。由于这些偏见通常是隐性的而非显性的，需要开发能够评估LLM隐性知识表示的评价方法。

Method: 采用基于提示的词关联网络方法，模拟LLM生成的词关联网络中的语义启动效应，挖掘LLM编码的隐性关系结构，提供定量和定性偏见评估。

Result: 应用该方法研究了性别、宗教、种族、性取向和政治党派等社会偏见，揭示了LLM与人类偏见之间的趋同和分歧，为使用LLM的潜在风险提供了新视角。

Conclusion: 该方法为评估和比较多个LLM与人类偏见提供了系统化、可扩展和可泛化的框架，推进了透明和负责任的语言技术发展目标。

Abstract: As Large language models (LLMs) become increasingly integrated into our
lives, their inherent social biases remain a pressing concern. Detecting and
evaluating these biases can be challenging because they are often implicit
rather than explicit in nature, so developing evaluation methods that assess
the implicit knowledge representations of LLMs is essential. We present a novel
word association network methodology for evaluating implicit biases in LLMs
based on simulating semantic priming within LLM-generated word association
networks. Our prompt-based approach taps into the implicit relational
structures encoded in LLMs, providing both quantitative and qualitative
assessments of bias. Unlike most prompt-based evaluation methods, our method
enables direct comparisons between various LLMs and humans, providing a
valuable point of reference and offering new insights into the alignment of
LLMs with human cognition. To demonstrate the utility of our methodology, we
apply it to both humans and several widely used LLMs to investigate social
biases related to gender, religion, ethnicity, sexual orientation, and
political party. Our results reveal both convergences and divergences between
LLM and human biases, providing new perspectives on the potential risks of
using LLMs. Our methodology contributes to a systematic, scalable, and
generalizable framework for evaluating and comparing biases across multiple
LLMs and humans, advancing the goal of transparent and socially responsible
language technologies.

</details>


### [56] [CritiCal: Can Critique Help LLM Uncertainty or Confidence Calibration?](https://arxiv.org/abs/2510.24505)
*Qing Zong,Jiayu Liu,Tianshi Zheng,Chunyang Li,Baixuan Xu,Haochen Shi,Weiqi Wang,Zhaowei Wang,Chunkit Chan,Yangqiu Song*

Main category: cs.CL

TL;DR: 提出使用自然语言批评来增强大语言模型的置信度校准，包括自我批评方法和CritiCal训练方法，在复杂推理任务中显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 传统置信度校准方法难以捕捉准确置信度评估所需的推理过程，而精确的黄金置信度标签难以获取且通常需要多次生成。

Method: 提出两种批评方法：Self-Critique让LLM自我批评并优化置信度；CritiCal是一种新颖的批评校准训练方法，利用自然语言批评改进置信度校准。

Result: CritiCal显著优于Self-Critique和其他竞争基线，在复杂推理任务中甚至超过其教师模型GPT-4o，并在分布外设置中表现出稳健的泛化能力。

Conclusion: 自然语言批评能有效增强LLM的置信度校准，提高模型可靠性，特别是在高风险领域应用中。

Abstract: Accurate confidence calibration in Large Language Models (LLMs) is critical
for safe use in high-stakes domains, where clear verbalized confidence enhances
user trust. Traditional methods that mimic reference confidence expressions
often fail to capture the reasoning needed for accurate confidence assessment.
We propose natural language critiques as a solution, ideally suited for
confidence calibration, as precise gold confidence labels are hard to obtain
and often require multiple generations. This paper studies how natural language
critiques can enhance verbalized confidence, addressing: (1) What to critique:
uncertainty (question-focused) or confidence (answer-specific)? Analysis shows
confidence suits multiple-choice tasks, while uncertainty excels in open-ended
scenarios. (2) How to critique: self-critique or critique calibration training?
We propose Self-Critique, enabling LLMs to critique and optimize their
confidence beyond mere accuracy, and CritiCal, a novel Critique Calibration
training method that leverages natural language critiques to improve confidence
calibration, moving beyond direct numerical optimization. Experiments show that
CritiCal significantly outperforms Self-Critique and other competitive
baselines, even surpassing its teacher model, GPT-4o, in complex reasoning
tasks. CritiCal also shows robust generalization in out-of-distribution
settings, advancing LLM's reliability.

</details>


### [57] [Levée d'ambiguïtés par grammaires locales](https://arxiv.org/abs/2510.24530)
*Eric G. C. Laporte*

Main category: cs.CL

TL;DR: 本文提出了一种在INTEX系统中实现的词性消歧方法，旨在实现零静默率目标，即正确词性标签永远不会被丢弃。


<details>
  <summary>Details</summary>
Motivation: 词性消歧是自然语言处理中的关键挑战，许多现有系统在文本存在歧义时无法找到唯一正确解。本文旨在开发一种适应零静默率目标的消歧方法。

Method: 在Silberztein的INTEX系统中实现的形式化词性消歧方法，使用局部消歧语法和转换器组合，强调需要验证转换器路径间的相互作用。

Result: 研究发现，验证局部消歧语法时不能单独考虑转换器路径，需要考虑它们的相互作用；组合多个转换器时，结果无法通过单独考虑来预测。

Conclusion: 为实现零静默率目标，局部语法需要仔细测试，需要详细规范语法在应用到文本时的行为，因为语法直觉可能因未预见的构造或歧义而不准确。

Abstract: Many words are ambiguous in terms of their part of speech (POS). However,
when a word appears in a text, this ambiguity is generally much reduced.
Disambiguating POS involves using context to reduce the number of POS
associated with words, and is one of the main challenges of lexical tagging.
The problem of labeling words by POS frequently arises in natural language
processing, for example for spelling correction, grammar or style checking,
expression recognition, text-to-speech conversion, text corpus analysis, etc.
Lexical tagging systems are thus useful as an initial component of many natural
language processing systems. A number of recent lexical tagging systems produce
multiple solutions when the text is lexically ambiguous or the uniquely correct
solution cannot be found. These contributions aim to guarantee a zero silence
rate: the correct tag(s) for a word must never be discarded. This objective is
unrealistic for systems that tag each word uniquely. This article concerns a
lexical disambiguation method adapted to the objective of a zero silence rate
and implemented in Silberztein's INTEX system (1993). We present here a formal
description of this method. We show that to verify a local disambiguation
grammar in this framework, it is not sufficient to consider the transducer
paths separately: one needs to verify their interactions. Similarly, if a
combination of multiple transducers is used, the result cannot be predicted by
considering them in isolation. Furthermore, when examining the initial labeling
of a text as produced by INTEX, ideas for disambiguation rules come
spontaneously, but grammatical intuitions may turn out to be inaccurate, often
due to an unforeseen construction or ambiguity. If a zero silence rate is
targeted, local grammars must be carefully tested. This is where a detailed
specification of what a grammar will do once applied to texts would be
necessary.

</details>


### [58] [Dark & Stormy: Modeling Humor in the Worst Sentences Ever Written](https://arxiv.org/abs/2510.24538)
*Venkata S Govindarajan,Laura Biester*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Textual humor is enormously diverse and computational studies need to account
for this range, including intentionally bad humor. In this paper, we curate and
analyze a novel corpus of sentences from the Bulwer-Lytton Fiction Contest to
better understand "bad" humor in English. Standard humor detection models
perform poorly on our corpus, and an analysis of literary devices finds that
these sentences combine features common in existing humor datasets (e.g., puns,
irony) with metaphor, metafiction and simile. LLMs prompted to synthesize
contest-style sentences imitate the form but exaggerate the effect by
over-using certain literary devices, and including far more novel
adjective-noun bigrams than human writers. Data, code and analysis are
available at https://github.com/venkatasg/bulwer-lytton

</details>


### [59] [Open Korean Historical Corpus: A Millennia-Scale Diachronic Collection of Public Domain Texts](https://arxiv.org/abs/2510.24541)
*Seyoung Song,Nawon Kim,Songeun Chae,Kiwoong Park,Jiho Jin,Haneul Yoo,Kyunghyun Cho,Alice Oh*

Main category: cs.CL

TL;DR: 介绍了开放韩语历史语料库，这是一个大规模、开放许可的数据集，涵盖1300年历史、6种语言，包含1800万份文档和50亿个标记，用于分析韩语的语言演变。


<details>
  <summary>Details</summary>
Motivation: 韩语历史中存在口语和书面语形式之间的差异，以及从汉字到韩文字母的关键转变，但由于缺乏可访问的历史语料库，这种语言演变在NLP领域尚未得到充分探索。

Method: 构建开放韩语历史语料库，该语料库跨越1300年，包含6种语言和代表性不足的书写系统，如韩式汉字（Idu）和汉字-韩文混合文字。

Result: 定量分析显示：(1) Idu使用在1860年代达到顶峰后急剧下降；(2) 从汉字到韩文的转变从1890年左右开始快速发生；(3) 朝鲜的词汇差异导致现代分词器产生高达51倍的词汇外率。

Conclusion: 该工作为定量历时分析提供了基础资源，捕捉了韩语的历史，并可作为大型语言模型的预训练语料库，提高其对现代韩文中的汉字词汇和古旧书写系统的理解。

Abstract: The history of the Korean language is characterized by a discrepancy between
its spoken and written forms and a pivotal shift from Chinese characters to the
Hangul alphabet. However, this linguistic evolution has remained largely
unexplored in NLP due to a lack of accessible historical corpora. To address
this gap, we introduce the Open Korean Historical Corpus, a large-scale, openly
licensed dataset spanning 1,300 years and 6 languages, as well as
under-represented writing systems like Korean-style Sinitic (Idu) and
Hanja-Hangul mixed script. This corpus contains 18 million documents and 5
billion tokens from 19 sources, ranging from the 7th century to 2025. We
leverage this resource to quantitatively analyze major linguistic shifts: (1)
Idu usage peaked in the 1860s before declining sharply; (2) the transition from
Hanja to Hangul was a rapid transformation starting around 1890; and (3) North
Korea's lexical divergence causes modern tokenizers to produce up to 51 times
higher out-of-vocabulary rates. This work provides a foundational resource for
quantitative diachronic analysis by capturing the history of the Korean
language. Moreover, it can serve as a pre-training corpus for large language
models, potentially improving their understanding of Sino-Korean vocabulary in
modern Hangul as well as archaic writing systems.

</details>


### [60] [BEST-RQ-Based Self-Supervised Learning for Whisper Domain Adaptation](https://arxiv.org/abs/2510.24570)
*Raphaël Bagat,Irina Illina,Emmanuel Vincent*

Main category: cs.CL

TL;DR: BEARD框架通过结合BEST-RQ目标和知识蒸馏，使用未标注数据适配Whisper编码器，在航空交通管制领域显著提升ASR性能


<details>
  <summary>Details</summary>
Motivation: 解决ASR系统在领域外和低资源场景下性能下降的问题，特别是在标注数据稀缺的情况下

Method: 提出BEARD框架，结合BEST-RQ目标与冻结教师编码器的知识蒸馏，确保编码器与预训练解码器的互补性

Result: 在ATCO2语料库上，使用5000小时未标注数据和2小时标注数据进行微调，相比基线模型获得12%的相对改进

Conclusion: 这是首个使用自监督学习目标进行Whisper领域适配的工作，在航空交通管制领域取得了显著性能提升

Abstract: Automatic Speech Recognition (ASR) systems, despite large multilingual
training, struggle in out-of-domain and low-resource scenarios where labeled
data is scarce. We propose BEARD (BEST-RQ Encoder Adaptation with Re-training
and Distillation), a novel framework designed to adapt Whisper's encoder using
unlabeled data. Unlike traditional self-supervised learning methods, BEARD
uniquely combines a BEST-RQ objective with knowledge distillation from a frozen
teacher encoder, ensuring the encoder's complementarity with the pre-trained
decoder. Our experiments focus on the ATCO2 corpus from the challenging Air
Traffic Control (ATC) communications domain, characterized by non-native
speech, noise, and specialized phraseology. Using about 5,000 hours of
untranscribed speech for BEARD and 2 hours of transcribed speech for
fine-tuning, the proposed approach significantly outperforms previous baseline
and fine-tuned model, achieving a relative improvement of 12% compared to the
fine-tuned model. To the best of our knowledge, this is the first work to use a
self-supervised learning objective for domain adaptation of Whisper.

</details>


### [61] [ReplicationBench: Can AI Agents Replicate Astrophysics Research Papers?](https://arxiv.org/abs/2510.24591)
*Christine Ye,Sihan Yuan,Suchetha Cooray,Steven Dillmann,Ian L. V. Roque,Dalya Baron,Philipp Frank,Sergio Martin-Alvarez,Nolan Koblischke,Frank J Qu,Diyi Yang,Risa Wechsler,Ioana Ciuca*

Main category: cs.CL

TL;DR: ReplicationBench是一个评估AI代理能否复制天体物理学研究论文的框架，通过将论文分解为任务来测试代理在实验设置、推导、数据分析和代码库方面的复制能力。


<details>
  <summary>Details</summary>
Motivation: 评估前沿AI代理作为科学研究助手的忠实性和正确性，特别是在需要较少实际实验的数据驱动科学领域。

Method: 将天体物理学论文分解为任务，每个任务与原论文作者共同开发，针对关键科学结果，评估代理的忠实性（遵循原始方法）和正确性（结果的技术准确性）。

Result: 当前最先进的语言模型在ReplicationBench上表现不佳，最佳模型得分低于20%。分析发现了代理在科学研究中的丰富多样的失败模式。

Conclusion: ReplicationBench建立了首个论文规模、专家验证的天体物理学研究任务基准，揭示了代理在数据驱动科学中的性能见解，并提供了衡量AI代理在科学研究中可靠性的可扩展框架。

Abstract: Frontier AI agents show increasing promise as scientific research assistants,
and may eventually be useful for extended, open-ended research workflows.
However, in order to use agents for novel research, we must first assess the
underlying faithfulness and correctness of their work. To evaluate agents as
research assistants, we introduce ReplicationBench, an evaluation framework
that tests whether agents can replicate entire research papers drawn from the
astrophysics literature. Astrophysics, where research relies heavily on
archival data and computational study while requiring little real-world
experimentation, is a particularly useful testbed for AI agents in scientific
research. We split each paper into tasks which require agents to replicate the
paper's core contributions, including the experimental setup, derivations, data
analysis, and codebase. Each task is co-developed with the original paper
authors and targets a key scientific result, enabling objective evaluation of
both faithfulness (adherence to original methods) and correctness (technical
accuracy of results). ReplicationBench is extremely challenging for current
frontier language models: even the best-performing language models score under
20%. We analyze ReplicationBench trajectories in collaboration with domain
experts and find a rich, diverse set of failure modes for agents in scientific
research. ReplicationBench establishes the first benchmark of paper-scale,
expert-validated astrophysics research tasks, reveals insights about agent
performance generalizable to other domains of data-driven science, and provides
a scalable framework for measuring AI agents' reliability in scientific
research.

</details>


### [62] [ReForm: Reflective Autoformalization with Prospective Bounded Sequence Optimization](https://arxiv.org/abs/2510.24592)
*Guoxin Chen,Jing Wu,Xinjie Chen,Wayne Xin Zhao,Ruihua Song,Chengxi Li,Kai Fan,Dayiheng Liu,Minpeng Liao*

Main category: cs.CL

TL;DR: ReForm是一种反射式自动形式化方法，通过集成语义一致性评估和迭代优化，显著提升了自然语言数学到机器可验证形式化语句的转换准确率。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型在自动形式化任务中虽然能生成语法正确的形式化语句，但常常无法保持原始问题的语义意图，这源于缺乏人类专家自然使用的自我反思和迭代优化机制。

Method: 提出ReForm方法，将语义一致性评估紧密集成到自动形式化过程中，使模型能够迭代生成形式化语句、评估语义保真度，并通过渐进优化自我纠正错误。使用前瞻有界序列优化(PBSO)训练模型，在不同序列位置使用不同奖励来确保准确的自动形式化和正确的语义验证。

Result: 在四个自动形式化基准测试中，ReForm相比最强基线平均提升了17.2个百分点。还引入了ConsistencyCheck基准，包含859个专家标注项目，验证了LLM作为评判者的可靠性，并显示自动形式化本身具有难度，人类专家也会在高达38.5%的情况下产生语义错误。

Conclusion: ReForm通过集成语义评估和迭代优化的反射式方法，显著提升了自动形式化的性能，同时揭示了该任务固有的挑战性，即使人类专家也难以完全避免语义错误。

Abstract: Autoformalization, which translates natural language mathematics into
machine-verifiable formal statements, is critical for using formal mathematical
reasoning to solve math problems stated in natural language. While Large
Language Models can generate syntactically correct formal statements, they
often fail to preserve the original problem's semantic intent. This limitation
arises from the LLM approaches' treating autoformalization as a simplistic
translation task which lacks mechanisms for self-reflection and iterative
refinement that human experts naturally employ. To address these issues, we
propose ReForm, a Reflective Autoformalization method that tightly integrates
semantic consistency evaluation into the autoformalization process. This
enables the model to iteratively generate formal statements, assess its
semantic fidelity, and self-correct identified errors through progressive
refinement. To effectively train this reflective model, we introduce
Prospective Bounded Sequence Optimization (PBSO), which employs different
rewards at different sequence positions to ensure that the model develops both
accurate autoformalization and correct semantic validations, preventing
superficial critiques that would undermine the purpose of reflection. Extensive
experiments across four autoformalization benchmarks demonstrate that ReForm
achieves an average improvement of 17.2 percentage points over the strongest
baselines. To further ensure evaluation reliability, we introduce
ConsistencyCheck, a benchmark of 859 expert-annotated items that not only
validates LLMs as judges but also reveals that autoformalization is inherently
difficult: even human experts produce semantic errors in up to 38.5% of cases.

</details>


### [63] [Diffusion LLM with Native Variable Generation Lengths: Let [EOS] Lead the Way](https://arxiv.org/abs/2510.24605)
*Yicun Yang,Cong Wang,Shaobo Wang,Zichen Wen,Biqing Qi,Hanlin Xu,Linfeng Zhang*

Main category: cs.CL

TL;DR: 提出dLLM-Var方法，使扩散大语言模型能够原生支持可变生成长度，解决了传统dLLMs必须预设生成长度的问题，实现了30.1倍的速度提升和2.4倍相对于自回归模型的加速。


<details>
  <summary>Details</summary>
Motivation: 当前基于扩散的大语言模型(dLLMs)存在固定生成长度的问题，必须在解码前确定生成长度作为超参数，这导致了效率和灵活性的问题。

Method: 训练扩散LLM原生支持可变生成长度(dLLM-Var)，通过准确预测[EOS]标记，使dLLM能够以块扩散方式推理，同时保持全局双向注意力和高并行性。

Result: 在标准基准测试中，该方法相比传统dLLM推理范式实现了30.1倍加速，相比Qwen和Llama等自回归模型实现了2.4倍加速，同时达到更高准确率。

Conclusion: 该方法实现了更高准确率和更快推理速度，将dLLMs从学术新奇提升到支持实际应用的水平。

Abstract: Diffusion-based large language models (dLLMs) have exhibited substantial
potential for parallel text generation, which may enable more efficient
generation compared to autoregressive models. However, current dLLMs suffer
from fixed generation lengths, which indicates the generation lengths of dLLMs
have to be determined before decoding as a hyper-parameter, leading to issues
in efficiency and flexibility. To solve these problems, in this work, we
propose to train a diffusion LLM with native variable generation lengths,
abbreviated as dLLM-Var. Concretely, we aim to train a model to accurately
predict the [EOS] token in the generated text, which makes a dLLM be able to
natively infer in a block diffusion manner, while still maintaining the ability
of global bi-directional (full) attention and high parallelism. Experiments on
standard benchmarks demonstrate that our method achieves a 30.1x speedup over
traditional dLLM inference paradigms and a 2.4x speedup relative to
autoregressive models such as Qwen and Llama. Our method achieves higher
accuracy and faster inference, elevating dLLMs beyond mere academic novelty and
supporting their practical use in real-world applications. Codes and models
have been released.

</details>


### [64] [Long-Context Modeling with Dynamic Hierarchical Sparse Attention for On-Device LLMs](https://arxiv.org/abs/2510.24606)
*Siheng Xiong,Joe Zou,Faramarz Fekri,Yae Jee Cho*

Main category: cs.CL

TL;DR: 提出了动态分层稀疏注意力（DHSA）框架，通过数据驱动的方式动态预测注意力稀疏性，在保持准确性的同时显著降低长上下文LLM的计算成本和内存使用。


<details>
  <summary>Details</summary>
Motivation: 现有静态稀疏方法（如滑动窗口或全局标记）无法适应注意力模式的内容依赖性变化，而动态方法又依赖预定义模板或启发式机制，限制了通用性和准确性。

Method: DHSA将序列自适应分割为变长块，通过长度归一化聚合计算块表示，然后将块级相似性上采样到标记级以确定保留哪些标记级交互。

Result: 在Gemma2上的实验显示，DHSA在保持密集注意力准确性的同时，将预填充延迟降低20-60%，峰值内存使用减少35%，相比其他基线方法准确率相对提升6-18%。

Conclusion: DHSA为长上下文设备端LLM提供了高效且适应性强的解决方案，在计算效率和准确性之间实现了良好平衡。

Abstract: The quadratic cost of attention hinders the scalability of long-context LLMs,
especially in resource-constrained settings. Existing static sparse methods
such as sliding windows or global tokens utilizes the sparsity of attention to
reduce the cost of attention, but poorly adapts to the content-dependent
variations in attention due to their staticity. While previous work has
proposed several dynamic approaches to improve flexibility, they still depend
on predefined templates or heuristic mechanisms. Such strategies reduce
generality and prune tokens that remain contextually important, limiting their
accuracy across diverse tasks. To tackle these bottlenecks of existing methods
for long-context modeling, we introduce Dynamic Hierarchical Sparse Attention
(DHSA), a data-driven framework that dynamically predicts attention sparsity
online without retraining. Our proposed DHSA adaptively segments sequences into
variable-length chunks, then computes chunk representations by aggregating the
token embeddings within each chunk. To avoid the bias introduced by varying
chunk lengths, we apply length-normalized aggregation that scales the averaged
embeddings by the square root of the chunk size. Finally, DHSA upsamples the
chunk-level similarity scores to token level similarities to calculate
importance scores that determine which token-level interactions should be
preserved. Our experiments on Gemma2 with Needle-in-a-Haystack Test and
LongBench show that DHSA matches dense attention in accuracy, while reducing
prefill latency by 20-60% and peak memory usage by 35%. Compared to other
representative baselines such as block sparse attention, DHSA achieves
consistently higher accuracy (6-18% relative gains) with comparable or lower
cost, offering an efficient and adaptable solution for long-context on-device
LLMs.

</details>


### [65] [Zero-Shot Cross-Lingual Transfer using Prefix-Based Adaptation](https://arxiv.org/abs/2510.24619)
*Snegha A,Sayambhu Sen,Piyush Singh Pasi,Abhishek Singhania,Preethi Jyothi*

Main category: cs.CL

TL;DR: 本文系统研究了三种基于前缀的方法在零样本跨语言迁移中的表现，发现前缀方法在Llama 3.1 8B和Mistral v0.3 7B模型上优于LoRA基线，在Belebele基准上提升达6%。


<details>
  <summary>Details</summary>
Motivation: 随着Llama和Mistral等大型语言模型的出现，零样本跨语言迁移变得可行，但将这些仅解码器LLM适应跨语言新任务仍具挑战性。前缀技术在仅解码器模型中的零样本迁移潜力尚未充分探索。

Method: 使用三种前缀方法（软提示调优、前缀调优和Llama Adapter）进行零样本跨语言迁移研究，涵盖从英语到35+种高资源和低资源语言的迁移，分析语言家族和文字的影响，以及模型规模从1B到24B的扩展效应。

Result: 前缀方法在Llama 3.1 8B上比LoRA基线在Belebele基准上提升达6%，Mistral v0.3 7B也观察到类似改进。前缀调优仅使用1.23M学习参数，但在多样化基准上实现了一致的改进。

Conclusion: 前缀技术是LoRA的有效且可扩展替代方案，特别是在低资源多语言设置中具有显著潜力。

Abstract: With the release of new large language models (LLMs) like Llama and Mistral,
zero-shot cross-lingual transfer has become increasingly feasible due to their
multilingual pretraining and strong generalization capabilities. However,
adapting these decoder-only LLMs to new tasks across languages remains
challenging. While parameter-efficient fine-tuning (PeFT) techniques like
Low-Rank Adaptation (LoRA) are widely used, prefix-based techniques such as
soft prompt tuning, prefix tuning, and Llama Adapter are less explored,
especially for zero-shot transfer in decoder-only models. We present a
comprehensive study of three prefix-based methods for zero-shot cross-lingual
transfer from English to 35+ high- and low-resource languages. Our analysis
further explores transfer across linguistic families and scripts, as well as
the impact of scaling model sizes from 1B to 24B. With Llama 3.1 8B, prefix
methods outperform LoRA-baselines by up to 6% on the Belebele benchmark.
Similar improvements were observed with Mistral v0.3 7B as well. Despite using
only 1.23M learning parameters with prefix tuning, we achieve consistent
improvements across diverse benchmarks. These findings highlight the potential
of prefix-based techniques as an effective and scalable alternative to LoRA,
particularly in low-resource multilingual settings.

</details>


### [66] [Relative Scaling Laws for LLMs](https://arxiv.org/abs/2510.24626)
*William Held,David Hall,Percy Liang,Diyi Yang*

Main category: cs.CL

TL;DR: 该论文提出了相对缩放定律，研究不同测试分布之间的性能差距如何随模型规模变化，发现缩放并非普遍均衡器，不同领域的性能演化轨迹各异。


<details>
  <summary>Details</summary>
Motivation: 传统的缩放定律基于聚合测试集，掩盖了不同子群体的性能差异。研究者希望了解缩放如何影响不同测试分布间的相对性能差距。

Method: 训练了255个解码器Transformer模型，在匹配计算预算(10^18-10^20 FLOPs)下使用标准预训练数据集，分析不同测试分布的相对性能演化。

Result: 发现多样化的演化轨迹：学术领域趋于均衡；英语方言性能取决于人口规模；AI风险行为出现分化，能力相关风险增加而对抗性风险不变。

Conclusion: 缩放虽然提升整体性能，但不是普遍均衡器。研究者发布所有模型检查点，鼓励同时测量相对和传统缩放定律，以更好应对鲁棒性挑战。

Abstract: Scaling laws describe how language models improve with additional data,
parameters, and compute. While widely used, they are typically measured on
aggregate test sets. Aggregate evaluations yield clean trends but average over
heterogeneous subpopulations, obscuring performance disparities. We introduce
relative scaling laws, which track how performance gaps between test
distributions evolve with scale rather than focusing solely on absolute error.
Using 255 decoder-only Transformers trained under matched-compute (IsoFLOP)
budgets from $10^{18}$--$10^{20}$ FLOPs on standard pretraining datasets, we
find diverse trajectories: academic domains on MMLU converge toward parity;
regional English dialects shift depending on population size; and clusters of
AI risk behaviours split, with capability- and influence-related risks
increasing during pretraining while adversarial risks do not. These results
show that although scaling improves overall performance, it is not a universal
equalizer. To support further study, we release all model checkpoints from this
work to enable practitioners to measure relative alongside traditional scaling
laws, in order to better prioritize robustness challenges in light of the
bitter lesson.

</details>


### [67] ["Mm, Wat?" Detecting Other-initiated Repair Requests in Dialogue](https://arxiv.org/abs/2510.24628)
*Anh Ngo,Nicolas Rollet,Catherine Pelachaud,Chloe Clavel*

Main category: cs.CL

TL;DR: 提出多模态模型检测荷兰对话中的修复发起，结合语言和韵律特征，显著提升预训练文本和音频嵌入的效果


<details>
  <summary>Details</summary>
Motivation: 对话代理无法识别用户修复发起导致对话中断或脱离，需要自动检测修复发起来维持相互理解

Method: 基于会话分析整合语言和韵律特征的多模态模型，使用预训练文本和音频嵌入

Result: 韵律线索补充语言特征，显著改善预训练嵌入的结果，揭示不同特征的交互作用

Conclusion: 韵律特征对修复发起检测有重要价值，未来可加入视觉线索并探索多语言跨语境语料库

Abstract: Maintaining mutual understanding is a key component in human-human
conversation to avoid conversation breakdowns, in which repair, particularly
Other-Initiated Repair (OIR, when one speaker signals trouble and prompts the
other to resolve), plays a vital role. However, Conversational Agents (CAs)
still fail to recognize user repair initiation, leading to breakdowns or
disengagement. This work proposes a multimodal model to automatically detect
repair initiation in Dutch dialogues by integrating linguistic and prosodic
features grounded in Conversation Analysis. The results show that prosodic cues
complement linguistic features and significantly improve the results of
pretrained text and audio embeddings, offering insights into how different
features interact. Future directions include incorporating visual cues,
exploring multilingual and cross-context corpora to assess the robustness and
generalizability.

</details>


### [68] [OpenReward: Learning to Reward Long-form Agentic Tasks via Reinforcement Learning](https://arxiv.org/abs/2510.24636)
*Ziyou Hu,Zhengliang Shi,Minghang Zhu,Haitao Li,Teng Sun,Pengjie Ren,Suzan Verberne,Zhaochun Ren*

Main category: cs.CL

TL;DR: OpenRM是一种工具增强的长文本奖励模型，通过调用外部工具收集相关证据来系统评估开放式回答，解决了现有奖励模型在知识密集和长文本任务上的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有奖励模型在知识密集和长文本任务上表现不佳，因为评估正确性需要超出模型内部知识的基础支撑，这限制了它们可靠区分细微质量差异的能力，特别是在需要外部证据的情况下。

Method: 使用Group Relative Policy Optimization (GRPO)在超过27K合成的成对示例上训练OpenRM，通过可控数据合成框架生成数据。训练目标同时监督中间工具使用和最终结果准确性，激励奖励模型学习有效的基于证据的判断策略。

Result: 在三个新收集的数据集和两个广泛使用的基准测试上的大量实验表明，OpenRM显著优于现有的奖励建模方法。将OpenRM集成到推理时响应选择和训练时数据选择中，在下游LLM对齐任务中带来了一致的增益。

Conclusion: 工具增强的奖励模型具有扩展可靠长文本评估的潜力，OpenRM的成功证明了这种方法在提升大语言模型对齐效果方面的价值。

Abstract: Reward models (RMs) have become essential for aligning large language models
(LLMs), serving as scalable proxies for human evaluation in both training and
inference. However, existing RMs struggle on knowledge-intensive and long-form
tasks, where evaluating correctness requires grounding beyond the model's
internal knowledge. This limitation hinders them from reliably discriminating
subtle quality differences, especially when external evidence is necessary. To
address this, we introduce OpenRM, a tool-augmented long-form reward model that
systematically judges open-ended responses by invoking external tools to gather
relevant evidence. We train OpenRM with Group Relative Policy Optimization
(GRPO) on over 27K synthesized pairwise examples generated through a
controllable data synthesis framework. The training objective jointly
supervises intermediate tool usage and final outcome accuracy, incentivizing
our reward model to learn effective evidence-based judgment strategies.
Extensive experiments on three newly-collected datasets and two widely-used
benchmarks demonstrate that OpenRM substantially outperforms existing reward
modeling approaches. As a further step, we integrate OpenRM into both
inference-time response selection and training-time data selection. This yields
consistent gains in downstream LLM alignment tasks, highlighting the potential
of tool-augmented reward models for scaling reliable long-form evaluation.

</details>


### [69] [Quantifying the Effects of Word Length, Frequency, and Predictability on Dyslexia](https://arxiv.org/abs/2510.24647)
*Hugo Rydel-Johnston,Alex Kafkas*

Main category: cs.CL

TL;DR: 本研究通过眼动追踪分析发现，阅读障碍者在单词长度、频率和可预测性三个特征上都表现出更强的敏感性，其中可预测性的影响最大。通过反事实操作这些特征，可以将阅读障碍者与正常读者的差距缩小约三分之一。


<details>
  <summary>Details</summary>
Motivation: 探究阅读障碍者在自然阅读情境中何时以及何种条件下出现阅读成本增加，通过量化单词特征对阅读障碍者阅读时间的影响，为干预措施和计算模型提供指导。

Method: 使用大规模自然阅读数据集，结合眼动追踪技术，分析单词长度、频率和可预测性三个特征对阅读障碍者和正常读者阅读时间的影响，并进行反事实特征操作。

Result: 所有三个单词特征都显著影响阅读时间，阅读障碍者对每个特征都表现出更强的敏感性，特别是可预测性。反事实操作可将阅读障碍者与正常读者的差距缩小约三分之一。

Conclusion: 研究结果支持阅读障碍理论中关于语言工作记忆和语音编码需求增加的假设，并为解释剩余差距提供了关于词汇复杂性和副中央凹预览效益的研究方向。

Abstract: We ask where, and under what conditions, dyslexic reading costs arise in a
large-scale naturalistic reading dataset. Using eye-tracking aligned to
word-level features (word length, frequency, and predictability), we model how
each feature influences dyslexic time costs. We find that all three features
robustly change reading times in both typical and dyslexic readers, and that
dyslexic readers show stronger sensitivities to each, especially
predictability. Counterfactual manipulations of these features substantially
narrow the dyslexic-control gap by about one third, with predictability showing
the strongest effect, followed by length and frequency. These patterns align
with dyslexia theories that posit heightened demands on linguistic working
memory and phonological encoding, and they motivate further work on lexical
complexity and parafoveal preview benefits to explain the remaining gap. In
short, we quantify when extra dyslexic costs arise, how large they are, and
offer actionable guidance for interventions and computational models for
dyslexics.

</details>


### [70] [Optimizing Retrieval for RAG via Reinforced Contrastive Learning](https://arxiv.org/abs/2510.24652)
*Jiawei Zhou,Lei Chen*

Main category: cs.CL

TL;DR: R3是一个通过试错反馈强化对比学习优化的RAG检索框架，无需标注数据即可动态优化检索器在RAG环境中的相关性判断。


<details>
  <summary>Details</summary>
Motivation: 随着RAG的普及，信息检索的角色从为人类用户检索信息转变为为AI系统检索上下文知识，其中相关性难以预先定义或标注。

Method: R3采用试错反馈强化对比学习，让检索器在RAG环境中动态探索和优化相关性，通过检索结果与环境交互产生对比信号来自动指导检索器的自我改进。

Result: 在多样化任务上的实验表明，R3相比原始检索器提升RAG性能5.2%，超越最先进检索器4.9%，达到与基于后训练或指令调优LLM的LLM增强检索和RAG系统相当的结果。

Conclusion: R3既高效又实用，仅需4个GPU且在一天内完成训练，为RAG系统提供了一种无需标注数据的有效检索优化方案。

Abstract: As retrieval-augmented generation (RAG) becomes increasingly widespread, the
role of information retrieval (IR) is shifting from retrieving information for
human users to retrieving contextual knowledge for artificial intelligence (AI)
systems, where relevance becomes difficult to define or annotate beforehand. To
address this challenge, we propose R3, a Retrieval framework optimized for RAG
through trialand-feedback Reinforced contrastive learning. Unlike prior
approaches that rely on annotated or synthetic data for supervised fine-tuning,
R3 enables the retriever to dynamically explore and optimize relevance within
the RAG environment. During training, the retrieved results interact with the
environment to produce contrastive signals that automatically guide the
retriever's self-improvement. Extensive experiments across diverse tasks
demonstrate that R3 improves RAG performance by 5.2% over the original
retriever and surpasses state-of-the-art retrievers by 4.9%, while achieving
comparable results to LLM-augmented retrieval and RAG systems built on
post-trained or instruction-tuned LLMs. It is both efficient and practical,
requiring only 4 GPUs and completing training within a single day.

</details>


### [71] [Evolving Diagnostic Agents in a Virtual Clinical Environment](https://arxiv.org/abs/2510.24654)
*Pengcheng Qiu,Chaoyi Wu,Junwei Liu,Qiaoyu Zheng,Yusheng Liao,Haowen Wang,Yun Yue,Qianrui Fan,Shuai Zhen,Jian Wang,Jinjie Gu,Yanfeng Wang,Ya Zhang,Weidi Xie*

Main category: cs.CL

TL;DR: 提出了一种基于强化学习的诊断代理训练框架，通过交互式探索和结果反馈学习诊断策略，在多个诊断任务中显著优于现有大型语言模型。


<details>
  <summary>Details</summary>
Motivation: 传统基于静态病例摘要的指令调优模型无法获得动态诊断管理能力，需要开发能够在交互式临床环境中学习诊断策略的方法。

Method: 开发了DiagGym诊断世界模型作为虚拟临床环境，使用端到端多轮强化学习训练DiagAgent，优化信息获取和诊断准确性。

Result: DiagAgent在单轮设置中诊断准确率提升9.34%，检查推荐命中率提升44.03%；在端到端设置中诊断准确率提升15.12%，检查推荐F1分数提升23.09%；在标准评估中比次优模型Claude-sonnet-4高7.1%。

Conclusion: 在交互式临床环境中学习策略能够赋予动态且具有临床意义的诊断管理能力，这是被动训练无法实现的。

Abstract: In this paper, we present a framework for training large language models
(LLMs) as diagnostic agents with reinforcement learning, enabling them to
manage multi-turn diagnostic processes, adaptively select examinations, and
commit to final diagnoses. Unlike instruction-tuned models trained on static
case summaries, our method acquires diagnostic strategies through interactive
exploration and outcome-based feedback. Our contributions are fourfold: (i) We
present DiagGym, a diagnostics world model trained with electronic health
records that emits examination outcomes conditioned on patient history and
recommended examination, serving as a virtual clinical environment for
realistic diagnosis training and evaluation; (ii) We train DiagAgent via
end-to-end, multi-turn reinforcement learning to learn diagnostic policies that
optimize both information yield and diagnostic accuracy; (iii) We introduce
DiagBench, a diagnostic benchmark comprising 750 cases with physician-validated
examination recommendations and 99 cases annotated with 973 physician-written
rubrics on diagnosis process; (iv) we demonstrate superior performance across
diverse diagnostic settings. DiagAgent significantly outperforms 10
state-of-the-art LLMs, including DeepSeek-v3 and GPT-4o, as well as two
prompt-engineered agents. In single-turn settings, DiagAgent achieves 9.34%
higher diagnostic accuracy and 44.03% improvement in examination recommendation
hit ratio. In end-to-end settings, it delivers 15.12% increase in diagnostic
accuracy and 23.09% boost in examination recommendation F1 score. In
rubric-based evaluation, it surpasses the next-best model, Claude-sonnet-4, by
7.1% in weighted rubric score. These findings indicate that learning policies
in interactive clinical environments confers dynamic and clinically meaningful
diagnostic management abilities unattainable through passive training alone.

</details>


### [72] [MQM Re-Annotation: A Technique for Collaborative Evaluation of Machine Translation](https://arxiv.org/abs/2510.24664)
*Parker Riley,Daniel Deutsch,Mara Finkelstein,Colten DiIanni,Juraj Juraska,Markus Freitag*

Main category: cs.CL

TL;DR: 提出了一种名为MQM重新标注的两阶段机器翻译评估方法，通过让标注者审查和编辑已有的MQM标注来提高评估质量。


<details>
  <summary>Details</summary>
Motivation: 随着机器翻译模型质量的提升，需要改进评估方法以确保质量提升不会在评估噪声中丢失。

Method: 采用两阶段MQM评估范式，让标注者审查和编辑已有的MQM标注（可能来自自己、其他标注者或自动系统）。

Result: 重新标注符合预期目标，能产生更高质量的标注，主要是通过发现第一次标注中遗漏的错误。

Conclusion: MQM重新标注是一种有效的机器翻译评估改进方法，能显著提高标注质量。

Abstract: Human evaluation of machine translation is in an arms race with translation
model quality: as our models get better, our evaluation methods need to be
improved to ensure that quality gains are not lost in evaluation noise. To this
end, we experiment with a two-stage version of the current state-of-the-art
translation evaluation paradigm (MQM), which we call MQM re-annotation. In this
setup, an MQM annotator reviews and edits a set of pre-existing MQM
annotations, that may have come from themselves, another human annotator, or an
automatic MQM annotation system. We demonstrate that rater behavior in
re-annotation aligns with our goals, and that re-annotation results in
higher-quality annotations, mostly due to finding errors that were missed
during the first pass.

</details>


### [73] [InteractComp: Evaluating Search Agents With Ambiguous Queries](https://arxiv.org/abs/2510.24668)
*Mingyi Deng,Lijun Huang,Yani Fan,Jiayi Zhang,Fashen Ren,Jinyi Bai,Fuzhen Yang,Dayi Miao,Zhaoyang Yu,Yifan Wu,Yanfei Zhang,Fengwei Teng,Yingjia Wan,Song Hu,Yude Li,Xin Jin,Conghao Hu,Haoyu Li,Qirui Fu,Tai Zhong,Xinyu Wang,Xiangru Tang,Nan Tang,Chenglin Wu,Yuyu Luo*

Main category: cs.CL

TL;DR: 提出了InteractComp基准来评估搜索代理在查询不明确时主动交互的能力，发现现有模型存在系统性过度自信问题，强制交互能显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有语言代理假设用户查询是完整明确的，但现实中用户常从模糊查询开始，需要交互澄清。现有基准无法评估这种交互能力。

Method: 通过目标-干扰方法构建210个专家策划的问题，涵盖9个领域，创建只能通过交互解决的真正模糊性。评估了17个模型。

Result: 最佳模型准确率仅13.73%，而有完整上下文时可达71.50%，暴露系统性过度自信而非推理缺陷。强制交互能带来显著提升。

Conclusion: 搜索代理的交互能力在15个月内停滞不前，而搜索性能提升了7倍，揭示了关键盲点。InteractComp为评估和训练搜索代理的交互能力提供了宝贵资源。

Abstract: Language agents have demonstrated remarkable potential in web search and
information retrieval. However, these search agents assume user queries are
complete and unambiguous, an assumption that diverges from reality where users
begin with incomplete queries requiring clarification through interaction. Yet
most agents lack interactive mechanisms during the search process, and existing
benchmarks cannot assess this capability. To address this gap, we introduce
InteractComp, a benchmark designed to evaluate whether search agents can
recognize query ambiguity and actively interact to resolve it during search.
Following the principle of easy to verify, interact to disambiguate, we
construct 210 expert-curated questions across 9 domains through a
target-distractor methodology that creates genuine ambiguity resolvable only
through interaction. Evaluation of 17 models reveals striking failure: the best
model achieves only 13.73% accuracy despite 71.50% with complete context,
exposing systematic overconfidence rather than reasoning deficits. Forced
interaction produces dramatic gains, demonstrating latent capability current
strategies fail to engage. Longitudinal analysis shows interaction capabilities
stagnated over 15 months while search performance improved seven-fold,
revealing a critical blind spot. This stagnation, coupled with the immediate
feedback inherent to search tasks, makes InteractComp a valuable resource for
both evaluating and training interaction capabilities in search agents. The
code is available at https://github.com/FoundationAgents/InteractComp.

</details>


### [74] [Dissecting Role Cognition in Medical LLMs via Neuronal Ablation](https://arxiv.org/abs/2510.24677)
*Xun Liang,Huayi Lai,Hanyu Wang,Wentao Zhang,Linfeng Zhang,Yanfang Chen,Feiyu Xiong,Zhiyu Li*

Main category: cs.CL

TL;DR: 该研究评估了基于提示的角色扮演(PBRP)对大型语言模型医学推理能力的影响，发现角色提示主要影响表面语言特征而非核心推理能力。


<details>
  <summary>Details</summary>
Motivation: 评估角色提示是否能在LLMs中诱导出不同的、角色特定的认知过程，还是仅仅修改语言风格。

Method: 引入RP-Neuron-Activated评估框架(RPNA)，在三个医学QA数据集上使用神经元消融和表示分析技术来评估推理路径变化。

Result: 角色提示并未显著增强LLMs的医学推理能力，主要影响表面语言特征，没有证据显示不同临床角色之间存在不同的推理路径或认知差异。

Conclusion: 当前PBRP方法无法复制真实世界医学实践中的认知复杂性，需要开发能够模拟真实认知过程而非语言模仿的模型。

Abstract: Large language models (LLMs) have gained significant traction in medical
decision support systems, particularly in the
  context of medical question answering and role-playing simulations. A common
practice, Prompt-Based Role Playing (PBRP),
  instructs models to adopt different clinical roles (e.g., medical students,
residents, attending physicians) to simulate varied
  professional behaviors. However, the impact of such role prompts on model
reasoning capabilities remains unclear. This
  study introduces the RP-Neuron-Activated Evaluation Framework(RPNA) to
evaluate whether role prompts induce distinct,
  role-specific cognitive processes in LLMs or merely modify linguistic style.
We test this framework on three medical QA
  datasets, employing neuron ablation and representation analysis techniques to
assess changes in reasoning pathways. Our
  results demonstrate that role prompts do not significantly enhance the
medical reasoning abilities of LLMs. Instead, they
  primarily affect surface-level linguistic features, with no evidence of
distinct reasoning pathways or cognitive differentiation
  across clinical roles. Despite superficial stylistic changes, the core
decision-making mechanisms of LLMs remain uniform
  across roles, indicating that current PBRP methods fail to replicate the
cognitive complexity found in real-world medical
  practice. This highlights the limitations of role-playing in medical AI and
emphasizes the need for models that simulate genuine
  cognitive processes rather than linguistic imitation.We have released the
related code in the following repository:https:
  //github.com/IAAR-Shanghai/RolePlay_LLMDoctor

</details>


### [75] [SPICE: Self-Play In Corpus Environments Improves Reasoning](https://arxiv.org/abs/2510.24684)
*Bo Liu,Chuanyang Jin,Seungone Kim,Weizhe Yuan,Wenting Zhao,Ilia Kulikov,Xian Li,Sainbayar Sukhbaatar,Jack Lanchantin,Jason Weston*

Main category: cs.CL

TL;DR: SPICE是一个强化学习框架，通过单一模型扮演挑战者和推理者两个角色，从大型语料库中挖掘文档生成多样化推理任务，实现持续的自我改进。


<details>
  <summary>Details</summary>
Motivation: 自我改进系统需要环境交互来实现持续适应。现有无基础的自博弈方法收益有限，需要一种能够持续生成挑战性目标并实现它们的机制。

Method: 引入SPICE框架：挑战者从大型语料库挖掘文档生成多样化推理任务，推理者解决这些任务。通过对抗性动态，挑战者在推理者能力前沿创建自动课程，语料库基础提供丰富的外部信号。

Result: 在数学推理（+8.9%）和通用推理（+9.8%）基准测试中实现一致增益，在多个模型家族上表现优异。文档基础是SPICE持续生成日益挑战性目标并实现它们的关键要素。

Conclusion: SPICE通过语料库基础的对抗性自博弈实现了持续的自我改进，文档基础是该方法成功的关键因素。

Abstract: Self-improving systems require environmental interaction for continuous
adaptation. We introduce SPICE (Self-Play In Corpus Environments), a
reinforcement learning framework where a single model acts in two roles: a
Challenger that mines documents from a large corpus to generate diverse
reasoning tasks, and a Reasoner that solves them. Through adversarial dynamics,
the Challenger creates an automatic curriculum at the frontier of the
Reasoner's capability, while corpus grounding provides the rich,
near-inexhaustible external signal necessary for sustained improvement. Unlike
existing ungrounded self-play methods that offer more limited benefits, SPICE
achieves consistent gains across mathematical (+8.9%) and general reasoning
(+9.8%) benchmarks on multiple model families. Our analysis reveals how
document grounding is a key ingredient in SPICE to continuously generate its
own increasingly challenging goals and achieve them, enabling sustained
self-improvement.

</details>


### [76] [Repurposing Synthetic Data for Fine-grained Search Agent Supervision](https://arxiv.org/abs/2510.24694)
*Yida Zhao,Kuan Li,Xixi Wu,Liwen Zhang,Dingchu Zhang,Baixuan Li,Maojia Song,Zhuo Chen,Chenxi Wang,Xinyu Wang,Kewei Tu,Pengjun Xie,Jingren Zhou,Yong Jiang*

Main category: cs.CL

TL;DR: 提出了E-GRPO框架，通过利用实体信息为错误样本分配部分奖励，有效学习"近似正确"样本，显著提升了搜索代理的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 现有训练方法如GRPO丢弃了丰富的实体信息，仅依赖稀疏的结果奖励，无法区分具有正确推理但最终答案错误的"近似正确"样本，浪费了宝贵的学习信号。

Method: 引入实体感知的群组相对策略优化(E-GRPO)，基于实体匹配率构建密集的实体感知奖励函数，为错误样本分配部分奖励。

Result: 在多种问答和深度研究基准测试中，E-GRPO始终显著优于GRPO基线，不仅准确率更高，还诱导出更高效的推理策略，需要更少的工具调用。

Conclusion: E-GRPO提供了一种更有效和样本效率更高的方法来对齐搜索代理，通过利用实体信息实现了更好的性能和推理效率。

Abstract: LLM-based search agents are increasingly trained on entity-centric synthetic
data to solve complex, knowledge-intensive tasks. However, prevailing training
methods like Group Relative Policy Optimization (GRPO) discard this rich entity
information, relying instead on sparse, outcome-based rewards. This critical
limitation renders them unable to distinguish informative "near-miss"
samples-those with substantially correct reasoning but a flawed final
answer-from complete failures, thus discarding valuable learning signals. We
address this by leveraging the very entities discarded during training. Our
empirical analysis reveals a strong positive correlation between the number of
ground-truth entities identified during an agent's reasoning process and final
answer accuracy. Building on this insight, we introduce Entity-aware Group
Relative Policy Optimization (E-GRPO), a novel framework that formulates a
dense entity-aware reward function. E-GRPO assigns partial rewards to incorrect
samples proportional to their entity match rate, enabling the model to
effectively learn from these "near-misses". Experiments on diverse
question-answering (QA) and deep research benchmarks show that E-GRPO
consistently and significantly outperforms the GRPO baseline. Furthermore, our
analysis reveals that E-GRPO not only achieves superior accuracy but also
induces more efficient reasoning policies that require fewer tool calls,
demonstrating a more effective and sample-efficient approach to aligning search
agents.

</details>


### [77] [AgentFrontier: Expanding the Capability Frontier of LLM Agents with ZPD-Guided Data Synthesis](https://arxiv.org/abs/2510.24695)
*Xuanzhong Chen,Zile Qiao,Guoxin Chen,Liangcai Su,Zhen Zhang,Xinyu Wang,Pengjun Xie,Fei Huang,Jingren Zhou,Yong Jiang*

Main category: cs.CL

TL;DR: 提出基于最近发展区理论的AgentFrontier引擎，通过自动化数据合成训练LLM代理，在复杂推理任务上达到最先进水平


<details>
  <summary>Details</summary>
Motivation: 在LLM能力边界上训练代理是解锁高级推理的关键，需要找到模型无法独立解决但能在指导下掌握的任务

Method: 基于最近发展区理论构建AgentFrontier引擎，自动合成高质量多学科数据，支持持续预训练和针对性后训练

Result: 训练的AgentFrontier-30B-A3B模型在Humanity's Last Exam等基准测试中达到最先进水平，甚至超过一些领先的专有代理

Conclusion: ZPD指导的数据合成方法为构建更强大LLM代理提供了可扩展且有效的路径

Abstract: Training large language model agents on tasks at the frontier of their
capabilities is key to unlocking advanced reasoning. We introduce a data
synthesis approach inspired by the educational theory of the Zone of Proximal
Development (ZPD), which defines this frontier as tasks an LLM cannot solve
alone but can master with guidance. To operationalize this, we present the
AgentFrontier Engine, an automated pipeline that synthesizes high-quality,
multidisciplinary data situated precisely within the LLM's ZPD. This engine
supports both continued pre-training with knowledge-intensive data and targeted
post-training on complex reasoning tasks. From the same framework, we derive
the ZPD Exam, a dynamic and automated benchmark designed to evaluate agent
capabilities on these frontier tasks. We train AgentFrontier-30B-A3B model on
our synthesized data, which achieves state-of-the-art results on demanding
benchmarks like Humanity's Last Exam, even surpassing some leading proprietary
agents. Our work demonstrates that a ZPD-guided approach to data synthesis
offers a scalable and effective path toward building more capable LLM agents.

</details>


### [78] [WebLeaper: Empowering Efficiency and Efficacy in WebAgent via Enabling Info-Rich Seeking](https://arxiv.org/abs/2510.24697)
*Zhengwei Tao,Haiyang Shen,Baixuan Li,Wenbiao Yin,Jialong Wu,Kuan Li,Zhongwang Zhang,Huifeng Yin,Rui Ye,Liwen Zhang,Xinyu Wang,Pengjun Xie,Jingren Zhou,Yong Jiang*

Main category: cs.CL

TL;DR: WebLeaper框架通过构建高覆盖率的信息搜索任务和生成高效解决方案轨迹，解决了LLM智能体在信息搜索中效率低下的问题，在多个基准测试中实现了效果和效率的双重提升。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的信息搜索智能体存在搜索效率低的问题，这限制了整体性能。主要原因是训练任务中目标实体稀疏，限制了智能体学习和泛化高效搜索行为的机会。

Method: 将信息搜索建模为树状结构推理问题，在受限上下文中嵌入更多目标实体。利用维基百科表格提出三种任务合成变体（Basic、Union、Reverse-Union），并通过保留既准确又高效的训练轨迹来优化模型。

Result: 在五个信息搜索基准测试（BrowserComp、GAIA、xbench-DeepSearch、WideSearch、Seal-0）上的广泛实验表明，该方法在效果和效率方面均优于强基线模型。

Conclusion: WebLeaper框架通过系统性地提高信息搜索任务的覆盖率和效率，显著提升了LLM智能体在开放问题解决中的信息搜索能力，实现了效果和效率的双重改进。

Abstract: Large Language Model (LLM)-based agents have emerged as a transformative
approach for open-ended problem solving, with information seeking (IS) being a
core capability that enables autonomous reasoning and decision-making. While
prior research has largely focused on improving retrieval depth, we observe
that current IS agents often suffer from low search efficiency, which in turn
constrains overall performance. A key factor underlying this inefficiency is
the sparsity of target entities in training tasks, which limits opportunities
for agents to learn and generalize efficient search behaviors. To address these
challenges, we propose WebLeaper, a framework for constructing high-coverage IS
tasks and generating efficient solution trajectories. We formulate IS as a
tree-structured reasoning problem, enabling a substantially larger set of
target entities to be embedded within a constrained context. Leveraging curated
Wikipedia tables, we propose three variants for synthesizing IS tasks, Basic,
Union, and Reverse-Union, to systematically increase both IS efficiency and
efficacy. Finally, we curate training trajectories by retaining only those that
are simultaneously accurate and efficient, ensuring that the model is optimized
for both correctness and search performance. Extensive experiments on both
basic and comprehensive settings, conducted on five IS benchmarks, BrowserComp,
GAIA, xbench-DeepSearch, WideSearch, and Seal-0, demonstrate that our method
consistently achieves improvements in both effectiveness and efficiency over
strong baselines.

</details>


### [79] [ParallelMuse: Agentic Parallel Thinking for Deep Information Seeking](https://arxiv.org/abs/2510.24698)
*Baixuan Li,Dingchu Zhang,Jialong Wu,Wenbiao Yin,Zhengwei Tao,Yida Zhao,Liwen Zhang,Haiyang Shen,Runnan Fang,Pengjun Xie,Jingren Zhou,Yong Jiang*

Main category: cs.CL

TL;DR: ParallelMuse是一个两阶段范式，通过功能化部分展开和压缩推理聚合来解决并行思维在信息搜索代理中的效率低下和长轨迹整合困难问题。


<details>
  <summary>Details</summary>
Motivation: 传统并行思维在信息搜索代理中存在两个关键挑战：从头开始重复展开导致效率低下，以及有限上下文容量难以在答案生成时整合长程推理轨迹。

Method: 提出ParallelMuse两阶段方法：第一阶段功能化部分展开，将生成序列分区为功能区域，进行不确定性引导的路径重用和分支；第二阶段压缩推理聚合，利用推理冗余无损压缩答案推导相关信息并合成连贯最终答案。

Result: 在多个开源代理和基准测试中，性能提升高达62%，探索性token消耗减少10-30%。

Conclusion: ParallelMuse通过高效的并行探索和压缩推理聚合，显著提升了信息搜索代理的问题解决能力，同时降低了计算成本。

Abstract: Parallel thinking expands exploration breadth, complementing the deep
exploration of information-seeking (IS) agents to further enhance
problem-solving capability. However, conventional parallel thinking faces two
key challenges in this setting: inefficiency from repeatedly rolling out from
scratch, and difficulty in integrating long-horizon reasoning trajectories
during answer generation, as limited context capacity prevents full
consideration of the reasoning process. To address these issues, we propose
ParallelMuse, a two-stage paradigm designed for deep IS agents. The first
stage, Functionality-Specified Partial Rollout, partitions generated sequences
into functional regions and performs uncertainty-guided path reuse and
branching to enhance exploration efficiency. The second stage, Compressed
Reasoning Aggregation, exploits reasoning redundancy to losslessly compress
information relevant to answer derivation and synthesize a coherent final
answer. Experiments across multiple open-source agents and benchmarks
demonstrate up to 62% performance improvement with a 10--30% reduction in
exploratory token consumption.

</details>


### [80] [AgentFold: Long-Horizon Web Agents with Proactive Context Management](https://arxiv.org/abs/2510.24699)
*Rui Ye,Zhongwang Zhang,Kuan Li,Huifeng Yin,Zhengwei Tao,Yida Zhao,Liangcai Su,Liwen Zhang,Zile Qiao,Xinyu Wang,Pengjun Xie,Fei Huang,Siheng Chen,Jingren Zhou,Yong Jiang*

Main category: cs.CL

TL;DR: AgentFold提出了一种新的智能体范式，通过主动上下文管理解决长视野任务中的上下文饱和问题，采用多尺度折叠操作来动态管理历史轨迹。


<details>
  <summary>Details</summary>
Motivation: 现有基于ReAct的智能体在长视野任务中存在上下文饱和问题，而固定总结方法可能导致关键细节丢失，需要一种更智能的上下文管理方法。

Method: AgentFold受人类回顾性认知过程启发，将上下文视为动态认知工作空间，通过折叠操作在多个尺度上管理历史轨迹：细粒度压缩保留关键细节，深度整合抽象多步子任务。

Result: 在BrowseComp上达到36.2%，BrowseComp-ZH上达到47.3%，性能超过或匹配更大规模的开源模型（如DeepSeek-V3.1-671B-A37B），并超越领先的专有智能体（如OpenAI o4-mini）。

Conclusion: AgentFold通过主动上下文管理范式显著提升了长视野任务的性能，证明了智能上下文管理比单纯扩大模型规模更有效。

Abstract: LLM-based web agents show immense promise for information seeking, yet their
effectiveness on long-horizon tasks is hindered by a fundamental trade-off in
context management. Prevailing ReAct-based agents suffer from context
saturation as they accumulate noisy, raw histories, while methods that fixedly
summarize the full history at each step risk the irreversible loss of critical
details. Addressing these, we introduce AgentFold, a novel agent paradigm
centered on proactive context management, inspired by the human cognitive
process of retrospective consolidation. AgentFold treats its context as a
dynamic cognitive workspace to be actively sculpted, rather than a passive log
to be filled. At each step, it learns to execute a `folding' operation, which
manages its historical trajectory at multiple scales: it can perform granular
condensations to preserve vital, fine-grained details, or deep consolidations
to abstract away entire multi-step sub-tasks. The results on prominent
benchmarks are striking: with simple supervised fine-tuning (without continual
pre-training or RL), our AgentFold-30B-A3B agent achieves 36.2% on BrowseComp
and 47.3% on BrowseComp-ZH. Notably, this performance not only surpasses or
matches open-source models of a dramatically larger scale, such as the
DeepSeek-V3.1-671B-A37B, but also surpasses leading proprietary agents like
OpenAI's o4-mini.

</details>


### [81] [Tongyi DeepResearch Technical Report](https://arxiv.org/abs/2510.24701)
*Tongyi DeepResearch Team,Baixuan Li,Bo Zhang,Dingchu Zhang,Fei Huang,Guangyu Li,Guoxin Chen,Huifeng Yin,Jialong Wu,Jingren Zhou,Kuan Li,Liangcai Su,Litu Ou,Liwen Zhang,Pengjun Xie,Rui Ye,Wenbiao Yin,Xinmiao Yu,Xinyu Wang,Xixi Wu,Xuanzhong Chen,Yida Zhao,Zhen Zhang,Zhengwei Tao,Zhongwang Zhang,Zile Qiao,Chenxi Wang,Donglei Yu,Gang Fu,Haiyang Shen,Jiayin Yang,Jun Lin,Junkai Zhang,Kui Zeng,Li Yang,Hailong Yin,Maojia Song,Ming Yan,Peng Xia,Qian Xiao,Rui Min,Ruixue Ding,Runnan Fang,Shaowei Chen,Shen Huang,Shihang Wang,Shihao Cai,Weizhou Shen,Xiaobin Wang,Xin Guan,Xinyu Geng,Yingcheng Shi,Yuning Wu,Zhuo Chen,Zijian Li,Yong Jiang*

Main category: cs.CL

TL;DR: Tongyi DeepResearch是一个专为深度信息搜索研究任务设计的智能大语言模型，通过端到端训练框架实现自主深度研究能力，在多个基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决长周期、深度信息搜索研究任务的挑战，开发能够自主进行深度研究的智能代理模型。

Method: 采用端到端训练框架，结合智能代理中期训练和后训练，设计高度可扩展的自动数据合成管道，为每个阶段构建定制化环境。

Result: Tongyi DeepResearch拥有305亿总参数，每个token仅激活33亿参数，在多个智能深度研究基准测试中取得最先进性能。

Conclusion: 该模型、框架和完整解决方案已开源，旨在赋能研究社区，推动智能深度研究技术的发展。

Abstract: We present Tongyi DeepResearch, an agentic large language model, which is
specifically designed for long-horizon, deep information-seeking research
tasks. To incentivize autonomous deep research agency, Tongyi DeepResearch is
developed through an end-to-end training framework that combines agentic
mid-training and agentic post-training, enabling scalable reasoning and
information seeking across complex tasks. We design a highly scalable data
synthesis pipeline that is fully automatic, without relying on costly human
annotation, and empowers all training stages. By constructing customized
environments for each stage, our system enables stable and consistent
interactions throughout. Tongyi DeepResearch, featuring 30.5 billion total
parameters, with only 3.3 billion activated per token, achieves
state-of-the-art performance across a range of agentic deep research
benchmarks, including Humanity's Last Exam, BrowseComp, BrowseComp-ZH,
WebWalkerQA, xbench-DeepSearch, FRAMES and xbench-DeepSearch-2510. We
open-source the model, framework, and complete solutions to empower the
community.

</details>


### [82] [Agent Data Protocol: Unifying Datasets for Diverse, Effective Fine-tuning of LLM Agents](https://arxiv.org/abs/2510.24702)
*Yueqi Song,Ketan Ramaneti,Zaid Sheikh,Ziru Chen,Boyu Gou,Tianbao Xie,Yiheng Xu,Danyang Zhang,Apurva Gandhi,Fan Yang,Joseph Liu,Tianyue Ou,Zhihao Yuan,Frank Xu,Shuyan Zhou,Xingyao Wang,Xiang Yue,Tao Yu,Huan Sun,Yu Su,Graham Neubig*

Main category: cs.CL

TL;DR: 提出了Agent数据协议(ADP)，一种轻量级表示语言，作为异构格式代理数据集与统一训练管道之间的中间语言，解决了代理训练数据碎片化问题。


<details>
  <summary>Details</summary>
Motivation: 大规模监督微调AI代理的研究结果相对稀少，主要瓶颈在于数据分散在异构格式、工具和接口中，而非缺乏底层数据源。

Method: 设计ADP协议，能够表达多种任务类型(API/工具使用、浏览、编码、软件工程等)，同时保持简单易解析。将13个现有代理训练数据集统一转换为ADP格式，并转换为多个代理框架的训练就绪格式。

Result: 在这些数据上进行SFT，相比基础模型平均性能提升约20%，在标准编码、浏览、工具使用和研究基准测试中达到SOTA或接近SOTA性能，无需领域特定调优。

Conclusion: ADP有助于降低标准化、可扩展和可复现代理训练的门槛，所有代码和数据已公开。

Abstract: Public research results on large-scale supervised finetuning of AI agents
remain relatively rare, since the collection of agent training data presents
unique challenges. In this work, we argue that the bottleneck is not a lack of
underlying data sources, but that a large variety of data is fragmented across
heterogeneous formats, tools, and interfaces. To this end, we introduce the
agent data protocol (ADP), a light-weight representation language that serves
as an "interlingua" between agent datasets in diverse formats and unified agent
training pipelines downstream. The design of ADP is expressive enough to
capture a large variety of tasks, including API/tool use, browsing, coding,
software engineering, and general agentic workflows, while remaining simple to
parse and train on without engineering at a per-dataset level. In experiments,
we unified a broad collection of 13 existing agent training datasets into ADP
format, and converted the standardized ADP data into training-ready formats for
multiple agent frameworks. We performed SFT on these data, and demonstrated an
average performance gain of ~20% over corresponding base models, and delivers
state-of-the-art or near-SOTA performance on standard coding, browsing, tool
use, and research benchmarks, without domain-specific tuning. All code and data
are released publicly, in the hope that ADP could help lower the barrier to
standardized, scalable, and reproducible agent training.

</details>


### [83] [ComboBench: Can LLMs Manipulate Physical Devices to Play Virtual Reality Games?](https://arxiv.org/abs/2510.24706)
*Shuqing Li,Jiayi Yan,Chenyu Niu,Jen-tse Huang,Yun Peng,Wenxuan Wang,Yepang Liu,Michael R. Lyu*

Main category: cs.CL

TL;DR: ComboBench是一个评估大型语言模型将语义动作转换为VR设备操作序列能力的基准测试，涵盖4个流行VR游戏的262个场景。结果表明顶级模型在任务分解方面表现良好，但在程序推理和空间理解方面仍落后于人类。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型是否能够像人类一样基于常识和具身理解，将高级语义动作准确转换为VR设备的具体操作序列。

Method: 创建ComboBench基准测试，在Half-Life: Alyx、Into the Radius、Moss: Book II和Vivecraft四个VR游戏的262个场景中，评估7个LLM将语义动作转换为设备操作序列的能力，并与人工标注和人类表现对比。

Result: Gemini-1.5-Pro等顶级模型在任务分解方面表现出色，但在程序推理和空间理解上仍不及人类。不同游戏间性能差异显著，表明对交互复杂度的敏感性。少样本学习能显著提升性能。

Conclusion: LLM在VR操作转换方面有潜力，但在程序推理和空间理解方面仍需改进。少样本学习是提升性能的有效方法，为针对性增强LLM的VR操作能力提供了方向。

Abstract: Virtual Reality (VR) games require players to translate high-level semantic
actions into precise device manipulations using controllers and head-mounted
displays (HMDs). While humans intuitively perform this translation based on
common sense and embodied understanding, whether Large Language Models (LLMs)
can effectively replicate this ability remains underexplored. This paper
introduces a benchmark, ComboBench, evaluating LLMs' capability to translate
semantic actions into VR device manipulation sequences across 262 scenarios
from four popular VR games: Half-Life: Alyx, Into the Radius, Moss: Book II,
and Vivecraft. We evaluate seven LLMs, including GPT-3.5, GPT-4, GPT-4o,
Gemini-1.5-Pro, LLaMA-3-8B, Mixtral-8x7B, and GLM-4-Flash, compared against
annotated ground truth and human performance. Our results reveal that while
top-performing models like Gemini-1.5-Pro demonstrate strong task decomposition
capabilities, they still struggle with procedural reasoning and spatial
understanding compared to humans. Performance varies significantly across
games, suggesting sensitivity to interaction complexity. Few-shot examples
substantially improve performance, indicating potential for targeted
enhancement of LLMs' VR manipulation capabilities. We release all materials at
https://sites.google.com/view/combobench.

</details>


### [84] [MetricX-25 and GemSpanEval: Google Translate Submissions to the WMT25 Evaluation Shared Task](https://arxiv.org/abs/2510.24707)
*Juraj Juraska,Tobias Domhan,Mara Finkelstein,Tetsuji Nakagawa,Geza Kovacs,Daniel Deutsch,Pidong Wang,Markus Freitag*

Main category: cs.CL

TL;DR: 提出了MetricX-25和GemSpanEval两个模型，分别用于WMT25翻译评估共享任务的质量分数预测和错误跨度检测子任务，均基于Gemma 3模型微调。


<details>
  <summary>Details</summary>
Motivation: 改进WMT翻译评估任务的性能，为质量分数预测和错误跨度检测两个子任务分别开发更有效的模型。

Method: MetricX-25采用编码器架构加回归头预测MQM和ESA质量分数；GemSpanEval采用解码器架构，将错误跨度检测作为生成任务，输出错误跨度及其严重程度、类别和上下文。

Result: MetricX-25显著超越其前身模型；GemSpanEval在错误跨度检测上与强基线xCOMET具有竞争力。

Conclusion: 基于Gemma 3的两种不同架构模型在翻译评估任务中均表现出色，证明了该方法的有效性。

Abstract: In this paper, we present our submissions to the unified WMT25 Translation
Evaluation Shared Task. For the Quality Score Prediction subtask, we create a
new generation of MetricX with improvements in the input format and the
training protocol, while for the Error Span Detection subtask we develop a new
model, GemSpanEval, trained to predict error spans along with their severities
and categories. Both systems are based on the state-of-the-art multilingual
open-weights model Gemma 3, fine-tuned on publicly available WMT data. We
demonstrate that MetricX-25, adapting Gemma 3 to an encoder-only architecture
with a regression head on top, can be trained to effectively predict both MQM
and ESA quality scores, and significantly outperforms its predecessor. Our
decoder-only GemSpanEval model, on the other hand, we show to be competitive in
error span detection with xCOMET, a strong encoder-only sequence-tagging
baseline. With error span detection formulated as a generative task, we
instruct the model to also output the context for each predicted error span,
thus ensuring that error spans are identified unambiguously.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [85] [emg2speech: synthesizing speech from electromyography using self-supervised speech models](https://arxiv.org/abs/2510.23969)
*Harshavardhana T. Gowda,Lee M. Miller*

Main category: cs.SD

TL;DR: 该论文提出了一种神经肌肉语音接口，通过将口面部肌肉的肌电信号直接映射到自监督语音特征空间来合成语音，实现了端到端的EMG到语音生成。


<details>
  <summary>Details</summary>
Motivation: 探索自监督语音表示与肌电信号之间的线性关系，利用这种关系构建无需显式发音模型和声码器训练的语音生成系统。

Method: 通过线性映射将肌电信号功率与自监督语音特征关联，利用不同发音手势在特征空间中的聚类特性，直接实现EMG到语音特征的映射和语音合成。

Result: 发现自监督语音特征与肌电信号功率之间存在强线性关系（r=0.85），不同发音手势在特征空间中形成可分离的聚类，成功实现了端到端的EMG到语音生成。

Conclusion: 自监督语音模型隐式编码了发音机制，这种特性可以用于构建高效的神经肌肉语音接口，为语音障碍患者提供新的沟通解决方案。

Abstract: We present a neuromuscular speech interface that translates electromyographic
(EMG) signals collected from orofacial muscles during speech articulation
directly into audio. We show that self-supervised speech (SS) representations
exhibit a strong linear relationship with the electrical power of muscle action
potentials: SS features can be linearly mapped to EMG power with a correlation
of $r = 0.85$. Moreover, EMG power vectors corresponding to different
articulatory gestures form structured and separable clusters in feature space.
This relationship: $\text{SS features}$ $\xrightarrow{\texttt{linear mapping}}$
$\text{EMG power}$ $\xrightarrow{\texttt{gesture-specific clustering}}$
$\text{articulatory movements}$, highlights that SS models implicitly encode
articulatory mechanisms. Leveraging this property, we directly map EMG signals
to SS feature space and synthesize speech, enabling end-to-end EMG-to-speech
generation without explicit articulatory models and vocoder training.

</details>


### [86] [STAR-Bench: Probing Deep Spatio-Temporal Reasoning as Audio 4D Intelligence](https://arxiv.org/abs/2510.24693)
*Zihan Liu,Zhikang Niu,Qiuyang Xiao,Zhisheng Zheng,Ruoqi Yuan,Yuhang Zang,Yuhang Cao,Xiaoyi Dong,Jianze Liang,Xie Chen,Leilei Sun,Dahua Lin,Jiaqi Wang*

Main category: cs.SD

TL;DR: STAR-Bench是一个新的音频基准测试，专注于测量音频4D智能——在时间和3D空间中推理声音动态的能力，相比现有基准更能揭示模型在细粒度感知推理上的缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型和音频-语言模型基准主要测试可从文本描述中恢复的语义，掩盖了模型在细粒度感知推理方面的不足。需要一个新的基准来评估模型对声音在时间和空间中动态变化的推理能力。

Method: STAR-Bench结合基础声学感知设置（六个属性在绝对和相对机制下）和整体时空推理设置（包括连续和离散过程的片段重排序，以及静态定位、多源关系和动态轨迹的空间任务）。数据收集使用程序合成和物理模拟音频，以及包含人工标注的四阶段流程。

Result: 评估19个模型显示，相比人类存在显著差距，并揭示了能力层次：闭源模型受限于细粒度感知，而开源模型在感知、知识和推理方面都落后。相比之前基准仅轻微降低准确率，STAR-Bench导致更大的性能下降（时间任务-31.5%，空间任务-35.2%）。

Conclusion: STAR-Bench提供了关键见解，为开发具有更强大物理世界理解能力的未来模型指明了清晰路径，证明其专注于语言难以描述的音频线索。

Abstract: Despite rapid progress in Multi-modal Large Language Models and Large
Audio-Language Models, existing audio benchmarks largely test semantics that
can be recovered from text captions, masking deficits in fine-grained
perceptual reasoning. We formalize audio 4D intelligence that is defined as
reasoning over sound dynamics in time and 3D space, and introduce STAR-Bench to
measure it. STAR-Bench combines a Foundational Acoustic Perception setting (six
attributes under absolute and relative regimes) with a Holistic Spatio-Temporal
Reasoning setting that includes segment reordering for continuous and discrete
processes and spatial tasks spanning static localization, multi-source
relations, and dynamic trajectories. Our data curation pipeline uses two
methods to ensure high-quality samples. For foundational tasks, we use
procedurally synthesized and physics-simulated audio. For holistic data, we
follow a four-stage process that includes human annotation and final selection
based on human performance. Unlike prior benchmarks where caption-only
answering reduces accuracy slightly, STAR-Bench induces far larger drops
(-31.5\% temporal, -35.2\% spatial), evidencing its focus on linguistically
hard-to-describe cues. Evaluating 19 models reveals substantial gaps compared
with humans and a capability hierarchy: closed-source models are bottlenecked
by fine-grained perception, while open-source models lag across perception,
knowledge, and reasoning. Our STAR-Bench provides critical insights and a clear
path forward for developing future models with a more robust understanding of
the physical world.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [87] [Latent Chain-of-Thought for Visual Reasoning](https://arxiv.org/abs/2510.23925)
*Guohao Sun,Hang Hua,Jian Wang,Jiebo Luo,Sohail Dianat,Majid Rabbani,Raghuveer Rao,Zhiqiang Tao*

Main category: cs.AI

TL;DR: 提出了一种基于变分推理的链式思维训练方法，通过稀疏奖励函数和贝叶斯推理扩展策略，提升大型视觉语言模型的推理能力、泛化性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有训练方法（SFT、PPO、GRPO）在未见推理任务上泛化能力不足，且过度依赖有偏见的奖励模型，限制了链式思维推理的发展。

Method: 将LVLMs推理重新表述为后验推理，采用摊销变分推理的扩展训练算法，使用多样性强化学习的稀疏奖励函数，并实施贝叶斯推理扩展策略替代昂贵的搜索方法。

Result: 在七个推理基准测试中，该方法在有效性、泛化性和可解释性方面提升了最先进的LVLMs性能。

Conclusion: 提出的变分推理训练框架成功解决了现有方法的局限性，为链式思维推理提供了更可靠和可扩展的解决方案。

Abstract: Chain-of-thought (CoT) reasoning is critical for improving the
interpretability and reliability of Large Vision-Language Models (LVLMs).
However, existing training algorithms such as SFT, PPO, and GRPO may not
generalize well across unseen reasoning tasks and heavily rely on a biased
reward model. To address this challenge, we reformulate reasoning in LVLMs as
posterior inference and propose a scalable training algorithm based on
amortized variational inference. By leveraging diversity-seeking reinforcement
learning algorithms, we introduce a novel sparse reward function for
token-level learning signals that encourage diverse, high-likelihood latent
CoT, overcoming deterministic sampling limitations and avoiding reward hacking.
Additionally, we implement a Bayesian inference-scaling strategy that replaces
costly Best-of-N and Beam Search with a marginal likelihood to efficiently rank
optimal rationales and answers. We empirically demonstrate that the proposed
method enhances the state-of-the-art LVLMs on seven reasoning benchmarks, in
terms of effectiveness, generalization, and interpretability.

</details>


### [88] [OS-Sentinel: Towards Safety-Enhanced Mobile GUI Agents via Hybrid Validation in Realistic Workflows](https://arxiv.org/abs/2510.24411)
*Qiushi Sun,Mukai Li,Zhoumianze Liu,Zhihui Xie,Fangzhi Xu,Zhangyue Yin,Kanzhi Cheng,Zehao Li,Zichen Ding,Qi Liu,Zhiyong Wu,Zhuosheng Zhang,Ben Kao,Lingpeng Kong*

Main category: cs.AI

TL;DR: 提出了MobileRisk-Live动态沙盒环境和OS-Sentinel混合安全检测框架，用于检测移动代理在数字环境中的安全风险，相比现有方法提升10%-30%性能。


<details>
  <summary>Details</summary>
Motivation: 基于视觉语言模型的计算机代理在移动平台等数字环境中展现出类人能力，但其潜在的不安全操作（如系统破坏和隐私泄露）引发严重担忧，而现有研究对此关注不足。

Method: 构建MobileRisk-Live动态沙盒环境和安全检测基准，提出OS-Sentinel混合框架，结合形式验证器检测系统级违规和基于VLM的上下文判断器评估上下文风险和代理行为。

Result: 实验表明OS-Sentinel在多个指标上比现有方法提升10%-30%性能，为开发更安全可靠的自主移动代理提供了关键见解。

Conclusion: 该研究为移动代理安全研究奠定了基础，提出的混合检测框架能有效识别安全风险，促进更安全可靠的自主移动代理发展。

Abstract: Computer-using agents powered by Vision-Language Models (VLMs) have
demonstrated human-like capabilities in operating digital environments like
mobile platforms. While these agents hold great promise for advancing digital
automation, their potential for unsafe operations, such as system compromise
and privacy leakage, is raising significant concerns. Detecting these safety
concerns across the vast and complex operational space of mobile environments
presents a formidable challenge that remains critically underexplored. To
establish a foundation for mobile agent safety research, we introduce
MobileRisk-Live, a dynamic sandbox environment accompanied by a safety
detection benchmark comprising realistic trajectories with fine-grained
annotations. Built upon this, we propose OS-Sentinel, a novel hybrid safety
detection framework that synergistically combines a Formal Verifier for
detecting explicit system-level violations with a VLM-based Contextual Judge
for assessing contextual risks and agent actions. Experiments show that
OS-Sentinel achieves 10%-30% improvements over existing approaches across
multiple metrics. Further analysis provides critical insights that foster the
development of safer and more reliable autonomous mobile agents.

</details>


### [89] [Law in Silico: Simulating Legal Society with LLM-Based Agents](https://arxiv.org/abs/2510.24442)
*Yiding Wang,Yuxuan Chen,Fanxu Meng,Xifan Chen,Xiaolei Yang,Muhan Zhang*

Main category: cs.AI

TL;DR: Law in Silico是一个基于大语言模型的法律社会模拟框架，通过AI代理模拟个体决策和立法、裁决、执法等制度机制，验证法律理论并支持法律管理。


<details>
  <summary>Details</summary>
Motivation: 由于现实世界中的法律实验成本高昂或不可行，需要一种有效的替代方法来验证和发展法律理论。大语言模型具备世界知识和角色扮演能力，是构建法律社会模拟的理想基础。

Method: 开发了Law in Silico框架，使用基于LLM的代理来模拟法律场景，包括个体决策和制度机制（立法、裁决、执法）。通过比较模拟犯罪率与现实世界数据进行实验验证。

Result: 实验表明，基于LLM的代理能够很大程度上复现宏观层面的犯罪趋势，并提供与现实观察一致的见解。微观模拟显示，功能良好、透明且适应性的法律系统能更好地保护弱势个体的权利。

Conclusion: LLM-based agents can effectively simulate legal systems, reproducing macro-level crime trends and providing insights that align with real-world observations, while also demonstrating the importance of well-functioning legal systems for protecting vulnerable individuals.

Abstract: Since real-world legal experiments are often costly or infeasible, simulating
legal societies with Artificial Intelligence (AI) systems provides an effective
alternative for verifying and developing legal theory, as well as supporting
legal administration. Large Language Models (LLMs), with their world knowledge
and role-playing capabilities, are strong candidates to serve as the foundation
for legal society simulation. However, the application of LLMs to simulate
legal systems remains underexplored. In this work, we introduce Law in Silico,
an LLM-based agent framework for simulating legal scenarios with individual
decision-making and institutional mechanisms of legislation, adjudication, and
enforcement. Our experiments, which compare simulated crime rates with
real-world data, demonstrate that LLM-based agents can largely reproduce
macro-level crime trends and provide insights that align with real-world
observations. At the same time, micro-level simulations reveal that a
well-functioning, transparent, and adaptive legal system offers better
protection of the rights of vulnerable individuals.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [90] [VC4VG: Optimizing Video Captions for Text-to-Video Generation](https://arxiv.org/abs/2510.24134)
*Yang Du,Zhuoran Lin,Kaiqiang Song,Biao Wang,Zhicheng Zheng,Tiezheng Ge,Bo Zheng,Qin Jin*

Main category: cs.CV

TL;DR: VC4VG是一个专门为文本到视频生成优化的视频字幕框架，通过分析视频重建所需的多维度要素来改进字幕质量，并建立了专门的评估基准。


<details>
  <summary>Details</summary>
Motivation: 当前文本到视频生成领域缺乏专门针对训练优化的视频字幕策略，高质量的视频-文本对对于生成连贯且符合指令的视频至关重要。

Method: 从T2V角度分析字幕内容，将视频重建所需要素分解为多个维度，提出原则性的字幕设计方法，并构建VC4VG-Bench评估基准。

Result: 广泛的T2V微调实验显示字幕质量改进与视频生成性能之间存在强相关性，验证了方法的有效性。

Conclusion: VC4VG框架通过优化视频字幕显著提升了文本到视频生成性能，为相关研究提供了有效的工具和基准。

Abstract: Recent advances in text-to-video (T2V) generation highlight the critical role
of high-quality video-text pairs in training models capable of producing
coherent and instruction-aligned videos. However, strategies for optimizing
video captions specifically for T2V training remain underexplored. In this
paper, we introduce VC4VG (Video Captioning for Video Generation), a
comprehensive caption optimization framework tailored to the needs of T2V
models.We begin by analyzing caption content from a T2V perspective,
decomposing the essential elements required for video reconstruction into
multiple dimensions, and proposing a principled caption design methodology. To
support evaluation, we construct VC4VG-Bench, a new benchmark featuring
fine-grained, multi-dimensional, and necessity-graded metrics aligned with
T2V-specific requirements.Extensive T2V fine-tuning experiments demonstrate a
strong correlation between improved caption quality and video generation
performance, validating the effectiveness of our approach. We release all
benchmark tools and code at https://github.com/qyr0403/VC4VG to support further
research.

</details>


### [91] [ViPER: Empowering the Self-Evolution of Visual Perception Abilities in Vision-Language Model](https://arxiv.org/abs/2510.24285)
*Juntian Zhang,Song Jin,Chuanqi Cheng,Yuhan Liu,Yankai Lin,Xun Zhang,Yufei Zhang,Fei Jiang,Guojun Yin,Wei Lin,Rui Yan*

Main category: cs.CV

TL;DR: 提出了ViPER框架，通过自举式训练方法解决视觉语言模型在细粒度视觉感知方面的瓶颈，实现了从粗到细的渐进式视觉感知学习。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在细粒度视觉感知方面存在能力限制，现有方法如监督微调会损害通用能力，而强化微调则过度关注文本推理而忽视视觉感知。

Method: 采用两阶段任务设计，将视觉感知学习构建为从粗到细的渐进过程，结合图像级和实例级重构，使用两阶段强化学习策略建立闭环训练范式。

Result: 在Qwen2.5-VL模型上应用ViPER产生Qwen-Viper系列，在7个综合基准测试中平均提升1.7%，细粒度感知任务上最高提升6.0%。

Conclusion: ViPER不仅实现了感知能力的自我提升，还证明了生成与理解之间的互惠关系，为开发更自主、更强大的视觉语言模型提供了突破。

Abstract: The limited capacity for fine-grained visual perception presents a critical
bottleneck for Vision-Language Models (VLMs) in real-world applications.
Addressing this is challenging due to the scarcity of high-quality data and the
limitations of existing methods: supervised fine-tuning (SFT) often compromises
general capabilities, while reinforcement fine-tuning (RFT) prioritizes textual
reasoning over visual perception. To bridge this gap, we propose a novel
two-stage task that structures visual perception learning as a coarse-to-fine
progressive process. Based on this task formulation, we develop ViPER, a
self-bootstrapping framework specifically designed to enable iterative
evolution through self-critiquing and self-prediction. By synergistically
integrating image-level and instance-level reconstruction with a two-stage
reinforcement learning strategy, ViPER establishes a closed-loop training
paradigm, where internally synthesized data directly fuel the enhancement of
perceptual ability. Applied to the Qwen2.5-VL family, ViPER produces the
Qwen-Viper series. With an average gain of 1.7% on seven comprehensive
benchmarks spanning various tasks and up to 6.0% on fine-grained perception,
Qwen-Viper consistently demonstrates superior performance across different
vision-language scenarios while maintaining generalizability. Beyond enabling
self-improvement in perceptual capabilities, ViPER provides concrete evidence
for the reciprocal relationship between generation and understanding, a
breakthrough to developing more autonomous and capable VLMs.

</details>


### [92] [Latent Sketchpad: Sketching Visual Thoughts to Elicit Multimodal Reasoning in MLLMs](https://arxiv.org/abs/2510.24514)
*Huanyu Zhang,Wenshan Wu,Chengzu Li,Ning Shang,Yan Xia,Yangyu Huang,Yifan Zhang,Li Dong,Zhang Zhang,Liang Wang,Tieniu Tan,Furu Wei*

Main category: cs.CV

TL;DR: Latent Sketchpad为多模态大语言模型添加内部视觉草稿功能，通过生成视觉潜在表示来支持视觉思维，在保持推理能力的同时增强复杂场景下的视觉规划能力。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在视觉理解方面表现出色，但在需要视觉规划和想象的复杂场景中表现不佳。受人类使用草图进行视觉思维的启发，需要为模型提供内部视觉工作空间。

Method: 提出Latent Sketchpad框架，包含两个组件：上下文感知视觉头自回归生成视觉表示，预训练草图解码器将其渲染为可解释图像。该方法将视觉生成直接集成到模型的自回归推理过程中。

Result: 在MazePlanning数据集上的实验表明，Latent Sketchpad在推理性能上可与骨干模型相媲美甚至更优，并能泛化到不同的前沿MLLMs（如Gemma3和Qwen2.5-VL）。

Conclusion: 通过将模型的文本推理扩展到视觉思维，该框架为人机交互和更广泛的应用开辟了新机会。

Abstract: While Multimodal Large Language Models (MLLMs) excel at visual understanding,
they often struggle in complex scenarios that require visual planning and
imagination. Inspired by how humans use sketching as a form of visual thinking
to develop and communicate ideas, we introduce Latent Sketchpad, a framework
that equips MLLMs with an internal visual scratchpad. The internal visual
representations of MLLMs have traditionally been confined to perceptual
understanding. We repurpose them to support generative visual thought without
compromising reasoning ability. Building on frontier MLLMs, our approach
integrates visual generation directly into their native autoregressive
reasoning process. It allows the model to interleave textual reasoning with the
generation of visual latents. These latents guide the internal thought process
and can be translated into sketch images for interpretability. To realize this,
we introduce two components: a Context-Aware Vision Head autoregressively
produces visual representations, and a pretrained Sketch Decoder renders these
into human-interpretable images. We evaluate the framework on our new dataset
MazePlanning. Experiments across various MLLMs show that Latent Sketchpad
delivers comparable or even superior reasoning performance to their backbone.
It further generalizes across distinct frontier MLLMs, including Gemma3 and
Qwen2.5-VL. By extending model's textual reasoning to visual thinking, our
framework opens new opportunities for richer human-computer interaction and
broader applications. More details and resources are available on our project
page: https://latent-sketchpad.github.io/.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [93] [VisCoder2: Building Multi-Language Visualization Coding Agents](https://arxiv.org/abs/2510.23642)
*Yuansheng Ni,Songcheng Cai,Xiangchao Chen,Jiarong Liang,Zhiheng Lyu,Jiaqi Deng,Kai Zou,Ping Nie,Fei Yuan,Xiang Yue,Wenhu Chen*

Main category: cs.SE

TL;DR: 提出了VisCode-Multi-679K数据集、VisPlotBench基准测试和VisCoder2模型，用于改进可视化编码代理，解决了现有模型在语言覆盖、执行可靠性和迭代修正方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型在生成可视化代码时存在语言覆盖有限、执行不可靠、缺乏迭代修正机制等问题，且受限于窄数据集和基准测试。

Method: 构建了包含679K验证可执行可视化样本的多轮修正对话数据集，设计了包含可执行任务和渲染输出的基准测试，并训练了多语言可视化模型VisCoder2。

Result: VisCoder2显著优于开源基线模型，接近GPT-4.1性能，通过迭代自调试在32B规模达到82.4%总体执行通过率，在符号或编译器依赖语言中表现突出。

Conclusion: 提出的三个互补资源有效推进了可视化编码代理的发展，VisCoder2在多个语言中表现出色，迭代自调试进一步提升了性能。

Abstract: Large language models (LLMs) have recently enabled coding agents capable of
generating, executing, and revising visualization code. However, existing
models often fail in practical workflows due to limited language coverage,
unreliable execution, and lack of iterative correction mechanisms. Progress has
been constrained by narrow datasets and benchmarks that emphasize single-round
generation and single-language tasks. To address these challenges, we introduce
three complementary resources for advancing visualization coding agents.
VisCode-Multi-679K is a large-scale, supervised dataset containing 679K
validated and executable visualization samples with multi-turn correction
dialogues across 12 programming languages. VisPlotBench is a benchmark for
systematic evaluation, featuring executable tasks, rendered outputs, and
protocols for both initial generation and multi-round self-debug. Finally, we
present VisCoder2, a family of multi-language visualization models trained on
VisCode-Multi-679K. Experiments show that VisCoder2 significantly outperforms
strong open-source baselines and approaches the performance of proprietary
models like GPT-4.1, with further gains from iterative self-debug, reaching
82.4% overall execution pass rate at the 32B scale, particularly in symbolic or
compiler-dependent languages.

</details>


### [94] [Automatically Benchmarking LLM Code Agents through Agent-Driven Annotation and Evaluation](https://arxiv.org/abs/2510.24358)
*Lingyue Fu,Bolun Zhang,Hao Guan,Yaoming Zhu,Lin Qiu,Weiwen Liu,Xuezhi Cao,Xunliang Cai,Weinan Zhang,Yong Yu*

Main category: cs.SE

TL;DR: 提出了PRDBench基准测试，通过代理驱动的管道构建包含50个真实Python项目的基准，解决现有代码代理评估的高标注成本和僵化评估指标问题。


<details>
  <summary>Details</summary>
Motivation: 现有代码代理评估基准存在高标注成本、专业知识要求高，以及主要依赖单元测试的僵化评估指标等局限性。

Method: 采用代理驱动的基准构建管道，结合人工监督生成多样化项目级任务；引入Agent-as-a-Judge范式对代理输出评分，支持超越单元测试的多种测试类型评估。

Result: 构建了PRDBench基准，包含50个跨20个领域的真实Python项目，每个项目都有结构化产品需求文档、全面评估标准和参考实现。

Conclusion: PRDBench为代码代理和评估代理的能力评估提供了可扩展且稳健的框架，在广泛实验中证明了其有效性。

Abstract: Recent advances in code agents have enabled automated software development at
the project level, supported by large language models (LLMs) and widely adopted
tools. However, existing benchmarks for code agent evaluation face two major
limitations: high annotation cost and expertise requirements, and rigid
evaluation metrics that rely primarily on unit tests. To address these
challenges, we propose an agent-driven benchmark construction pipeline that
leverages human supervision to efficiently generate diverse and challenging
project-level tasks. Based on this approach, we introduce PRDBench, a novel
benchmark comprising 50 real-world Python projects across 20 domains, each with
structured Product Requirement Document (PRD) requirements, comprehensive
evaluation criteria, and reference implementations. PRDBench features rich data
sources, high task complexity, and flexible metrics. We further employ an
Agent-as-a-Judge paradigm to score agent outputs, enabling the evaluation of
various test types beyond unit tests. Extensive experiments on PRDBench
demonstrate its effectiveness in assessing the capabilities of both code agents
and evaluation agents, providing a scalable and robust framework for annotation
and evaluation.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [95] [RoboOmni: Proactive Robot Manipulation in Omni-modal Context](https://arxiv.org/abs/2510.23763)
*Siyin Wang,Jinlan Fu,Feihong Liu,Xinzhe He,Huangxuan Wu,Junhao Shi,Kexin Huang,Zhaoye Fei,Jingjing Gong,Zuxuan Wu,Yugang Jiang,See-Kiong Ng,Tat-Seng Chua,Xipeng Qiu*

Main category: cs.RO

TL;DR: 提出了RoboOmni框架，基于全模态大语言模型，通过融合听觉和视觉信号进行意图识别，支持直接语音交互，在机器人操作中实现主动意图推断。


<details>
  <summary>Details</summary>
Motivation: 当前机器人操作主要依赖显式指令，而真实世界中人类很少直接发出指令。需要机器人能够主动推断用户意图，实现更自然的协作。

Method: 提出RoboOmni框架，采用感知者-思考者-说话者-执行者架构，基于端到端全模态大语言模型，统一意图识别、交互确认和动作执行。时空融合听觉和视觉信号进行鲁棒意图识别。

Result: 在仿真和真实环境实验中，RoboOmni在成功率、推理速度、意图识别和主动协助方面均优于基于文本和ASR的基线方法。

Conclusion: RoboOmni框架能够有效处理跨模态上下文指令，实现主动意图识别和自然的人机协作，为机器人操作提供了新的解决方案。

Abstract: Recent advances in Multimodal Large Language Models (MLLMs) have driven rapid
progress in Vision-Language-Action (VLA) models for robotic manipulation.
Although effective in many scenarios, current approaches largely rely on
explicit instructions, whereas in real-world interactions, humans rarely issue
instructions directly. Effective collaboration requires robots to infer user
intentions proactively. In this work, we introduce cross-modal contextual
instructions, a new setting where intent is derived from spoken dialogue,
environmental sounds, and visual cues rather than explicit commands. To address
this new setting, we present RoboOmni, a Perceiver-Thinker-Talker-Executor
framework based on end-to-end omni-modal LLMs that unifies intention
recognition, interaction confirmation, and action execution. RoboOmni fuses
auditory and visual signals spatiotemporally for robust intention recognition,
while supporting direct speech interaction. To address the absence of training
data for proactive intention recognition in robotic manipulation, we build
OmniAction, comprising 140k episodes, 5k+ speakers, 2.4k event sounds, 640
backgrounds, and six contextual instruction types. Experiments in simulation
and real-world settings show that RoboOmni surpasses text- and ASR-based
baselines in success rate, inference speed, intention recognition, and
proactive assistance.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [96] [A Neural Model for Contextual Biasing Score Learning and Filtering](https://arxiv.org/abs/2510.23849)
*Wanting Huang,Weiran Wang*

Main category: eess.AS

TL;DR: 提出了一种基于注意力机制的上下文偏置方法，通过判别性目标函数提升ASR性能，能有效过滤候选短语并在浅层融合偏置中显著改善识别准确率。


<details>
  <summary>Details</summary>
Motivation: 上下文偏置通过整合外部知识（如用户特定短语或实体）来改进自动语音识别，但需要更有效的方法来筛选候选短语并提升偏置效果。

Method: 使用基于注意力的偏置解码器从ASR编码器提取声学信息，为候选短语生成分数，引入每个token的判别性目标函数，鼓励对真实短语给出更高分数同时抑制干扰项。

Result: 在Librispeech偏置基准测试中，该方法能有效过滤大部分候选短语，在不同偏置条件下使用浅层融合偏置时显著提高了识别准确率。

Conclusion: 该方法具有模块化特性，可与任何ASR系统配合使用，其过滤机制还有潜力提升其他偏置方法的性能。

Abstract: Contextual biasing improves automatic speech recognition (ASR) by integrating
external knowledge, such as user-specific phrases or entities, during decoding.
In this work, we use an attention-based biasing decoder to produce scores for
candidate phrases based on acoustic information extracted by an ASR encoder,
which can be used to filter out unlikely phrases and to calculate bonus for
shallow-fusion biasing. We introduce a per-token discriminative objective that
encourages higher scores for ground-truth phrases while suppressing
distractors. Experiments on the Librispeech biasing benchmark show that our
method effectively filters out majority of the candidate phrases, and
significantly improves recognition accuracy under different biasing conditions
when the scores are used in shallow fusion biasing. Our approach is modular and
can be used with any ASR system, and the filtering mechanism can potentially
boost performance of other biasing methods.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [97] [An Enhanced Dual Transformer Contrastive Network for Multimodal Sentiment Analysis](https://arxiv.org/abs/2510.23617)
*Phuong Q. Dao,Mark Roantree,Vuong M. Ngo*

Main category: cs.LG

TL;DR: 提出BERT-ViT-EF模型和其扩展DTCN，通过早期融合策略和对比学习在多模态情感分析中实现更好的性能


<details>
  <summary>Details</summary>
Motivation: 多模态情感分析通过联合分析文本和图像数据，比单模态方法能提供更丰富和准确的情感理解

Method: BERT-ViT-EF结合BERT和ViT编码器进行早期融合；DTCN在BERT后添加额外Transformer层，并使用对比学习对齐文本和图像表示

Result: 在TumEmo数据集上达到78.4%准确率和78.3% F1分数，在MVSA-Single上达到76.6%准确率和75.9% F1分数

Conclusion: 早期融合和更深层次的上下文建模在基于Transformer的多模态情感分析中具有显著优势

Abstract: Multimodal Sentiment Analysis (MSA) seeks to understand human emotions by
jointly analyzing data from multiple modalities typically text and images
offering a richer and more accurate interpretation than unimodal approaches. In
this paper, we first propose BERT-ViT-EF, a novel model that combines powerful
Transformer-based encoders BERT for textual input and ViT for visual input
through an early fusion strategy. This approach facilitates deeper cross-modal
interactions and more effective joint representation learning. To further
enhance the model's capability, we propose an extension called the Dual
Transformer Contrastive Network (DTCN), which builds upon BERT-ViT-EF. DTCN
incorporates an additional Transformer encoder layer after BERT to refine
textual context (before fusion) and employs contrastive learning to align text
and image representations, fostering robust multimodal feature learning.
Empirical results on two widely used MSA benchmarks MVSA-Single and TumEmo
demonstrate the effectiveness of our approach. DTCN achieves best accuracy
(78.4%) and F1-score (78.3%) on TumEmo, and delivers competitive performance on
MVSA-Single, with 76.6% accuracy and 75.9% F1-score. These improvements
highlight the benefits of early fusion and deeper contextual modeling in
Transformer-based multimodal sentiment analysis.

</details>


### [98] [From Detection to Discovery: A Closed-Loop Approach for Simultaneous and Continuous Medical Knowledge Expansion and Depression Detection on Social Media](https://arxiv.org/abs/2510.23626)
*Shuang Geng,Wenli Zhang,Jiaheng Xie,Rui Wang,Sudha Ram*

Main category: cs.LG

TL;DR: 提出一个闭环LLM-知识图谱框架，将抑郁症预测与知识扩展结合在迭代学习循环中，通过社交媒体内容同时提升预测准确性和医学知识发现。


<details>
  <summary>Details</summary>
Motivation: 现有研究仅利用医学知识改进预测准确性，但忽略了通过预测过程同时扩展医学知识的机会。需要实现预测与知识扩展的相互促进。

Method: 开发闭环LLM-知识图谱框架：1)知识感知抑郁症检测阶段：LLM联合执行抑郁症检测和实体提取，知识图谱表示和加权实体以优化预测；2)知识精炼扩展阶段：在专家监督下将LLM提取的新实体、关系和类型纳入知识图谱。

Result: 使用大规模用户生成内容，该框架同时提升了预测准确性和医学理解。专家评估确认发现了与现有文献互补的临床有意义症状、共病和社会触发因素。

Conclusion: 概念化和实现了预测-学习和学习-预测作为相互促进的过程，推进了预测分析的方法论和理论理解。该框架展示了计算模型和领域知识的共同演化，为其他动态风险监测环境提供了自适应、数据驱动的知识系统基础。

Abstract: Social media user-generated content (UGC) provides real-time, self-reported
indicators of mental health conditions such as depression, offering a valuable
source for predictive analytics. While prior studies integrate medical
knowledge to improve prediction accuracy, they overlook the opportunity to
simultaneously expand such knowledge through predictive processes. We develop a
Closed-Loop Large Language Model (LLM)-Knowledge Graph framework that
integrates prediction and knowledge expansion in an iterative learning cycle.
In the knowledge-aware depression detection phase, the LLM jointly performs
depression detection and entity extraction, while the knowledge graph
represents and weights these entities to refine prediction performance. In the
knowledge refinement and expansion phase, new entities, relationships, and
entity types extracted by the LLM are incorporated into the knowledge graph
under expert supervision, enabling continual knowledge evolution. Using
large-scale UGC, the framework enhances both predictive accuracy and medical
understanding. Expert evaluations confirmed the discovery of clinically
meaningful symptoms, comorbidities, and social triggers complementary to
existing literature. We conceptualize and operationalize
prediction-through-learning and learning-through-prediction as mutually
reinforcing processes, advancing both methodological and theoretical
understanding in predictive analytics. The framework demonstrates the
co-evolution of computational models and domain knowledge, offering a
foundation for adaptive, data-driven knowledge systems applicable to other
dynamic risk monitoring contexts.

</details>


### [99] [NUM2EVENT: Interpretable Event Reasoning from Numerical time-series](https://arxiv.org/abs/2510.23630)
*Ninghui Feng,Yiyan Qi*

Main category: cs.LG

TL;DR: 提出数字到事件推理任务，通过推理感知框架从数值时间序列中推断可解释的结构化事件，解决现有方法无法揭示驱动数值变化的潜在事件的问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在多模态推理方面表现出色，但对纯数值时间序列信号的理解有限。现有方法主要关注预测或趋势描述，未能揭示驱动数值变化的潜在事件或解释其推理过程。

Method: 提出推理感知框架，包含代理引导的事件提取器(AGE)、基于标记多元霍克斯过程的合成生成器(EveDTS)，以及结合时间序列编码器和结构化解码器的两阶段微调流程。模型显式推理数值变化，生成中间解释，输出结构化事件假设。

Result: 在多领域数据集上的实验表明，该方法在事件级精确率和召回率方面显著优于强大的LLM基线。

Conclusion: 这项工作为桥接定量推理和语义理解开辟了新方向，使LLM能够直接从数值动态中解释和预测事件。

Abstract: Large language models (LLMs) have recently demonstrated impressive multimodal
reasoning capabilities, yet their understanding of purely numerical time-series
signals remains limited. Existing approaches mainly focus on forecasting or
trend description, without uncovering the latent events that drive numerical
changes or explaining the reasoning process behind them. In this work, we
introduce the task of number-to-event reasoning and decoding, which aims to
infer interpretable structured events from numerical inputs, even when current
text is unavailable. To address the data scarcity and semantic alignment
challenges, we propose a reasoning-aware framework that integrates an
agent-guided event extractor (AGE), a marked multivariate Hawkes-based
synthetic generator (EveDTS), and a two-stage fine-tuning pipeline combining a
time-series encoder with a structured decoder. Our model explicitly reasons
over numerical changes, generates intermediate explanations, and outputs
structured event hypotheses. Experiments on multi-domain datasets show that our
method substantially outperforms strong LLM baselines in event-level precision
and recall. These results suggest a new direction for bridging quantitative
reasoning and semantic understanding, enabling LLMs to explain and predict
events directly from numerical dynamics.

</details>


### [100] [Flight Delay Prediction via Cross-Modality Adaptation of Large Language Models and Aircraft Trajectory Representation](https://arxiv.org/abs/2510.23636)
*Thaweerath Phisannupawong,Joshua Julian Damanik,Han-Lim Choi*

Main category: cs.LG

TL;DR: 提出了一种基于轻量级大语言模型的多模态航班延误预测方法，从空管人员监控终端区飞机延误的角度出发，整合轨迹表示与文本航空信息。


<details>
  <summary>Details</summary>
Motivation: 航班延误预测已成为空中交通管理的关键焦点，延误突显了影响整体网络效率的问题。

Method: 将轨迹数据适配到语言模态中，整合飞行信息、天气报告和机场通告等文本航空信息，通过跨模态适配捕获空域状况。

Result: 实验结果显示模型通过有效利用与延误来源相关的上下文信息，持续实现亚分钟级预测误差。

Conclusion: 该框架证明语言理解与轨迹信息的跨模态适配相结合可增强延误预测，方法具有实用性和可扩展性，支持实时更新以优化预测。

Abstract: Flight delay prediction has become a key focus in air traffic management, as
delays highlight inefficiencies that impact overall network performance. This
paper presents a lightweight large language model-based multimodal flight delay
prediction, formulated from the perspective of air traffic controllers
monitoring aircraft delay after entering the terminal area. The approach
integrates trajectory representations with textual aeronautical information,
including flight information, weather reports, and aerodrome notices, by
adapting trajectory data into the language modality to capture airspace
conditions. Experimental results show that the model consistently achieves
sub-minute prediction error by effectively leveraging contextual information
related to the sources of delay. The framework demonstrates that linguistic
understanding, when combined with cross-modality adaptation of trajectory
information, enhances delay prediction. Moreover, the approach shows
practicality and scalability for real-world operations, supporting real-time
updates that refine predictions upon receiving new operational information.

</details>


### [101] [Combining Textual and Structural Information for Premise Selection in Lean](https://arxiv.org/abs/2510.23637)
*Job Petrovčič,David Eliecer Narvaez Denis,Ljupčo Todorovski*

Main category: cs.LG

TL;DR: 提出了一种图增强方法，将Lean形式化的密集文本嵌入与图神经网络相结合，在异构依赖图上进行前提选择，相比纯语言方法提升超过25%。


<details>
  <summary>Details</summary>
Motivation: 现有基于语言的方法通常孤立处理前提，忽略了连接前提的依赖关系网络，这是扩展定理证明在大型形式库中的关键瓶颈。

Method: 结合Lean形式化的密集文本嵌入与图神经网络，在捕获状态-前提和前提-前提关系的异构依赖图上进行建模。

Result: 在LeanDojo基准测试中，该方法在标准检索指标上比ReProver语言基线提升了超过25%。

Conclusion: 关系信息对于更有效的前提选择具有强大作用。

Abstract: Premise selection is a key bottleneck for scaling theorem proving in large
formal libraries. Yet existing language-based methods often treat premises in
isolation, ignoring the web of dependencies that connects them. We present a
graph-augmented approach that combines dense text embeddings of Lean
formalizations with graph neural networks over a heterogeneous dependency graph
capturing both state--premise and premise--premise relations. On the LeanDojo
Benchmark, our method outperforms the ReProver language-based baseline by over
25% across standard retrieval metrics. These results demonstrate the power of
relational information for more effective premise selection.

</details>


### [102] [MUStReason: A Benchmark for Diagnosing Pragmatic Reasoning in Video-LMs for Multimodal Sarcasm Detection](https://arxiv.org/abs/2510.23727)
*Anisha Saha,Varsha Suresh,Timothy Hospedales,Vera Demberg*

Main category: cs.LG

TL;DR: 提出了MUStReason诊断基准和PragCoT框架，用于评估和改进视频语言模型在讽刺检测任务中的表现，重点关注多模态线索感知和语用推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前多模态模型在讽刺检测等复杂任务上表现不佳，这些任务需要跨模态识别相关线索并进行语用推理来推断说话者意图。

Method: 引入MUStReason诊断基准，包含模态特定相关线索和推理步骤标注；提出PragCoT框架，引导视频语言模型关注隐含意图而非字面意义。

Result: 通过MUStReason对视频语言模型进行定量和定性评估，将问题分解为感知和推理两个层面进行分析。

Conclusion: PragCoT框架能够有效提升视频语言模型在讽刺检测任务中的表现，通过关注语用推理来更好地理解说话者的真实意图。

Abstract: Sarcasm is a specific type of irony which involves discerning what is said
from what is meant. Detecting sarcasm depends not only on the literal content
of an utterance but also on non-verbal cues such as speaker's tonality, facial
expressions and conversational context. However, current multimodal models
struggle with complex tasks like sarcasm detection, which require identifying
relevant cues across modalities and pragmatically reasoning over them to infer
the speaker's intention. To explore these limitations in VideoLMs, we introduce
MUStReason, a diagnostic benchmark enriched with annotations of
modality-specific relevant cues and underlying reasoning steps to identify
sarcastic intent. In addition to benchmarking sarcasm classification
performance in VideoLMs, using MUStReason we quantitatively and qualitatively
evaluate the generated reasoning by disentangling the problem into perception
and reasoning, we propose PragCoT, a framework that steers VideoLMs to focus on
implied intentions over literal meaning, a property core to detecting sarcasm.

</details>


### [103] [GIFT: Group-relative Implicit Fine Tuning Integrates GRPO with DPO and UNA](https://arxiv.org/abs/2510.23868)
*Zhichao Wang*

Main category: cs.LG

TL;DR: GIFT是一种新的强化学习框架，通过最小化隐式和显式奖励模型之间的差异来对齐LLMs，将复杂的奖励最大化问题转化为简单的MSE损失问题。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法如PPO、GRPO、DPO和UNA在LLM对齐中的局限性，包括离线方法缺乏探索能力、收敛速度慢、超参数多和训练过拟合等问题。

Method: 结合GRPO的多响应生成和归一化、DPO的隐式奖励公式以及UNA的隐式-显式奖励对齐原则，通过联合归一化隐式和显式奖励，将非凸优化问题转化为凸的MSE损失。

Result: GIFT在数学基准测试中实现了优越的推理和对齐性能，同时保持计算效率，收敛更快，泛化更好，训练过拟合显著减少。

Conclusion: GIFT提供了一个稳定、高效且易于优化的LLM对齐框架，在保持在线策略探索能力的同时，优于现有方法。

Abstract: I propose \textbf{G}roup-relative \textbf{I}mplicit \textbf{F}ine
\textbf{T}uning (GIFT), a novel reinforcement learning framework for aligning
LLMs. Instead of directly maximizing cumulative rewards like PPO or GRPO, GIFT
minimizes the discrepancy between implicit and explicit reward models. It
combines three key ideas: (1) the online multi-response generation and
normalization of GRPO, (2) the implicit reward formulation of DPO, and (3) the
implicit-explicit reward alignment principle of UNA. By jointly normalizing the
implicit and explicit rewards, GIFT eliminates an otherwise intractable term
that prevents effective use of implicit rewards. This normalization transforms
the complex reward maximization objective into a simple mean squared error
(MSE) loss between the normalized reward functions, converting a non-convex
optimization problem into a convex, stable, and analytically differentiable
formulation. Unlike offline methods such as DPO and UNA, GIFT remains on-policy
and thus retains exploration capability. Compared to GRPO, it requires fewer
hyperparameters, converges faster, and generalizes better with significantly
reduced training overfitting. Empirically, GIFT achieves superior reasoning and
alignment performance on mathematical benchmarks while remaining
computationally efficient.

</details>


### [104] [GraphNet: A Large-Scale Computational Graph Dataset for Tensor Compiler Research](https://arxiv.org/abs/2510.24035)
*Xinqi Li,Yiqun Liu,Shan Jiang,Enrong Zheng,Huaijin Zheng,Wenhao Dai,Haodong Deng,Dianhai Yu,Yanjun Ma*

Main category: cs.LG

TL;DR: GraphNet是一个包含2.7K真实深度学习计算图的数据集，提出了Speedup Score S(t)和Error-aware Speedup Score ES(t)两种评估指标，用于评估张量编译器性能，并展示了在CV和NLP任务上的基准测试结果。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏真实世界的深度学习计算图数据集来评估张量编译器性能，需要更可靠的评估指标来综合考虑运行速度提升和执行正确性。

Method: 构建GraphNet数据集，包含6个主要任务类别的2.7K计算图；提出Speedup Score S(t)作为基准指标，考虑运行速度提升和正确性；扩展为ES(t)包含错误信息；在CV和NLP样本上测试CINN和TorchInductor编译器。

Result: 成功构建了GraphNet数据集和评估框架，展示了在计算机视觉和自然语言处理任务上的编译器性能评估结果。

Conclusion: GraphNet为张量编译器性能评估提供了实用的数据集和评估指标，有助于编译器开发者识别性能瓶颈，推动深度学习框架优化。

Abstract: We introduce GraphNet, a dataset of 2.7K real-world deep learning
computational graphs with rich metadata, spanning six major task categories
across multiple deep learning frameworks. To evaluate tensor compiler
performance on these samples, we propose the benchmark metric Speedup Score
S(t), which jointly considers runtime speedup and execution correctness under
tunable tolerance levels, offering a reliable measure of general optimization
capability. Furthermore, we extend S(t) to the Error-aware Speedup Score ES(t),
which incorporates error information and helps compiler developers identify key
performance bottlenecks. In this report, we benchmark the default tensor
compilers, CINN for PaddlePaddle and TorchInductor for PyTorch, on computer
vision (CV) and natural language processing (NLP) samples to demonstrate the
practicality of GraphNet. The full construction pipeline with graph extraction
and compiler evaluation tools is available at
https://github.com/PaddlePaddle/GraphNet .

</details>
