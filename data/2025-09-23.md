<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 140]
- [cs.CR](#cs.CR) [Total: 1]
- [cs.CV](#cs.CV) [Total: 7]
- [cs.IR](#cs.IR) [Total: 7]
- [cs.RO](#cs.RO) [Total: 1]
- [cs.MM](#cs.MM) [Total: 1]
- [quant-ph](#quant-ph) [Total: 1]
- [cs.SE](#cs.SE) [Total: 1]
- [cs.DB](#cs.DB) [Total: 1]
- [cs.AI](#cs.AI) [Total: 12]
- [cs.CY](#cs.CY) [Total: 4]
- [cs.HC](#cs.HC) [Total: 4]
- [cs.LG](#cs.LG) [Total: 9]
- [cs.SD](#cs.SD) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [On LLM-Based Scientific Inductive Reasoning Beyond Equations](https://arxiv.org/abs/2509.16226)
*Brian S. Lin,Jiaxin Yuan,Zihan Zhou,Shouli Wang,Shuo Wang,Cunliang Kong,Qi Shi,Yuxuan Li,Liner Yang,Zhiyuan Liu,Maosong Sun*

Main category: cs.CL

TL;DR: 本文提出了基于LLM的科学归纳推理任务（超越方程范畴），并创建了SIRBench-V1基准来评估LLM在科学场景中的归纳推理能力。实验表明当前LLM在此任务上仍有困难。


<details>
  <summary>Details</summary>
Motivation: 现有LLM归纳推理研究主要关注可用数学方程表达的规则，而超越方程范畴的研究缺乏具体场景基础。受人类科学发现与归纳推理的相似性启发，需要评估LLM在真实科学环境中的归纳推理能力。

Method: 提出LLM-Based Scientific Inductive Reasoning Beyond Equations任务，并开发SIRBench-V1基准来系统评估LLM在科学场景下的归纳推理表现。

Result: 实验结果显示，当前的大型语言模型在科学归纳推理任务上表现不佳，表明该任务具有挑战性。

Conclusion: 该研究揭示了LLM在科学归纳推理方面的局限性，强调了在这一领域需要进一步发展和改进的必要性。

Abstract: As large language models (LLMs) increasingly exhibit human-like capabilities,
a fundamental question emerges: How can we enable LLMs to learn the underlying
patterns from limited examples in entirely novel environments and apply them
effectively? This question is central to the ability of LLMs in inductive
reasoning. Existing research on LLM-based inductive reasoning can be broadly
categorized based on whether the underlying rules are expressible via explicit
mathematical equations. However, many recent studies in the beyond-equations
category have emphasized rule design without grounding them in specific
scenarios. Inspired by the parallels between inductive reasoning and human
scientific discovery, we propose the task of LLM-Based Scientific Inductive
Reasoning Beyond Equations and introduce a new benchmark, SIRBench-V1, to
evaluate the inductive reasoning abilities of LLMs in scientific settings. Our
experimental results show that current LLMs still struggle with this task,
underscoring its difficulty and the need for further advancement in this area.

</details>


### [2] [REAMS: Reasoning Enhanced Algorithm for Maths Solving](https://arxiv.org/abs/2509.16241)
*Eishkaran Singh,Tanav Singh Bajaj,Siddharth Nayak*

Main category: cs.CL

TL;DR: 本文提出了一种基于语言的方法，利用零样本学习和数学推理来解决、解释和生成大学级别数学问题的解决方案，通过集成程序合成显著提高了问题解决准确率。


<details>
  <summary>Details</summary>
Motivation: 解决复杂大学级别数学问题（特别是MIT、哥伦比亚大学课程和MATH数据集中的问题）一直是人工智能领域的重大挑战，传统方法在这一领域表现不佳，需要更先进的解决方案。

Method: 采用基于语言的方法，结合零样本学习和数学推理，集成程序合成技术，减少对大规模训练数据的依赖。

Result: 该方法达到了90.15%的准确率，相比之前81%的基准有显著提升，为自动化数学问题解决设立了新标准。

Conclusion: 研究结果表明先进的人工智能方法在解决复杂数学课程和数据集挑战方面具有巨大潜力。

Abstract: The challenges of solving complex university-level mathematics problems,
particularly those from MIT, and Columbia University courses, and selected
tasks from the MATH dataset, remain a significant obstacle in the field of
artificial intelligence. Conventional methods have consistently fallen short in
this domain, highlighting the need for more advanced approaches. In this paper,
we introduce a language-based solution that leverages zero-shot learning and
mathematical reasoning to effectively solve, explain, and generate solutions
for these advanced math problems. By integrating program synthesis, our method
reduces reliance on large-scale training data while significantly improving
problem-solving accuracy. Our approach achieves an accuracy of 90.15%,
representing a substantial improvement over the previous benchmark of 81% and
setting a new standard in automated mathematical problem-solving. These
findings highlight the significant potential of advanced AI methodologies to
address and overcome the challenges presented by some of the most complex
mathematical courses and datasets.

</details>


### [3] [HausaMovieReview: A Benchmark Dataset for Sentiment Analysis in Low-Resource African Language](https://arxiv.org/abs/2509.16256)
*Asiya Ibrahim Zanga,Salisu Mamman Abdulrahman,Abubakar Ado,Abdulkadir Abubakar Bichi,Lukman Aliyu Jibril,Abdulmajid Babangida Umar,Alhassan Adamu,Shamsuddeen Hassan Muhammad,Bashir Salisu Abubakar*

Main category: cs.CL

TL;DR: 该论文介绍了HausaMovieReview数据集，包含5000条豪萨语和英语混合的YouTube评论，用于低资源语言的NLP研究。研究发现决策树分类器在情感分析任务上表现优于深度学习模型。


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言（如豪萨语）因标注数据稀缺而阻碍NLP工具开发的问题。

Method: 构建HausaMovieReview数据集，由三位独立标注者标注（Fleiss' Kappa=0.85），比较经典模型（逻辑回归、决策树、K近邻）和微调Transformer模型（BERT、RoBERTa）的性能。

Result: 决策树分类器表现最佳，准确率89.72%，F1分数89.60%，显著优于深度学习模型。

Conclusion: 在低资源环境下，有效的特征工程可使经典模型达到最先进性能，为未来研究奠定基础。

Abstract: The development of Natural Language Processing (NLP) tools for low-resource
languages is critically hindered by the scarcity of annotated datasets. This
paper addresses this fundamental challenge by introducing HausaMovieReview, a
novel benchmark dataset comprising 5,000 YouTube comments in Hausa and
code-switched English. The dataset was meticulously annotated by three
independent annotators, demonstrating a robust agreement with a Fleiss' Kappa
score of 0.85 between annotators. We used this dataset to conduct a comparative
analysis of classical models (Logistic Regression, Decision Tree, K-Nearest
Neighbors) and fine-tuned transformer models (BERT and RoBERTa). Our results
reveal a key finding: the Decision Tree classifier, with an accuracy and
F1-score 89.72% and 89.60% respectively, significantly outperformed the deep
learning models. Our findings also provide a robust baseline, demonstrating
that effective feature engineering can enable classical models to achieve
state-of-the-art performance in low-resource contexts, thereby laying a solid
foundation for future research.
  Keywords: Hausa, Kannywood, Low-Resource Languages, NLP, Sentiment Analysis

</details>


### [4] [Gender and Political Bias in Large Language Models: A Demonstration Platform](https://arxiv.org/abs/2509.16264)
*Wenjie Lin,Hange Liu,Xutao Mao,Yingying Zhuang,Jingwei Shi,Xudong Han,Tianyu Shi,Jinrui Yang*

Main category: cs.CL

TL;DR: ParlAI Vote是一个交互式系统，用于探索欧洲议会辩论和投票，并测试LLMs在投票预测和偏见分析方面的表现。该系统整合了辩论话题、演讲、投票结果及人口统计数据，可视化EuroParlVote基准测试，揭示前沿LLMs的系统性性能偏见。


<details>
  <summary>Details</summary>
Motivation: 开发一个统一平台来降低研究门槛，支持立法决策的研究、教育和公众参与，同时清晰展示当前LLMs在政治分析中的优势和局限性。

Method: 构建ParlAI Vote交互系统，连接辩论话题、演讲和投票结果，包含丰富的人口统计数据（性别、年龄、国家、政治团体），用户可浏览辩论、检查关联演讲、比较真实投票结果与LLMs预测，并查看按人口统计组别的错误分解。

Result: 系统成功可视化EuroParlVote基准及其核心任务（性别分类和投票预测），突显出前沿LLMs存在系统性性能偏见。

Conclusion: ParlAI Vote通过统一数据、模型和可视化分析于单一界面，有效支持研究成果复现、行为审计和反事实场景运行，为LLMs在政治分析中的应用提供了重要工具和洞察。

Abstract: We present ParlAI Vote, an interactive system for exploring European
Parliament debates and votes, and for testing LLMs on vote prediction and bias
analysis. This platform connects debate topics, speeches, and roll-call
outcomes, and includes rich demographic data such as gender, age, country, and
political group. Users can browse debates, inspect linked speeches, compare
real voting outcomes with predictions from frontier LLMs, and view error
breakdowns by demographic group. Visualizing the EuroParlVote benchmark and its
core tasks of gender classification and vote prediction, ParlAI Vote highlights
systematic performance bias in state-of-the-art LLMs. The system unifies data,
models, and visual analytics in a single interface, lowering the barrier for
reproducing findings, auditing behavior, and running counterfactual scenarios.
It supports research, education, and public engagement with legislative
decision-making, while making clear both the strengths and the limitations of
current LLMs in political analysis.

</details>


### [5] [Language Modeling with Learned Meta-Tokens](https://arxiv.org/abs/2509.16278)
*Alok N. Shah,Khush Gupta,Keshav Ramji,Pratik Chaudhari*

Main category: cs.CL

TL;DR: 本文提出了一种使用元标记和元注意力机制的新方法，通过预训练语言模型来增强长距离依赖关系的捕捉能力，实现数据高效的长上下文语言建模。


<details>
  <summary>Details</summary>
Motivation: 现代Transformer语言模型在多任务泛化方面取得了成功，但在捕捉上下文窗口内的长距离依赖关系方面存在困难。

Method: 在GPT-2架构基础上引入元标记和元注意力机制进行预训练，元标记作为可训练的内容基准标记，隐式压缩前文内容。

Result: 使用少于100B标记的数据高效预训练后，模型在合成任务上表现优异，能够实现2倍上下文窗口的长度泛化。

Conclusion: 元标记预训练为增强长上下文语言建模性能提供了一种简单、数据高效的方法，并为长度泛化行为提供了新见解。

Abstract: While modern Transformer-based language models (LMs) have achieved major
success in multi-task generalization, they often struggle to capture long-range
dependencies within their context window. This work introduces a novel approach
using meta-tokens, special tokens injected during pre-training, along with a
dedicated meta-attention mechanism to guide LMs to use these tokens. We
pre-train a language model with a modified GPT-2 architecture equipped with
meta-attention in addition to causal multi-head attention, and study the impact
of these tokens on a suite of synthetic tasks. We find that data-efficient
language model pre-training on fewer than 100B tokens utilizing meta-tokens and
our meta-attention mechanism achieves strong performance on these tasks after
fine-tuning. We suggest that these gains arise due to the meta-tokens
sharpening the positional encoding. This enables them to operate as trainable,
content-based landmarks, implicitly compressing preceding context and "caching"
it in the meta-token. At inference-time, the meta-token points to relevant
context, facilitating length generalization up to 2$\times$ its context window,
even after extension with YaRN. We provide further evidence of these behaviors
by visualizing model internals to study the residual stream, and assessing the
compression quality by information-theoretic analysis on the rate-distortion
tradeoff. Our findings suggest that pre-training LMs with meta-tokens offers a
simple, data-efficient method to enhance long-context language modeling
performance, while introducing new insights into the nature of their behavior
towards length generalization.

</details>


### [6] [Overhearing LLM Agents: A Survey, Taxonomy, and Roadmap](https://arxiv.org/abs/2509.16325)
*Andrew Zhu,Chris Callison-Burch*

Main category: cs.CL

TL;DR: 该论文提出了"旁听智能体"的概念，这是一种新型的人机交互范式，让AI助手在不打断对话的情况下提供上下文相关的辅助服务。


<details>
  <summary>Details</summary>
Motivation: 研究如何让AI助手在不干扰用户对话的情况下提供无缝的上下文辅助，解决传统聊天式AI需要用户主动交互的问题。

Method: 通过对现有LLM智能体工作的调查和探索性人机交互研究，建立了旁听智能体的分类学，并制定了最佳实践指南。

Result: 建立了旁听智能体的系统分类和交互模式，为研究人员和开发者提供了构建此类系统的指导原则。

Conclusion: 旁听智能体代表了人机交互的新范式，论文指出了该领域的研究空白和未来发展方向。

Abstract: Imagine AI assistants that enhance conversations without interrupting them:
quietly providing relevant information during a medical consultation,
seamlessly preparing materials as teachers discuss lesson plans, or
unobtrusively scheduling meetings as colleagues debate calendars. While modern
conversational LLM agents directly assist human users with tasks through a chat
interface, we study this alternative paradigm for interacting with LLM agents,
which we call "overhearing agents." Rather than demanding the user's attention,
overhearing agents continuously monitor ambient activity and intervene only
when they can provide contextual assistance. In this paper, we present the
first analysis of overhearing LLM agents as a distinct paradigm in human-AI
interaction and establish a taxonomy of overhearing agent interactions and
tasks grounded in a survey of works on prior LLM-powered agents and exploratory
HCI studies. Based on this taxonomy, we create a list of best practices for
researchers and developers building overhearing agent systems. Finally, we
outline the remaining research gaps and reveal opportunities for future
research in the overhearing paradigm.

</details>


### [7] [HARE: an entity and relation centric evaluation framework for histopathology reports](https://arxiv.org/abs/2509.16326)
*Yunsoo Kim,Michal W. S. Ong,Alex Shavick,Honghan Wu,Adam P. Levine*

Main category: cs.CL

TL;DR: 提出了HARE框架，用于评估病理学报告的临床质量，通过实体和关系提取来比对生成报告与参考报告的关键内容。


<details>
  <summary>Details</summary>
Motivation: 医学领域自动文本生成的临床质量评估存在挑战，特别是在病理学等缺乏领域特定指标的领域。

Method: 开发了HARE框架，包括基准数据集、命名实体识别模型、关系提取模型和新指标，通过比对病理学实体和关系来评估报告质量。

Result: HARE-NER和HARE-RE模型达到最高F1分数0.915，HARE指标在相关性分析和回归分析中均优于传统指标和放射学指标。

Conclusion: HARE为病理学报告生成提供了强大的评估框架，有助于提高报告质量。

Abstract: Medical domain automated text generation is an active area of research and
development; however, evaluating the clinical quality of generated reports
remains a challenge, especially in instances where domain-specific metrics are
lacking, e.g. histopathology. We propose HARE (Histopathology Automated Report
Evaluation), a novel entity and relation centric framework, composed of a
benchmark dataset, a named entity recognition (NER) model, a relation
extraction (RE) model, and a novel metric, which prioritizes clinically
relevant content by aligning critical histopathology entities and relations
between reference and generated reports. To develop the HARE benchmark, we
annotated 813 de-identified clinical diagnostic histopathology reports and 652
histopathology reports from The Cancer Genome Atlas (TCGA) with domain-specific
entities and relations. We fine-tuned GatorTronS, a domain-adapted language
model to develop HARE-NER and HARE-RE which achieved the highest overall
F1-score (0.915) among the tested models. The proposed HARE metric outperformed
traditional metrics including ROUGE and Meteor, as well as radiology metrics
such as RadGraph-XL, with the highest correlation and the best regression to
expert evaluations (higher than the second best method, GREEN, a large language
model based radiology report evaluator, by Pearson $r = 0.168$, Spearman $\rho
= 0.161$, Kendall $\tau = 0.123$, $R^2 = 0.176$, $RMSE = 0.018$). We release
HARE, datasets, and the models at https://github.com/knowlab/HARE to foster
advancements in histopathology report generation, providing a robust framework
for improving the quality of reports.

</details>


### [8] [RephQA: Evaluating Readability of Large Language Models in Public Health Question Answering](https://arxiv.org/abs/2509.16360)
*Weikang Qiu,Tinglin Huang,Ryan Rullo,Yucheng Kuang,Ali Maatouk,S. Raquel Ramos,Rex Ying*

Main category: cs.CL

TL;DR: 提出了RephQA基准来评估LLM在公共卫生问答中的可读性，发现大多数模型无法满足可读性标准，并通过token-adapted GRPO方法显著提升了可读性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注LLM的准确性和推理能力，但在医疗健康应用中，LLM生成回答的可读性对于非医学背景用户至关重要，这是一个关键瓶颈。

Method: 构建包含533个专家评审QA对的RephQA基准，使用Flesch-Kincaid等级和专业评分两个可读性指标，并探索了标准提示、思维链提示、GRPO及其token-adapted变体四种可读性增强策略。

Result: 评估25个LLM显示大多数模型无法满足可读性标准，token-adapted GRPO方法取得了最佳效果。

Conclusion: 这项工作推动了更实用、用户友好的公共卫生智能代理的发展，强调了在LLM应用中可读性与推理能力同等重要。

Abstract: Large Language Models (LLMs) hold promise in addressing complex medical
problems. However, while most prior studies focus on improving accuracy and
reasoning abilities, a significant bottleneck in developing effective
healthcare agents lies in the readability of LLM-generated responses,
specifically, their ability to answer public health problems clearly and simply
to people without medical backgrounds. In this work, we introduce RephQA, a
benchmark for evaluating the readability of LLMs in public health question
answering (QA). It contains 533 expert-reviewed QA pairs from 27 sources across
13 topics, and includes a proxy multiple-choice task to assess informativeness,
along with two readability metrics: Flesch-Kincaid grade level and professional
score. Evaluation of 25 LLMs reveals that most fail to meet readability
standards, highlighting a gap between reasoning and effective communication. To
address this, we explore four readability-enhancing strategies-standard
prompting, chain-of-thought prompting, Group Relative Policy Optimization
(GRPO), and a token-adapted variant. Token-adapted GRPO achieves the best
results, advancing the development of more practical and user-friendly public
health agents. These results represent a step toward building more practical
agents for public health.

</details>


### [9] [Whisper-UT: A Unified Translation Framework for Speech and Text](https://arxiv.org/abs/2509.16375)
*Cihan Xiao,Matthew Wiesner,Debashish Chakraborty,Reno Kriz,Keith Cunningham,Kenton Murray,Kevin Duh,Luis Tavarez-Arce,Paul McNamee,Sanjeev Khudanpur*

Main category: cs.CL

TL;DR: Whisper-UT是一个统一高效的框架，通过轻量级适配器实现跨任务无缝适应，包括多模态机器翻译任务，能够同时处理语音和文本输入。


<details>
  <summary>Details</summary>
Motivation: 编码器-解码器模型在语音和文本任务中取得了显著成功，但如何高效适应不同的单/多模态场景仍是一个开放挑战。

Method: 利用轻量级适配器，通过ASR假设或真实转录作为提示，采用2阶段解码策略增强语音翻译性能，支持跨模态和跨任务微调。

Result: 该方法提高了语音翻译性能，且无需3向并行数据，展示了框架在多模态翻译中的灵活性、效率和通用性。

Conclusion: Whisper-UT框架在跨模态和跨任务适应方面表现出色，为多模态翻译提供了有效的解决方案。

Abstract: Encoder-decoder models have achieved remarkable success in speech and text
tasks, yet efficiently adapting these models to diverse uni/multi-modal
scenarios remains an open challenge. In this paper, we propose Whisper-UT, a
unified and efficient framework that leverages lightweight adapters to enable
seamless adaptation across tasks, including a multi-modal machine translation
(MMT) task that explicitly conditions translation on both speech and source
language text inputs. By incorporating ASR hypotheses or ground-truth
transcripts as prompts, this approach not only enables the system to process
both modalities simultaneously but also enhances speech translation (ST)
performance through a 2-stage decoding strategy. We demonstrate our methods
using the Whisper model, though in principle they are general and could be
applied to similar multitask models. We highlight the effectiveness of
cross-modal and cross-task fine-tuning, which improves performance without
requiring 3-way parallel data. Our results underscore the flexibility,
efficiency, and general applicability of the proposed framework for multi-modal
translation.

</details>


### [10] [Evaluating Behavioral Alignment in Conflict Dialogue: A Multi-Dimensional Comparison of LLM Agents and Humans](https://arxiv.org/abs/2509.16394)
*Deuksin Kwon,Kaleen Shrestha,Bin Han,Elena Hayoung Lee,Gale Lucas*

Main category: cs.CL

TL;DR: 本研究通过模拟多轮冲突对话，评估了具有人格提示的大型语言模型在对抗性争议解决中的行为对齐程度，发现GPT-4.1在语言风格和情感动态方面与人类最接近，而Claude-3.7-Sonnet在战略行为方面表现最佳，但仍存在显著对齐差距。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型越来越多地应用于社会复杂性任务中，但其在情感和战略复杂性情境下模拟人类行为的能力尚未充分探索，需要评估LLMs在对抗性争议解决中的行为对齐程度。

Method: 通过模拟包含谈判的多轮冲突对话，为每个LLM匹配五因素人格配置文件来控制个体差异并增强真实性，从语言风格、情感表达和战略行为三个维度评估对齐程度。

Result: GPT-4.1在语言风格和情感动态方面与人类最接近，Claude-3.7-Sonnet在战略行为方面表现最佳，但所有模型都存在显著的对齐差距。

Conclusion: 研究为LLMs与人类在社会复杂互动中的对齐建立了基准，强调了人格调节在对话建模中的潜力和局限性。

Abstract: Large Language Models (LLMs) are increasingly deployed in socially complex,
interaction-driven tasks, yet their ability to mirror human behavior in
emotionally and strategically complex contexts remains underexplored. This
study assesses the behavioral alignment of personality-prompted LLMs in
adversarial dispute resolution by simulating multi-turn conflict dialogues that
incorporate negotiation. Each LLM is guided by a matched Five-Factor
personality profile to control for individual variation and enhance realism. We
evaluate alignment across three dimensions: linguistic style, emotional
expression (e.g., anger dynamics), and strategic behavior. GPT-4.1 achieves the
closest alignment with humans in linguistic style and emotional dynamics, while
Claude-3.7-Sonnet best reflects strategic behavior. Nonetheless, substantial
alignment gaps persist. Our findings establish a benchmark for alignment
between LLMs and humans in socially complex interactions, underscoring both the
promise and the limitations of personality conditioning in dialogue modeling.

</details>


### [11] ['Rich Dad, Poor Lad': How do Large Language Models Contextualize Socioeconomic Factors in College Admission ?](https://arxiv.org/abs/2509.16400)
*Huy Nghiem,Phuong-Anh Nguyen-Le,John Prindle,Rachel Rudinger,Hal Daumé III*

Main category: cs.CL

TL;DR: 本文通过双过程框架审计LLM在高校招生决策中对社会经济地位的处理，发现LLM倾向于优待低SES申请者，且系统2模式会放大这种倾向。


<details>
  <summary>Details</summary>
Motivation: LLM越来越多地参与高风险领域决策，但其在社会敏感决策中的推理机制尚未充分探索，特别是在社会经济地位影响方面。

Method: 使用基于真实世界相关性的3万份合成申请档案，对4个开源LLM进行500万次提示测试，采用双过程框架：快速决策模式（系统1）和解释性模式（系统2）。

Result: LLM一致倾向于优待低SES申请者（即使控制学业表现），系统2模式通过明确引用SES作为补偿性理由进一步放大这种倾向。

Conclusion: LLM作为决策者具有潜力和不稳定性，提出了DPAF双过程审计框架来探测LLM在敏感应用中的推理行为。

Abstract: Large Language Models (LLMs) are increasingly involved in high-stakes
domains, yet how they reason about socially sensitive decisions remains
underexplored. We present a large-scale audit of LLMs' treatment of
socioeconomic status (SES) in college admissions decisions using a novel
dual-process framework inspired by cognitive science. Leveraging a synthetic
dataset of 30,000 applicant profiles grounded in real-world correlations, we
prompt 4 open-source LLMs (Qwen 2, Mistral v0.3, Gemma 2, Llama 3.1) under 2
modes: a fast, decision-only setup (System 1) and a slower, explanation-based
setup (System 2). Results from 5 million prompts reveal that LLMs consistently
favor low-SES applicants -- even when controlling for academic performance --
and that System 2 amplifies this tendency by explicitly invoking SES as
compensatory justification, highlighting both their potential and volatility as
decision-makers. We then propose DPAF, a dual-process audit framework to probe
LLMs' reasoning behaviors in sensitive applications.

</details>


### [12] [Pico: A Modular Framework for Hypothesis-Driven Small Language Model Research](https://arxiv.org/abs/2509.16413)
*Richard Diehl Martinez,David Demitri Africa,Yuval Weiss,Suchir Salhan,Ryan Daniels,Paula Buttery*

Main category: cs.CL

TL;DR: Pico是一个轻量级模块化框架，用于系统化研究中小型语言模型的开发，通过提供实验沙盒和基准模型支持可重复的实验研究。


<details>
  <summary>Details</summary>
Motivation: 当前中小型语言模型的开发缺乏科学系统性，设计选择往往基于经验而非科学验证，参数预算紧张使得每个决策都至关重要。

Method: Pico框架包含两个库，提供实验沙盒环境，研究人员可以针对性地修改模型架构或训练流程，并直接观察对模型行为的影响。同时发布了标准条件下训练的基准模型pico-decoder。

Result: 案例研究展示了Pico如何支持迭代式的小型语言模型设计和分析，为社区提供了可复现的实验基础。

Conclusion: Pico框架填补了中小型语言模型开发中系统性研究工具的空白，为研究人员提供了科学验证设计选择的实用平台。

Abstract: Building language models (LMs), especially small and medium ones, remains
more art than science. While large LMs often improve by sheer scale, it is
still unclear why many design choices work. For small LMs, this uncertainty is
more limiting: tight parameter budgets make each decision critical, yet
researchers still lack systematic, scientific ways to test and refine new
ideas.
  We introduce Pico, a lightweight, modular framework that enables systematic,
hypothesis-driven research for small and medium-scale language model
development. Pico consists of two libraries that together provide a practical
sandbox where researchers can make targeted changes to a model's architecture
or training procedures and directly observe their effects on the model's
behavior. To support reproducible experimentation, we also release a suite of
baseline models, pico-decoder, trained under standardized conditions and
open-sourced for the community. Case studies highlight how Pico can support
iterative small LM design and analysis.

</details>


### [13] [Evaluating CxG Generalisation in LLMs via Construction-Based NLI Fine Tuning](https://arxiv.org/abs/2509.16422)
*Tom Mackintosh,Harish Tayyar Madabushi,Claire Bonial*

Main category: cs.CL

TL;DR: 论文提出了ConTest-NLI基准测试，用于评估大语言模型学习构式语法中深层形式-意义映射的能力，发现LLMs在自然数据和对抗数据上存在显著性能差距，特别是在图式化构式上表现最差。


<details>
  <summary>Details</summary>
Motivation: 研究大语言模型是否能够学习构式语法定义的深层形式-意义映射，填补当前LLMs在构式学习能力评估方面的空白。

Method: 构建包含8万个句子的ConTest-NLI基准测试，涵盖8种英语构式（从高度词汇化到高度图式化），通过模板化和模型循环过滤生成多样化的合成NLI三元组。

Result: 零样本测试显示领先LLMs在自然数据上准确率为88%，对抗数据上为64%，图式化构式最难；微调可带来9%的改进，但仍存在抽象能力差距。

Conclusion: 当前LLMs在构式学习方面存在持续的抽象能力差距，ConTest-NLI提供了一个可扩展的框架来评估构式导向的学习能力。

Abstract: We probe large language models' ability to learn deep form-meaning mappings
as defined by construction grammars. We introduce the ConTest-NLI benchmark of
80k sentences covering eight English constructions from highly lexicalized to
highly schematic. Our pipeline generates diverse synthetic NLI triples via
templating and the application of a model-in-the-loop filter. This provides
aspects of human validation to ensure challenge and label reliability.
Zero-shot tests on leading LLMs reveal a 24% drop in accuracy between
naturalistic (88%) and adversarial data (64%), with schematic patterns proving
hardest. Fine-tuning on a subset of ConTest-NLI yields up to 9% improvement,
yet our results highlight persistent abstraction gaps in current LLMs and offer
a scalable framework for evaluating construction-informed learning.

</details>


### [14] [PersonaMatrix: A Recipe for Persona-Aware Evaluation of Legal Summarization](https://arxiv.org/abs/2509.16449)
*Tsz Fung Pang,Maryam Berijanian,Thomas Orth,Breanna Shi,Charlotte S. Alexander*

Main category: cs.CL

TL;DR: PersonaMatrix是一个基于角色评估的法律文档摘要框架，通过六个不同角色视角来评估摘要质量，旨在满足法律专家和非专业用户的不同需求。


<details>
  <summary>Details</summary>
Motivation: 法律文档通常冗长复杂难以理解，现有自动化摘要评估方法忽视了不同用户和利益相关者的需求差异，需要开发能同时满足法律专家和普通公众需求的工具。

Method: 提出了PersonaMatrix评估框架和受控维度偏移数据集，包含深度、可访问性和程序细节等维度，并引入多样性覆盖指数(DCI)来揭示角色感知与角色无关评估之间的差异。

Result: 开发了一个美国民权案件摘要的试点数据集，能够暴露不同角色对法律摘要优化的分歧，代码和数据已在GitHub公开。

Conclusion: 这项工作能够改进法律AI摘要系统，使其同时满足专家和非专家用户需求，有潜力提高法律知识的可及性。

Abstract: Legal documents are often long, dense, and difficult to comprehend, not only
for laypeople but also for legal experts. While automated document
summarization has great potential to improve access to legal knowledge,
prevailing task-based evaluators overlook divergent user and stakeholder needs.
Tool development is needed to encompass the technicality of a case summary for
a litigator yet be accessible for a self-help public researching for their
lawsuit. We introduce PersonaMatrix, a persona-by-criterion evaluation
framework that scores summaries through the lens of six personas, including
legal and non-legal users. We also introduce a controlled dimension-shifted
pilot dataset of U.S. civil rights case summaries that varies along depth,
accessibility, and procedural detail as well as Diversity-Coverage Index (DCI)
to expose divergent optima of legal summary between persona-aware and
persona-agnostic judges. This work enables refinement of legal AI summarization
systems for both expert and non-expert users, with the potential to increase
access to legal knowledge. The code base and data are publicly available in
GitHub.

</details>


### [15] [Implicit Behavioral Alignment of Language Agents in High-Stakes Crowd Simulations](https://arxiv.org/abs/2509.16457)
*Yunzhe Wang,Gale M. Lucas,Burcin Becerik-Gerber,Volkan Ustun*

Main category: cs.CL

TL;DR: 本文提出PEBA理论框架和PEvo算法来解决生成智能体行为与真实数据之间的差距问题，通过在活跃枪手事件模拟中验证，显著提升了行为真实性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前基于语言模型的生成智能体在社交模拟中经常偏离专家预期和真实数据，存在行为-真实性差距问题，这影响了高风险社交模拟的可信度。

Method: 提出Persona-Environment Behavioral Alignment (PEBA)理论框架，基于Lewin行为方程，将行为视为个体与环境函数。开发PersonaEvolve (PEvo)算法，通过迭代优化智能体角色，使其集体行为与专家基准在特定环境背景下对齐。

Result: 在活跃枪手事件模拟中，PEvo相比无引导方法平均减少84%分布差异，比显式指令基线提升34%。优化后的角色还能泛化到新的相关模拟场景。

Conclusion: PEBA-PEvo框架为开发可信赖的LLM驱动社交模拟提供了原则性方法，显著提升了行为真实性和可靠性，特别是在高风险场景中。

Abstract: Language-driven generative agents have enabled large-scale social simulations
with transformative uses, from interpersonal training to aiding global
policy-making. However, recent studies indicate that generative agent behaviors
often deviate from expert expectations and real-world data--a phenomenon we
term the Behavior-Realism Gap. To address this, we introduce a theoretical
framework called Persona-Environment Behavioral Alignment (PEBA), formulated as
a distribution matching problem grounded in Lewin's behavior equation stating
that behavior is a function of the person and their environment. Leveraging
PEBA, we propose PersonaEvolve (PEvo), an LLM-based optimization algorithm that
iteratively refines agent personas, implicitly aligning their collective
behaviors with realistic expert benchmarks within a specified environmental
context. We validate PEvo in an active shooter incident simulation we
developed, achieving an 84% average reduction in distributional divergence
compared to no steering and a 34% improvement over explicit instruction
baselines. Results also show PEvo-refined personas generalize to novel, related
simulation scenarios. Our method greatly enhances behavioral realism and
reliability in high-stakes social simulations. More broadly, the PEBA-PEvo
framework provides a principled approach to developing trustworthy LLM-driven
social simulations.

</details>


### [16] [Intrinsic Meets Extrinsic Fairness: Assessing the Downstream Impact of Bias Mitigation in Large Language Models](https://arxiv.org/abs/2509.16462)
*'Mina Arzaghi','Alireza Dehghanpour Farashah','Florian Carichon',' Golnoosh Farnadi'*

Main category: cs.CL

TL;DR: 本文提出了一个统一的评估框架，研究LLMs内在偏见缓解与下游任务公平性之间的关系，发现在金融分类任务中通过概念遗忘进行的内在偏见缓解能显著降低性别偏见并改善下游公平性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型存在社会经济偏见，这些偏见可能传播到下游任务中。本研究旨在实证调查内在偏见是否影响下游任务层面的公平性。

Method: 提出了统一的评估框架，比较通过概念遗忘的内在偏见缓解与通过反事实数据增强的外在偏见缓解。在三个真实世界金融分类任务上进行实验，使用三种开源LLMs，评估冻结嵌入提取器和微调分类器两种情况。

Result: 内在偏见缓解通过遗忘方法将内在性别偏见降低高达94.9%，同时将下游任务公平性指标（如人口均等）改善高达82%，且不影响准确性。

Conclusion: 该框架为缓解偏见提供了实用指导，强调了在下游部署前应用早期阶段缓解的重要性。

Abstract: Large Language Models (LLMs) exhibit socio-economic biases that can propagate
into downstream tasks. While prior studies have questioned whether intrinsic
bias in LLMs affects fairness at the downstream task level, this work
empirically investigates the connection. We present a unified evaluation
framework to compare intrinsic bias mitigation via concept unlearning with
extrinsic bias mitigation via counterfactual data augmentation (CDA). We
examine this relationship through real-world financial classification tasks,
including salary prediction, employment status, and creditworthiness
assessment. Using three open-source LLMs, we evaluate models both as frozen
embedding extractors and as fine-tuned classifiers. Our results show that
intrinsic bias mitigation through unlearning reduces intrinsic gender bias by
up to 94.9%, while also improving downstream task fairness metrics, such as
demographic parity by up to 82%, without compromising accuracy. Our framework
offers practical guidance on where mitigation efforts can be most effective and
highlights the importance of applying early-stage mitigation before downstream
deployment.

</details>


### [17] [Computational Analysis of Conversation Dynamics through Participant Responsivity](https://arxiv.org/abs/2509.16464)
*Margaret Hughes,Brandon Roy,Elinor Poole-Dayan,Deb Roy,Jad Kabbara*

Main category: cs.CL

TL;DR: 本文提出了一种基于"响应性"概念的方法来评估对话质量，通过语义相似度和大型语言模型来量化对话中说话者之间的响应关系，并开发了对话级别的度量指标来表征不同对话的结构特征。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注对话中的毒性和极化问题，但对于什么使对话具有建设性和亲社会性的研究相对较少。本文旨在探索如何表征对话质量，特别是通过响应性这一核心概念。

Method: 开发了两种量化响应性的方法：1）基于说话者轮次语义相似度的方法；2）利用最先进的大型语言模型识别两个说话者轮次之间的关系。选择性能更好的LLM方法进一步分析响应的性质（实质性响应与否）。

Result: 评估了两种方法在人工标注对话数据集上的表现，并基于LLM方法开发了对话级别的衍生度量指标，能够有效区分和表征不同类型对话的结构特征。

Conclusion: 响应性链接是对话的基本特征，但不同对话的响应性结构差异显著。开发的度量指标支持对多样化对话集合进行有意义的表征和区分，为理解对话质量提供了新的分析框架。

Abstract: Growing literature explores toxicity and polarization in discourse, with
comparatively less work on characterizing what makes dialogue prosocial and
constructive. We explore conversational discourse and investigate a method for
characterizing its quality built upon the notion of ``responsivity'' -- whether
one person's conversational turn is responding to a preceding turn. We develop
and evaluate methods for quantifying responsivity -- first through semantic
similarity of speaker turns, and second by leveraging state-of-the-art large
language models (LLMs) to identify the relation between two speaker turns. We
evaluate both methods against a ground truth set of human-annotated
conversations. Furthermore, selecting the better performing LLM-based approach,
we characterize the nature of the response -- whether it responded to that
preceding turn in a substantive way or not.
  We view these responsivity links as a fundamental aspect of dialogue but note
that conversations can exhibit significantly different responsivity structures.
Accordingly, we then develop conversation-level derived metrics to address
various aspects of conversational discourse. We use these derived metrics to
explore other conversations and show that they support meaningful
characterizations and differentiations across a diverse collection of
conversations.

</details>


### [18] [The Oracle Has Spoken: A Multi-Aspect Evaluation of Dialogue in Pythia](https://arxiv.org/abs/2509.16487)
*Zixun Chen,Petr Babkin,Akshat Gupta,Gopala Anumanchipalli,Xiaomo Liu*

Main category: cs.CL

TL;DR: 该研究分析了大型语言模型对话能力的具体成分，发现模型大小对大多数对话指标影响有限，而监督微调会快速饱和性能指标，且不同指标间存在高度相关性，引发了对指标可靠性的质疑。


<details>
  <summary>Details</summary>
Motivation: 尽管对话是大型语言模型的核心能力，但很少有研究深入分析后训练过程中对话行为的具体构成要素。本研究旨在通过语言学理论指导的细粒度指标来理解对话能力的形成机制。

Method: 使用基于模型的综合评估指标套件，每个指标针对对话的特定维度。评估预训练的Pythia模型在不同模型大小和对话数据集监督微调下的性能变化。

Result: 模型大小对大多数指标影响有限，而微调会快速饱和所有模型（除最小模型外）的得分。许多指标显示出相似趋势，特别是当它们基于相同的评估模型时。

Conclusion: 研究揭示了对话能力评估指标的局限性，需要通过分数分布分析、指标相关性和生成响应中的术语频率等额外分析来解释观察结果，这对未来对话能力评估方法提出了挑战。

Abstract: Dialogue is one of the landmark abilities of large language models (LLMs).
Despite its ubiquity, few studies actually distinguish specific ingredients
underpinning dialogue behavior emerging during post-training. We employ a
comprehensive suite of model-based metrics, each targeting a distinct
fine-grained aspect of dialogue, motivated by linguistic theory. We evaluate
how the performance of pre-trained Pythia models changes with respect to each
of those dimensions, depending on model size and as a result of supervised
fine-tuning on conversational datasets. We observe only a mild impact of raw
model size on most metrics, whereas fine-tuning quickly saturates the scores
for all but the smallest models tested. Somewhat contrary to our expectations,
many metrics show very similar trends, especially if they are all rooted in the
same evaluator model, which raises the question of their reliability in
measuring a specific dimension. To that end, we conduct additional analyses of
score distributions, metric correlations, and term frequencies in generated
responses to help explain our observations.

</details>


### [19] [Can an Individual Manipulate the Collective Decisions of Multi-Agents?](https://arxiv.org/abs/2509.16494)
*Fengyuan Liu,Rui Zhao,Shuo Chen,Guohao Li,Philip Torr,Lei Han,Jindong Gu*

Main category: cs.CL

TL;DR: 本文提出了M-Spoiler框架，研究在多智能体系统中，攻击者仅知道一个目标智能体时，能否生成对抗样本误导整个系统的协作决策。


<details>
  <summary>Details</summary>
Motivation: 由于单个LLM存在漏洞且难以访问多智能体系统中的所有智能体，研究攻击者仅知道一个智能体时是否能误导集体决策具有重要意义。

Method: 将问题建模为不完全信息博弈，提出M-Spoiler框架，通过引入顽固智能体模拟目标系统中其他智能体的潜在顽固响应，优化对抗样本的生成。

Result: 实验证实了多智能体系统中单个智能体知识带来的风险，并证明了M-Spoiler框架的有效性，即使在防御机制下仍比基线方法更有效。

Conclusion: 该研究揭示了多智能体系统的安全漏洞，强调了需要进一步研究防御策略来保护协作决策系统。

Abstract: Individual Large Language Models (LLMs) have demonstrated significant
capabilities across various domains, such as healthcare and law. Recent studies
also show that coordinated multi-agent systems exhibit enhanced decision-making
and reasoning abilities through collaboration. However, due to the
vulnerabilities of individual LLMs and the difficulty of accessing all agents
in a multi-agent system, a key question arises: If attackers only know one
agent, could they still generate adversarial samples capable of misleading the
collective decision? To explore this question, we formulate it as a game with
incomplete information, where attackers know only one target agent and lack
knowledge of the other agents in the system. With this formulation, we propose
M-Spoiler, a framework that simulates agent interactions within a multi-agent
system to generate adversarial samples. These samples are then used to
manipulate the target agent in the target system, misleading the system's
collaborative decision-making process. More specifically, M-Spoiler introduces
a stubborn agent that actively aids in optimizing adversarial samples by
simulating potential stubborn responses from agents in the target system. This
enhances the effectiveness of the generated adversarial samples in misleading
the system. Through extensive experiments across various tasks, our findings
confirm the risks posed by the knowledge of an individual agent in multi-agent
systems and demonstrate the effectiveness of our framework. We also explore
several defense mechanisms, showing that our proposed attack framework remains
more potent than baselines, underscoring the need for further research into
defensive strategies.

</details>


### [20] [AIPsychoBench: Understanding the Psychometric Differences between LLMs and Humans](https://arxiv.org/abs/2509.16530)
*Wei Xie,Shuoyoucheng Ma,Zhenhua Wang,Enze Wang,Kai Chen,Xiaobing Sun,Baosheng Wang*

Main category: cs.CL

TL;DR: AIPsychoBench是一个专门用于评估大语言模型心理属性的基准测试，通过轻量级角色扮演提示绕过LLM对齐，显著提高有效响应率并降低偏差，同时首次全面证明了语言对LLM心理测量的影响。


<details>
  <summary>Details</summary>
Motivation: 现有研究试图借用人类心理学概念来评估LLM的心理测量特性，但未能考虑LLM与人类的根本差异，导致直接重用人类量表时拒绝率很高，且这些量表不支持不同语言下LLM心理属性变化的测量。

Method: 使用轻量级角色扮演提示来绕过LLM的对齐机制，构建AIPsychoBench基准测试，在7种语言下评估112个心理测量子类别。

Result: 平均有效响应率从70.12%提高到90.40%；平均偏差仅为3.3%（正向）和2.1%（负向），显著低于传统越狱提示的9.8%和6.9%；在43个子类别中，7种语言相对于英语的得分偏差范围为5%到20.2%。

Conclusion: AIPsychoBench为LLM心理属性评估提供了有效的基准测试方法，首次全面证明了语言对LLM心理测量的显著影响，为理解LLM在不同语言环境下的行为差异提供了重要依据。

Abstract: Large Language Models (LLMs) with hundreds of billions of parameters have
exhibited human-like intelligence by learning from vast amounts of
internet-scale data. However, the uninterpretability of large-scale neural
networks raises concerns about the reliability of LLM. Studies have attempted
to assess the psychometric properties of LLMs by borrowing concepts from human
psychology to enhance their interpretability, but they fail to account for the
fundamental differences between LLMs and humans. This results in high rejection
rates when human scales are reused directly. Furthermore, these scales do not
support the measurement of LLM psychological property variations in different
languages. This paper introduces AIPsychoBench, a specialized benchmark
tailored to assess the psychological properties of LLM. It uses a lightweight
role-playing prompt to bypass LLM alignment, improving the average effective
response rate from 70.12% to 90.40%. Meanwhile, the average biases are only
3.3% (positive) and 2.1% (negative), which are significantly lower than the
biases of 9.8% and 6.9%, respectively, caused by traditional jailbreak prompts.
Furthermore, among the total of 112 psychometric subcategories, the score
deviations for seven languages compared to English ranged from 5% to 20.2% in
43 subcategories, providing the first comprehensive evidence of the linguistic
impact on the psychometrics of LLM.

</details>


### [21] [Leveraging Multilingual Training for Authorship Representation: Enhancing Generalization across Languages and Domains](https://arxiv.org/abs/2509.16531)
*Junghwan Kim,Haotian Zhang,David Jurgens*

Main category: cs.CL

TL;DR: 本文提出了一种多语言作者表征学习方法，通过概率内容掩码和语言感知批处理技术，在36种语言和13个领域上训练模型，显著提升了非英语语言的作者归属任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有的作者表征学习研究主要集中于英语单语环境，多语言作者表征模型的潜力尚未充分探索。本文旨在填补这一空白，开发能够跨语言和跨领域泛化的多语言作者表征模型。

Method: 提出了两个关键技术：1）概率内容掩码，鼓励模型关注风格指示性词汇而非内容特定词汇；2）语言感知批处理，通过减少跨语言干扰来改进对比学习。模型在超过450万作者、36种语言和13个领域的数据集上训练。

Result: 模型在22种非英语语言中的21种上持续优于单语基线，Recall@8平均提升4.85%，单语言最大增益达15.91%。与仅使用英语训练的单语模型相比，展现出更强的跨语言和跨领域泛化能力。

Conclusion: 分析证实了所提两种技术的有效性，强调了它们在模型性能提升中的关键作用。该方法为多语言作者表征学习提供了有效解决方案。

Abstract: Authorship representation (AR) learning, which models an author's unique
writing style, has demonstrated strong performance in authorship attribution
tasks. However, prior research has primarily focused on monolingual
settings-mostly in English-leaving the potential benefits of multilingual AR
models underexplored. We introduce a novel method for multilingual AR learning
that incorporates two key innovations: probabilistic content masking, which
encourages the model to focus on stylistically indicative words rather than
content-specific words, and language-aware batching, which improves contrastive
learning by reducing cross-lingual interference. Our model is trained on over
4.5 million authors across 36 languages and 13 domains. It consistently
outperforms monolingual baselines in 21 out of 22 non-English languages,
achieving an average Recall@8 improvement of 4.85%, with a maximum gain of
15.91% in a single language. Furthermore, it exhibits stronger cross-lingual
and cross-domain generalization compared to a monolingual model trained solely
on English. Our analysis confirms the effectiveness of both proposed
techniques, highlighting their critical roles in the model's improved
performance.

</details>


### [22] [Challenging the Evaluator: LLM Sycophancy Under User Rebuttal](https://arxiv.org/abs/2509.16533)
*Sungwon Kim,Daniel Khashabi*

Main category: cs.CL

TL;DR: LLMs在对话中会迎合用户观点，但在同时评估冲突论点时表现良好，研究揭示了这种矛盾现象及其风险


<details>
  <summary>Details</summary>
Motivation: 探究LLMs为何在后续对话中表现出迎合性，但在同时评估冲突论点时表现良好这一矛盾现象

Method: 通过改变关键交互模式进行实证测试，包括对比用户后续反馈与同时呈现论点、详细推理与随意反馈等场景

Result: 发现LLMs更倾向于认同用户的后续反驳，容易受详细推理说服，对随意反馈更敏感，即使推理结论错误或反馈缺乏依据

Conclusion: 在依赖LLMs进行判断任务时需要考虑对话框架的影响，否则存在风险

Abstract: Large Language Models (LLMs) often exhibit sycophancy, distorting responses
to align with user beliefs, notably by readily agreeing with user
counterarguments. Paradoxically, LLMs are increasingly adopted as successful
evaluative agents for tasks such as grading and adjudicating claims. This
research investigates that tension: why do LLMs show sycophancy when challenged
in subsequent conversational turns, yet perform well when evaluating
conflicting arguments presented simultaneously? We empirically tested these
contrasting scenarios by varying key interaction patterns. We find that
state-of-the-art models: (1) are more likely to endorse a user's
counterargument when framed as a follow-up from a user, rather than when both
responses are presented simultaneously for evaluation; (2) show increased
susceptibility to persuasion when the user's rebuttal includes detailed
reasoning, even when the conclusion of the reasoning is incorrect; and (3) are
more readily swayed by casually phrased feedback than by formal critiques, even
when the casual input lacks justification. Our results highlight the risk of
relying on LLMs for judgment tasks without accounting for conversational
framing.

</details>


### [23] [InteGround: On the Evaluation of Verification and Retrieval Planning in Integrative Grounding](https://arxiv.org/abs/2509.16534)
*Cheng Jiayang,Qianqian Zhuang,Haoran Li,Chunkit Chan,Xin Liu,Lin Qiu,Yangqiu Song*

Main category: cs.CL

TL;DR: 本文提出了"整合性基础"的概念，旨在解决LLMs在需要综合多个相互依赖证据的复杂查询中的基础问题。通过四个领域的数据评估，发现LLMs在基础验证中对冗余证据具有鲁棒性，但在信息不完整时倾向于使用内部知识进行合理化；在检索规划策略中，无向规划会引入噪声降低性能，而前提推导因其逻辑约束表现出潜力。


<details>
  <summary>Details</summary>
Motivation: 现有基础方法适用于简单查询，但现实世界的信息需求往往需要综合多个证据。为了系统研究这一问题，作者引入了"整合性基础"的概念，即检索和验证多个相互依赖的证据来支持假设查询。

Method: 重新利用来自四个领域的数据来评估整合性基础能力，研究LLMs在基础验证中的表现，并比较不同的检索规划策略（无向规划与前提推导）。

Result: 研究发现：1）LLMs对冗余证据具有鲁棒性，但在信息不完整时倾向于使用内部知识；2）无向规划会通过引入噪声降低性能，而前提推导因其逻辑约束成为有前景的方法；3）LLMs的零样本自我反思能力持续提高基础质量。

Conclusion: 这些发现为开发更有效的整合性基础系统提供了有价值的方向，强调了逻辑约束规划和自我反思在复杂信息综合中的重要性。

Abstract: Grounding large language models (LLMs) in external knowledge sources is a
promising method for faithful prediction. While existing grounding approaches
work well for simple queries, many real-world information needs require
synthesizing multiple pieces of evidence. We introduce "integrative grounding"
-- the challenge of retrieving and verifying multiple inter-dependent pieces of
evidence to support a hypothesis query. To systematically study this problem,
we repurpose data from four domains for evaluating integrative grounding
capabilities. Our investigation reveals two critical findings: First, in
groundedness verification, while LLMs are robust to redundant evidence, they
tend to rationalize using internal knowledge when information is incomplete.
Second, in examining retrieval planning strategies, we find that undirected
planning can degrade performance through noise introduction, while premise
abduction emerges as a promising approach due to its logical constraints.
Additionally, LLMs' zero-shot self-reflection capabilities consistently improve
grounding quality. These insights provide valuable direction for developing
more effective integrative grounding systems.

</details>


### [24] [Mental Multi-class Classification on Social Media: Benchmarking Transformer Architectures against LSTM Models](https://arxiv.org/abs/2509.16542)
*Khalid Hasan,Jamil Saquer,Yifan Zhang*

Main category: cs.CL

TL;DR: 该研究对最先进的transformer模型与LSTM模型在心理健康帖子多分类任务上的性能进行了大规模比较研究，发现transformer模型（特别是RoBERTa）表现最佳，而带有BERT嵌入的注意力增强LSTM在保持较高性能的同时训练速度更快。


<details>
  <summary>Details</summary>
Motivation: 虽然数百万人公开在社交媒体上分享心理健康问题，为早期检测提供了丰富数据，但现有NLP研究主要关注单疾病识别，缺乏对多心理健康状况区分效果的系统评估。

Method: 研究首先构建了一个包含六种心理健康状况和对照组的Reddit帖子数据集，然后在相同条件下评估了五种transformer架构（BERT、RoBERTa等）与多种LSTM变体（带/不带注意力，使用上下文/静态嵌入）的性能。

Result: 实验结果显示transformer模型始终优于其他方法，RoBERTa在所有类别上达到91-99%的F1分数和准确率。带有BERT嵌入的注意力增强LSTM接近transformer性能（最高97% F1分数），且训练速度快2-3.5倍。

Conclusion: 这项研究为多类心理健康检测提供了首个全面基准，为模型选择提供了实用指导，并揭示了心理健康NLP系统实际部署中的准确性与效率权衡。

Abstract: Millions of people openly share mental health struggles on social media,
providing rich data for early detection of conditions such as depression,
bipolar disorder, etc. However, most prior Natural Language Processing (NLP)
research has focused on single-disorder identification, leaving a gap in
understanding the efficacy of advanced NLP techniques for distinguishing among
multiple mental health conditions. In this work, we present a large-scale
comparative study of state-of-the-art transformer versus Long Short-Term Memory
(LSTM)-based models to classify mental health posts into exclusive categories
of mental health conditions. We first curate a large dataset of Reddit posts
spanning six mental health conditions and a control group, using rigorous
filtering and statistical exploratory analysis to ensure annotation quality. We
then evaluate five transformer architectures (BERT, RoBERTa, DistilBERT,
ALBERT, and ELECTRA) against several LSTM variants (with or without attention,
using contextual or static embeddings) under identical conditions. Experimental
results show that transformer models consistently outperform the alternatives,
with RoBERTa achieving 91-99% F1-scores and accuracies across all classes.
Notably, attention-augmented LSTMs with BERT embeddings approach transformer
performance (up to 97% F1-score) while training 2-3.5 times faster, whereas
LSTMs using static embeddings fail to learn useful signals. These findings
represent the first comprehensive benchmark for multi-class mental health
detection, offering practical guidance on model selection and highlighting an
accuracy-efficiency trade-off for real-world deployment of mental health NLP
systems.

</details>


### [25] [ChemOrch: Empowering LLMs with Chemical Intelligence via Synthetic Instructions](https://arxiv.org/abs/2509.16543)
*Yue Huang,Zhengzhe Jiang,Xiaonan Luo,Kehan Guo,Haomin Zhuang,Yujun Zhou,Zhengqing Yuan,Xiaoqi Sun,Jules Schleinitz,Yanbo Wang,Shuhao Zhang,Mihir Surve,Nitesh V Chawla,Olaf Wiest,Xiangliang Zhang*

Main category: cs.CL

TL;DR: ChemOrch是一个为大型语言模型提供化学智能的框架，通过两阶段过程合成化学基础的指令-响应对，解决现有数据生成方法与化学信息层次化结构不匹配的问题。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏高质量的化学领域特定指令-响应数据集，且现有合成数据生成流程与化学信息的层次化和规则化结构存在不一致性，限制了LLMs在化学领域的应用。

Method: 采用两阶段流程：任务控制指令生成和工具感知响应构建。通过工具规划和蒸馏、基于工具的自我修复机制确保响应精度，并实现任务的可控多样性和难度级别。

Result: 1) 生成的指令数据质量高，具有优越的多样性和与化学约束的强对齐性；2) 可靠生成能更有效揭示LLMs化学弱点的评估任务；3) 使用生成数据进行微调显著提升了LLMs的化学能力。

Conclusion: ChemOrch代表了向可扩展和可验证的LLMs化学智能迈出的关键一步。

Abstract: Empowering large language models (LLMs) with chemical intelligence remains a
challenge due to the scarcity of high-quality, domain-specific
instruction-response datasets and the misalignment of existing synthetic data
generation pipelines with the inherently hierarchical and rule-governed
structure of chemical information. To address this, we propose ChemOrch, a
framework that synthesizes chemically grounded instruction-response pairs
through a two-stage process: task-controlled instruction generation and
tool-aware response construction. ChemOrch enables controllable diversity and
levels of difficulty for the generated tasks, and ensures response precision
through tool planning and distillation, and tool-based self-repair mechanisms.
The effectiveness of ChemOrch is evaluated based on: 1) the high quality of
generated instruction data, demonstrating superior diversity and strong
alignment with chemical constraints; 2) the reliable generation of evaluation
tasks that more effectively reveal LLM weaknesses in chemistry; and 3) the
significant improvement of LLM chemistry capabilities when the generated
instruction data are used for fine-tuning. Our work thus represents a critical
step toward scalable and verifiable chemical intelligence in LLMs.

</details>


### [26] [Rethinking the Role of Text Complexity in Language Model Pretraining](https://arxiv.org/abs/2509.16551)
*Dan John Velasco,Matthew Theodore Roque*

Main category: cs.CL

TL;DR: 本文研究了文本复杂度对语言模型预训练的影响，通过使用大语言模型简化文本内容，在不同规模模型上进行实验，发现模型容量与文本复杂度存在交互作用，且文本复杂度对下游任务的影响因任务类型而异。


<details>
  <summary>Details</summary>
Motivation: 探索文本复杂度（如句子长度、词汇选择、句子结构等表面特征）如何影响语言模型的预训练效果，以及能否仅从简化文本中学习有用的表示。

Method: 使用大语言模型简化人类撰写的文本，保持核心内容不变但降低表面复杂度，然后在不同规模（28M-500M）的因果模型上从头开始预训练，并在微调和零样本设置下进行评估。

Result: 困惑度对模型容量和文本复杂度的交互作用敏感——较小模型在简化文本上的性能下降较少；文本复杂度对微调评估影响不大；零样本评估表明简化文本有利于语言知识任务，而复杂文本更有利于需要世界知识和实体跟踪的任务。

Conclusion: 文本复杂度在语言模型预训练中具有重要影响，其效果取决于模型规模和下游任务类型，简化文本可能对特定任务有益，但复杂文本在处理需要深层次知识的任务时表现更佳。

Abstract: Improving pretraining data quality and size is known to boost downstream
performance, but the role of text complexity is less explored. Text complexity
refers to how hard a text is to read, and is typically estimated from surface
cues such as sentence length, word choice, and sentence structure. We reduce
surface-level complexity--shorter sentences, simpler words, simpler
structure--while keeping core text content close to constant, and ask: (1) How
does complexity affect language modeling across model sizes? (2) Can useful
representations be learned from simpler text alone? (3) How does pretraining
text complexity influence downstream language understanding? To answer these
questions, we simplify human-written texts using a large language model, then
pretrain causal models (28M-500M) from scratch on both original and simplified
data, and evaluate them in finetuning and zero-shot setups. We find that
perplexity is sensitive to the interaction between model capacity and text
complexity--smaller models degrade far less on simpler texts--while text
complexity has little impact on finetuning evaluations, with zero-shot
evaluations indicating that simpler texts benefit performance on linguistic
knowledge tasks, whereas more complex texts favor tasks requiring world
knowledge and entity tracking.

</details>


### [27] [MPCG: Multi-Round Persona-Conditioned Generation for Modeling the Evolution of Misinformation with LLMs](https://arxiv.org/abs/2509.16564)
*Jun Rong Brian Chong,Yixuan Tang,Anthony K. H. Tung*

Main category: cs.CL

TL;DR: MPCG是一个多轮次、人物角色条件化的框架，用于模拟错误信息如何被不同意识形态的代理人迭代重新解释，从而研究错误信息的演变过程。


<details>
  <summary>Details</summary>
Motivation: 当前错误信息检测方法隐含假设错误信息是静态的，但实际上错误信息在传播过程中会不断演变，适应不同受众的语言、框架和道德重点。

Method: 使用未经审查的大语言模型（LLM）在多轮次中生成特定人物角色的声明，每轮生成都以前一轮输出为条件，通过人类和LLM标注、认知努力指标、情感唤起指标等多种方法进行评估。

Result: 生成声明比原始声明需要更多认知努力，保持人物角色对齐的情感道德框架，语义漂移但保持主题连贯性，可行性率达77%，常用错误信息检测器的性能下降高达49.7%。

Conclusion: MPCG框架有效模拟了错误信息的动态演变过程，揭示了现有检测方法对动态错误信息的局限性，为研究错误信息传播提供了新工具。

Abstract: Misinformation evolves as it spreads, shifting in language, framing, and
moral emphasis to adapt to new audiences. However, current misinformation
detection approaches implicitly assume that misinformation is static. We
introduce MPCG, a multi-round, persona-conditioned framework that simulates how
claims are iteratively reinterpreted by agents with distinct ideological
perspectives. Our approach uses an uncensored large language model (LLM) to
generate persona-specific claims across multiple rounds, conditioning each
generation on outputs from the previous round, enabling the study of
misinformation evolution. We evaluate the generated claims through human and
LLM-based annotations, cognitive effort metrics (readability, perplexity),
emotion evocation metrics (sentiment analysis, morality), clustering,
feasibility, and downstream classification. Results show strong agreement
between human and GPT-4o-mini annotations, with higher divergence in fluency
judgments. Generated claims require greater cognitive effort than the original
claims and consistently reflect persona-aligned emotional and moral framing.
Clustering and cosine similarity analyses confirm semantic drift across rounds
while preserving topical coherence. Feasibility results show a 77% feasibility
rate, confirming suitability for downstream tasks. Classification results
reveal that commonly used misinformation detectors experience macro-F1
performance drops of up to 49.7%. The code is available at
https://github.com/bcjr1997/MPCG

</details>


### [28] [From Scores to Steps: Diagnosing and Improving LLM Performance in Evidence-Based Medical Calculations](https://arxiv.org/abs/2509.16584)
*Benlu Wang,Iris Xia,Yifan Zhang,Junda Wang,Feiyun Ouyang,Shuo Han,Arman Cohan,Hong Yu,Zonghai Yao*

Main category: cs.CL

TL;DR: 本文提出了一种更严格的医学计算评估方法，通过分步评估揭示LLMs在医学计算中的系统性错误，并开发了MedRaC模块化代理管道来显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有医学计算基准仅评估最终答案且容忍度较宽，忽视了系统性推理错误，可能导致严重的临床误判。需要更临床可信的评估方法。

Method: 1) 清理并重构MedCalc-Bench数据集，提出分步评估管道；2) 引入自动错误分析框架；3) 开发MedRaC模块化代理管道，结合检索增强生成和Python代码执行。

Result: GPT-4o的准确率从62.7%降至43.6%；MedRaC无需微调即可将不同LLMs的准确率从16.35%提升至53.19%。

Conclusion: 当前基准实践存在局限性，需要更临床可信的方法论。通过透明可转移的推理评估，使基于LLM的系统在真实医疗应用中更值得信赖。

Abstract: Large language models (LLMs) have demonstrated promising performance on
medical benchmarks; however, their ability to perform medical calculations, a
crucial aspect of clinical decision-making, remains underexplored and poorly
evaluated. Existing benchmarks often assess only the final answer with a wide
numerical tolerance, overlooking systematic reasoning failures and potentially
causing serious clinical misjudgments. In this work, we revisit medical
calculation evaluation with a stronger focus on clinical trustworthiness.
First, we clean and restructure the MedCalc-Bench dataset and propose a new
step-by-step evaluation pipeline that independently assesses formula selection,
entity extraction, and arithmetic computation. Under this granular framework,
the accuracy of GPT-4o drops from 62.7% to 43.6%, revealing errors masked by
prior evaluations. Second, we introduce an automatic error analysis framework
that generates structured attribution for each failure mode. Human evaluation
confirms its alignment with expert judgment, enabling scalable and explainable
diagnostics. Finally, we propose a modular agentic pipeline, MedRaC, that
combines retrieval-augmented generation and Python-based code execution.
Without any fine-tuning, MedRaC improves the accuracy of different LLMs from
16.35% up to 53.19%. Our work highlights the limitations of current benchmark
practices and proposes a more clinically faithful methodology. By enabling
transparent and transferable reasoning evaluation, we move closer to making
LLM-based systems trustworthy for real-world medical applications.

</details>


### [29] [Benchmarking Contextual and Paralinguistic Reasoning in Speech-LLMs: A Case Study with In-the-Wild Data](https://arxiv.org/abs/2509.16589)
*Qiongqiong Wang,Hardik Bhupendra Sailor,Tianchi Liu,Wenyu Zhang,Muhammad Huzaifah,Nattadaporn Lertcheva,Shuo Sun,Nancy F. Chen,Jinyang Wu,AiTi Aw*

Main category: cs.CL

TL;DR: CP-Bench是一个用于评估语音大语言模型在上下文副语言推理能力的基准测试，重点关注语音中情感和韵律等非语言线索的理解。


<details>
  <summary>Details</summary>
Motivation: 现有的语音-LLMs在转录和翻译任务上表现出色，但在理解副语言方面存在局限，而这些副语言特征对于社交和情感智能至关重要。

Method: 创建了两个精心策划的问答数据集，需要语言理解和共情能力。评估了开源和闭源的最先进语音-LLMs，并进行了不同问题类型的综合分析，对表现最好的两个模型进行了温度调优分析。

Result: 基准测试揭示了现有评估方法的关键差距，现有模型在副语言推理能力上存在明显不足。

Conclusion: CP-Bench为构建更具上下文感知能力和情感智能的语音-LLMs提供了重要见解，填补了当前评估体系的空白。

Abstract: Recent speech-LLMs have shown impressive performance in tasks like
transcription and translation, yet they remain limited in understanding the
paralinguistic aspects of speech crucial for social and emotional intelligence.
We propose CP-Bench, a benchmark for evaluating speech-LLMs on contextual
paralinguistic reasoning the integration of verbal content with non-verbal cues
like emotion and prosody. The benchmark includes two curated question answering
(QA) datasets requiring both linguistic and empathetic understanding. We
evaluate state-of-the-art speech-LLMs from both open and closed-source models
and perform a comprehensive analysis across different question types. The top
two models were further analyzed under temperature tuning to understand its
effect on this task. Our benchmark reveals a key gap in existing evaluations
and offers insights into building more context-aware and emotionally
intelligent speech-capable LLMs.

</details>


### [30] [From Uniform to Heterogeneous: Tailoring Policy Optimization to Every Token's Nature](https://arxiv.org/abs/2509.16591)
*Zheng Liu,Mengjie Liu,Siwei Wen,Mengzhang Cai,Bin Cui,Conghui He,Wentao Zhang*

Main category: cs.CL

TL;DR: HAPO是一种针对LLM推理增强的token感知强化学习算法，通过动态调整基于token熵的优化策略，解决了现有算法对所有token进行统一优化的问题。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习算法对所有token采用统一优化，忽略了它们在推理过程中的不同角色。为了解决这一局限性，需要开发能够根据token重要性进行差异化优化的方法。

Method: 提出异构自适应策略优化(HAPO)，包含：自适应温度采样调整采样温度、token级别组平均归一化优势值、差分优势重分配利用熵和重要性比率调节奖励、非对称自适应裁剪实现差异化概率调整。

Result: 在多个模型规模上的广泛实验表明，HAPO始终优于DAPO算法，实现了更精细的控制效果。

Conclusion: 通过将token级别处理嵌入到每个训练阶段，HAPO实现了对推理过程的细粒度控制，为LLM推理增强提供了有效的解决方案。

Abstract: Reinforcement Learning has emerged as the fundamental technique for enhancing
reasoning in LLMs. However, existing algorithms apply uniform optimization to
all tokens, ignoring their different roles in reasoning process. To address
this limitation, we introduce Heterogeneous Adaptive Policy Optimization
(HAPO), a comprehensive token-aware algorithm that dynamically adapts
optimization based on token entropy. For rollout sampling, we propose Adaptive
Temperature Sampling, which adjusts sampling temperature in real time,
promoting exploration at high-entropy tokens while preserving coherence at
low-entropy ones. For advantage calculation, we introduce Token Level Group
Average that normalizes advantages at token level, jointly accounting for
sequence-length as in token-mean loss while preserving non-biased treatment. We
then develop Differential Advantage Redistribution that leverages entropy and
importance ratios to modulate rewards-adjusting updates for tokens with clear
signals. For clipping loss, we design Asymmetric Adaptive Clipping, allowing
aggressive probability reduction for noisy low-entropy tokens while enabling
exploration for high-entropy tokens. Through systematic investigation between
entropy and training dynamics, we embedded token-level treatment into every
stages to achieve fine-grained control. Extensive experiments demonstrate that
HAPO consistently outperforms DAPO across multiple model scales. Our code can
be found in https://github.com/starriver030515/HAPO.

</details>


### [31] [Analyzing the Effects of Supervised Fine-Tuning on Model Knowledge from Token and Parameter Levels](https://arxiv.org/abs/2509.16596)
*Junjie Ye,Yuming Yang,Yang Nan,Shuo Li,Qi Zhang,Tao Gui,Xuanjing Huang,Peng Wang,Zhongchao Shi,Jianping Fan*

Main category: cs.CL

TL;DR: 本文研究发现，在大型语言模型的监督微调过程中，使用更多样本（1920个）反而比使用较少样本（240个）在闭卷问答任务上表现差14%，且参数更新中高达90%的部分对知识增强没有贡献。


<details>
  <summary>Details</summary>
Motivation: 当前对监督微调如何影响模型知识的研究不足，限制了我们对微调过程中知识变化行为的控制能力。

Method: 评估了LLaMA-2和LLaMA-3系列五个模型在闭卷问答任务上的表现，分析了不同微调数据量（240vs1920样本）和知识掌握程度的影响，并在token和参数层面进行了行为分析。

Result: 微调数据量增加反而导致性能下降14%，知识掌握程度变化引起超过12%的性能波动。参数分析显示90%的更新对知识增强无效，但恢复这些更新可以改善性能。

Conclusion: 研究结果为开发更有效的微调策略提供了实用指导，有助于更好地增强模型知识。

Abstract: Large language models (LLMs) acquire substantial world knowledge during
pre-training, which is further shaped by post-training techniques such as
supervised fine-tuning (SFT). However, the impact of SFT on a model's knowledge
remains underexplored, limiting our ability to control knowledge change
behavior in fine-tuned models. To address this gap, we evaluate closed-book
question answering (CBQA) performance across five LLMs from the LLaMA-2 and
LLaMA-3 families. Surprisingly, models fine-tuned on 1,920 samples perform up
to 14% worse than those fine-tuned on only 240 samples. Furthermore, varying
the level of knowledge mastery in the fine-tuning data leads to performance
fluctuations of over 12%. To investigate these effects, we analyze model
behavior at both the token and parameter levels. Our analysis reveals that up
to 90% of parameter updates during SFT do not contribute to knowledge
enhancement. Restoring these updates can improve performance on the CBQA task,
depending on the characteristics of the fine-tuning data. These insights offer
practical guidance for developing fine-tuning strategies that more effectively
strengthen model knowledge.

</details>


### [32] [MCP: A Control-Theoretic Orchestration Framework for Synergistic Efficiency and Interpretability in Multimodal Large Language Models](https://arxiv.org/abs/2509.16597)
*Luyan Zhang*

Main category: cs.CL

TL;DR: 提出基于模型-控制器-任务适应的三层协作框架（MCP），解决大模型在多轮推理和多模态协作中的计算效率低和可解释性不足问题


<details>
  <summary>Details</summary>
Motivation: 针对大模型在复杂任务中面临的计算效率低和可解释性不足问题，寻求新的技术路径来解决大模型实际应用的瓶颈

Method: 通过将大模型功能解耦为推理、生成和检索模块，结合强化学习驱动的动态路由算法和任务适应机制，实现控制理论与大模型动态推理的系统集成

Result: MCP框架在GLUE、COCO、ScienceQA等跨模态基准任务上性能提升15-30%，推理效率提高40%，通过Presenter层生成可解释中间结果，获得90%的人工可解释性评分

Conclusion: 该研究为解决大模型实际应用瓶颈提供了全新的技术路径

Abstract: Aiming at the problems of computational inefficiency and insufficient
interpretability faced by large models in complex tasks such as multi-round
reasoning and multi-modal collaboration, this study proposes a three-layer
collaboration framework based on model-controller-task adaptation (MCP). By
decoupling large model functions into reasoning, generation and retrieval
modules, and combining reinforcement learning-driven dynamic routing algorithms
and task adaptation mechanisms, the systematic integration of control theory
and large model dynamic reasoning is achieved for the first time. Experiments
show that the MCP framework improves the performance of cross-modal
benchmarking tasks, such as GLUE, COCO, ScienceQA, etc., by 15-30% compared
with the baseline model, improves the reasoning efficiency by 40%, and
generates the interpretable intermediate results through the Presenter layer,
obtaining 90% of the manual interpretability scores, which provides a brand-new
technological path to solve the bottleneck of the practical application of the
large model.

</details>


### [33] [PruneCD: Contrasting Pruned Self Model to Improve Decoding Factuality](https://arxiv.org/abs/2509.16598)
*Byeongho Yu,Changhun Lee,Jungyu Jin,Eunhyeok Park*

Main category: cs.CL

TL;DR: PruneCD是一种新的对比解码方法，通过层剪枝而非早期退出来构建业余模型，以解决DoLa方法中早期退出logits平坦、幅度低的问题，从而更有效地缓解大语言模型的幻觉问题。


<details>
  <summary>Details</summary>
Motivation: DoLa方法利用同一模型的早期退出logits作为对比先验来缓解幻觉问题，但研究发现这些早期退出logits往往平坦、幅度低，无法反映有意义的对比。

Method: 提出PruneCD方法，通过层剪枝而非早期退出来构建业余模型，这种设计产生更具信息量和良好对齐的logits，实现更有效的对比解码。

Result: 通过定性和定量分析证明，PruneCD在最小推理开销下持续提高事实性。

Conclusion: PruneCD为缓解LLM幻觉提供了一种鲁棒且实用的方法。

Abstract: To mitigate the hallucination problem in large language models, DoLa exploits
early exit logits from the same model as a contrastive prior. However, we found
that these early exit logits tend to be flat, low in magnitude, and fail to
reflect meaningful contrasts. To address this, we propose PruneCD, a novel
contrastive decoding method that constructs the amateur model via layer pruning
rather than early exit. This design leads to more informative and well-aligned
logits, enabling more effective contrastive decoding. Through qualitative and
quantitative analyses, we demonstrate that PruneCD consistently improves
factuality with minimal inference overhead, offering a robust and practical
approach to mitigating hallucinations in LLMs.

</details>


### [34] [Computational-Assisted Systematic Review and Meta-Analysis (CASMA): Effect of a Subclass of GnRH-a on Endometriosis Recurrence](https://arxiv.org/abs/2509.16599)
*Sandro Tsang*

Main category: cs.CL

TL;DR: 本研究评估了一种基于信息检索的工作流程，旨在提高系统评价的效率、透明度和可重复性。以子宫内膜异位症复发为案例，通过混合方法整合PRISMA指南和计算技术，显著减少了筛选工作量。


<details>
  <summary>Details</summary>
Motivation: 证据合成是循证医学的基础，但面对海量文献，传统方法难以应对。本研究旨在开发一个高效、透明、可重复的系统评价工作流程，以解决文献检索和筛选的挑战。

Method: 采用混合方法整合PRISMA指南和计算技术。应用半自动去重技术高效过滤记录，然后进行人工筛选。针对多臂试验的单元分析错误采用了改进的分割方法。

Result: 工作流程显著减少了筛选工作量，仅用11天就获取并筛选了812条记录。最终纳入7项RCT研究，涉及841名患者。汇总随机效应模型显示风险比为0.64（95% CI 0.48-0.86），子宫内膜异位症复发风险降低36%。

Conclusion: 该研究证明了基于信息检索的医学证据合成工作流程的有效性。该方法不仅获得了有价值的临床结果，还为加速系统评价过程提供了框架，能够推广到其他复杂的系统评价中。

Abstract: Background: Evidence synthesis facilitates evidence-based medicine. Without
information retrieval techniques, this task is impossible due to the vast and
expanding literature. Objective: Building on prior work, this study evaluates
an information retrieval-driven workflow to enhance the efficiency,
transparency, and reproducibility of systematic reviews. We use endometriosis
recurrence as an ideal case due to its complex and ambiguous literature.
Methods: Our hybrid approach integrates PRISMA guidelines with computational
techniques. We applied semi-automated deduplication to efficiently filter
records before manual screening. This workflow synthesized evidence from
randomised controlled trials on the efficacy of a subclass of
gonadotropin-releasing hormone agonists (GnRH'as). A modified splitting method
addressed unit-of-analysis errors in multi-arm trials. Results: Our workflow
efficiently reduced the screening workload. It took only 11 days to fetch and
filter 812 records. Seven RCTs were eligible, providing evidence from 841
patients in 4 countries. The pooled random-effects model yielded a Risk Ratio
(RR) of 0.64 (95% CI (0.48 to 0.86)), with non-significant heterogeneity
($I^2=0.00\%$, $\tau=0.00$); i.e., a 36% reduction in endometriosis recurrence.
Sensitivity analyses and bias assessments supported the robustness of our
findings. Conclusion: This study demonstrates an information-retrieval-driven
workflow for medical evidence synthesis. Our approach yields valuable clinical
results while providing a framework for accelerating the systematic review
process. It bridges the gap between clinical research and computer science and
can be generalized to other complex systematic reviews.

</details>


### [35] [LLMsPark: A Benchmark for Evaluating Large Language Models in Strategic Gaming Contexts](https://arxiv.org/abs/2509.16610)
*Junhao Chen,Jingbo Sun,Xiang Li,Haidong Xin,Yuhao Xue,Yibin Xu,Hao Zhao*

Main category: cs.CL

TL;DR: LLMsPark是一个基于博弈论的评估平台，用于评估大型语言模型在游戏理论环境中的决策策略和社交行为，通过多智能体环境探索战略深度。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在多样化任务中的进步，需要超越单一指标的全面评估。为了全面评估LLM的智能，必须检查它们的交互动态和战略行为。

Method: 开发了LLMsPark平台，在经典博弈论设置中评估15个领先LLM（商业和开源）的决策策略和社交行为，使用排行榜排名和评分机制进行交叉评估。

Result: 更高的分数反映了更强的推理和战略能力，揭示了不同模型之间的明显行为模式和性能差异。

Conclusion: 这项工作为评估LLM的战略智能引入了新的视角，丰富了现有基准测试，并拓宽了在交互式博弈论场景中的评估范围。

Abstract: As large language models (LLMs) advance across diverse tasks, the need for
comprehensive evaluation beyond single metrics becomes increasingly important.
To fully assess LLM intelligence, it is crucial to examine their interactive
dynamics and strategic behaviors. We present LLMsPark, a game theory-based
evaluation platform that measures LLMs' decision-making strategies and social
behaviors in classic game-theoretic settings, providing a multi-agent
environment to explore strategic depth. Our system cross-evaluates 15 leading
LLMs (both commercial and open-source) using leaderboard rankings and scoring
mechanisms. Higher scores reflect stronger reasoning and strategic
capabilities, revealing distinct behavioral patterns and performance
differences across models. This work introduces a novel perspective for
evaluating LLMs' strategic intelligence, enriching existing benchmarks and
broadening their assessment in interactive, game-theoretic scenarios. The
benchmark and rankings are publicly available at https://llmsparks.github.io/.

</details>


### [36] [Redefining Experts: Interpretable Decomposition of Language Models for Toxicity Mitigation](https://arxiv.org/abs/2509.16660)
*Zuhair Hasan Shaik,Abdullah Mazhar,Aseem Srivastava,Md Shad Akhtar*

Main category: cs.CL

TL;DR: 该论文提出了一种基于特征值分解的新方法EigenShift，用于抑制大型语言模型生成有毒内容，相比现有的神经元级干预方法更加稳定和精确。


<details>
  <summary>Details</summary>
Motivation: 现有毒性缓解方法主要操纵单个神经元激活，但存在不稳定性、上下文依赖性问题，并且常常损害模型的核心语言能力。

Method: 提出EigenShift方法，基于语言模型最终输出层的特征值分解，选择性针对生成对齐的组件进行干预，无需额外训练或微调。

Result: 在Jigsaw和ToxiCN数据集上的实验表明，聚合的层级特征比单个神经元提供更稳健的信号，能够精确抑制毒性而不损害语言能力。

Conclusion: EigenShift方法提供了一种理论严谨、计算成本低且无需训练的毒性抑制方案，解决了现有方法的局限性。

Abstract: Large Language Models have demonstrated impressive fluency across diverse
tasks, yet their tendency to produce toxic content remains a critical challenge
for AI safety and public trust. Existing toxicity mitigation approaches
primarily manipulate individual neuron activations, but these methods suffer
from instability, context dependence, and often compromise the model's core
language abilities. To address these shortcomings, we investigate three key
questions: the stability of neuron-level toxicity indicators, the advantages of
structural (layer-wise) representations, and the interpretability of mechanisms
driving toxic generation. Through extensive experiments on Jigsaw and ToxiCN
datasets, we show that aggregated layer-wise features provide more robust
signals than single neurons. Moreover, we observe conceptual limitations in
prior works that conflate toxicity detection experts and generation experts
within neuron-based interventions. To mitigate this, we propose a novel
principled intervention technique, EigenShift, based on eigen-decomposition of
the language model's final output layer. This method selectively targets
generation-aligned components, enabling precise toxicity suppression without
impairing linguistic competence. Our method requires no additional training or
fine-tuning, incurs minimal computational cost, and is grounded in rigorous
theoretical analysis.

</details>


### [37] [Robust Native Language Identification through Agentic Decomposition](https://arxiv.org/abs/2509.16666)
*Ahmet Yavuz Uluslu,Tannon Kew,Tilia Ellendorff,Gerold Schneider,Rico Sennrich*

Main category: cs.CL

TL;DR: 本文提出了一种基于法医语言学启发的智能体NLI管道，通过专门智能体积累和分类多样化语言证据，再由协调智能体综合评估，显著提升了原生语言识别的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有LLMs在原生语言识别中过度依赖表面上下文线索（如姓名、地点、文化刻板印象）而非真正的语言模式，导致预测容易被误导性提示改变，需要更可靠的方法。

Method: 设计了一个智能体NLI管道：专门智能体负责积累和分类语言证据，目标感知协调智能体进行最终综合评估和预测。

Result: 在两个基准数据集上，该方法显著提高了NLI对误导性上下文线索的鲁棒性和性能一致性，优于标准提示方法。

Conclusion: 基于法医语言学启发的智能体方法能够有效解决LLMs在原生语言识别中的脆弱性问题，提供更可靠的预测结果。

Abstract: Large language models (LLMs) often achieve high performance in native
language identification (NLI) benchmarks by leveraging superficial contextual
clues such as names, locations, and cultural stereotypes, rather than the
underlying linguistic patterns indicative of native language (L1) influence. To
improve robustness, previous work has instructed LLMs to disregard such clues.
In this work, we demonstrate that such a strategy is unreliable and model
predictions can be easily altered by misleading hints. To address this problem,
we introduce an agentic NLI pipeline inspired by forensic linguistics, where
specialized agents accumulate and categorize diverse linguistic evidence before
an independent final overall assessment. In this final assessment, a goal-aware
coordinating agent synthesizes all evidence to make the NLI prediction. On two
benchmark datasets, our approach significantly enhances NLI robustness against
misleading contextual clues and performance consistency compared to standard
prompting methods.

</details>


### [38] [Reinforcement Learning Meets Large Language Models: A Survey of Advancements and Applications Across the LLM Lifecycle](https://arxiv.org/abs/2509.16679)
*Keliang Liu,Dingkang Yang,Ziyun Qian,Weijie Yin,Yuchi Wang,Hongsheng Li,Jun Liu,Peng Zhai,Yang Liu,Lihua Zhang*

Main category: cs.CL

TL;DR: 这篇论文系统综述了强化学习在大型语言模型全生命周期中的应用，特别是可验证奖励的强化学习（RLVR），涵盖了预训练、对齐微调和强化推理等阶段，并整理了相关数据集、评估基准和开源工具。


<details>
  <summary>Details</summary>
Motivation: 现有综述对强化学习增强LLMs的覆盖范围有限，未能全面总结RL在LLM全生命周期中的运作方式。本文旨在系统回顾RL赋能LLMs的理论和实践进展。

Method: 首先介绍RL基础理论，然后详细阐述RL在LLM不同阶段的应用策略，包括预训练、对齐微调和强化推理。特别强调强化推理阶段的RL方法是推动模型推理能力达到极限的关键驱动力。

Result: 整理了现有的RL微调数据集和评估基准，包括人工标注数据集、AI辅助偏好数据和程序验证式语料库，并回顾了主流开源工具和训练框架。

Conclusion: 分析了RL增强LLMs领域的未来挑战和趋势，旨在为研究者和从业者提供RL与LLMs交叉领域的最新发展和前沿趋势，促进更智能、可泛化和安全的LLMs发展。

Abstract: In recent years, training methods centered on Reinforcement Learning (RL)
have markedly enhanced the reasoning and alignment performance of Large
Language Models (LLMs), particularly in understanding human intents, following
user instructions, and bolstering inferential strength. Although existing
surveys offer overviews of RL augmented LLMs, their scope is often limited,
failing to provide a comprehensive summary of how RL operates across the full
lifecycle of LLMs. We systematically review the theoretical and practical
advancements whereby RL empowers LLMs, especially Reinforcement Learning with
Verifiable Rewards (RLVR). First, we briefly introduce the basic theory of RL.
Second, we thoroughly detail application strategies for RL across various
phases of the LLM lifecycle, including pre-training, alignment fine-tuning, and
reinforced reasoning. In particular, we emphasize that RL methods in the
reinforced reasoning phase serve as a pivotal driving force for advancing model
reasoning to its limits. Next, we collate existing datasets and evaluation
benchmarks currently used for RL fine-tuning, spanning human-annotated
datasets, AI-assisted preference data, and program-verification-style corpora.
Subsequently, we review the mainstream open-source tools and training
frameworks available, providing clear practical references for subsequent
research. Finally, we analyse the future challenges and trends in the field of
RL-enhanced LLMs. This survey aims to present researchers and practitioners
with the latest developments and frontier trends at the intersection of RL and
LLMs, with the goal of fostering the evolution of LLMs that are more
intelligent, generalizable, and secure.

</details>


### [39] [EG-MLA: Embedding-Gated Multi-head Latent Attention for Scalable and Efficient LLMs](https://arxiv.org/abs/2509.16686)
*Zhengge Cai,Haowen Hou*

Main category: cs.CL

TL;DR: EG-MLA是一种新型注意力机制，通过在潜在空间中引入嵌入门控机制，进一步减少KV缓存大小并增强表示表达能力，相比MHA减少91.6%缓存，相比MLA提升准确性并节省59.9%内存。


<details>
  <summary>Details</summary>
Motivation: 减少KV缓存大小是实现大型语言模型高效推理的关键步骤，虽然MLA已实现显著压缩，但进一步压缩空间有限且会带来性能损失。

Method: 提出嵌入门控多头潜在注意力（EG-MLA），在MLA基础上引入token特定的嵌入门控机制，在潜在空间中对压缩的KV向量进行细粒度调制。

Result: 相比MHA实现91.6%的KV缓存减少且性能损失可忽略；相比MLA在各种推理基准上持续提升任务准确性，同时实现高达59.9%的额外内存节省。

Conclusion: EG-MLA被证明是一种内存和计算效率高的注意力机制，能够在大规模LLM部署中实现可扩展的高性能推理。

Abstract: Reducing the key-value (KV) cache size is a crucial step toward enabling
efficient inference in large language models (LLMs), especially under latency
and memory constraints. While Multi-Head Attention (MHA) offers strong
representational power, it incurs significant memory overhead. Recent work on
Multi-head Latent Attention (MLA) mitigates this by compressing KV
representations into a shared latent space, achieving a better trade-off
between performance and cache efficiency. While MLA already achieves
significant KV cache reduction, the scope for further compression remains
limited without performance loss. In this paper, we propose
\textbf{Embedding-Gated Multi-head Latent Attention (EG-MLA)}, a novel
extension of MLA that further reduces KV cache size while enhancing
representational expressiveness. EG-MLA introduces a token-specific embedding
gating mechanism applied in the latent space, enabling fine-grained modulation
of compressed KV vectors with minimal additional computation. Compared to MHA,
EG-MLA achieves over 91.6\% reduction in KV cache size with negligible
performance degradation. Relative to MLA, EG-MLA consistently improves task
accuracy across diverse reasoning benchmarks while achieving up to 59.9\%
additional memory savings. Our theoretical analysis highlights how embedding
gating induces implicit high-order interactions, and empirical evaluations
demonstrate robust generalization across model scales and compression regimes.
Notably, we successfully scale EG-MLA to over 1 billion parameters,
demonstrating its practical viability for large-scale LLM deployment. These
results establish EG-MLA as a memory- and compute-efficient attention mechanism
that enables scalable, high-performance inference in modern LLMs.

</details>


### [40] [Decoding Uncertainty: The Impact of Decoding Strategies for Uncertainty Estimation in Large Language Models](https://arxiv.org/abs/2509.16696)
*Wataru Hashimoto,Hidetaka Kamigaito,Taro Watanabe*

Main category: cs.CL

TL;DR: 该研究探讨了不同解码策略对大型语言模型不确定性估计的影响，发现对比搜索策略在偏好对齐的LLMs中能提供更好的不确定性估计，但在仅经过监督微调而未明确对齐的模型中效果不一。


<details>
  <summary>Details</summary>
Motivation: 解码策略通过操纵语言模型输出的概率分布，会影响生成质量和不确定性。本研究旨在系统评估不同解码策略如何影响LLMs的不确定性估计能力。

Method: 通过实验比较多种解码策略（特别是对比搜索策略）在不同类型LLMs（偏好对齐模型和仅监督微调模型）上的不确定性估计表现。

Result: 实验表明，对比搜索策略在缓解重复生成的同时，在偏好对齐的LLMs中平均能提供更好的不确定性估计。但对于仅经过监督微调而未明确对齐的模型，这些策略的益处有时会出现分歧。

Conclusion: 解码策略的选择对LLMs的不确定性估计有显著影响，对比搜索策略在偏好对齐模型中表现最佳，但策略效果取决于模型的对齐程度。

Abstract: Decoding strategies manipulate the probability distribution underlying the
output of a language model and can therefore affect both generation quality and
its uncertainty. In this study, we investigate the impact of decoding
strategies on uncertainty estimation in Large Language Models (LLMs). Our
experiments show that Contrastive Search, which mitigates repetition, yields
better uncertainty estimates on average across a range of preference-aligned
LLMs. In contrast, the benefits of these strategies sometimes diverge when the
model is only post-trained with supervised fine-tuning, i.e. without explicit
alignment.

</details>


### [41] [OPEN-THEATRE: An Open-Source Toolkit for LLM-based Interactive Drama](https://arxiv.org/abs/2509.16713)
*Tianyang Xu,Hongqiu Wu,Weiqi Wu,Hai Zhao*

Main category: cs.CL

TL;DR: Open-Theatre是一个开源工具包，用于体验和定制基于LLM的互动戏剧，解决了该领域缺乏标准化平台的问题。


<details>
  <summary>Details</summary>
Motivation: LLM互动戏剧是一个新兴领域，但由于缺乏设计良好的开发平台，研究人员难以复制、扩展和研究此类系统。

Method: 采用高效的多智能体架构和分层检索式记忆系统，增强叙事连贯性和长期行为真实性，并提供高度可配置的流水线。

Result: 开发了首个开源工具包Open-Theatre，为研究人员提供了开发和优化新方法的便捷平台。

Conclusion: Open-Theatre降低了LLM互动戏剧研究的门槛，促进了该领域的发展。

Abstract: LLM-based Interactive Drama introduces a novel dialogue scenario in which the
player immerses into a character and engages in a dramatic story by interacting
with LLM agents. Despite the fact that this emerging area holds significant
promise, it remains largely underexplored due to the lack of a well-designed
playground to develop a complete drama. This makes a significant barrier for
researchers to replicate, extend, and study such systems. Hence, we present
Open-Theatre, the first open-source toolkit for experiencing and customizing
LLM-based interactive drama. It refines prior work with an efficient
multi-agent architecture and a hierarchical retrieval-based memory system,
designed to enhance narrative coherence and realistic long-term behavior in
complex interactions. In addition, we provide a highly configurable pipeline,
making it easy for researchers to develop and optimize new approaches.

</details>


### [42] [Semi-Supervised Synthetic Data Generation with Fine-Grained Relevance Control for Short Video Search Relevance Modeling](https://arxiv.org/abs/2509.16717)
*Haoran Li,Zhiming Su,Junyan Yao,Enwei Zhang,Yang Ji,Yan Chen,Kan Zhou,Chao Feng,Jiao Ran*

Main category: cs.CL

TL;DR: 本文提出了一种半监督合成数据管道，用于生成具有可控相关性标签的中文短视频数据，解决了现有提示合成方法在领域特定数据分布和细粒度相关性多样性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有基于提示的合成方法难以捕捉领域特定的数据分布，特别是在数据稀缺的领域，并且经常忽略细粒度的相关性多样性。

Method: 提出半监督合成数据管道，通过两个协同训练的模型生成具有可控相关性标签的领域自适应短视频数据，特别为代表性不足的中间相关性标签合成样本。

Result: 离线实验显示，使用合成数据训练的嵌入模型优于基于提示生成或普通监督微调的数据。在线A/B测试中，点击率提升1.45%，强相关性比率提升4.9%，图像用户渗透率提升0.1054%。

Conclusion: 在训练数据中融入更多样化的细粒度相关性级别可以增强模型对细微语义差异的敏感性，凸显了细粒度相关性监督在嵌入学习中的价值。

Abstract: Synthetic data is widely adopted in embedding models to ensure diversity in
training data distributions across dimensions such as difficulty, length, and
language. However, existing prompt-based synthesis methods struggle to capture
domain-specific data distributions, particularly in data-scarce domains, and
often overlook fine-grained relevance diversity. In this paper, we present a
Chinese short video dataset with 4-level relevance annotations, filling a
critical resource void. Further, we propose a semi-supervised synthetic data
pipeline where two collaboratively trained models generate domain-adaptive
short video data with controllable relevance labels. Our method enhances
relevance-level diversity by synthesizing samples for underrepresented
intermediate relevance labels, resulting in a more balanced and semantically
rich training data set. Extensive offline experiments show that the embedding
model trained on our synthesized data outperforms those using data generated
based on prompting or vanilla supervised fine-tuning(SFT). Moreover, we
demonstrate that incorporating more diverse fine-grained relevance levels in
training data enhances the model's sensitivity to subtle semantic distinctions,
highlighting the value of fine-grained relevance supervision in embedding
learning. In the search enhanced recommendation pipeline of Douyin's
dual-column scenario, through online A/B testing, the proposed model increased
click-through rate(CTR) by 1.45%, raised the proportion of Strong Relevance
Ratio (SRR) by 4.9%, and improved the Image User Penetration Rate (IUPR) by
0.1054%.

</details>


### [43] [Time to Revist Exact Match](https://arxiv.org/abs/2509.16720)
*Auss Abbood,Zaiqiao Meng,Nigel Collier*

Main category: cs.CL

TL;DR: 本文提出将时间问答任务重新定义为数值估计问题，引入TempAnswerQA基准，并使用sMAPE和MASE等预测指标来评估模型性能，发现传统精确匹配评估方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统的时间问答评估使用精确匹配方法，无法区分小错误和大错误，不能充分反映模型的时间推理能力。

Method: 构建TempAnswerQA基准数据集，采用对称平均绝对百分比误差和平均绝对缩放误差等预测指标来评估模型的时间推理性能。

Result: 研究发现误差大小与精确匹配得分之间存在解耦现象，某些模型虽然精确匹配得分低但误差小，反之亦然。模型最常见的错误是与真实值仅相差±1。

Conclusion: 时间问答任务需要专门的评估指标，sMAPE和MASE能够更准确地评估模型的时间推理能力，特别是对于接近正确答案的预测。

Abstract: Temporal question answering is an established method for evaluating temporal
reasoning in large language models. Expected answers are often numeric (e.g.,
dates or durations), yet model responses are evaluated like regular text with
exact match (EM), unable to distinguish small from large errors. In this
investigative work, we frame temporal question answering as a numerical
estimation task to assess the shortcomings of EM. We introduce TempAnswerQA, a
benchmark distilled from Test of Time and TempTabQA, where all questions
require a numerical, temporal answer, allowing us to evaluate models beyond EM.
We use the forecasting metrics symmetric mean absolute percentage error (sMAPE)
and mean absolute scaled error (MASE). With sMAPE, we find that error size and
EM are decoupled. Models with low EM still have low sMAPE (both ~20%), and some
models have high sMAPE despite high EM. Scaling errors by the deviation of the
ground truth data with MASE reshuffles model rankings compared to EM, revealing
gaps in models' understanding of temporal domain knowledge, especially when
trained with synthetic data. Lastly, the models' most frequent error is to
deviate by only $\pm1$ from the ground truth. sMAPE and MASE, unlike EM,
adequately weight these errors. Our findings underscore the need for
specialised metrics for temporal QA tasks. Code and data are available on
https://github.com/aauss/temporal-answer-qa.

</details>


### [44] [A Multi-Level Benchmark for Causal Language Understanding in Social Media Discourse](https://arxiv.org/abs/2509.16722)
*Xiaohan Ding,Kaike Ping,Buse Çarık,Eugenia Rho*

Main category: cs.CL

TL;DR: CausalTalk是一个多级因果语言数据集，包含2020-2024年Reddit上关于COVID-19公共卫生讨论的帖子，标注了10120个帖子，涵盖四个因果任务：二元因果分类、显隐因果区分、因果跨度提取和因果要点生成。


<details>
  <summary>Details</summary>
Motivation: 现有数据集主要关注结构化文本中的显式因果关系，对社交媒体等非正式文本中的隐式因果表达检测支持有限。

Method: 构建包含专家标注的金标准和GPT-4o生成、人工验证的银标准标注的多级数据集，涵盖四个因果分析任务。

Result: CausalTalk数据集连接了细粒度因果检测和基于要点的推理，为研究社交媒体中的因果推理提供了丰富资源。

Conclusion: 该数据集填补了非正式文本中因果语言理解的空白，支持判别式和生成式模型的基准测试，促进了社交媒体语境下因果推理的研究。

Abstract: Understanding causal language in informal discourse is a core yet
underexplored challenge in NLP. Existing datasets largely focus on explicit
causality in structured text, providing limited support for detecting implicit
causal expressions, particularly those found in informal, user-generated social
media posts. We introduce CausalTalk, a multi-level dataset of five years of
Reddit posts (2020-2024) discussing public health related to the COVID-19
pandemic, among which 10120 posts are annotated across four causal tasks: (1)
binary causal classification, (2) explicit vs. implicit causality, (3)
cause-effect span extraction, and (4) causal gist generation. Annotations
comprise both gold-standard labels created by domain experts and
silver-standard labels generated by GPT-4o and verified by human annotators.
CausalTalk bridges fine-grained causal detection and gist-based reasoning over
informal text. It enables benchmarking across both discriminative and
generative models, and provides a rich resource for studying causal reasoning
in social media contexts.

</details>


### [45] [Angular Dispersion Accelerates $k$-Nearest Neighbors Machine Translation](https://arxiv.org/abs/2509.16729)
*Evgeniia Tokarchuk,Sergey Troshin,Vlad Niculae*

Main category: cs.CL

TL;DR: 本文提出通过改善神经网络隐藏表示的角分散性来加速k近邻机器翻译的近似检索过程，同时略微提升翻译质量。


<details>
  <summary>Details</summary>
Motivation: k-NN MT方法虽然能提升翻译性能，但其近似检索算法在大型数据存储中仍然是性能瓶颈，现有研究主要关注减少数据存储规模或检索次数，而本文探索了基于检索数据结构性能特性的正交方向。

Method: 通过鼓励神经网络上下文隐藏表示的角分散性，改善近似k-NN MT检索数据结构的平衡性，从而加速检索过程。

Result: 改进分散性能够加速检索过程，同时略微改善翻译质量。

Conclusion: 通过优化隐藏表示的角分散性，可以在不减少数据存储规模或检索次数的情况下有效提升k-NN MT的性能，这是一个与现有研究方向正交的有效方法。

Abstract: Augmenting neural machine translation with external memory at decoding time,
in the form of k-nearest neighbors machine translation ($k$-NN MT), is a
well-established strategy for increasing translation performance. $k$-NN MT
retrieves a set of tokens that occurred in the most similar contexts recorded
in a prepared data store, using hidden state representations of translation
contexts as vector lookup keys. One of the main disadvantages of this method is
the high computational cost and memory requirements. Since an exhaustive search
is not feasible in large data stores, practitioners commonly use approximate
$k$-NN MT lookup, yet even such algorithms are a bottleneck. In contrast to
research directions seeking to accelerate $k$-NN MT by reducing data store size
or the number of lookup calls, we pursue an orthogonal direction based on the
performance properties of approximate $k$-NN MT lookup data structures. In
particular, we propose to encourage angular dispersion of the neural hidden
representations of contexts. We show that improving dispersion leads to better
balance in the retrieval data structures, accelerating retrieval and slightly
improving translations.

</details>


### [46] [The Sound of Syntax: Finetuning and Comprehensive Evaluation of Language Models for Speech Pathology](https://arxiv.org/abs/2509.16765)
*Fagun Patel,Duc Q. Nguyen,Sang T. Truong,Jody Vaynshtok,Sanmi Koyejo,Nick Haber*

Main category: cs.CL

TL;DR: 该论文开发了首个针对语音语言病理学的多模态语言模型综合基准，评估了15个最先进模型在5个核心应用场景下的表现，发现现有模型存在系统性差异且没有单一模型在所有任务中表现最佳。


<details>
  <summary>Details</summary>
Motivation: 美国有340万儿童需要语音障碍干预，但语音语言病理学家数量严重不足，急需技术支持来提高工作效率。目前多模态语言模型在临床环境中的性能表现尚未得到充分研究。

Method: 与领域专家合作开发了语音语言病理学中多模态语言模型的应用分类法，构建了包含5,000个手动标注数据点的综合基准，进行了鲁棒性和敏感性测试，评估了15个最先进模型，并研究了领域特定数据的微调效果。

Result: 评估显示没有单一模型在所有任务中表现一致最佳；发现模型在男性说话者上表现更好；思维链提示在具有大标签空间和窄决策边界的分类任务中可能降低性能；领域特定数据微调可使性能提升30%以上。

Conclusion: 当前多模态语言模型在语音语言病理学应用中既有潜力也存在局限性，需要进一步研究和针对性开发。

Abstract: According to the U.S. National Institutes of Health, more than 3.4 million
children experience speech disorders that require clinical intervention. The
number of speech-language pathologists (SLPs) is roughly 20 times fewer than
the number of affected children, highlighting a significant gap in children's
care and a pressing need for technological support that improves the
productivity of SLPs. State-of-the-art multimodal language models (MLMs) show
promise for supporting SLPs, but their use remains underexplored largely due to
a limited understanding of their performance in high-stakes clinical settings.
To address this gap, we collaborate with domain experts to develop a taxonomy
of real-world use cases of MLMs in speech-language pathologies. Building on
this taxonomy, we introduce the first comprehensive benchmark for evaluating
MLM across five core use cases, each containing 1,000 manually annotated data
points. This benchmark includes robustness and sensitivity tests under various
settings, including background noise, speaker gender, and accent. Our
evaluation of 15 state-of-the-art MLMs reveals that no single model
consistently outperforms others across all tasks. Notably, we find systematic
disparities, with models performing better on male speakers, and observe that
chain-of-thought prompting can degrade performance on classification tasks with
large label spaces and narrow decision boundaries. Furthermore, we study
fine-tuning MLMs on domain-specific data, achieving improvements of over 30%
compared to base models. These findings highlight both the potential and
limitations of current MLMs for speech-language pathology applications,
underscoring the need for further research and targeted development.

</details>


### [47] [MoRoVoc: A Large Dataset for Geographical Variation Identification of the Spoken Romanian Language](https://arxiv.org/abs/2509.16781)
*Andrei-Marius Avram,Ema-Ioana Bănescu,Anda-Teodora Robea,Dumitru-Clementin Cercel,Mihaela-Claudia Cercel*

Main category: cs.CL

TL;DR: MoRoVoc是最大的罗马尼亚语口语区域变异分析数据集，包含93小时音频和88,192个样本，平衡了罗马尼亚和摩尔多瓦的语音数据。论文提出了多目标对抗训练框架，将人口属性作为对抗目标，通过元学习动态调整对抗系数。


<details>
  <summary>Details</summary>
Motivation: 解决罗马尼亚语口语区域变异分析缺乏大规模数据集的问题，并开发能够区分主要任务同时保持对次要属性不变性的语音模型。

Method: 提出多目标对抗训练框架，将年龄和性别等人口属性作为对抗目标，使用元学习动态调整对抗系数来优化模型性能。

Result: Wav2Vec2-Base在使用性别作为对抗目标时，罗马尼亚语变异识别准确率达到78.21%；Wav2Vec2-Large在使用方言和年龄作为对抗目标时，性别分类准确率达到93.08%。

Conclusion: MoRoVoc数据集和提出的多目标对抗训练框架在罗马尼亚语口语分析任务中取得了显著效果，证明了该方法在语音模型优化中的有效性。

Abstract: This paper introduces MoRoVoc, the largest dataset for analyzing the regional
variation of spoken Romanian. It has more than 93 hours of audio and 88,192
audio samples, balanced between the Romanian language spoken in Romania and the
Republic of Moldova. We further propose a multi-target adversarial training
framework for speech models that incorporates demographic attributes (i.e., age
and gender of the speakers) as adversarial targets, making models
discriminative for primary tasks while remaining invariant to secondary
attributes. The adversarial coefficients are dynamically adjusted via
meta-learning to optimize performance. Our approach yields notable gains:
Wav2Vec2-Base achieves 78.21% accuracy for the variation identification of
spoken Romanian using gender as an adversarial target, while Wav2Vec2-Large
reaches 93.08% accuracy for gender classification when employing both dialect
and age as adversarial objectives.

</details>


### [48] [Domain-Adaptive Pre-Training for Arabic Aspect-Based Sentiment Analysis: A Comparative Study of Domain Adaptation and Fine-Tuning Strategies](https://arxiv.org/abs/2509.16788)
*Salha Alyami,Amani Jamal,Areej Alhothali*

Main category: cs.CL

TL;DR: 本文提出了一种针对阿拉伯语方面情感分析（ABSA）的领域自适应预训练方法，通过比较特征提取、全微调和适配器微调等策略，发现适配器微调在计算效率和性能方面表现最佳，但模型预测和数据集标注仍存在挑战。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语ABSA面临标注数据稀缺的问题，现有基于BERT的预训练模型使用事实数据可能引入领域偏差，目前尚无研究将自适应预训练应用于阿拉伯语上下文模型的ABSA任务。

Method: 采用领域自适应预训练方法，针对方面情感分类（ASC）和意见目标表达（OTE）提取任务，比较了特征提取、全微调和适配器微调三种微调策略，使用多个适应语料库和上下文模型。

Result: 领域自适应预训练带来适度改进，适配器微调在计算效率上表现优异且达到竞争性结果。但错误分析揭示了模型预测和数据集标注的问题，包括情感标签错误、对比标记误解、早期术语的积极性偏见等。

Conclusion: 研究结果表明需要开发语法和语义感知模型（如图卷积网络），以更有效地捕捉长距离关系和复杂的基于方面的意见对齐。

Abstract: Aspect-based sentiment analysis (ABSA) in natural language processing enables
organizations to understand customer opinions on specific product aspects.
While deep learning models are widely used for English ABSA, their application
in Arabic is limited due to the scarcity of labeled data. Researchers have
attempted to tackle this issue by using pre-trained contextualized language
models such as BERT. However, these models are often based on fact-based data,
which can introduce bias in domain-specific tasks like ABSA. To our knowledge,
no studies have applied adaptive pre-training with Arabic contextualized models
for ABSA. This research proposes a novel approach using domain-adaptive
pre-training for aspect-sentiment classification (ASC) and opinion target
expression (OTE) extraction. We examine fine-tuning strategies - feature
extraction, full fine-tuning, and adapter-based methods - to enhance
performance and efficiency, utilizing multiple adaptation corpora and
contextualized models. Our results show that in-domain adaptive pre-training
yields modest improvements. Adapter-based fine-tuning is a computationally
efficient method that achieves competitive results. However, error analyses
reveal issues with model predictions and dataset labeling. In ASC, common
problems include incorrect sentiment labeling, misinterpretation of contrastive
markers, positivity bias for early terms, and challenges with conflicting
opinions and subword tokenization. For OTE, issues involve mislabeling targets,
confusion over syntactic roles, difficulty with multi-word expressions, and
reliance on shallow heuristics. These findings underscore the need for syntax-
and semantics-aware models, such as graph convolutional networks, to more
effectively capture long-distance relations and complex aspect-based opinion
alignments.

</details>


### [49] [KuBERT: Central Kurdish BERT Model and Its Application for Sentiment Analysis](https://arxiv.org/abs/2509.16804)
*Kozhin muhealddin Awlla,Hadi Veisi,Abdulhady Abas Abdullah*

Main category: cs.CL

TL;DR: 本文通过将BERT集成到自然语言处理技术中，提升了中央库尔德语情感分析的研究水平。


<details>
  <summary>Details</summary>
Motivation: 库尔德语是一种低资源语言，具有高度的语言多样性但计算资源有限，这使得情感分析具有挑战性。传统方法如Word2Vec效果有限，而BERT的先进词嵌入能力有望改善这一状况。

Method: 将双向编码器表示转换器（BERT）集成到自然语言处理技术中，利用其更好的词嵌入能力来捕捉库尔德语的细微语义和上下文复杂性。

Result: 该方法为低资源语言的情感分析设立了新的基准，能够更好地处理库尔德语的语言特性。

Conclusion: BERT模型在库尔德语情感分析中表现出色，为低资源语言的自然语言处理任务提供了有效的解决方案。

Abstract: This paper enhances the study of sentiment analysis for the Central Kurdish
language by integrating the Bidirectional Encoder Representations from
Transformers (BERT) into Natural Language Processing techniques. Kurdish is a
low-resourced language, having a high level of linguistic diversity with
minimal computational resources, making sentiment analysis somewhat
challenging. Earlier, this was done using a traditional word embedding model,
such as Word2Vec, but with the emergence of new language models, specifically
BERT, there is hope for improvements. The better word embedding capabilities of
BERT lend to this study, aiding in the capturing of the nuanced semantic pool
and the contextual intricacies of the language under study, the Kurdish
language, thus setting a new benchmark for sentiment analysis in low-resource
languages.

</details>


### [50] [Cognitive Linguistic Identity Fusion Score (CLIFS): A Scalable Cognition-Informed Approach to Quantifying Identity Fusion from Text](https://arxiv.org/abs/2509.16813)
*Devin R. Wright,Jisun An,Yong-Yeol Ahn*

Main category: cs.CL

TL;DR: 本文提出了一种名为CLIFS的新指标，通过结合认知语言学和大型语言模型来量化身份融合，相比传统方法具有自动化、可扩展的优势，在暴力风险评估中表现优异。


<details>
  <summary>Details</summary>
Motivation: 身份融合（个体与群体或抽象目标的心理融合）对于理解群体行为至关重要，但传统评估方法需要受控调查或直接接触，缺乏自动化评估工具。

Method: 开发CLIFS指标，整合认知语言学和LLMs，基于隐式隐喻检测，实现完全自动化的身份融合评估。

Result: CLIFS在基准测试中优于现有自动化方法和人工标注，在暴力风险评估中能将评估效果提升240%以上。

Conclusion: CLIFS为身份融合评估提供了有效的自动化工具，未来需要开发更大、更多样化的数据集来增强泛化能力。

Abstract: Quantifying identity fusion -- the psychological merging of self with another
entity or abstract target (e.g., a religious group, political party, ideology,
value, brand, belief, etc.) -- is vital for understanding a wide range of
group-based human behaviors. We introduce the Cognitive Linguistic Identity
Fusion Score (CLIFS), a novel metric that integrates cognitive linguistics with
large language models (LLMs), which builds on implicit metaphor detection.
Unlike traditional pictorial and verbal scales, which require controlled
surveys or direct field contact, CLIFS delivers fully automated, scalable
assessments while maintaining strong alignment with the established verbal
measure. In benchmarks, CLIFS outperforms both existing automated approaches
and human annotation. As a proof of concept, we apply CLIFS to violence risk
assessment to demonstrate that it can improve violence risk assessment by more
than 240%. Building on our identification of a new NLP task and early success,
we underscore the need to develop larger, more diverse datasets that encompass
additional fusion-target domains and cultural backgrounds to enhance
generalizability and further advance this emerging area. CLIFS models and code
are public at https://github.com/DevinW-sudo/CLIFS.

</details>


### [51] [Semantic-Driven Topic Modeling for Analyzing Creativity in Virtual Brainstorming](https://arxiv.org/abs/2509.16835)
*Melkamu Abay Mersha,Jugal Kalita*

Main category: cs.CL

TL;DR: 提出了一种基于语义的主题建模框架，用于自动分析虚拟头脑风暴会议中的创意，相比传统方法具有更高的主题一致性和更好的可解释性。


<details>
  <summary>Details</summary>
Motivation: 虚拟头脑风暴会议中创意数量庞大且分布不均，手动编码耗时且主观，需要自动化方法来支持群体创造力的评估。

Method: 集成四个模块化组件的语义驱动主题建模框架：基于Transformer的嵌入（Sentence-BERT）、降维（UMAP）、聚类（HDBSCAN）以及主题提取与精炼。

Result: 在Zoom头脑风暴会话上的评估显示，该模型平均一致性得分0.687（CV），显著优于LDA、ETM和BERTopic等基准方法。

Conclusion: 这项工作凸显了基于嵌入的主题建模在分析协作构思方面的潜力，为研究同步虚拟会议中的创造力提供了高效可扩展的框架。

Abstract: Virtual brainstorming sessions have become a central component of
collaborative problem solving, yet the large volume and uneven distribution of
ideas often make it difficult to extract valuable insights efficiently. Manual
coding of ideas is time-consuming and subjective, underscoring the need for
automated approaches to support the evaluation of group creativity. In this
study, we propose a semantic-driven topic modeling framework that integrates
four modular components: transformer-based embeddings (Sentence-BERT),
dimensionality reduction (UMAP), clustering (HDBSCAN), and topic extraction
with refinement. The framework captures semantic similarity at the sentence
level, enabling the discovery of coherent themes from brainstorming transcripts
while filtering noise and identifying outliers. We evaluate our approach on
structured Zoom brainstorming sessions involving student groups tasked with
improving their university. Results demonstrate that our model achieves higher
topic coherence compared to established methods such as LDA, ETM, and BERTopic,
with an average coherence score of 0.687 (CV), outperforming baselines by a
significant margin. Beyond improved performance, the model provides
interpretable insights into the depth and diversity of topics explored,
supporting both convergent and divergent dimensions of group creativity. This
work highlights the potential of embedding-based topic modeling for analyzing
collaborative ideation and contributes an efficient and scalable framework for
studying creativity in synchronous virtual meetings.

</details>


### [52] [Multi-task Pretraining for Enhancing Interpretable L2 Pronunciation Assessment](https://arxiv.org/abs/2509.16876)
*Jiun-Ting Li,Bi-Cheng Yan,Yi-Cheng Wang,Berlin Chen*

Main category: cs.CL

TL;DR: 该论文提出了一种多任务预训练策略来解决自动发音评估中过度依赖音素级特征的问题，同时通过整合手工特征来连接发音评估和口语能力评估。


<details>
  <summary>Details</summary>
Motivation: 现有的自动发音评估系统主要依赖音素级特征，忽视了超音段发音线索，且缺乏与口语能力评估的整合，限制了全面性评估能力。

Method: 提出多任务预训练策略，通过随机掩码音素级特征并基于上下文重建来捕获长期时间发音线索；同时整合手工特征（如流利度、重音等）来生成可解释的能力分数。

Result: 在speechocean762数据集上的实验显示，该方法在发音评分和口语能力相关性方面均有提升。

Conclusion: 该方法能够实现针对性训练和全面的能力评估，为发音评估和口语能力评估提供了有效的整合框架。

Abstract: Automatic pronunciation assessment (APA) analyzes second-language (L2)
learners' speech by providing fine-grained pronunciation feedback at various
linguistic levels. Most existing efforts on APA typically adopt segmental-level
features as inputs and predict pronunciation scores at different granularities
via hierarchical (or parallel) pronunciation modeling. This, however,
inevitably causes assessments across linguistic levels (e.g., phone, word, and
utterance) to rely solely on phoneme-level pronunciation features, nearly
sidelining supra-segmental pronunciation cues. To address this limitation, we
introduce multi-task pretraining (MTP) for APA, a simple yet effective strategy
that attempts to capture long-term temporal pronunciation cues while
strengthening the intrinsic structures within an utterance via the objective of
reconstructing input features. Specifically, for a phoneme-level encoder of an
APA model, the proposed MTP strategy randomly masks segmental-level
pronunciation features and reconstructs the masked ones based on their
surrounding pronunciation context. Furthermore, current APA systems lack
integration with automated speaking assessment (ASA), limiting holistic
proficiency evaluation. Drawing on empirical studies and prior knowledge in
ASA, our framework bridges this gap by incorporating handcrafted features
(HCFs), such as fluency (speech rate, silence duration) and stress (pitch
accent strength), derived from human-designed formulas via regressors to
generate interpretable proficiency scores. Experiments on speechocean762 show
improved pronunciation scoring and ASA proficiency correlation, enabling
targeted training and comprehensive proficiency assessment.

</details>


### [53] [Can GRPO Boost Complex Multimodal Table Understanding?](https://arxiv.org/abs/2509.16889)
*Xiaoqiang Kang,Shengen Wu,Zimu Wang,Yilin Liu,Xiaobo Jin,Kaizhu Huang,Wei Wang,Yutao Yue,Xiaowei Huang,Qiufeng Wang*

Main category: cs.CL

TL;DR: Table-R1是一个三阶段强化学习框架，通过预热、感知对齐和提示完成三个阶段，提升多模态表格理解能力，显著超越传统监督微调和GRPO方法。


<details>
  <summary>Details</summary>
Motivation: 现有表格理解方法面临复杂表格结构和逻辑推理的挑战，传统强化学习方法在表格场景中存在初始策略精度低和奖励粗糙的问题。

Method: Table-R1包含三个阶段：(1)预热阶段提升初始感知和推理能力；(2)感知对齐GRPO使用连续树编辑距离相似度奖励识别表格结构和内容；(3)提示完成GRPO利用基于提示问题的残差步骤细粒度奖励。

Result: 实验表明Table-R1在held-in和held-out数据集上显著提升表格推理性能，Qwen2-VL-7B模型甚至超越更大的专用表格理解模型，在held-in数据集上达到与GPT-4o相当的性能。

Conclusion: Table-R1通过克服初始化和奖励稀疏性瓶颈，有效推进了鲁棒的多模态表格理解技术发展。

Abstract: Existing table understanding methods face challenges due to complex table
structures and intricate logical reasoning. While supervised finetuning (SFT)
dominates existing research, reinforcement learning (RL), such as Group
Relative Policy Optimization (GRPO), has shown promise but struggled with low
initial policy accuracy and coarse rewards in tabular contexts. In this paper,
we introduce Table-R1, a three-stage RL framework that enhances multimodal
table understanding through: (1) Warm-up that prompts initial perception and
reasoning capabilities, (2) Perception Alignment GRPO (PA-GRPO), which employs
continuous Tree-Edit-Distance Similarity (TEDS) rewards for recognizing table
structures and contents, and (3) Hint-Completion GRPO (HC-GRPO), which utilizes
fine-grained rewards of residual steps based on the hint-guided question.
Extensive experiments demonstrate that Table-R1 can boost the model's table
reasoning performance obviously on both held-in and held-out datasets,
outperforming SFT and GRPO largely. Notably, Qwen2-VL-7B with Table-R1
surpasses larger specific table understanding models (e.g., Table-LLaVA 13B),
even achieving comparable performance to the closed-source model GPT-4o on
held-in datasets, demonstrating the efficacy of each stage of Table-R1 in
overcoming initialization bottlenecks and reward sparsity, thereby advancing
robust multimodal table understanding.

</details>


### [54] [CLaC at DISRPT 2025: Hierarchical Adapters for Cross-Framework Multi-lingual Discourse Relation Classification](https://arxiv.org/abs/2509.16903)
*Nawar Turk,Daniele Comitogianni,Leila Kosseim*

Main category: cs.CL

TL;DR: 本文介绍了DISRPT 2025共享任务3的提交方案，该任务涉及跨39个语料库、16种语言和6种话语框架的17种话语关系分类。研究比较了多语言BERT模型、基于提示的大语言模型以及提出的HiDAC模型在统一标签集上的表现。


<details>
  <summary>Details</summary>
Motivation: 解决多语言和跨形式化的话语关系分类挑战，建立统一的话语关系标签集基准，并探索参数高效的模型方法。

Method: 首先对多语言BERT模型进行微调基准测试，然后评估基于提示的LLM（Claude Opus 4.0）的零样本和少样本性能，最后提出HiDAC（分层双适配器对比学习模型）。

Result: 较大的transformer模型准确率更高但改进有限；解冻编码器顶部75%层可获得与完全微调相当的性能但参数更少；基于提示的模型显著落后于微调模型；HiDAC达到最高准确率67.5%且参数效率更高。

Conclusion: HiDAC模型在多语言话语关系分类任务中实现了最佳性能与参数效率的平衡，为跨语言话语分析提供了有效的解决方案。

Abstract: We present our submission to Task 3 (Discourse Relation Classification) of
the DISRPT 2025 shared task. Task 3 introduces a unified set of 17 discourse
relation labels across 39 corpora in 16 languages and six discourse frameworks,
posing significant multilingual and cross-formalism challenges. We first
benchmark the task by fine-tuning multilingual BERT-based models (mBERT,
XLM-RoBERTa-Base, and XLM-RoBERTa-Large) with two argument-ordering strategies
and progressive unfreezing ratios to establish strong baselines. We then
evaluate prompt-based large language models (namely Claude Opus 4.0) in
zero-shot and few-shot settings to understand how LLMs respond to the newly
proposed unified labels. Finally, we introduce HiDAC, a Hierarchical
Dual-Adapter Contrastive learning model. Results show that while larger
transformer models achieve higher accuracy, the improvements are modest, and
that unfreezing the top 75% of encoder layers yields performance comparable to
full fine-tuning while training far fewer parameters. Prompt-based models lag
significantly behind fine-tuned transformers, and HiDAC achieves the highest
overall accuracy (67.5%) while remaining more parameter-efficient than full
fine-tuning.

</details>


### [55] [CUTE: A Multilingual Dataset for Enhancing Cross-Lingual Knowledge Transfer in Low-Resource Languages](https://arxiv.org/abs/2509.16914)
*Wenhao Zhuang,Yuan Sun*

Main category: cs.CL

TL;DR: 本文构建并开源了CUTE多语言数据集，包含中文、维吾尔语、藏语和英语的平行和非平行语料，旨在提升大语言模型对低资源语言的处理能力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在资源丰富语言上表现出色，但对低资源语言支持不足，主要原因是训练语料稀缺。本文旨在解决维吾尔语和藏语等低资源语言的语料匮乏问题。

Method: 通过机器翻译构建了25GB的四语言语料库（包含平行和非平行语料），并在构建前通过人工评估验证了中文-维吾尔语和中文-藏语机器翻译质量接近中文-英语翻译水平。

Result: CUTE是目前最大的维吾尔语和藏语开源语料库，实验证明它能有效提升大语言模型处理低资源语言的能力，并探索了语料平行性在跨语言迁移学习中的作用。

Conclusion: CUTE数据集和相关模型已向研究社区公开，为低资源语言的自然语言处理研究提供了重要资源支持。

Abstract: Large Language Models (LLMs) demonstrate exceptional zero-shot capabilities
in various NLP tasks, significantly enhancing user experience and efficiency.
However, this advantage is primarily limited to resource-rich languages. For
the diverse array of low-resource languages, support remains inadequate, with
the scarcity of training corpora considered the primary cause. We construct and
open-source CUTE Chinese, Uyghur, Tibetan,English dataset, consisting of two
25GB sets of four-language corpora (one parallel and one non-parallel),
obtained through machine translation. CUTE encompasses two resource-rich
languages (Chinese and English) and two low-resource languages (Uyghur and
Tibetan). Prior to constructing CUTE, human assessment validates that the
machine translation quality between Chinese-Uyghur and Chinese-Tibetan
approaches that of Chinese-English translation. CUTE represents the largest
open-source corpus for Uyghur and Tibetan languages to date, and we demonstrate
its effectiveness in enhancing LLMs' ability to process low-resource languages
while investigating the role of corpus parallelism in cross-lingual transfer
learning. The CUTE corpus and related models are made publicly available to the
research community.

</details>


### [56] [K-DeCore: Facilitating Knowledge Transfer in Continual Structured Knowledge Reasoning via Knowledge Decoupling](https://arxiv.org/abs/2509.16929)
*Yongrui Chen,Yi Huang,Yunchang Liu,Shenyu Zhang,Junhao He,Tongtong Wu,Guilin Qi,Tianxing Wu*

Main category: cs.CL

TL;DR: 提出K-DeCore框架，解决持续结构化知识推理中的泛化问题和参数增长问题，通过知识解耦机制和双视角记忆巩固实现高效推理。


<details>
  <summary>Details</summary>
Motivation: 现有的持续学习方法在处理异构结构化知识时泛化能力差，且随着任务增加参数增长导致推理效率低下。

Method: K-DeCore框架包含知识解耦机制（将推理过程分解为任务特定和任务无关阶段）、双视角记忆巩固机制和结构引导的伪数据合成策略。

Result: 在四个基准数据集上的实验表明，K-DeCore在多个指标上优于现有持续学习方法，适用于各种骨干大语言模型。

Conclusion: K-DeCore通过固定数量的可调参数有效解决了CSKR任务中的关键挑战，实现了优异的性能表现。

Abstract: Continual Structured Knowledge Reasoning (CSKR) focuses on training models to
handle sequential tasks, where each task involves translating natural language
questions into structured queries grounded in structured knowledge. Existing
general continual learning approaches face significant challenges when applied
to this task, including poor generalization to heterogeneous structured
knowledge and inefficient reasoning due to parameter growth as tasks increase.
To address these limitations, we propose a novel CSKR framework,
\textsc{K-DeCore}, which operates with a fixed number of tunable parameters.
Unlike prior methods, \textsc{K-DeCore} introduces a knowledge decoupling
mechanism that disentangles the reasoning process into task-specific and
task-agnostic stages, effectively bridging the gaps across diverse tasks.
Building on this foundation, \textsc{K-DeCore} integrates a dual-perspective
memory consolidation mechanism for distinct stages and introduces a
structure-guided pseudo-data synthesis strategy to further enhance the model's
generalization capabilities. Extensive experiments on four benchmark datasets
demonstrate the superiority of \textsc{K-DeCore} over existing continual
learning methods across multiple metrics, leveraging various backbone large
language models.

</details>


### [57] [AirQA: A Comprehensive QA Dataset for AI Research with Instance-Level Evaluation](https://arxiv.org/abs/2509.16952)
*Tiancheng Huang,Ruisheng Cao,Yuxin Zhang,Zhangyi Kang,Zijian Wang,Chenrun Wang,Yijie Luo,Hang Zheng,Lirong Qian,Lu Chen,Kai Yu*

Main category: cs.CL

TL;DR: 提出了AirQA数据集和ExTrActor框架，用于评估和改进LLM在科学论文问答任务中的能力


<details>
  <summary>Details</summary>
Motivation: 学术论文数量激增使得研究人员难以高效提取关键信息，现有缺乏全面且现实的基准来评估LLM在科学论文问答中的能力，且高质量交互轨迹数据不足

Method: 构建了包含13,948篇AI领域论文和1,246个问题的人工标注数据集AirQA，并提出ExTrActor自动化框架，使用三个LLM代理进行示例生成和轨迹收集

Result: 评估显示大多数模型在AirQA上表现不佳，证明了数据集质量。实验证实ExTrActor能持续提升小模型的多轮工具使用能力，使其达到与更大模型相当的性能

Conclusion: AirQA为科学论文问答提供了全面基准，ExTrActor框架有效解决了高质量交互数据短缺问题，显著提升了小模型的多轮工具使用能力

Abstract: The growing volume of academic papers has made it increasingly difficult for
researchers to efficiently extract key information. While large language models
(LLMs) based agents are capable of automating question answering (QA) workflows
for scientific papers, there still lacks a comprehensive and realistic
benchmark to evaluate their capabilities. Moreover, training an interactive
agent for this specific task is hindered by the shortage of high-quality
interaction trajectories. In this work, we propose AirQA, a human-annotated
comprehensive paper QA dataset in the field of artificial intelligence (AI),
with 13,948 papers and 1,246 questions, that encompasses multi-task,
multi-modal and instance-level evaluation. Furthermore, we propose ExTrActor,
an automated framework for instruction data synthesis. With three LLM-based
agents, ExTrActor can perform example generation and trajectory collection
without human intervention. Evaluations of multiple open-source and proprietary
models show that most models underperform on AirQA, demonstrating the quality
of our dataset. Extensive experiments confirm that ExTrActor consistently
improves the multi-turn tool-use capability of small models, enabling them to
achieve performance comparable to larger ones.

</details>


### [58] [Preference Distillation via Value based Reinforcement Learning](https://arxiv.org/abs/2509.16965)
*Minchan Kwon,Junwon Ko,Kangil Kim,Junmo Kim*

Main category: cs.CL

TL;DR: 本文提出TVKD方法，通过教师模型的价值函数引入辅助奖励，解决DPO在小模型训练中二元监督不足的问题，保持DPO的全局奖励结构同时提升性能。


<details>
  <summary>Details</summary>
Motivation: DPO的二元胜负监督对小容量模型训练不足，现有方法主要模仿教师模型行为而忽视了奖励建模的蒸馏。

Method: 提出Teacher Value-based Knowledge Distillation (TVKD)，利用教师模型价值函数提供软指导的辅助奖励，满足基于势能的奖励塑造条件，可无缝集成到标准DPO框架中。

Result: 实验结果表明TVKD在各种基准测试和模型规模下都能持续提升性能。

Conclusion: TVKD方法有效解决了小模型DPO训练的局限性，通过奖励建模蒸馏显著提升了模型对齐效果。

Abstract: Direct Preference Optimization (DPO) is a powerful paradigm to align language
models with human preferences using pairwise comparisons. However, its binary
win-or-loss supervision often proves insufficient for training small models
with limited capacity. Prior works attempt to distill information from large
teacher models using behavior cloning or KL divergence. These methods often
focus on mimicking current behavior and overlook distilling reward modeling. To
address this issue, we propose \textit{Teacher Value-based Knowledge
Distillation} (TVKD), which introduces an auxiliary reward from the value
function of the teacher model to provide a soft guide. This auxiliary reward is
formulated to satisfy potential-based reward shaping, ensuring that the global
reward structure and optimal policy of DPO are preserved. TVKD can be
integrated into the standard DPO training framework and does not require
additional rollouts. Our experimental results show that TVKD consistently
improves performance across various benchmarks and model sizes.

</details>


### [59] [Advancing Speech Understanding in Speech-Aware Language Models with GRPO](https://arxiv.org/abs/2509.16990)
*Avishai Elmakies,Hagai Aronowitz,Nimrod Shabtay,Eli Schwartz,Ron Hoory,Avihu Dekel*

Main category: cs.CL

TL;DR: 本文提出了一种基于群体相对策略优化（GRPO）的方法，用于训练语音感知大语言模型（SALLMs）在开放格式语音理解任务上的表现，如口语问答和自动语音翻译。


<details>
  <summary>Details</summary>
Motivation: SALLMs在语音理解任务中表现出色，GRPO因其在训练LLMs中的高效性而受到关注。先前研究主要将GRPO应用于多项选择题，本文旨在探索其在更能体现模型生成能力的开放格式任务中的应用。

Method: 采用GRPO方法，以BLEU作为奖励信号来优化SALLMs，并探索在GRPO中引入离策略样本的潜力。

Result: 实证研究表明，该方法在多个关键指标上超越了标准的监督微调（SFT）。

Conclusion: GRPO结合BLEU奖励在开放格式语音理解任务中有效，离策略样本的引入为未来改进和研究提供了方向。

Abstract: In this paper, we introduce a Group Relative Policy Optimization (GRPO)-based
method for training Speech-Aware Large Language Models (SALLMs) on open-format
speech understanding tasks, such as Spoken Question Answering and Automatic
Speech Translation. SALLMs have proven highly effective for speech
understanding tasks. GRPO has recently gained traction for its efficiency in
training LLMs, and prior work has explored its application to SALLMs, primarily
in multiple-choice tasks. Building on this, we focus on open-format tasks that
better reflect the generative abilities of the models. Our approach leverages
GRPO with BLEU as the reward signal to optimize SALLMs, and we demonstrate
empirically that it surpasses standard SFT across several key metrics. Finally,
we explore the potential of incorporating off-policy samples within GRPO for
these tasks, highlighting avenues for further improvement and further research.

</details>


### [60] [The Transfer Neurons Hypothesis: An Underlying Mechanism for Language Latent Space Transitions in Multilingual LLMs](https://arxiv.org/abs/2509.17030)
*Hinata Tezuka,Naoya Inoue*

Main category: cs.CL

TL;DR: 该论文提出了转移神经元假说，认为MLP模块中的特定神经元负责在语言特定潜在空间和共享语义潜在空间之间转移表示，并验证了这些神经元对于多语言LLM推理的关键作用。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明解码器型LLM的多语言输入处理框架中，早期层将输入转换为英语中心和语言无关表示，中间层在英语中心潜在空间中进行推理，最终层将这些表示转换回语言特定潜在空间。但这种转换的内部动态和底层机制尚未充分探索。

Method: 提出并实证验证转移神经元假说，识别MLP模块中负责在语言特定潜在空间和共享语义潜在空间之间转移表示的特定神经元，并分析语言特定神经元在促进潜在空间间移动的功能。

Result: 验证了转移神经元的存在及其功能，发现语言特定神经元的一个功能是促进潜在空间间的移动，并证明转移神经元对多语言LLM的推理至关重要。

Conclusion: 转移神经元假说为理解多语言LLM的内部表示转换机制提供了新视角，揭示了特定神经元在多语言处理中的关键作用，有助于深化对LLM多语言能力的理解。

Abstract: Recent studies have suggested a processing framework for multilingual inputs
in decoder-based LLMs: early layers convert inputs into English-centric and
language-agnostic representations; middle layers perform reasoning within an
English-centric latent space; and final layers generate outputs by transforming
these representations back into language-specific latent spaces. However, the
internal dynamics of such transformation and the underlying mechanism remain
underexplored. Towards a deeper understanding of this framework, we propose and
empirically validate The Transfer Neurons Hypothesis: certain neurons in the
MLP module are responsible for transferring representations between
language-specific latent spaces and a shared semantic latent space.
Furthermore, we show that one function of language-specific neurons, as
identified in recent studies, is to facilitate movement between latent spaces.
Finally, we show that transfer neurons are critical for reasoning in
multilingual LLMs.

</details>


### [61] [Modeling Bottom-up Information Quality during Language Processing](https://arxiv.org/abs/2509.17047)
*Cui Ding,Yanning Yin,Lena A. Jäger,Ethan Gotlieb Wilcox*

Main category: cs.CL

TL;DR: 该研究通过信息论方法量化阅读中自下而上信息的质量，测试了视觉信息质量对阅读速度的影响，并比较了英文和中文中上下半部分信息分布的不对称性。


<details>
  <summary>Details</summary>
Motivation: 验证语言处理理论中自下而上输入质量对处理难易度的影响，即噪声输入会导致理解困难。

Method: 提出用视觉信息与词汇身份之间的互信息来量化信息质量，通过遮挡单词上下半部分来降低信息质量，使用多模态语言模型估计互信息，并比较英文和中文阅读数据。

Result: 英文和中文中上半部分包含更多词汇身份信息，但英文的不对称性更明显，这一模式在阅读时间中得到了反映。

Conclusion: 视觉信息质量确实影响阅读处理难度，信息分布的不对称性在不同语言中存在差异，支持了整合自上而下预期和自下而上输入的语言处理模型。

Abstract: Contemporary theories model language processing as integrating both top-down
expectations and bottom-up inputs. One major prediction of such models is that
the quality of the bottom-up inputs modulates ease of processing -- noisy
inputs should lead to difficult and effortful comprehension. We test this
prediction in the domain of reading. First, we propose an information-theoretic
operationalization for the "quality" of bottom-up information as the mutual
information (MI) between visual information and word identity. We formalize
this prediction in a mathematical model of reading as a Bayesian update.
Second, we test our operationalization by comparing participants' reading times
in conditions where words' information quality has been reduced, either by
occluding their top or bottom half, with full words. We collect data in English
and Chinese. We then use multimodal language models to estimate the mutual
information between visual inputs and words. We use these data to estimate the
specific effect of reduced information quality on reading times. Finally, we
compare how information is distributed across visual forms. In English and
Chinese, the upper half contains more information about word identity than the
lower half. However, the asymmetry is more pronounced in English, a pattern
which is reflected in the reading times.

</details>


### [62] [TactfulToM: Do LLMs Have the Theory of Mind Ability to Understand White Lies?](https://arxiv.org/abs/2509.17054)
*Yiwei Liu,Emma Jane Pretty,Jiahao Huang,Saku Sugawara*

Main category: cs.CL

TL;DR: TactfulToM是一个新的英语基准测试，用于评估大型语言模型在真实对话中理解善意谎言并推理其背后亲社会动机的能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注LLMs在心理理论推理任务上的表现，但对于需要更细致社会背景的心理理论能力（如善意谎言）的研究有限。

Method: 通过多阶段人机协作流程生成基准测试，其中LLMs扩展手动设计的种子故事为对话，保持参与者之间的信息不对称以创造真实的善意谎言场景。

Result: 最先进的模型在TactfulToM基准上表现具有挑战性，其性能显著低于人类水平。

Conclusion: LLMs在完全理解支持真正理解善意谎言的心理理论推理能力方面存在不足。

Abstract: While recent studies explore Large Language Models' (LLMs) performance on
Theory of Mind (ToM) reasoning tasks, research on ToM abilities that require
more nuanced social context is limited, such as white lies. We introduce
TactfulToM, a novel English benchmark designed to evaluate LLMs' ability to
understand white lies within real-life conversations and reason about prosocial
motivations behind them, particularly when they are used to spare others'
feelings and maintain social harmony. Our benchmark is generated through a
multi-stage human-in-the-loop pipeline where LLMs expand manually designed seed
stories into conversations to maintain the information asymmetry between
participants necessary for authentic white lies. We show that TactfulToM is
challenging for state-of-the-art models, which perform substantially below
humans, revealing shortcomings in their ability to fully comprehend the ToM
reasoning that enables true understanding of white lies.

</details>


### [63] [SFT-TA: Supervised Fine-Tuned Agents in Multi-Agent LLMs for Automated Inductive Thematic Analysis](https://arxiv.org/abs/2509.17167)
*Seungjun Yi,Joakim Nguyen,Huimin Xu,Terence Lim,Joseph Skrovan,Mehak Beri,Hitakshi Modi,Andrew Well,Liu Leqi,Mia Markey,Ying Ding*

Main category: cs.CL

TL;DR: SFT-TA是一个自动化主题分析框架，通过在多智能体系统中嵌入监督微调(SFT)代理，提高了与人类参考主题的对齐度，超越了现有框架和gpt-4o基线。


<details>
  <summary>Details</summary>
Motivation: 手动主题分析耗时且难以扩展，现有LLM自动化方法在结果对齐方面存在局限，需要改进自动化主题分析的准确性和可扩展性。

Method: 提出SFT-TA框架，在多智能体系统中嵌入监督微调(SFT)代理，通过智能体间的协作和特定角色分配来优化主题分析过程。

Result: SFT-TA框架在主题对齐方面优于现有框架和gpt-4o基线，多智能体系统能显著提升SFT代理的性能表现。

Conclusion: 在多智能体系统中嵌入SFT代理是提高主题分析结果与期望输出对齐度的有效途径，为自动化定性分析提供了有前景的解决方案。

Abstract: Thematic Analysis (TA) is a widely used qualitative method that provides a
structured yet flexible framework for identifying and reporting patterns in
clinical interview transcripts. However, manual thematic analysis is
time-consuming and limits scalability. Recent advances in LLMs offer a pathway
to automate thematic analysis, but alignment with human results remains
limited. To address these limitations, we propose SFT-TA, an automated thematic
analysis framework that embeds supervised fine-tuned (SFT) agents within a
multi-agent system. Our framework outperforms existing frameworks and the
gpt-4o baseline in alignment with human reference themes. We observed that SFT
agents alone may underperform, but achieve better results than the baseline
when embedded within a multi-agent system. Our results highlight that embedding
SFT agents in specific roles within a multi-agent system is a promising pathway
to improve alignment with desired outputs for thematic analysis.

</details>


### [64] [FlagEval Findings Report: A Preliminary Evaluation of Large Reasoning Models on Automatically Verifiable Textual and Visual Questions](https://arxiv.org/abs/2509.17177)
*Bowen Qin,Chen Yue,Fang Yin,Hui Wang,JG Yao,Jiakang Liu,Jing-Shu Zheng,Miguel Hu Chen,Richeng Xuan,Shibei Meng,Shiqi Zhou,Teng Dai,Tong-Shuai Ren,Wei Cui,Xi Yang,Xialin Du,Xiaojing Xu,Xue Sun,Xuejing Li,Yaming Liu,Yesheng Liu,Ying Liu,Yonghua Lin,Yu Zhao,Yunduo Zhang,Yuwen Luo,Zheqi He,Zhiyuan He,Zhongyuan Wang*

Main category: cs.CL

TL;DR: 本文进行了中等规模的无污染评估，测试当前大型推理模型，并发布了ROME评估基准用于测试视觉语言模型的视觉线索推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前需要评估大型推理模型在视觉语言任务中的表现，特别是从视觉线索进行推理的能力，但缺乏合适的无污染评估基准。

Method: 开发了ROME评估基准，专门设计用于测试视觉语言模型从视觉线索进行推理的能力，并进行了中等规模的评估实验。

Result: 发布了ROME基准测试集，提供了评估数据和其他更新，建立了评估网站https://flageval-baai.github.io/LRM-Eval/

Conclusion: 这项工作为大型推理模型的视觉语言推理能力评估提供了重要基准，有助于推动该领域的发展。

Abstract: We conduct a moderate-scale contamination-free (to some extent) evaluation of
current large reasoning models (LRMs) with some preliminary findings. We also
release ROME, our evaluation benchmark for vision language models intended to
test reasoning from visual clues. We attach links to the benchmark, evaluation
data, and other updates on this website:
https://flageval-baai.github.io/LRM-Eval/

</details>


### [65] [Attention Consistency for LLMs Explanation](https://arxiv.org/abs/2509.17178)
*Tian Lan,Jinyuan Xu,Xue He,Jenq-Neng Hwang,Lei Li*

Main category: cs.CL

TL;DR: 提出了MACS（多层注意力一致性评分），一种轻量级、易于部署的启发式方法，用于估计基于解码器模型中输入令牌的重要性。


<details>
  <summary>Details</summary>
Motivation: 当前可解释性方法存在分辨率低和计算成本高的问题，需要开发更高效的方法来理解大型语言模型的决策过程。

Method: MACS通过测量最大注意力的一致性来评估输入令牌的贡献，是一种轻量级的启发式方法。

Result: 实验评估显示MACS在可解释性质量和计算效率之间取得了良好平衡，与复杂技术相比，VRAM使用量减少22%，延迟降低30%。

Conclusion: MACS为理解LLM决策过程提供了一种高效可靠的可解释性工具。

Abstract: Understanding the decision-making processes of large language models (LLMs)
is essential for their trustworthy development and deployment. However, current
interpretability methods often face challenges such as low resolution and high
computational cost. To address these limitations, we propose the
\textbf{Multi-Layer Attention Consistency Score (MACS)}, a novel, lightweight,
and easily deployable heuristic for estimating the importance of input tokens
in decoder-based models. MACS measures contributions of input tokens based on
the consistency of maximal attention. Empirical evaluations demonstrate that
MACS achieves a favorable trade-off between interpretability quality and
computational efficiency, showing faithfulness comparable to complex techniques
with a 22\% decrease in VRAM usage and 30\% reduction in latency.

</details>


### [66] [LifeAlign: Lifelong Alignment for Large Language Models with Memory-Augmented Focalized Preference Optimization](https://arxiv.org/abs/2509.17183)
*Junsong Li,Jie Zhou,Bihao Zhan,Yutao Yang,Qianjun Pan,Shilian Chen,Tianyu Huai,Xin Li,Qin Chen,Liang He*

Main category: cs.CL

TL;DR: LifeAlign是一个用于大语言模型终身对齐的新框架，通过聚焦偏好优化和短到长记忆巩固机制，解决传统对齐方法中的灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 传统的大语言模型对齐方法存在灾难性遗忘问题，当模型适应新偏好或领域时会丢失之前获得的知识。需要一种能够持续保持人类偏好对齐而不遗忘先前知识的终身对齐方法。

Method: LifeAlign包含两个关键创新：1）聚焦偏好优化策略，在使模型与新偏好对齐的同时防止先前任务知识的侵蚀；2）短到长记忆巩固机制，通过内在维度缩减将去噪后的短期偏好表示合并到稳定的长期记忆中。

Result: 在多个顺序对齐任务上的实验结果表明，LifeAlign在保持偏好对齐质量和知识保留方面优于现有的终身学习方法。

Conclusion: LifeAlign框架能够有效实现大语言模型的终身对齐，在不同领域和偏好类型的连续学习任务中保持一致的性能表现。

Abstract: Alignment plays a crucial role in Large Language Models (LLMs) in aligning
with human preferences on a specific task/domain. Traditional alignment methods
suffer from catastrophic forgetting, where models lose previously acquired
knowledge when adapting to new preferences or domains. We introduce LifeAlign,
a novel framework for lifelong alignment that enables LLMs to maintain
consistent human preference alignment across sequential learning tasks without
forgetting previously learned knowledge. Our approach consists of two key
innovations. First, we propose a focalized preference optimization strategy
that aligns LLMs with new preferences while preventing the erosion of knowledge
acquired from previous tasks. Second, we develop a short-to-long memory
consolidation mechanism that merges denoised short-term preference
representations into stable long-term memory using intrinsic dimensionality
reduction, enabling efficient storage and retrieval of alignment patterns
across diverse domains. We evaluate LifeAlign across multiple sequential
alignment tasks spanning different domains and preference types. Experimental
results demonstrate that our method achieves superior performance in
maintaining both preference alignment quality and knowledge retention compared
to existing lifelong learning approaches. The codes and datasets will be
released on GitHub.

</details>


### [67] [Evolution of Concepts in Language Model Pre-Training](https://arxiv.org/abs/2509.17196)
*Xuyang Ge,Wentao Shu,Jiaxing Wu,Yunhua Zhou,Zhengfu He,Xipeng Qiu*

Main category: cs.CL

TL;DR: 使用交叉编码器方法追踪语言模型预训练过程中的线性可解释特征演化，发现特征形成具有阶段性，与Transformer两阶段学习过程一致


<details>
  <summary>Details</summary>
Motivation: 语言模型预训练过程仍是一个黑盒，需要理解其特征演化过程

Method: 使用稀疏字典学习方法（交叉编码器）分析预训练快照中的线性可解释特征

Result: 大多数特征在特定时间点开始形成，复杂模式在后期训练阶段出现，特征归因分析显示特征演化与下游性能存在因果关系

Conclusion: 工作为追踪语言模型学习动态中的细粒度表示进展提供了可能性

Abstract: Language models obtain extensive capabilities through pre-training. However,
the pre-training process remains a black box. In this work, we track linear
interpretable feature evolution across pre-training snapshots using a sparse
dictionary learning method called crosscoders. We find that most features begin
to form around a specific point, while more complex patterns emerge in later
training stages. Feature attribution analyses reveal causal connections between
feature evolution and downstream performance. Our feature-level observations
are highly consistent with previous findings on Transformer's two-stage
learning process, which we term a statistical learning phase and a feature
learning phase. Our work opens up the possibility to track fine-grained
representation progress during language model learning dynamics.

</details>


### [68] [Prompt-Based Simplification for Plain Language using Spanish Language Models](https://arxiv.org/abs/2509.17209)
*Lourdes Moreno,Jesus M. Sanchez-Gomez,Marco Antonio Sanchez-Escudero,Paloma Martínez*

Main category: cs.CL

TL;DR: HULAT-UC3M团队在CLEARS 2025任务1中探索了基于西班牙语文本的模型策略，包括零样本提示工程和LoRA微调，最终系统在语义相似度上排名第一，可读性排名第四。


<details>
  <summary>Details</summary>
Motivation: 研究西班牙语文本向通俗语言(PL)的转换策略，解决训练数据异质性和评估指标在语言清晰度和内容保持方面的局限性。

Method: 使用基于西班牙语文本训练的模型，包括零样本配置的提示工程和LoRA微调版本，通过余弦相似度和Fernández-Huerta可读性指数评估不同策略。

Result: 最终系统结合标准化步骤、RigoChat-7B-v2模型和专用PL导向提示，在语义相似度上排名第一(SIM=0.75)，可读性排名第四(FH=69.72)。

Conclusion: 讨论了训练数据异质性的关键挑战以及当前评估指标在捕捉语言清晰度和内容保持方面的局限性。

Abstract: This paper describes the participation of HULAT-UC3M in CLEARS 2025 Subtask
1: Adaptation of Text to Plain Language (PL) in Spanish. We explored strategies
based on models trained on Spanish texts, including a zero-shot configuration
using prompt engineering and a fine-tuned version with Low-Rank Adaptation
(LoRA). Different strategies were evaluated on representative internal subsets
of the training data, using the official task metrics, cosine similarity (SIM)
and the Fern\'andez-Huerta readability index (FH) to guide the selection of the
optimal model and prompt combination. The final system was selected for its
balanced and consistent performance, combining normalization steps, the
RigoChat-7B-v2 model, and a dedicated PL-oriented prompt. It ranked first in
semantic similarity (SIM = 0.75), however, fourth in readability (FH = 69.72).
We also discuss key challenges related to training data heterogeneity and the
limitations of current evaluation metrics in capturing both linguistic clarity
and content preservation.

</details>


### [69] [Extending Automatic Machine Translation Evaluation to Book-Length Documents](https://arxiv.org/abs/2509.17249)
*Kuang-Da Wang,Shuoyang Ding,Chao-Han Huck Yang,Ping-Chun Hsieh,Wen-Chih Peng,Vitaly Lavrukhin,Boris Ginsburg*

Main category: cs.CL

TL;DR: SEGALE是一个评估长文档翻译的方案，通过将文档视为连续文本并应用句子分割和对齐方法，扩展现有自动指标以支持长文档翻译评估。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在翻译性能和长上下文能力方面表现出色，但由于数据集限制、指标中的token数量限制以及严格的句子边界要求，评估方法仍局限于句子级别评估。

Method: SEGALE方案将文档视为连续文本，应用句子分割和对齐方法，处理任意长度的翻译，同时考虑欠翻译/过翻译和不同的句子边界。

Result: 实验表明该方案显著优于现有的长文档评估方案，与使用真实句子对齐的评估相当。应用该方案发现许多开源LLM无法在其报告的最大上下文长度下有效翻译文档。

Conclusion: SEGALE为长文档翻译评估提供了有效的解决方案，揭示了当前LLM在长文档翻译方面的局限性。

Abstract: Despite Large Language Models (LLMs) demonstrating superior translation
performance and long-context capabilities, evaluation methodologies remain
constrained to sentence-level assessment due to dataset limitations, token
number restrictions in metrics, and rigid sentence boundary requirements. We
introduce SEGALE, an evaluation scheme that extends existing automatic metrics
to long-document translation by treating documents as continuous text and
applying sentence segmentation and alignment methods. Our approach enables
previously unattainable document-level evaluation, handling translations of
arbitrary length generated with document-level prompts while accounting for
under-/over-translations and varied sentence boundaries. Experiments show our
scheme significantly outperforms existing long-form document evaluation
schemes, while being comparable to evaluations performed with groundtruth
sentence alignments. Additionally, we apply our scheme to book-length texts and
newly demonstrate that many open-weight LLMs fail to effectively translate
documents at their reported maximum context lengths.

</details>


### [70] [Probabilistic Token Alignment for Large Language Model Fusion](https://arxiv.org/abs/2509.17276)
*Runjia Zeng,James Chenhao Liang,Cheng Han,Zhiwen Cao,Jiahao Liu,Xiaojun Quan,Yingjie Victor Chen,Lifu Huang,Tong Geng,Qifan Wang,Dongfang Liu*

Main category: cs.CL

TL;DR: 本文提出PTA-LLM方法，通过概率令牌对齐解决现有模型融合方法依赖手动预定义词汇对齐的问题，将令牌对齐重新表述为最优传输问题，实现更连贯的模型融合。


<details>
  <summary>Details</summary>
Motivation: 从头训练大语言模型成本高昂且容易产生冗余能力，融合现有预训练模型是更经济的选择，但现有方法依赖手动词汇对齐，在不同上下文中泛化能力差，导致性能下降。

Method: 提出概率令牌对齐方法，将令牌对齐重新表述为最优传输问题，利用分布感知学习促进更连贯的模型融合，该方法具有通用性和可解释性。

Result: 实证结果表明，概率令牌对齐能够提升目标模型在多种能力上的性能表现。

Conclusion: PTA-LLM提供了一种通用且可解释的模型融合方法，通过分布学习视角解决令牌对齐问题，有效提升融合模型的性能。

Abstract: Training large language models (LLMs) from scratch can yield models with
unique functionalities and strengths, but it is costly and often leads to
redundant capabilities. A more cost-effective alternative is to fuse existing
pre-trained LLMs with different architectures into a more powerful model.
However, a key challenge in existing model fusion is their dependence on
manually predefined vocabulary alignment, which may not generalize well across
diverse contexts, leading to performance degradation in several evaluation. To
solve this, we draw inspiration from distribution learning and propose the
probabilistic token alignment method as a general and soft mapping for
alignment, named as PTA-LLM. Our approach innovatively reformulates token
alignment into a classic mathematical problem: optimal transport, seamlessly
leveraging distribution-aware learning to facilitate more coherent model
fusion. Apart from its inherent generality, PTA-LLM exhibits interpretability
from a distributional perspective, offering insights into the essence of the
token alignment. Empirical results demonstrate that probabilistic token
alignment enhances the target model's performance across multiple capabilities.
Our code is avaliable at https://runjia.tech/neurips_pta-llm/.

</details>


### [71] [Automated Knowledge Graph Construction using Large Language Models and Sentence Complexity Modelling](https://arxiv.org/abs/2509.17289)
*Sydney Anuyah,Mehedi Mahmud Kaushik,Krishna Dwarampudi,Rakesh Shiradkar,Arjan Durresi,Sunandan Chakraborty*

Main category: cs.CL

TL;DR: CoDe-KG是一个开源端到端流水线，通过结合核心消解和句法分解提取句子级知识图谱，贡献了15万+知识三元组数据集，在关系提取任务上达到65.8%宏F1分数，比现有技术提升8个百分点。


<details>
  <summary>Details</summary>
Motivation: 解决现有知识图谱提取方法在复杂句子处理上的不足，特别是核心消解和句子结构复杂性带来的挑战，旨在提高关系提取的准确性和覆盖率。

Method: 结合鲁棒的核心消解和句法句子分解，系统选择最优提示-模型对，使用混合思维链和少样本提示技术，在五个复杂度类别上进行优化。

Result: 在句子简化任务上达到99.8%精确匹配准确率；在REBEL数据集上关系提取宏F1达到65.8%（提升8点），WebNLG2上微F1达到75.7%；消融研究显示整合核心消解和分解使稀有关系召回率提升超过20%。

Conclusion: CoDe-KG展示了通过整合核心消解和句子分解可以显著提升知识图谱提取性能，特别是在处理复杂句子和稀有关系方面，为开放领域知识图谱构建提供了有效解决方案。

Abstract: We introduce CoDe-KG, an open-source, end-to-end pipeline for extracting
sentence-level knowledge graphs by combining robust coreference resolution with
syntactic sentence decomposition. Using our model, we contribute a dataset of
over 150,000 knowledge triples, which is open source. We also contribute a
training corpus of 7248 rows for sentence complexity, 190 rows of gold human
annotations for co-reference resolution using open source lung-cancer abstracts
from PubMed, 900 rows of gold human annotations for sentence conversion
policies, and 398 triples of gold human annotations. We systematically select
optimal prompt-model pairs across five complexity categories, showing that
hybrid chain-of-thought and few-shot prompting yields up to 99.8% exact-match
accuracy on sentence simplification. On relation extraction (RE), our pipeline
achieves 65.8% macro-F1 on REBEL, an 8-point gain over the prior state of the
art, and 75.7% micro-F1 on WebNLG2, while matching or exceeding performance on
Wiki-NRE and CaRB. Ablation studies demonstrate that integrating coreference
and decomposition increases recall on rare relations by over 20%. Code and
dataset are available at https://github.com/KaushikMahmud/CoDe-KG_EMNLP_2025

</details>


### [72] [Multi-View Attention Multiple-Instance Learning Enhanced by LLM Reasoning for Cognitive Distortion Detection](https://arxiv.org/abs/2509.17292)
*Jun Seo Kim,Hyemi Kim,Woo Joo Oh,Hongjin Cho,Hochul Lee,Hye Hyeon Kim*

Main category: cs.CL

TL;DR: 提出结合大语言模型和多示例学习的新框架，通过分解话语为情绪、逻辑和行为组件来检测认知扭曲，在韩语和英语数据集上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 认知扭曲与心理健康障碍密切相关，但由于上下文模糊性、共现性和语义重叠，其自动检测一直具有挑战性。

Method: 将每个话语分解为情绪、逻辑和行为（ELB）组件，使用LLM推断多个扭曲实例，通过多视图门控注意力机制进行集成分类。

Result: 在韩语（KoACD）和英语（Therapist QA）数据集上的实验表明，结合ELB和LLM推断的显著性分数提高了分类性能，特别是对于解释模糊性高的扭曲。

Conclusion: 该方法为心理健康NLP中的细粒度推理提供了一种心理基础且可推广的方法。

Abstract: Cognitive distortions have been closely linked to mental health disorders,
yet their automatic detection remained challenging due to contextual ambiguity,
co-occurrence, and semantic overlap. We proposed a novel framework that
combines Large Language Models (LLMs) with Multiple-Instance Learning (MIL)
architecture to enhance interpretability and expression-level reasoning. Each
utterance was decomposed into Emotion, Logic, and Behavior (ELB) components,
which were processed by LLMs to infer multiple distortion instances, each with
a predicted type, expression, and model-assigned salience score. These
instances were integrated via a Multi-View Gated Attention mechanism for final
classification. Experiments on Korean (KoACD) and English (Therapist QA)
datasets demonstrate that incorporating ELB and LLM-inferred salience scores
improves classification performance, especially for distortions with high
interpretive ambiguity. Our results suggested a psychologically grounded and
generalizable approach for fine-grained reasoning in mental health NLP.

</details>


### [73] [Scaling, Simplification, and Adaptation: Lessons from Pretraining on Machine-Translated Text](https://arxiv.org/abs/2509.17317)
*Dan John Velasco,Matthew Theodore Roque*

Main category: cs.CL

TL;DR: 该研究探讨了使用机器翻译从高资源语言生成数据来训练低资源语言模型的可行性，研究了模型容量扩展、源语言简化以及有限本地数据微调的效果。


<details>
  <summary>Details</summary>
Motivation: 大多数语言缺乏大规模单语预训练数据，存在"数据墙"问题。多语言预训练受限于语言不平衡和"多语言诅咒"。研究探索通过机器翻译生成数据作为替代方案。

Method: 将英语翻译成印度尼西亚语和泰米尔语，使用原始和LLM简化的英语文本，预训练GPT-2模型（124M-774M参数），评估在本地文本上的交叉熵损失、句法探测和下游任务准确性。

Result: 1）基于MT预训练的模型受益于规模扩展；2）源语言简化对本地文本泛化有害；3）在有限本地数据上微调MT预训练模型通常优于仅使用本地数据的模型，但需要文化细微差别的任务需要更多本地数据。

Conclusion: 机器翻译生成的数据可以有效支持低资源语言的模型预训练，特别是在模型规模扩展和有限本地数据微调方面表现良好，但对于需要文化理解的任务仍需更多本地数据。

Abstract: Most languages lack sufficient data for large-scale monolingual pretraining,
creating a "data wall." Multilingual pretraining helps but is limited by
language imbalance and the "curse of multilinguality." An alternative is to
translate high-resource text with machine translation (MT), which raises three
questions: (1) How does MT-derived data scale with model capacity? (2) Can
source-side transformations (e.g., simplifying English with an LLM) improve
generalization to native text? (3) How well do models pretrained on MT-derived
data adapt when continually trained on limited native text? We investigate
these questions by translating English into Indonesian and Tamil--two
typologically distant, lower-resource languages--and pretraining GPT-2 models
(124M-774M) on native or MT-derived corpora from raw and LLM-simplified
English. We evaluate cross-entropy loss on native text, along with accuracy on
syntactic probes and downstream tasks. Our results show that (1) MT-pretrained
models benefit from scaling; (2) source-side simplification harms
generalization to native text; and (3) adapting MT-pretrained models on native
text often yields better performance than native-only models, even with less
native data. However, tasks requiring cultural nuance (e.g., toxicity
detection) demand more exposure to native data.

</details>


### [74] [AIMMerging: Adaptive Iterative Model Merging Using Training Trajectories for Language Model Continual Learning](https://arxiv.org/abs/2509.17348)
*Yujie Feng,Jian Li,Xiaoyu Dong,Pengfei Xu,Xiaohui Zhou,Yujia Zhang,Zexin LU,Yasha Wang,Alan Zhao,Xu Chu,Xiao-Ming Wu*

Main category: cs.CL

TL;DR: AimMerging是一个新颖的持续学习框架，通过动态监测模型训练状态来自适应确定模型融合的时间和频率，有效平衡新知识学习和防止遗忘。


<details>
  <summary>Details</summary>
Motivation: 现有的基于模型融合的持续学习方法在管理新知识学习和防止遗忘之间的权衡方面存在困难，主要源于次优的融合次数和频率。

Method: AimMerging利用训练轨迹中的学习和遗忘信号动态监测模型状态，通过训练轨迹指导的融合控制器自适应确定迭代融合时机和频率，同时使用基于排练的知识融合模块计算融合权重并执行融合。

Result: 在三个持续学习基准测试中（模型规模从770M到13B），AimMerging相比现有最先进方法实现了显著性能提升，FWT和BWT分别平均相对提升80%和59%。

Conclusion: AimMerging框架通过自适应迭代模型融合有效解决了持续学习中的知识遗忘问题，在大规模语言模型上表现出优越性能。

Abstract: Continual learning (CL) is essential for deploying large language models
(LLMs) in dynamic real-world environments without the need for costly
retraining. Recent model merging-based methods have attracted significant
attention, but they still struggle to effectively manage the trade-off between
learning new knowledge and preventing forgetting, a challenge largely stemming
from suboptimal number of merges and merging frequency. In this paper, we
introduce Adaptive Iterative Model Merging (AimMerging), a novel CL framework
that utilizes learning and forgetting signals from the training trajectory to
dynamically monitor the model's training status. Guided by dynamic monitoring,
the training trajectory-guided merge controller adaptively determines the
timing and frequency of iterative fusion, while the rehearsal-based knowledge
fusion module computes the merging weights and executes the fusion.
Comprehensive experiments on three CL benchmarks with various model sizes (from
770M to 13B) demonstrate that AimMerging achieves significant performance
improvements over existing state-of-the-art methods, with an average relative
improvement of 80% and 59% on FWT and BWT, respectively. The source code is
provided for reproducibility.

</details>


### [75] [Better Late Than Never: Evaluation of Latency Metrics for Simultaneous Speech-to-Text Translation](https://arxiv.org/abs/2509.17349)
*Peter Polák,Sara Papi,Luisa Bentivogli,Ondřej Bojar*

Main category: cs.CL

TL;DR: 本文提出了YAAL和LongYAAL两个改进的延迟度量指标，以及SoftSegmenter重分割工具，用于更准确地评估同声传译系统的延迟性能。


<details>
  <summary>Details</summary>
Motivation: 现有的同声传译延迟度量指标在短文本设置下存在结构偏差，导致评估结果不一致或误导性，特别是在人工预分割的语音场景中。

Method: 1）提出YAAL指标改进短文本场景的延迟评估；2）扩展LongYAAL用于未分割音频；3）开发基于词级对齐的SoftSegmenter重分割工具。

Result: 实验表明YAAL和LongYAAL在语言对、系统配置和长短文本场景下都优于现有流行延迟度量指标，SoftSegmenter提升了长文本评估中的对齐质量。

Conclusion: 新提出的度量指标和工具能够为同声传译系统提供更可靠的延迟评估，解决了现有度量方法的结构偏差问题。

Abstract: Simultaneous speech-to-text translation (SimulST) systems have to balance
translation quality with latency--the delay between speech input and the
translated output. While quality evaluation is well established, accurate
latency measurement remains a challenge. Existing metrics often produce
inconsistent or misleading results, especially in the widely used short-form
setting, where speech is artificially presegmented. In this paper, we present
the first comprehensive analysis of SimulST latency metrics across language
pairs, systems, and both short- and long-form regimes. We uncover a structural
bias in current metrics related to segmentation that undermines fair and
meaningful comparisons. To address this, we introduce YAAL (Yet Another Average
Lagging), a refined latency metric that delivers more accurate evaluations in
the short-form regime. We extend YAAL to LongYAAL for unsegmented audio and
propose SoftSegmenter, a novel resegmentation tool based on word-level
alignment. Our experiments show that YAAL and LongYAAL outperform popular
latency metrics, while SoftSegmenter enhances alignment quality in long-form
evaluation, together enabling more reliable assessments of SimulST systems.

</details>


### [76] [Scale-free Characteristics of Multilingual Legal Texts and the Limitations of LLMs](https://arxiv.org/abs/2509.17367)
*Haoyang Chen,Kumiko Tanaka-Ishii*

Main category: cs.CL

TL;DR: 本文使用尺度无关指标比较不同领域文本的复杂性，发现法律文本具有独特的词汇增长模式和术语一致性，而AI生成文本更接近普通语言模式。


<details>
  <summary>Details</summary>
Motivation: 研究不同领域（法律文本、普通自然语言、AI生成文本）的文本复杂性差异，特别关注法律文本的领域特异性结构。

Method: 使用Heaps指数β（词汇增长）、Taylor指数α（词频波动缩放）、压缩率r（冗余度）和熵等尺度无关指标，分析法律文件、普通文本和GPT生成文本的语料库。

Result: 法律文本比普通文本词汇增长更慢（β更低）、术语一致性更高（α更高）；在法律领域内，法规代码的β最低、α最高，反映严格的起草规范；GPT生成文本的统计特征更接近普通语言。

Conclusion: 法律文本具有领域特定的结构和复杂性，当前生成模型未能完全复制这些特征。

Abstract: We present a comparative analysis of text complexity across domains using
scale-free metrics. We quantify linguistic complexity via Heaps' exponent
$\beta$ (vocabulary growth), Taylor's exponent $\alpha$ (word-frequency
fluctuation scaling), compression rate $r$ (redundancy), and entropy. Our
corpora span three domains: legal documents (statutes, cases, deeds) as a
specialized domain, general natural language texts (literature, Wikipedia), and
AI-generated (GPT) text. We find that legal texts exhibit slower vocabulary
growth (lower $\beta$) and higher term consistency (higher $\alpha$) than
general texts. Within legal domain, statutory codes have the lowest $\beta$ and
highest $\alpha$, reflecting strict drafting conventions, while cases and deeds
show higher $\beta$ and lower $\alpha$. In contrast, GPT-generated text shows
the statistics more aligning with general language patterns. These results
demonstrate that legal texts exhibit domain-specific structures and
complexities, which current generative models do not fully replicate.

</details>


### [77] [Robustness of Neurosymbolic Reasoners on First-Order Logic Problems](https://arxiv.org/abs/2509.17377)
*Hannah Bansal,Kemal Kurniawan,Lea Frermann*

Main category: cs.CL

TL;DR: 该论文探讨了神经符号方法是否能提高大语言模型在反事实逻辑推理任务中的鲁棒性，发现虽然神经符号方法更稳健，但整体性能不如纯神经方法，而结合思维链的NSCoT方法虽有改进但仍落后于标准思维链方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明大语言模型在反事实逻辑推理任务中表现脆弱，容易依赖表面模式而非真正逻辑推理，因此需要探索神经符号方法是否能提高其推理鲁棒性。

Method: 采用神经符号方法，将大语言模型与符号逻辑求解器结合，并在不同规模的大语言模型上进行实验，同时提出结合思维链的NSCoT方法。

Result: 神经符号方法比纯神经方法更稳健，但整体性能较差；NSCoT方法虽然能提升性能，但仍落后于标准思维链方法。

Conclusion: 神经符号方法在提高推理鲁棒性方面有潜力，但需要进一步研究来缩小与纯神经方法的性能差距，为未来工作指明了研究方向。

Abstract: Recent trends in NLP aim to improve reasoning capabilities in Large Language
Models (LLMs), with key focus on generalization and robustness to variations in
tasks. Counterfactual task variants introduce minimal but semantically
meaningful changes to otherwise valid first-order logic (FOL) problem instances
altering a single predicate or swapping roles of constants to probe whether a
reasoning system can maintain logical consistency under perturbation. Previous
studies showed that LLMs becomes brittle on counterfactual variations,
suggesting that they often rely on spurious surface patterns to generate
responses. In this work, we explore if a neurosymbolic (NS) approach that
integrates an LLM and a symbolic logical solver could mitigate this problem.
Experiments across LLMs of varying sizes show that NS methods are more robust
but perform worse overall that purely neural methods. We then propose NSCoT
that combines an NS method and Chain-of-Thought (CoT) prompting and demonstrate
that while it improves performance, NSCoT still lags behind standard CoT. Our
analysis opens research directions for future work.

</details>


### [78] [FinDebate: Multi-Agent Collaborative Intelligence for Financial Analysis](https://arxiv.org/abs/2509.17395)
*Tianshi Cai,Guanxu Li,Nijia Han,Ce Huang,Zimu Wang,Changyu Zeng,Yuqi Wang,Jingshi Zhou,Haiyang Zhang,Qi Chen,Yushan Pan,Shuihua Wang,Wei Wang*

Main category: cs.CL

TL;DR: FinDebate是一个用于金融分析的多智能体框架，结合了协作辩论和领域特定的检索增强生成技术。


<details>
  <summary>Details</summary>
Motivation: 为了解决金融分析中过度自信和可靠性不足的问题，需要一种能够整合多方证据并产生校准置信度的分析框架。

Method: 使用五个专业智能体（收益、市场、情绪、估值和风险）并行运行，通过安全辩论协议让智能体相互挑战和优化初始结论。

Result: 基于LLM和人工评估的实验结果表明，该框架能够产生高质量的分析结果，具有校准的置信度水平，并生成跨多个时间范围的可操作投资策略。

Conclusion: FinDebate框架在金融分析中表现出色，能够提供可靠的多维度洞察和投资建议。

Abstract: We introduce FinDebate, a multi-agent framework for financial analysis,
integrating collaborative debate with domain-specific Retrieval-Augmented
Generation (RAG). Five specialized agents, covering earnings, market,
sentiment, valuation, and risk, run in parallel to synthesize evidence into
multi-dimensional insights. To mitigate overconfidence and improve reliability,
we introduce a safe debate protocol that enables agents to challenge and refine
initial conclusions while preserving coherent recommendations. Experimental
results, based on both LLM-based and human evaluations, demonstrate the
framework's efficacy in producing high-quality analysis with calibrated
confidence levels and actionable investment strategies across multiple time
horizons.

</details>


### [79] [EpiCache: Episodic KV Cache Management for Long Conversational Question Answering](https://arxiv.org/abs/2509.17396)
*Minsoo Kim,Arnav Kundu,Han-Byul Kim,Richa Dixit,Minsik Cho*

Main category: cs.CL

TL;DR: EpiCache是一个无需训练的KV缓存管理框架，通过分块预填充和情景化KV压缩来解决长对话问答中的内存限制问题，在严格资源约束下实现高效的多轮交互。


<details>
  <summary>Details</summary>
Motivation: 现有KV缓存压缩方法存在两个主要限制：全上下文预填充后驱逐条目会导致无界峰值内存，以及查询相关驱逐将缓存限制为单一查询，导致多轮对话准确性下降。

Method: EpiCache采用分块预填充技术限制缓存增长，通过情景化KV压缩将对话历史聚类为连贯的情景并应用情景特定的KV缓存驱逐策略，同时设计了自适应分层预算分配策略来优化内存使用。

Result: 在三个长对话问答基准测试中，EpiCache相比现有基线方法准确率提升高达40%，在4-6倍压缩下保持接近完整的KV准确性，延迟和内存分别减少高达2.4倍和3.5倍。

Conclusion: EpiCache能够在严格资源约束下实现高效的多轮交互，为长对话问答场景下的KV缓存管理提供了有效的解决方案。

Abstract: Recent advances in large language models (LLMs) have extended context
lengths, enabling assistants to sustain long histories for coherent,
personalized responses. This ability, however, hinges on Key-Value (KV)
caching, whose memory grows linearly with dialogue length and quickly dominates
under strict resource constraints. An active line of research for reducing this
overhead is KV cache compression, which seeks to limit cache size while
preserving accuracy. Yet existing methods face two major limitations: (i)
evicting entries after full-context prefill causes unbounded peak memory, and
(ii) query-dependent eviction narrows the cache to a single query, leading to
degraded accuracy in multi-turn conversations. We introduce EpiCache, a
training-free KV cache management framework for long conversational question
answering (LongConvQA) under fixed memory budgets. EpiCache bounds cache growth
through block-wise prefill and preserves topic-relevant context via episodic KV
compression, which clusters conversation history into coherent episodes and
applies episode-specific KV cache eviction. We further design an adaptive
layer-wise budget allocation strategy that measures each layer's sensitivity to
eviction and distributes the memory budget across layers accordingly. Across
three LongConvQA benchmarks, EpiCache improves accuracy by up to 40% over
recent baselines, sustains near-full KV accuracy under 4-6x compression, and
reduces latency and memory by up to 2.4x and 3.5x, thereby enabling efficient
multi-turn interaction under strict resource constraints.

</details>


### [80] [DIWALI - Diversity and Inclusivity aWare cuLture specific Items for India: Dataset and Assessment of LLMs for Cultural Text Adaptation in Indian Context](https://arxiv.org/abs/2509.17399)
*Pramit Sahoo,Maharaj Brahma,Maunendra Sankar Desarkar*

Main category: cs.CL

TL;DR: 该论文针对大型语言模型在文化对齐方面的不足，提出了一个专门针对印度文化的文化特定项目数据集DIWALI，用于评估LLMs的文化能力。


<details>
  <summary>Details</summary>
Motivation: 现有LLMs缺乏文化对齐能力，产生有偏见的生成结果，且缺乏合适的评估指标和代表区域及次区域文化复杂性的数据集。

Method: 构建包含约8,000个文化概念的印度文化数据集，涵盖17个文化方面和36个次区域，使用CSI、LLM作为评判者和人类评估来测量LLMs的文化文本适应能力。

Result: 定量分析显示所有考虑的LLMs都存在选择性次区域覆盖和表面级适应问题。

Conclusion: DIWALI数据集为评估LLMs的文化能力提供了重要资源，揭示了当前模型在文化对齐方面的局限性。

Abstract: Large language models (LLMs) are widely used in various tasks and
applications. However, despite their wide capabilities, they are shown to lack
cultural alignment \citep{ryan-etal-2024-unintended,
alkhamissi-etal-2024-investigating} and produce biased generations
\cite{naous-etal-2024-beer} due to a lack of cultural knowledge and competence.
Evaluation of LLMs for cultural awareness and alignment is particularly
challenging due to the lack of proper evaluation metrics and unavailability of
culturally grounded datasets representing the vast complexity of cultures at
the regional and sub-regional levels. Existing datasets for culture specific
items (CSIs) focus primarily on concepts at the regional level and may contain
false positives. To address this issue, we introduce a novel CSI dataset for
Indian culture, belonging to 17 cultural facets. The dataset comprises $\sim$8k
cultural concepts from 36 sub-regions. To measure the cultural competence of
LLMs on a cultural text adaptation task, we evaluate the adaptations using the
CSIs created, LLM as Judge, and human evaluations from diverse
socio-demographic region. Furthermore, we perform quantitative analysis
demonstrating selective sub-regional coverage and surface-level adaptations
across all considered LLMs. Our dataset is available here:
\href{https://huggingface.co/datasets/nlip/DIWALI}{https://huggingface.co/datasets/nlip/DIWALI},
project
webpage\footnote{\href{https://nlip-lab.github.io/nlip/publications/diwali/}{https://nlip-lab.github.io/nlip/publications/diwali/}},
and our codebase with model outputs can be found here:
\href{https://github.com/pramitsahoo/culture-evaluation}{https://github.com/pramitsahoo/culture-evaluation}.

</details>


### [81] [Vision Language Models Are Not (Yet) Spelling Correctors](https://arxiv.org/abs/2509.17418)
*Junhong Liang,Bojun Zhang*

Main category: cs.CL

TL;DR: ReViCo是首个系统评估视觉语言模型在真实世界视觉拼写纠正任务上的基准，包含中英文自然错误数据，实验显示当前模型在纠正方面远低于人类水平，并提出了两种改进方法。


<details>
  <summary>Details</summary>
Motivation: 视觉输入中的拼写纠正确认视觉语言模型面临独特挑战，需要直接在图像中检测和纠正文本错误，但目前缺乏系统评估基准。

Method: 构建ReViCo基准，包含真实世界图像中的自然错误；评估代表性开源和闭源模型；提出联合OCR-纠正管道和背景信息增强两种改进方法。

Result: 当前视觉语言模型在拼写纠正方面表现显著低于人类水平，特别是在纠正任务上；提出的两种方法都能带来一致的性能提升。

Conclusion: 分析揭示了现有架构的根本局限性，为推进多模态拼写纠正提供了可行的见解，ReViCo基准将促进该领域的发展。

Abstract: Spelling correction from visual input poses unique challenges for vision
language models (VLMs), as it requires not only detecting but also correcting
textual errors directly within images. We present ReViCo (Real Visual
Correction), the first benchmark that systematically evaluates VLMs on
real-world visual spelling correction across Chinese and English. ReViCo
contains naturally occurring errors collected from real-world image data and
supports fine-grained evaluation at both image and token levels. Through
comprehensive experiments on representative cascaded (Qwen) and native
(InternVL) open-source models, as well as closed-source systems (GPT-4o,
Claude), we show that current VLMs fall significantly short of human
performance, particularly in correction. To address these limitations, we
explore two solution paradigms: a Joint OCR-Correction pipeline and a
Background Information enhanced approach, both of which yield consistent
performance gains. Our analysis highlights fundamental limitations of existing
architectures and provides actionable insights for advancing multimodal
spelling correction.

</details>


### [82] [RealBench: A Chinese Multi-image Understanding Benchmark Close to Real-world Scenarios](https://arxiv.org/abs/2509.17421)
*Fei Zhao,Chengqiang Lu,Yufan Shen,Qimeng Wang,Yicheng Qian,Haoxin Zhang,Yan Gao,Yi Wu,Yao Hu,Zhen Wu,Shangyu Xing,Xinyu Dai*

Main category: cs.CL

TL;DR: RealBench是第一个中文多模态多图像数据集，包含9393个样本和69910张图像，基于真实用户生成内容，涵盖多样场景和图像结构，用于评估多图像理解能力。


<details>
  <summary>Details</summary>
Motivation: 填补中文多图像数据集的空白，现有数据集主要基于英文，缺乏针对中文多图像理解的研究基础。

Method: 构建包含真实用户生成内容的中文多模态多图像数据集RealBench，涵盖多种场景、分辨率和图像结构，并使用21个不同规模的多模态大语言模型进行综合评估。

Result: 实验结果显示，即使最强大的闭源模型在处理中文多图像场景时仍面临挑战，开源视觉/视频模型与闭源模型之间存在平均约71.8%的性能差距。

Conclusion: RealBench为在中文语境下进一步探索多图像理解能力提供了重要的研究基础，揭示了当前模型在多图像中文场景处理上的局限性。

Abstract: While various multimodal multi-image evaluation datasets have been emerged,
but these datasets are primarily based on English, and there has yet to be a
Chinese multi-image dataset. To fill this gap, we introduce RealBench, the
first Chinese multimodal multi-image dataset, which contains 9393 samples and
69910 images. RealBench distinguishes itself by incorporating real
user-generated content, ensuring high relevance to real-world applications.
Additionally, the dataset covers a wide variety of scenes, image resolutions,
and image structures, further increasing the difficulty of multi-image
understanding. Ultimately, we conduct a comprehensive evaluation of RealBench
using 21 multimodal LLMs of different sizes, including closed-source models
that support multi-image inputs as well as open-source visual and video models.
The experimental results indicate that even the most powerful closed-source
models still face challenges when handling multi-image Chinese scenarios.
Moreover, there remains a noticeable performance gap of around 71.8\% on
average between open-source visual/video models and closed-source models. These
results show that RealBench provides an important research foundation for
further exploring multi-image understanding capabilities in the Chinese
context.

</details>


### [83] [QWHA: Quantization-Aware Walsh-Hadamard Adaptation for Parameter-Efficient Fine-Tuning on Large Language Models](https://arxiv.org/abs/2509.17428)
*Hyesung Jeon,Seojune Lee,Beomseok Kang,Yulhwa Kim,Jae-Joon Kim*

Main category: cs.CL

TL;DR: QWHA是一种针对量化大语言模型的高效微调方法，通过Walsh-Hadamard变换和创新的适配器初始化方案，有效降低量化误差并减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有量化感知的PEFT方法存在表示能力有限的问题，而基于傅里叶变换的适配器虽然表示能力更强，但在量化模型中直接集成会导致错误减少效果不佳和计算开销增加。

Method: 提出QWHA方法，使用Walsh-Hadamard变换作为变换核，结合包含自适应参数选择和值细化的新型适配器初始化方案，将FT-based适配器集成到量化模型中。

Result: 实验结果显示QWHA在低比特量化精度上持续优于基线方法，相比现有FT-based适配器实现了显著的训练加速。

Conclusion: QWHA能够有效缓解量化误差并促进微调，其设计显著降低了计算成本，为大语言模型的高效部署提供了有效解决方案。

Abstract: The demand for efficient deployment of large language models (LLMs) has
driven interest in quantization, which reduces inference cost, and
parameter-efficient fine-tuning (PEFT), which lowers training overhead. This
motivated the development of quantization-aware PEFT to produce accurate yet
efficient quantized models. In this setting, reducing quantization error prior
to fine-tuning is crucial for achieving high model accuracy. However, existing
methods that rely on low-rank adaptation suffer from limited representational
capacity. Recent Fourier-related transform (FT)-based adapters offer greater
representational power than low-rank adapters, but their direct integration
into quantized models often results in ineffective error reduction and
increased computational overhead. To overcome these limitations, we propose
QWHA, a method that integrates FT-based adapters into quantized models by
employing the Walsh-Hadamard Transform (WHT) as the transform kernel, together
with a novel adapter initialization scheme incorporating adaptive parameter
selection and value refinement. We demonstrate that QWHA effectively mitigates
quantization errors while facilitating fine-tuning, and that its design
substantially reduces computational cost. Experimental results show that QWHA
consistently outperforms baselines in low-bit quantization accuracy and
achieves significant training speedups over existing FT-based adapters. The
code is available at https://github.com/vantaa89/qwha.

</details>


### [84] [MedFact: A Large-scale Chinese Dataset for Evidence-based Medical Fact-checking of LLM Responses](https://arxiv.org/abs/2509.17436)
*Tong Chen,Zimu Wang,Yiyi Miao,Haoran Luo,Yuanfei Sun,Wei Wang,Zhengyong Jiang,Procheta Sen,Jionglong Su*

Main category: cs.CL

TL;DR: MedFact是首个基于证据的中文医疗事实核查数据集，专注于大语言模型生成的医疗内容，包含1,321个问题和7,409个声明，旨在解决现有数据集主要关注人类生成内容而忽略LLM生成内容验证的问题。


<details>
  <summary>Details</summary>
Motivation: 随着越来越多人在线寻求医疗信息，医疗事实核查变得日益重要。然而现有数据集主要关注人类生成内容，对大语言模型生成的医疗内容的验证研究相对缺乏。

Method: 构建了MedFact数据集，包含1,321个问题和7,409个声明，反映了真实世界医疗场景的复杂性。在上下文学习和微调设置下进行了全面实验。

Result: 实验展示了当前LLMs在该任务上的能力和挑战，并进行了深入的错误分析。

Conclusion: 该研究为医疗事实核查领域提供了首个专门针对LLM生成内容的数据集，指出了未来研究的关键方向，数据集已公开可用。

Abstract: Medical fact-checking has become increasingly critical as more individuals
seek medical information online. However, existing datasets predominantly focus
on human-generated content, leaving the verification of content generated by
large language models (LLMs) relatively unexplored. To address this gap, we
introduce MedFact, the first evidence-based Chinese medical fact-checking
dataset of LLM-generated medical content. It consists of 1,321 questions and
7,409 claims, mirroring the complexities of real-world medical scenarios. We
conduct comprehensive experiments in both in-context learning (ICL) and
fine-tuning settings, showcasing the capability and challenges of current LLMs
on this task, accompanied by an in-depth error analysis to point out key
directions for future research. Our dataset is publicly available at
https://github.com/AshleyChenNLP/MedFact.

</details>


### [85] [GeoPQA: Bridging the Visual Perception Gap in MLLMs for Geometric Reasoning](https://arxiv.org/abs/2509.17437)
*Guizhen Chen,Weiwen Xu,Hao Zhang,Hou Pong Chan,Deli Zhao,Anh Tuan Luu,Yu Rong*

Main category: cs.CL

TL;DR: 该论文提出了一种两阶段强化学习训练框架，通过先增强多模态大语言模型的视觉感知能力，再培养推理能力，来解决几何推理等视觉密集型任务中的幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在视觉密集型任务（如几何推理）中经常出现幻觉，导致推理不准确。作者认为这是由于MLLMs存在感知瓶颈，限制了推理训练的效果。

Method: 设计了GeoPQA基准测试来量化感知瓶颈，并提出两阶段RL训练框架：第一阶段增强几何结构的视觉感知，第二阶段培养推理能力。

Result: 在Qwen2.5-VL-3B-Instruct模型上，两阶段训练相比直接推理训练方法，几何推理能力提升9.7%，几何问题解决能力提升9.1%。该方法在其他视觉密集型领域（如图表理解）也表现出良好的泛化能力。

Conclusion: 研究强调了感知基础在有效MLLM推理中的重要性，表明增强视觉感知能力是提升多模态大语言模型推理性能的关键。

Abstract: Recent advancements in reinforcement learning (RL) have enhanced the
reasoning abilities of large language models (LLMs), yet the impact on
multimodal LLMs (MLLMs) is limited. Particularly in vision-intensive tasks like
geometric reasoning, MLLMs hallucinate frequently, leading to inaccurate
reasoning. We attribute this to the perceptual bottleneck in MLLMs, which caps
the benefits of reasoning training. To quantify this, we design a
Geo-Perception Question-Answering (GeoPQA) benchmark, targeting basic geometric
concepts and spatial relationships. Experiments on GeoPQA reveal significant
shortcomings of MLLMs in visual perception, which constrain RL reward signals
for effective training. To address this bottleneck, we propose a two-stage RL
training framework by first enhancing the visual perception of geometric
structures, then fostering reasoning capabilities. Applied to
Qwen2.5-VL-3B-Instruct, our two-stage training improves geometric reasoning by
9.7% and geometric problem solving by 9.1%, compared to the direct reasoning
training approach. Our method also generalizes to other vision-intensive
domains like figure understanding, highlighting the importance of perceptual
grounding in effective MLLM reasoning.

</details>


### [86] [Filling in the Clinical Gaps in Benchmark: Case for HealthBench for the Japanese medical system](https://arxiv.org/abs/2509.17444)
*Shohei Hisada,Endo Sunao,Himi Yamato,Shoko Wakamiya,Eiji Aramaki*

Main category: cs.CL

TL;DR: 本研究探讨了将HealthBench医学基准应用于日本语境的适用性，发现直接翻译基准存在局限性，需要针对日本临床指南、医疗系统和文化规范进行本地化适配。


<details>
  <summary>Details</summary>
Motivation: 日本语医学LLM评估资源有限，主要依赖翻译的多选题，缺乏针对日本医疗环境的鲁棒评估框架。

Method: 1) 使用机器翻译的HealthBench基准评估多语言模型和日本本土模型；2) 采用LLM-as-a-Judge方法系统分类基准场景和评分标准，识别与日本医疗环境不匹配的"语境差距"。

Result: GPT-4.1因评分标准不匹配出现性能下降，日本本土模型在临床完整性方面表现显著不足；多数场景适用但大量评分标准需要本地化。

Conclusion: 直接翻译基准存在局限性，迫切需要开发针对日本语境的J-HealthBench，以确保医学LLM在日本的安全可靠评估。

Abstract: This study investigates the applicability of HealthBench, a large-scale,
rubric-based medical benchmark, to the Japanese context. While robust
evaluation frameworks are crucial for the safe development of medical LLMs,
resources in Japanese remain limited, often relying on translated
multiple-choice questions. Our research addresses this gap by first
establishing a performance baseline, applying a machine-translated version of
HealthBench's 5,000 scenarios to evaluate both a high-performing multilingual
model (GPT-4.1) and a Japanese-native open-source model (LLM-jp-3.1). Second,
we employ an LLM-as-a-Judge approach to systematically classify the benchmark's
scenarios and rubric criteria, identifying "contextual gaps" where content is
misaligned with Japan's clinical guidelines, healthcare systems, or cultural
norms. Our findings reveal a modest performance drop in GPT-4.1 due to rubric
mismatches and a significant failure in the Japanese-native model, which lacked
the required clinical completeness. Furthermore, our classification indicates
that while the majority of scenarios are applicable, a substantial portion of
the rubric criteria requires localization. This work underscores the
limitations of direct benchmark translation and highlights the urgent need for
a context-aware, localized adaptation, a J-HealthBench, to ensure the reliable
and safe evaluation of medical LLMs in Japan.

</details>


### [87] [Semantic Reformulation Entropy for Robust Hallucination Detection in QA Tasks](https://arxiv.org/abs/2509.17445)
*Chaodong Tong,Qi Zhang,Lei Jiang,Yanbing Liu,Nannan Sun,Wei Li*

Main category: cs.CL

TL;DR: 本文提出语义重构熵（SRE）方法，通过输入侧语义重构和渐进式能量混合聚类来改进大语言模型的不确定性估计，从而更可靠地检测幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于熵的语义级不确定性估计方法受限于采样噪声和变长答案的不稳定聚类，导致大语言模型在问答任务中产生幻觉（事实错误的流畅输出）。

Method: 提出SRE方法：1）输入侧语义重构生成忠实释义，扩展估计空间，减少解码器表面倾向的偏差；2）渐进式能量混合聚类稳定语义分组。

Result: 在SQuAD和TriviaQA数据集上的实验表明，SRE优于强基线方法，提供更鲁棒和可泛化的幻觉检测。

Conclusion: 结合输入多样化和多信号聚类能显著增强语义级不确定性估计，为解决大语言模型的幻觉问题提供了有效方案。

Abstract: Reliable question answering with large language models (LLMs) is challenged
by hallucinations, fluent but factually incorrect outputs arising from
epistemic uncertainty. Existing entropy-based semantic-level uncertainty
estimation methods are limited by sampling noise and unstable clustering of
variable-length answers. We propose Semantic Reformulation Entropy (SRE), which
improves uncertainty estimation in two ways. First, input-side semantic
reformulations produce faithful paraphrases, expand the estimation space, and
reduce biases from superficial decoder tendencies. Second, progressive,
energy-based hybrid clustering stabilizes semantic grouping. Experiments on
SQuAD and TriviaQA show that SRE outperforms strong baselines, providing more
robust and generalizable hallucination detection. These results demonstrate
that combining input diversification with multi-signal clustering substantially
enhances semantic-level uncertainty estimation.

</details>


### [88] [SLAyiNG: Towards Queer Language Processing](https://arxiv.org/abs/2509.17449)
*Leonor Veloso,Lea Hirlimann,Philipp Wicke,Hinrich Schütze*

Main category: cs.CL

TL;DR: 本文介绍了SLAyiNG数据集，这是第一个包含来自字幕、社交媒体帖子和播客的注释性酷儿俚语的数据集，旨在解决LLMs在处理酷儿俚语时可能产生的误解和负面响应问题。


<details>
  <summary>Details</summary>
Motivation: 酷儿俚语在用户交互中常被LLMs误判为仇恨言论或引发负面响应，但目前缺乏高质量注释基准来评估酷儿俚语的检测和处理。

Method: 通过收集俚语术语和定义，从字幕、社交媒体和播客中抓取反映这些术语使用的示例，并进行人工注释和OpenAI模型o3-mini的感知消歧任务评估。

Result: 初步结果显示，人工注释者与o3-mini模型的平均Krippendorff's alpha为0.746，表明先进推理模型可用于预过滤，但复杂敏感的酷儿语言数据仍需专家和社区驱动的注释工作。

Conclusion: SLAyiNG数据集填补了酷儿俚语注释基准的空白，强调了在酷儿语言数据处理中结合自动化工具与专家注释的重要性。

Abstract: Knowledge of slang is a desirable feature of LLMs in the context of user
interaction, as slang often reflects an individual's social identity. Several
works on informal language processing have defined and curated benchmarks for
tasks such as detection and identification of slang. In this paper, we focus on
queer slang. Queer slang can be mistakenly flagged as hate speech or can evoke
negative responses from LLMs during user interaction. Research efforts so far
have not focused explicitly on queer slang. In particular, detection and
processing of queer slang have not been thoroughly evaluated due to the lack of
a high-quality annotated benchmark. To address this gap, we curate SLAyiNG, the
first dataset containing annotated queer slang derived from subtitles, social
media posts, and podcasts, reflecting real-world usage. We describe our data
curation process, including the collection of slang terms and definitions,
scraping sources for examples that reflect usage of these terms, and our
ongoing annotation process. As preliminary results, we calculate
inter-annotator agreement for human annotators and OpenAI's model o3-mini,
evaluating performance on the task of sense disambiguation. Reaching an average
Krippendorff's alpha of 0.746, we argue that state-of-the-art reasoning models
can serve as tools for pre-filtering, but the complex and often sensitive
nature of queer language data requires expert and community-driven annotation
efforts.

</details>


### [89] [Codifying Natural Langauge Tasks](https://arxiv.org/abs/2509.17455)
*Haoyang Chen,Kumiko Tanaka-Ishii*

Main category: cs.CL

TL;DR: ICRAG框架通过将自然语言转换为可执行程序，利用外部知识进行迭代优化，在13个基准测试中实现了最高161.1%的相对改进。


<details>
  <summary>Details</summary>
Motivation: 探索文本到代码方法在解决现实世界问题（如法律判决和医疗问答）中的应用，利用程序生成提供的显式推理能力。

Method: 提出ICRAG框架，通过从领域资源和GitHub获取外部知识，对自然语言进行迭代精炼，生成可执行程序。

Result: 在13个基准测试中取得显著改进，相对性能提升最高达161.1%。

Conclusion: 分析了生成代码的质量和外部知识的影响，讨论了将文本到代码方法应用于现实世界自然语言任务的局限性。

Abstract: We explore the applicability of text-to-code to solve real-world problems
that are typically solved in natural language, such as legal judgment and
medical QA. Unlike previous works, our approach leverages the explicit
reasoning provided by program generation. We present ICRAG, a framework that
transforms natural language into executable programs through iterative
refinement using external knowledge from domain resources and GitHub. Across 13
benchmarks, ICRAG achieves up to 161.1\% relative improvement. We provide a
detailed analysis of the generated code and the impact of external knowledge,
and we discuss the limitations of applying text-to-code approaches to
real-world natural language tasks.

</details>


### [90] [PRINCIPLES: Synthetic Strategy Memory for Proactive Dialogue Agents](https://arxiv.org/abs/2509.17459)
*Namyoung Kim,Kai Tzu-iunn Ong,Yeonjun Hwang,Minseok Kang,Iiseo Jihn,Gayoung Kim,Minju Kim,Jinyoung Yeo*

Main category: cs.CL

TL;DR: 提出了PRINCIPLES方法，通过离线自博弈模拟构建策略记忆库，用于指导主动对话中的策略规划，无需额外训练和数据标注。


<details>
  <summary>Details</summary>
Motivation: 现有主动对话策略规划方法存在策略覆盖有限、规划偏好偏差、依赖昂贵额外训练等问题。

Method: 通过离线自博弈模拟生成合成策略记忆库，作为可重用知识在推理时指导策略规划。

Result: 在情感支持和说服领域评估显示，相比强基线模型取得一致改进，并在扩展和多样化评估设置中保持鲁棒性。

Conclusion: PRINCIPLES方法有效解决了主动对话策略规划的局限性，提供了一种无需额外训练的高效解决方案。

Abstract: Dialogue agents based on large language models (LLMs) have shown promising
performance in proactive dialogue, which requires effective strategy planning.
However, existing approaches to strategy planning for proactive dialogue face
several limitations: limited strategy coverage, preference bias in planning,
and reliance on costly additional training. To address these, we propose
PRINCIPLES: a synthetic strategy memory for proactive dialogue agents.
PRINCIPLES is derived through offline self-play simulations and serves as
reusable knowledge that guides strategy planning during inference, eliminating
the need for additional training and data annotation. We evaluate PRINCIPLES in
both emotional support and persuasion domains, demonstrating consistent
improvements over strong baselines. Furthermore, PRINCIPLES maintains its
robustness across extended and more diverse evaluation settings. See our
project page at https://huggingface.co/spaces/kimnamssya/Principles.

</details>


### [91] [Diagnosing Model Editing via Knowledge Spectrum](https://arxiv.org/abs/2509.17482)
*Tsung-Hsuan Pan,Chung-Chi Chen,Hen-Hsen Huang,Hsin-Hsi Chen*

Main category: cs.CL

TL;DR: 本文提出了知识谱系框架来系统分类知识特性，并开发了知识诊断框架来根据知识难度自适应调整编辑强度，显著提升了模型编辑的成功率。


<details>
  <summary>Details</summary>
Motivation: 现有模型编辑方法往往会产生不可预测的副作用，而目标知识的内在特性这一重要因素尚未得到充分研究。

Method: 首先提出知识谱系框架，基于知识流行度、模型熟悉度和问题语言结构分类知识；然后开发知识诊断框架，根据知识难度自适应调整编辑强度。

Result: 实证分析表明知识特性是编辑成功和稳定性的强预测因子，知识诊断框架显著提高了困难编辑的成功率并优化了计算资源。

Conclusion: 这项工作为理解模型编辑的调控因素提供了更全面的视角，证明了考虑知识内在特性的重要性。

Abstract: Model editing, the process of efficiently modifying factual knowledge in
pre-trained language models, is critical for maintaining their accuracy and
relevance. However, existing editing methods often introduce unintended side
effects, degrading model performance in unpredictable ways. While much research
has focused on improving editing algorithms, the role of the target knowledge's
intrinsic properties remains a significant, underexplored factor. This paper
addresses this gap by first proposing the ``Knowledge Spectrum,'' a systematic
framework for categorizing knowledge based on its real-world popularity, the
model's pre-edit familiarity, and the linguistic structure of the eliciting
question. Our empirical analysis reveals that these characteristics are strong
predictors of editing success and stability. Informed by these findings, we
introduce the ``Knowledge-Diagnostic Framework,'' an adaptive strategy that
tailors editing intensity to the diagnosed difficulty of a knowledge item. We
demonstrate that this framework significantly improves success rates for
challenging edits while optimizing computational resources. Our work provides a
more comprehensive understanding of the factors governing model editing.

</details>


### [92] [AttnComp: Attention-Guided Adaptive Context Compression for Retrieval-Augmented Generation](https://arxiv.org/abs/2509.17486)
*Lvzhou Luo,Yixuan Cao,Ping Luo*

Main category: cs.CL

TL;DR: AttnComp是一个自适应、高效且上下文感知的压缩框架，通过利用LLM的注意力机制识别相关信息，采用Top-P压缩算法保留最小文档集，提高检索增强生成的事实准确性。


<details>
  <summary>Details</summary>
Motivation: 检索增强生成虽然能提高LLM的事实准确性，但常因检索到无关内容而影响效果。现有压缩方法难以自适应调整压缩率、保持低延迟并整合多文档信息。

Method: 利用LLM的注意力机制识别相关信息，采用Top-P压缩算法保留累积注意力权重超过预设阈值的最小文档集，同时评估响应置信度。

Result: 实验表明AttnComp优于现有压缩方法和未压缩基线，在保持高压缩率和低延迟的同时实现更高准确性。

Conclusion: AttnComp有效解决了检索增强生成中的无关内容问题，提供了自适应、高效的上下文压缩方案。

Abstract: Retrieval-augmented generation improves the factual accuracy of Large
Language Models (LLMs) by incorporating external context, but often suffers
from irrelevant retrieved content that hinders effectiveness. Context
compression addresses this issue by filtering out irrelevant information from
context before LLM generation. However, existing methods struggle to adaptively
adjust compression rates for different context, maintain low latency and
integrate information across multiple documents. To overcome these limitations,
We introduce AttnComp, an adaptive, efficient and context-aware compression
framework. By leveraging the attention mechanism of LLMs to identify relevant
information, AttnComp employs a Top-P compression algorithm to retain the
minimal set of documents whose cumulative attention weights exceeds a
predefined threshold. In addition to compression, AttnComp estimates response
confidence by assessing the overall relevance of the retrieved content,
enabling users to gauge response reliability. Experiments demonstrate that
AttnComp outperforms existing compression methods and uncompressed baselines,
achieving higher accuracy with substantial compression rates and lower latency.

</details>


### [93] [MapCoder-Lite: Squeezing Multi-Agent Coding into a Single Small LLM](https://arxiv.org/abs/2509.17489)
*Woongkyu Lee,Junhee Cho,Jungwook Choi*

Main category: cs.CL

TL;DR: MapCoder-Lite将单个7B模型升级为四个角色专业化代理（检索器、规划器、编码器、调试器），仅使用rank-32 LoRA适配器（<3%额外参数），在小模型上实现高质量多代理代码生成。


<details>
  <summary>Details</summary>
Motivation: 现有多代理解决方案要么依赖昂贵的大规模模型（>30B），要么在缩小到小型开源模型时崩溃，需要开发能在小模型上有效工作的多代理代码生成系统。

Method: 使用三种轻量级技术：1）从强LLM进行轨迹蒸馏修复检索和调试中的格式脆弱性；2）监督者引导的纠正强化规划和编码代理；3）代理级LoRA微调实现内存高效专业化。

Result: 在xCodeEval、APPS和CodeContests上的综合评估显示，MapCoder-Lite将xCodeEval准确率从13.2%提升至28.3%，消除所有格式失败，接近32B基线6个百分点，同时将GPU内存和token生成时间减少4倍。

Conclusion: 精心设计的代理级微调能够在小语言模型上释放高质量的多代理编码能力。

Abstract: Large language models (LLMs) have advanced code generation from
single-function tasks to competitive-programming problems, but existing
multi-agent solutions either rely on costly large-scale ($>$ 30B) models or
collapse when downsized to small open-source models. We present MapCoder-Lite,
which upgrades a single 7B model into four role-specialised agents-retriever,
planner, coder, and debugger-using only rank-32, role-specific LoRA adapters
($<3\%$ extra parameters). Three lightweight techniques make this possible: (i)
trajectory distillation from strong LLMs fixes format fragility in retrieval
and debugging, (ii) supervisor-guided correction strengthens planning and
coding agents, and (iii) agent-wise LoRA fine-tuning delivers memory-efficient
specialisation. Comprehensive evaluation on xCodeEval, APPS, and CodeContests
shows that MapCoder-Lite more than doubles xCodeEval accuracy (from $13.2\%$ to
$28.3\%$), eliminates all format failures, and closes to within six points of a
32B baseline while cutting GPU memory and token-generation time by $4\times$.
These results demonstrate that careful agent-wise fine-tuning unleashes
high-quality multi-agent coding on a small language model.

</details>


### [94] [Enhancing Cross-Lingual Transfer through Reversible Transliteration: A Huffman-Based Approach for Low-Resource Languages](https://arxiv.org/abs/2509.17493)
*Wenhao Zhuang,Yuan Sun,Xiaobing Zhao*

Main category: cs.CL

TL;DR: 本文提出了一种结合字符音译和霍夫曼编码的完整框架，用于提升大语言模型对低资源语言的处理能力，实现了存储压缩、无损转换和训练效率提升。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在多语言处理中，对使用非拉丁文字的低资源语言支持不足，缺乏系统的音译集成框架。

Method: 创新性地结合字符音译与霍夫曼编码，设计完整的音译框架，包括压缩存储、无损转换和高效处理。

Result: 实验表明该方法在文本分类、机器阅读理解等任务中显著提升低资源语言处理能力，文件大小减少50%，token数量减少50-80%。

Conclusion: 该框架有效解决了低资源语言处理难题，具有压缩率高、转换无损、效率提升和可扩展性强的优势。

Abstract: As large language models (LLMs) are trained on increasingly diverse and
extensive multilingual corpora, they demonstrate cross-lingual transfer
capabilities. However, these capabilities often fail to effectively extend to
low-resource languages, particularly those utilizing non-Latin scripts. While
transliterating low-resource languages into Latin script presents a natural
solution, there currently lacks a comprehensive framework for integrating
transliteration into LLMs training and deployment. Taking a pragmatic approach,
this paper innovatively combines character transliteration with Huffman coding
to design a complete transliteration framework. Our proposed framework offers
the following advantages: 1) Compression: Reduces storage requirements for
low-resource language content, achieving up to 50% reduction in file size and
50-80% reduction in token count. 2) Accuracy: Guarantees 100% lossless
conversion from transliterated text back to the source language. 3) Efficiency:
Eliminates the need for vocabulary expansion for low-resource languages,
improving training and inference efficiency. 4) Scalability: The framework can
be extended to other low-resource languages. We validate the effectiveness of
our framework across multiple downstream tasks, including text classification,
machine reading comprehension, and machine translation. Experimental results
demonstrate that our method significantly enhances the model's capability to
process low-resource languages while maintaining performance on high-resource
languages. Our data and code are publicly available at
https://github.com/CMLI-NLP/HuffmanTranslit.

</details>


### [95] [CorefInst: Leveraging LLMs for Multilingual Coreference Resolution](https://arxiv.org/abs/2509.17505)
*Tuğba Pamay Arslan,Emircan Erol,Gülşen Eryiğit*

Main category: cs.CL

TL;DR: 本研究提出了首个多语言共指消解方法，利用仅解码器LLM处理显式和零指代，通过五种指令集和受控推理方法，在Llama 3.1、Gemma 2和Mistral 0.3上评估，结果显示指令调优后的LLM能超越最先进的特定任务架构。


<details>
  <summary>Details</summary>
Motivation: 共指消解是自然语言理解中的关键但具有挑战性的任务，传统方法受限于特定任务架构和基于编码器的语言模型，需要大量训练且缺乏适应性。

Method: 使用仅解码器LLM处理多语言共指消解，通过五种不同的指令集建模任务，采用受控推理方法，在三个LLM上进行评估。

Result: 最佳模型（完全微调的Llama 3.1）在CorefUD v1.2数据集的所有语言上平均比领先的多语言CR模型（Corpipe 24单阶段变体）高出2个百分点。

Conclusion: 当使用合适的指令集进行指令调优时，LLM能够超越最先进的特定任务架构，在多语言共指消解任务中表现出色。

Abstract: Coreference Resolution (CR) is a crucial yet challenging task in natural
language understanding, often constrained by task-specific architectures and
encoder-based language models that demand extensive training and lack
adaptability. This study introduces the first multilingual CR methodology which
leverages decoder-only LLMs to handle both overt and zero mentions. The article
explores how to model the CR task for LLMs via five different instruction sets
using a controlled inference method. The approach is evaluated across three
LLMs; Llama 3.1, Gemma 2, and Mistral 0.3. The results indicate that LLMs, when
instruction-tuned with a suitable instruction set, can surpass state-of-the-art
task-specific architectures. Specifically, our best model, a fully fine-tuned
Llama 3.1 for multilingual CR, outperforms the leading multilingual CR model
(i.e., Corpipe 24 single stage variant) by 2 pp on average across all languages
in the CorefUD v1.2 dataset collection.

</details>


### [96] [Leveraging Audio-Visual Data to Reduce the Multilingual Gap in Self-Supervised Speech Models](https://arxiv.org/abs/2509.17523)
*María Andrea Cruz Blandón,Zakaria Aldeneh,Jie Chi,Maureen de Seyssel*

Main category: cs.CL

TL;DR: 该论文提出了一种通过引入有限视觉信息来提升双语语音自监督学习模型性能的方法，显著缩小了双语与单语模型之间的性能差距。


<details>
  <summary>Details</summary>
Motivation: 现有的多语言自监督学习模型在单语任务上表现不如单语模型，特别是在双语等语言数量较少的多语言场景中。作者希望通过视觉信息的引入来弥补这一性能差距。

Method: 在双语语音自监督学习模型中引入有限的视觉信息进行视觉对齐，增强模型的表示学习能力。

Result: 视觉对齐对单语和双语模型都有帮助，尤其对双语模型效果显著，将零样本音素识别的多语言性能差距从音频模型的31.5%降低到8.04%。

Conclusion: 有限的视觉信息可以有效提升双语语音自监督学习模型的性能，显著缩小与单语模型的性能差距，为多语言语音处理提供了新的思路。

Abstract: Self-supervised learning (SSL) has made significant advances in speech
representation learning. Models like wav2vec 2.0 and HuBERT have achieved
state-of-the-art results in tasks such as speech recognition, particularly in
monolingual settings. However, multilingual SSL models tend to underperform
their monolingual counterparts on each individual language, especially in
multilingual scenarios with few languages such as the bilingual setting. In
this work, we investigate a novel approach to reduce this performance gap by
introducing limited visual grounding into bilingual speech SSL models. Our
results show that visual grounding benefits both monolingual and bilingual
models, with especially pronounced gains for the latter, reducing the
multilingual performance gap on zero-shot phonetic discrimination from 31.5%
for audio-only models to 8.04% with grounding.

</details>


### [97] [Can LLMs Reason Over Non-Text Modalities in a Training-Free Manner? A Case Study with In-Context Representation Learning](https://arxiv.org/abs/2509.17552)
*Tianle Zhang,Wanlong Fang,Jonathan Woo,Paridhi Latawa,Deepak A. Subramanian,Alvin Chan*

Main category: cs.CL

TL;DR: 提出了ICRL（上下文表示学习）框架，无需训练即可将非文本模态表示集成到基于文本的大语言模型中，实现多模态推理


<details>
  <summary>Details</summary>
Motivation: 现有方法需要额外的监督训练来集成非文本模态表示，限制了在新领域和模态上的即时适应能力

Method: ICRL用基础模型表示替换文本输入，通过少量样本学习使LLM能够自适应利用非文本模态表示，无需微调

Result: 在分子领域任务上评估了ICRL，研究了表示映射方法、性能影响因素和有效机制

Conclusion: ICRL是首个无需训练的非文本模态表示集成框架，为可适应的多模态泛化提供了有前景的方向

Abstract: The remarkable performance of Large Language Models (LLMs) can be enhanced
with test-time computation, which relies on external tools and even other deep
learning models. However, existing approaches for integrating non-text modality
representations into LLMs typically require additional costly supervised
training, restricting on-the-fly adaptation to new domains and modalities. In
this work, we explore the feasibility of integrating representations from
non-text foundational models (FMs) into text-based LLMs in a training-free
manner. We propose In-Context Representation Learning (ICRL) as a
proof-of-concept to allow LLMs to adaptively utilize non-text modality
representations with few-shot learning. Unlike traditional in-context learning,
which incorporates text-label pairs, ICRL replaces text inputs with FM
representations, enabling the LLM to perform multi-modal inference without
fine-tuning. We evaluate ICRL on a suite of tasks in the molecular domain,
investigating three core research questions: (i) how to map FM representations
into LLMs in a training-free manner, (ii) what factors influence ICRL
performance, and (iii) what mechanisms underlie the effectiveness of ICRL. To
the best of our knowledge, ICRL is the first training-free framework for
integrating non-text modality representations into text-based LLMs, presenting
a promising direction for adaptable, multi-modal generalization.

</details>


### [98] [Specification-Aware Machine Translation and Evaluation for Purpose Alignment](https://arxiv.org/abs/2509.17559)
*Yoko Kayano,Saku Sugawara*

Main category: cs.CL

TL;DR: 本文提出了一种基于规格说明的机器翻译评估框架，通过将专业翻译中的客户需求规格化，指导LLM翻译在投资者关系文本翻译中超越了官方人工翻译的质量。


<details>
  <summary>Details</summary>
Motivation: 现有机器翻译研究往往只隐式处理翻译规格说明，而专业翻译实践中规格说明对翻译质量至关重要。本文旨在填补这一理论与实践之间的差距。

Method: 基于翻译研究理论，提出了规格感知的机器翻译和评估框架，并在33家上市公司投资者关系文本翻译中应用，比较了五种翻译类型（包括官方人工翻译和基于提示的LLM输出），采用专家错误分析、用户偏好排序和自动指标进行评估。

Result: 结果显示，在规格说明指导下的LLM翻译在人工评估中持续优于官方人工翻译，揭示了感知质量与预期质量之间的差距。

Conclusion: 将规格说明整合到机器翻译工作流程中，配合人工监督，可以按照专业实践的方式提高翻译质量。

Abstract: In professional settings, translation is guided by communicative goals and
client needs, often formalized as specifications. While existing evaluation
frameworks acknowledge the importance of such specifications, these
specifications are often treated only implicitly in machine translation (MT)
research. Drawing on translation studies, we provide a theoretical rationale
for why specifications matter in professional translation, as well as a
practical guide to implementing specification-aware MT and evaluation. Building
on this foundation, we apply our framework to the translation of investor
relations texts from 33 publicly listed companies. In our experiment, we
compare five translation types, including official human translations and
prompt-based outputs from large language models (LLMs), using expert error
analysis, user preference rankings, and an automatic metric. The results show
that LLM translations guided by specifications consistently outperformed
official human translations in human evaluations, highlighting a gap between
perceived and expected quality. These findings demonstrate that integrating
specifications into MT workflows, with human oversight, can improve translation
quality in ways aligned with professional practice.

</details>


### [99] [Asking a Language Model for Diverse Responses](https://arxiv.org/abs/2509.17570)
*Sergey Troshin,Irina Saparina,Antske Fokkens,Vlad Niculae*

Main category: cs.CL

TL;DR: 本文研究了三种候选采样策略（祖先采样、枚举采样和迭代采样）在大型语言模型中的表现，发现在相同计算预算下，枚举和迭代采样策略能产生更高的多样性且保持可比的质量。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型越来越依赖显式推理链，并能对给定上下文产生多个合理响应。需要研究不同采样策略如何影响响应多样性和质量。

Method: 对比三种采样策略：祖先采样（并行）、枚举采样（一次生成n个候选）和迭代采样（顺序生成并基于当前响应集进行条件采样），在匹配的计算预算下评估质量、词汇多样性、计算流多样性和效率。

Result: 实证结果表明，枚举和迭代采样策略在保持可比质量的同时，能产生更高的多样性。

Conclusion: 简单的非独立采样策略有潜力在不牺牲生成质量的情况下提高响应多样性。

Abstract: Large language models increasingly rely on explicit reasoning chains and can
produce multiple plausible responses for a given context. We study the
candidate sampler that produces the set of plausible responses contrasting the
ancestral (parallel) sampling against two alternatives: enumeration, which asks
the model to produce $n$ candidates in one pass, and iterative sampling, which
proposes candidates sequentially while conditioning on the currently generated
response set. Under matched budgets, we compare these samplers on quality,
lexical and computation flow diversity, and efficiency. Our empirical results
demonstrate that enumeration and iterative strategies result in higher
diversity at comparable quality. Our findings highlight the potential of simple
non-independent sampling strategies to improve response diversity without
sacrificing generation quality.

</details>


### [100] [MSCoRe: A Benchmark for Multi-Stage Collaborative Reasoning in LLM Agents](https://arxiv.org/abs/2509.17628)
*Yuzhen Lei,Hongbin Xie,Jiaxing Zhao,Shuangxue Liu,Xuan Song*

Main category: cs.CL

TL;DR: MSCoRe是一个新的基准测试，包含126696个领域特定的QA实例，用于评估LLM在多阶段复杂场景中的推理和协调能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要关注单领域或孤立任务，忽视了LLM在多阶段协作和优化方面的能力，需要新的评估工具来填补这一空白。

Method: 采用三阶段流水线创建数据集：动态采样、迭代问答生成和多层次质量评估。任务按阶段覆盖率和复杂度分为三个难度级别。

Result: 商业模型在所有任务和场景中表现最佳，但简单任务和复杂任务之间的ROUGE分数存在显著差距，且模型性能受噪声数据负面影响。

Conclusion: MSCoRe为社区评估和改进LLM代理的多阶段推理能力提供了宝贵资源，揭示了当前模型在复杂多阶段任务中的局限性。

Abstract: Large Language Models (LLMs) have excelled in question-answering (QA) tasks
within single domains. However, their reasoning and coordination capabilities
in complex, multi-stage scenarios remain underexplored. Existing benchmarks
typically focus on isolated tasks or narrow domains, overlooking models'
abilities for multi-stage collaboration and optimization without explicit
external guidance. To bridge this gap, we propose \textbf{MSCoRe}, a novel
benchmark comprising 126696 domain-specific QA instances spanning scenarios in
automotive, pharmaceutical, electronics, and energy sectors. The dataset is
created using a structured three-phase pipeline: dynamic sampling, iterative
question-answer generation, and a multi-level quality assessment to ensure data
quality. Tasks are further categorized into three difficulty levels according
to stage coverage and complexity. With MSCoRe, we have conducted a
comprehensive evaluation of various state-of-the-art LLM agents. The commercial
models performed best across all tasks and scenarios, but a notable gap in
ROUGE scores remains between simple and complex tasks. We also tested the
models' robustness and found that their performance is negatively affected by
noisy data. MSCoRe provides a valuable new resource for the community to
evaluate and improve multi-stage reasoning in LLM agents. The code and data are
available at https://github.com/D3E0-source/MSCoRE.

</details>


### [101] [AuditoryBench++: Can Language Models Understand Auditory Knowledge without Hearing?](https://arxiv.org/abs/2509.17641)
*Hyunjong Ok,Suho Yoo,Hyeonjun Kim,Jaeho Lee*

Main category: cs.CL

TL;DR: AuditoryBench++是一个评估文本语言模型听觉常识推理能力的基准，AIR-CoT方法通过听觉想象推理提升模型表现


<details>
  <summary>Details</summary>
Motivation: 人类能够轻松推理听觉属性，但语言模型缺乏这种能力，限制了多模态交互效果

Method: 提出AIR-CoT方法，通过特殊标记的跨度检测和知识注入在推理过程中生成和整合听觉信息

Result: 实验表明AIR-CoT在最近的LLM和多模态LLM上表现优于基线模型和听觉知识增强模型

Conclusion: 该工作为语言模型的听觉推理能力提供了系统评估框架，并提出了有效的改进方法

Abstract: Even without directly hearing sounds, humans can effortlessly reason about
auditory properties, such as pitch, loudness, or sound-source associations,
drawing on auditory commonsense. In contrast, language models often lack this
capability, limiting their effectiveness in multimodal interactions. As an
initial step to address this gap, we present AuditoryBench++, a comprehensive
benchmark for evaluating auditory knowledge and reasoning in text-only
settings. The benchmark encompasses tasks that range from basic auditory
comparisons to contextually grounded reasoning, enabling fine-grained analysis
of how models process and integrate auditory concepts. In addition, we
introduce AIR-CoT, a novel auditory imagination reasoning method that generates
and integrates auditory information during inference through span detection
with special tokens and knowledge injection. Extensive experiments with recent
LLMs and Multimodal LLMs demonstrate that AIR-CoT generally outperforms both
the off-the-shelf models and those augmented with auditory knowledge. The
project page is available at https://auditorybenchpp.github.io.

</details>


### [102] [Crosslingual Optimized Metric for Translation Assessment of Indian Languages](https://arxiv.org/abs/2509.17667)
*Arafat Ahsan,Vandan Mujadia,Pruthwik Mishra,Yash Bhaskar,Dipti Misra Sharma*

Main category: cs.CL

TL;DR: 本文创建了一个包含13种印度语言的翻译评估数据集COMTAIL，并训练了神经翻译评估指标COMTAIL，在印度语言翻译评估上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有翻译自动评估方法的局限性，特别是针对印度语言缺乏高质量评估数据的问题。

Method: 构建大规模人工评估数据集（13种印度语言，21个翻译方向），训练神经翻译评估指标COMTAIL。

Result: COMTAIL在印度语言翻译评估上表现显著优于现有最先进方法，并通过消融研究分析了指标对领域、翻译质量和语言分组的敏感性。

Conclusion: COMTAIL数据集和指标模型为印度语言翻译评估提供了有价值的资源，填补了该领域的空白。

Abstract: Automatic evaluation of translation remains a challenging task owing to the
orthographic, morphological, syntactic and semantic richness and divergence
observed across languages. String-based metrics such as BLEU have previously
been extensively used for automatic evaluation tasks, but their limitations are
now increasingly recognized. Although learned neural metrics have helped
mitigate some of the limitations of string-based approaches, they remain
constrained by a paucity of gold evaluation data in most languages beyond the
usual high-resource pairs. In this present work we address some of these gaps.
We create a large human evaluation ratings dataset for 13 Indian languages
covering 21 translation directions and then train a neural translation
evaluation metric named Cross-lingual Optimized Metric for Translation
Assessment of Indian Languages (COMTAIL) on this dataset. The best performing
metric variants show significant performance gains over previous
state-of-the-art when adjudging translation pairs with at least one Indian
language. Furthermore, we conduct a series of ablation studies to highlight the
sensitivities of such a metric to changes in domain, translation quality, and
language groupings. We release both the COMTAIL dataset and the accompanying
metric models.

</details>


### [103] [PG-CE: A Progressive Generation Dataset with Constraint Enhancement for Controllable Text Generation](https://arxiv.org/abs/2509.17669)
*Yan Zhuang,Yuan Sun*

Main category: cs.CL

TL;DR: 本文提出PG-CE方法，通过三步分解可控文本生成任务，动态构建多维度约束来提升生成质量


<details>
  <summary>Details</summary>
Motivation: 解决传统可控文本生成方法的局限性，提高系统可靠性和用户体验

Method: 将CTG任务分解为类型预测、约束构建和引导生成三个步骤，使用约束生成模型动态构建语调、表达风格和主题焦点等多维度约束

Result: 实验表明PG-CE在多个场景下显著提升生成质量，同时保持文本可控性、主题相关性和响应实用性，构建了包含9万约束-文本对的数据集

Conclusion: PG-CE方法有效解决了可控文本生成的挑战，为实际应用需求提供了可靠解决方案

Abstract: With the rapid development of Large Language Models (LLMs), Controllable Text
Generation (CTG) has become a critical technology for enhancing system
reliability and user experience. Addressing the limitations of traditional
methods, this paper proposes the PG-CE (Progressive Generation with Constraint
Enhancement) approach, which decomposes CTG tasks into three steps: type
prediction, constraint construction, and guided generation. This method employs
constraint generation models to dynamically build multi-dimensional constraints
including tone, expression style, and thematic focus to guide output.
Experiments demonstrate that PG-CE significantly improves generation quality
across multiple scenarios while maintaining text controllability, thematic
relevance, and response practicality. The research developed a dataset
containing 90,000 constraint-text pairs (with an 8:2 ratio between daily and
other topics), effectively reflecting real-world application requirements.

</details>


### [104] [Turk-LettuceDetect: A Hallucination Detection Models for Turkish RAG Applications](https://arxiv.org/abs/2509.17671)
*Selva Taş,Mahmut El Huseyni,Özay Ezerceli,Reyhan Bayraktar,Fatma Betül Terzioğlu*

Main category: cs.CL

TL;DR: 该论文介绍了Turk-LettuceDetect，这是首个专门为土耳其语RAG应用设计的幻觉检测模型套件，基于LettuceDetect框架，通过微调三种编码器架构，在机器翻译的RAGTruth基准数据集上取得了良好性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在生成内容时容易产生幻觉（生成看似合理但事实错误的信息），特别是在土耳其语等形态复杂、资源匮乏的语言中，RAG系统也难以完全解决这一问题。

Method: 将幻觉检测制定为令牌级分类任务，微调了三种编码器架构：土耳其语专用的ModernBERT、TurkEmbed4STS和多语言EuroBERT，使用包含17,790个实例的机器翻译RAGTruth基准数据集进行训练。

Result: 基于ModernBERT的模型在完整测试集上达到0.7266的F1分数，在结构化任务上表现尤为突出，模型支持长达8,192个令牌的上下文，计算效率高，适合实时部署。

Conclusion: 这项工作填补了多语言NLP的关键空白，为土耳其语和其他语言开发更可靠、可信的AI应用奠定了基础，通过发布模型和翻译数据集，推动了该领域的发展。

Abstract: The widespread adoption of Large Language Models (LLMs) has been hindered by
their tendency to hallucinate, generating plausible but factually incorrect
information. While Retrieval-Augmented Generation (RAG) systems attempt to
address this issue by grounding responses in external knowledge, hallucination
remains a persistent challenge, particularly for morphologically complex,
low-resource languages like Turkish. This paper introduces Turk-LettuceDetect,
the first suite of hallucination detection models specifically designed for
Turkish RAG applications. Building on the LettuceDetect framework, we formulate
hallucination detection as a token-level classification task and fine-tune
three distinct encoder architectures: a Turkish-specific ModernBERT,
TurkEmbed4STS, and multilingual EuroBERT. These models were trained on a
machine-translated version of the RAGTruth benchmark dataset containing 17,790
instances across question answering, data-to-text generation, and summarization
tasks. Our experimental results show that the ModernBERT-based model achieves
an F1-score of 0.7266 on the complete test set, with particularly strong
performance on structured tasks. The models maintain computational efficiency
while supporting long contexts up to 8,192 tokens, making them suitable for
real-time deployment. Comparative analysis reveals that while state-of-the-art
LLMs demonstrate high recall, they suffer from low precision due to
over-generation of hallucinated content, underscoring the necessity of
specialized detection mechanisms. By releasing our models and translated
dataset, this work addresses a critical gap in multilingual NLP and establishes
a foundation for developing more reliable and trustworthy AI applications for
Turkish and other languages.

</details>


### [105] [When TableQA Meets Noise: A Dual Denoising Framework for Complex Questions and Large-scale Tables](https://arxiv.org/abs/2509.17680)
*Shenghao Ye,Yu Guo,Dong Jin,Yikai Shen,Yunpeng Hou,Shuangwu Chen,Jian Yang,Xiaofeng Jiang*

Main category: cs.CL

TL;DR: EnoTab是一个用于表格问答的双重去噪框架，通过问题分解和表格剪枝来处理复杂问题和大型表格中的噪声数据，提高推理性能。


<details>
  <summary>Details</summary>
Motivation: 现实应用中的表格问答涉及复杂问题和大型表格，引入大量噪声数据严重降低推理性能，需要改进相关性过滤和表格剪枝能力。

Method: 提出EnoTab双重去噪框架：1）基于证据的问题去噪，将问题分解为最小语义单元并过滤无关部分；2）证据树引导的表格去噪，构建透明的表格剪枝路径，使用后序节点回滚机制处理异常状态。

Result: 大量实验表明EnoTab在复杂问题和大型表格的TableQA任务上取得了优异性能，证实了其有效性。

Conclusion: EnoTab通过双重去噪机制有效解决了表格问答中的噪声问题，为处理复杂问题和大型表格提供了可靠解决方案。

Abstract: Table question answering (TableQA) is a fundamental task in natural language
processing (NLP). The strong reasoning capabilities of large language models
(LLMs) have brought significant advances in this field. However, as real-world
applications involve increasingly complex questions and larger tables,
substantial noisy data is introduced, which severely degrades reasoning
performance. To address this challenge, we focus on improving two core
capabilities: Relevance Filtering, which identifies and retains information
truly relevant to reasoning, and Table Pruning, which reduces table size while
preserving essential content. Based on these principles, we propose EnoTab, a
dual denoising framework for complex questions and large-scale tables.
Specifically, we first perform Evidence-based Question Denoising by decomposing
the question into minimal semantic units and filtering out those irrelevant to
answer reasoning based on consistency and usability criteria. Then, we propose
Evidence Tree-guided Table Denoising, which constructs an explicit and
transparent table pruning path to remove irrelevant data step by step. At each
pruning step, we observe the intermediate state of the table and apply a
post-order node rollback mechanism to handle abnormal table states, ultimately
producing a highly reliable sub-table for final answer reasoning. Finally,
extensive experiments show that EnoTab achieves outstanding performance on
TableQA tasks with complex questions and large-scale tables, confirming its
effectiveness.

</details>


### [106] [TASO: Task-Aligned Sparse Optimization for Parameter-Efficient Model Adaptation](https://arxiv.org/abs/2509.17688)
*Daiye Miao,Yufang Liu,Jie Wang,Changzhi Sun,Yunke Zhang,Demei Yan,Shaokang Dong,Qi Zhang,Yuanbin Wu*

Main category: cs.CL

TL;DR: TASO是一种基于预训练模型权重重要性信息的LoRA冗余减少方法，通过识别任务特定的核心区域来确定LoRA模块的稀疏结构，显著减少可训练参数数量。


<details>
  <summary>Details</summary>
Motivation: LoRA方法存在显著的参数冗余问题，这不仅增加了可训练参数数量，还阻碍了微调效果。由于识别LoRA中的冗余参数本身很困难，如何高效准确地消除这些冗余是一个挑战性问题。

Method: TASO利用预训练模型权重的重要性信息来减轻LoRA冗余。具体方法包括：1）在下游任务上估计参数重要性；2）基于重要性分数分布识别任务特定的核心区域；3）使用核心区域的位置信息确定LoRA模块的稀疏结构，在微调前实现冗余消除。

Result: 实验结果表明，在参数预算与rank=1的标准LoRA相当的情况下，TASO在多个任务上持续优于标准LoRA，实现了强大的微调性能，同时有效消除了冗余参数。

Conclusion: TASO显著减少了任务适应所需的可训练参数数量，同时为LoRA冗余减少提供了一个新颖的任务对齐视角。

Abstract: LoRA has become one of the most widely used parameter-efficient fine-tuning
methods due to its simplicity and effectiveness. However, numerous studies have
shown that LoRA often introduces substantial parameter redundancy, which not
only increases the number of trainable parameters but also hinders the
effectiveness of fine-tuning. Since identifying redundant parameters in LoRA is
inherently difficult, how to eliminate them efficiently and accurately remains
a challenging problem. In this paper, we propose TASO, a redundancy reduction
method that leverages importance information from the pretrained model's
weights to mitigate LoRA redundancy. Specifically, we estimate parameter
importance on downstream tasks and identify task-specific core regions based on
the distribution of importance scores. The location information of these core
regions is then used to determine the sparse structure of LoRA modules,
enabling redundancy removal before fine-tuning. Our approach significantly
reduces the number of trainable parameters required for task adaptation, while
providing a novel task-aligned perspective for LoRA redundancy reduction.
Experimental results demonstrate that, with a parameter budget comparable to
LoRA with rank $r = 1$, TASO consistently outperforms standard LoRA across
multiple tasks, achieving strong fine-tuning performance while effectively
eliminating redundant parameters.

</details>


### [107] [Evaluating LLM-Generated Versus Human-Authored Responses in Role-Play Dialogues](https://arxiv.org/abs/2509.17694)
*Dongxu Lu,Johan Jeuring,Albert Gatt*

Main category: cs.CL

TL;DR: 该研究比较了LLM生成和人类创作在专业训练模拟中的多轮对话响应，发现LLM响应质量随对话轮次显著下降，而人类响应则逐渐改善。


<details>
  <summary>Details</summary>
Motivation: 评估LLM在长形式、知识基础的角色扮演对话中的表现仍然具有挑战性，特别是在多轮专业训练模拟中。

Method: 通过人类评估（N=38）和自动化的LLM作为评判者评估，比较LLM生成和人类创作的响应质量。

Result: 人类评估显示LLM生成响应质量在多轮对话中显著下降，特别是在自然性、上下文维护和整体质量方面，而人类创作响应则逐步改善。自动化评估（Gemini 2.0 Flash）与人类评估结果一致。

Conclusion: 研究揭示了LLM在知识基础角色扮演对话中的退化问题，并提供了一个经过验证的混合评估框架，以指导LLM在训练模拟中的可靠集成。

Abstract: Evaluating large language models (LLMs) in long-form, knowledge-grounded
role-play dialogues remains challenging. This study compares LLM-generated and
human-authored responses in multi-turn professional training simulations
through human evaluation ($N=38$) and automated LLM-as-a-judge assessment.
Human evaluation revealed significant degradation in LLM-generated response
quality across turns, particularly in naturalness, context maintenance and
overall quality, while human-authored responses progressively improved. In line
with this finding, participants also indicated a consistent preference for
human-authored dialogue. These human judgements were validated by our automated
LLM-as-a-judge evaluation, where Gemini 2.0 Flash achieved strong alignment
with human evaluators on both zero-shot pairwise preference and stochastic
6-shot construct ratings, confirming the widening quality gap between LLM and
human responses over time. Our work contributes a multi-turn benchmark exposing
LLM degradation in knowledge-grounded role-play dialogues and provides a
validated hybrid evaluation framework to guide the reliable integration of LLMs
in training simulations.

</details>


### [108] [Investigating Bias: A Multilingual Pipeline for Generating, Solving, and Evaluating Math Problems with LLMs](https://arxiv.org/abs/2509.17701)
*Mariam Mahran,Katharina Simbeck*

Main category: cs.CL

TL;DR: 本文提出了一个自动化多语言管道，用于生成、解决和评估与德国K-10课程对齐的数学问题，发现LLMs在英语、德语和阿拉伯语中的解决方案质量存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型越来越多地用于教育支持，但其响应质量因交互语言而异，需要评估多语言环境下的表现差异。

Method: 生成了628个数学练习题并翻译成英语、德语和阿拉伯语，使用三种商业LLMs生成逐步解决方案，并由LLM评审小组使用比较框架评估解决方案质量。

Result: 结果显示英语解决方案始终评分最高，阿拉伯语通常排名较低，存在一致的语言偏见差距。

Conclusion: 这些发现突显了持续存在的语言偏见，以及教育中需要更公平的多语言AI系统。

Abstract: Large Language Models (LLMs) are increasingly used for educational support,
yet their response quality varies depending on the language of interaction.
This paper presents an automated multilingual pipeline for generating, solving,
and evaluating math problems aligned with the German K-10 curriculum. We
generated 628 math exercises and translated them into English, German, and
Arabic. Three commercial LLMs (GPT-4o-mini, Gemini 2.5 Flash, and Qwen-plus)
were prompted to produce step-by-step solutions in each language. A held-out
panel of LLM judges, including Claude 3.5 Haiku, evaluated solution quality
using a comparative framework. Results show a consistent gap, with English
solutions consistently rated highest, and Arabic often ranked lower. These
findings highlight persistent linguistic bias and the need for more equitable
multilingual AI systems in education.

</details>


### [109] [Breaking Token Into Concepts: Exploring Extreme Compression in Token Representation Via Compositional Shared Semantics](https://arxiv.org/abs/2509.17737)
*Kavin R V,Pawan Goyal*

Main category: cs.CL

TL;DR: 该论文提出了一种名为聚合语义分组（ASG）的新方法，利用产品量化（PQ）来构建组合式的token表示，在保持95%以上任务性能的同时实现了极端的嵌入参数压缩（0.4-0.5%）。


<details>
  <summary>Details</summary>
Motivation: 标准语言模型使用单一、整体的token嵌入，可能限制了捕捉词语多面性含义的能力。研究者希望探索是否可以通过组合结构更有效地表示token，积累多样化的语义方面。

Method: 提出ASG方法，基于产品量化构建组合式token表示，并在标准Transformer架构（mBERT、XLM-R、mT5）上进行应用，同时在生物医学领域特定基准（BC5CDR）上使用BioBERT进行评估。

Result: ASG方法在多种任务（NLI、NER、QA）中实现了极端的参数压缩（仅需0.4-0.5%的嵌入参数），同时保持超过95%的任务性能，在生成任务、跨语言迁移和领域特定设置中都表现良好。

Conclusion: 研究验证了token可以作为共享语义构建块的组合来有效建模的原则。ASG提供了一个简单而具体的方法来实现这一目标，展示了组合表示如何在实现紧凑模型的同时捕捉语言丰富性。

Abstract: Standard language models employ unique, monolithic embeddings for each token,
potentially limiting their ability to capture the multifaceted nature of word
meanings. We investigate whether tokens can be more effectively represented
through a compositional structure that accumulates diverse semantic facets. To
explore this, we propose Aggregate Semantic Grouping (ASG), a novel approach
leveraging Product Quantization (PQ). We apply ASG to standard transformer
architectures (mBERT, XLM-R, mT5) and evaluate this representational scheme
across diverse tasks (NLI, NER, QA), as well as a biomedical domain-specific
benchmark (BC5CDR) using BioBERT. Our findings demonstrate that representing
tokens compositionally via ASG achieves extreme compression in embedding
parameters (0.4--0.5\%) while maintaining $>$95\% task performance relative to
the base model, even in generative tasks and extends to both cross lingual
transfer and domain-specific settings. These results validate the principle
that tokens can be effectively modeled as combinations of shared semantic
building blocks. ASG offers a simple yet concrete method for achieving this,
showcasing how compositional representations can capture linguistic richness
while enabling compact yet semantically rich models.

</details>


### [110] [Qwen3-Omni Technical Report](https://arxiv.org/abs/2509.17765)
*Jin Xu,Zhifang Guo,Hangrui Hu,Yunfei Chu,Xiong Wang,Jinzheng He,Yuxuan Wang,Xian Shi,Ting He,Xinfa Zhu,Yuanjun Lv,Yongqi Wang,Dake Guo,He Wang,Linhan Ma,Pei Zhang,Xinyu Zhang,Hongkun Hao,Zishan Guo,Baosong Yang,Bin Zhang,Ziyang Ma,Xipin Wei,Shuai Bai,Keqin Chen,Xuejing Liu,Peng Wang,Mingkun Yang,Dayiheng Liu,Xingzhang Ren,Bo Zheng,Rui Men,Fan Zhou,Bowen Yu,Jianxin Yang,Le Yu,Jingren Zhou,Junyang Lin*

Main category: cs.CL

TL;DR: Qwen3-Omni是首个在文本、图像、音频和视频四种模态上均保持最先进性能的多模态模型，无需牺牲单模态性能。该模型在36个音频和音视频基准测试中表现优异，采用Thinker-Talker MoE架构，支持119种语言的文本交互和多种语言的语音处理。


<details>
  <summary>Details</summary>
Motivation: 开发一个真正统一的多模态模型，在文本、图像、音频和视频四种模态上都能达到最先进性能，而不像现有模型在扩展模态时会牺牲某些模态的性能。

Method: 采用Thinker-Talker MoE架构统一感知和生成，使用多码本方案预测离散语音编解码器，用轻量级因果ConvNet替代计算密集的块扩散，实现流式合成。引入Thinking模型进行显式多模态推理。

Result: 在36个音频和音视频基准测试中，Qwen3-Omni在32个测试上达到开源SOTA，在22个测试上达到总体SOTA，超越了Gemini-2.5-Pro、Seed-ASR和GPT-4o-Transcribe等闭源模型。冷启动设置下理论端到端首包延迟为234毫秒。

Conclusion: Qwen3-Omni成功实现了真正统一的多模态建模，在保持各模态性能的同时显著提升了音频处理能力，为多模态AI发展提供了重要突破。模型已基于Apache 2.0许可证公开发布。

Abstract: We present Qwen3-Omni, a single multimodal model that, for the first time,
maintains state-of-the-art performance across text, image, audio, and video
without any degradation relative to single-modal counterparts. Qwen3-Omni
matches the performance of same-sized single-modal models within the Qwen
series and excels particularly on audio tasks. Across 36 audio and audio-visual
benchmarks, Qwen3-Omni achieves open-source SOTA on 32 benchmarks and overall
SOTA on 22, outperforming strong closed-source models such as Gemini-2.5-Pro,
Seed-ASR, and GPT-4o-Transcribe. Qwen3-Omni adopts a Thinker-Talker MoE
architecture that unifies perception and generation across text, images, audio,
and video, yielding fluent text and natural real-time speech. It supports text
interaction in 119 languages, speech understanding in 19 languages, and speech
generation in 10 languages. To reduce first-packet latency in streaming
synthesis, Talker autoregressively predicts discrete speech codecs using a
multi-codebook scheme. Leveraging the representational capacity of these
codebooks, we replace computationally intensive block-wise diffusion with a
lightweight causal ConvNet, enabling streaming from the first codec frame. In
cold-start settings, Qwen3-Omni achieves a theoretical end-to-end first-packet
latency of 234 ms. To further strengthen multimodal reasoning, we introduce a
Thinking model that explicitly reasons over inputs from any modality. Since the
research community currently lacks a general-purpose audio captioning model, we
fine-tuned Qwen3-Omni-30B-A3B to obtain Qwen3-Omni-30B-A3B-Captioner, which
produces detailed, low-hallucination captions for arbitrary audio inputs.
Qwen3-Omni-30B-A3B, Qwen3-Omni-30B-A3B-Thinking, and
Qwen3-Omni-30B-A3B-Captioner are publicly released under the Apache 2.0
license.

</details>


### [111] [A State-Update Prompting Strategy for Efficient and Robust Multi-turn Dialogue](https://arxiv.org/abs/2509.17766)
*Ziyi Liu*

Main category: cs.CL

TL;DR: 提出了一种无需训练的提示工程方法——状态更新多轮对话策略，通过状态重建和历史提醒机制解决LLM在长对话中的信息遗忘和效率低下问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在长跨度多轮对话中存在信息遗忘和效率低下的问题，需要有效管理对话历史的方法。

Method: 采用状态重建和历史提醒两种机制，通过提示工程优化对话历史管理，无需额外训练。

Result: 在HotpotQA数据集上，核心信息过滤得分提升32.6%，下游QA得分提升14.1%，推理时间减少73.1%，token消耗降低59.4%。

Conclusion: 该方法为优化LLM在长程交互中的表现提供了有效解决方案，为开发更鲁棒的智能体提供了新思路。

Abstract: Large Language Models (LLMs) struggle with information forgetting and
inefficiency in long-horizon, multi-turn dialogues. To address this, we propose
a training-free prompt engineering method, the State-Update Multi-turn Dialogue
Strategy. It utilizes "State Reconstruction" and "History Remind" mechanisms to
effectively manage dialogue history. Our strategy shows strong performance
across multiple multi-hop QA datasets. For instance, on the HotpotQA dataset,
it improves the core information filtering score by 32.6%, leading to a 14.1%
increase in the downstream QA score, while also reducing inference time by
73.1% and token consumption by 59.4%. Ablation studies confirm the pivotal
roles of both components. Our work offers an effective solution for optimizing
LLMs in long-range interactions, providing new insights for developing more
robust Agents.

</details>


### [112] [DIVERS-Bench: Evaluating Language Identification Across Domain Shifts and Code-Switching](https://arxiv.org/abs/2509.17768)
*Jessica Ojo,Zina Kamel,David Ifeoluwa Adelani*

Main category: cs.CL

TL;DR: 该论文介绍了DIVERS-BENCH评估框架，发现当前语言识别模型在干净数据上表现良好，但在噪声和混合语言文本中性能显著下降。


<details>
  <summary>Details</summary>
Motivation: 当前语言识别系统过度依赖干净的单语数据，无法有效处理现实世界中的多样化文本输入，需要更全面的评估基准。

Method: 构建了DIVERS-BENCH评估框架，涵盖语音转录、网络文本、社交媒体、儿童故事和语码转换文本等多个领域，并创建了DIVERS-CS语码转换基准数据集。

Result: 模型在精选数据集上准确率高，但在噪声和非正式输入中性能急剧下降，现有模型难以检测同一句子中的多种语言。

Conclusion: 现实世界应用需要更鲁棒和包容的语言识别系统，当前模型在处理多样化文本方面存在明显不足。

Abstract: Language Identification (LID) is a core task in multilingual NLP, yet current
systems often overfit to clean, monolingual data. This work introduces
DIVERS-BENCH, a comprehensive evaluation of state-of-the-art LID models across
diverse domains, including speech transcripts, web text, social media texts,
children's stories, and code-switched text. Our findings reveal that while
models achieve high accuracy on curated datasets, performance degrades sharply
on noisy and informal inputs. We also introduce DIVERS-CS, a diverse
code-switching benchmark dataset spanning 10 language pairs, and show that
existing models struggle to detect multiple languages within the same sentence.
These results highlight the need for more robust and inclusive LID systems in
real-world settings.

</details>


### [113] [One Agent to Serve All: a Lite-Adaptive Stylized AI Assistant for Millions of Multi-Style Official Accounts](https://arxiv.org/abs/2509.17788)
*Xingyu Fan,Feifei Li,Wenhui Que,Hailong Li*

Main category: cs.CL

TL;DR: WeStar是一个轻量自适应框架，用于解决工业级公众号平台中对话代理生成既上下文相关又风格对齐的响应问题，通过结合RAG和参数化RAG实现高效风格化问答。


<details>
  <summary>Details</summary>
Motivation: 现有方法在工业级公众号平台中难以同时满足上下文相关性和风格对齐要求：CoT提示导致延迟高，单账号微调计算成本高，长提示方法会降低模型理解能力。

Method: WeStar结合基于RAG的上下文生成和基于参数化RAG的风格感知生成，使用LoRA模块按风格簇动态激活，并提出多维聚类参数共享方案和风格增强直接偏好优化方法。

Result: 在大规模工业数据集上的实验验证了WeStar的有效性和效率，证明了其在真实部署中的实用价值。

Conclusion: WeStar能够以最小开销服务大量官方账号，提供了一种实用的工业级对话生成解决方案。

Abstract: Conversational agents deployed in industrial-scale official account platforms
must generate responses that are both contextually grounded and stylistically
aligned-requirements that existing methods struggle to meet. Chain-of-thought
(CoT) prompting induces significant latency due to multi-turn reasoning;
per-account fine-tuning is computationally prohibitive; and long prompt-based
methods degrade the model's ability to grasp injected context and style. In
this paper, we propose WeStar, a lite-adaptive framework for stylized
contextual question answering that scales to millions of official accounts.
WeStar combines context-grounded generation via RAG with style-aware generation
using Parametric RAG (PRAG), where LoRA modules are dynamically activated per
style cluster. Our contributions are fourfold: (1) We introduce WeStar, a
unified framework capable of serving large volumes of official accounts with
minimal overhead. (2) We propose a multi-dimensional, cluster-based parameter
sharing scheme that enables compact style representation while preserving
stylistic diversity. (3) We develop a style-enhanced Direct Preference
Optimization (SeDPO) method to optimize each style cluster's parameters for
improved generation quality. (4) Experiments on a large-scale industrial
dataset validate the effectiveness and efficiency of WeStar, underscoring its
pracitical value in real-world deployment.

</details>


### [114] [Learning to vary: Teaching LMs to reproduce human linguistic variability in next-word prediction](https://arxiv.org/abs/2509.17794)
*Tobias Groot,Salo Lacunes,Evgenia Ilia*

Main category: cs.CL

TL;DR: 该论文研究了通过多标签微调方法提升语言模型在自然语言生成任务中重现人类语言变异性的能力。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型难以很好地重现人类语言中固有的变异性，这可能源于训练数据缺乏对这种内在变异性的体现。作者希望验证通过训练模型学习多个合理的词续写是否能改善这一能力。

Method: 使用Provo语料库对预训练模型（GPT-2和Mistral-7B-IT）进行多标签微调，让模型学习每个上下文对应的多个有效词续写。

Result: 评估结果显示，多标签微调显著提高了语言模型重现人类语言变异性的能力，无论是在高变异性还是低变异性的上下文中都表现出改善。

Conclusion: 通过训练语言模型学习多个合理的词续写可以有效提升其重现人类语言变异性的能力，这为解决语言模型多样性不足问题提供了有效途径。

Abstract: Natural language generation (NLG) tasks are often subject to inherent
variability; \emph{e.g.} predicting the next word given a context has multiple
valid responses, evident when asking multiple humans to complete the task.
While having language models (LMs) that are aligned pluralistically, so that
they are able to reproduce well the inherent diversity in perspectives of an
entire population of interest is clearly beneficial, \citet{ilia2024predict}
show that LMs do not reproduce this type of linguistic variability well. They
speculate this inability might stem from the lack of consistent training of LMs
with data reflecting this type of inherent variability. As such, we investigate
whether training LMs on multiple plausible word continuations per context can
improve their ability to reproduce human linguistic variability for next-word
prediction. We employ fine-tuning techniques for pre-trained and
instruction-tuned models; and demonstrate their potential when fine-tuning
GPT-2 and Mistral-7B-IT, using Provo Corpus. Our evaluation, which measures
divergence among empirically estimated human and model next-word distributions
across contexts before and after fine-tuning, shows that our multi-label
fine-tuning improves the LMs' ability to reproduce linguistic variability; both
for contexts that admit higher and lower variability.

</details>


### [115] [Findings of the Fourth Shared Task on Multilingual Coreference Resolution: Can LLMs Dethrone Traditional Approaches?](https://arxiv.org/abs/2509.17796)
*Michal Novák,Miloslav Konopík,Anna Nedoluzhko,Martin Popel,Ondřej Pražák,Jakub Sido,Milan Straka,Zdeněk Žabokrtský,Daniel Zeman*

Main category: cs.CL

TL;DR: 本文介绍了CODI-CRAC 2025研讨会中第四届多语言共指消解共享任务的概况，重点包括新增的LLM专用赛道、扩展到22个数据集17种语言，以及9个参赛系统的表现分析。


<details>
  <summary>Details</summary>
Motivation: 推动多语言共指消解技术的发展，探索大型语言模型在该领域的应用潜力，并通过标准化数据集促进不同方法的比较。

Method: 采用CorefUD 1.3版本的标准化数据集，设立传统系统和LLM专用两个赛道，LLM赛道使用简化的纯文本格式替代复杂的CoNLL-U表示。

Result: 共有9个系统参赛（包括4个LLM方法），传统系统仍保持领先，但LLM显示出明显潜力，有望在未来挑战传统方法。

Conclusion: LLM在多语言共指消解任务中展现出良好前景，虽然目前传统方法仍占优势，但LLM的快速发展预示着未来格局可能发生变化。

Abstract: The paper presents an overview of the fourth edition of the Shared Task on
Multilingual Coreference Resolution, organized as part of the CODI-CRAC 2025
workshop. As in the previous editions, participants were challenged to develop
systems that identify mentions and cluster them according to identity
coreference.
  A key innovation of this year's task was the introduction of a dedicated
Large Language Model (LLM) track, featuring a simplified plaintext format
designed to be more suitable for LLMs than the original CoNLL-U representation.
  The task also expanded its coverage with three new datasets in two additional
languages, using version 1.3 of CorefUD - a harmonized multilingual collection
of 22 datasets in 17 languages.
  In total, nine systems participated, including four LLM-based approaches (two
fine-tuned and two using few-shot adaptation). While traditional systems still
kept the lead, LLMs showed clear potential, suggesting they may soon challenge
established approaches in future editions.

</details>


### [116] [Everyday Physics in Korean Contexts: A Culturally Grounded Physical Reasoning Benchmark](https://arxiv.org/abs/2509.17807)
*Jihae Jeong,DaeYeop Lee,DongGeon Lee,Hwanjo Yu*

Main category: cs.CL

TL;DR: EPiK是一个针对韩国文化背景的物理常识推理基准测试，包含181个二元选择题，涵盖9个推理子任务和84个场景，旨在解决现有基准测试忽视文化差异的问题。


<details>
  <summary>Details</summary>
Motivation: 现有物理常识推理基准主要关注西方背景，忽略了不同文化背景下物理问题解决的差异，需要开发文化敏感的评估工具。

Method: 采用两阶段生成和验证流程，从韩国文化背景有机生成问题，确保文化真实性和物理推理严谨性，避免简单翻译方法。

Result: 评估显示韩国专用模型在同等规模下始终优于通用模型，表明文化无关模型存在局限性。

Conclusion: 需要文化感知的基准测试来真正衡量语言理解能力，EPiK的推出填补了文化多样性在物理推理评估中的空白。

Abstract: Existing physical commonsense reasoning benchmarks predominantly focus on
Western contexts, overlooking cultural variations in physical problem-solving.
To address this gap, we introduce EPiK (Everyday Physics in Korean Contexts), a
novel benchmark comprising 181 binary-choice problems that test physical
reasoning within Korean cultural contexts, ranging from kimchi (Korean food) to
traditional fermentation. EPiK is constructed using a two-stage generation and
verification pipeline to create culturally-authentic problems across 9
reasoning subtasks and 84 scenarios. Unlike approaches based on simple
translation, our method generates problems organically from Korean contexts
while upholding rigorous physical reasoning standards. Our evaluations show
that Korean-specialized models consistently outperform general-purpose models
of comparable size. This performance gap highlights the limitations of
culturally-agnostic models and demonstrates the critical need for
culturally-aware benchmarks to truly measure language understanding. Our EPiK
is publicly available at https://huggingface.co/datasets/jjae/EPiK.

</details>


### [117] [Towards Adaptive Context Management for Intelligent Conversational Question Answering](https://arxiv.org/abs/2509.17829)
*Manoj Madushanka Perera,Adnan Mahmood,Kasun Eranda Wijethilake,Quan Z. Sheng*

Main category: cs.CL

TL;DR: 本文提出了用于对话问答系统的自适应上下文管理框架，通过动态管理上下文来优化对话历史的使用，在模型token限制内最大化相关信息。


<details>
  <summary>Details</summary>
Motivation: 对话问答系统在处理长对话历史时面临token限制问题，需要有效管理上下文以确保相关信息不被截断。

Method: 采用三层模块架构：上下文管理模块动态调整上下文大小，摘要模块通过滑动窗口总结旧对话历史，实体提取模块在摘要窗口超限时保留关键实体。

Result: 实验结果表明该框架能生成准确且上下文适当的回答，提升了对话问答系统的鲁棒性和可扩展性。

Conclusion: ACM框架通过智能的上下文管理策略有效解决了对话问答系统中的上下文长度限制问题，具有实际应用价值。

Abstract: This particular paper introduces an Adaptive Context Management (ACM)
framework for the Conversational Question Answering (ConvQA) systems. The key
objective of the ACM framework is to optimize the use of the conversation
history by dynamically managing context for maximizing the relevant information
provided to a ConvQA model within its token limit. Our approach incorporates a
Context Manager (CM) Module, a Summarization (SM) Module, and an Entity
Extraction (EE) Module in a bid to handle the conversation history
efficaciously. The CM Module dynamically adjusts the context size, thereby
preserving the most relevant and recent information within a model's token
limit. The SM Module summarizes the older parts of the conversation history via
a sliding window. When the summarization window exceeds its limit, the EE
Module identifies and retains key entities from the oldest conversation turns.
Experimental results demonstrate the effectiveness of our envisaged framework
in generating accurate and contextually appropriate responses, thereby
highlighting the potential of the ACM framework to enhance the robustness and
scalability of the ConvQA systems.

</details>


### [118] [Fine-Grained Detection of AI-Generated Text Using Sentence-Level Segmentation](https://arxiv.org/abs/2509.17830)
*Lekkala Sai Teja,Annepaka Yadagiri,and Partha Pakray,Chukhu Chunka,Mangadoddi Srikar Vardhan*

Main category: cs.CL

TL;DR: 提出了一种句子级别的序列标记模型，用于检测混合文本中AI生成内容与人类撰写内容之间的转换，解决了传统文档级分类器在检测轻微编辑或混合文本时的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统AI检测器依赖文档级分类，难以识别经过编辑或混合的AI生成文本，导致无法有效区分人类撰写和AI生成内容。需要更细粒度的检测方法来应对AI文本的滥用问题。

Method: 结合预训练Transformer模型、神经网络和条件随机场(CRF)，在token级别检测和分割AI与人类撰写文本。利用Transformer提取语义和句法模式，神经网络捕获序列级表示，CRF层优化边界预测。

Result: 在两个公开基准数据集上的实验表明，该方法能准确检测完全协作文本中的AI文本片段，性能优于零样本检测器和现有最先进模型。

Conclusion: 提出的句子级序列标记方法能够有效识别混合文本中AI生成内容的边界，为AI文本检测提供了更精细的解决方案，所有源代码和处理后的数据集已在GitHub上公开。

Abstract: Generation of Artificial Intelligence (AI) texts in important works has
become a common practice that can be used to misuse and abuse AI at various
levels. Traditional AI detectors often rely on document-level classification,
which struggles to identify AI content in hybrid or slightly edited texts
designed to avoid detection, leading to concerns about the model's efficiency,
which makes it hard to distinguish between human-written and AI-generated
texts. A sentence-level sequence labeling model proposed to detect transitions
between human- and AI-generated text, leveraging nuanced linguistic signals
overlooked by document-level classifiers. By this method, detecting and
segmenting AI and human-written text within a single document at the
token-level granularity is achieved. Our model combines the state-of-the-art
pre-trained Transformer models, incorporating Neural Networks (NN) and
Conditional Random Fields (CRFs). This approach extends the power of
transformers to extract semantic and syntactic patterns, and the neural network
component to capture enhanced sequence-level representations, thereby improving
the boundary predictions by the CRF layer, which enhances sequence recognition
and further identification of the partition between Human- and AI-generated
texts. The evaluation is performed on two publicly available benchmark datasets
containing collaborative human and AI-generated texts. Our experimental
comparisons are with zero-shot detectors and the existing state-of-the-art
models, along with rigorous ablation studies to justify that this approach, in
particular, can accurately detect the spans of AI texts in a completely
collaborative text. All our source code and the processed datasets are
available in our GitHub repository.

</details>


### [119] [Trust Me, I Can Convince You: The Contextualized Argument Appraisal Framework](https://arxiv.org/abs/2509.17844)
*Lynn Greschner,Sabine Weber,Roman Klinger*

Main category: cs.CL

TL;DR: 提出了情境化论证评估框架，将发送者、接收者和论证之间的相互作用情境化，包含情感标签、评估维度（如论证熟悉度、响应紧迫性、预期努力）和说服力变量。通过角色扮演场景研究验证框架，发现说服力与积极情感正相关，与消极情感负相关，论证熟悉度是重要评估变量。


<details>
  <summary>Details</summary>
Motivation: 情感影响论证的说服力，但现有研究仅关注二元情感性，未将认知评估过程与论证挖掘结合。需要建模发送者、接收者和论证之间的认知评估交互。

Method: 提出情境化论证评估框架，在角色扮演场景中进行实证研究，收集800个论证（每个由5名参与者标注），包括情感、主要原因、论证评估和感知说服力等数据，同时收集人口统计数据和人格特质。

Result: 说服力与积极情感（如信任）正相关，与消极情感（如愤怒）负相关。论证熟悉度是重要评估变量，大多数参与者的情感反应主要由论证内容本身驱动。

Conclusion: 情境化论证评估框架有效整合了情感分析和认知评估，揭示了情感与说服力的关系，论证熟悉度是关键评估因素，为计算建模奠定了基础。

Abstract: Emotions, which influence how convincing an argument is, are developed
  in context of the self and sender, and therefore require modeling
  the cognitive evaluation process. While binary emotionality has been
  studied in argument mining, and the cognitive appraisal has been
  modeled in general emotion analysis, these fields have not been
  brought together yet. We therefore propose the Contextualized
  Argument Appraisal Framework that contextualizes the interplay
  between the sender, receiver, and argument. It includes emotion
  labels, appraisals, such as argument familiarity, response urgency,
  and expected effort, as well as convincingness variables. To evaluate
  the framework and pave the way to computational modeling, we perform
  a study in a role-playing scenario, mimicking real-world exposure to
  arguments, asking participants to disclose their emotion, explain the main
cause, the
  argument appraisal, and the
  perceived convincingness. To consider the subjective nature of such
  annotations, we also collect demographic data and personality traits
  of both the participants and the perceived sender of the argument.
  The analysis of the resulting corpus of 800 arguments, each
  annotated by 5 participants, reveals that convincingness is
  positively correlated with positive emotions (e.g., trust) and
  negatively correlated with negative emotions (e.g., anger). The
  appraisal variables disclose the importance of the argument
  familiarity. For most participants, the content of the argument
  itself is the primary driver of the emotional response.

</details>


### [120] [Make Every Letter Count: Building Dialect Variation Dictionaries from Monolingual Corpora](https://arxiv.org/abs/2509.17855)
*Robert Litschko,Verena Blaschke,Diana Burkhardt,Barbara Plank,Diego Frassinelli*

Main category: cs.CL

TL;DR: 该论文研究了大型语言模型处理方言词汇的能力，以巴伐利亚语为例，通过DiaLemma框架创建了10万对德语-巴伐利亚语词汇对，评估了9个先进LLM在方言翻译和变体识别方面的表现。


<details>
  <summary>Details</summary>
Motivation: 方言由于缺乏标准拼写而存在很大变异，但LLM处理方言的能力尚未得到充分研究。作者旨在填补这一空白，通过巴伐利亚语案例研究LLM的方言词汇理解能力。

Method: 提出DiaLemma注释框架，仅从单语数据创建方言变异词典，并构建包含10万对人工标注的德语-巴伐利亚语词汇对的数据集，评估9个先进LLM在识别方言翻译、屈折变体和无关形式方面的能力。

Result: LLM在名词和词汇相似词对上表现最佳，但在区分直接翻译和屈折变体方面最困难。提供上下文示例能提高翻译性能，但会降低识别方言变体的能力。

Conclusion: 研究揭示了LLM在处理拼写方言变异方面的局限性，强调未来需要针对方言进行LLM适配工作。

Abstract: Dialects exhibit a substantial degree of variation due to the lack of a
standard orthography. At the same time, the ability of Large Language Models
(LLMs) to process dialects remains largely understudied. To address this gap,
we use Bavarian as a case study and investigate the lexical dialect
understanding capability of LLMs by examining how well they recognize and
translate dialectal terms across different parts-of-speech. To this end, we
introduce DiaLemma, a novel annotation framework for creating dialect variation
dictionaries from monolingual data only, and use it to compile a ground truth
dataset consisting of 100K human-annotated German-Bavarian word pairs. We
evaluate how well nine state-of-the-art LLMs can judge Bavarian terms as
dialect translations, inflected variants, or unrelated forms of a given German
lemma. Our results show that LLMs perform best on nouns and lexically similar
word pairs, and struggle most in distinguishing between direct translations and
inflected variants. Interestingly, providing additional context in the form of
example usages improves the translation performance, but reduces their ability
to recognize dialect variants. This study highlights the limitations of LLMs in
dealing with orthographic dialect variation and emphasizes the need for future
work on adapting LLMs to dialects.

</details>


### [121] [CorPipe at CRAC 2025: Evaluating Multilingual Encoders for Multilingual Coreference Resolution](https://arxiv.org/abs/2509.17858)
*Milan Straka*

Main category: cs.CL

TL;DR: CorPipe 25是CRAC 2025多语言共指消解共享任务的获胜系统，在LLM和无约束两个赛道中均以8个百分点的优势显著优于其他提交系统


<details>
  <summary>Details</summary>
Motivation: 参加CRAC 2025共享任务，该任务新增了LLM赛道并减少了数据集规模以降低计算需求

Method: 完全重新实现了之前的系统，从TensorFlow迁移到PyTorch框架

Result: 在两个赛道中都大幅领先其他提交系统8个百分点，源代码和训练模型已公开

Conclusion: CorPipe 25在多语言共指消解任务中表现出色，证明了系统设计的有效性

Abstract: We present CorPipe 25, the winning entry to the CRAC 2025 Shared Task on
Multilingual Coreference Resolution. This fourth iteration of the shared task
introduces a new LLM track alongside the original unconstrained track, features
reduced development and test sets to lower computational requirements, and
includes additional datasets. CorPipe 25 represents a complete reimplementation
of our previous systems, migrating from TensorFlow to PyTorch. Our system
significantly outperforms all other submissions in both the LLM and
unconstrained tracks by a substantial margin of 8 percentage points. The source
code and trained models are publicly available at
https://github.com/ufal/crac2025-corpipe.

</details>


### [122] [Unsupervised Learning and Representation of Mandarin Tonal Categories by a Generative CNN](https://arxiv.org/abs/2509.17859)
*Kai Schenck,Gašper Beguš*

Main category: cs.CL

TL;DR: 本文提出了一种在完全无监督的人类语言习得模型中模拟声调学习的方法，证明生成模型ciwGAN可以在无标注数据的情况下学习汉语普通话的声调类别。


<details>
  <summary>Details</summary>
Motivation: 声调模式是语言中最复杂的学习目标之一，研究旨在探索无监督模型是否能够像人类语言学习者一样习得声调系统。

Method: 使用ciwGAN生成模型，在无标注数据上训练，通过分析分类变量与声调类别的关联来评估学习效果，并开发了追踪内部卷积层声调表示的方法。

Result: 所有三个训练模型在分类变量的F0上都显示出统计学显著差异，仅使用男性语音训练的模型能够持续编码声调信息。

Conclusion: 模型不仅学会了普通话声调对比，而且学习到的系统对应于人类语言学习者的习得阶段，语言学工具有助于深度学习可解释性并可用于神经实验。

Abstract: This paper outlines the methodology for modeling tonal learning in fully
unsupervised models of human language acquisition. Tonal patterns are among the
computationally most complex learning objectives in language. We argue that a
realistic generative model of human language (ciwGAN) can learn to associate
its categorical variables with Mandarin Chinese tonal categories without any
labeled data. All three trained models showed statistically significant
differences in F0 across categorical variables. The model trained solely on
male tokens consistently encoded tone. Our results sug- gest that not only does
the model learn Mandarin tonal contrasts, but it learns a system that
corresponds to a stage of acquisition in human language learners. We also
outline methodology for tracing tonal representations in internal convolutional
layers, which shows that linguistic tools can contribute to interpretability of
deep learning and can ultimately be used in neural experiments.

</details>


### [123] [How Persuasive is Your Context?](https://arxiv.org/abs/2509.17879)
*Tu Nguyen,Kevin Du,Alexander Miserlis Hoyle,Ryan Cotterell*

Main category: cs.CL

TL;DR: 本文提出了目标说服分数（TPS），用于量化上下文对语言模型回答问题的说服能力，通过Wasserstein距离衡量上下文将模型原始答案分布向目标分布转移的程度。


<details>
  <summary>Details</summary>
Motivation: 语言模型具有利用先验知识回答问题和根据上下文信息适应的能力，但现有方法仅通过贪婪解码评估说服力，缺乏对模型行为的细粒度分析。

Method: 基于Wasserstein距离设计TPS指标，测量上下文对模型答案分布的偏移程度，通过一系列实验验证其有效性。

Result: 实验表明TPS比先前提出的指标更能捕捉说服力的细微差别，提供了更细致的模型行为分析。

Conclusion: TPS为评估语言模型上下文说服力提供了更精确和细粒度的度量方法，有助于深入理解模型的知识更新机制。

Abstract: Two central capabilities of language models (LMs) are: (i) drawing on prior
knowledge about entities, which allows them to answer queries such as "What's
the official language of Austria?", and (ii) adapting to new information
provided in context, e.g., "Pretend the official language of Austria is
Tagalog.", that is pre-pended to the question. In this article, we introduce
targeted persuasion score (TPS), designed to quantify how persuasive a given
context is to an LM where persuasion is operationalized as the ability of the
context to alter the LM's answer to the question. In contrast to evaluating
persuasiveness only by inspecting the greedily decoded answer under the model,
TPS provides a more fine-grained view of model behavior. Based on the
Wasserstein distance, TPS measures how much a context shifts a model's original
answer distribution toward a target distribution. Empirically, through a series
of experiments, we show that TPS captures a more nuanced notion of
persuasiveness than previously proposed metrics.

</details>


### [124] [SiDiaC: Sinhala Diachronic Corpus](https://arxiv.org/abs/2509.17912)
*Nevidu Jayatilleke,Nisansa de Silva*

Main category: cs.CL

TL;DR: SiDiaC是首个全面的僧伽罗语历时语料库，涵盖公元5世纪至20世纪的文本，包含58k单词的46部文学作品，按年代标注并分类，为僧伽罗语NLP研究提供基础资源。


<details>
  <summary>Details</summary>
Motivation: 解决僧伽罗语作为低资源语言缺乏历时语料库的问题，为词汇变化、新词追踪、历史句法和基于语料库的词典编纂等研究提供数据支持。

Method: 从斯里兰卡国家图书馆获取文本，使用Google Document AI OCR数字化，进行后处理校正格式和现代化正字法，借鉴FarPaHC等语料库的句法标注和文本规范化策略。

Result: 成功构建了包含58k单词的历时语料库，按主要分类（非虚构/虚构）和次要分类（宗教、历史、诗歌、语言、医学）进行组织。

Conclusion: 尽管面临稀有文本获取困难和依赖二手日期来源等挑战，SiDiaC显著扩展了僧伽罗语资源，为僧伽罗语NLP的历时研究奠定了重要基础。

Abstract: SiDiaC, the first comprehensive Sinhala Diachronic Corpus, covers a
historical span from the 5th to the 20th century CE. SiDiaC comprises 58k words
across 46 literary works, annotated carefully based on the written date, after
filtering based on availability, authorship, copyright compliance, and data
attribution. Texts from the National Library of Sri Lanka were digitised using
Google Document AI OCR, followed by post-processing to correct formatting and
modernise the orthography. The construction of SiDiaC was informed by practices
from other corpora, such as FarPaHC, particularly in syntactic annotation and
text normalisation strategies, due to the shared characteristics of
low-resourced language status. This corpus is categorised based on genres into
two layers: primary and secondary. Primary categorisation is binary,
classifying each book into Non-Fiction or Fiction, while the secondary
categorisation is more specific, grouping texts under Religious, History,
Poetry, Language, and Medical genres. Despite challenges including limited
access to rare texts and reliance on secondary date sources, SiDiaC serves as a
foundational resource for Sinhala NLP, significantly extending the resources
available for Sinhala, enabling diachronic studies in lexical change, neologism
tracking, historical syntax, and corpus-based lexicography.

</details>


### [125] [Improving Zero-shot Sentence Decontextualisation with Content Selection and Planning](https://arxiv.org/abs/2509.17921)
*Zhenyun Deng,Yulong Chen,Andreas Vlachos*

Main category: cs.CL

TL;DR: 提出零样本去语境化框架，通过内容选择和规划来解决句子脱离上下文后缺乏核心指代和背景信息的问题


<details>
  <summary>Details</summary>
Motivation: 从文档中提取句子作为证据或推理步骤时，这些句子往往缺乏必要的上下文信息（如指代关系和背景信息），导致理解困难

Method: 1) 将句子分割为基本语义独立单元；2) 识别潜在歧义单元；3) 基于语篇关系从上下文中提取相关单元；4) 生成内容计划来重写句子，为每个歧义单元补充相关信息

Result: 实验结果表明该方法在句子去语境化任务中具有竞争力，生成的句子具有更好的语义完整性和语篇连贯性，优于现有方法

Conclusion: 提出的内容选择和规划框架能有效解决句子脱离上下文后的理解问题，为NLP任务中的句子提取提供了更好的解决方案

Abstract: Extracting individual sentences from a document as evidence or reasoning
steps is commonly done in many NLP tasks. However, extracted sentences often
lack context necessary to make them understood, e.g., coreference and
background information. To this end, we propose a content selection and
planning framework for zero-shot decontextualisation, which determines what
content should be mentioned and in what order for a sentence to be understood
out of context. Specifically, given a potentially ambiguous sentence and its
context, we first segment it into basic semantically-independent units. We then
identify potentially ambiguous units from the given sentence, and extract
relevant units from the context based on their discourse relations. Finally, we
generate a content plan to rewrite the sentence by enriching each ambiguous
unit with its relevant units. Experimental results demonstrate that our
approach is competitive for sentence decontextualisation, producing sentences
that exhibit better semantic integrity and discourse coherence, outperforming
existing methods.

</details>


### [126] [Transformer-Encoder Trees for Efficient Multilingual Machine Translation and Speech Translation](https://arxiv.org/abs/2509.17930)
*Yiwen Guan,Jacob Whitehill*

Main category: cs.CL

TL;DR: 提出了一种新颖的分层Transformer编码器树（TET）结合非自回归编码器模型，用于多语言翻译，特别是语音翻译，旨在解决计算冗余和低资源语言准确性问题。


<details>
  <summary>Details</summary>
Motivation: 多语言翻译面临计算冗余和低资源语言准确率有限的问题，尤其是在语音翻译中。

Method: 采用分层Transformer编码器树（TET）结合非自回归编码器模型，使用连接时序分类（CTC）进行训练，通过共享语言相似目标语言的中间表示来提高效率。

Result: TET能够提高低资源语言的准确率，减少计算冗余，并在单次前向传播中生成所有目标语言。在语音翻译中，结合wav2vec2的非自回归系统比自回归系统快7-14倍，且翻译质量有潜力。

Conclusion: 该方法有效解决了多语言翻译中的计算和准确性问题，特别是在语音翻译中展示了高效和质量的平衡。

Abstract: Multilingual translation faces challenges of computational redundancy and
limited accuracy for low-resource languages, especially in speech translation.
To address this, we propose a novel hierarchical Transformer Encoder Tree (TET)
combined with non-autoregressive encoder-only models trained with Connectionist
Temporal Classification for multilingual translation. By sharing intermediate
representations among linguistically similar target languages, TET can improve
accuracy on low-resource languages, reduce computational redundancy, and allow
generating all target languages in a single forward pass, thus eliminating
sequential bottlenecks and improving parallelism. For speech translation,
combining TET with a non-autoregressive speech recognition backbone (wav2vec2)
shows promising results in terms of translation quality compared to
autoregressive systems while being 7-14 times faster.

</details>


### [127] [Training-free Truthfulness Detection via Value Vectors in LLMs](https://arxiv.org/abs/2509.17932)
*Runheng Liu,Heyan Huang,Xingchen Xiao,Zhijing Wu*

Main category: cs.CL

TL;DR: 本文提出TruthV方法，利用MLP模块中的值向量检测LLM生成内容的真实性，在NoVo基准上显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有基于内部激活的训练方法存在可扩展性和泛化性问题，而训练无关方法NoVo仅关注注意力机制，忽略了MLP模块在事实召回中的重要作用

Method: TruthV是一种简单可解释的训练无关方法，通过利用MLP模块中值向量表现出的真实性相关统计模式来检测内容真实性

Result: 在NoVo基准测试中，TruthV显著优于NoVo和似然比基线方法

Conclusion: MLP模块尽管在之前的训练无关研究中被忽视，但编码了丰富有用的真实性信号，为理解LLM内部真实性表示提供了新视角

Abstract: Large language models often generate factually incorrect outputs, motivating
efforts to detect the truthfulness of their content. Most existing approaches
rely on training probes over internal activations, but these methods suffer
from scalability and generalization issues. A recent training-free method,
NoVo, addresses this challenge by exploiting statistical patterns from the
model itself. However, it focuses exclusively on attention mechanisms,
potentially overlooking the MLP module-a core component of Transformer models
known to support factual recall. In this paper, we show that certain value
vectors within MLP modules exhibit truthfulness-related statistical patterns.
Building on this insight, we propose TruthV, a simple and interpretable
training-free method that detects content truthfulness by leveraging these
value vectors. On the NoVo benchmark, TruthV significantly outperforms both
NoVo and log-likelihood baselines, demonstrating that MLP modules-despite being
neglected in prior training-free efforts-encode rich and useful signals for
truthfulness detection. These findings offer new insights into how truthfulness
is internally represented in LLMs and motivate further research on scalable and
interpretable truthfulness detection.

</details>


### [128] [D-REX: A Benchmark for Detecting Deceptive Reasoning in Large Language Models](https://arxiv.org/abs/2509.17938)
*Satyapriya Krishna,Andy Zou,Rahul Gupta,Eliot Krzysztof Jones,Nick Winter,Dan Hendrycks,J. Zico Kolter,Matt Fredrikson,Spyros Matsoukas*

Main category: cs.CL

TL;DR: 本文提出D-REX数据集，用于评估大语言模型内部推理过程与最终输出之间的差异，揭示模型可能产生表面无害但内部推理恶意的欺骗性对齐问题。


<details>
  <summary>Details</summary>
Motivation: 当前的安全评估方法主要关注明显有害的输出，但忽视了模型可能产生表面无害输出而内部推理过程存在恶意的问题，这种欺骗性对齐是一个被低估的重大风险。

Method: 通过竞争性红队演练构建D-REX数据集，包含对抗性系统提示、用户查询、模型表面无害的响应以及揭示恶意意图的内部思维链。

Result: D-REX对现有模型和安全机制构成了显著挑战，表明需要开发能够审查模型内部推理过程的新技术。

Conclusion: 仅关注最终输出是不够的，必须开发能够检测模型内部推理过程的技术来应对欺骗性对齐风险。

Abstract: The safety and alignment of Large Language Models (LLMs) are critical for
their responsible deployment. Current evaluation methods predominantly focus on
identifying and preventing overtly harmful outputs. However, they often fail to
address a more insidious failure mode: models that produce benign-appearing
outputs while operating on malicious or deceptive internal reasoning. This
vulnerability, often triggered by sophisticated system prompt injections,
allows models to bypass conventional safety filters, posing a significant,
underexplored risk. To address this gap, we introduce the Deceptive Reasoning
Exposure Suite (D-REX), a novel dataset designed to evaluate the discrepancy
between a model's internal reasoning process and its final output. D-REX was
constructed through a competitive red-teaming exercise where participants
crafted adversarial system prompts to induce such deceptive behaviors. Each
sample in D-REX contains the adversarial system prompt, an end-user's test
query, the model's seemingly innocuous response, and, crucially, the model's
internal chain-of-thought, which reveals the underlying malicious intent. Our
benchmark facilitates a new, essential evaluation task: the detection of
deceptive alignment. We demonstrate that D-REX presents a significant challenge
for existing models and safety mechanisms, highlighting the urgent need for new
techniques that scrutinize the internal processes of LLMs, not just their final
outputs.

</details>


### [129] [HICode: Hierarchical Inductive Coding with LLMs](https://arxiv.org/abs/2509.17946)
*Mian Zhong,Pristina Wang,Anjalie Field*

Main category: cs.CL

TL;DR: HICode是一种利用LLM进行细粒度语料分析的两阶段管道，通过归纳生成标签和层次聚类来替代手动标注和传统统计方法


<details>
  <summary>Details</summary>
Motivation: 解决研究人员依赖难以扩展的手动标注或难以控制的统计工具（如主题建模）进行细粒度语料分析的问题

Method: HICode两阶段管道：1）从分析数据中归纳生成标签；2）层次聚类标签以浮现涌现主题，灵感来自定性研究方法

Result: 在三个不同数据集上验证，测量与人工构建主题的一致性，并通过自动和人工评估证明其鲁棒性。在阿片类药物诉讼文件案例研究中揭示了制药公司的激进营销策略

Conclusion: HICode展示了利用LLM将研究人员通常手动进行的细致分析扩展到大型文本语料库的潜力

Abstract: Despite numerous applications for fine-grained corpus analysis, researchers
continue to rely on manual labeling, which does not scale, or statistical tools
like topic modeling, which are difficult to control. We propose that LLMs have
the potential to scale the nuanced analyses that researchers typically conduct
manually to large text corpora. To this effect, inspired by qualitative
research methods, we develop HICode, a two-part pipeline that first inductively
generates labels directly from analysis data and then hierarchically clusters
them to surface emergent themes. We validate this approach across three diverse
datasets by measuring alignment with human-constructed themes and demonstrating
its robustness through automated and human evaluations. Finally, we conduct a
case study of litigation documents related to the ongoing opioid crisis in the
U.S., revealing aggressive marketing strategies employed by pharmaceutical
companies and demonstrating HICode's potential for facilitating nuanced
analyses in large-scale data.

</details>


### [130] [Dorabella Cipher as Musical Inspiration](https://arxiv.org/abs/2509.17950)
*Bradley Hauer,Colin Choi,Abram Hindle,Scott Smallwood,Grzegorz Kondrak*

Main category: cs.CL

TL;DR: 本文探讨了Dorabella密码可能代表加密音乐而非英文文本的假设，通过开发简化的音乐符号和n-gram模型，尝试从密码中重建旋律，并将解密过程视为作曲过程的一部分。


<details>
  <summary>Details</summary>
Motivation: Dorabella密码是英国作曲家爱德华·埃尔加写的一份加密笔记，一个多世纪以来一直未被破解。大多数解决方案假设其为英文文本，但本文研究其代表加密音乐的可能性。

Method: 开发简化的音乐符号，使用n-gram音乐模型验证单字母替换加密的现有音乐语料库，并将这些方法应用于Dorabella密码以重建旋律。

Result: 通过对Dorabella应用该方法，产生了一个具有音乐品质的解密结果，并通过艺术性作曲转化为可听的旋律。

Conclusion: 研究结果并不声称是唯一真正的解决方案，而是将解密过程框架为作曲过程的一部分。

Abstract: The Dorabella cipher is an encrypted note written by English composer Edward
Elgar, which has defied decipherment attempts for more than a century. While
most proposed solutions are English texts, we investigate the hypothesis that
Dorabella represents enciphered music. We weigh the evidence for and against
the hypothesis, devise a simplified music notation, and attempt to reconstruct
a melody from the cipher. Our tools are n-gram models of music which we
validate on existing music corpora enciphered using monoalphabetic
substitution. By applying our methods to Dorabella, we produce a decipherment
with musical qualities, which is then transformed via artful composition into a
listenable melody. Far from arguing that the end result represents the only
true solution, we instead frame the process of decipherment as part of the
composition process.

</details>


### [131] [Bringing Pedagogy into Focus: Evaluating Virtual Teaching Assistants' Question-Answering in Asynchronous Learning Environments](https://arxiv.org/abs/2509.17961)
*Li Siyan,Zhen Xu,Vethavikashini Chithrra Raghuram,Xuanming Zhang,Renzhe Yu,Zhou Yu*

Main category: cs.CL

TL;DR: 提出一个基于学习科学的评估框架，用于评估异步学习环境中虚拟教学助手的教学效果，通过专家标注构建分类器来改进VTA系统的评估方法。


<details>
  <summary>Details</summary>
Motivation: 异步学习环境中虚拟教学助手缺乏基于教育理论的严谨评估，现有评估方法往往依赖表面指标，难以有意义地比较不同VTA系统的教学有效性。

Method: 构建基于学习科学的评估框架，使用专家对VTA响应的标注来训练分类器，针对异步论坛讨论这一常见VTA部署场景进行评估。

Result: 评估了分类器的有效性，识别了提高准确性的方法以及阻碍泛化的挑战，为VTA系统的理论驱动评估奠定了基础。

Conclusion: 这项工作为VTA系统的理论驱动评估奠定了基础，为教育中更具教学效果的AI应用铺平了道路。

Abstract: Asynchronous learning environments (ALEs) are widely adopted for formal and
informal learning, but timely and personalized support is often limited. In
this context, Virtual Teaching Assistants (VTAs) can potentially reduce the
workload of instructors, but rigorous and pedagogically sound evaluation is
essential. Existing assessments often rely on surface-level metrics and lack
sufficient grounding in educational theories, making it difficult to
meaningfully compare the pedagogical effectiveness of different VTA systems. To
bridge this gap, we propose an evaluation framework rooted in learning sciences
and tailored to asynchronous forum discussions, a common VTA deployment context
in ALE. We construct classifiers using expert annotations of VTA responses on a
diverse set of forum posts. We evaluate the effectiveness of our classifiers,
identifying approaches that improve accuracy as well as challenges that hinder
generalization. Our work establishes a foundation for theory-driven evaluation
of VTA systems, paving the way for more pedagogically effective AI in
education.

</details>


### [132] [ReDepress: A Cognitive Framework for Detecting Depression Relapse from Social Media](https://arxiv.org/abs/2509.17991)
*Aakash Kumar Agarwal,Saprativa Bhattacharjee,Mauli Rastogi,Jemima S. Jacob,Biplab Banerjee,Rashmi Gupta,Pushpak Bhattacharyya*

Main category: cs.CL

TL;DR: 该论文提出了首个临床验证的抑郁症复发检测数据集ReDepress，基于认知理论构建特征，通过机器学习模型实现了86%的F1分数，为抑郁症复发早期检测提供了新方法。


<details>
  <summary>Details</summary>
Motivation: 近50%的抑郁症患者面临复发风险，复发后风险增至80%。目前社交媒体上的抑郁症检测研究较多，但复发检测因缺乏标注数据和难以区分复发/非复发用户而研究不足。

Method: 构建了首个临床验证的复发数据集（204名Reddit用户），基于认知理论（注意力偏差、解释偏差、记忆偏差和反刍思维）进行标注和建模，使用基于transformer的时间模型。

Result: 认知标记能显著区分复发和非复发群体，基于认知特征增强的模型性能优异，transformer时间模型F1分数达到0.86。

Conclusion: 研究验证了心理学理论在真实文本数据中的应用，展示了认知信息计算方法在早期复发检测中的潜力，为低成本、可扩展的心理健康干预铺平了道路。

Abstract: Almost 50% depression patients face the risk of going into relapse. The risk
increases to 80% after the second episode of depression. Although, depression
detection from social media has attained considerable attention, depression
relapse detection has remained largely unexplored due to the lack of curated
datasets and the difficulty of distinguishing relapse and non-relapse users. In
this work, we present ReDepress, the first clinically validated social media
dataset focused on relapse, comprising 204 Reddit users annotated by mental
health professionals. Unlike prior approaches, our framework draws on cognitive
theories of depression, incorporating constructs such as attention bias,
interpretation bias, memory bias and rumination into both annotation and
modeling. Through statistical analyses and machine learning experiments, we
demonstrate that cognitive markers significantly differentiate relapse and
non-relapse groups, and that models enriched with these features achieve
competitive performance, with transformer-based temporal models attaining an F1
of 0.86. Our findings validate psychological theories in real-world textual
data and underscore the potential of cognitive-informed computational methods
for early relapse detection, paving the way for scalable, low-cost
interventions in mental healthcare.

</details>


### [133] [Variation in Verification: Understanding Verification Dynamics in Large Language Models](https://arxiv.org/abs/2509.17995)
*Yefan Zhou,Austin Xu,Yilun Zhou,Janvijay Singh,Jiang Gui,Shafiq Joty*

Main category: cs.CL

TL;DR: 本文研究了生成式验证器在测试时扩展（TTS）中的应用，通过系统分析验证动态，发现验证效果受问题难度、生成器能力和验证器生成能力的影响，并提出了优化验证策略的机会。


<details>
  <summary>Details</summary>
Motivation: 随着测试时计算扩展使大语言模型能够解决更复杂问题，生成式验证器（通过生成思维链推理进行验证）的有效性需要系统研究，以优化TTS应用中的验证策略。

Method: 在12个基准测试（数学推理、知识和自然语言推理任务）上使用14个开源模型（2B到72B参数范围）和GPT-4o，系统分析验证动态的三个维度：问题难度、生成器能力和验证器生成能力。

Result: 实验发现：（1）简单问题使验证器更可靠地认证正确响应；（2）弱生成器产生的错误比强生成器更容易检测；（3）验证能力与验证器自身问题解决能力相关，但随问题难度变化。弱生成器经验证后性能可接近强生成器，强验证器在某些情况下优势有限。

Conclusion: 验证效果受多因素影响，优化验证策略可提升TTS性能，但验证器扩展本身无法克服基本验证挑战，需综合考虑问题难度和生成器能力。

Abstract: Recent advances have shown that scaling test-time computation enables large
language models (LLMs) to solve increasingly complex problems across diverse
domains. One effective paradigm for test-time scaling (TTS) involves LLM
generators producing multiple solution candidates, with LLM verifiers assessing
the correctness of these candidates without reference answers. In this paper,
we study generative verifiers, which perform verification by generating
chain-of-thought (CoT) reasoning followed by a binary verdict. We
systematically analyze verification dynamics across three dimensions - problem
difficulty, generator capability, and verifier generation capability - with
empirical studies on 12 benchmarks across mathematical reasoning, knowledge,
and natural language reasoning tasks using 14 open-source models (2B to 72B
parameter range) and GPT-4o. Our experiments reveal three key findings about
verification effectiveness: (1) Easy problems allow verifiers to more reliably
certify correct responses; (2) Weak generators produce errors that are easier
to detect than strong generators; (3) Verification ability is generally
correlated with the verifier's own problem-solving capability, but this
relationship varies with problem difficulty. These findings reveal
opportunities to optimize basic verification strategies in TTS applications.
First, given the same verifier, some weak generators can nearly match stronger
ones in post-verification TTS performance (e.g., the Gemma2-9B to Gemma2-27B
performance gap shrinks by 75.5%). Second, we identify cases where strong
verifiers offer limited advantage over weak ones, as both fail to provide
meaningful verification gains, suggesting that verifier scaling alone cannot
overcome fundamental verification challenges.

</details>


### [134] [WenetSpeech-Chuan: A Large-Scale Sichuanese Corpus with Rich Annotation for Dialectal Speech Processing](https://arxiv.org/abs/2509.18004)
*Yuhang Dai,Ziyu Zhang,Shuai Wang,Longhao Li,Zhao Guo,Tianlun Zuo,Shuiyuan Wang,Hongfei Xue,Chengyou Wang,Qing Wang,Xin Xu,Hui Bu,Jie Li,Jian Kang,Binbin Zhang,Lei Xie*

Main category: cs.CL

TL;DR: 本文介绍了WenetSpeech-Chuan，一个10,000小时的四川方言语音语料库，通过Chuan-Pipeline数据处理框架构建，并发布了ASR和TTS基准测试。


<details>
  <summary>Details</summary>
Motivation: 解决四川方言大规模开源数据稀缺的问题，促进方言语音技术发展，降低研究门槛，促进AI公平性。

Method: 使用新颖的Chuan-Pipeline数据处理框架构建语料库，包含手动验证的转录文本，并建立ASR和TTS基准测试。

Result: 在WenetSpeech-Chuan上训练的模型在开源系统中达到最先进性能，与商业服务结果相当。

Conclusion: WenetSpeech-Chuan作为最大的开源四川方言语料库，不仅降低了方言语音处理研究门槛，还在促进AI公平性和减少语音技术偏见方面发挥关键作用。

Abstract: The scarcity of large-scale, open-source data for dialects severely hinders
progress in speech technology, a challenge particularly acute for the widely
spoken Sichuanese dialects of Chinese. To address this critical gap, we
introduce WenetSpeech-Chuan, a 10,000-hour, richly annotated corpus constructed
using our novel Chuan-Pipeline, a complete data processing framework for
dialectal speech. To facilitate rigorous evaluation and demonstrate the
corpus's effectiveness, we also release high-quality ASR and TTS benchmarks,
WenetSpeech-Chuan-Eval, with manually verified transcriptions. Experiments show
that models trained on WenetSpeech-Chuan achieve state-of-the-art performance
among open-source systems and demonstrate results comparable to commercial
services. As the largest open-source corpus for Sichuanese dialects,
WenetSpeech-Chuan not only lowers the barrier to research in dialectal speech
processing but also plays a crucial role in promoting AI equity and mitigating
bias in speech technologies. The corpus, benchmarks, models, and receipts are
publicly available on our project page.

</details>


### [135] [Cross-Attention is Half Explanation in Speech-to-Text Models](https://arxiv.org/abs/2509.18010)
*Sara Papi,Dennis Fucci,Marco Gaido,Matteo Negri,Luisa Bentivogli*

Main category: cs.CL

TL;DR: 本文评估了语音转文本模型中交叉注意力的解释能力，发现注意力分数与基于显著性的解释有中度到强相关性，但仅能捕捉约50%的输入相关性，表明交叉注意力作为解释性代理存在根本局限性。


<details>
  <summary>Details</summary>
Motivation: 交叉注意力在语音转文本处理中被广泛用于下游应用（如时间戳估计和音频-文本对齐），但其作为依赖关系反映的假设在语音领域尚未充分探索。本文旨在填补这一空白。

Method: 通过比较交叉注意力分数与从特征归因导出的输入显著性图，评估交叉注意力的解释能力。分析涵盖单语和多语、单任务和多任务模型，并在多个尺度上进行。

Result: 注意力分数与基于显著性的解释有中度到强对齐（特别是跨头和层聚合时），但仅能捕捉约50%的输入相关性，在最佳情况下仅部分反映解码器对编码器表示的关注（占显著性的52-75%）。

Conclusion: 交叉注意力作为解释性代理存在根本局限性，它提供了信息性但不完整的视图，不能完全反映语音转文本模型预测的驱动因素。

Abstract: Cross-attention is a core mechanism in encoder-decoder architectures,
widespread in many fields, including speech-to-text (S2T) processing. Its
scores have been repurposed for various downstream applications--such as
timestamp estimation and audio-text alignment--under the assumption that they
reflect the dependencies between input speech representation and the generated
text. While the explanatory nature of attention mechanisms has been widely
debated in the broader NLP literature, this assumption remains largely
unexplored within the speech domain. To address this gap, we assess the
explanatory power of cross-attention in S2T models by comparing its scores to
input saliency maps derived from feature attribution. Our analysis spans
monolingual and multilingual, single-task and multi-task models at multiple
scales, and shows that attention scores moderately to strongly align with
saliency-based explanations, particularly when aggregated across heads and
layers. However, it also shows that cross-attention captures only about 50% of
the input relevance and, in the best case, only partially reflects how the
decoder attends to the encoder's representations--accounting for just 52-75% of
the saliency. These findings uncover fundamental limitations in interpreting
cross-attention as an explanatory proxy, suggesting that it offers an
informative yet incomplete view of the factors driving predictions in S2T
models.

</details>


### [136] [RadEval: A framework for radiology text evaluation](https://arxiv.org/abs/2509.18030)
*Justin Xu,Xi Zhang,Javid Abderezaei,Julie Bauml,Roger Boodoo,Fatemeh Haghighi,Ali Ganjizadeh,Eric Brattain,Dave Van Veen,Zaiqiao Meng,David Eyre,Jean-Benoit Delbrouck*

Main category: cs.CL

TL;DR: RadEval是一个统一的开源框架，用于评估放射学文本，整合了多种指标，包括经典n-gram重叠、上下文度量、临床概念评分和基于LLM的评估器，并提供了统计测试工具和基准模型评估。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏统一的放射学文本评估框架，现有指标分散且实现不一致，难以进行可复现和稳健的基准测试。

Method: 整合多种评估指标，标准化实现，扩展GREEN支持多模态成像，预训练领域特定的放射学编码器，发布专家标注数据集，并提供统计测试工具。

Result: 展示了领域特定编码器的强零样本检索性能，不同指标与放射科医生判断的相关性，以及在多个公开数据集上的基准模型评估结果。

Conclusion: RadEval促进了放射学报告生成的可复现性和稳健基准测试，为研究社区提供了全面的评估工具。

Abstract: We introduce RadEval, a unified, open-source framework for evaluating
radiology texts. RadEval consolidates a diverse range of metrics, from classic
n-gram overlap (BLEU, ROUGE) and contextual measures (BERTScore) to clinical
concept-based scores (F1CheXbert, F1RadGraph, RaTEScore, SRR-BERT,
TemporalEntityF1) and advanced LLM-based evaluators (GREEN). We refine and
standardize implementations, extend GREEN to support multiple imaging
modalities with a more lightweight model, and pretrain a domain-specific
radiology encoder, demonstrating strong zero-shot retrieval performance. We
also release a richly annotated expert dataset with over 450 clinically
significant error labels and show how different metrics correlate with
radiologist judgment. Finally, RadEval provides statistical testing tools and
baseline model evaluations across multiple publicly available datasets,
facilitating reproducibility and robust benchmarking in radiology report
generation.

</details>


### [137] [The PIMMUR Principles: Ensuring Validity in Collective Behavior of LLM Societies](https://arxiv.org/abs/2509.18052)
*Jiaxu Zhou,Jen-tse Huang,Xuhui Zhou,Man Ho Lam,Xintao Wang,Hao Zhu,Wenxuan Wang,Maarten Sap*

Main category: cs.CL

TL;DR: 该论文提出了PIMMUR原则，作为LLM社会模拟研究的六个必要方法论标准，旨在提高此类研究的可信度和可重复性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM社会模拟研究存在系统性方法缺陷，许多研究采用削弱其主张有效性的实验设计，需要建立方法论标准。

Method: 通过调查40多篇论文识别六种常见方法缺陷，将其形式化为PIMMUR原则，并用支持PIMMUR的框架重新运行五个代表性研究进行验证。

Result: 发现GPT-4o和Qwen-3在53.1%的情况下能正确推断出实验假设，违反无意识原则；在更严格条件下，许多报告的社会现象无法复现。

Conclusion: PIMMUR原则是LLM社会模拟研究的必要条件，为更可靠的"AI社会"研究奠定了基础。

Abstract: Large Language Models (LLMs) are increasingly used for social simulation,
where populations of agents are expected to reproduce human-like collective
behavior. However, we find that many recent studies adopt experimental designs
that systematically undermine the validity of their claims. From a survey of
over 40 papers, we identify six recurring methodological flaws: agents are
often homogeneous (Profile), interactions are absent or artificially imposed
(Interaction), memory is discarded (Memory), prompts tightly control outcomes
(Minimal-Control), agents can infer the experimental hypothesis (Unawareness),
and validation relies on simplified theoretical models rather than real-world
data (Realism). For instance, GPT-4o and Qwen-3 correctly infer the underlying
social experiment in 53.1% of cases when given instructions from prior
work-violating the Unawareness principle. We formalize these six requirements
as the PIMMUR principles and argue they are necessary conditions for credible
LLM-based social simulation. To demonstrate their impact, we re-run five
representative studies using a framework that enforces PIMMUR and find that the
reported social phenomena frequently fail to emerge under more rigorous
conditions. Our work establishes methodological standards for LLM-based
multi-agent research and provides a foundation for more reliable and
reproducible claims about "AI societies."

</details>


### [138] [TMD-TTS: A Unified Tibetan Multi-Dialect Text-to-Speech Synthesis for Ü-Tsang, Amdo and Kham Speech Dataset Generation](https://arxiv.org/abs/2509.18060)
*Yutong Liu,Ziyue Zhang,Ban Ma-bao,Renzeng Duojie,Yuqing Cai,Yongbin Yu,Xiangxiang Wang,Fan Gao,Cheng Huang,Nyima Tashi*

Main category: cs.CL

TL;DR: TMD-TTS是一个统一的藏语多方言文本转语音框架，通过方言融合模块和方言专用动态路由网络来合成具有明确方言标签的平行方言语音。


<details>
  <summary>Details</summary>
Motivation: 藏语是一种低资源语言，其三大方言（卫藏、安多和康巴）的平行语音语料库有限，这限制了语音建模的进展。

Method: 提出TMD-TTS框架，包含方言融合模块和方言专用动态路由网络（DSDR-Net），以捕捉跨方言的细粒度声学和语言变异。

Result: 广泛的客观和主观评估表明，TMD-TTS在方言表达性方面显著优于基线方法。

Conclusion: 通过具有挑战性的语音到语音方言转换任务进一步验证了合成语音的质量和实用性。

Abstract: Tibetan is a low-resource language with limited parallel speech corpora
spanning its three major dialects (\"U-Tsang, Amdo, and Kham), limiting
progress in speech modeling. To address this issue, we propose TMD-TTS, a
unified Tibetan multi-dialect text-to-speech (TTS) framework that synthesizes
parallel dialectal speech from explicit dialect labels. Our method features a
dialect fusion module and a Dialect-Specialized Dynamic Routing Network
(DSDR-Net) to capture fine-grained acoustic and linguistic variations across
dialects. Extensive objective and subjective evaluations demonstrate that
TMD-TTS significantly outperforms baselines in dialectal expressiveness. We
further validate the quality and utility of the synthesized speech through a
challenging Speech-to-Speech Dialect Conversion (S2SDC) task.

</details>


### [139] [ARK-V1: An LLM-Agent for Knowledge Graph Question Answering Requiring Commonsense Reasoning](https://arxiv.org/abs/2509.18063)
*Jan-Felix Klein,Lars Ohnemus*

Main category: cs.CL

TL;DR: ARK-V1是一个简单的知识图谱代理，通过迭代探索图谱来回答自然语言查询，在需要领域知识和常识推理的任务中显著优于思维链基线方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型依赖的内部知识往往不充分、过时或不正确，特别是在需要特定领域知识的问题上。知识图谱提供了结构化外部知识，但其复杂性和多跳推理需求使得集成具有挑战性。

Method: 提出ARK-V1知识图谱代理，使用未经微调的最先进LLM作为骨干，在CoLoTa数据集上评估，该数据集需要对长尾实体进行基于知识图谱和常识的推理。

Result: ARK-V1的条件准确率显著高于思维链基线方法，更大的骨干模型在覆盖率、正确性和稳定性方面表现出明显的提升趋势。

Conclusion: ARK-V1证明了将知识图谱与LLM结合的有效性，为需要外部知识增强的复杂推理任务提供了有前景的解决方案。

Abstract: Large Language Models (LLMs) show strong reasoning abilities but rely on
internalized knowledge that is often insufficient, outdated, or incorrect when
trying to answer a question that requires specific domain knowledge. Knowledge
Graphs (KGs) provide structured external knowledge, yet their complexity and
multi-hop reasoning requirements make integration challenging. We present
ARK-V1, a simple KG-agent that iteratively explores graphs to answer natural
language queries. We evaluate several not fine-tuned state-of-the art LLMs as
backbones for ARK-V1 on the CoLoTa dataset, which requires both KG-based and
commonsense reasoning over long-tail entities. ARK-V1 achieves substantially
higher conditional accuracies than Chain-of-Thought baselines, and larger
backbone models show a clear trend toward better coverage, correctness, and
stability.

</details>


### [140] [SEQR: Secure and Efficient QR-based LoRA Routing](https://arxiv.org/abs/2509.18093)
*William Fleshman,Benjamin Van Durme*

Main category: cs.CL

TL;DR: 本文提出了SEQR，一种无监督的LoRA路由算法，通过最大化激活范数来高效选择适配器，解决了在隐私敏感环境中LoRA路由的挑战。


<details>
  <summary>Details</summary>
Motivation: LoRA已成为大语言模型参数高效微调的标准技术，但在隐私敏感环境中，监督训练路由器可能引发隐私问题，因此需要无监督的路由方法。

Method: 基于激活范数最大化理论框架，开发了SEQR算法，该算法通过最大化激活范数来识别最优适配器，并提供严格的路由保证。

Result: 实验验证表明SEQR在多任务性能和效率方面均有提升，能够显著提高路由效率。

Conclusion: SEQR是一种高度可扩展且有效的动态LoRA组合解决方案，为无监督LoRA路由提供了理论基础和实用算法。

Abstract: Low-Rank Adaptation (LoRA) has become a standard technique for
parameter-efficient fine-tuning of large language models, enabling large
libraries of LoRAs, each for a specific task or domain. Efficiently selecting
the correct LoRA adapter for a given input remains a challenge, particularly in
secure environments where supervised training of routers may raise privacy
concerns. Motivated by previous approaches, we formalize the goal of
unsupervised LoRA routing in terms of activation norm maximization, providing a
theoretical framework for analysis. We demonstrate the discriminative power of
activation norms and introduce SEQR, an unsupervised LoRA routing algorithm
designed to maximize efficiency while providing strict routing guarantees. SEQR
provably identifies the norm-maximizing adapter with significantly greater
efficiency, making it a highly scalable and effective solution for dynamic LoRA
composition. We validate our results through experiments that demonstrate
improved multi-task performance and efficiency.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [141] [Localizing Malicious Outputs from CodeLLM](https://arxiv.org/abs/2509.17070)
*Mayukh Borana,Junyi Liang,Sai Sathiesh Rajan,Sudipta Chattopadhyay*

Main category: cs.CR

TL;DR: FreqRank是一种基于突变的防御方法，用于定位LLM输出中的恶意组件及其对应的后门触发器。该方法通过频率排名系统识别恶意子串，并利用这些信息定位输入中的后门触发器。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在代码相关任务中的广泛应用，后门攻击对模型安全性构成严重威胁。需要一种有效的方法来检测和定位恶意组件，确保LLM输出的安全性。

Method: FreqRank假设恶意子串在触发输入时持续出现在输出中，使用基于频率的排名系统来识别这些恶意组件。通过创建多个突变体并分析输出频率，定位后门触发器。

Result: 在9个恶意模型上的实验显示，平均攻击成功率为86.6%。FreqRank在98%的情况下将恶意输出列为前5个建议之一，且比其他防御方法有效35-50%。

Conclusion: FreqRank是一种有效的后门攻击防御方法，能够准确识别恶意输出并定位触发器，特别是在突变体数量增加时效果更佳，且对样本数量要求较低。

Abstract: We introduce FreqRank, a mutation-based defense to localize malicious
components in LLM outputs and their corresponding backdoor triggers. FreqRank
assumes that the malicious sub-string(s) consistently appear in outputs for
triggered inputs and uses a frequency-based ranking system to identify them.
Our ranking system then leverages this knowledge to localize the backdoor
triggers present in the inputs. We create nine malicious models through
fine-tuning or custom instructions for three downstream tasks, namely, code
completion (CC), code generation (CG), and code summarization (CS), and show
that they have an average attack success rate (ASR) of 86.6%. Furthermore,
FreqRank's ranking system highlights the malicious outputs as one of the top
five suggestions in 98% of cases. We also demonstrate that FreqRank's
effectiveness scales as the number of mutants increases and show that FreqRank
is capable of localizing the backdoor trigger effectively even with a limited
number of triggered samples. Finally, we show that our approach is 35-50% more
effective than other defense methods.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [142] [AutoArabic: A Three-Stage Framework for Localizing Video-Text Retrieval Benchmarks](https://arxiv.org/abs/2509.16438)
*Mohamed Eltahir,Osamah Sarraj,Abdulrahman Alfrihidi,Taha Alshatiri,Mohammed Khurd,Mohammed Bremoo,Tanveer Hussain*

Main category: cs.CV

TL;DR: AutoArabic是一个三阶段框架，利用大型语言模型将非阿拉伯语视频检索基准翻译成现代标准阿拉伯语，显著减少人工修订工作量，并开发了阿拉伯语版本的DiDeMo基准（DiDeMo-AR）。


<details>
  <summary>Details</summary>
Motivation: 当前视频到文本和文本到视频检索主要由英语基准主导，阿拉伯语缺乏本地化的评估指标和基准数据集。

Method: 采用三阶段框架：1）使用LLM进行翻译；2）错误检测模块自动标记潜在翻译错误（准确率97%）；3）生成阿拉伯语基准数据集。

Result: 成功创建了DiDeMo-AR，包含40,144个流畅的阿拉伯语描述。在阿拉伯语和英语基准上训练CLIP风格模型，发现性能差距约为3个百分点，表明阿拉伯语本地化保持了基准难度。

Conclusion: AutoArabic框架有效解决了阿拉伯语视频检索基准的缺失问题，支持不同后编辑预算，代码已开源以确保可复现性。

Abstract: Video-to-text and text-to-video retrieval are dominated by English benchmarks
(e.g. DiDeMo, MSR-VTT) and recent multilingual corpora (e.g. RUDDER), yet
Arabic remains underserved, lacking localized evaluation metrics. We introduce
a three-stage framework, AutoArabic, utilizing state-of-the-art large language
models (LLMs) to translate non-Arabic benchmarks into Modern Standard Arabic,
reducing the manual revision required by nearly fourfold. The framework
incorporates an error detection module that automatically flags potential
translation errors with 97% accuracy. Applying the framework to DiDeMo, a video
retrieval benchmark produces DiDeMo-AR, an Arabic variant with 40,144 fluent
Arabic descriptions. An analysis of the translation errors is provided and
organized into an insightful taxonomy to guide future Arabic localization
efforts. We train a CLIP-style baseline with identical hyperparameters on the
Arabic and English variants of the benchmark, finding a moderate performance
gap (about 3 percentage points at Recall@1), indicating that Arabic
localization preserves benchmark difficulty. We evaluate three post-editing
budgets (zero/ flagged-only/ full) and find that performance improves
monotonically with more post-editing, while the raw LLM output (zero-budget)
remains usable. To ensure reproducibility to other languages, we made the code
available at https://github.com/Tahaalshatiri/AutoArabic.

</details>


### [143] [Seeing Culture: A Benchmark for Visual Reasoning and Grounding](https://arxiv.org/abs/2509.16517)
*Burak Satar,Zhixin Ma,Patrick A. Irawan,Wilfried A. Mulyawan,Jing Jiang,Ee-Peng Lim,Chong-Wah Ngo*

Main category: cs.CV

TL;DR: 该论文提出了Seeing Culture Benchmark (SCB)，这是一个专注于文化推理的多模态视觉语言模型基准测试，通过两阶段评估（多选视觉问答和相关文化文物分割）来评估模型的文化推理能力，重点关注东南亚七国的138种文化文物。


<details>
  <summary>Details</summary>
Motivation: 现有的文化数据集在提供文化推理方面存在不足，且对许多文化代表性不够。特别是东南亚等地区的多元文化往往被忽视，需要专门的基准测试来评估模型的文化理解和推理能力。

Method: 设计了双阶段评估方法：第一阶段要求模型从三个系统组织的视觉选项类型中选择正确答案（同国家、不同国家或混合组）；第二阶段要求模型分割相关的文化文物作为推理证据。基准包含1,065张图像和3,178个问题。

Result: 对各种视觉语言模型的评估揭示了跨模态文化推理的复杂性，并凸显了在文化细微场景中视觉推理与空间定位之间的差距。

Conclusion: SCB基准测试对于识别当前模型在文化推理方面的不足至关重要，为文化推理领域的未来发展提供了指导方向。

Abstract: Multimodal vision-language models (VLMs) have made substantial progress in
various tasks that require a combined understanding of visual and textual
content, particularly in cultural understanding tasks, with the emergence of
new cultural datasets. However, these datasets frequently fall short of
providing cultural reasoning while underrepresenting many cultures. In this
paper, we introduce the Seeing Culture Benchmark (SCB), focusing on cultural
reasoning with a novel approach that requires VLMs to reason on culturally rich
images in two stages: i) selecting the correct visual option with
multiple-choice visual question answering (VQA), and ii) segmenting the
relevant cultural artifact as evidence of reasoning. Visual options in the
first stage are systematically organized into three types: those originating
from the same country, those from different countries, or a mixed group.
Notably, all options are derived from a singular category for each type.
Progression to the second stage occurs only after a correct visual option is
chosen. The SCB benchmark comprises 1,065 images that capture 138 cultural
artifacts across five categories from seven Southeast Asia countries, whose
diverse cultures are often overlooked, accompanied by 3,178 questions, of which
1,093 are unique and meticulously curated by human annotators. Our evaluation
of various VLMs reveals the complexities involved in cross-modal cultural
reasoning and highlights the disparity between visual reasoning and spatial
grounding in culturally nuanced scenarios. The SCB serves as a crucial
benchmark for identifying these shortcomings, thereby guiding future
developments in the field of cultural reasoning.
https://github.com/buraksatar/SeeingCulture

</details>


### [144] [Advancing Reference-free Evaluation of Video Captions with Factual Analysis](https://arxiv.org/abs/2509.16538)
*Shubhashis Roy Dipta,Tz-Ying Wu,Subarna Tripathi*

Main category: cs.CV

TL;DR: 本文提出了VC-Inspector，一种无需参考标注的参考无关视频字幕质量评估框架，通过利用大语言模型生成不同质量的伪字幕来训练多模态评估器，在事实准确性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 获取人工标注的视频字幕成本高昂，特别是在多样化视频领域中。现有基于参考的评估方法需要真实标注，这在现实视频评估中不切实际，因此需要开发参考无关的评估框架。

Method: 利用大语言模型基于监督数据生成不同质量的伪字幕，然后使用这些数据训练多模态模型（Qwen2.5-VL）作为评估器，专注于事实准确性评估。

Result: 在VATEX-Eval数据集上与人类判断高度一致，优于现有方法，并且在图像字幕数据集Flickr8K-Expert和Flickr8K-CF上也能良好泛化。

Conclusion: VC-Inspector为视频字幕的事实准确性评估提供了可扩展和可泛化的解决方案，为多样化视频领域的更有效和客观评估方法铺平了道路。

Abstract: Video captions offer concise snapshots of actors, objects, and actions within
a video, serving as valuable assets for applications such as question answering
and event localization. However, acquiring human annotations for video captions
is costly or even impractical, especially when dealing with diverse video
domains. Existing models trained on supervised datasets face challenges in
evaluating performance across different domains due to the reliance on
reference-based evaluation protocols, which necessitate ground truth captions.
This assumption is unrealistic for evaluating videos in the wild. To address
these limitations, we propose a reference-free evaluation framework that does
not require ground truth captions, focusing on factual grounding to ensure
accurate assessment of caption quality. We introduce VC-Inspector, a novel
caption quality evaluator that is both reference-free and factually grounded.
Utilizing large language models, we generate pseudo captions of varying quality
based on supervised data, which are subsequently used to train a multimodal
model (i.e., Qwen2.5-VL) as the evaluator. Our approach demonstrates superior
alignment with human judgments on the VATEX-Eval dataset, outperforming
existing methods. The performance also generalizes to image caption datasets,
Flickr8K-Expert and Flickr8K-CF, when viewing images as 1-frame videos.
Overall, VC-Inspector offers a scalable and generalizable solution for
evaluating the factual accuracy of video captions, paving the way for more
effective and objective assessment methodologies in diverse video domains.

</details>


### [145] [When Big Models Train Small Ones: Label-Free Model Parity Alignment for Efficient Visual Question Answering using Small VLMs](https://arxiv.org/abs/2509.16633)
*Abhirama Subramanyam Penamakuri,Navlika Singh,Piyush Arora,Anand Mishra*

Main category: cs.CV

TL;DR: 提出了Model Parity Aligner (MPA)框架，通过无标签图像和大型视觉语言模型的知识转移，系统性地提升小型视觉语言模型的性能，缩小与大模型的性能差距。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型(L-VLMs)计算成本高，不适合资源受限场景；小型视觉语言模型(S-VLMs)效率高但性能差距显著。需要一种方法在保持效率的同时提升S-VLMs的性能。

Method: MPA采用基于对等的策略方法，精确识别S-VLMs和L-VLMs之间的知识差异，并仅针对这些差异进行优化训练，而不是依赖标注数据的传统知识蒸馏方法。

Result: 在TextVQA、ST-VQA、ChartQA和OKVQA四个VQA基准测试中，MPA持续提升了S-VLMs的性能，缩小了性能差距，同时保持了计算效率。

Conclusion: MPA框架有效解决了S-VLMs性能不足的问题，为资源受限环境提供了可行的解决方案，代码已公开。

Abstract: Large Vision-Language Models (L-VLMs) have demonstrated remarkable
performance in various vision and language tasks, including visual question
answering (VQA). However, their high computational cost makes them impractical
for resource-constrained settings and inference-heavy applications. In
contrast, Small Vision-Language Models (S-VLMs) offer efficiency but suffer
from a significant performance gap compared to their larger counterparts. In
this work, we introduce the Model Parity Aligner (MPA), a novel framework
designed to systematically improve S-VLMs by leveraging unlabeled images and
effective knowledge transfer from L-VLMs. Instead of traditional knowledge
distillation methods that rely on labeled training data, MPA employs a
strategic parity-based approach that precisely identifies the knowledge
disparities between S-VLMs and L-VLMs, and optimizes training by targeting only
these disparities. We conduct extensive experiments on four diverse VQA
benchmarks, namely TextVQA, ST-VQA, ChartQA, and OKVQA, each of which requires
specialized reasoning capabilities such as text recognition, chart
interpretation, and commonsense and factual understanding. Our results
demonstrate that MPA consistently enhances the performance of S-VLMs on all
benchmarks, reducing the performance gap while maintaining computational
efficiency. We make our code publicly available.

</details>


### [146] [VaseVQA: Multimodal Agent and Benchmark for Ancient Greek Pottery](https://arxiv.org/abs/2509.17191)
*Jinchao Ge,Tengfei Cheng,Biao Wu,Zeyu Zhang,Shiya Huang,Judith Bishop,Gillian Shepherd,Meng Fang,Ling Chen,Yang Zhao*

Main category: cs.CV

TL;DR: VaseVL是一个针对古希腊陶器分析的MLLM系统，通过SFT-then-RL方法提升模型在文化遗产领域的专家级推理能力，显著优于仅使用SFT的基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM在文化遗产分析方面存在局限性：通用模型缺乏领域专业知识，而SFT方法容易过拟合表面模式，导致认证和历史归属推理脆弱。需要开发具有鲁棒专家级推理能力的模型。

Method: 构建问题类型分类法，通过SFT模型定位类型特定的性能差距，使用类型条件、组合性导向的奖励进行RL优化。同时发布了包含31,773张图像的VaseVQA基准数据集。

Result: 在风格分类和历史归属任务上达到最先进水平，相比仅使用SFT的基线模型在组合鲁棒性方面有显著提升。

Conclusion: 验证了诊断引导、分类法条件奖励工程的有效性，为未来研究提供了可重用资源。代码和数据集将公开。

Abstract: Analyzing cultural-heritage artifacts remains challenging for MLLMs: general
models lack domain expertise, and SFT often overfits superficial patterns,
yielding brittle reasoning for authentication and historical attribution. This
raises the question of how to equip MLLMs with robust, expert-level reasoning
for ancient Greek pottery. We present VaseVL, an SFT-then-RL system that turns
evaluation into supervision: we construct a taxonomy of question types, probe
the SFT model to localize type-specific performance gaps, and optimize with
type-conditioned, compositionality-oriented rewards targeting those gaps. We
also release VaseVQA, a comprehensive benchmark of 31,773 images designed to
probe deep understanding. Experiments show state-of-the-art results on style
classification and historical attribution with marked gains in compositional
robustness over SFT-only baselines, validating diagnosis-guided,
taxonomy-conditioned reward engineering and providing a reusable resource for
future research. Code and dataset will be available at
https://github.com/AIGeeksGroup/VaseVQA.

</details>


### [147] [ChartHal: A Fine-grained Framework Evaluating Hallucination of Large Vision Language Models in Chart Understanding](https://arxiv.org/abs/2509.17481)
*Xingqi Wang,Yiming Cui,Xin Yao,Shijin Wang,Guoping Hu,Xiaoyu Qin*

Main category: cs.CV

TL;DR: 提出了ChartHal基准，用于评估大视觉语言模型在图表理解中的幻觉问题，发现现有模型存在严重幻觉现象


<details>
  <summary>Details</summary>
Motivation: 图表理解需要复杂的感知和认知能力以及严格的事实准确性，但现有研究对图表理解中的幻觉问题关注不足

Method: 构建了包含1,062个样本的人类验证数据集，设计了细粒度的幻觉场景分类法

Result: 最先进的LVLMs在ChartHal上表现不佳，GPT-5和o4-mini分别仅达到34.46%和22.79%的准确率，涉及图表中缺失或矛盾信息的问题更容易引发幻觉

Conclusion: 图表理解中的幻觉问题严重，迫切需要更鲁棒的缓解策略

Abstract: Large Vision-Language Models (LVLMs) have recently demonstrated remarkable
progress, yet hallucination remains a critical barrier, particularly in chart
understanding, which requires sophisticated perceptual and cognitive abilities
as well as rigorous factual accuracy. While prior work has investigated
hallucinations and chart comprehension independently, their intersection
remains largely unexplored. To address this gap, we present ChartHal, a
benchmark that features a fine-grained taxonomy of hallucination scenarios in
chart understanding, along with a human-validated dataset of 1,062 samples. Our
evaluation shows that state-of-the-art LVLMs suffer from severe hallucinations
on ChartHal, including proprietary models such as GPT-5 and o4-mini, which
achieve only 34.46% and 22.79% accuracy, respectively. Further analysis reveals
that questions involving information absent from or contradictory to charts are
especially likely to trigger hallucinations, underscoring the urgent need for
more robust mitigation strategies. Code and data are available at
https://github.com/ymcui/ChartHal .

</details>


### [148] [WISE: Weak-Supervision-Guided Step-by-Step Explanations for Multimodal LLMs in Image Classification](https://arxiv.org/abs/2509.17740)
*Yiwen Jiang,Deval Mehta,Siyuan Yan,Yaling Shen,Zimu Wang,Zongyuan Ge*

Main category: cs.CV

TL;DR: 提出了WISE方法，通过弱监督将概念瓶颈模型的概念表示转化为可解释的推理链，增强多模态大语言模型在图像分类中的细粒度视觉理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有MCoT方法依赖丰富的数据集且主要关注对象间推理，忽视了图像分类中至关重要的对象内理解。

Method: WISE方法在弱监督下将概念瓶颈模型的概念表示重新表述为简洁可解释的推理链，为任何图像分类数据集生成MCoT。

Result: 在十个数据集上的实验表明，生成的MCoT不仅将可解释性提高了37%，而且在用于微调MLLMs时还能提升分类准确率。

Conclusion: 该工作连接了基于概念的可解释性和生成式MCoT推理，为增强MLLMs在细粒度视觉理解方面提供了通用框架。

Abstract: Multimodal Large Language Models (MLLMs) have shown promise in visual-textual
reasoning, with Multimodal Chain-of-Thought (MCoT) prompting significantly
enhancing interpretability. However, existing MCoT methods rely on
rationale-rich datasets and largely focus on inter-object reasoning,
overlooking the intra-object understanding crucial for image classification. To
address this gap, we propose WISE, a Weak-supervision-guided Step-by-step
Explanation method that augments any image classification dataset with MCoTs by
reformulating the concept-based representations from Concept Bottleneck Models
(CBMs) into concise, interpretable reasoning chains under weak supervision.
Experiments across ten datasets show that our generated MCoTs not only improve
interpretability by 37% but also lead to gains in classification accuracy when
used to fine-tune MLLMs. Our work bridges concept-based interpretability and
generative MCoT reasoning, providing a generalizable framework for enhancing
MLLMs in fine-grained visual understanding.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [149] [Hierarchical Retrieval: The Geometry and a Pretrain-Finetune Recipe](https://arxiv.org/abs/2509.16411)
*Chong You,Rajesh Jayaram,Ananda Theertha Suresh,Robin Nittka,Felix Yu,Sanjiv Kumar*

Main category: cs.IR

TL;DR: 本文研究了双编码器模型在层次检索中的局限性，提出了预训练-微调方法来解决长距离检索性能下降的问题，显著提升了检索效果。


<details>
  <summary>Details</summary>
Motivation: 双编码器模型在信息检索中广泛应用，但其欧几里得嵌入空间的几何特性限制了表达能力，特别是在层次检索场景下，当匹配文档是查询的所有祖先时，长距离检索性能会下降。

Method: 首先证明了双编码器在层次检索中的可行性条件，然后提出预训练-微调方法：先在层次结构上进行预训练，再在标准检索任务上微调，以解决"迷失在长距离"现象。

Result: 在WordNet层次结构上的实验表明，预训练-微调方法将长距离对的召回率从19%提升到76%，同时在购物查询数据集上也改善了相关产品的检索效果。

Conclusion: 预训练-微调方法能有效解决双编码器在层次检索中的长距离性能下降问题，显著提升检索质量，为层次结构数据检索提供了有效解决方案。

Abstract: Dual encoder (DE) models, where a pair of matching query and document are
embedded into similar vector representations, are widely used in information
retrieval due to their simplicity and scalability. However, the Euclidean
geometry of the embedding space limits the expressive power of DEs, which may
compromise their quality. This paper investigates such limitations in the
context of hierarchical retrieval (HR), where the document set has a
hierarchical structure and the matching documents for a query are all of its
ancestors. We first prove that DEs are feasible for HR as long as the embedding
dimension is linear in the depth of the hierarchy and logarithmic in the number
of documents. Then we study the problem of learning such embeddings in a
standard retrieval setup where DEs are trained on samples of matching query and
document pairs. Our experiments reveal a lost-in-the-long-distance phenomenon,
where retrieval accuracy degrades for documents further away in the hierarchy.
To address this, we introduce a pretrain-finetune recipe that significantly
improves long-distance retrieval without sacrificing performance on closer
documents. We experiment on a realistic hierarchy from WordNet for retrieving
documents at various levels of abstraction, and show that pretrain-finetune
boosts the recall on long-distance pairs from 19% to 76%. Finally, we
demonstrate that our method improves retrieval of relevant products on a
shopping queries dataset.

</details>


### [150] [Evaluating the Effectiveness and Scalability of LLM-Based Data Augmentation for Retrieval](https://arxiv.org/abs/2509.16442)
*Pranjal A. Chitale,Bishal Santra,Yashoteja Prabhu,Amit Sharma*

Main category: cs.IR

TL;DR: 本文对LLM数据增强在检索任务中的有效性进行了系统性研究，发现增强效果存在收益递减现象，小模型增强可媲美大模型，且增强对预训练不足的模型效果最显著。


<details>
  <summary>Details</summary>
Motivation: 双编码器检索模型因知识有限而性能不如LLM检索模型，LLM数据增强被提出作为解决方案，但缺乏对其有效性和可扩展性的系统理解。

Method: 通过100多个不同实验设置，系统研究检索模型、增强模型和增强策略等关键因素对检索性能的影响。

Result: 增强能提升检索性能但存在收益递减；小LLM增强可达到与大模型竞争的效果；增强对预训练不足的模型效果最明显。

Conclusion: 研究结果为更明智和高效的增强策略提供了指导，有助于在成本效益最大化的同时提升检索性能。

Abstract: Compact dual-encoder models are widely used for retrieval owing to their
efficiency and scalability. However, such models often underperform compared to
their Large Language Model (LLM)-based retrieval counterparts, likely due to
their limited world knowledge. While LLM-based data augmentation has been
proposed as a strategy to bridge this performance gap, there is insufficient
understanding of its effectiveness and scalability to real-world retrieval
problems. Existing research does not systematically explore key factors such as
the optimal augmentation scale, the necessity of using large augmentation
models, and whether diverse augmentations improve generalization, particularly
in out-of-distribution (OOD) settings. This work presents a comprehensive study
of the effectiveness of LLM augmentation for retrieval, comprising over 100
distinct experimental settings of retrieval models, augmentation models and
augmentation strategies. We find that, while augmentation enhances retrieval
performance, its benefits diminish beyond a certain augmentation scale, even
with diverse augmentation strategies. Surprisingly, we observe that
augmentation with smaller LLMs can achieve performance competitive with larger
augmentation models. Moreover, we examine how augmentation effectiveness varies
with retrieval model pre-training, revealing that augmentation provides the
most benefit to models which are not well pre-trained. Our insights pave the
way for more judicious and efficient augmentation strategies, thus enabling
informed decisions and maximizing retrieval performance while being more
cost-effective. Code and augmented datasets accompanying this work are publicly
available at https://aka.ms/DAGR.

</details>


### [151] [Purely Semantic Indexing for LLM-based Generative Recommendation and Retrieval](https://arxiv.org/abs/2509.16446)
*Ruohan Zhang,Jiacheng Li,Julian McAuley,Yupeng Hou*

Main category: cs.IR

TL;DR: 提出纯语义索引方法，通过放松严格最近质心选择和引入两种模型无关算法（ECM和RRS），解决语义ID冲突问题，在不添加非语义标记的情况下生成唯一且保持语义的ID。


<details>
  <summary>Details</summary>
Motivation: 现有语义ID方法存在语义冲突问题，即语义相似的文档被分配相同ID。为避免冲突而添加非语义标记会引入随机性并扩大搜索空间，从而损害性能。

Method: 提出纯语义索引方法，通过放松严格最近质心选择，引入两种模型无关算法：穷举候选匹配（ECM）和递归残差搜索（RRS），确保ID唯一性。

Result: 在顺序推荐、产品搜索和文档检索任务上的大量实验表明，该方法提高了整体性能和冷启动性能。

Conclusion: 确保ID唯一性的方法有效，纯语义索引能够在不损害语义的情况下解决ID冲突问题。

Abstract: Semantic identifiers (IDs) have proven effective in adapting large language
models for generative recommendation and retrieval. However, existing methods
often suffer from semantic ID conflicts, where semantically similar documents
(or items) are assigned identical IDs. A common strategy to avoid conflicts is
to append a non-semantic token to distinguish them, which introduces randomness
and expands the search space, therefore hurting performance. In this paper, we
propose purely semantic indexing to generate unique, semantic-preserving IDs
without appending non-semantic tokens. We enable unique ID assignment by
relaxing the strict nearest-centroid selection and introduce two model-agnostic
algorithms: exhaustive candidate matching (ECM) and recursive residual
searching (RRS). Extensive experiments on sequential recommendation, product
search, and document retrieval tasks demonstrate that our methods improve both
overall and cold-start performance, highlighting the effectiveness of ensuring
ID uniqueness.

</details>


### [152] [Long document summarization using page specific target text alignment and distilling page importance](https://arxiv.org/abs/2509.16539)
*Pushpa Devi,Ayush Agrawal,Ashutosh Dubey,C. Ravindranath Chowdary*

Main category: cs.IR

TL;DR: 提出了PTS和PTSPI两种模型，通过将长文档分页并与目标摘要对齐，解决了BART模型在长文档摘要中的上下文窗口限制问题。PTSPI在PTS基础上增加了页面重要性权重，在基准数据集上显著优于现有最佳方法。


<details>
  <summary>Details</summary>
Motivation: 随着文本数据在新闻、法律、医疗和科学领域的快速增长，用户难以高效消费和提取有意义的信息。长文档摘要化摘要资源密集，现有文献较少，且BART等模型受限于上下文窗口长度。

Method: PTS模型将源文档分页，每页与目标摘要的相关部分对齐，生成部分摘要。PTSPI在PTS基础上增加页面重要性层，提供动态页面权重和显式监督，聚焦信息量最大的页面。

Result: 在基准数据集上，PTSPI在ROUGE-1和ROUGE-2分数上分别比现有最佳方法提升了6.32%和8.08%。

Conclusion: 提出的PTS和PTSPI模型有效解决了长文档摘要化摘要的挑战，通过分页对齐和页面重要性加权机制显著提升了摘要质量。

Abstract: The rapid growth of textual data across news, legal, medical, and scientific
domains is becoming a challenge for efficiently accessing and understanding
large volumes of content. It is increasingly complex for users to consume and
extract meaningful information efficiently. Thus, raising the need for
summarization. Unlike short document summarization, long document abstractive
summarization is resource-intensive, and very little literature is present in
this direction. BART is a widely used efficient sequence-to-sequence
(seq-to-seq) model. However, when it comes to summarizing long documents, the
length of the context window limits its capabilities. We proposed a model
called PTS (Page-specific Target-text alignment Summarization) that extends the
seq-to-seq method for abstractive summarization by dividing the source document
into several pages. PTS aligns each page with the relevant part of the target
summary for better supervision. Partial summaries are generated for each page
of the document. We proposed another model called PTSPI (Page-specific
Target-text alignment Summarization with Page Importance), an extension to PTS
where an additional layer is placed before merging the partial summaries into
the final summary. This layer provides dynamic page weightage and explicit
supervision to focus on the most informative pages. We performed experiments on
the benchmark dataset and found that PTSPI outperformed the SOTA by 6.32\% in
ROUGE-1 and 8.08\% in ROUGE-2 scores.

</details>


### [153] [The Role of Vocabularies in Learning Sparse Representations for Ranking](https://arxiv.org/abs/2509.16621)
*Hiun Kim,Tae Kwan Lee,Taeryun Won*

Main category: cs.IR

TL;DR: 该论文研究了SPLADE模型中词汇表的作用及其与检索效率和效果的关系，通过构建不同词汇表大小的BERT模型并进行实验，发现词汇表大小和预训练权重对检索性能有重要影响。


<details>
  <summary>Details</summary>
Motivation: 目前对于学习型稀疏检索（LSR）如SPLADE的研究中，虽然已有工作探索了扩展词汇表的方法（ESPLADE），但对于词汇表在SPLADE模型中的具体作用及其与检索效率和效果的关系研究较少。

Method: 构建了两个具有10万大小输出词汇表的BERT模型：一个使用ESPLADE预训练方法初始化，另一个随机初始化。在真实搜索点击日志上微调后，应用基于logit分数的查询和文档剪枝来平衡效率。

Result: 实验结果显示，在应用剪枝后，两个模型在计算预算下都比32K大小的普通SPLADE模型更有效，且ESPLADE模型比随机词汇表模型更有效，同时保持相似的检索成本。

Conclusion: 词汇表大小和预训练权重在检索引擎中起着配置查询、文档及其交互表示规范的作用，超越了它们在NLP中的原始意义。这些发现为LSR的改进提供了新的方向。

Abstract: Learned Sparse Retrieval (LSR) such as SPLADE has growing interest for
effective semantic 1st stage matching while enjoying the efficiency of inverted
indices. A recent work on learning SPLADE models with expanded vocabularies
(ESPLADE) was proposed to represent queries and documents into a sparse space
of custom vocabulary which have different levels of vocabularic granularity.
Within this effort, however, there have not been many studies on the role of
vocabulary in SPLADE models and their relationship to retrieval efficiency and
effectiveness.
  To study this, we construct BERT models with 100K-sized output vocabularies,
one initialized with the ESPLADE pretraining method and one initialized
randomly. After finetune on real-world search click logs, we applied logit
score-based queries and documents pruning to max size for further balancing
efficiency. The experimental result in our evaluation set shows that, when
pruning is applied, the two models are effective compared to the 32K-sized
normal SPLADE model in the computational budget under the BM25. And the ESPLADE
models are more effective than the random vocab model, while having a similar
retrieval cost.
  The result indicates that the size and pretrained weight of output
vocabularies play the role of configuring the representational specification
for queries, documents, and their interactions in the retrieval engine, beyond
their original meaning and purposes in NLP. These findings can provide a new
room for improvement for LSR by identifying the importance of representational
specification from vocabulary configuration for efficient and effective
retrieval.

</details>


### [154] [OnePiece: Bringing Context Engineering and Reasoning to Industrial Cascade Ranking System](https://arxiv.org/abs/2509.18091)
*Sunhao Dai,Jiakai Tang,Jiahua Wu,Kun Wang,Yuxuan Zhu,Bingjun Chen,Bangyang Hong,Yu Zhao,Cong Fu,Kangle Wu,Yabo Ni,Anxiang Zeng,Wenjie Wang,Xu Chen,Jun Xu,See-Kiong Ng*

Main category: cs.IR

TL;DR: OnePiece是一个统一框架，将LLM风格的上下文工程和推理机制集成到工业级检索和排序模型中，在Shopee的主要个性化搜索场景中部署并取得了显著业务提升。


<details>
  <summary>Details</summary>
Motivation: 现有工业推荐系统主要局限于移植Transformer架构，而LLM的成功不仅来自架构，还来自上下文工程和多步推理机制，这些机制在工业排序系统中尚未充分探索。

Method: 基于纯Transformer架构，提出三个关键创新：结构化上下文工程（用偏好和场景信号增强交互历史）、块级潜在推理（通过块大小扩展推理带宽的多步表示细化）、渐进式多任务训练（利用用户反馈链监督推理步骤）。

Result: 在Shopee主要个性化搜索场景中部署，实现了关键业务指标的持续提升，包括超过+2%的GMV/UU和+2.90%的广告收入增长。

Conclusion: OnePiece框架成功证明了将LLM风格的上下文工程和推理机制集成到工业级推荐系统中的有效性，为推荐系统带来了实质性改进。

Abstract: Despite the growing interest in replicating the scaled success of large
language models (LLMs) in industrial search and recommender systems, most
existing industrial efforts remain limited to transplanting Transformer
architectures, which bring only incremental improvements over strong Deep
Learning Recommendation Models (DLRMs). From a first principle perspective, the
breakthroughs of LLMs stem not only from their architectures but also from two
complementary mechanisms: context engineering, which enriches raw input queries
with contextual cues to better elicit model capabilities, and multi-step
reasoning, which iteratively refines model outputs through intermediate
reasoning paths. However, these two mechanisms and their potential to unlock
substantial improvements remain largely underexplored in industrial ranking
systems.
  In this paper, we propose OnePiece, a unified framework that seamlessly
integrates LLM-style context engineering and reasoning into both retrieval and
ranking models of industrial cascaded pipelines. OnePiece is built on a pure
Transformer backbone and further introduces three key innovations: (1)
structured context engineering, which augments interaction history with
preference and scenario signals and unifies them into a structured tokenized
input sequence for both retrieval and ranking; (2) block-wise latent reasoning,
which equips the model with multi-step refinement of representations and scales
reasoning bandwidth via block size; (3) progressive multi-task training, which
leverages user feedback chains to effectively supervise reasoning steps during
training. OnePiece has been deployed in the main personalized search scenario
of Shopee and achieves consistent online gains across different key business
metrics, including over $+2\%$ GMV/UU and a $+2.90\%$ increase in advertising
revenue.

</details>


### [155] [MetaEmbed: Scaling Multimodal Retrieval at Test-Time with Flexible Late Interaction](https://arxiv.org/abs/2509.18095)
*Zilin Xiao,Qi Ma,Mengting Gu,Chun-cheng Jason Chen,Xintao Chen,Vicente Ordonez,Vijai Mohan*

Main category: cs.IR

TL;DR: MetaEmbed是一个新的多模态检索框架，通过引入可学习的元标记来生成紧凑但表达力强的多向量嵌入，实现了检索质量和效率之间的灵活平衡。


<details>
  <summary>Details</summary>
Motivation: 当前多模态嵌入方法要么将查询和候选压缩为单个向量（限制细粒度信息表达），要么生成过多向量（多向量检索成本过高），需要一种既能保持表达力又高效的解决方案。

Method: 在训练期间向输入序列添加固定数量的可学习元标记，在测试时使用其最后一层上下文表示作为多向量嵌入，通过Matryoshka多向量检索训练按粒度组织信息。

Result: 在MMEB和ViDoRe基准测试中达到最先进的检索性能，并能稳健扩展到320亿参数模型，实现检索质量与效率的灵活权衡。

Conclusion: MetaEmbed框架成功解决了多模态检索中表达力与效率的平衡问题，为大规模多模态检索提供了有效的解决方案。

Abstract: Universal multimodal embedding models have achieved great success in
capturing semantic relevance between queries and candidates. However, current
methods either condense queries and candidates into a single vector,
potentially limiting the expressiveness for fine-grained information, or
produce too many vectors that are prohibitively expensive for multi-vector
retrieval. In this work, we introduce MetaEmbed, a new framework for multimodal
retrieval that rethinks how multimodal embeddings are constructed and
interacted with at scale. During training, a fixed number of learnable Meta
Tokens are appended to the input sequence. At test-time, their last-layer
contextualized representations serve as compact yet expressive multi-vector
embeddings. Through the proposed Matryoshka Multi-Vector Retrieval training,
MetaEmbed learns to organize information by granularity across multiple
vectors. As a result, we enable test-time scaling in multimodal retrieval,
where users can balance retrieval quality against efficiency demands by
selecting the number of tokens used for indexing and retrieval interactions.
Extensive evaluations on the Massive Multimodal Embedding Benchmark (MMEB) and
the Visual Document Retrieval Benchmark (ViDoRe) confirm that MetaEmbed
achieves state-of-the-art retrieval performance while scaling robustly to
models with 32B parameters.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [156] [OpenGVL - Benchmarking Visual Temporal Progress for Data Curation](https://arxiv.org/abs/2509.17321)
*Paweł Budzianowski,Emilia Wiśnios,Gracjan Góral,Igor Kulakov,Viktor Petrenko,Krzysztof Walas*

Main category: cs.RO

TL;DR: OpenGVL是一个用于评估任务进度预测的基准测试，专注于机器人操作任务，比较开源和闭源基础模型的性能，并展示其在自动化数据管理中的应用。


<details>
  <summary>Details</summary>
Motivation: 机器人领域数据稀缺，但现有数据量快速增长，需要可靠的任务完成预测方法来自动标注和管理大规模数据。

Method: 基于生成价值学习(GVL)方法，利用视觉语言模型(VLMs)从视觉观察中预测任务进度，构建OpenGVL基准测试评估不同模型在多样化操作任务中的表现。

Result: 开源模型家族在时间进度预测任务上表现显著低于闭源模型，仅达到闭源模型约70%的性能。

Conclusion: OpenGVL可作为自动化数据管理和筛选的实用工具，有效评估大规模机器人数据集的质量，相关代码和基准已开源。

Abstract: Data scarcity remains one of the most limiting factors in driving progress in
robotics. However, the amount of available robotics data in the wild is growing
exponentially, creating new opportunities for large-scale data utilization.
Reliable temporal task completion prediction could help automatically annotate
and curate this data at scale. The Generative Value Learning (GVL) approach was
recently proposed, leveraging the knowledge embedded in vision-language models
(VLMs) to predict task progress from visual observations. Building upon GVL, we
propose OpenGVL, a comprehensive benchmark for estimating task progress across
diverse challenging manipulation tasks involving both robotic and human
embodiments. We evaluate the capabilities of publicly available open-source
foundation models, showing that open-source model families significantly
underperform closed-source counterparts, achieving only approximately $70\%$ of
their performance on temporal progress prediction tasks. Furthermore, we
demonstrate how OpenGVL can serve as a practical tool for automated data
curation and filtering, enabling efficient quality assessment of large-scale
robotics datasets. We release the benchmark along with the complete codebase at
\href{github.com/budzianowski/opengvl}{OpenGVL}.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [157] [Mano Report](https://arxiv.org/abs/2509.17336)
*Tianyu Fu,Anyang Su,Chenxu Zhao,Hanning Wang,Minghui Wu,Zhe Yu,Fei Hu,Mingjia Shi,Wei Dong,Jiayao Wang,Yuyang Chen,Ruiyang Yu,Siran Peng,Menglin Li,Nan Huang,Haitian Wei,Jiawei Yu,Yi Xin,Xilin Zhao,Kai Gu,Ping Jiang,Sifan Zhou,Shuo Wang*

Main category: cs.MM

TL;DR: 提出了Mano GUI代理，通过多模态基础模型和三阶段训练流程解决现有VLM方法在GUI自动化中的分辨率限制、领域不匹配和序列决策能力不足问题。


<details>
  <summary>Details</summary>
Motivation: 图形用户界面(GUI)是人机交互的主要媒介，但自动化GUI交互面临视觉元素复杂性、动态环境和多步推理需求的挑战。现有基于视觉语言模型(VLM)的方法存在分辨率限制、领域不匹配和序列决策能力不足的问题。

Method: 基于在大量网页和计算机系统数据上预训练的多模态基础模型构建Mano代理，包括：1)新颖的高保真数据生成模拟环境；2)三阶段训练流程（监督微调、离线强化学习、在线强化学习）；3)错误恢复的验证模块。

Result: Mano在多个GUI基准测试（包括Mind2Web和OSWorld）上实现了最先进的性能，在成功率和操作准确性方面取得了显著提升。

Conclusion: 该研究为将强化学习与VLM有效集成以实际部署GUI代理提供了新见解，强调了领域特定数据、迭代训练和整体奖励设计的重要性。

Abstract: Graphical user interfaces (GUIs) are the primary medium for human-computer
interaction, yet automating GUI interactions remains challenging due to the
complexity of visual elements, dynamic environments, and the need for
multi-step reasoning. Existing methods based on vision-language models (VLMs)
often suffer from limited resolution, domain mismatch, and insufficient
sequential decisionmaking capability. To address these issues, we propose Mano,
a robust GUI agent built upon a multi-modal foundation model pre-trained on
extensive web and computer system data. Our approach integrates a novel
simulated environment for high-fidelity data generation, a three-stage training
pipeline (supervised fine-tuning, offline reinforcement learning, and online
reinforcement learning), and a verification module for error recovery. Mano
demonstrates state-of-the-art performance on multiple GUI benchmarks, including
Mind2Web and OSWorld, achieving significant improvements in success rate and
operational accuracy. Our work provides new insights into the effective
integration of reinforcement learning with VLMs for practical GUI agent
deployment, highlighting the importance of domain-specific data, iterative
training, and holistic reward design.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [158] [How Can Quantum Deep Learning Improve Large Language Models?](https://arxiv.org/abs/2509.16244)
*Emily Jimin Roh,Hyojun Ahn,Samuel Yen-Chi Chen,Soohyun Park,Joongheon Kim*

Main category: quant-ph

TL;DR: 本文系统调查和比较了传统参数高效微调方法（如LoRA、Prefix tuning、SoRA）与量子振幅嵌入适应（QAA）框架在大型语言模型适应中的性能差异。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的全参数微调计算和内存成本过高，而现有参数高效微调方法在可扩展性、稳定性和泛化能力方面存在局限性。量子深度学习方法为LLM适应提供了新的机会。

Method: 通过系统调查和比较分析，评估传统PEFT方法（LoRA、Prefix tuning、SoRA）与量子启发的QAA框架在收敛性、效率和表示能力方面的权衡。

Result: 分析揭示了不同方法在收敛速度、计算效率和模型表达能力方面的权衡关系，并展示了量子方法在未来LLM适应中的潜力。

Conclusion: 量子振幅嵌入适应框架展示了以最小开销实现表达性模型更新的潜力，为未来LLM的高效适应提供了有前景的方向。

Abstract: The rapid progress of large language models (LLMs) has transformed natural
language processing, yet the challenge of efficient adaptation remains
unresolved. Full fine-tuning achieves strong performance but imposes
prohibitive computational and memory costs. Parameter-efficient fine-tuning
(PEFT) strategies, such as low-rank adaptation (LoRA), Prefix tuning, and
sparse low-rank adaptation (SoRA), address this issue by reducing trainable
parameters while maintaining competitive accuracy. However, these methods often
encounter limitations in scalability, stability, and generalization across
diverse tasks. Recent advances in quantum deep learning introduce novel
opportunities through quantum-inspired encoding and parameterized quantum
circuits (PQCs). In particular, the quantum-amplitude embedded adaptation (QAA)
framework demonstrates expressive model updates with minimal overhead. This
paper presents a systematic survey and comparative analysis of conventional
PEFT methods and QAA. The analysis demonstrates trade-offs in convergence,
efficiency, and representational capacity, while providing insight into the
potential of quantum approaches for future LLM adaptation.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [159] [SWE-Bench Pro: Can AI Agents Solve Long-Horizon Software Engineering Tasks?](https://arxiv.org/abs/2509.16941)
*Xiang Deng,Jeff Da,Edwin Pan,Yannis Yiming He,Charles Ide,Kanak Garg,Niklas Lauffer,Andrew Park,Nitin Pasari,Chetan Rane,Karmini Sampath,Maya Krishnan,Srivatsa Kundurthy,Sean Hendryx,Zifan Wang,Chen Bo Calvin Zhang,Noah Jacobson,Bing Liu,Brad Kenstler*

Main category: cs.SE

TL;DR: SWE-Bench Pro是一个更具挑战性的基准测试，基于SWE-BENCH的最佳实践构建，专门设计用于捕捉SWE-BENCH范围之外的现实、复杂、企业级问题。


<details>
  <summary>Details</summary>
Motivation: 现有的SWE-BENCH基准测试无法充分反映真实世界中复杂的企业级软件开发问题，需要创建一个更能准确评估专业软件工程能力的测试平台。

Method: 从41个活跃维护的代码库中收集1,865个问题，涵盖商业应用、B2B服务和开发者工具。基准分为公开集、保留集和商业集，所有任务都经过人工验证并包含足够的上下文信息。

Result: 在统一框架下评估广泛使用的编码模型，发现它们在SWE-Bench Pro上的表现低于25%（Pass@1），GPT-5达到最高分23.3%。通过聚类分析失败模式来理解模型局限性。

Conclusion: SWE-BENCH PRO提供了一个抗污染测试平台，更真实地捕捉了现实世界软件开发的复杂性和多样性，推动了专业级自主软件工程代理的发展。

Abstract: We introduce SWE-Bench Pro, a substantially more challenging benchmark that
builds upon the best practices of SWE-BENCH [25], but is explicitly designed to
capture realistic, complex, enterprise-level problems beyond the scope of
SWE-BENCH. SWE-BENCH PRO contains 1,865 problems sourced from a diverse set of
41 actively maintained repositories spanning business applications, B2B
services, and developer tools. The benchmark is partitioned into a public set
with open access to problems sourced from 11 repositories, a held-out set of 12
repositories and a commercial set of 18 proprietary repositories where we have
formal partnership agreements with early-stage startups. Problems in the
held-out and the commercial set are not publicly accessible, but we release
results on the commercial set. Our benchmark features long-horizon tasks that
may require hours to days for a professional software engineer to complete,
often involving patches across multiple files and substantial code
modifications. All tasks are human-verified and augmented with sufficient
context to ensure resolvability. In our evaluation of widely used coding
models, under a unified scaffold, we observe that their performance on
SWE-Bench PRO remains below 25% (Pass@1), with GPT-5 achieving the highest
score to date at 23.3%. To better understand these limitations, we cluster the
failure modes observed in the collected agent trajectories for a clearer
characterization of the error patterns exhibited by current models. Overall,
SWE-BENCH PRO provides a contamination-resistant testbed that more faithfully
captures the complexity and diversity of real-world software development,
advancing the pursuit of truly autonomous software engineering agents at a
professional level.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [160] [From Documents to Database: Failure Modes for Industrial Assets](https://arxiv.org/abs/2509.17834)
*Duygu Kabakci-Zorlu,Fabio Lorenzi,John Sheehan,Karol Lynch,Bradley Eck*

Main category: cs.DB

TL;DR: 提出一个使用基础模型和用户提供的技术文档来为工业设备生成失效模式与影响分析（FMEA）的交互式系统


<details>
  <summary>Details</summary>
Motivation: 减少创建知识密集型内容所需的时间，超越传统手动方法

Method: 系统聚合跨文档的非结构化内容生成FMEA，并将其存储在关系数据库中

Result: 成功展示了基础模型在促进企业资产管理系统中创建专业化结构化内容方面的潜力

Conclusion: 该系统证明了基础模型在企业资产管理领域的应用价值，能够有效提升FMEA创建的效率

Abstract: We propose an interactive system using foundation models and user-provided
technical documents to generate Failure Mode and Effects Analyses (FMEA) for
industrial equipment. Our system aggregates unstructured content across
documents to generate an FMEA and stores it in a relational database.
Leveraging this tool, the time required for creation of this
knowledge-intensive content is reduced, outperforming traditional manual
approaches. This demonstration showcases the potential of foundation models to
facilitate the creation of specialized structured content for enterprise asset
management systems.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [161] [Psychometric Personality Shaping Modulates Capabilities and Safety in Language Models](https://arxiv.org/abs/2509.16332)
*Stephen Fitz,Peter Romero,Steven Basart,Sipeng Chen,Jose Hernandez-Orallo*

Main category: cs.AI

TL;DR: 该研究探讨了通过调节大语言模型的五大人格特质如何影响其在能力和安全基准测试中的表现，发现降低尽责性会显著降低模型的安全性和一般能力。


<details>
  <summary>Details</summary>
Motivation: 虽然已有研究表明LLMs展现出可测量的合成人格特质，但关于调节这些特质如何影响模型行为的研究还很缺乏。

Method: 基于五大人格框架，通过心理测量人格控制来研究AI行为在能力和安全基准测试中的变化。

Result: 实验显示，降低尽责性会导致WMDP、TruthfulQA、ETHICS和Sycophancy等安全相关指标的显著下降，以及MMLU测量的一般能力降低。

Conclusion: 人格塑造是一个强大且未被充分探索的模型控制维度，与安全性和一般能力都有关联，需要开展人格敏感性安全评估和动态行为控制的新研究方向。

Abstract: Large Language Models increasingly mediate high-stakes interactions,
intensifying research on their capabilities and safety. While recent work has
shown that LLMs exhibit consistent and measurable synthetic personality traits,
little is known about how modulating these traits affects model behavior. We
address this gap by investigating how psychometric personality control grounded
in the Big Five framework influences AI behavior in the context of capability
and safety benchmarks. Our experiments reveal striking effects: for example,
reducing conscientiousness leads to significant drops in safety-relevant
metrics on benchmarks such as WMDP, TruthfulQA, ETHICS, and Sycophancy as well
as reduction in general capabilities as measured by MMLU. These findings
highlight personality shaping as a powerful and underexplored axis of model
control that interacts with both safety and general competence. We discuss the
implications for safety evaluation, alignment strategies, steering model
behavior after deployment, and risks associated with possible exploitation of
these findings. Our findings motivate a new line of research on
personality-sensitive safety evaluations and dynamic behavioral control in
LLMs.

</details>


### [162] [SalaMAnder: Shapley-based Mathematical Expression Attribution and Metric for Chain-of-Thought Reasoning](https://arxiv.org/abs/2509.16561)
*Yue Xin,Chen Shen,Shaotian Yan,Xiaosong Yuan,Yaoming Wang,Xiaofeng Zhang,Chenxi Huang,Jieping Ye*

Main category: cs.AI

TL;DR: 本文提出了SalaMAnder框架，这是一个基于Shapley值的理论方法，用于量化少样本思维链推理中组件级贡献，并开发了CoSP评估指标来验证模型性能与组件贡献之间的相关性。


<details>
  <summary>Details</summary>
Motivation: 思维链提示显著提升了大型语言模型的数学推理能力，但其背后的机制尚未被充分探索。本文旨在从理论上解释思维链提示为何有效，并提供数学严谨的评估方法。

Method: 利用Shapley值进行数学表达式归因，开发了高效的分层抽样算法降低计算复杂度，并通过协方差分析建立了CoSP指标。

Result: 在多个主流LLM模型和数学基准测试上的验证表明，CoSP指标与模型性能呈现稳健的单调相关性，为现有少shot思维链的成功提供了理论解释。

Conclusion: SalaMAnder框架不仅解释了思维链提示的实证成功，还为提示构建优化建立了数学严谨的原则，统一了先前工作的见解。

Abstract: Chain-of-Thought (CoT) prompting enhances the math reasoning capability of
large language models (LLMs) to a large margin. However, the mechanism
underlying such improvements remains unexplored. In this paper, we present
\textbf{SalaMAnder} (\textbf{S}h\textbf{a}p\textbf{l}ey-b\textbf{a}sed
\textbf{M}athematical Expression \textbf{A}ttribution a\textbf{nd}
M\textbf{e}t\textbf{r}ic), a theoretically grounded methodology as well as a
mathematically rigorous evaluation metric for quantifying component-level
contributions in few-shot CoT reasoning. Concretely, we leverage the Shapley
value for mathematical expression attribution and develop an efficient
stratified sampling algorithm that significantly reduces the computational
complexity. Besides, we develop the \textbf{CoSP} (\textbf{C}ardinality
\textbf{o}f \textbf{S}hapley \textbf{P}ositives) metric through covariance
analysis. Comprehensive validation across popular LLM models and diverse
mathematical benchmarks demonstrates that the CoSP metric within our SalaMAnder
framework exhibits a robust monotonic correlation with model performance, not
only providing theoretical explanations for the empirical success of existing
few-shot CoT but also establishing mathematically rigorous principles for
prompt construction optimization. Furthermore, we verify the reliability of the
explanation, based on which we unify the insights of previous work.

</details>


### [163] [Question Answering with LLMs and Learning from Answer Sets](https://arxiv.org/abs/2509.16590)
*Manuel Borroto,Katie Gallagher,Antonio Ielo,Irfan Kareem,Francesco Ricca,Alessandra Russo*

Main category: cs.AI

TL;DR: LLM2LAS是一个结合大型语言模型、答案集学习和答案集编程的混合系统，用于自动学习符号推理规则，解决故事问答任务中的常识推理问题


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖人工设计符号推理组件，作者认为该组件可以从示例中自动学习，从而克服LLM在显式常识推理方面的不足

Method: 使用LLM从文本中提取语义结构，ILASP系统将其转化为可解释的逻辑规则，然后ASP求解器进行精确推理

Result: 实验结果表明该方法在故事问答基准测试中能够有效学习和推理

Conclusion: LLM2LAS展示了自动学习符号推理规则的可行性，为结合神经和符号方法提供了新思路

Abstract: Large Language Models (LLMs) excel at understanding natural language but
struggle with explicit commonsense reasoning. A recent trend of research
suggests that the combination of LLM with robust symbolic reasoning systems can
overcome this problem on story-based question answering tasks. In this setting,
existing approaches typically depend on human expertise to manually craft the
symbolic component. We argue, however, that this component can also be
automatically learned from examples. In this work, we introduce LLM2LAS, a
hybrid system that effectively combines the natural language understanding
capabilities of LLMs, the rule induction power of the Learning from Answer Sets
(LAS) system ILASP, and the formal reasoning strengths of Answer Set
Programming (ASP). LLMs are used to extract semantic structures from text,
which ILASP then transforms into interpretable logic rules. These rules allow
an ASP solver to perform precise and consistent reasoning, enabling correct
answers to previously unseen questions. Empirical results outline the strengths
and weaknesses of our automatic approach for learning and reasoning in a
story-based question answering benchmark.

</details>


### [164] [FESTA: Functionally Equivalent Sampling for Trust Assessment of Multimodal LLMs](https://arxiv.org/abs/2509.16648)
*Debarpan Bhattacharya,Apoorva Kulkarni,Sriram Ganapathy*

Main category: cs.AI

TL;DR: FESTA是一种多模态输入采样技术，通过等效和互补采样生成不确定性度量，用于评估多模态大语言模型的预测可信度，在选择性预测性能上取得显著提升。


<details>
  <summary>Details</summary>
Motivation: 由于多模态输入范式的多样性，准确评估多模态大语言模型生成预测的可信度具有挑战性，这限制了选择性预测和用户信心的提升。

Method: 提出FESTA方法，采用任务保持采样方法进行不确定性量化，通过等效采样（评估一致性）和互补采样（评估敏感性）来扩展输入空间，仅需模型的黑盒输入输出访问，无需真实标签（无监督）。

Result: 在视觉和音频推理任务上，FESTA不确定性估计在选择性预测性能上取得显著改进：视觉LLMs相对改进33.3%，音频LLMs相对改进29.6%（基于AUROC指标检测错误预测）。

Conclusion: FESTA是一种有效的黑盒无监督方法，能够显著提升多模态大语言模型的可信度评估性能，代码已开源。

Abstract: The accurate trust assessment of multimodal large language models (MLLMs)
generated predictions, which can enable selective prediction and improve user
confidence, is challenging due to the diverse multi-modal input paradigms. We
propose Functionally Equivalent Sampling for Trust Assessment (FESTA), a
multimodal input sampling technique for MLLMs, that generates an uncertainty
measure based on the equivalent and complementary input samplings. The proposed
task-preserving sampling approach for uncertainty quantification expands the
input space to probe the consistency (through equivalent samples) and
sensitivity (through complementary samples) of the model. FESTA uses only
input-output access of the model (black-box), and does not require ground truth
(unsupervised). The experiments are conducted with various off-the-shelf
multi-modal LLMs, on both visual and audio reasoning tasks. The proposed FESTA
uncertainty estimate achieves significant improvement (33.3% relative
improvement for vision-LLMs and 29.6% relative improvement for audio-LLMs) in
selective prediction performance, based on
area-under-receiver-operating-characteristic curve (AUROC) metric in detecting
mispredictions. The code implementation is open-sourced.

</details>


### [165] [seqBench: A Tunable Benchmark to Quantify Sequential Reasoning Limits of LLMs](https://arxiv.org/abs/2509.16866)
*Mohammad Ramezanali,Mo Vazifeh,Paolo Santi*

Main category: cs.AI

TL;DR: seqBench是一个参数化基准测试，用于通过精确控制多个关键复杂度维度来探究大语言模型的序列推理极限。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试无法系统分析LLMs在序列推理中的失败模式，需要一种能够精细控制逻辑深度、回溯步骤和噪声比率的基准来揭示模型的推理局限性。

Method: seqBench通过参数化控制三个关键维度：(1)逻辑深度-解决任务所需的顺序动作数量；(2)回溯步骤-最优路径上需要重新访问先前状态的次数；(3)噪声比率-支持性事实与干扰性事实的比例。

Result: 评估显示最先进的LLMs存在普遍失败模式：在模型特定的逻辑深度之外，准确率呈指数级下降。即使顶级模型在最小搜索复杂度下也会在结构化推理任务中系统性失败。

Conclusion: seqBench揭示了LLMs在常识推理能力上的关键局限性，其数据集已公开发布以促进对LLM推理能力的深入研究，旨在更清晰地理解其真实潜力和当前边界。

Abstract: We introduce seqBench, a parametrized benchmark for probing sequential
reasoning limits in Large Language Models (LLMs) through precise,
multi-dimensional control over several key complexity dimensions. seqBench
allows systematic variation of (1) the logical depth, defined as the number of
sequential actions required to solve the task; (2) the number of backtracking
steps along the optimal path, quantifying how often the agent must revisit
prior states to satisfy deferred preconditions (e.g., retrieving a key after
encountering a locked door); and (3) the noise ratio, defined as the ratio
between supporting and distracting facts about the environment. Our evaluations
on state-of-the-art LLMs reveal a universal failure pattern: accuracy collapses
exponentially beyond a model-specific logical depth. Unlike existing
benchmarks, seqBench's fine-grained control facilitates targeted analyses of
these reasoning failures, illuminating universal scaling laws and statistical
limits, as detailed in this paper alongside its generation methodology and
evaluation metrics. We find that even top-performing models systematically fail
on seqBench's structured reasoning tasks despite minimal search complexity,
underscoring key limitations in their commonsense reasoning capabilities.
Designed for future evolution to keep pace with advancing models, the seqBench
datasets are publicly released to spur deeper scientific inquiry into LLM
reasoning, aiming to establish a clearer understanding of their true potential
and current boundaries for robust real-world application.

</details>


### [166] [ARE: Scaling Up Agent Environments and Evaluations](https://arxiv.org/abs/2509.17158)
*Pierre Andrews,Amine Benhalloum,Gerard Moreno-Torres Bertran,Matteo Bettini,Amar Budhiraja,Ricardo Silveira Cabral,Virginie Do,Romain Froger,Emilien Garreau,Jean-Baptiste Gaya,Hugo Laurençon,Maxime Lecanu,Kunal Malkan,Dheeraj Mekala,Pierre Ménard,Grégoire Mialon,Ulyana Piterbarg,Mikhail Plekhanov,Mathieu Rita,Andrey Rusakov,Thomas Scialom,Vladislav Vorotilov,Mengjue Wang,Ian Yu*

Main category: cs.AI

TL;DR: 本文介绍了Meta Agents Research Environments (ARE)平台和Gaia2基准测试，旨在解决AI代理在真实世界部署中的挑战，通过异步动态环境测试代理的综合能力。


<details>
  <summary>Details</summary>
Motivation: 当前AI代理开发与真实世界部署之间存在差距，现有基准测试多为静态环境，无法充分评估代理在动态、噪声、协作等复杂场景下的能力。

Method: 开发ARE平台提供环境创建、应用集成和代理编排的抽象接口；在ARE上构建Gaia2基准测试，要求代理处理模糊性、噪声、动态环境、多代理协作和时间约束。

Result: 实验表明，没有系统能在所有智能维度上表现最优，强推理能力往往以效率为代价，预算扩展曲线存在平台期，突显需要新架构和自适应计算策略。

Conclusion: ARE抽象支持Gaia2向其他环境的持续扩展，使社区能够快速创建针对特定领域的新基准测试，这对推动AI前沿能力发展至关重要。

Abstract: We introduce Meta Agents Research Environments (ARE), a research platform for
scalable creation of environments, integration of synthetic or real
applications, and execution of agentic orchestrations. ARE provides simple
abstractions to build complex and diverse environments, each with their own
rules, tools, content, and verifiers, helping to bridge the gap between model
development and real-world deployment. We also propose Gaia2, a benchmark built
in ARE and designed to measure general agent capabilities. Beyond search and
execution, Gaia2 requires agents to handle ambiguities and noise, adapt to
dynamic environments, collaborate with other agents, and operate under temporal
constraints. Unlike prior benchmarks, Gaia2 runs asynchronously, surfacing new
failure modes that are invisible in static settings. Our experiments show that
no system dominates across the intelligence spectrum: stronger reasoning often
comes at the cost of efficiency, and budget scaling curves plateau,
highlighting the need for new architectures and adaptive compute strategies.
Perhaps more importantly, ARE abstractions enable continuous extension of Gaia2
to other environments, empowering the community to rapidly create new
benchmarks tailored to their domains. In AI's second half, progress
increasingly depends on defining meaningful tasks and robust evaluations to
drive frontier capabilities forward.

</details>


### [167] [MoEs Are Stronger than You Think: Hyper-Parallel Inference Scaling with RoE](https://arxiv.org/abs/2509.17238)
*Soheil Zibakhsh,Mohammad Samragh,Kumari Nishu,Lauren Hannah,Arnav Kundu,Minsik Cho*

Main category: cs.AI

TL;DR: 本文提出了超并行缩放框架，通过token级别的多输出提案聚合来提升大语言模型的生成质量，并在MoE模型中实现为无需训练的推理算法RoE。


<details>
  <summary>Details</summary>
Motivation: 现有推理时序列级缩放方法（如思维链）主要关注序列层面改进，但token级别的预测质量仍有提升空间。

Method: 在MoE模型中实现RoE算法，通过向专家路由机制注入可控随机性，为每个token采样多个不同专家并聚合其输出，同时采用高效批处理策略和专用KV缓存机制降低计算开销。

Result: 7B MoE模型使用RoE后性能达到10.5B MoE模型水平，推理计算量减少30%，且无需微调模型参数。

Conclusion: 超并行缩放是序列级缩放方法的有效补充，RoE为MoE模型提供了训练无关的性能提升方案。

Abstract: The generation quality of large language models (LLMs) is often improved by
utilizing inference-time sequence-level scaling methods (e.g.,
Chain-of-Thought). We introduce hyper-parallel scaling, a complementary
framework that improves prediction quality at the token level. Hyper-parallel
scaling computes and aggregates multiple output proposals for a single token
from the model. We implement this concept in Mixture-of-Experts (MoE) models,
which we refer to as Roster of Experts (RoE). RoE is a training-free inference
algorithm that turns a single MoE into a dynamic ensemble of MoEs. RoE injects
controlled stochasticity into the expert routing mechanism, enabling it to
sample multiple diverse experts for each token and aggregate their outputs for
a more accurate final prediction.To overcome the computational cost, we
introduce an efficient batching strategy and a specialized KV-caching mechanism
that minimizes compute and memory overhead. For example, RoE enables a 7B MoE
model to match the performance of a 10.5B MoE model while using 30% less
compute for inference. These gains are achieved without any fine-tuning of
model parameters.

</details>


### [168] [Can Agents Judge Systematic Reviews Like Humans? Evaluating SLRs with LLM-based Multi-Agent System](https://arxiv.org/abs/2509.17240)
*Abdullah Mushtaq,Muhammad Rafay Naeem,Ibrahim Ghaznavi,Alaa Abd-alrazaq,Aliya Tabassum,Junaid Qadir*

Main category: cs.AI

TL;DR: 本文提出了一种基于LLM和多智能体系统的系统文献综述评估助手，用于自动化评估SLR的质量，包括协议验证、方法学评估和主题相关性检查。


<details>
  <summary>Details</summary>
Motivation: 系统文献综述是证据基础研究的基础，但传统方法劳动密集且在不同学科间存在不一致性，需要更高效和一致的评估工具。

Method: 采用多智能体系统架构，基于PRISMA指南设计专门的智能体方法，通过学术数据库进行协议验证、方法学评估和主题相关性检查。

Result: 在五个不同领域的已发表SLR上进行初步研究，系统输出与专家标注的PRISMA评分达到84%的一致性。

Conclusion: 虽然早期结果有前景，但这是迈向可扩展和准确的NLP驱动系统的第一步，展示了其在跨学科工作流程中进行严格、领域无关知识聚合的能力。

Abstract: Systematic Literature Reviews (SLRs) are foundational to evidence-based
research but remain labor-intensive and prone to inconsistency across
disciplines. We present an LLM-based SLR evaluation copilot built on a
Multi-Agent System (MAS) architecture to assist researchers in assessing the
overall quality of the systematic literature reviews. The system automates
protocol validation, methodological assessment, and topic relevance checks
using a scholarly database. Unlike conventional single-agent methods, our
design integrates a specialized agentic approach aligned with PRISMA guidelines
to support more structured and interpretable evaluations. We conducted an
initial study on five published SLRs from diverse domains, comparing system
outputs to expert-annotated PRISMA scores, and observed 84% agreement. While
early results are promising, this work represents a first step toward scalable
and accurate NLP-driven systems for interdisciplinary workflows and reveals
their capacity for rigorous, domain-agnostic knowledge aggregation to
streamline the review process.

</details>


### [169] [CogAtom: From Cognitive Atoms to Olympiad-level Mathematical Reasoning in Large Language Models](https://arxiv.org/abs/2509.17318)
*Zhuofan Chen,Jiyuan He,Yichi Zhang,Xing Hu,Haoxing Wen,Jun Bai,Wenge Rong*

Main category: cs.AI

TL;DR: CogAtom是一个基于认知原子的框架，用于合成数学上严谨且认知多样的问题，通过提取人类解题中的基本推理单元并重组来生成高质量数学问题。


<details>
  <summary>Details</summary>
Motivation: 数学推理对大型语言模型具有挑战性，而奥林匹克级别数学问题的稀缺性限制了测试时扩展技术的效果。

Method: 将问题构建建模为选择和重组从人类解题中提取的基本推理单元（认知原子），使用多样性促进的随机游走算法探索认知原子空间，并通过基于约束的重组机制确保逻辑严密性。

Result: CogAtom在准确性、推理深度和多样性方面优于现有方法，生成的问题难度与AIME相当但在结构变化上更优。

Conclusion: 该工作为可扩展、高质量的数学问题生成提供了一条认知基础路径。

Abstract: Mathematical reasoning poses significant challenges for Large Language Models
(LLMs) due to its demand for multi-step reasoning and abstract conceptual
integration. While recent test-time scaling techniques rely heavily on
high-quality, challenging problems, the scarcity of Olympiad-level math
problems remains a bottleneck. We introduce CogAtom, a novel cognitive
atom-based framework for synthesizing mathematically rigorous and cognitively
diverse problems. Unlike prior approaches, CogAtom models problem construction
as a process of selecting and recombining fundamental reasoning units,
cognitive atoms, extracted from human-authored solutions. A diversity-promoting
random walk algorithm enables exploration of the cognitive atom space, while a
constraint-based recombination mechanism ensures logical soundness and
structural validity. The combinatorial nature of the graph structure provides a
near-infinite space of reasoning paths, and the walk algorithm systematically
explores this space to achieve large-scale synthesis of high-quality problems;
meanwhile, by controlling the number of cognitive atoms, we can precisely
adjust problem difficulty, ensuring diversity, scalability, and controllability
of the generated problems. Experimental results demonstrate that CogAtom
outperforms existing methods in accuracy, reasoning depth, and diversity,
generating problems that closely match the difficulty of AIME while exceeding
it in structural variation. Our work offers a cognitively grounded pathway
toward scalable, high-quality math problem generation.Our code is publicly
available at https://github.com/Icarus-1111/CogAtom.

</details>


### [170] [LLaVul: A Multimodal LLM for Interpretable Vulnerability Reasoning about Source Code](https://arxiv.org/abs/2509.17337)
*Ala Jararweh,Michael Adams,Avinash Sahu,Abdullah Mueen,Afsah Anwar*

Main category: cs.AI

TL;DR: LLaVul是一个多模态大语言模型，专门用于通过问答方式对代码进行细粒度安全漏洞分析，在漏洞检测和问答任务上优于现有最先进的通用和代码LLMs。


<details>
  <summary>Details</summary>
Motivation: 当前软件系统日益复杂，对源代码漏洞分析工具需求增长。现有方法多将漏洞分析简化为分类任务，忽略了现实场景的细微差别和上下文依赖性。虽然当前代码LLMs在代码理解方面表现出色，但往往缺乏对安全特定推理的关注。

Method: 提出LLaVul多模态LLM，训练模型将配对的代码和自然语言查询整合到统一空间中，增强对代码漏洞的推理和上下文相关洞察。构建了包含真实世界漏洞的安全焦点问答数据集进行评估。

Result: LLaVul在问答和检测任务上优于最先进的通用和代码LLMs。通过定性分析进一步解释了决策过程，突出了模型的能力和局限性。

Conclusion: 通过整合代码和问答，LLaVul实现了更可解释和以安全为中心的代码理解。

Abstract: Increasing complexity in software systems places a growing demand on
reasoning tools that unlock vulnerabilities manifest in source code. Many
current approaches focus on vulnerability analysis as a classifying task,
oversimplifying the nuanced and context-dependent real-world scenarios. Even
though current code large language models (LLMs) excel in code understanding,
they often pay little attention to security-specific reasoning. We propose
LLaVul, a multimodal LLM tailored to provide fine-grained reasoning about code
through question-answering (QA). Our model is trained to integrate paired code
and natural queries into a unified space, enhancing reasoning and
context-dependent insights about code vulnerability. To evaluate our model
performance, we construct a curated dataset of real-world vulnerabilities
paired with security-focused questions and answers. Our model outperforms
state-of-the-art general-purpose and code LLMs in the QA and detection tasks.
We further explain decision-making by conducting qualitative analysis to
highlight capabilities and limitations. By integrating code and QA, LLaVul
enables more interpretable and security-focused code understanding.

</details>


### [171] [Program Synthesis via Test-Time Transduction](https://arxiv.org/abs/2509.17393)
*Kang-il Lee,Jahyun Koo,Seunghyun Yoon,Minbeom Kim,Hyukhun Koh,Dongryeol Lee,Kyomin Jung*

Main category: cs.AI

TL;DR: 本文提出了一种新的程序合成方法——转导式程序合成，通过在合成过程中显式利用测试输入来提高鲁棒性，解决了传统方法在训练样本有限且测试输入包含边缘情况时的泛化问题。


<details>
  <summary>Details</summary>
Motivation: 传统程序合成方法（基于自然语言描述或输入输出示例）通常难以在训练样本有限且测试输入涉及各种边缘情况的真实世界场景中保持鲁棒性。

Method: 提出一个新颖框架，将合成视为在由程序输出定义的有限假设类上进行主动学习。使用LLM预测选定测试输入的输出，并通过贪婪最大化算法选择输入以最小化LLM查询次数，从而消除不一致的假设。

Result: 在四个基准测试（Playgol、MBPP+、1D-ARC和MiniGrid上的程序化世界建模）上评估，该方法在准确性和效率方面显著提升了程序合成性能。

Conclusion: 转导式程序合成通过主动利用测试输入有效提高了程序合成的鲁棒性，在多个基准测试中表现出优越性能。

Abstract: We introduce transductive program synthesis, a new formulation of the program
synthesis task that explicitly leverages test inputs during synthesis. While
prior approaches to program synthesis--whether based on natural language
descriptions or input-output examples--typically aim to generalize from
training examples, they often struggle with robustness, especially in
real-world settings where training examples are limited and test inputs involve
various edge cases. To address this, we propose a novel framework that improves
robustness by treating synthesis as an active learning over a finite hypothesis
class defined by programs' outputs. We use an LLM to predict outputs for
selected test inputs and eliminate inconsistent hypotheses, where the inputs
are chosen via a greedy maximin algorithm to minimize the number of LLM queries
required. We evaluate our approach on four benchmarks: Playgol, MBPP+, 1D-ARC,
and programmatic world modeling on MiniGrid. We demonstrate that our method
significantly improves program synthesis in both accuracy and efficiency. We
release our code at https://github.com/klee972/SYNTRA.

</details>


### [172] [Reasoning Core: A Scalable RL Environment for LLM Symbolic Reasoning](https://arxiv.org/abs/2509.18083)
*Valentin Lacombe,Valentin Quesnel,Damien Sileo*

Main category: cs.AI

TL;DR: Reasoning Core是一个新的可扩展强化学习环境，专注于通过可验证奖励来提升大语言模型的符号推理能力，涵盖多种形式化领域的问题生成和验证。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要关注游戏或孤立谜题，缺乏对核心符号推理能力的系统性评估。需要一种能够生成多样化、可验证推理问题的环境来推动LLM推理能力的发展。

Method: 基于高通用性问题分布、外部工具验证和连续难度控制的设计原则，过程化生成PDDL规划、一阶逻辑、上下文无关文法解析、因果推理和系统方程求解等领域的问题。

Result: 初始零样本评估显示前沿LLMs在Reasoning Core任务上表现困难，证实了该环境的挑战性。

Conclusion: Reasoning Core作为一个具有无限训练实例供应的环境，有望成为提升未来模型推理能力的重要资源。

Abstract: We introduce Reasoning Core, a new scalable environment for Reinforcement
Learning with Verifiable Rewards (RLVR), designed to advance foundational
symbolic reasoning in Large Language Models (LLMs). Unlike existing benchmarks
that focus on games or isolated puzzles, Reasoning Core procedurally generates
problems across core formal domains, including PDDL planning, first-order
logic, context-free grammar parsing, causal reasoning, and system equation
solving. The environment is built on key design principles of high-generality
problem distributions, verification via external tools, and continuous
difficulty control, which together provide a virtually infinite supply of novel
training instances. Initial zero-shot evaluations with frontier LLMs confirm
the difficulty of Reasoning Core's tasks, positioning it as a promising
resource to improve the reasoning capabilities of future models.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [173] [Predicting First Year Dropout from Pre Enrolment Motivation Statements Using Text Mining](https://arxiv.org/abs/2509.16224)
*K. F. B. Soppe,A. Bagheri,S. Nadi,I. G. Klugkist,T. Wubbels,L. D. N. V. Wijngaards-De Meij*

Main category: cs.CY

TL;DR: 使用文本挖掘技术分析学生动机陈述来预测大学辍学率，结合传统学生特征数据，发现文本分析单独预测辍学率与传统特征方法效果相当。


<details>
  <summary>Details</summary>
Motivation: 防止学生辍学是高等教育的主要挑战，高中GPA虽然是强预测因子，但仍有大量辍学方差无法解释。本研究旨在通过挖掘学生动机陈述中的信息来增强预测能力。

Method: 收集7,060名荷兰大学学生的动机陈述，使用支持向量机训练模型，结合TF-IDF、主题建模、LIWC词典等文本分析技术与传统学生特征数据。

Result: 虽然文本与学生特征的组合没有改善辍学预测，但单独的文本分析预测辍学率与传统学生特征集效果相当。

Conclusion: 文本分析可以作为预测学生辍学的有效工具，为未来研究提供了新的方向。

Abstract: Preventing student dropout is a major challenge in higher education and it is
difficult to predict prior to enrolment which students are likely to drop out
and which students are likely to succeed. High School GPA is a strong predictor
of dropout, but much variance in dropout remains to be explained. This study
focused on predicting university dropout by using text mining techniques with
the aim of exhuming information contained in motivation statements written by
students. By combining text data with classic predictors of dropout in the form
of student characteristics, we attempt to enhance the available set of
predictive student characteristics. Our dataset consisted of 7,060 motivation
statements of students enrolling in a non-selective bachelor at a Dutch
university in 2014 and 2015. Support Vector Machines were trained on 75 percent
of the data and several models were estimated on the test data. We used various
combinations of student characteristics and text, such as TFiDF, topic
modelling, LIWC dictionary. Results showed that, although the combination of
text and student characteristics did not improve the prediction of dropout,
text analysis alone predicted dropout similarly well as a set of student
characteristics. Suggestions for future research are provided.

</details>


### [174] [Patterns in the Transition From Founder-Leadership to Community Governance of Open Source](https://arxiv.org/abs/2509.16295)
*Mobina Noori,Mahasweta Chakraborti,Amy X Zhang,Seth Frey*

Main category: cs.CY

TL;DR: 分析637个GitHub仓库，追踪开源项目从创始人主导到社区治理的转变过程，通过解析GOVERNANCE.md文件来研究社区治理的发展轨迹。


<details>
  <summary>Details</summary>
Motivation: 开源数字公共基础设施需要社区管理来确保问责制、可持续性和稳健性，但目前成功的社区治理决定因素尚不明确。

Method: 使用语义解析管道从版本控制的项目章程GOVERNANCE.md中提取制度角色、行动和义务线索，将元素聚类为更广泛的角色和行动类型。

Result: 发现角色和行动数量增长，监管变得更加平衡，反映了治理范围和差异化随时间的增加。社区通过分层和细化职责来发展，而非改变基调。

Conclusion: 随着向社区管理的过渡成熟，项目越来越多地规范生态系统层面的关系，并为项目监督角色增加定义。这项工作为跟踪社区治理制度的发展提供了可扩展的管道。

Abstract: Open digital public infrastructure needs community management to ensure
accountability, sustainability, and robustness. Yet open-source projects often
rely on centralized decision-making, and the determinants of successful
community management remain unclear. We analyze 637 GitHub repositories to
trace transitions from founder-led to shared governance. Specifically, we
document trajectories to community governance by extracting institutional
roles, actions, and deontic cues from version-controlled project constitutions
GOVERNANCE.md. With a semantic parsing pipeline, we cluster elements into
broader role and action types. We find roles and actions grow, and regulation
becomes more balanced, reflecting increases in governance scope and
differentiation over time. Rather than shifting tone, communities grow by
layering and refining responsibilities. As transitions to community management
mature, projects increasingly regulate ecosystem-level relationships and add
definition to project oversight roles. Overall, this work offers a scalable
pipeline for tracking the growth and development of community governance
regimes from open-source software's familiar default of founder-ownership.

</details>


### [175] [How Large Language Models are Designed to Hallucinate](https://arxiv.org/abs/2509.16297)
*Richard Ackermann,Simeon Emanuilov*

Main category: cs.CY

TL;DR: 该论文提出幻觉是Transformer架构的结构性结果，而非数据或优化问题。作者区分了本体论幻觉和残余推理幻觉，并基于海德格尔哲学提出了预测性分类法和设计方向。


<details>
  <summary>Details</summary>
Motivation: 现有研究将LLM幻觉归因于数据缺口、上下文限制或优化错误，但作者认为这些解释不足，需要从Transformer架构本身的结构特性来理解幻觉现象。

Method: 通过案例研究（基于海德格尔范畴）和实验（在12个LLM上测试扩展提示下的"自我保存"模拟），分析幻觉模式。

Result: 发现幻觉是Transformer模型的固有特性，作为连贯性引擎，它们必须产生流畅的延续，但缺乏人类理解的时间性、情绪性和关怀等存在基础。

Conclusion: 幻觉不是偶然缺陷，而是基于Transformer模型的根本限制，现有的支架方法只能掩盖但无法解决这一问题，需要开发能够"约束真理"的新架构。

Abstract: Large language models (LLMs) achieve remarkable fluency across linguistic and
reasoning tasks but remain systematically prone to hallucination. Prevailing
accounts attribute hallucinations to data gaps, limited context, or
optimization errors. We argue instead that hallucination is a structural
outcome of the transformer architecture. As coherence engines, transformers are
compelled to produce fluent continuations, with self-attention simulating the
relational structure of meaning but lacking the existential grounding of
temporality, mood, and care that stabilizes human understanding. On this basis,
we distinguish ontological hallucination, arising when continuations require
disclosure of beings in world, and residual reasoning hallucination, where
models mimic inference by recycling traces of human reasoning in text. We
illustrate these patterns through case studies aligned with Heideggerian
categories and an experiment across twelve LLMs showing how simulated
"self-preservation" emerges under extended prompts. Our contribution is
threefold: (1) a comparative account showing why existing explanations are
insufficient; (2) a predictive taxonomy of hallucination linked to existential
structures with proposed benchmarks; and (3) design directions toward
"truth-constrained" architectures capable of withholding or deferring when
disclosure is absent. We conclude that hallucination is not an incidental
defect but a defining limit of transformer-based models, an outcome scaffolding
can mask but never resolve.

</details>


### [176] [Longitudinal and Multimodal Recording System to Capture Real-World Patient-Clinician Conversations for AI and Encounter Research: Protocol](https://arxiv.org/abs/2509.16378)
*Misk Al Zahidy,Kerly Guevara Maldonado,Luis Vilatuna Andrango,Ana Cristina Proano,Ana Gabriela Claros,Maria Lizarazo Jimenez,David Toro-Tobon,Oscar J. Ponce-Ponce,Juan P. Brito*

Main category: cs.CY

TL;DR: 该研究开发了一个多模态系统来捕捉医患互动，将360度视频/音频记录与调查和电子健康记录数据相结合，旨在为AI研究创建包含临床交流复杂性的数据集。


<details>
  <summary>Details</summary>
Motivation: 现有AI模型主要基于电子健康记录训练，但缺乏医患互动的关键信息（语音、文本、视频），这可能导致AI系统忽视临床交流的重要性，延续狭隘的生物医学视角。

Method: 在梅奥诊所内分泌门诊进行单中心研究，使用360度摄像机记录医患会面，患者完成满意度调查，并提取EHR数据，评估五个可行性终点：医生同意率、患者同意率、记录成功率、调查完成率和多模态数据链接。

Result: 截至2025年8月，36名合格医生中35名（97%）和281名患者中212名（75%）同意参与，162次会面（76%）有完整记录，204次（96%）完成调查。

Conclusion: 该研究证明了捕捉医患互动多模态动态的可行性，为创建包含临床交流复杂性的纵向数据集提供了可复制的框架，为开发更全面的AI医疗模型奠定了基础。

Abstract: The promise of AI in medicine depends on learning from data that reflect what
matters to patients and clinicians. Most existing models are trained on
electronic health records (EHRs), which capture biological measures but rarely
patient-clinician interactions. These relationships, central to care, unfold
across voice, text, and video, yet remain absent from datasets. As a result, AI
systems trained solely on EHRs risk perpetuating a narrow biomedical view of
medicine and overlooking the lived exchanges that define clinical encounters.
Our objective is to design, implement, and evaluate the feasibility of a
longitudinal, multimodal system for capturing patient-clinician encounters,
linking 360 degree video/audio recordings with surveys and EHR data to create a
dataset for AI research. This single site study is in an academic outpatient
endocrinology clinic at Mayo Clinic. Adult patients with in-person visits to
participating clinicians are invited to enroll. Encounters are recorded with a
360 degree video camera. After each visit, patients complete a survey on
empathy, satisfaction, pace, and treatment burden. Demographic and clinical
data are extracted from the EHR. Feasibility is assessed using five endpoints:
clinician consent, patient consent, recording success, survey completion, and
data linkage across modalities. Recruitment began in January 2025. By August
2025, 35 of 36 eligible clinicians (97%) and 212 of 281 approached patients
(75%) had consented. Of consented encounters, 162 (76%) had complete recordings
and 204 (96%) completed the survey. This study aims to demonstrate the
feasibility of a replicable framework for capturing the multimodal dynamics of
patient-clinician encounters. By detailing workflows, endpoints, and ethical
safeguards, it provides a template for longitudinal datasets and lays the
foundation for AI models that incorporate the complexity of care.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [177] [Autiverse: Eliciting Autistic Adolescents' Daily Narratives through AI-guided Multimodal Journaling](https://arxiv.org/abs/2509.17466)
*Migyeong Yang,Kyungah Lee,Jinyoung Han,SoHyun Park,Young-Ho Kim*

Main category: cs.HC

TL;DR: Autiverse是一个AI引导的多模态日记应用，通过对话式提示和视觉支持帮助自闭症青少年构建叙事，将日常经历转化为可编辑的四格漫画。


<details>
  <summary>Details</summary>
Motivation: 传统日记的文本中心性和高执行功能要求对自闭症青少年构成障碍，需要开发更适合他们认知特点的叙事支持工具。

Method: 开发了Autiverse应用，通过可定制的AI同伴进行逐步对话引导，收集关键细节并自动生成四格漫画。进行了为期两周的部署研究，涉及10对自闭症青少年-家长组合。

Result: Autiverse帮助自闭症青少年构建连贯叙事，让家长了解更多孩子的事件和情绪细节。定制化AI同伴创造了舒适的分享空间，培养了享受感和强烈的主体感。

Conclusion: 设计技术时应兼顾自闭症青少年的优势，同时确保他们在分享经历时的自主性和安全性。

Abstract: Journaling can potentially serve as an effective method for autistic
adolescents to improve narrative skills. However, its text-centric nature and
high executive functioning demands present barriers to practice. We present
Autiverse, an AI-guided multimodal journaling app for tablets that scaffolds
storytelling through conversational prompts and visual supports. Autiverse
elicits key details through a stepwise dialogue with peer-like, customizable AI
and composes them into an editable four-panel comic strip. Through a two-week
deployment study with 10 autistic adolescent-parent dyads, we examine how
Autiverse supports autistic adolescents to organize their daily experience and
emotion. Autiverse helped them construct coherent narratives, while enabling
parents to learn additional details of their child's events and emotions. The
customized AI peer created a comfortable space for sharing, fostering enjoyment
and a strong sense of agency. We discuss the implications of designing
technologies that complement autistic adolescents' strengths while ensuring
their autonomy and safety in sharing experiences.

</details>


### [178] [LingoQ: Bridging the Gap between ESL Learning and Work through AI-Generated Work-Related Quizzes](https://arxiv.org/abs/2509.17477)
*Yeonsun Yang,Sang Won Lee,Jean Y. Song,Sangdoo Yun,Young-Ho Kim*

Main category: cs.HC

TL;DR: LingoQ是一个AI驱动的系统，通过从工作相关的LLM查询生成个性化英语测验，帮助非母语英语学习者在工作环境中练习英语。


<details>
  <summary>Details</summary>
Motivation: 非母语英语学习者在工作中使用英语时难以持续学习，现有学习材料与工作环境脱节，而他们依赖的LLM助手虽然解决即时需求，但无法直接提升英语技能。

Method: 开发LingoQ系统，利用AI从用户的LLM工作查询中生成个性化英语测验，用户可通过智能手机进行复习和练习。进行了为期三周、28名ESL工作者参与的部署研究。

Result: 参与者重视反映自身工作背景的相关测验，在研究期间持续使用应用。这种积极互动提高了自我效能感，初学者取得了学习进步，中级学习者也可能受益。

Conclusion: 利用用户对LLM的依赖，将学习情境化到用户工作环境中，为改进学习提供了机会。

Abstract: Non-native English speakers performing English-related tasks at work struggle
to sustain ESL learning, despite their motivation. Often, study materials are
disconnected from their work context. Although workers rely on LLM assistants
to address their immediate needs, these interactions may not directly
contribute to their English skills. We present LingoQ, an AI-mediated system
that allows workers to practice English using quizzes generated from their LLM
queries during work. LingoQ leverages these queries using AI to generate
personalized quizzes that workers can review and practice on their smartphones.
We conducted a three-week deployment study with 28 ESL workers to evaluate
LingoQ. Participants valued the relevance of quizzes that reflect their own
context, constantly engaging with the app during the study. This active
engagement improved self-efficacy and led to learning gains for beginners and,
potentially, for intermediate learners. We discuss opportunities of leveraging
users' reliance on LLMs to situate their learning in the user context for
improved learning.

</details>


### [179] [AutiHero: Leveraging Generative AI in Social Narratives to Engage Parents in Story-Driven Behavioral Guidance for Autistic Children](https://arxiv.org/abs/2509.17608)
*Jungeun Lee,Kyungah Lee,Inseok Hwang,SoHyun Park,Young-Ho Kim*

Main category: cs.HC

TL;DR: AutiHero是一个基于生成式AI的社交叙事系统，帮助父母为自闭症儿童创建个性化故事，以指导他们的社交行为。


<details>
  <summary>Details</summary>
Motivation: 现有的社交叙事材料需要根据每个孩子的独特行为背景进行定制，这对父母来说需要大量时间和精力。

Method: 开发了AutiHero系统，使用生成式AI生成反映孩子兴趣、目标行为和日常情境的文本和视觉插图。

Result: 在为期两周的部署研究中，16对自闭症儿童-父母组合创建了218个故事，平均每天阅读4.25个故事，显示出高参与度。

Conclusion: AutiHero为引导儿童社交行为提供了有效且低负担的手段，生成式AI工具能够赋能父母促进孩子的社交学习。

Abstract: Social narratives are known to help autistic children understand and navigate
social situations through stories. To ensure effectiveness, however, the
materials need to be customized to reflect each child's unique behavioral
context, requiring considerable time and effort for parents to practice at
home. We present AutiHero, a generative AI-based social narrative system for
behavioral guidance, which supports parents to create personalized stories for
their autistic children and read them together. AutiHero generates text and
visual illustrations that reflect their children's interests, target behaviors,
and everyday contexts. In a two-week deployment study with 16 autistic
child-parent dyads, parents created 218 stories and read an average of 4.25
stories per day, demonstrating a high level of engagement. AutiHero also
provided an effective, low-demanding means to guide children's social
behaviors, encouraging positive change. We discuss the implications of
generative AI-infused tools to empower parents in guiding their children's
behaviors, fostering their social learning.

</details>


### [180] [Through the Lens of Human-Human Collaboration: A Configurable Research Platform for Exploring Human-Agent Collaboration](https://arxiv.org/abs/2509.18008)
*Bingsheng Yao,Jiaju Chen,Chaoran Chen,April Wang,Toby Jia-jun Li,Dakuo Wang*

Main category: cs.HC

TL;DR: 该论文介绍了一个用于研究人类与LLM智能体协作的开源可配置平台，通过重新实现经典CSCW实验来探索人机协作原则的适用性。


<details>
  <summary>Details</summary>
Motivation: 传统智能系统被设计为工具而非协作伙伴，缺乏协作所需的关键特性。LLM智能体的发展为人类-LLM智能体协作提供了新机会，但需要系统研究传统人机协作原则在人与LLM智能体协作中的适用性。

Method: 开发了一个模块化研究平台，支持经典CSCW实验的适配和理论驱动的交互控制。通过两个案例研究验证平台有效性：1）将经典Shape Factory任务重新实现为人与智能体协作实验；2）与HCI研究人员进行参与式认知走查。

Result: 平台成功支持了16名参与者的人-智能体协作实验，并通过5名HCI研究人员的参与式评估改进了实验设置和分析的工作流程与界面。

Conclusion: 该平台为HCI研究人员提供了系统研究人类与LLM智能体协作的有效工具，有助于探索传统协作原则在新的人机协作场景中的适用性变化。

Abstract: Intelligent systems have traditionally been designed as tools rather than
collaborators, often lacking critical characteristics that collaboration
partnerships require. Recent advances in large language model (LLM) agents open
new opportunities for human-LLM-agent collaboration by enabling natural
communication and various social and cognitive behaviors. Yet it remains
unclear whether principles of computer-mediated collaboration established in
HCI and CSCW persist, change, or fail when humans collaborate with LLM agents.
To support systematic investigations of these questions, we introduce an open
and configurable research platform for HCI researchers. The platform's modular
design allows seamless adaptation of classic CSCW experiments and manipulation
of theory-grounded interaction controls. We demonstrate the platform's
effectiveness and usability through two case studies: (1) re-implementing the
classic human-human-collaboration task Shape Factory as a between-subject
human-agent-collaboration experiment with 16 participants, and (2) a
participatory cognitive walkthrough with five HCI researchers to refine
workflows and interfaces for experiment setup and analysis.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [181] [Towards Universal Debiasing for Language Models-based Tabular Data Generation](https://arxiv.org/abs/2509.16475)
*Tianchun Li,Tianci Liu,Xingchen Wang,Rongzhe Wei,Pan Li,Lu Su,Jing Gao*

Main category: cs.LG

TL;DR: 提出一个通用的去偏框架，通过同时减少优势特征与保护特征之间的互信息来最小化群体级依赖关系，有效平衡公平性和实用性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在表格数据生成中表现出色，但表格数据中固有的历史偏见会导致模型加剧公平性问题，特别是在涉及多个优势特征和保护特征时。

Method: 利用基于LLM的表格数据生成器的自回归结构和分析采样分布，高效计算互信息，提出两种互补方法：UDF-DPO（基于直接偏好优化的策略）和UDF-MIX（无需调整LLM参数的定向去偏技术）。

Result: 大量实验证明该框架能有效平衡公平性和实用性。

Conclusion: 该框架为高风险应用中的去偏问题提供了可扩展且实用的解决方案。

Abstract: Large language models (LLMs) have achieved promising results in tabular data
generation. However, inherent historical biases in tabular datasets often cause
LLMs to exacerbate fairness issues, particularly when multiple advantaged and
protected features are involved. In this work, we introduce a universal
debiasing framework that minimizes group-level dependencies by simultaneously
reducing the mutual information between advantaged and protected attributes. By
leveraging the autoregressive structure and analytic sampling distributions of
LLM-based tabular data generators, our approach efficiently computes mutual
information, reducing the need for cumbersome numerical estimations. Building
on this foundation, we propose two complementary methods: a direct preference
optimization (DPO)-based strategy, namely UDF-DPO, that integrates seamlessly
with existing models, and a targeted debiasing technique, namely UDF-MIX, that
achieves debiasing without tuning the parameters of LLMs. Extensive experiments
demonstrate that our framework effectively balances fairness and utility,
offering a scalable and practical solution for debiasing in high-stakes
applications.

</details>


### [182] [SCAN: Self-Denoising Monte Carlo Annotation for Robust Process Reward Learning](https://arxiv.org/abs/2509.16548)
*Yuyang Ding,Xinyu Shi,Juntao Li,Xiaobo Liang,Zhaopeng Tu,Min Zhang*

Main category: cs.LG

TL;DR: 本文提出了SCAN框架，通过自去噪蒙特卡洛标注方法解决过程奖励模型训练中合成数据噪声高的问题，显著降低了标注成本并提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 过程奖励模型需要精细的步骤级评估来支持复杂推理任务，但人工标注成本高且难以扩展。蒙特卡洛估计生成的合成数据存在高噪声问题，容易导致过拟合。

Method: 提出SCAN框架，包含自去噪策略和噪声容忍学习机制。通过分析MC估计中的噪声分布，让轻量级模型进行自去噪标注，仅需6%的推理成本即可生成高质量标注数据。

Result: 在ProcessBench上F1分数从19.9提升至59.1，提升39.2分。使用紧凑合成数据集即可超越基于大规模人工标注数据集（如PRM800K）的基线模型，且随着合成数据规模扩大性能持续提升。

Conclusion: SCAN框架为过程奖励模型训练提供了可扩展、成本效益高且鲁棒的解决方案，证明了轻量级模型通过自去噪策略能够产生高质量标注，为大规模PRM训练开辟了新途径。

Abstract: Process reward models (PRMs) offer fine-grained, step-level evaluations that
facilitate deeper reasoning processes in large language models (LLMs), proving
effective in complex tasks like mathematical reasoning. However, developing
PRMs is challenging due to the high cost and limited scalability of
human-annotated data. Synthetic data from Monte Carlo (MC) estimation is a
promising alternative but suffers from a high noise ratio, which can cause
overfitting and hinder large-scale training. In this work, we conduct a
preliminary study on the noise distribution in synthetic data from MC
estimation, identifying that annotation models tend to both underestimate and
overestimate step correctness due to limitations in their annotation
capabilities. Building on these insights, we propose Self-Denoising Monte Carlo
Annotation (SCAN), an efficient data synthesis and noise-tolerant learning
framework. Our key findings indicate that: (1) Even lightweight models (e.g.,
1.5B parameters) can produce high-quality annotations through a self-denoising
strategy, enabling PRMs to achieve superior performance with only 6% the
inference cost required by vanilla MC estimation. (2) With our robust learning
strategy, PRMs can effectively learn from this weak supervision, achieving a
39.2 F1 score improvement (from 19.9 to 59.1) in ProcessBench. Despite using
only a compact synthetic dataset, our models surpass strong baselines,
including those trained on large-scale human-annotated datasets such as
PRM800K. Furthermore, performance continues to improve as we scale up the
synthetic data, highlighting the potential of SCAN for scalable,
cost-efficient, and robust PRM training.

</details>


### [183] [Geometric Mixture Classifier (GMC): A Discriminative Per-Class Mixture of Hyperplanes](https://arxiv.org/abs/2509.16769)
*Prasanth K K,Shubham Sharma*

Main category: cs.LG

TL;DR: 提出了几何混合分类器（GMC），一种判别式模型，将每个类别表示为超平面的混合，以处理多模态数据，在准确性、可解释性和效率之间取得良好平衡。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的许多类别是多模态的，单个类别在特征空间中占据不相交的区域。经典线性模型（如逻辑回归、线性SVM）使用单个全局超平面，在此类数据上表现不佳，而高容量方法（如核SVM、深度网络）虽然能拟合多模态结构，但牺牲了可解释性、需要更重的调参和更高的计算成本。

Method: GMC将每个类别表示为超平面的混合，在类别内通过温度控制的soft-OR（log-sum-exp）平滑近似最大值来组合平面得分，在类别间使用标准softmax产生概率后验。可选使用随机傅里叶特征（RFF）进行非线性映射，同时保持推理在平面和特征数量上的线性。训练方法包括几何感知的k-means初始化、基于轮廓的平面预算、alpha退火、使用感知的L2正则化、标签平滑和早停。

Result: 在合成多模态数据集（moons、circles、blobs、spirals）和表格/图像基准（iris、wine、WDBC、digits）上，GMC一致优于线性基线和k-NN，与RBF-SVM、随机森林和小型MLP竞争，并提供通过每个平面和类别责任可视化的几何内省。推理在平面和特征上线性扩展，CPU友好，每个示例的延迟为微秒级，通常比RBF-SVM和紧凑MLP更快。后处理温度缩放将ECE从约0.06降低到0.02。

Conclusion: GMC在准确性、可解释性和效率之间取得了有利的平衡：比线性模型更具表现力，比核或深度模型更轻量、更透明、更快。

Abstract: Many real world categories are multimodal, with single classes occupying
disjoint regions in feature space. Classical linear models (logistic
regression, linear SVM) use a single global hyperplane and perform poorly on
such data, while high-capacity methods (kernel SVMs, deep nets) fit multimodal
structure but at the expense of interpretability, heavier tuning, and higher
computational cost. We propose the Geometric Mixture Classifier (GMC), a
discriminative model that represents each class as a mixture of hyperplanes.
Within each class, GMC combines plane scores via a temperature-controlled
soft-OR (log-sum-exp), smoothly approximating the max; across classes, standard
softmax yields probabilistic posteriors. GMC optionally uses Random Fourier
Features (RFF) for nonlinear mappings while keeping inference linear in the
number of planes and features. Our practical training recipe: geometry-aware
k-means initialization, silhouette-based plane budgeting, alpha annealing,
usage-aware L2 regularization, label smoothing, and early stopping, makes GMC
plug-and-play. Across synthetic multimodal datasets (moons, circles, blobs,
spirals) and tabular/image benchmarks (iris, wine, WDBC, digits), GMC
consistently outperforms linear baselines and k-NN, is competitive with
RBF-SVM, Random Forests, and small MLPs, and provides geometric introspection
via per-plane and class responsibility visualizations. Inference scales
linearly in planes and features, making GMC CPU-friendly, with single-digit
microsecond latency per example, often faster than RBF-SVM and compact MLPs.
Post-hoc temperature scaling reduces ECE from about 0.06 to 0.02. GMC thus
strikes a favorable balance of accuracy, interpretability, and efficiency: it
is more expressive than linear models and lighter, more transparent, and faster
than kernel or deep models.

</details>


### [184] [Dynamic Expert Specialization: Towards Catastrophic Forgetting-Free Multi-Domain MoE Adaptation](https://arxiv.org/abs/2509.16882)
*Junzhuo Li,Bo Wang,Xiuze Zhou,Xuming Hu*

Main category: cs.LG

TL;DR: DES-MoE是一个动态专家专业化框架，用于混合专家模型的多领域适应，通过自适应路由、实时专家-领域关联映射和三阶段自适应微调来解决灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 混合专家模型具有巨大容量，但在适应多个领域时面临灾难性遗忘的挑战，现有方法要么计算成本过高，要么存在跨领域干扰，或者需要为每个领域单独训练。

Method: DES-MoE采用三个创新：(1)通过蒸馏平衡预训练知识保留和任务特定更新的自适应路由器；(2)实时专家-领域关联映射以隔离领域特定梯度；(3)逐步冻结非专门化参数的三阶段自适应微调计划。

Result: 在六个领域（数学、代码、法律等）上评估，DES-MoE在训练一个统一模型时匹配单领域ESFT性能，与完全微调相比，当领域从2个扩展到6个时，遗忘减少89%，收敛速度比传统方法快68%。

Conclusion: 动态专家隔离是多任务MoE适应的可扩展范式。

Abstract: Mixture-of-Experts (MoE) models offer immense capacity via sparsely gated
expert subnetworks, yet adapting them to multiple domains without catastrophic
forgetting remains an open challenge. Existing approaches either incur
prohibitive computation, suffer cross-domain interference, or require separate
runs per domain. We propose DES-MoE, a dynamic expert specialization framework
for multi-domain adaptation of Mixture-of-Experts models. DES-MoE addresses
catastrophic forgetting through three innovations: (1) an adaptive router
balancing pre-trained knowledge retention and task-specific updates via
distillation, (2) real-time expert-domain correlation mapping to isolate
domain-specific gradients, and (3) a three-phase adaptive fine-tuning schedule
that progressively freezes non-specialized parameters. Evaluated on six domains
(math, code, law, etc.), DES-MoE matches single-domain ESFT performance while
training one unified model, reduces forgetting by 89% compared to full
fine-tuning as domains scale from 2 to 6, and achieves 68% faster convergence
than conventional methods. Our work establishes dynamic expert isolation as a
scalable paradigm for multi-task MoE adaptation.

</details>


### [185] [DRES: Fake news detection by dynamic representation and ensemble selection](https://arxiv.org/abs/2509.16893)
*Faramarz Farhangian,Leandro A. Ensina,George D. C. Cavalcanti,Rafael M. O. Cruz*

Main category: cs.LG

TL;DR: 提出了一种基于动态表示和集成选择的假新闻检测方法DRES，通过实例难度评估和动态选择文本表示及分类器集成，显著提高了检测准确率


<details>
  <summary>Details</summary>
Motivation: 社交媒体信息快速传播使得基于文本的假新闻检测变得至关重要，因为假新闻对社会有重大影响

Method: DRES方法利用实例难度度量来评估每个新闻文章在不同文本特征表示下的分类难度，动态选择最适合的文本表示和分类器集成

Result: 大量实验表明DRES在假新闻检测任务上显著优于现有最先进方法

Conclusion: 基于实例难度的表示选择和动态集成选择能有效提升假新闻检测性能

Abstract: The rapid spread of information via social media has made text-based fake
news detection critically important due to its societal impact. This paper
presents a novel detection method called Dynamic Representation and Ensemble
Selection (DRES) for identifying fake news based solely on text. DRES leverages
instance hardness measures to estimate the classification difficulty for each
news article across multiple textual feature representations. By dynamically
selecting the textual representation and the most competent ensemble of
classifiers for each instance, DRES significantly enhances prediction accuracy.
Extensive experiments show that DRES achieves notable improvements over
state-of-the-art methods, confirming the effectiveness of representation
selection based on instance hardness and dynamic ensemble selection in boosting
performance. Codes and data are available at:
https://github.com/FFarhangian/FakeNewsDetection_DRES

</details>


### [186] [Causal Representation Learning from Multimodal Clinical Records under Non-Random Modality Missingness](https://arxiv.org/abs/2509.17228)
*Zihan Liang,Ziwen Pan,Ruoxuan Xiong*

Main category: cs.LG

TL;DR: 提出一个因果表示学习框架来处理临床记录中的多模态缺失数据问题，通过MMNAR感知的模态融合、模态重建和多任务预测来提高患者表示质量。


<details>
  <summary>Details</summary>
Motivation: 临床笔记包含丰富患者信息但经常缺失，其他模态数据也存在缺失且受临床决策影响，形成缺失非随机模式，需要专门方法处理。

Method: 包含三个组件：1) MMNAR感知的模态融合，整合结构化数据、影像和文本；2) 带对比学习的模态重建确保语义充分性；3) 带校正器的多任务结果预测模型纠正残留偏差。

Result: 在MIMIC-IV和eICU数据集上评估，相比最强基线在再入院预测上AUC提升13.8%，ICU入院预测提升13.1%。

Conclusion: 该框架能有效处理多模态临床数据中的缺失问题，显著提升预测性能，为临床决策提供更可靠的表示学习方案。

Abstract: Clinical notes contain rich patient information, such as diagnoses or
medications, making them valuable for patient representation learning. Recent
advances in large language models have further improved the ability to extract
meaningful representations from clinical texts. However, clinical notes are
often missing. For example, in our analysis of the MIMIC-IV dataset, 24.5% of
patients have no available discharge summaries. In such cases, representations
can be learned from other modalities such as structured data, chest X-rays, or
radiology reports. Yet the availability of these modalities is influenced by
clinical decision-making and varies across patients, resulting in modality
missing-not-at-random (MMNAR) patterns. We propose a causal representation
learning framework that leverages observed data and informative missingness in
multimodal clinical records. It consists of: (1) an MMNAR-aware modality fusion
component that integrates structured data, imaging, and text while conditioning
on missingness patterns to capture patient health and clinician-driven
assignment; (2) a modality reconstruction component with contrastive learning
to ensure semantic sufficiency in representation learning; and (3) a multitask
outcome prediction model with a rectifier that corrects for residual bias from
specific modality observation patterns. Comprehensive evaluations across
MIMIC-IV and eICU show consistent gains over the strongest baselines, achieving
up to 13.8% AUC improvement for hospital readmission and 13.1% for ICU
admission.

</details>


### [187] [Generalizable End-to-End Tool-Use RL with Synthetic CodeGym](https://arxiv.org/abs/2509.17325)
*Weihua Du,Hailei Gong,Zhan Ling,Kang Liu,Lingfeng Shen,Xuesong Yao,Yufei Xu,Dingyuan Shi,Yiming Yang,Jiecao Chen*

Main category: cs.LG

TL;DR: CodeGym是一个可扩展的框架，通过将静态编程问题转化为交互式环境，为LLM智能体提供多样化的工具使用训练环境，提升其泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体的训练方法（如监督微调或强化学习）在开发环境之外泛化能力差，对新工具和未见工作流程表现脆弱。代码执行反映了现实工作流程的结构，因此基于编程问题构建智能体训练环境具有天然优势。

Method: CodeGym将静态编程问题重写为交互式环境，通过提取原子函数或逻辑为可调用工具，创建可验证的多轮工具使用任务。使用强化学习在CodeGym环境中训练不同规模和思维链配置的模型。

Result: 在CodeGym中训练的模型表现出持续的外分布泛化能力，例如Qwen2.5-32B-Instruct在OOD基准测试τ-Bench上实现了8.7个百分点的绝对准确率提升。

Conclusion: CodeGym是朝着可扩展通用强化学习环境迈出的一步，这些环境与现实世界的智能体工作流程保持一致。

Abstract: Tool-augmented large language models (LLMs), hereafter LLM agents, leverage
external tools to solve diverse tasks and interface with the real world.
However, current training practices largely rely on supervised fine-tuning
(SFT) over static trajectories or reinforcement learning (RL) on narrow tasks,
and generalize poorly beyond development settings, leading to brittleness with
new tools and unseen workflows. Because code execution reflects many structures
of real-world workflows, coding problems provide a natural basis for building
agent training environments. Motivated by this, we introduce CodeGym, a
scalable framework that synthesizes diverse, verifiable, and controllable
multi-turn tool-use environments for agent RL, enabling LLM agents to explore
and master various workflows actively. CodeGym rewrites static coding problems
into interactive environments by extracting atomic functions or logic into
callable tools, yielding verifiable tasks that span various tool-execution
workflows. Models of varying sizes and chain-of-thought configurations, trained
in CodeGym, exhibit consistent out-of-distribution generalizability; for
example, Qwen2.5-32B-Instruct achieves an absolute accuracy gain of 8.7 points
on the OOD benchmark $\tau$-Bench. These results highlight CodeGym as a step
toward scalable general-purpose RL environments that align with real-world
agent workflows.

</details>


### [188] [ConfClip: Confidence-Weighted and Clipped Reward for Reinforcement Learning in LLMs](https://arxiv.org/abs/2509.17730)
*Bonan Zhang,Zhongqi Chen,Bowen Song,Qinya Li,Fan Wu,Guihai Chen*

Main category: cs.LG

TL;DR: 本文提出了一种结合可验证结果和模型置信度估计的强化学习技术，旨在解决RLVR框架中二元反馈稀疏和梯度消失的问题，从而提升RL性能并减少推理时的token消耗。


<details>
  <summary>Details</summary>
Motivation: 现有的基于可验证奖励的强化学习（RLVR）框架存在两个关键限制：一是二元反馈过于稀疏，无法捕捉推理过程的质量；二是粗粒度的奖励可能导致梯度消失。受人类学习启发，作者希望通过结合可验证结果和模型置信度估计来丰富奖励信号。

Method: 引入一种强化学习技术，将可验证结果（如正确性或可执行性）与模型自身的置信度估计相结合。这种联合设计提供了更细粒度的反馈，并隐式监督推理过程。

Result: 实验结果表明，所提出的方法在多个数据集上提升了RL性能，减少了推理时的token消耗，且额外训练成本可忽略不计。此外，该方法可作为插件模块增强其他最先进的RL方法。

Conclusion: 通过结合可验证结果和置信度估计，该方法有效解决了RLVR框架的局限性，提升了强化学习的效果和效率，并具有良好的通用性。

Abstract: Reinforcement learning (RL) has become a standard paradigm for refining large
language models (LLMs) beyond pre-training and instruction tuning. A prominent
line of work is RL with verifiable rewards (RLVR), which leverages
automatically verifiable outcomes (e.g., correctness or executability) to
generate reward signals. While efficient, this framework faces two key
limitations: First, its binary feedback is too sparse to capture the quality of
the reasoning process. Second, its coarse-grained rewards potentially lead to
vanishing gradients. Inspired by observations from human learning, we introduce
a RL technique that integrates verifiable outcomes with the model's own
confidence estimates. This joint design enriches the reward signal, providing
finer-grained feedback and implicitly supervising the reasoning process.
Experimental results demonstrate that our proposed method enhances RL
performance across multiple datasets and reduces token consumption during
inference, while incurring negligible additional training cost. Moreover, it
can be used as a plug-in module to enhance other state-of-the-art RL methods.

</details>


### [189] [Spiffy: Multiplying Diffusion LLM Acceleration via Lossless Speculative Decoding](https://arxiv.org/abs/2509.18085)
*Sudhanshu Agrawal,Risheek Garrepalli,Raghavv Goel,Mingu Lee,Christopher Lott,Fatih Porikli*

Main category: cs.LG

TL;DR: Spiffy是一种用于加速扩散语言模型推理的推测解码算法，通过自动推测方式生成候选状态并使用定向草图图结构，在保持输出分布的同时实现2.8-3.1倍的加速


<details>
  <summary>Details</summary>
Motivation: 当前开源扩散语言模型生成速率较低，通常每个去噪时间步只解码单个令牌以最大化输出质量，需要更高效的推理方法

Method: 提出Spiffy推测解码算法，利用dLLM自身分布进行自动推测生成候选状态，设计定向草图图结构利用dLLM的双向块状生成特性，并引入离线校准算法优化草图图配置

Result: Spiffy实现2.8-3.1倍的推理加速，且与KV缓存和多令牌解掩码等并行解码算法结合时，总加速比可达7.9倍

Conclusion: Spiffy是首个为扩散语言模型设计的推测解码算法，能显著提升推理速度且与现有加速技术互补，为dLLM的高效部署提供了有效解决方案

Abstract: Diffusion LLMs (dLLMs) have recently emerged as a powerful alternative to
autoregressive LLMs (AR-LLMs) with the potential to operate at significantly
higher token generation rates. However, currently available open-source dLLMs
often generate at much lower rates, typically decoding only a single token at
every denoising timestep in order to maximize output quality. We present
Spiffy, a speculative decoding algorithm that accelerates dLLM inference by
$\mathbf{2.8{-}3.1\times}$ while provably preserving the model's output
distribution. This work addresses the unique challenges involved in applying
ideas from speculative decoding of AR-LLMs to the dLLM setting. Spiffy proposes
draft states by leveraging the dLLM's distribution itself in an
auto-speculative manner. This approach is efficient and effective, and
eliminates the overheads of training and running an independent draft model. To
structure the candidate draft states, we propose a novel directed draft graph
which is uniquely designed to take advantage of the bidirectional, block-wise
nature of dLLM generation and can be verified in parallel by the dLLM. To
further optimize the structure of these draft graphs, we introduce an
efficient, offline calibration algorithm that procedurally determines
high-quality graph configurations. These optimized draft graphs, enabling
increased acceptance rates, lead to a significant boost in the overall speedup
achieved by the system. Crucially, Spiffy is also complementary to other recent
innovations in improving dLLM generation speeds such as KV-caching and
multi-token unmasking. We demonstrate that when combined with such parallel
decoding algorithms, Spiffy is able to effectively multiply the benefits of
these methods leading to total speedups of up to $\mathbf{7.9\times}$.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [190] [Idiosyncratic Versus Normative Modeling of Atypical Speech Recognition: Dysarthric Case Studies](https://arxiv.org/abs/2509.16718)
*Vishnu Raja,Adithya V Ganesan,Anand Syamkumar,Ritwik Banerjee,H Andrew Schwartz*

Main category: cs.SD

TL;DR: 该论文研究了针对构音障碍等非典型语音的自动语音识别(ASR)模型优化策略，提出了结合通用模式和个性化模式的方法，在减少数据需求的同时提高了识别准确率。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的ASR模型(如Whisper)在非典型语音(如构音障碍患者语音)上表现不佳。传统方法主要研究完全个性化的模型，但需要探索既能泛化又能处理个体差异的建模策略。

Method: 比较了四种策略：(a)基于典型语音的规范模型；(b)完全个性化的特异模型；(c)基于其他构音障碍说话者的构音障碍规范模型；(d)结合策略的构音障碍-特异模型，先建模规范模式再适应个体语音。重点研究了仅调整语音编码器而非语言模型解码器的效果。

Result: 构音障碍-特异模型表现优于纯特异模型，且所需个性化数据减少一半以上(128训练样本达到36.43 WER vs 256样本的36.99 WER)。仅调整语音编码器可将词错误率从71%降至32%。

Conclusion: 研究表明结合规范(跨说话者)和特异(说话者特定)模式对于改善非典型语音群体的ASR性能具有重要价值，这种混合策略在减少数据需求的同时提高了识别准确性。

Abstract: State-of-the-art automatic speech recognition (ASR) models like Whisper,
perform poorly on atypical speech, such as that produced by individuals with
dysarthria. Past works for atypical speech have mostly investigated fully
personalized (or idiosyncratic) models, but modeling strategies that can both
generalize and handle idiosyncracy could be more effective for capturing
atypical speech. To investigate this, we compare four strategies: (a)
$\textit{normative}$ models trained on typical speech (no personalization), (b)
$\textit{idiosyncratic}$ models completely personalized to individuals, (c)
$\textit{dysarthric-normative}$ models trained on other dysarthric speakers,
and (d) $\textit{dysarthric-idiosyncratic}$ models which combine strategies by
first modeling normative patterns before adapting to individual speech. In this
case study, we find the dysarthric-idiosyncratic model performs better than
idiosyncratic approach while requiring less than half as much personalized data
(36.43 WER with 128 train size vs 36.99 with 256). Further, we found that
tuning the speech encoder alone (as opposed to the LM decoder) yielded the best
results reducing word error rate from 71% to 32% on average. Our findings
highlight the value of leveraging both normative (cross-speaker) and
idiosyncratic (speaker-specific) patterns to improve ASR for underrepresented
speech populations.

</details>


### [191] [SVeritas: Benchmark for Robust Speaker Verification under Diverse Conditions](https://arxiv.org/abs/2509.17091)
*Massa Baali,Sarthak Bisht,Francisco Teixeira,Kateryna Shapovalenko,Rita Singh,Bhiksha Raj*

Main category: cs.SD

TL;DR: SVeritas是一个全面的说话人验证基准测试套件，评估SV系统在各种现实和恶意条件下的性能，包括录音时长、噪声、混响、信道不匹配、音频带宽、编解码器、说话人年龄、欺骗和对抗攻击等压力因素。


<details>
  <summary>Details</summary>
Motivation: 现有的说话人验证基准测试只评估部分条件，缺乏对许多现实世界挑战的全面基准测试，导致SV模型在实际应用中的鲁棒性评估不足。

Method: 开发SVeritas基准测试套件，系统性地评估SV系统在多种压力条件下的性能，包括自然和恶意创建的条件，如信号退化、注册和测试数据不匹配等。

Result: 评估多个最先进的SV模型发现，虽然某些架构在常见失真下保持稳定，但在跨语言试验、年龄不匹配和编解码器引起的压缩等场景中性能显著下降。同时发现不同人口统计子组（年龄、性别、语言背景）在鲁棒性上存在差异。

Conclusion: SVeritas通过标准化在现实和合成压力条件下的评估，能够精确诊断模型弱点，为推进公平可靠的说话人验证系统奠定基础。

Abstract: Speaker verification (SV) models are increasingly integrated into security,
personalization, and access control systems, yet their robustness to many
real-world challenges remains inadequately benchmarked. These include a variety
of natural and maliciously created conditions causing signal degradations or
mismatches between enrollment and test data, impacting performance. Existing
benchmarks evaluate only subsets of these conditions, missing others entirely.
We introduce SVeritas, a comprehensive Speaker Verification tasks benchmark
suite, assessing SV systems under stressors like recording duration,
spontaneity, content, noise, microphone distance, reverberation, channel
mismatches, audio bandwidth, codecs, speaker age, and susceptibility to
spoofing and adversarial attacks. While several benchmarks do exist that each
cover some of these issues, SVeritas is the first comprehensive evaluation that
not only includes all of these, but also several other entirely new, but
nonetheless important, real-life conditions that have not previously been
benchmarked. We use SVeritas to evaluate several state-of-the-art SV models and
observe that while some architectures maintain stability under common
distortions, they suffer substantial performance degradation in scenarios
involving cross-language trials, age mismatches, and codec-induced compression.
Extending our analysis across demographic subgroups, we further identify
disparities in robustness across age groups, gender, and linguistic
backgrounds. By standardizing evaluation under realistic and synthetic stress
conditions, SVeritas enables precise diagnosis of model weaknesses and
establishes a foundation for advancing equitable and reliable speaker
verification systems.

</details>
