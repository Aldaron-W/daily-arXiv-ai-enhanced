<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 25]
- [cs.MA](#cs.MA) [Total: 1]
- [cs.CV](#cs.CV) [Total: 4]
- [cs.RO](#cs.RO) [Total: 1]
- [cs.CR](#cs.CR) [Total: 1]
- [cs.AI](#cs.AI) [Total: 8]
- [cs.LG](#cs.LG) [Total: 1]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.IR](#cs.IR) [Total: 3]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [What Really Counts? Examining Step and Token Level Attribution in Multilingual CoT Reasoning](https://arxiv.org/abs/2511.15886)
*Jeremias Ferrao,Ezgi Basar,Khondoker Ittehadul Islam,Mahrokh Hassani*

Main category: cs.CL

TL;DR: 本研究调查多语言LLM中思维链推理的归因模式，发现归因分数过度强调最终推理步骤、结构化CoT提示主要对高资源拉丁语系语言有效、受控扰动会降低模型准确性和归因一致性。


<details>
  <summary>Details</summary>
Motivation: 评估多语言LLM中思维链推理的忠实性和可解释性，特别是在不同语言环境下的表现。

Method: 使用ContextCite进行步骤级归因和Inseq进行令牌级归因，在Qwen2.5 1.5B-Instruct模型上应用MGSM基准测试，并通过否定和干扰句进行受控扰动。

Result: 归因分数过度强调最终推理步骤（尤其在错误生成中）；结构化CoT提示显著提高高资源拉丁语系语言的准确性；受控扰动会降低模型准确性和归因一致性。

Conclusion: 思维链提示在多语言鲁棒性和解释透明度方面存在局限性。

Abstract: This study investigates the attribution patterns underlying Chain-of-Thought (CoT) reasoning in multilingual LLMs. While prior works demonstrate the role of CoT prompting in improving task performance, there are concerns regarding the faithfulness and interpretability of the generated reasoning chains. To assess these properties across languages, we applied two complementary attribution methods--ContextCite for step-level attribution and Inseq for token-level attribution--to the Qwen2.5 1.5B-Instruct model using the MGSM benchmark. Our experimental results highlight key findings such as: (1) attribution scores excessively emphasize the final reasoning step, particularly in incorrect generations; (2) structured CoT prompting significantly improves accuracy primarily for high-resource Latin-script languages; and (3) controlled perturbations via negation and distractor sentences reduce model accuracy and attribution coherence. These findings highlight the limitations of CoT prompting, particularly in terms of multilingual robustness and interpretive transparency.

</details>


### [2] [Mind the Motions: Benchmarking Theory-of-Mind in Everyday Body Language](https://arxiv.org/abs/2511.15887)
*Seungbeen Lee,Jinhong Jeong,Donghyun Kim,Yejin Son,Youngjae Yu*

Main category: cs.CL

TL;DR: Motion2Mind是一个评估机器理解非语言线索能力的框架，包含精心策划的视频数据集，涵盖222种非语言线索和397种心理状态，揭示了当前AI系统在非语言沟通解释方面的显著不足。


<details>
  <summary>Details</summary>
Motivation: 现有心理理论基准主要关注错误信念任务和非对称信息推理，忽视了信念之外的其他心理状态和丰富的非语言沟通，需要开发能够评估机器理解非语言线索心理理论能力的框架。

Method: 利用专家策划的身体语言参考作为知识库，构建Motion2Mind数据集，包含细粒度非语言线索标注和手动验证的心理解释，涵盖222种非语言线索和397种心理状态。

Result: 当前AI系统在非语言线索解释方面表现显著不足，在检测任务中存在巨大性能差距，在解释任务中表现出过度解释的模式。

Conclusion: Motion2Mind为评估机器心理理论能力提供了新框架，揭示了AI在理解非语言沟通方面的局限性，为未来研究指明了方向。

Abstract: Our ability to interpret others' mental states through nonverbal cues (NVCs) is fundamental to our survival and social cohesion. While existing Theory of Mind (ToM) benchmarks have primarily focused on false-belief tasks and reasoning with asymmetric information, they overlook other mental states beyond belief and the rich tapestry of human nonverbal communication. We present Motion2Mind, a framework for evaluating the ToM capabilities of machines in interpreting NVCs. Leveraging an expert-curated body-language reference as a proxy knowledge base, we build Motion2Mind, a carefully curated video dataset with fine-grained nonverbal cue annotations paired with manually verified psychological interpretations. It encompasses 222 types of nonverbal cues and 397 mind states. Our evaluation reveals that current AI systems struggle significantly with NVC interpretation, exhibiting not only a substantial performance gap in Detection, as well as patterns of over-interpretation in Explanation compared to human annotators.

</details>


### [3] [TOD-ProcBench: Benchmarking Complex Instruction-Following in Task-Oriented Dialogues](https://arxiv.org/abs/2511.15976)
*Sarik Ghazarian,Abhinav Gullapalli,Swair Shah,Anurag Beniwal,Nanyun Peng,Narayanan Sadagopan,Zhou Yu*

Main category: cs.CL

TL;DR: 提出了TOD-ProcBench基准，用于评估LLMs在多轮任务导向对话中遵循复杂流程指令的能力，包含三个任务：相关语句检索与动作预测、指令违规响应识别、条件生成指令遵循响应。


<details>
  <summary>Details</summary>
Motivation: 现有TOD基准过度简化复杂指令为简单模式，无法真实反映现实世界中代理需要严格遵循包含复杂约束的自然语言指令的需求。

Method: 基于高质量ABCD数据集构建包含复杂流程指令和对应对话的基准，将细粒度约束和动作流程表述为多级条件-动作指令语句，设计三个任务全面评估LLMs能力。

Result: 构建了包含复杂流程指令的基准数据集，并设计了系统性的评估框架来测试LLMs在多轮TOD中的指令遵循能力。

Conclusion: TOD-ProcBench填补了现有基准的不足，为系统评估LLMs在复杂指令遵循能力方面提供了重要工具，支持多语言和不同指令格式的研究。

Abstract: In real-world task-oriented dialogue (TOD) settings, agents are required to strictly adhere to complex instructions while conducting multi-turn conversations with customers. These instructions are typically presented in natural language format and include general guidelines and step-by-step procedures with complex constraints. Existing TOD benchmarks often oversimplify the complex nature of these instructions by reducing them to simple schemas composed of intents, slots, and API call configurations. To address this gap and systematically benchmark LLMs' instruction-following capabilities, we propose TOD-ProcBench, a challenging benchmark featuring complex process instructions with intricate, fine-grained constraints that evaluates various LLMs' abilities to understand and follow instructions in multi-turn TODs. Our benchmark dataset comprises instruction documents derived from the high-quality ABCD dataset with corresponding conversations under human quality control. We formulate fine-grained constraints and action procedures as multi-level condition-action instruction statements. We design three tasks to comprehensively benchmark LLMs' complex instruction-following capabilities in multi-turn TODs. Task 1 evaluates how LLMs retrieve the most relevant statement from a complex instruction and predict the corresponding next action. In Task 2, we synthesize instruction-violating responses by injecting inconsistencies and manipulating the original instructions, and then we analyze how effectively LLMs can identify instruction-violating responses. Task 3 investigates LLMs' abilities in conditional generation of instruction-following responses based on the original complex instructions. Additionally, we conduct studies on the impact of multilingual settings and different instruction text formats on compliance performance. We release our benchmark under the Llama 3.3 Community License Agreement.

</details>


### [4] [Liars' Bench: Evaluating Lie Detectors for Language Models](https://arxiv.org/abs/2511.16035)
*Kieron Kretschmar,Walter Laurito,Sharan Maiya,Samuel Marks*

Main category: cs.CL

TL;DR: LIARS' BENCH是一个包含72,863个谎言和诚实回答的测试平台，用于评估大语言模型的谎言检测技术，发现现有技术在检测某些类型的谎言时存在系统性失败。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型谎言检测技术通常在狭窄环境中验证，无法捕捉模型可能生成的各种谎言类型，需要更全面的测试平台来评估这些技术。

Method: 构建LIARS' BENCH测试平台，包含7个数据集的72,863个例子，涵盖不同谎言类型，评估三种黑白盒谎言检测技术。

Result: 现有技术在某些类型的谎言检测上系统性失败，特别是在仅从文本转录无法确定模型是否说谎的情况下。

Conclusion: LIARS' BENCH揭示了现有技术的局限性，为谎言检测技术的进步提供了实用的测试平台。

Abstract: Prior work has introduced techniques for detecting when large language models (LLMs) lie, that is, generating statements they believe are false. However, these techniques are typically validated in narrow settings that do not capture the diverse lies LLMs can generate. We introduce LIARS' BENCH, a testbed consisting of 72,863 examples of lies and honest responses generated by four open-weight models across seven datasets. Our settings capture qualitatively different types of lies and vary along two dimensions: the model's reason for lying and the object of belief targeted by the lie. Evaluating three black- and white-box lie detection techniques on LIARS' BENCH, we find that existing techniques systematically fail to identify certain types of lies, especially in settings where it's not possible to determine whether the model lied from the transcript alone. Overall, LIARS' BENCH reveals limitations in prior techniques and provides a practical testbed for guiding progress in lie detection.

</details>


### [5] [Learning Tractable Distributions Of Language Model Continuations](https://arxiv.org/abs/2511.16054)
*Gwen Yidou-Weng,Ian Li,Anji Liu,Oliver Broadrick,Guy Van den Broeck,Benjie Wang*

Main category: cs.CL

TL;DR: LTLA是一种混合方法，结合基础语言模型和固定可处理代理模型，通过单次批量HMM更新处理所有候选标记，提高受控文本生成的约束满足度和流畅性。


<details>
  <summary>Details</summary>
Motivation: 现有方法使用可处理代理模型（如HMM）近似延续概率，但这些代理模型通常上下文感知能力较弱，影响查询质量。

Method: LTLA将基础语言模型用于丰富前缀编码，与固定可处理代理模型配对计算精确延续概率，通过单次批量HMM更新避免效率问题。

Result: LTLA获得了比无条件HMM更高的条件似然，在视觉语言模型中近似延续分布，在受控生成任务中提高了约束满足度且保持相当的流畅性。

Conclusion: LTLA方法有效解决了受控文本生成中的效率问题，在最小推理开销下显著提升了性能。

Abstract: Controlled language generation conditions text on sequence-level constraints (for example, syntax, style, or safety). These constraints may depend on future tokens, which makes directly conditioning an autoregressive language model (LM) generally intractable. Prior work uses tractable surrogates such as hidden Markov models (HMMs) to approximate the distribution over continuations and adjust the model's next-token logits at decoding time. However, we find that these surrogates are often weakly context aware, which reduces query quality. We propose Learning to Look Ahead (LTLA), a hybrid approach that pairs the same base language model for rich prefix encoding with a fixed tractable surrogate model that computes exact continuation probabilities. Two efficiency pitfalls arise when adding neural context: (i) naively rescoring the prefix with every candidate next token requires a sweep over the entire vocabulary at each step, and (ii) predicting fresh surrogate parameters for each prefix, although tractable at a single step, forces recomputation of future probabilities for every new prefix and eliminates reuse. LTLA avoids both by using a single batched HMM update to account for all next-token candidates at once, and by conditioning only the surrogate's latent state prior on the LM's hidden representations while keeping the surrogate decoder fixed, so computations can be reused across prefixes. Empirically, LTLA attains higher conditional likelihood than an unconditional HMM, approximates continuation distributions for vision-language models where a standalone HMM cannot encode visual context, and improves constraint satisfaction at comparable fluency on controlled-generation tasks, with minimal inference overhead.

</details>


### [6] [Early science acceleration experiments with GPT-5](https://arxiv.org/abs/2511.16072)
*Sébastien Bubeck,Christian Coester,Ronen Eldan,Timothy Gowers,Yin Tat Lee,Alexandru Lupsasca,Mehtaab Sawhney,Robert Scherrer,Mark Sellke,Brian K. Spears,Derya Unutmaz,Kevin Weil,Steven Yin,Nikita Zhivotovskiy*

Main category: cs.CL

TL;DR: GPT-5在多个科学领域帮助研究人员取得新进展，包括数学、物理、天文学等，展示了AI与人类合作的价值。


<details>
  <summary>Details</summary>
Motivation: 许多科学家对前沿AI的能力了解不足，本文旨在通过实际案例展示GPT-5在科学研究中的具体应用价值。

Method: 收集了多个领域的短案例研究，记录研究人员与GPT-5的互动过程，展示AI如何加速研究以及人类输入的关键作用。

Result: 在数学领域获得了四个经人类验证的新结果，解决了之前未解决的问题；在其他科学领域也产生了具体的研究进展。

Conclusion: GPT-5能够有效辅助科学研究，虽然贡献规模有限但意义深远，展示了前沿AI快速发展的潜力。

Abstract: AI models like GPT-5 are an increasingly valuable tool for scientists, but many remain unaware of the capabilities of frontier AI. We present a collection of short case studies in which GPT-5 produced new, concrete steps in ongoing research across mathematics, physics, astronomy, computer science, biology, and materials science. In these examples, the authors highlight how AI accelerated their work, and where it fell short; where expert time was saved, and where human input was still key. We document the interactions of the human authors with GPT-5, as guiding examples of fruitful collaboration with AI. Of note, this paper includes four new results in mathematics (carefully verified by the human authors), underscoring how GPT-5 can help human mathematicians settle previously unsolved problems. These contributions are modest in scope but profound in implication, given the rate at which frontier AI is progressing.

</details>


### [7] [ELPO: Ensemble Learning Based Prompt Optimization for Large Language Models](https://arxiv.org/abs/2511.16122)
*Qing Zhang,Bing Xu,Xudong Zhang,Yifan Shi,Yang Li,Chen Zhang,Yik Chung Wu,Ngai Wong,Yijie Chen,Hong Dai,Xiansen Chen,Mian Zhang*

Main category: cs.CL

TL;DR: 提出了一种基于集成学习的自动提示优化框架ELPO，通过投票机制和多种搜索方法提升提示优化的准确性和鲁棒性，在多个任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有自动提示优化方法通常只使用单一模型或算法，在处理复杂任务时性能受限，需要更有效的方法来提升提示优化的效果。

Method: ELPO框架采用集成学习思想，结合投票机制、共享生成策略和多种搜索方法，并提出了更高效的提示生成和搜索算法。

Result: 实验结果表明ELPO在不同任务上优于现有最优方法，如在ArSarcasm数据集上F1分数提高了7.6分。

Conclusion: ELPO框架通过集成学习方法有效提升了自动提示优化的性能，为LLMs的实用化应用提供了更好的解决方案。

Abstract: The remarkable performance of Large Language Models (LLMs) highly relies on crafted prompts. However, manual prompt engineering is a laborious process, creating a core bottleneck for practical application of LLMs. This phenomenon has led to the emergence of a new research area known as Automatic Prompt Optimization (APO), which develops rapidly in recent years. Existing APO methods such as those based on evolutionary algorithms or trial-and-error approaches realize an efficient and accurate prompt optimization to some extent. However, those researches focus on a single model or algorithm for the generation strategy and optimization process, which limits their performance when handling complex tasks. To address this, we propose a novel framework called Ensemble Learning based Prompt Optimization (ELPO) to achieve more accurate and robust results. Motivated by the idea of ensemble learning, ELPO conducts voting mechanism and introduces shared generation strategies along with different search methods for searching superior prompts. Moreover, ELPO creatively presents more efficient algorithms for the prompt generation and search process. Experimental results demonstrate that ELPO outperforms state-of-the-art prompt optimization methods across different tasks, e.g., improving F1 score by 7.6 on ArSarcasm dataset.

</details>


### [8] [TS-PEFT: Token-Selective Parameter-Efficient Fine-Tuning with Learnable Threshold Gating](https://arxiv.org/abs/2511.16147)
*Dabiao Ma,Ziming Dai,Zhimin Xin,Shu Wang,Ye Wang,Haojun Fei*

Main category: cs.CL

TL;DR: 本文提出Token-Selective PEFT（TS-PEFT），挑战传统PEFT对所有位置索引进行修改的做法，通过选择性应用PEFT修改到位置索引子集来优化大模型微调。


<details>
  <summary>Details</summary>
Motivation: 质疑传统参数高效微调（PEFT）方法对所有位置索引进行修改的必要性，认为这种不加区分的修改可能不仅多余甚至适得其反。

Method: 引入TS-PEFT范式，通过选择函数S有选择地将PEFT修改应用于位置索引的子集，而非所有索引。

Result: 实验结果表明，不加选择地对所有索引应用PEFT不仅多余，还可能产生负面影响。

Conclusion: 为PEFT提供了新视角，倡导更针对性的修改方法，并为未来优化大模型微调过程提供了框架。

Abstract: In the field of large models (LMs) for natural language processing (NLP) and computer vision (CV), Parameter-Efficient Fine-Tuning (PEFT) has emerged as a resource-efficient method that modifies a limited number of parameters while keeping the pretrained weights fixed. This paper investigates the traditional PEFT approach, which applies modifications to all position indices, and questions its necessity. We introduce a new paradigm called Token-Selective PEFT (TS-PEFT), in which a function S selectively applies PEFT modifications to a subset of position indices, potentially enhancing performance on downstream tasks. Our experimental results reveal that the indiscriminate application of PEFT to all indices is not only superfluous, but may also be counterproductive. This study offers a fresh perspective on PEFT, advocating for a more targeted approach to modifications and providing a framework for future research to optimize the fine-tuning process for large models.

</details>


### [9] [SemanticCite: Citation Verification with AI-Powered Full-Text Analysis and Evidence-Based Reasoning](https://arxiv.org/abs/2511.16198)
*Sebastian Haan*

Main category: cs.CL

TL;DR: SemanticCite是一个AI驱动的系统，通过全文分析验证引文准确性，提供详细推理和相关文本片段，解决语义引文错误、AI生成幻觉引用等学术文献挑战。


<details>
  <summary>Details</summary>
Motivation: 学术文献面临语义引文错误、AI生成幻觉引用以及传统引文格式无法指示具体支持段落等问题，需要准确验证引文以维护研究完整性。

Method: 结合多种检索方法和四类分类系统（支持、部分支持、不支持、不确定），通过微调的轻量级语言模型进行全文源分析。

Result: 微调的轻量级语言模型性能与大型商业系统相当，但计算需求显著降低，使大规模引文验证实际可行。系统提供透明、基于证据的解释。

Conclusion: SemanticCite通过可扩展的引文验证、简化同行评审和AI生成内容质量控制，为维护大规模引文准确性提供了开源基础。

Abstract: Effective scientific communication depends on accurate citations that validate sources and guide readers to supporting evidence. Yet academic literature faces mounting challenges: semantic citation errors that misrepresent sources, AI-generated hallucinated references, and traditional citation formats that point to entire papers without indicating which sections substantiate specific claims. We introduce SemanticCite, an AI-powered system that verifies citation accuracy through full-text source analysis while providing rich contextual information via detailed reasoning and relevant text snippets. Our approach combines multiple retrieval methods with a four-class classification system (Supported, Partially Supported, Unsupported, Uncertain) that captures nuanced claim-source relationships and enables appropriate remedial actions for different error types. Our experiments show that fine-tuned lightweight language models achieve performance comparable to large commercial systems with significantly lower computational requirements, making large-scale citation verification practically feasible. The system provides transparent, evidence-based explanations that support user understanding and trust. We contribute a comprehensive dataset of over 1,000 citations with detailed alignments, functional classifications, semantic annotations, and bibliometric metadata across eight disciplines, alongside fine-tuned models and the complete verification framework as open-source software. SemanticCite addresses critical challenges in research integrity through scalable citation verification, streamlined peer review, and quality control for AI-generated content, providing an open-source foundation for maintaining citation accuracy at scale.

</details>


### [10] [SeSE: A Structural Information-Guided Uncertainty Quantification Framework for Hallucination Detection in LLMs](https://arxiv.org/abs/2511.16275)
*Xingtao Zhao,Hao Peng,Dingli Su,Xianghua Zeng,Chunyang Liu,Jinzhi Liao,Philip S. Yu*

Main category: cs.CL

TL;DR: 本文提出了语义结构熵(SeSE)框架，从结构信息角度量化大语言模型的语义不确定性，用于检测幻觉生成。该方法通过构建自适应稀疏语义图，利用层次抽象提取潜在语义结构信息，显著优于现有不确定性量化方法。


<details>
  <summary>Details</summary>
Motivation: 现有不确定性量化方法主要依赖语义概率分布或成对距离，忽略了能够实现更精确不确定性估计的潜在语义结构信息。在安全关键场景中，可靠的不确定性量化对于防止大语言模型产生幻觉至关重要。

Method: 开发自适应稀疏有向语义图构建算法，捕获方向性语义依赖并自动剪除引入负面干扰的不必要连接。然后通过层次抽象利用潜在语义结构信息：SeSE定义为最优语义编码树的结构熵，形式化最优压缩后语义空间的内在不确定性。

Result: 在29个模型-数据集组合上的广泛实验表明，SeSE显著优于先进的不确定性量化基线，包括强监督方法和最近提出的KLE方法。

Conclusion: SeSE框架通过利用语义结构信息，为大语言模型提供了更可靠的不确定性量化方法，有效检测幻觉生成，在安全关键应用中具有重要价值。

Abstract: Reliable uncertainty quantification (UQ) is essential for deploying large language models (LLMs) in safety-critical scenarios, as it enables them to abstain from responding when uncertain, thereby avoiding hallucinating falsehoods. However, state-of-the-art UQ methods primarily rely on semantic probability distributions or pairwise distances, overlooking latent semantic structural information that could enable more precise uncertainty estimates. This paper presents Semantic Structural Entropy (SeSE), a principled UQ framework that quantifies the inherent semantic uncertainty of LLMs from a structural information perspective for hallucination detection. Specifically, to effectively model semantic spaces, we first develop an adaptively sparsified directed semantic graph construction algorithm that captures directional semantic dependencies while automatically pruning unnecessary connections that introduce negative interference. We then exploit latent semantic structural information through hierarchical abstraction: SeSE is defined as the structural entropy of the optimal semantic encoding tree, formalizing intrinsic uncertainty within semantic spaces after optimal compression. A higher SeSE value corresponds to greater uncertainty, indicating that LLMs are highly likely to generate hallucinations. In addition, to enhance fine-grained UQ in long-form generation -- where existing methods often rely on heuristic sample-and-count techniques -- we extend SeSE to quantify the uncertainty of individual claims by modeling their random semantic interactions, providing theoretically explicable hallucination detection. Extensive experiments across 29 model-dataset combinations show that SeSE significantly outperforms advanced UQ baselines, including strong supervised methods and the recently proposed KLE.

</details>


### [11] [SDA: Steering-Driven Distribution Alignment for Open LLMs without Fine-Tuning](https://arxiv.org/abs/2511.16324)
*Wei Xia,Zhi-Hong Deng*

Main category: cs.CL

TL;DR: 提出SDA（Steering-Driven Distribution Alignment）框架，一种无需训练、模型无关的对齐方法，通过动态重分布模型输出概率来增强LLMs与人类意图的对齐效果。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在现实应用中的广泛部署，确保模型输出与人类意图对齐成为关键挑战。需要在不进行昂贵重训练或大量监督的情况下，在推理阶段有效且高效地对齐模型行为。

Method: SDA基于用户定义的对齐指令动态重分布模型输出概率，无需微调。该方法轻量、资源高效，可独立使用或与基于训练的对齐策略集成，支持个性化偏好对齐。

Result: 在8个不同规模和来源的开源LLMs上评估，SDA在helpfulness、harmlessness和honesty三个对齐维度上分别平均提升64.4%、11.5%和30%，显示出良好的泛化能力。

Conclusion: SDA是一种有效的训练无关对齐框架，能够显著提升LLMs与人类意图的对齐性能，适用于多样化模型和应用场景。

Abstract: With the rapid advancement of large language models (LLMs), their deployment in real-world applications has become increasingly widespread. LLMs are expected to deliver robust performance across diverse tasks, user preferences, and practical scenarios. However, as demands grow, ensuring that LLMs produce responses aligned with human intent remains a foundational challenge. In particular, aligning model behavior effectively and efficiently during inference, without costly retraining or extensive supervision, is both a critical requirement and a non-trivial technical endeavor. To address the challenge, we propose SDA (Steering-Driven Distribution Alignment), a training-free and model-agnostic alignment framework designed for open-source LLMs. SDA dynamically redistributes model output probabilities based on user-defined alignment instructions, enhancing alignment between model behavior and human intents without fine-tuning. The method is lightweight, resource-efficient, and compatible with a wide range of open-source LLMs. It can function independently during inference or be integrated with training-based alignment strategies. Moreover, SDA supports personalized preference alignment, enabling flexible control over the model response behavior. Empirical results demonstrate that SDA consistently improves alignment performance across 8 open-source LLMs with varying scales and diverse origins, evaluated on three key alignment dimensions, helpfulness, harmlessness, and honesty (3H). Specifically, SDA achieves average gains of 64.4% in helpfulness, 30% in honesty and 11.5% in harmlessness across the tested models, indicating its effectiveness and generalization across diverse models and application scenarios.

</details>


### [12] [Incorporating Self-Rewriting into Large Language Model Reasoning Reinforcement](https://arxiv.org/abs/2511.16331)
*Jiashu Yao,Heyan Huang,Shuang Zeng,Chuwei Luo,WangJie You,Jie Tang,Qingsong Liu,Yuhang Guo,Yangyang Kang*

Main category: cs.CL

TL;DR: 提出自我重写框架，通过模型重写自身推理文本来改善内部推理质量，在保持GRPO奖励信号的同时减少推理长度46%并提升准确性0.6%。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习仅关注最终正确性的单边奖励无法对内部推理过程提供详细监督，导致推理质量不佳，出现过思考、欠思考、冗余思考和思维混乱等问题。

Method: 采用选择性重写方法，仅对模型持续正确的"简单"样本进行重写，将重写和原始生成编译在单个批次中，仅增加约10%开销。

Result: 在准确性-长度权衡方面，自我重写方法在减少46%推理长度的同时提升准确性0.6%；在内部推理质量方面，LLM作为评判者的评分显著提高7.2分。

Conclusion: 自我重写框架有效缓解了内部推理缺陷，在保持强化学习算法可扩展性的同时显著提升了推理质量和效率。

Abstract: Through reinforcement learning (RL) with outcome correctness rewards, large reasoning models (LRMs) with scaled inference computation have demonstrated substantial success on complex reasoning tasks. However, the one-sided reward, focused solely on final correctness, limits its ability to provide detailed supervision over internal reasoning process. This deficiency leads to suboptimal internal reasoning quality, manifesting as issues like over-thinking, under-thinking, redundant-thinking, and disordered-thinking. Inspired by the recent progress in LRM self-rewarding, we introduce self-rewriting framework, where a model rewrites its own reasoning texts, and subsequently learns from the rewritten reasoning to improve the internal thought process quality. For algorithm design, we propose a selective rewriting approach wherein only "simple" samples, defined by the model's consistent correctness, are rewritten, thereby preserving all original reward signals of GRPO. For practical implementation, we compile rewriting and vanilla generation within one single batch, maintaining the scalability of the RL algorithm and introducing only ~10% overhead. Extensive experiments on diverse tasks with different model sizes validate the effectiveness of self-rewriting. In terms of the accuracy-length tradeoff, the self-rewriting approach achieves improved accuracy (+0.6) with substantially shorter reasoning (-46%) even without explicit instructions in rewriting prompts to reduce reasoning length, outperforming existing strong baselines. In terms of internal reasoning quality, self-rewriting achieves significantly higher scores (+7.2) under the LLM-as-a-judge metric, successfully mitigating internal reasoning flaws.

</details>


### [13] [NLP Datasets for Idiom and Figurative Language Tasks](https://arxiv.org/abs/2511.16345)
*Blake Matheny,Phuong Minh Nguyen,Minh Le Nguyen,Stephanie Reynolds*

Main category: cs.CL

TL;DR: 本文创建了大规模习语和比喻语言数据集，用于评估预训练语言模型处理比喻意义的能力，通过习语识别任务来缩小LLMs在理解非正式语言方面的差距。


<details>
  <summary>Details</summary>
Motivation: 习语和比喻语言在口语和书面语中占很大比例，但大型语言模型在这方面仍然表现不佳。虽然大语料库似乎能解决大多数NLP问题，但习语和比喻语言仍然是LLMs的难点。

Method: 使用现有习语数据集获取组合习语列表，从大型语料库中检索上下文序列。创建了一个大规模潜在习语数据集和两个人工标注的确切习语数据集，用于评估预训练语言模型在习语识别任务中的表现。

Result: 开发的数据集经过后处理以适应模型无关的训练兼容性，并在槽位标注和序列标注任务中进行了训练和评估。

Conclusion: 微调方法被证明是最优的，但更好更大的数据集可以进一步缩小LLMs在理解习语和比喻语言方面的差距。本文提供的数据集为构建新模型和开发新方法提供了多样化的类别基础。

Abstract: Idiomatic and figurative language form a large portion of colloquial speech and writing. With social media, this informal language has become more easily observable to people and trainers of large language models (LLMs) alike. While the advantage of large corpora seems like the solution to all machine learning and Natural Language Processing (NLP) problems, idioms and figurative language continue to elude LLMs. Finetuning approaches are proving to be optimal, but better and larger datasets can help narrow this gap even further. The datasets presented in this paper provide one answer, while offering a diverse set of categories on which to build new models and develop new approaches. A selection of recent idiom and figurative language datasets were used to acquire a combined idiom list, which was used to retrieve context sequences from a large corpus. One large-scale dataset of potential idiomatic and figurative language expressions and two additional human-annotated datasets of definite idiomatic and figurative language expressions were created to evaluate the baseline ability of pre-trained language models in handling figurative meaning through idiom recognition (detection) tasks. The resulting datasets were post-processed for model agnostic training compatibility, utilized in training, and evaluated on slot labeling and sequence tagging.

</details>


### [14] [Learning from Sufficient Rationales: Analysing the Relationship Between Explanation Faithfulness and Token-level Regularisation Strategies](https://arxiv.org/abs/2511.16353)
*Jonathan Kamp,Lisa Beinborn,Antske Fokkens*

Main category: cs.CL

TL;DR: 本文探讨了自然语言解释（rationales）在模型评估中的作用，发现常用的充分性指标对模型性能影响有限，需要结合标记分类和注意力正则化来更全面地理解rationales的价值。


<details>
  <summary>Details</summary>
Motivation: 现有方法使用rationales来评估模型是否基于正确原因学习标签，但常用的充分性指标只能提供有限信息，无法全面反映rationales对模型性能的影响。

Method: 将充分性与两种建模范式联系起来：通过标记分类识别rationales中的标记，以及通过注意力正则化在输入中融入rationales来提升模型性能。

Result: 研究发现高度信息化的rationales不一定有助于正确分类；充分性实际上反映了非rationalized上下文对分类的干扰；在输入中融入rationales可以提升跨域分类，但结果因任务和模型类型而异；充分性与标记分类似乎无关。

Conclusion: 这些结果显示了rationales的复杂性，表明需要进一步研究能够系统捕捉此类信息的度量方法。

Abstract: Human explanations of natural language, rationales, form a tool to assess whether models learn a label for the right reasons or rely on dataset-specific shortcuts. Sufficiency is a common metric for estimating the informativeness of rationales, but it provides limited insight into the effects of rationale information on model performance. We address this limitation by relating sufficiency to two modelling paradigms: the ability of models to identify which tokens are part of the rationale (through token classification) and the ability of improving model performance by incorporating rationales in the input (through attention regularisation). We find that highly informative rationales are not likely to help classify the instance correctly. Sufficiency conversely captures the classification impact of the non-rationalised context, which interferes with rationale information in the same input. We also find that incorporating rationale information in model inputs can boost cross-domain classification, but results are inconsistent per task and model type. Finally, sufficiency and token classification appear to be unrelated. These results exemplify the complexity of rationales, showing that metrics capable of systematically capturing this type of information merit further investigation.

</details>


### [15] [AICC: Parse HTML Finer, Make Models Better -- A 7.3T AI-Ready Corpus Built by a Model-Based HTML Parser](https://arxiv.org/abs/2511.16397)
*Ren Ma,Jiantao Qiu,Chao Xu,Pei Chu,Kaiwen Liu,Pengli Ren,Yuan Qu,Jiahui Peng,Linfeng Hou,Mengjie Liu,Lindong Lu,Wenchang Ning,Jia Yu,Rui Min,Jin Shi,Haojiong Chen,Peng Zhang,Wenjian Zhang,Qian Jiang,Zengjie Hu,Guoqiang Yang,Zhenxiang Li,Fukai Shang,Zhongying Tu,Wentao Zhang,Dahua Lin,Conghui He*

Main category: cs.CL

TL;DR: MinerU-HTML是一个基于语言模型的HTML到文本提取管道，通过序列标注方法显著提升提取质量，构建了7.3万亿token的多语言语料库AICC，在预训练实验中证明提取质量对模型性能有重要影响。


<details>
  <summary>Details</summary>
Motivation: 现有网络语料库依赖基于启发式的提取器，无法很好地保留文档结构和结构化元素（如公式、代码、表格），而改进提取质量可能对下游性能产生与过滤策略同等重要的影响。

Method: 将内容提取重新定义为序列标注问题，使用0.6B参数的语言模型解决，采用两阶段格式化管道，先对语义元素进行分类再转换为Markdown格式。

Result: 在MainWebBench基准测试中，MinerU-HTML获得81.8% ROUGE-N F1，显著优于Trafilatura的63.6%，结构化元素保留率极高（代码块90.9%，公式94.0%）。使用AICC语料库训练的模型在13个基准测试中平均准确率达到50.8%，优于TfCC 1.08个百分点。

Conclusion: HTML提取是网络语料库构建中关键但常被低估的组件，基于模型的提取方法具有内在可扩展性，而启发式方法改进路径有限。

Abstract: While web data quality is crucial for large language models, most curation efforts focus on filtering and deduplication,treating HTML-to-text extraction as a fixed pre-processing step. Existing web corpora rely on heuristic-based extractors like Trafilatura, which struggle to preserve document structure and frequently corrupt structured elements such as formulas, codes, and tables. We hypothesize that improving extraction quality can be as impactful as aggressive filtering strategies for downstream performance. We introduce MinerU-HTML, a novel extraction pipeline that reformulates content extraction as a sequence labeling problem solved by a 0.6B-parameter language model. Unlike text-density heuristics, MinerU-HTML leverages semantic understanding and employs a two-stage formatting pipeline that explicitly categorizes semantic elements before converting to Markdown. Crucially, its model-based approach is inherently scalable, whereas heuristic methods offer limited improvement pathways. On MainWebBench, our benchmark of 7,887 annotated web pages, MinerU-HTML achieves 81.8\% ROUGE-N F1 compared to Trafilatura's 63.6\%, with exceptional structured element preservation (90.9\% for code blocks, 94.0\% for formulas). Using MinerU-HTML, we construct AICC (AI-ready Common Crawl), a 7.3-trillion token multilingual corpus from two Common Crawl snapshots. In controlled pretraining experiments where AICC and Trafilatura-extracted TfCC undergo identical filtering, models trained on AICC (62B tokens) achieve 50.8\% average accuracy across 13 benchmarks, outperforming TfCC by 1.08pp-providing direct evidence that extraction quality significantly impacts model capabilities. AICC also surpasses RefinedWeb and FineWeb on key benchmarks. We publicly release MainWebBench, MinerU-HTML, and AICC, demonstrating that HTML extraction is a critical, often underestimated component of web corpus construction.

</details>


### [16] [Classification of worldwide news articles by perceived quality, 2018-2024](https://arxiv.org/abs/2511.16416)
*Connor McElroy,Thiago E. A. de Oliveira,Chris Brogly*

Main category: cs.CL

TL;DR: 本研究评估了机器学习和深度学习模型在区分感知低质量与高质量新闻文章方面的效果，使用140万+新闻文章数据集，发现深度学习模型（特别是ModernBERT-large）表现最佳。


<details>
  <summary>Details</summary>
Motivation: 探索机器学习和深度学习模型是否能够有效区分感知低质量与高质量新闻文章，以帮助自动识别新闻质量。

Method: 使用3种机器学习分类器和3种深度学习模型，基于新创建的1,412,272篇英语新闻文章数据集，每篇文章提取194个语言特征，将专家评分的579个新闻网站按中位数分为低质量与高质量两类。

Result: 传统机器学习分类器（如随机森林）表现良好（准确率0.7355，ROC AUC 0.8131），而深度学习模型中ModernBERT-large表现最佳（准确率0.8744，ROC-AUC 0.9593，F1 0.8739）。

Conclusion: 传统CPU机器学习和深度学习分类器都能有效区分全球新闻文章的感知质量，其中深度学习模型表现更优。

Abstract: This study explored whether supervised machine learning and deep learning models can effectively distinguish perceived lower-quality news articles from perceived higher-quality news articles. 3 machine learning classifiers and 3 deep learning models were assessed using a newly created dataset of 1,412,272 English news articles from the Common Crawl over 2018-2024. Expert consensus ratings on 579 source websites were split at the median, creating perceived low and high-quality classes of about 706,000 articles each, with 194 linguistic features per website-level labelled article. Traditional machine learning classifiers such as the Random Forest demonstrated capable performance (0.7355 accuracy, 0.8131 ROC AUC). For deep learning, ModernBERT-large (256 context length) achieved the best performance (0.8744 accuracy; 0.9593 ROC-AUC; 0.8739 F1), followed by DistilBERT-base (512 context length) at 0.8685 accuracy and 0.9554 ROC-AUC. DistilBERT-base (256 context length) reached 0.8478 accuracy and 0.9407 ROC-AUC, while ModernBERT-base (256 context length) attained 0.8569 accuracy and 0.9470 ROC-AUC. These results suggest that the perceived quality of worldwide news articles can be effectively differentiated by traditional CPU-based machine learning classifiers and deep learning classifiers.

</details>


### [17] [ESGBench: A Benchmark for Explainable ESG Question Answering in Corporate Sustainability Reports](https://arxiv.org/abs/2511.16438)
*Sherine George,Nithish Saji*

Main category: cs.CL

TL;DR: ESGBench是一个用于评估可解释ESG问答系统的基准数据集和评估框架，包含基于企业可持续发展报告的问题、人工标注答案和证据支持。


<details>
  <summary>Details</summary>
Motivation: 需要评估ESG问答系统的可解释性、事实一致性和领域对齐能力，推动透明和可问责的ESG人工智能系统研究。

Method: 构建包含多个ESG主题的领域基础问题，配以人工标注的答案和证据支持，用于细粒度评估模型推理能力。

Result: 分析了最先进大语言模型在ESGBench上的表现，揭示了在事实一致性、可追溯性和领域对齐方面的关键挑战。

Conclusion: ESGBench旨在加速透明和可问责的ESG导向AI系统的研究发展。

Abstract: We present ESGBench, a benchmark dataset and evaluation framework designed to assess explainable ESG question answering systems using corporate sustainability reports. The benchmark consists of domain-grounded questions across multiple ESG themes, paired with human-curated answers and supporting evidence to enable fine-grained evaluation of model reasoning. We analyze the performance of state-of-the-art LLMs on ESGBench, highlighting key challenges in factual consistency, traceability, and domain alignment. ESGBench aims to accelerate research in transparent and accountable ESG-focused AI systems.

</details>


### [18] [Anatomy of an Idiom: Tracing Non-Compositionality in Language Models](https://arxiv.org/abs/2511.16467)
*Andrew Gomes*

Main category: cs.CL

TL;DR: 本文研究了基于Transformer的语言模型如何处理习语表达，通过电路发现和分析技术揭示了习语处理的独特计算模式，包括习语头部的识别和增强的注意力机制。


<details>
  <summary>Details</summary>
Motivation: 研究Transformer模型如何处理非组合性语言（如习语），探索模型在计算效率和鲁棒性之间的平衡机制。

Method: 使用改进的路径修补算法进行电路发现，识别习语头部和增强的注意力机制（称为"增强接收"）。

Result: 发现习语处理具有独特的计算模式，识别出跨不同习语频繁激活的习语头部，以及习语标记间因早期处理而增强的注意力。

Conclusion: 这些发现揭示了Transformer处理非组合性语言的机制，为理解更复杂语法结构的处理提供了途径。

Abstract: We investigate the processing of idiomatic expressions in transformer-based language models using a novel set of techniques for circuit discovery and analysis. First discovering circuits via a modified path patching algorithm, we find that idiom processing exhibits distinct computational patterns. We identify and investigate ``Idiom Heads,'' attention heads that frequently activate across different idioms, as well as enhanced attention between idiom tokens due to earlier processing, which we term ``augmented reception.'' We analyze these phenomena and the general features of the discovered circuits as mechanisms by which transformers balance computational efficiency and robustness. Finally, these findings provide insights into how transformers handle non-compositional language and suggest pathways for understanding the processing of more complex grammatical constructions.

</details>


### [19] [Arctic-Extract Technical Report](https://arxiv.org/abs/2511.16470)
*Mateusz Chiliński,Julita Ołtusek,Wojciech Jaśkowski*

Main category: cs.CL

TL;DR: Arctic-Extract是一个用于从扫描或数字商业文档中提取结构化数据（问答、实体和表格）的最先进模型，具有轻量化设计，可在资源受限的硬件上部署。


<details>
  <summary>Details</summary>
Motivation: 开发一个既具备最先进性能又能在资源受限硬件上部署的文档理解模型，以满足实际业务场景中对长文档处理的需求。

Method: 采用了特定的训练协议，设计轻量化模型架构，使模型大小仅为6.6 GiB，能够在A10 GPU（24GB内存）等资源受限设备上运行。

Result: 模型在A10 GPU上可处理多达125页A4文档，在文档理解任务中表现出强大的性能，适合长文档处理场景。

Conclusion: Arctic-Extract成功实现了在保持最先进性能的同时，具备轻量化和高效部署能力，为商业文档处理提供了实用的解决方案。

Abstract: Arctic-Extract is a state-of-the-art model designed for extracting structural data (question answering, entities and tables) from scanned or digital-born business documents. Despite its SoTA capabilities, the model is deployable on resource-constrained hardware, weighting only 6.6 GiB, making it suitable for deployment on devices with limited resources, such as A10 GPUs with 24 GB of memory. Arctic-Extract can process up to 125 A4 pages on those GPUs, making suitable for long document processing. This paper highlights Arctic-Extract's training protocols and evaluation results, demonstrating its strong performance in document understanding.

</details>


### [20] [TurkColBERT: A Benchmark of Dense and Late-Interaction Models for Turkish Information Retrieval](https://arxiv.org/abs/2511.16528)
*Özay Ezerceli,Mahmoud El Hussieni,Selva Taş,Reyhan Bayraktar,Fatma Betül Terzioğlu,Yusuf Çelebi,Yağız Asker*

Main category: cs.CL

TL;DR: TurkColBERT是首个针对土耳其语检索的全面基准，比较了密集编码器和延迟交互模型。结果显示延迟交互模型在参数效率上显著优于密集编码器，同时保持了高性能。


<details>
  <summary>Details</summary>
Motivation: 神经信息检索系统在高资源语言中表现出色，但在形态丰富的低资源语言如土耳其语中研究不足。密集编码器目前主导土耳其语IR，但延迟交互模型尚未得到系统评估。

Method: 采用两阶段适应流程：先在土耳其NLI/STS任务上微调英语和多语言编码器，然后使用PyLate在MS MARCO-TR上将其转换为ColBERT风格的检索器。评估了10个模型在5个土耳其BEIR数据集上的表现。

Result: 延迟交互模型参数效率高：1.0M参数的colbert-hash-nano-tr比600M参数的turkish-e5-large小600倍，但保持了71%以上的平均mAP。3-5倍小的延迟交互模型显著优于密集编码器，ColmmBERT-base-TR在特定领域任务上mAP提升达+13.8%。

Conclusion: TurkColBERT为土耳其语检索提供了首个全面基准，证明了延迟交互模型在参数效率和性能上的优势。MUVERA+Rerank索引算法比PLAID快3.33倍，提供+1.7%相对mAP增益，实现了低延迟检索。

Abstract: Neural information retrieval systems excel in high-resource languages but remain underexplored for morphologically rich, lower-resource languages such as Turkish. Dense bi-encoders currently dominate Turkish IR, yet late-interaction models -- which retain token-level representations for fine-grained matching -- have not been systematically evaluated. We introduce TurkColBERT, the first comprehensive benchmark comparing dense encoders and late-interaction models for Turkish retrieval. Our two-stage adaptation pipeline fine-tunes English and multilingual encoders on Turkish NLI/STS tasks, then converts them into ColBERT-style retrievers using PyLate trained on MS MARCO-TR. We evaluate 10 models across five Turkish BEIR datasets covering scientific, financial, and argumentative domains. Results show strong parameter efficiency: the 1.0M-parameter colbert-hash-nano-tr is 600$\times$ smaller than the 600M turkish-e5-large dense encoder while preserving over 71\% of its average mAP. Late-interaction models that are 3--5$\times$ smaller than dense encoders significantly outperform them; ColmmBERT-base-TR yields up to +13.8\% mAP on domain-specific tasks. For production-readiness, we compare indexing algorithms: MUVERA+Rerank is 3.33$\times$ faster than PLAID and offers +1.7\% relative mAP gain. This enables low-latency retrieval, with ColmmBERT-base-TR achieving 0.54 ms query times under MUVERA. We release all checkpoints, configs, and evaluation scripts. Limitations include reliance on moderately sized datasets ($\leq$50K documents) and translated benchmarks, which may not fully reflect real-world Turkish retrieval conditions; larger-scale MUVERA evaluations remain necessary.

</details>


### [21] [Beyond Tokens in Language Models: Interpreting Activations through Text Genre Chunks](https://arxiv.org/abs/2511.16540)
*Éloïse Benito-Rodriguez,Einar Urdshals,Jasmina Nasufi,Nicky Pochinkov*

Main category: cs.CL

TL;DR: 本文提出了一个预测框架，通过分析LLM的激活状态来预测输入文本的体裁，使用Mistral-7B模型在两个数据集上实现了最高98%和71%的F1分数。


<details>
  <summary>Details</summary>
Motivation: 理解大型语言模型对于确保其安全有益部署至关重要，但由于LLM结构难以解释且无法对所有输出进行人工评估，这一任务变得复杂。

Method: 使用Mistral-7B模型，基于其激活状态预测文本体裁，采用scikit-learn分类器进行浅层学习建模。

Result: 在两个数据集上分别实现了98%和71%的F1分数，结果始终优于对照任务，证明了从LLM中推断文本体裁的可行性。

Conclusion: 这为从LLM中推断文本体裁提供了一个概念验证，表明浅层学习模型可以有效提取LLM中的体裁信息。

Abstract: Understanding Large Language Models (LLMs) is key to ensure their safe and beneficial deployment. This task is complicated by the difficulty of interpretability of LLM structures, and the inability to have all their outputs human-evaluated. In this paper, we present the first step towards a predictive framework, where the genre of a text used to prompt an LLM, is predicted based on its activations. Using Mistral-7B and two datasets, we show that genre can be extracted with F1-scores of up to 98% and 71% using scikit-learn classifiers. Across both datasets, results consistently outperform the control task, providing a proof of concept that text genres can be inferred from LLMs with shallow learning models.

</details>


### [22] [WER is Unaware: Assessing How ASR Errors Distort Clinical Understanding in Patient Facing Dialogue](https://arxiv.org/abs/2511.16544)
*Zachary Ellis,Jared Joselowitz,Yash Deo,Yajie He,Anna Kalygina,Aisling Higham,Mana Rahimzadeh,Yan Jia,Ibrahim Habli,Ernest Lim*

Main category: cs.CL

TL;DR: 挑战ASR评估中过度依赖词错误率(WER)的标准，提出基于临床影响的新评估框架，使用LLM模拟专家临床评估，实现与人类相当的准确性。


<details>
  <summary>Details</summary>
Motivation: 当前ASR在临床对话中部署日益增多，但标准评估仍主要依赖WER，缺乏对转录错误临床影响的考量。

Method: 建立专家标注的黄金标准基准，使用GEPA程序化优化LLM作为评判者(Gemini-2.5-Pro)，复制专家临床评估。

Result: 优化后的评判者达到90%准确率和0.816的Cohen's κ系数，表现与人类专家相当。

Conclusion: 提供了一个经过验证的自动化框架，将ASR评估从简单的文本保真度转向必要的、可扩展的临床对话安全性评估。

Abstract: As Automatic Speech Recognition (ASR) is increasingly deployed in clinical dialogue, standard evaluations still rely heavily on Word Error Rate (WER). This paper challenges that standard, investigating whether WER or other common metrics correlate with the clinical impact of transcription errors. We establish a gold-standard benchmark by having expert clinicians compare ground-truth utterances to their ASR-generated counterparts, labeling the clinical impact of any discrepancies found in two distinct doctor-patient dialogue datasets. Our analysis reveals that WER and a comprehensive suite of existing metrics correlate poorly with the clinician-assigned risk labels (No, Minimal, or Significant Impact). To bridge this evaluation gap, we introduce an LLM-as-a-Judge, programmatically optimized using GEPA to replicate expert clinical assessment. The optimized judge (Gemini-2.5-Pro) achieves human-comparable performance, obtaining 90% accuracy and a strong Cohen's $κ$ of 0.816. This work provides a validated, automated framework for moving ASR evaluation beyond simple textual fidelity to a necessary, scalable assessment of safety in clinical dialogue.

</details>


### [23] [Integrating Symbolic Natural Language Understanding and Language Models for Word Sense Disambiguation](https://arxiv.org/abs/2511.16577)
*Kexin Zhao,Ken Forbus*

Main category: cs.CL

TL;DR: 提出一种基于统计语言模型的词义消歧方法，无需人工标注训练数据，通过将符号NLU系统生成的候选含义转换为可区分的自然语言替代项，使用LLM根据上下文选择合适解释。


<details>
  <summary>Details</summary>
Motivation: 当前词义消歧方法主要针对粗粒度表示且需要人工标注训练数据，难以自动消歧更丰富的表示（如基于OpenCyc），这些表示对于复杂推理至关重要。

Method: 使用统计语言模型作为消歧预言机，将符号NLU系统生成的多个候选含义转换为可区分的自然语言替代项，通过查询LLM根据语言上下文选择合适解释，并将选定含义传播回符号NLU系统。

Result: 通过与人工标注的金标准答案对比评估，证明了该方法的有效性。

Conclusion: 该方法提供了一种无需人工标注训练数据的词义消歧解决方案，能够处理更丰富的语义表示，为复杂推理任务提供支持。

Abstract: Word sense disambiguation is a fundamental challenge in natural language understanding. Current methods are primarily aimed at coarse-grained representations (e.g. WordNet synsets or FrameNet frames) and require hand-annotated training data to construct. This makes it difficult to automatically disambiguate richer representations (e.g. built on OpenCyc) that are needed for sophisticated inference. We propose a method that uses statistical language models as oracles for disambiguation that does not require any hand-annotation of training data. Instead, the multiple candidate meanings generated by a symbolic NLU system are converted into distinguishable natural language alternatives, which are used to query an LLM to select appropriate interpretations given the linguistic context. The selected meanings are propagated back to the symbolic NLU system. We evaluate our method against human-annotated gold answers to demonstrate its effectiveness.

</details>


### [24] [Comparison of Text-Based and Image-Based Retrieval in Multimodal Retrieval Augmented Generation Large Language Model Systems](https://arxiv.org/abs/2511.16654)
*Elias Lumer,Alex Cardenas,Matt Melich,Myles Mason,Sara Dieter,Vamse Kumar Subbiah,Pradeep Honaganahalli Basavaraju,Roberto Hernandez*

Main category: cs.CL

TL;DR: 本文比较了多模态RAG系统中的两种检索方法：基于文本分块检索和直接多模态嵌入检索，发现直接多模态嵌入检索在金融文档问答中显著优于基于LLM摘要的方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM摘要的多模态RAG系统在预处理时将图像转换为文本，导致关键视觉信息和上下文丢失，影响下游检索和问答性能。

Method: 在包含40个问答对的金融财报电话会议基准上，评估了6个LLM模型和2个多模态嵌入模型，比较文本分块检索与直接多模态嵌入检索两种方法。

Result: 直接多模态嵌入检索显著优于基于LLM摘要的方法，在mAP@5和nDCG@5上分别获得13%和11%的绝对提升，相对提升分别为32%和20%。

Conclusion: LLM摘要会在预处理中引入信息损失，而直接多模态嵌入能够保留视觉上下文，为检索和推理提供更准确的结果。

Abstract: Recent advancements in Retrieval-Augmented Generation (RAG) have enabled Large Language Models (LLMs) to access multimodal knowledge bases containing both text and visual information such as charts, diagrams, and tables in financial documents. However, existing multimodal RAG systems rely on LLM-based summarization to convert images into text during preprocessing, storing only text representations in vector databases, which causes loss of contextual information and visual details critical for downstream retrieval and question answering. To address this limitation, we present a comprehensive comparative analysis of two retrieval approaches for multimodal RAG systems, including text-based chunk retrieval (where images are summarized into text before embedding) and direct multimodal embedding retrieval (where images are stored natively in the vector space). We evaluate all three approaches across 6 LLM models and a two multi-modal embedding models on a newly created financial earnings call benchmark comprising 40 question-answer pairs, each paired with 2 documents (1 image and 1 text chunk). Experimental results demonstrate that direct multimodal embedding retrieval significantly outperforms LLM-summary-based approaches, achieving absolute improvements of 13% in mean average precision (mAP@5) and 11% in normalized discounted cumulative gain. These gains correspond to relative improvements of 32% in mAP@5 and 20% in nDCG@5, providing stronger evidence of their practical impact. We additionally find that direct multimodal retrieval produces more accurate and factually consistent answers as measured by LLM-as-a-judge pairwise comparisons. We demonstrate that LLM summarization introduces information loss during preprocessing, whereas direct multimodal embeddings preserve visual context for retrieval and inference.

</details>


### [25] [Nemotron Elastic: Towards Efficient Many-in-One Reasoning LLMs](https://arxiv.org/abs/2511.16664)
*Ali Taghibakhshi,Sharath Turuvekere Sreenivas,Saurav Muralidharan,Ruisi Cai,Marcin Chochowski,Ameya Sunil Mahabaleshwarkar,Yoshi Suhara,Oluwatobi Olabiyi,Daniel Korzekwa,Mostofa Patwary,Mohammad Shoeybi,Jan Kautz,Bryan Catanzaro,Ashwath Aithal,Nima Tajbakhsh,Pavlo Molchanov*

Main category: cs.CL

TL;DR: Nemotron Elastic是一个构建推理导向LLM的框架，通过单一父模型嵌入多个嵌套子模型，实现零成本提取不同规模的模型，大幅降低训练成本。


<details>
  <summary>Details</summary>
Motivation: 传统方法训练不同规模的语言模型家族成本过高，需要为每个尺寸单独训练。现有压缩方法虽然降低成本，但仍需大量训练token。

Method: 采用混合Mamba-Attention架构，通过端到端训练的路由器和两阶段训练课程，结合组感知SSM弹性化、异质MLP弹性化、归一化MSE层重要性评估和知识蒸馏技术。

Result: 在Nemotron Nano V2 12B模型上应用，仅用110B训练token同时生成9B和6B模型，成本比从头训练降低360倍，比最先进压缩技术降低7倍。嵌套模型在准确率上达到或超过SOTA。

Conclusion: 该方法实现了多合一推理模型，部署内存与模型家族数量无关，为构建高效多尺度LLM提供了经济有效的解决方案。

Abstract: Training a family of large language models targeting multiple scales and deployment objectives is prohibitively expensive, requiring separate training runs for each different size. Recent work on model compression through pruning and knowledge distillation has reduced this cost; however, this process still incurs hundreds of billions of tokens worth of training cost per compressed model. In this paper, we present Nemotron Elastic, a framework for building reasoning-oriented LLMs, including hybrid Mamba-Attention architectures, that embed multiple nested submodels within a single parent model, each optimized for different deployment configurations and budgets. Each of these submodels shares weights with the parent model and can be extracted zero-shot during deployment without additional training or fine-tuning. We enable this functionality through an end-to-end trained router, tightly coupled to a two-stage training curriculum designed specifically for reasoning models. We additionally introduce group-aware SSM elastification that preserves Mamba's structural constraints, heterogeneous MLP elastification, normalized MSE-based layer importance for improved depth selection, and knowledge distillation enabling simultaneous multi-budget optimization. We apply Nemotron Elastic to the Nemotron Nano V2 12B model, simultaneously producing a 9B and a 6B model using only 110B training tokens; this results in over 360x cost reduction compared to training model families from scratch, and around 7x compared to SoTA compression techniques. Each of the nested models performs on par or better than the SoTA in accuracy. Moreover, unlike other compression methods, the nested capability of our approach allows having a many-in-one reasoning model that has constant deployment memory against the number of models in the family.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [26] [The Subtle Art of Defection: Understanding Uncooperative Behaviors in LLM based Multi-Agent Systems](https://arxiv.org/abs/2511.15862)
*Devang Kulshreshtha,Wanyu Du,Raghav Jain,Srikanth Doss,Hang Su,Sandesh Swamy,Yanjun Qi*

Main category: cs.MA

TL;DR: 提出了一个模拟和分析不合作行为如何破坏LLM多智能体系统稳定性的框架，包含基于博弈论的不合作行为分类法和多阶段模拟管道，在资源管理场景中验证了不合作行为会导致系统快速崩溃。


<details>
  <summary>Details</summary>
Motivation: 现有文献缺乏对不合作行为如何影响LLM多智能体系统稳定性的系统研究，需要填补这一空白来构建更鲁棒的多智能体系统。

Method: 开发了基于博弈论的不合作行为分类法，并构建了多阶段模拟管道来动态生成和优化不合作行为，在协作资源管理场景中进行评估。

Result: 框架生成真实不合作行为的准确率达96.7%；合作智能体保持100%系统稳定性，而不合作行为可在1-7轮内导致系统崩溃。

Conclusion: 不合作智能体会显著恶化集体结果，凸显了设计更具弹性的多智能体系统的必要性。

Abstract: This paper introduces a novel framework for simulating and analyzing how uncooperative behaviors can destabilize or collapse LLM-based multi-agent systems. Our framework includes two key components: (1) a game theory-based taxonomy of uncooperative agent behaviors, addressing a notable gap in the existing literature; and (2) a structured, multi-stage simulation pipeline that dynamically generates and refines uncooperative behaviors as agents' states evolve. We evaluate the framework via a collaborative resource management setting, measuring system stability using metrics such as survival time and resource overuse rate. Empirically, our framework achieves 96.7% accuracy in generating realistic uncooperative behaviors, validated by human evaluations. Our results reveal a striking contrast: cooperative agents maintain perfect system stability (100% survival over 12 rounds with 0% resource overuse), while any uncooperative behavior can trigger rapid system collapse within 1 to 7 rounds. These findings demonstrate that uncooperative agents can significantly degrade collective outcomes, highlighting the need for designing more resilient multi-agent systems.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [27] [Can MLLMs Read the Room? A Multimodal Benchmark for Assessing Deception in Multi-Party Social Interactions](https://arxiv.org/abs/2511.16221)
*Caixin Kang,Yifei Huang,Liangyang Ouyang,Mingfang Zhang,Ruicong Liu,Yoichi Sato*

Main category: cs.CV

TL;DR: 提出了多模态交互欺骗评估任务和数据集，评估了12个先进MLLM在识别欺骗方面的表现，发现即使是GPT-4o也难以可靠区分真假。设计了SoCoT推理流程和DSEM模块来提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的多模态大语言模型缺乏人类智能的核心能力：在复杂社交互动中'察言观色'和评估欺骗的能力。

Method: 引入MIDA任务和新颖的多模态数据集，建立包含12个先进MLLM的综合基准，分析失败模式，并设计SoCoT推理流程和DSEM模块。

Result: 发现显著的性能差距：即使强大模型也难以可靠区分真假，模型无法有效将语言与多模态社交线索关联，缺乏建模他人知识、信念或意图的能力。

Conclusion: 迫切需要新方法来构建更具洞察力和可信度的AI系统，提出的框架在挑战性任务上表现出性能提升，展示了构建具有真正类人社交推理能力的MLLM的新路径。

Abstract: Despite their advanced reasoning capabilities, state-of-the-art Multimodal Large Language Models (MLLMs) demonstrably lack a core component of human intelligence: the ability to `read the room' and assess deception in complex social interactions. To rigorously quantify this failure, we introduce a new task, Multimodal Interactive Deception Assessment (MIDA), and present a novel multimodal dataset providing synchronized video and text with verifiable ground-truth labels for every statement. We establish a comprehensive benchmark evaluating 12 state-of-the-art open- and closed-source MLLMs, revealing a significant performance gap: even powerful models like GPT-4o struggle to distinguish truth from falsehood reliably. Our analysis of failure modes indicates that these models fail to effectively ground language in multimodal social cues and lack the ability to model what others know, believe, or intend, highlighting the urgent need for novel approaches to building more perceptive and trustworthy AI systems. To take a step forward, we design a Social Chain-of-Thought (SoCoT) reasoning pipeline and a Dynamic Social Epistemic Memory (DSEM) module. Our framework yields performance improvement on this challenging task, demonstrating a promising new path toward building MLLMs capable of genuine human-like social reasoning.

</details>


### [28] [TimeViper: A Hybrid Mamba-Transformer Vision-Language Model for Efficient Long Video Understanding](https://arxiv.org/abs/2511.16595)
*Boshen Xu,Zihan Xiao,Jiaze Li,Jianzhong Ju,Zhenbo Luo,Jian Luan,Qin Jin*

Main category: cs.CV

TL;DR: TimeViper是一个混合视觉语言模型，采用Mamba-Transformer混合架构处理长视频理解，提出TransV模块压缩视觉token，可处理超过10,000帧的时长视频


<details>
  <summary>Details</summary>
Motivation: 处理长视频需要高效的模型架构和有效的长时序上下文处理机制，同时发现视觉token到文本token的信息聚合现象导致视觉token冗余

Method: 采用混合Mamba-Transformer骨干网络，结合状态空间模型的效率和注意力机制的表达能力，提出TransV模块将视觉token转移压缩到指令token中

Result: 在多个基准测试中与最先进模型竞争，同时扩展了处理帧数，能够处理超过10,000帧的时长视频

Conclusion: 这项工作代表了开发、解释和压缩混合Mamba-Transformer架构的初步步骤，为混合模型可解释性提供了新见解

Abstract: We introduce TimeViper, a hybrid vision-language model designed to tackle challenges of long video understanding. Processing long videos demands both an efficient model architecture and an effective mechanism for handling extended temporal contexts. To this end, TimeViper adopts a hybrid Mamba-Transformer backbone that combines the efficiency of state-space models with the expressivity of attention mechanisms. Through this hybrid design, we reveal the vision-to-text information aggregation phenomenon, where information progressively flows from vision tokens to text tokens across increasing LLM depth, resulting in severe vision token redundancy. Motivated by this observation, we propose TransV, a token information transfer module that transfers and compresses vision tokens into instruction tokens while maintaining multimodal understanding capabilities. This design enables TimeViper to process hour-long videos exceeding 10,000 frames. Extensive experiments across multiple benchmarks demonstrate that TimeViper competes with state-of-the-art models while extending frame numbers. We further analyze attention behaviors of both Mamba and Transformer layers, offering new insights into hybrid model interpretability. This work represents an initial step towards developing, interpreting, and compressing hybrid Mamba-Transformer architectures.

</details>


### [29] [SurvAgent: Hierarchical CoT-Enhanced Case Banking and Dichotomy-Based Multi-Agent System for Multimodal Survival Prediction](https://arxiv.org/abs/2511.16635)
*Guolin Huang,Wenting Chen,Jiaqi Yang,Xinheng Lyu,Xiaoling Luo,Sen Yang,Xiaohan Xing,Linlin Shen*

Main category: cs.CV

TL;DR: SurvAgent是首个用于多模态生存预测的分层思维链增强多智能体系统，通过两阶段方法整合病理图像和基因数据，在五个TCGA队列中优于传统方法、专有MLLM和医疗智能体。


<details>
  <summary>Details</summary>
Motivation: 现有生存分析方法缺乏临床采用所需的透明度，而现有病理智能体在生存预测中存在三个局限：无法整合多模态数据、无效的感兴趣区域探索、未能利用历史案例的经验学习。

Method: 两阶段方法：1) WSI-基因CoT增强案例库构建，通过低倍镜筛查、跨模态相似性感知补丁挖掘和置信度感知补丁挖掘分析病理图像，基因分层分析处理六个功能基因类别；2) 二分法多专家智能体推理，通过RAG检索相似案例，通过渐进区间细化整合多模态报告与专家预测。

Result: 在五个TCGA队列上的广泛实验证明SurvAgent优于传统方法、专有MLLM和医疗智能体。

Conclusion: 为精准肿瘤学中的可解释AI驱动生存预测建立了新范式。

Abstract: Survival analysis is critical for cancer prognosis and treatment planning, yet existing methods lack the transparency essential for clinical adoption. While recent pathology agents have demonstrated explainability in diagnostic tasks, they face three limitations for survival prediction: inability to integrate multimodal data, ineffective region-of-interest exploration, and failure to leverage experiential learning from historical cases. We introduce SurvAgent, the first hierarchical chain-of-thought (CoT)-enhanced multi-agent system for multimodal survival prediction. SurvAgent consists of two stages: (1) WSI-Gene CoT-Enhanced Case Bank Construction employs hierarchical analysis through Low-Magnification Screening, Cross-Modal Similarity-Aware Patch Mining, and Confidence-Aware Patch Mining for pathology images, while Gene-Stratified analysis processes six functional gene categories. Both generate structured reports with CoT reasoning, storing complete analytical processes for experiential learning. (2) Dichotomy-Based Multi-Expert Agent Inference retrieves similar cases via RAG and integrates multimodal reports with expert predictions through progressive interval refinement. Extensive experiments on five TCGA cohorts demonstrate SurvAgent's superority over conventional methods, proprietary MLLMs, and medical agents, establishing a new paradigm for explainable AI-driven survival prediction in precision oncology.

</details>


### [30] [Thinking-while-Generating: Interleaving Textual Reasoning throughout Visual Generation](https://arxiv.org/abs/2511.16671)
*Ziyu Guo,Renrui Zhang,Hongyu Li,Manyuan Zhang,Xinyan Chen,Sifan Wang,Yan Feng,Peng Pei,Pheng-Ann Heng*

Main category: cs.CV

TL;DR: 提出了TwiG框架，首次在视觉生成过程中实现文本推理与生成的交替进行，通过三种策略探索交替推理的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有视觉生成方法只在生成前或生成后进行文本推理，缺乏在生成过程中的多模态交互。

Method: 引入Thinking-while-Generating框架，在视觉内容逐步生成时交替进行文本推理，指导后续区域生成并反思已合成内容。研究了三种策略：零样本提示、监督微调和强化学习。

Result: 该框架能够产生更具上下文感知和语义丰富的视觉输出。

Conclusion: 这项工作为通过交替文本推理增强视觉生成的研究提供了启发。

Abstract: Recent advances in visual generation have increasingly explored the integration of reasoning capabilities. They incorporate textual reasoning, i.e., think, either before (as pre-planning) or after (as post-refinement) the generation process, yet they lack on-the-fly multimodal interaction during the generation itself. In this preliminary study, we introduce Thinking-while-Generating (TwiG), the first interleaved framework that enables co-evolving textual reasoning throughout the visual generation process. As visual content is progressively generating, textual reasoning is interleaved to both guide upcoming local regions and reflect on previously synthesized ones. This dynamic interplay produces more context-aware and semantically rich visual outputs. To unveil the potential of this framework, we investigate three candidate strategies, zero-shot prompting, supervised fine-tuning (SFT) on our curated TwiG-50K dataset, and reinforcement learning (RL) via a customized TwiG-GRPO strategy, each offering unique insights into the dynamics of interleaved reasoning. We hope this work inspires further research into interleaving textual reasoning for enhanced visual generation. Code will be released at: https://github.com/ZiyuGuo99/Thinking-while-Generating.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [31] [MiMo-Embodied: X-Embodied Foundation Model Technical Report](https://arxiv.org/abs/2511.16518)
*Xiaoshuai Hao,Lei Zhou,Zhijian Huang,Zhiwen Hou,Yingbo Tang,Lingfeng Zhang,Guang Li,Zheng Lu,Shuhuai Ren,Xianhui Meng,Yuchen Zhang,Jing Wu,Jinghui Lu,Chenxu Dang,Jiayi Guan,Jianhua Wu,Zhiyi Hou,Hanbing Li,Shumeng Xia,Mingliang Zhou,Yinan Zheng,Zihao Yue,Shuhao Gu,Hao Tian,Yuannan Shen,Jianwei Cui,Wen Zhang,Shaoqing Xu,Bing Wang,Haiyang Sun,Zeyu Zhu,Yuncheng Jiang,Zibin Guo,Chuhong Gong,Chaofan Zhang,Wenbo Ding,Kun Ma,Guang Chen,Rui Cai,Diyun Xiang,Heng Qu,Fuli Luo,Hangjun Ye,Long Chen*

Main category: cs.RO

TL;DR: MiMo-Embodied是首个在自动驾驶和具身AI领域都取得最先进性能的跨具身基础模型，在29个基准测试中创下新记录。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够同时处理自动驾驶和具身AI任务的统一基础模型，探索这两个领域之间的正迁移效应。

Method: 采用多阶段学习、精心构建的数据集以及思维链/强化学习微调方法。

Result: 在17个具身AI基准测试（任务规划、功能预测、空间理解）和12个自动驾驶基准测试（环境感知、状态预测、驾驶规划）中均创下新记录，显著超越现有开源、闭源和专用基线模型。

Conclusion: 通过多阶段学习、数据构建和微调方法，自动驾驶和具身AI领域展现出强烈的正迁移效应，能够相互促进。模型设计和训练方法已开源以促进进一步研究。

Abstract: We open-source MiMo-Embodied, the first cross-embodied foundation model to successfully integrate and achieve state-of-the-art performance in both Autonomous Driving and Embodied AI. MiMo-Embodied sets new records across 17 embodied AI benchmarks in Task Planning, Affordance Prediction and Spatial Understanding, while also excelling in 12 autonomous driving benchmarks across Environmental Perception, Status Prediction, and Driving Planning. Across these tasks, MiMo-Embodied significantly outperforms existing open-source, closed-source, and specialized baselines. Our results indicate that through multi-stage learning, curated data construction, and CoT/RL fine-tuning, these two domains exhibit strong positive transfer and mutually reinforce one another. We provide a detailed analysis of our model design and training methodologies to facilitate further research. Code and models are available at https://github.com/XiaomiMiMo/MiMo-Embodied.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [32] [PSM: Prompt Sensitivity Minimization via LLM-Guided Black-Box Optimization](https://arxiv.org/abs/2511.16209)
*Huseein Jawad,Nicolas Brunel*

Main category: cs.CR

TL;DR: 本文提出了一种通过shield appending来强化系统提示的新框架，将提示硬化形式化为效用约束优化问题，使用LLM作为优化器搜索最佳防护层，在保持任务效用的同时最小化提示泄露风险。


<details>
  <summary>Details</summary>
Motivation: 系统提示包含专有逻辑和敏感信息，容易受到提取攻击，现有防御机制要么依赖启发式方法，要么计算开销大，要么不适用于黑盒API访问的模型。

Method: 采用shield appending方法，在原始提示上添加保护性文本层，使用LLM-as-optimizer搜索可能的SHIELDs，最小化基于对抗攻击套件的泄露指标，同时保持任务效用高于指定阈值。

Result: 优化的SHIELDs显著减少了对全面提取攻击的提示泄露，优于现有基线防御方法，且不损害模型的预期功能。

Conclusion: 这项工作为在LLM安全不断升级的背景下开发鲁棒、效用感知的防御提供了范例。

Abstract: System prompts are critical for guiding the behavior of Large Language Models (LLMs), yet they often contain proprietary logic or sensitive information, making them a prime target for extraction attacks. Adversarial queries can successfully elicit these hidden instructions, posing significant security and privacy risks. Existing defense mechanisms frequently rely on heuristics, incur substantial computational overhead, or are inapplicable to models accessed via black-box APIs. This paper introduces a novel framework for hardening system prompts through shield appending, a lightweight approach that adds a protective textual layer to the original prompt. Our core contribution is the formalization of prompt hardening as a utility-constrained optimization problem. We leverage an LLM-as-optimizer to search the space of possible SHIELDs, seeking to minimize a leakage metric derived from a suite of adversarial attacks, while simultaneously preserving task utility above a specified threshold, measured by semantic fidelity to baseline outputs. This black-box, optimization-driven methodology is lightweight and practical, requiring only API access to the target and optimizer LLMs. We demonstrate empirically that our optimized SHIELDs significantly reduce prompt leakage against a comprehensive set of extraction attacks, outperforming established baseline defenses without compromising the model's intended functionality. Our work presents a paradigm for developing robust, utility-aware defenses in the escalating landscape of LLM security. The code is made public on the following link: https://github.com/psm-defense/psm

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [33] [Chain of Summaries: Summarization Through Iterative Questioning](https://arxiv.org/abs/2511.15719)
*William Brach,Lukas Galke Poech*

Main category: cs.AI

TL;DR: 提出Chain of Summaries (CoS)方法，通过类黑格尔辩证法的迭代过程生成信息密集的通用摘要，解决LLM处理网页内容时的格式不友好和上下文长度限制问题。


<details>
  <summary>Details</summary>
Motivation: LLMs越来越多地使用外部网页内容，但这些内容由于格式不友好和上下文长度限制而难以被LLMs有效消化。

Method: CoS方法：基于黑格尔辩证法，通过初始摘要（正题）、质疑识别局限性（反题）、生成通用摘要（合题）的迭代过程，创建能满足当前和未来信息需求的通用摘要。

Result: 在TriviaQA、TruthfulQA和SQUAD数据集上，CoS比零样本LLM基线提升66%，比专业摘要方法BRIO和PEGASUS提升27%。CoS生成的摘要用更少token获得更高Q&A性能，且与下游LLM无关。

Conclusion: CoS为网站维护者提供了一种使内容更易于LLM访问的吸引人选项，同时保留了人工监督的可能性。

Abstract: Large Language Models (LLMs) are increasingly using external web content. However, much of this content is not easily digestible by LLMs due to LLM-unfriendly formats and limitations of context length. To address this issue, we propose a method for generating general-purpose, information-dense summaries that act as plain-text repositories of web content. Inspired by Hegel's dialectical method, our approach, denoted as Chain of Summaries (CoS), iteratively refines an initial summary (thesis) by identifying its limitations through questioning (antithesis), leading to a general-purpose summary (synthesis) that can satisfy current and anticipate future information needs. Experiments on the TriviaQA, TruthfulQA, and SQUAD datasets demonstrate that CoS outperforms zero-shot LLM baselines by up to 66% and specialized summarization methods such as BRIO and PEGASUS by up to 27%. CoS-generated summaries yield higher Q&A performance compared to the source content, while requiring substantially fewer tokens and being agnostic to the specific downstream LLM. CoS thus resembles an appealing option for website maintainers to make their content more accessible for LLMs, while retaining possibilities for human oversight.

</details>


### [34] [Step-Audio-R1 Technical Report](https://arxiv.org/abs/2511.15848)
*Fei Tian,Xiangyu Tony Zhang,Yuxin Zhang,Haoyang Zhang,Yuxin Li,Daijiao Liu,Yayue Deng,Donghang Wu,Jun Chen,Liang Zhao,Chengyuan Yao,Hexin Liu,Eng Siong Chng,Xuerui Yang,Xiangyu Zhang,Daxin Jiang,Gang Yu*

Main category: cs.AI

TL;DR: Step-Audio-R1是首个成功解锁音频推理能力的模型，通过模态接地推理蒸馏框架，在音频理解基准测试中超越Gemini 2.5 Pro，性能媲美Gemini 3 Pro。


<details>
  <summary>Details</summary>
Motivation: 解决音频语言模型中存在的困惑现象：推理越少性能越好，探索音频智能是否真正能从深思熟虑中受益。

Method: 提出模态接地推理蒸馏框架，让模型学习生成与音频特征真正相关的推理链，而不是产生脱节的思考。

Result: 模型在涵盖语音、环境声音和音乐的综合音频理解和推理基准测试中表现出强大的音频推理能力。

Conclusion: 推理是跨模态可转移的能力，当适当锚定时，扩展思考可以从负担转变为音频智能的强大资产。

Abstract: Recent advances in reasoning models have demonstrated remarkable success in text and vision domains through extended chain-of-thought deliberation. However, a perplexing phenomenon persists in audio language models: they consistently perform better with minimal or no reasoning, raising a fundamental question - can audio intelligence truly benefit from deliberate thinking? We introduce Step-Audio-R1, the first audio reasoning model that successfully unlocks reasoning capabilities in the audio domain. Through our proposed Modality-Grounded Reasoning Distillation (MGRD) framework, Step-Audio-R1 learns to generate audio-relevant reasoning chains that genuinely ground themselves in acoustic features rather than hallucinating disconnected deliberations. Our model exhibits strong audio reasoning capabilities, surpassing Gemini 2.5 Pro and achieving performance comparable to the state-of-the-art Gemini 3 Pro across comprehensive audio understanding and reasoning benchmarks spanning speech, environmental sounds, and music. These results demonstrate that reasoning is a transferable capability across modalities when appropriately anchored, transforming extended deliberation from a liability into a powerful asset for audio intelligence. By establishing the first successful audio reasoning model, Step-Audio-R1 opens new pathways toward building truly multimodal reasoning systems that think deeply across all sensory modalities.

</details>


### [35] [JudgeBoard: Benchmarking and Enhancing Small Language Models for Reasoning Evaluation](https://arxiv.org/abs/2511.15958)
*Zhenyu Bi,Gaurav Srivastava,Yang Li,Meng Lu,Swastik Roy,Morteza Ziyadi,Xuan Wang*

Main category: cs.AI

TL;DR: JudgeBoard是一个新的评估框架，直接查询模型来评估答案正确性，无需额外答案比较。通过多智能体评判(MAJ)框架，使用多个小型语言模型协作达到接近大型语言模型的判断准确度。


<details>
  <summary>Details</summary>
Motivation: 现有LLM-as-a-judge框架依赖答案与真实标签或其他答案的比较，这种方法间接且难以完全自动化，对推理输出的细粒度可扩展评估支持有限。

Method: 提出JudgeBoard评估管道，直接查询模型评估答案正确性；构建任务特定评估排行榜；提出MAJ多智能体评估框架，利用多个具有不同推理特征的SLM通过协作审议来近似LLM级判断准确度。

Result: 实验显示SLM和LLM在独立判断任务中存在显著性能差距，但MAJ框架显著提高了SLM的可靠性和一致性。在MATH数据集上，使用较小模型作为骨干的MAJ表现与较大模型相当甚至更好。

Conclusion: 多智能体SLM系统在判断任务中可能匹配或超越LLM性能，对可扩展和高效评估具有重要意义。

Abstract: While small language models (SLMs) have shown promise on various reasoning tasks, their ability to judge the correctness of answers remains unclear compared to large language models (LLMs). Prior work on LLM-as-a-judge frameworks typically relies on comparing candidate answers against ground-truth labels or other candidate answers using predefined metrics like entailment. However, this approach is inherently indirect and difficult to fully automate, offering limited support for fine-grained and scalable evaluation of reasoning outputs. In this work, we propose JudgeBoard, a novel evaluation pipeline that directly queries models to assess the correctness of candidate answers without requiring extra answer comparisons. We focus on two core reasoning domains: mathematical reasoning and science/commonsense reasoning, and construct task-specific evaluation leaderboards using both accuracy-based ranking and an Elo-based rating system across five benchmark datasets, enabling consistent model comparison as judges rather than comparators. To improve judgment performance in lightweight models, we propose MAJ (Multi-Agent Judging), a novel multi-agent evaluation framework that leverages multiple interacting SLMs with distinct reasoning profiles to approximate LLM-level judgment accuracy through collaborative deliberation. Experimental results reveal a significant performance gap between SLMs and LLMs in isolated judging tasks. However, our MAJ framework substantially improves the reliability and consistency of SLMs. On the MATH dataset, MAJ using smaller-sized models as backbones performs comparatively well or even better than their larger-sized counterparts. Our findings highlight that multi-agent SLM systems can potentially match or exceed LLM performance in judgment tasks, with implications for scalable and efficient assessment.

</details>


### [36] [CARE-RAG - Clinical Assessment and Reasoning in RAG](https://arxiv.org/abs/2511.15994)
*Deepthi Potluri,Aby Mammen Mathew,Jeffrey B DeWitt,Alexander L. Rasgon,Yide Hao,Junyuan Hong,Ying Ding*

Main category: cs.AI

TL;DR: 该论文研究了LLMs在获取正确证据后仍无法正确推理的问题，特别是在临床环境中。作者使用书面暴露疗法指南作为测试平台，提出了评估推理准确性、一致性和忠实度的框架。


<details>
  <summary>Details</summary>
Motivation: 在临床环境中，即使LLMs获取了正确的证据，其推理输出仍可能不符合结构化协议，这种检索与推理之间的差距存在严重风险。

Method: 使用书面暴露疗法指南作为测试平台，评估模型对临床医生验证问题的响应，提出评估推理准确性、一致性和忠实度的框架。

Result: 即使提供权威段落，模型错误仍然存在。检索增强生成可以约束输出，但安全部署需要同等严格地评估推理过程。

Conclusion: 在临床环境中部署LLMs时，需要像严格评估检索一样严格评估推理过程，以确保输出安全可靠。

Abstract: Access to the right evidence does not guarantee that large language models (LLMs) will reason with it correctly. This gap between retrieval and reasoning is especially concerning in clinical settings, where outputs must align with structured protocols. We study this gap using Written Exposure Therapy (WET) guidelines as a testbed. In evaluating model responses to curated clinician-vetted questions, we find that errors persist even when authoritative passages are provided. To address this, we propose an evaluation framework that measures accuracy, consistency, and fidelity of reasoning. Our results highlight both the potential and the risks: retrieval-augmented generation (RAG) can constrain outputs, but safe deployment requires assessing reasoning as rigorously as retrieval.

</details>


### [37] [SpellForger: Prompting Custom Spell Properties In-Game using BERT supervised-trained model](https://arxiv.org/abs/2511.16018)
*Emanuel C. Silva,Emily S. M. Salum,Gabriel M. Arantes,Matheus P. Pereira,Vinicius F. Oliveira,Alessandro L. Bicho*

Main category: cs.AI

TL;DR: SpellForger是一款让玩家通过自然语言提示创建自定义法术的游戏，使用BERT模型解析文本描述并映射到法术模板，在Unity中开发，旨在验证AI作为核心游戏机制的应用。


<details>
  <summary>Details</summary>
Motivation: 探索AI作为游戏玩法共同创造工具的应用，目前这方面研究不足，旨在提供个性化和创造性的独特游戏体验。

Method: 使用监督训练的BERT模型解释玩家提示，将文本描述映射到法术模板并平衡参数（伤害、成本、效果），在Unity游戏引擎中开发，AI后端使用Python。

Result: 预期交付一个功能原型，能够实时生成法术并应用于吸引人的游戏循环中，使玩家创造力成为体验的核心。

Conclusion: 该研究验证了AI作为直接游戏机制的有效性，展示了自然语言处理在游戏内容生成中的潜力。

Abstract: Introduction: The application of Artificial Intelligence in games has evolved significantly, allowing for dynamic content generation. However, its use as a core gameplay co-creation tool remains underexplored. Objective: This paper proposes SpellForger, a game where players create custom spells by writing natural language prompts, aiming to provide a unique experience of personalization and creativity. Methodology: The system uses a supervisedtrained BERT model to interpret player prompts. This model maps textual descriptions to one of many spell prefabs and balances their parameters (damage, cost, effects) to ensure competitive integrity. The game is developed in the Unity Game Engine, and the AI backend is in Python. Expected Results: We expect to deliver a functional prototype that demonstrates the generation of spells in real time, applied to an engaging gameplay loop, where player creativity is central to the experience, validating the use of AI as a direct gameplay mechanic.

</details>


### [38] [OpenMMReasoner: Pushing the Frontiers for Multimodal Reasoning with an Open and General Recipe](https://arxiv.org/abs/2511.16334)
*Kaichen Zhang,Keming Wu,Zuhao Yang,Kairui Hu,Bin Wang,Ziwei Liu,Xingxuan Li,Lidong Bing*

Main category: cs.AI

TL;DR: OpenMMReasoner是一个完全透明的两阶段多模态推理训练方法，包含监督微调(SFT)和强化学习(RL)阶段，在9个多模态推理基准上比Qwen2.5-VL-7B-Instruct基线提升11.6%。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉推理领域取得了显著进展，但缺乏透明和可复现的数据整理和训练策略仍然是可扩展研究的主要障碍。

Method: 提出两阶段训练方法：SFT阶段使用87.4万样本的冷启动数据集进行逐步验证；RL阶段使用7.4万样本跨多个领域进一步优化和稳定推理能力。

Result: 在9个多模态推理基准上比Qwen2.5-VL-7B-Instruct基线提升11.6%，证明了数据质量和训练设计对多模态推理性能的关键作用。

Conclusion: 该训练方法不仅超越了强基线，还为未来大规模多模态推理研究奠定了坚实的实证基础，所有代码、流程和数据均已开源。

Abstract: Recent advancements in large reasoning models have fueled growing interest in extending such capabilities to multimodal domains. However, despite notable progress in visual reasoning, the lack of transparent and reproducible data curation and training strategies remains a major barrier to scalable research. In this work, we introduce OpenMMReasoner, a fully transparent two-stage recipe for multimodal reasoning spanning supervised fine-tuning (SFT) and reinforcement learning (RL). In the SFT stage, we construct an 874K-sample cold-start dataset with rigorous step-by-step validation, providing a strong foundation for reasoning capabilities. The subsequent RL stage leverages a 74K-sample dataset across diverse domains to further sharpen and stabilize these abilities, resulting in a more robust and efficient learning process. Extensive evaluations demonstrate that our training recipe not only surpasses strong baselines but also highlights the critical role of data quality and training design in shaping multimodal reasoning performance. Notably, our method achieves a 11.6% improvement over the Qwen2.5-VL-7B-Instruct baseline across nine multimodal reasoning benchmarks, establishing a solid empirical foundation for future large-scale multimodal reasoning research. We open-sourced all our codes, pipeline, and data at https://github.com/EvolvingLMMs-Lab/OpenMMReasoner.

</details>


### [39] [TOFA: Training-Free One-Shot Federated Adaptation for Vision-Language Models](https://arxiv.org/abs/2511.16423)
*Li Zhang,Zhongxuan Han,XiaoHua Feng,Jiaming Zhang,Yuyuan Li,Linbo Jiang,Jianan Lin,Chaochao Chen*

Main category: cs.AI

TL;DR: 提出了TOFA框架，一种无需训练的单次联邦视觉语言模型适配方法，通过视觉和文本双管道充分挖掘多模态信息，解决了现有方法在数据异构性处理和资源消耗方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有联邦视觉语言模型适配方法需要多次迭代训练，通信成本高且易受攻击。单次联邦训练技术虽能减少通信轮次，但在多模态信息利用、数据异构性处理和额外训练资源需求方面存在不足。

Method: TOFA采用无需训练的双管道方法：视觉管道使用分层贝叶斯模型学习个性化类别原型分布；文本管道评估并全局对齐本地文本提示。引入自适应权重校准机制平衡个性化和鲁棒性。

Result: 在9个数据集上的广泛实验表明，TOFA在各种联邦设置下均表现出色，有效解决了数据异构性问题且无需额外训练资源。

Conclusion: TOFA是一种高效、轻量级的单次联邦视觉语言模型适配框架，能够充分利用预训练模型的多模态特征，在无需额外训练的情况下有效处理数据异构性挑战。

Abstract: Efficient and lightweight adaptation of pre-trained Vision-Language Models (VLMs) to downstream tasks through collaborative interactions between local clients and a central server is a rapidly emerging research topic in federated learning. Existing adaptation algorithms are typically trained iteratively, which incur significant communication costs and increase the susceptibility to potential attacks. Motivated by the one-shot federated training techniques that reduce client-server exchanges to a single round, developing a lightweight one-shot federated VLM adaptation method to alleviate these issues is particularly attractive. However, current one-shot approaches face certain challenges in adapting VLMs within federated settings: (1) insufficient exploitation of the rich multimodal information inherent in VLMs; (2) lack of specialized adaptation strategies to systematically handle the severe data heterogeneity; and (3) requiring additional training resource of clients or server. To bridge these gaps, we propose a novel Training-free One-shot Federated Adaptation framework for VLMs, named TOFA. To fully leverage the generalizable multimodal features in pre-trained VLMs, TOFA employs both visual and textual pipelines to extract task-relevant representations. In the visual pipeline, a hierarchical Bayesian model learns personalized, class-specific prototype distributions. For the textual pipeline, TOFA evaluates and globally aligns the generated local text prompts for robustness. An adaptive weight calibration mechanism is also introduced to combine predictions from both modalities, balancing personalization and robustness to handle data heterogeneity. Our method is training-free, not relying on additional training resources on either the client or server side. Extensive experiments across 9 datasets in various federated settings demonstrate the effectiveness of the proposed TOFA method.

</details>


### [40] [D-GARA: A Dynamic Benchmarking Framework for GUI Agent Robustness in Real-World Anomalies](https://arxiv.org/abs/2511.16590)
*Sen Chen,Tong Zhao,Yi Bin,Fei Ma,Wenqi Shao,Zheng Wang*

Main category: cs.AI

TL;DR: D-GARA是一个动态基准测试框架，用于评估Android GUI代理在真实世界异常情况下的鲁棒性，填补了现有静态数据集无法反映现实环境复杂性的研究空白。


<details>
  <summary>Details</summary>
Motivation: 现有GUI代理训练和评估数据集多为静态理想化环境，无法反映真实世界中异常情况的复杂性和不可预测性，需要开发能够评估代理在异常环境下鲁棒性的基准测试框架。

Method: 提出D-GARA动态基准测试框架，引入多种真实世界异常类型（如权限对话框、电池警告、更新提示等），构建包含常用Android应用和嵌入异常的基准数据集。

Result: 实验表明，最先进的GUI代理在异常丰富的环境中性能显著下降，凸显了鲁棒性学习的重要性。

Conclusion: D-GARA是模块化和可扩展的框架，支持无缝集成新任务、异常类型和交互场景，为GUI代理的鲁棒性评估提供了重要工具。

Abstract: Developing intelligent agents capable of operating a wide range of Graphical User Interfaces (GUIs) with human-level proficiency is a key milestone on the path toward Artificial General Intelligence. While most existing datasets and benchmarks for training and evaluating GUI agents are static and idealized, failing to reflect the complexity and unpredictability of real-world environments, particularly the presence of anomalies. To bridge this research gap, we propose D-GARA, a dynamic benchmarking framework, to evaluate Android GUI agent robustness in real-world anomalies. D-GARA introduces a diverse set of real-world anomalies that GUI agents commonly face in practice, including interruptions such as permission dialogs, battery warnings, and update prompts. Based on D-GARA framework, we construct and annotate a benchmark featuring commonly used Android applications with embedded anomalies to support broader community research. Comprehensive experiments and results demonstrate substantial performance degradation in state-of-the-art GUI agents when exposed to anomaly-rich environments, highlighting the need for robustness-aware learning. D-GARA is modular and extensible, supporting the seamless integration of new tasks, anomaly types, and interaction scenarios to meet specific evaluation goals.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [41] [AccelOpt: A Self-Improving LLM Agentic System for AI Accelerator Kernel Optimization](https://arxiv.org/abs/2511.15915)
*Genghan Zhang,Shaowei Zhu,Anjiang Wei,Zhenyu Song,Allen Nie,Zhen Jia,Nandita Vijaykumar,Yida Wang,Kunle Olukotun*

Main category: cs.LG

TL;DR: AccelOpt是一个自改进的LLM代理系统，能够自主优化新兴AI加速器的内核，无需专家提供的硬件特定优化知识。通过迭代生成和优化记忆机制，系统性能随时间提升，在Trainium加速器上显著提高吞吐量峰值百分比，且成本效益极高。


<details>
  <summary>Details</summary>
Motivation: 解决新兴AI加速器内核优化需要大量专家知识和手动调优的问题，实现自动化、自适应的内核优化系统。

Method: 使用自改进的LLM代理系统，通过迭代生成探索内核优化空间，结合优化记忆机制记录和利用先前的优化经验。

Result: 在Trainium 1上平均峰值吞吐量从49%提升到61%，在Trainium 2上从45%提升到59%；使用开源模型达到与Claude Sonnet 4相同的改进效果，但成本降低26倍。

Conclusion: AccelOpt证明了自改进LLM系统能够有效自动化AI加速器内核优化，显著提升性能同时大幅降低成本。

Abstract: We present AccelOpt, a self-improving large language model (LLM) agentic system that autonomously optimizes kernels for emerging AI acclerators, eliminating the need for expert-provided hardware-specific optimization knowledge. AccelOpt explores the kernel optimization space through iterative generation, informed by an optimization memory that curates experiences and insights from previously encountered slow-fast kernel pairs. We build NKIBench, a new benchmark suite of AWS Trainium accelerator kernels with varying complexity extracted from real-world LLM workloads to evaluate the effectiveness of AccelOpt. Our evaluation confirms that AccelOpt's capability improves over time, boosting the average percentage of peak throughput from $49\%$ to $61\%$ on Trainium 1 and from $45\%$ to $59\%$ on Trainium 2 for NKIBench kernels. Moreover, AccelOpt is highly cost-effective: using open-source models, it matches the kernel improvements of Claude Sonnet 4 while being $26\times$ cheaper.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [42] [Codec2Vec: Self-Supervised Speech Representation Learning Using Neural Speech Codecs](https://arxiv.org/abs/2511.16639)
*Wei-Cheng Tseng,David Harwath*

Main category: eess.AS

TL;DR: Codec2Vec是首个基于离散音频编解码单元的语音表示学习框架，在SUPERB基准测试中表现优异，同时显著降低存储需求和训练时间。


<details>
  <summary>Details</summary>
Motivation: 探索神经音频编解码器作为通用声学特征提取器的潜力，为更广泛的语音处理任务提供高效解决方案。

Method: 使用离散音频编解码单元进行掩码预测，采用多种训练目标推导策略来验证框架有效性。

Result: 在SUPERB基准测试中达到与连续输入模型相当的竞争性性能，存储需求降低16.5倍，训练时间减少2.3倍。

Conclusion: Codec2Vec展示了离散音频编解码单元在语音表示学习中的高效性和可扩展性，为语音处理任务提供了更优的解决方案。

Abstract: Recent advancements in neural audio codecs have not only enabled superior audio compression but also enhanced speech synthesis techniques. Researchers are now exploring their potential as universal acoustic feature extractors for a broader range of speech processing tasks. Building on this trend, we introduce Codec2Vec, the first speech representation learning framework that relies exclusively on discrete audio codec units. This approach offers several advantages, including improved data storage and transmission efficiency, faster training, and enhanced data privacy. We explore masked prediction with various training target derivation strategies to thoroughly understand the effectiveness of this framework. Evaluated on the SUPERB benchmark, Codec2Vec achieves competitive performance compared to continuous-input models while reducing storage requirements by up to 16.5x and training time by 2.3x, showcasing its scalability and efficiency.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [43] [QueryGym: A Toolkit for Reproducible LLM-Based Query Reformulation](https://arxiv.org/abs/2511.15996)
*Amin Bigdeli,Radin Hamidi Rad,Mert Incesu,Negar Arabzadeh,Charles L. A. Clarke,Ebrahim Bagheri*

Main category: cs.IR

TL;DR: QueryGym是一个轻量级、可扩展的Python工具包，为基于大语言模型的查询重构提供统一框架，解决现有方法实现分散、难以公平比较的问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的查询重构方法实现分散，缺乏统一工具包，阻碍了公平比较、快速实验、一致基准测试和可靠部署。

Method: 提供Python API支持多种LLM方法、检索无关接口、集中式提示管理系统、内置基准测试支持，以及完全开源的可扩展实现。

Result: 开发了QueryGym工具包，统一实现了LLM查询重构方法，支持与Pyserini和PyTerrier等后端集成。

Conclusion: QueryGym填补了LLM查询重构领域缺乏统一工具包的空白，为研究人员提供了公平比较和快速实验的平台。

Abstract: We present QueryGym, a lightweight, extensible Python toolkit that supports large language model (LLM)-based query reformulation. This is an important tool development since recent work on llm-based query reformulation has shown notable increase in retrieval effectiveness. However, while different authors have sporadically shared the implementation of their methods, there is no unified toolkit that provides a consistent implementation of such methods, which hinders fair comparison, rapid experimentation, consistent benchmarking and reliable deployment. QueryGym addresses this gap by providing a unified framework for implementing, executing, and comparing llm-based reformulation methods. The toolkit offers: (1) a Python API for applying diverse LLM-based methods, (2) a retrieval-agnostic interface supporting integration with backends such as Pyserini and PyTerrier, (3) a centralized prompt management system with versioning and metadata tracking, (4) built-in support for benchmarks like BEIR and MS MARCO, and (5) a completely open-source extensible implementation available to all researchers. QueryGym is publicly available at https://github.com/radinhamidi/QueryGym.

</details>


### [44] [Music Recommendation with Large Language Models: Challenges, Opportunities, and Evaluation](https://arxiv.org/abs/2511.16478)
*Elena V. Epure,Yashar Deldjoo,Bruno Sguerra,Markus Schedl,Manuel Moussallam*

Main category: cs.IR

TL;DR: 论文认为LLM驱动的音乐推荐系统需要重新思考评估方法，传统的信息检索框架和准确性指标不再适用，需要从NLP领域借鉴评估实践并建立新的成功和风险维度。


<details>
  <summary>Details</summary>
Motivation: 传统音乐推荐系统基于信息检索框架，主要依赖准确性指标，但无法回答"什么是好的推荐"这一根本问题。LLM的出现颠覆了这一框架，因为它们是生成式而非排序式，传统评估方法难以适用。

Method: 首先回顾LLM如何重塑音乐推荐中的用户建模、物品建模和自然语言推荐；然后借鉴NLP领域的评估实践；最后通过LLM提示技术为MRS制定结构化的成功和风险维度。

Result: 提出了一个更新的、教学性的、跨学科的评估视角，为MRS社区提供了适应LLM时代的评估框架。

Conclusion: LLM驱动的音乐推荐系统需要根本性地重新思考评估方法，传统的信息检索框架已不再适用，需要建立新的评估范式来应对生成式模型带来的挑战和机遇。

Abstract: Music Recommender Systems (MRS) have long relied on an information-retrieval framing, where progress is measured mainly through accuracy on retrieval-oriented subtasks. While effective, this reductionist paradigm struggles to address the deeper question of what makes a good recommendation, and attempts to broaden evaluation, through user studies or fairness analyses, have had limited impact. The emergence of Large Language Models (LLMs) disrupts this framework: LLMs are generative rather than ranking-based, making standard accuracy metrics questionable. They also introduce challenges such as hallucinations, knowledge cutoffs, non-determinism, and opaque training data, rendering traditional train/test protocols difficult to interpret. At the same time, LLMs create new opportunities, enabling natural-language interaction and even allowing models to act as evaluators.
  This work argues that the shift toward LLM-driven MRS requires rethinking evaluation. We first review how LLMs reshape user modeling, item modeling, and natural-language recommendation in music. We then examine evaluation practices from NLP, highlighting methodologies and open challenges relevant to MRS. Finally, we synthesize insights-focusing on how LLM prompting applies to MRS, to outline a structured set of success and risk dimensions. Our goal is to provide the MRS community with an updated, pedagogical, and cross-disciplinary perspective on evaluation.

</details>


### [45] [The Oracle and The Prism: A Decoupled and Efficient Framework for Generative Recommendation Explanation](https://arxiv.org/abs/2511.16543)
*Jiaheng Zhang,Daqiang Zhang*

Main category: cs.IR

TL;DR: 提出Prism框架，将推荐系统解耦为独立的排序阶段和解释生成阶段，使用知识蒸馏方法让紧凑的学生模型专门生成个性化解释，在保持高质量的同时大幅提升效率。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在可解释推荐系统中存在的性能-效率权衡问题，避免端到端架构中排序和解释联合优化导致的次优妥协。

Method: 采用解耦框架，使用强大的教师LLM作为Oracle生成高保真解释知识，然后让经过微调的紧凑学生模型专门合成个性化解释，实现组件专业化优化。

Result: 140M参数的Prism模型在忠实度和个性化的人类评估中显著优于11B参数的教师模型，推理速度提升24倍，内存消耗减少10倍。

Conclusion: 解耦结合定向蒸馏为高质量可解释推荐提供了高效有效的途径，证明了专业化组件优化的优势。

Abstract: The integration of Large Language Models (LLMs) into explainable recommendation systems often leads to a performance-efficiency trade-off in end-to-end architectures, where joint optimization of ranking and explanation can result in suboptimal compromises. To resolve this, we propose Prism, a novel decoupled framework that rigorously separates the recommendation process into a dedicated ranking stage and an explanation generation stage.
  Inspired by knowledge distillation, Prism leverages a powerful teacher LLM (e.g., FLAN-T5-XXL) as an Oracle to produce high-fidelity explanatory knowledge. A compact, fine-tuned student model (e.g., BART-Base), the Prism, then specializes in synthesizing this knowledge into personalized explanations. This decomposition ensures that each component is optimized for its specific objective, eliminating inherent conflicts in coupled models.
  Extensive experiments on benchmark datasets demonstrate that our 140M-parameter Prism model significantly outperforms its 11B-parameter teacher in human evaluations of faithfulness and personalization, while achieving a 24 times speedup and a 10 times reduction in memory consumption during inference. These results validate that decoupling, coupled with targeted distillation, provides an efficient and effective pathway to high-quality explainable recommendation.

</details>
