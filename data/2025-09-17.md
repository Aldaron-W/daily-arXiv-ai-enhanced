<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 45]
- [cs.AI](#cs.AI) [Total: 6]
- [cs.RO](#cs.RO) [Total: 2]
- [cs.CR](#cs.CR) [Total: 2]
- [cs.HC](#cs.HC) [Total: 2]
- [cs.SI](#cs.SI) [Total: 1]
- [cs.CE](#cs.CE) [Total: 1]
- [cs.LG](#cs.LG) [Total: 6]
- [quant-ph](#quant-ph) [Total: 1]
- [cs.IR](#cs.IR) [Total: 2]
- [cs.CV](#cs.CV) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [MTEB-NL and E5-NL: Embedding Benchmark and Models for Dutch](https://arxiv.org/abs/2509.12340)
*Nikolay Banar,Ehsan Lotfi,Jens Van Nooten,Cristina Arhiliuc,Marija Kliocaite,Walter Daelemans*

Main category: cs.CL

TL;DR: 为解决荷兰语在多语言嵌入资源中代表性不足的问题，研究团队发布了MTEB-NL评测基准、训练数据集和E5-NL嵌入模型系列，以促进荷兰语嵌入技术的发展。


<details>
  <summary>Details</summary>
Motivation: 荷兰语在多语言嵌入资源（模型、基准测试和数据集）中代表性不足，通常只占很小的比例，需要补上这个空白并鼓励荷兰语嵌入技术的进一步发展。

Method: 1. 构建MTEB-NL评测基准，包含现有荷兰语数据集和新创建的数据集，覆盖广泛的任务范围
2. 提供训练数据集，编诒自可用的荷兰语检索数据集，并通过大语言模型生成合成数据来扩展任务覆盖范围
3. 发布E5-NL模型系列，这是一组简洁但高效的嵌入模型

Result: 开发了完整的荷兰语嵌入评估与生成资源，包括MTEB-NL评测基准、训练数据集和E5-NL模型系列。这些资源已通过Hugging Face Hub和MTEB包公开发布。

Conclusion: 该研究有效地解决了荷兰语在多语言嵌入资源中的代表性问题，为荷兰语嵌入技术的发展提供了重要的评估工具、训练数据和基础模型，将有力地鼓励该领域的进一步研究和应用。

Abstract: Recently, embedding resources, including models, benchmarks, and datasets,
have been widely released to support a variety of languages. However, the Dutch
language remains underrepresented, typically comprising only a small fraction
of the published multilingual resources. To address this gap and encourage the
further development of Dutch embeddings, we introduce new resources for their
evaluation and generation. First, we introduce the Massive Text Embedding
Benchmark for Dutch (MTEB-NL), which includes both existing Dutch datasets and
newly created ones, covering a wide range of tasks. Second, we provide a
training dataset compiled from available Dutch retrieval datasets, complemented
with synthetic data generated by large language models to expand task coverage
beyond retrieval. Finally, we release a series of E5-NL models compact yet
efficient embedding models that demonstrate strong performance across multiple
tasks. We make our resources publicly available through the Hugging Face Hub
and the MTEB package.

</details>


### [2] [MORABLES: A Benchmark for Assessing Abstract Moral Reasoning in LLMs with Fables](https://arxiv.org/abs/2509.12371)
*Matteo Marcuzzo,Alessandro Zangari,Andrea Albarelli,Jose Camacho-Collados,Mohammad Taher Pilehvar*

Main category: cs.CL

TL;DR: MORABLES是一个基于寓言和短篇故事的人类验证基准测试，用于评估LLM的道德推理能力，发现即使大模型也容易受到对抗性攻击，存在显著的自相矛盾问题。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在标准阅读理解基准上表现出色，需要评估它们在复杂抽象推理和推理方面的能力。基于文学的基准测试以其丰富的叙事和道德深度，为评估更深层次的理解技能提供了有说服力的框架。

Method: 构建MORABLES基准测试，包含从历史文学中提取的寓言和短篇故事，采用多项选择题形式针对道德推理，并设计精心制作的干扰项。还引入了对抗性变体来测试模型鲁棒性。

Result: 研究发现，虽然大模型表现优于小模型，但它们仍然容易受到对抗性操纵，经常依赖表面模式而非真正的道德推理。最佳模型在大约20%的情况下会自我反驳答案。推理增强模型未能弥合这一差距。

Conclusion: 规模而非推理能力是性能的主要驱动因素，LLM在道德推理方面存在脆弱性，容易产生自相矛盾的结果。

Abstract: As LLMs excel on standard reading comprehension benchmarks, attention is
shifting toward evaluating their capacity for complex abstract reasoning and
inference. Literature-based benchmarks, with their rich narrative and moral
depth, provide a compelling framework for evaluating such deeper comprehension
skills. Here, we present MORABLES, a human-verified benchmark built from fables
and short stories drawn from historical literature. The main task is structured
as multiple-choice questions targeting moral inference, with carefully crafted
distractors that challenge models to go beyond shallow, extractive question
answering. To further stress-test model robustness, we introduce adversarial
variants designed to surface LLM vulnerabilities and shortcuts due to issues
such as data contamination. Our findings show that, while larger models
outperform smaller ones, they remain susceptible to adversarial manipulation
and often rely on superficial patterns rather than true moral reasoning. This
brittleness results in significant self-contradiction, with the best models
refuting their own answers in roughly 20% of cases depending on the framing of
the moral choice. Interestingly, reasoning-enhanced models fail to bridge this
gap, suggesting that scale - not reasoning ability - is the primary driver of
performance.

</details>


### [3] [LLM-as-a-Judge: Rapid Evaluation of Legal Document Recommendation for Retrieval-Augmented Generation](https://arxiv.org/abs/2509.12382)
*Anu Pradhan,Alexandra Ortan,Apurv Verma,Madhavan Seshadri*

Main category: cs.CL

TL;DR: 本文研究在法学推荐系统中使用LLM作为评估者的可行性，发现传统评估指标存在误导性，提出使用Gwet's AC2和秩相关系数作为更可靠的评估指标，配合Wilcoxon符号秩检验进行系统比较。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI的兴起，传统评估指标无法捕捉法学等专业领域的推荐质量细微差别，需要探索LLM作为评估者的可靠性，以解决评估瓶颈问题。

Method: 通过系统性实验，研究不同评估者间可靠性指标在LLM评估中的表现，比较传统指标与替代指标的适用性，并使用统计检验方法进行系统对比分析。

Result: 发现传统指标如Krippendorff's alpha在AI系统评估的偏态分布中具有误导性，Gwet's AC2和秩相关系数更适合作为评估者选择指标，Wilcoxon符号秩检验配合Benjamini-Hochberg校正能提供可靠的统计比较。

Conclusion: LLM-as-a-Judge方法为法学推荐系统提供了一条可扩展、成本效益高的评估路径，将人力密集型评估瓶颈转化为自动化且统计严谨的评估框架。

Abstract: The evaluation bottleneck in recommendation systems has become particularly
acute with the rise of Generative AI, where traditional metrics fall short of
capturing nuanced quality dimensions that matter in specialized domains like
legal research. Can we trust Large Language Models to serve as reliable judges
of their own kind? This paper investigates LLM-as-a-Judge as a principled
approach to evaluating Retrieval-Augmented Generation systems in legal
contexts, where the stakes of recommendation quality are exceptionally high.
  We tackle two fundamental questions that determine practical viability: which
inter-rater reliability metrics best capture the alignment between LLM and
human assessments, and how do we conduct statistically sound comparisons
between competing systems? Through systematic experimentation, we discover that
traditional agreement metrics like Krippendorff's alpha can be misleading in
the skewed distributions typical of AI system evaluations. Instead, Gwet's AC2
and rank correlation coefficients emerge as more robust indicators for judge
selection, while the Wilcoxon Signed-Rank Test with Benjamini-Hochberg
corrections provides the statistical rigor needed for reliable system
comparisons.
  Our findings suggest a path toward scalable, cost-effective evaluation that
maintains the precision demanded by legal applications, transforming what was
once a human-intensive bottleneck into an automated, yet statistically
principled, evaluation framework.

</details>


### [4] [SENTRA: Selected-Next-Token Transformer for LLM Text Detection](https://arxiv.org/abs/2509.12385)
*Mitchell Plyler,Yilun Zhang,Alexander Tuzhilin,Saoud Khalifah,Sen Tian*

Main category: cs.CL

TL;DR: 提出SENTRA检测器，基于Transformer编码器和对比预训练，在跨域文本检测中显著优于基线方法


<details>
  <summary>Details</summary>
Motivation: 随着LLM能力增强和普及，未声明AI生成文本的滥用风险增加，需要有效检测方法

Method: 使用selected-next-token概率序列，基于Transformer编码器架构，通过对比预训练在大规模无标注数据上训练

Result: 在3个公开数据集24个文本域上的实验表明，SENTRA在跨域设置下显著优于流行基线方法

Conclusion: SENTRA是一个通用分类器，能有效检测未声明的LLM生成文本

Abstract: LLMs are becoming increasingly capable and widespread. Consequently, the
potential and reality of their misuse is also growing. In this work, we address
the problem of detecting LLM-generated text that is not explicitly declared as
such. We present a novel, general-purpose, and supervised LLM text detector,
SElected-Next-Token tRAnsformer (SENTRA). SENTRA is a Transformer-based encoder
leveraging selected-next-token-probability sequences and utilizing contrastive
pre-training on large amounts of unlabeled data. Our experiments on three
popular public datasets across 24 domains of text demonstrate SENTRA is a
general-purpose classifier that significantly outperforms popular baselines in
the out-of-domain setting.

</details>


### [5] [MORQA: Benchmarking Evaluation Metrics for Medical Open-Ended Question Answering](https://arxiv.org/abs/2509.12405)
*Wen-wai Yim,Asma Ben Abacha,Zixuan Yu,Robert Doerning,Fei Xia,Meliha Yetisgen*

Main category: cs.CL

TL;DR: MORQA是一个新的多语言医学问答评估基准，包含英语和中文的医学视觉和文本QA数据集，具有多个专业医生编写的参考答案和专家评分，研究发现基于LLM的评估方法显著优于传统指标


<details>
  <summary>Details</summary>
Motivation: 医学领域的自然语言生成评估面临独特挑战，传统自动评估指标（如BLEU、ROUGE、BERTScore）在区分高质量输出方面存在不足，特别是在医学开放问答任务中可能存在多个有效回答

Method: 引入MORQA基准，包含三个医学视觉和文本QA数据集（英语和中文），每个数据集有2-4+个医学专家编写的参考答案和专家人工评分，对比评估传统指标和基于LLM（如GPT-4、Gemini）的评估方法

Result: 基于LLM的评估方法在相关性方面显著优于传统指标，LLM对语义细微差别敏感且对参考答案变异性具有鲁棒性

Conclusion: 研究提供了医学领域首个全面的多语言NLG评估质量研究，强调了需要与人类判断对齐的评估方法，所有数据集和标注将公开发布以支持未来研究

Abstract: Evaluating natural language generation (NLG) systems in the medical domain
presents unique challenges due to the critical demands for accuracy, relevance,
and domain-specific expertise. Traditional automatic evaluation metrics, such
as BLEU, ROUGE, and BERTScore, often fall short in distinguishing between
high-quality outputs, especially given the open-ended nature of medical
question answering (QA) tasks where multiple valid responses may exist. In this
work, we introduce MORQA (Medical Open-Response QA), a new multilingual
benchmark designed to assess the effectiveness of NLG evaluation metrics across
three medical visual and text-based QA datasets in English and Chinese. Unlike
prior resources, our datasets feature 2-4+ gold-standard answers authored by
medical professionals, along with expert human ratings for three English and
Chinese subsets. We benchmark both traditional metrics and large language model
(LLM)-based evaluators, such as GPT-4 and Gemini, finding that LLM-based
approaches significantly outperform traditional metrics in correlating with
expert judgments. We further analyze factors driving this improvement,
including LLMs' sensitivity to semantic nuances and robustness to variability
among reference answers. Our results provide the first comprehensive,
multilingual qualitative study of NLG evaluation in the medical domain,
highlighting the need for human-aligned evaluation methods. All datasets and
annotations will be publicly released to support future research.

</details>


### [6] [MedFact: Benchmarking the Fact-Checking Capabilities of Large Language Models on Chinese Medical Texts](https://arxiv.org/abs/2509.12440)
*Jiayi He,Yangmin Huang,Qianyun Du,Xiangying Zhou,Zhiyang He,Jiaxue Hu,Xiaodong Tao,Lixian Lai*

Main category: cs.CL

TL;DR: MedFact是一个新的中文医疗事实核查基准，包含2,116个专家标注实例，涵盖13个医学专业和8种错误类型，用于评估LLM在医疗领域的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有基准在医疗领域的数据范围有限，无法捕捉真实世界医疗信息的复杂性，需要更严格的评估标准来确保LLM在医疗应用中的事实可靠性。

Method: 采用混合AI-人类框架构建基准，通过迭代专家反馈优化AI驱动的多标准过滤过程，确保数据质量和难度。评估了20个领先LLM在真实性分类和错误定位方面的表现。

Result: 研究发现模型虽然能判断文本是否包含错误，但精确定位错误仍具挑战性，即使表现最好的模型也达不到人类水平。还发现了'过度批评'现象，即模型倾向于将正确信息误判为错误。

Conclusion: MedFact突显了在医疗应用中部署LLM的关键挑战，为开发更事实可靠和医学感知的模型提供了强大资源。

Abstract: The increasing deployment of Large Language Models (LLMs) in healthcare
necessitates a rigorous evaluation of their factual reliability. However,
existing benchmarks are often limited by narrow domains of data, failing to
capture the complexity of real-world medical information. To address this
critical gap, we introduce MedFact, a new and challenging benchmark for Chinese
medical fact-checking. MedFact comprises 2,116 expert-annotated instances
curated from diverse real-world texts, spanning 13 medical specialties, 8
fine-grained error types, 4 writing styles, and multiple difficulty levels. Its
construction employs a hybrid AI-human framework where iterative expert
feedback refines an AI-driven, multi-criteria filtering process, ensuring both
high data quality and difficulty. We conduct a comprehensive evaluation of 20
leading LLMs, benchmarking their performance on veracity classification and
error localization against a human expert baseline. Our results reveal that
while models can often determine if a text contains an error, precisely
localizing it remains a substantial challenge, with even top-performing models
falling short of human performance. Furthermore, our analysis uncovers a
frequent ``over-criticism'' phenomenon, a tendency for models to misidentify
correct information as erroneous, which is exacerbated by advanced reasoning
techniques such as multi-agent collaboration and inference-time scaling. By
highlighting these critical challenges for deploying LLMs in medical
applications, MedFact provides a robust resource to drive the development of
more factually reliable and medically aware models.

</details>


### [7] [Topic Coverage-based Demonstration Retrieval for In-Context Learning](https://arxiv.org/abs/2509.12451)
*Wonbin Kweon,SeongKu Kang,Runchu Tian,Pengcheng Jiang,Jiawei Han,Hwanjo Yu*

Main category: cs.CL

TL;DR: TopicK是一个基于主题覆盖的检索框架，通过选择能够全面覆盖测试输入和模型相关主题知识的演示样本来提升上下文学习效果。


<details>
  <summary>Details</summary>
Motivation: 现有的上下文学习方法通常仅基于嵌入相似度或生成概率来检索演示样本，导致选择不相关或冗余的示例，无法有效覆盖细粒度的知识需求。

Method: TopicK首先估计输入所需的主题并评估模型在这些主题上的知识水平，然后迭代选择能够引入模型知识水平较低且之前未被覆盖的必需主题的演示样本。

Result: 在多个数据集和开源/闭源大语言模型上的广泛实验验证了TopicK的有效性。

Conclusion: TopicK通过主题覆盖的方法显著提升了上下文学习中演示样本选择的质量和效果。

Abstract: The effectiveness of in-context learning relies heavily on selecting
demonstrations that provide all the necessary information for a given test
input. To achieve this, it is crucial to identify and cover fine-grained
knowledge requirements. However, prior methods often retrieve demonstrations
based solely on embedding similarity or generation probability, resulting in
irrelevant or redundant examples. In this paper, we propose TopicK, a topic
coverage-based retrieval framework that selects demonstrations to
comprehensively cover topic-level knowledge relevant to both the test input and
the model. Specifically, TopicK estimates the topics required by the input and
assesses the model's knowledge on those topics. TopicK then iteratively selects
demonstrations that introduce previously uncovered required topics, in which
the model exhibits low topical knowledge. We validate the effectiveness of
TopicK through extensive experiments across various datasets and both open- and
closed-source LLMs. Our source code is available at
https://github.com/WonbinKweon/TopicK_EMNLP2025.

</details>


### [8] [Does Language Model Understand Language?](https://arxiv.org/abs/2509.12459)
*Suvojit Acharjee,Utathya Aich,Asfak Ali*

Main category: cs.CL

TL;DR: 这篇论文通过新的LUCID数据集和RECISE指南，评估了多个SOTA语言模型在英语和孜加拉语中对语言细层现象（否定、时态、语态等）的理解能力，Compound-Beta模型表现最优。


<details>
  <summary>Details</summary>
Motivation: 语言模型在细层语言现象上的衡量与人类理解之间存在差距，而在教育技术中语言清晰性至关重要，需要系统性评估。

Method: 构建LUCID数据集（英语和孜加拉语句子对），采用RECISE指南进行结构化评估，使用Pearson、Spearman相关系数、MAE和新的HCE准确率指标测试MISTRAL-SABA-24B等多个SOTA模型。

Result: Compound-Beta模型表现最优，在英语中获得最高Pearson相关系数，在混合语言数据上也呈现出健壮性能，与人类判断有强对齐性。

Conclusion: 该研究为语言模型在细层语言理解方面的评估提供了新方法，并确认了Compound-Beta模型在跨语言场景下与人类理解的最佳对齐性。

Abstract: Despite advances in natural language generation and understanding, LM still
struggle with fine grained linguistic phenomena such as tense, negation, voice,
and modality which are the elements central to effective human communication.
In the context of the United Nations SDG 4, where linguistic clarity is
critical, the deployment of LMs in educational technologies demands careful
scrutiny. As LMs are increasingly powering applications like tutoring systems,
automated grading, and translation, their alignment with human linguistic
interpretation becomes essential for effective learning. In this study, we
conduct a evaluation of SOTA language models across these challenging contexts
in both English and Bengali. To ensure a structured assessment, we introduce a
new Route for Evaluation of Cognitive Inference in Systematic Environments
guidelines. Our proposed LUCID dataset, composed of carefully crafted sentence
pairs in English and Bengali, specifically challenges these models on critical
aspects of language comprehension, including negation, tense, voice variations.
We assess the performance of SOTA models including MISTRAL-SABA-24B,
LLaMA-4-Scout-17B, LLaMA-3.3-70B, Gemma2-9B, and Compound-Beta using standard
metrics like Pearson correlation, Spearman correlation, and Mean Absolute
Error, as well as novel, linguistically inspired metric the HCE accuracy. The
HCE accuracy measures how often model predictions fall within one standard
deviation of the mean human rating, thus capturing human like tolerance for
variability in language interpretation. Our findings highlight Compound-Beta as
the most balanced model, consistently achieving high correlations and low MAEs
across diverse language conditions. It records the highest Pearson correlation
in English and demonstrates robust performance on mixed-language data,
indicating a strong alignment with human judgments in cross lingual scenarios.

</details>


### [9] [Audited Reasoning Refinement: Fine-Tuning Language Models via LLM-Guided Step-Wise Evaluation and Correction](https://arxiv.org/abs/2509.12476)
*Sumanta Bhattacharyya,Sara Riaz,Pedram Rooshenas*

Main category: cs.CL

TL;DR: R2tA方法通过提炼大语言模型的推理轨迹来训练任务特定的小型推理模型，在数据稀缺领域提供了一种实用且成本效益高的LLM适应路径


<details>
  <summary>Details</summary>
Motivation: 在直接人工监督或高质量标签稀缺的情况下，训练任务特定的小型推理模型具有挑战性，但具备推理能力的大语言模型能产生丰富的中间推理轨迹

Method: 提出Reason-Refine-then-Align (R2tA)方法：首先生成初始推理和响应，然后精炼这些轨迹以修复幻觉和不一致性，形成高质量数据集，最后进行两阶段对齐（SFT和DPO）

Result: 在数据库系统设计的扩展实体关系图评估任务中，R2tA方法在600个EERD变体数据集上表现出色，相比仅提示方法能更好地检测错误

Conclusion: R2tA为数据稀缺领域的可扩展LLM适应提供了实用且成本效益高的路径，支持教育和更广泛领域的可重现AI工具

Abstract: Training a task-specific small reasoning model is challenging when direct
human supervision or high-quality labels are scarce. However, LLMs with
reasoning capabilities produce abundant intermediate reasoning traces that can
be systematically refined to create effective supervision signals. We propose
Reason-Refine-then-Align (R2tA), which turns refined model rationales into
supervision for training task-specific reasoning models. Our method generates
initial reasoning and responses from an open-source base model on task-specific
inputs, then refines these traces, fixing hallucinations and inconsistencies,
to form a high-fidelity dataset. We perform a two-stage alignment, supervised
fine-tuning (SFT), followed by direct preference optimization (DPO) to
calibrate the model's intermediate reasoning with human-validated conceptual
preferences and then condition the final output on that aligned reasoning. As a
case study, we apply R2tA to evaluate extended entity relationship diagrams
(EERDs) in database system design, a structurally complex task where
prompt-only methods miss or hallucinate errors. We curated a dataset of 600
EERD variants (train/test split of 450/150, respectively) with induced mistakes
spanning 11 categories. Empirical evaluation suggests R2tA provides a
practical, cost-effective path to scalable LLM adaptation in data-scarce
domains, enabling reproducible AI tools for education and beyond.

</details>


### [10] [FunAudio-ASR Technical Report](https://arxiv.org/abs/2509.12508)
*Keyu An,Yanni Chen,Chong Deng,Changfeng Gao,Zhifu Gao,Bo Gong,Xiangang Li,Yabin Li,Xiang Lv,Yunjie Ji,Yiheng Jiang,Bin Ma,Haoneng Luo,Chongjia Ni,Zexu Pan,Yiping Peng,Zhendong Peng,Peiyao Wang,Hao Wang,Wen Wang,Wupeng Wang,Biao Tian,Zhentao Tan,Nan Yang,Bin Yuan,Jieping Ye,Jixing Yu,Qinglin Zhang,Kun Zou,Han Zhao,Shengkui Zhao,Jingren Zhou*

Main category: cs.CL

TL;DR: FunAudio-ASR是一个基于大语言模型的大规模语音识别系统，通过结合海量数据、大模型容量、LLM集成和强化学习，在实际工业应用中实现了最先进的性能表现。


<details>
  <summary>Details</summary>
Motivation: 虽然基于大语言模型的ASR系统在开源基准测试中表现良好，但在实际工业评估中往往表现不佳，主要原因是LLM容易产生幻觉问题，严重影响用户体验。

Method: 采用大规模数据、大模型容量、LLM深度集成和强化学习相结合的方法，并针对实际部署进行了流式处理能力、噪声鲁棒性、代码切换、热词定制等优化。

Result: FunAudio-ASR在实际应用数据集上实现了SOTA性能，证明了其在真实场景中的有效性和鲁棒性，而大多数基于LLM的ASR系统在工业评估集上表现不佳。

Conclusion: 该研究展示了通过生产导向的优化，基于LLM的ASR系统可以在实际工业应用中实现卓越性能，为解决LLM幻觉问题提供了有效方案。

Abstract: In recent years, automatic speech recognition (ASR) has witnessed
transformative advancements driven by three complementary paradigms: data
scaling, model size scaling, and deep integration with large language models
(LLMs). However, LLMs are prone to hallucination, which can significantly
degrade user experience in real-world ASR applications. In this paper, we
present FunAudio-ASR, a large-scale, LLM-based ASR system that synergistically
combines massive data, large model capacity, LLM integration, and reinforcement
learning to achieve state-of-the-art performance across diverse and complex
speech recognition scenarios. Moreover, FunAudio-ASR is specifically optimized
for practical deployment, with enhancements in streaming capability, noise
robustness, code-switching, hotword customization, and satisfying other
real-world application requirements. Experimental results show that while most
LLM-based ASR systems achieve strong performance on open-source benchmarks,
they often underperform on real industry evaluation sets. Thanks to
production-oriented optimizations, FunAudio-ASR achieves SOTA performance on
real application datasets, demonstrating its effectiveness and robustness in
practical settings.

</details>


### [11] [A comparison of pipelines for the translation of a low resource language based on transformers](https://arxiv.org/abs/2509.12514)
*Chiara Bonfanti,Michele Colombino,Giulia Coucourde,Faeze Memari,Stefano Pinardi,Rosa Meo*

Main category: cs.CL

TL;DR: 本文比较了三种软件汉语语言Bambara的机器翻译模型训练方案，发现简单的Transformer模型在低资源条件下表现最佳


<details>
  <summary>Details</summary>
Motivation: 研究Bambara语言的机器翻译技术，该语言在非洲有近1400万使用者，属于低资源语言，需要有效的翻译方案

Method: 使用三种流水线：1）基础Transformer模型训练法语翻译；2）LLaMA3指令模型微调；3）语言蓬泽技术集成LaBSE模型。使用BLEU和chrF指标评估

Result: 第一种流水线表现最好：在Bayelemagaba数据集上达到10% BLEU和21% chrF，在Yiri数据集上达到33.81% BLEU和41% chrF。指令模型在单个数据集表现更好

Conclusion: 在低资源语言翻译中，简单的Transformer模型比复杂的指令微调或语言蓬泽方案更有效，这与低资源翻译的一般观察一致

Abstract: This work compares three pipelines for training transformer-based neural
networks to produce machine translators for Bambara, a Mand\`e language spoken
in Africa by about 14,188,850 people. The first pipeline trains a simple
transformer to translate sentences from French into Bambara. The second
fine-tunes LLaMA3 (3B-8B) instructor models using decoder-only architectures
for French-to-Bambara translation. Models from the first two pipelines were
trained with different hyperparameter combinations to improve BLEU and chrF
scores, evaluated on both test sentences and official Bambara benchmarks. The
third pipeline uses language distillation with a student-teacher dual neural
network to integrate Bambara into a pre-trained LaBSE model, which provides
language-agnostic embeddings. A BERT extension is then applied to LaBSE to
generate translations. All pipelines were tested on Dokotoro (medical) and
Bayelemagaba (mixed domains). Results show that the first pipeline, although
simpler, achieves the best translation accuracy (10% BLEU, 21% chrF on
Bayelemagaba), consistent with low-resource translation results. On the Yiri
dataset, created for this work, it achieves 33.81% BLEU and 41% chrF.
Instructor-based models perform better on single datasets than on aggregated
collections, suggesting they capture dataset-specific patterns more
effectively.

</details>


### [12] [MAGIC-Enhanced Keyword Prompting for Zero-Shot Audio Captioning with CLIP Models](https://arxiv.org/abs/2509.12591)
*Vijay Govindarajan,Pratik Patel,Sahil Tripathi,Md Azizul Hoque,Gautam Siddharth Kashyap*

Main category: cs.CL

TL;DR: 零梭学习自动音频描述系统，利用预训练模型避免大量训练数据，通过音频CLIP提取特征并生成结构化提示，使用LLM生成描述，并通音频CLIP精炼标记适配音频内容，在NLG平均分数上获得35%提升。


<details>
  <summary>Details</summary>
Motivation: 解决自动音频描述(AAC)面临的数据集有限问题，避免需要大量训练数据的问题，提出零梭学习方案。

Method: 使用预训练音频CLIP模型提取听觉特征，生成结构化提示指导大语言模型(LLM)生成描述，通音频CLIP模型精炼标记适配音频内容，使用MAGIC搜索策略。

Result: 在WavCaps模型上实验结果显示NLG平均分数从4.7提升到7.3，提升35%，性能受音频-文本匹配模型和关键词选择影响显著，使用单个关键词提示最优，无关键词列表时性能下降50%。

Conclusion: 零梭学习AAC系统通过利用预训练模型和结构化提示方法，在不需大量训练数据的情况下实现了显著性能提升，关键词选择对系统性能至关重要。

Abstract: Automated Audio Captioning (AAC) generates captions for audio clips but faces
challenges due to limited datasets compared to image captioning. To overcome
this, we propose the zero-shot AAC system that leverages pre-trained models,
eliminating the need for extensive training. Our approach uses a pre-trained
audio CLIP model to extract auditory features and generate a structured prompt,
which guides a Large Language Model (LLM) in caption generation. Unlike
traditional greedy decoding, our method refines token selection through the
audio CLIP model, ensuring alignment with the audio content. Experimental
results demonstrate a 35% improvement in NLG mean score (from 4.7 to 7.3) using
MAGIC search with the WavCaps model. The performance is heavily influenced by
the audio-text matching model and keyword selection, with optimal results
achieved using a single keyword prompt, and a 50% performance drop when no
keyword list is used.

</details>


### [13] [EconProver: Towards More Economical Test-Time Scaling for Automated Theorem Proving](https://arxiv.org/abs/2509.12603)
*Mukai Li,Linfeng Song,Zhenwen Liang,Jiahao Xu,Shansan Gong,Qi Liu,Haitao Mi,Dong Yu*

Main category: cs.CL

TL;DR: 这篇论文提出了EconProver方法，通过动态CoT切换机制和多样性并行增强学习，在保持定理证明性能的同时大幅降低计算成本，仅需原有计算成本的12%


<details>
  <summary>Details</summary>
Motivation: 现有的自动定理证明模型使用反思链式推理和增加采样次数等策略虽然提高了性能，但导致了过高的计算成本，而且现有成本分析通常只关注采样次数，忽视了不同策略带来的采样成本差异

Method: 提出了两种互补方法：(1)动态Chain-of-Thought切换机制，减少不必要的标记消耗；(2)多样性并行增强学习算法，使用可训练前缀来在限制采样次数下提高通过率。这两种方法可集成到统一的EconRL流水线中

Result: 在miniF2F和ProofNet数据集上的实验表明，EconProver在仅需要基线方法12%计算成本的情况下，达到了相似的性能水平

Conclusion: 这项工作为部署轻量级自动定理证明模型提供了可操作的见解，在不牺牲性能的前提下实现了显著的计算效率提升

Abstract: Large Language Models (LLMs) have recently advanced the field of Automated
Theorem Proving (ATP), attaining substantial performance gains through widely
adopted test-time scaling strategies, notably reflective Chain-of-Thought (CoT)
reasoning and increased sampling passes. However, they both introduce
significant computational overhead for inference. Moreover, existing cost
analyses typically regulate only the number of sampling passes, while
neglecting the substantial disparities in sampling costs introduced by
different scaling strategies. In this paper, we systematically compare the
efficiency of different test-time scaling strategies for ATP models and
demonstrate the inefficiency of the current state-of-the-art (SOTA) open-source
approaches. We then investigate approaches to significantly reduce token usage
and sample passes while maintaining the original performance. Specifically, we
propose two complementary methods that can be integrated into a unified EconRL
pipeline for amplified benefits: (1) a dynamic Chain-of-Thought (CoT) switching
mechanism designed to mitigate unnecessary token consumption, and (2) Diverse
parallel-scaled reinforcement learning (RL) with trainable prefixes to enhance
pass rates under constrained sampling passes. Experiments on miniF2F and
ProofNet demonstrate that our EconProver achieves comparable performance to
baseline methods with only 12% of the computational cost. This work provides
actionable insights for deploying lightweight ATP models without sacrificing
performance.

</details>


### [14] [Positional Encoding via Token-Aware Phase Attention](https://arxiv.org/abs/2509.12635)
*Yu Wang,Sheng Shen,Rémi Munos,Hongyuan Zhan,Yuandong Tian*

Main category: cs.CL

TL;DR: RoPE存在距离依赖偏差限制长上下文建模能力，本文提出TAPA方法通过可学习相位函数改进位置编码，在长上下文上获得更低困惑度


<details>
  <summary>Details</summary>
Motivation: RoPE位置编码存在内在的距离依赖偏差，限制了长上下文建模能力，现有扩展方法需要训练后调整，需要更好的解决方案

Method: 提出Token-Aware Phase Attention (TAPA)，在注意力机制中引入可学习相位函数的位置编码方法

Result: TAPA能够保持长距离token交互，通过轻量微调扩展到更长上下文，外推到未见长度，在长上下文上获得显著低于RoPE家族的困惑度

Conclusion: TAPA是一种有效的位置编码改进方法，能够解决RoPE的长上下文建模限制问题，具有更好的扩展性和性能

Abstract: We prove under practical assumptions that Rotary Positional Embedding (RoPE)
introduces an intrinsic distance-dependent bias in attention scores that limits
RoPE's ability to model long-context. RoPE extension methods may alleviate this
issue, but they typically require post-hoc adjustments after pretraining, such
as rescaling or hyperparameters retuning. This paper introduces Token-Aware
Phase Attention (TAPA), a new positional encoding method that incorporates a
learnable phase function into the attention mechanism. TAPA preserves token
interactions over long range, extends to longer contexts with direct and light
fine-tuning, extrapolates to unseen lengths, and attains significantly lower
perplexity on long-context than RoPE families.

</details>


### [15] [PAC: Pronunciation-Aware Contextualized Large Language Model-based Automatic Speech Recognition](https://arxiv.org/abs/2509.12647)
*Li Fu,Yu Xin,Sunlu Zeng,Lu Fan,Youzheng Wu,Xiaodong He*

Main category: cs.CL

TL;DR: 这篇论文提出了一种发音感知上下文化(PAC)框架，通过两阶段学习方法有效解决了基于大语言模型的自动语音识别系统中的发音建模和同音字辨别问题，在英语和普通话数据集上都取得了显著的识别准确率提升。


<details>
  <summary>Details</summary>
Motivation: 解决基于大语言模型的自动语音识别系统在发音建模和同音字辨别方面的关键挑战，特别是对于生脏词或长尾词的识别问题。

Method: 采用两阶段学习范式：首先引入发音导向的上下文学习方法，使用交置字符-音素上下文建模策略并包含仅字符干扰器；然后提出发音辨别的强化学习方法，通过干扰标签采样来提升模型辨别上下文化同音字的能力。

Result: 在英语Librispeech和普通话AISHELL-1数据集上：(1)相比预训练的LLM基于ASR模型，WER相对降低30.2%和53.8%；(2)与强基线相比，长尾词的偏差WER相对降低31.8%和60.5%。

Conclusion: PAC框架通过有效的发音建模和同音字辨别技术，显著提升了大语言模型在自动语音识别任务中的性能，尤其在处理生脏词和长尾词方面表现突出。

Abstract: This paper presents a Pronunciation-Aware Contextualized (PAC) framework to
address two key challenges in Large Language Model (LLM)-based Automatic Speech
Recognition (ASR) systems: effective pronunciation modeling and robust
homophone discrimination. Both are essential for raw or long-tail word
recognition. The proposed approach adopts a two-stage learning paradigm. First,
we introduce a pronunciation-guided context learning method. It employs an
interleaved grapheme-phoneme context modeling strategy that incorporates
grapheme-only distractors, encouraging the model to leverage phonemic cues for
accurate recognition. Then, we propose a pronunciation-discriminative
reinforcement learning method with perturbed label sampling to further enhance
the model\'s ability to distinguish contextualized homophones. Experimental
results on the public English Librispeech and Mandarin AISHELL-1 datasets
indicate that PAC: (1) reduces relative Word Error Rate (WER) by 30.2% and
53.8% compared to pre-trained LLM-based ASR models, and (2) achieves 31.8% and
60.5% relative reductions in biased WER for long-tail words compared to strong
baselines, respectively.

</details>


### [16] [Don't Change My View: Ideological Bias Auditing in Large Language Models](https://arxiv.org/abs/2509.12652)
*Paul Kröger,Emilio Barkett*

Main category: cs.CL

TL;DR: 这篇论文提出了一种检测大语言模型意识形态偏向的统计方法，适用于审计专有黑盒系统。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在产品中的普及，它们的输出可能影响公众意见。如果模型能够被意图地向特定意识形态偏吐，控制者将获得不成比例的影响力。

Method: 采用模型无关的统计方法，通过分析模型在与特定主题相关提示下的输出分布移动来识别意识形态偏吐。方法不需要访问模型内部结构。

Result: 通过一系列实验验证了该方法的实际应用性，证明其能够支持对大语言模型行为的独立后置审计。

Conclusion: 该研究为检测大语言模型的意识形态偏吐提供了一种有效的方法，尤其适用于审计专有黑盒系统，对维护公共议程的公平性具有重要意义。

Abstract: As large language models (LLMs) become increasingly embedded in products used
by millions, their outputs may influence individual beliefs and, cumulatively,
shape public opinion. If the behavior of LLMs can be intentionally steered
toward specific ideological positions, such as political or religious views,
then those who control these systems could gain disproportionate influence over
public discourse. Although it remains an open question whether LLMs can
reliably be guided toward coherent ideological stances and whether such
steering can be effectively prevented, a crucial first step is to develop
methods for detecting when such steering attempts occur. In this work, we adapt
a previously proposed statistical method to the new context of ideological bias
auditing. Our approach carries over the model-agnostic design of the original
framework, which does not require access to the internals of the language
model. Instead, it identifies potential ideological steering by analyzing
distributional shifts in model outputs across prompts that are thematically
related to a chosen topic. This design makes the method particularly suitable
for auditing proprietary black-box systems. We validate our approach through a
series of experiments, demonstrating its practical applicability and its
potential to support independent post hoc audits of LLM behavior.

</details>


### [17] [Mitigating Strategy Preference Bias in Emotional Support Conversation via Uncertainty Estimations](https://arxiv.org/abs/2509.12661)
*Yougen Zhou,Qin Chen,Ningning Zhou,Jie Zhou,Xingjiao Wu,Liang He*

Main category: cs.CL

TL;DR: 通过揭示LLM在情感支持对话中的策略偏好偏差的知识边界根源，提出基于双重奖励减渣学习的方法来减少偏差、提高策略规划准确性


<details>
  <summary>Details</summary>
Motivation: 大语言模型在情感支持对话中存在策略规划准确性低和偏好偏差问题，但偏差的根本原因未得到充分研究

Method: 首先揭示LLM在策略规划中的知识边界，然后提出基于双重奖励减渣学习的方法，通过准确性和基于熵的信心度优化策略规划

Result: 在ESCov和ExTES数据集上的实验显示，该方法在多个LLM底层上都超过了基线方法，证明了方法的有效性

Conclusion: 通过揭示LLM的知识边界并采用双重奖励减渣学习方法，可有效减少情感支持对话中的策略偏好偏差，提高策略规划准确性

Abstract: Emotional support conversation (ESC) aims to alleviate distress through
empathetic dialogue, yet large language models (LLMs) face persistent
challenges in delivering effective ESC due to low accuracy in strategy
planning. Moreover, there is a considerable preference bias towards specific
strategies. Prior methods using fine-tuned strategy planners have shown
potential in reducing such bias, while the underlying causes of the preference
bias in LLMs have not well been studied. To address these issues, we first
reveal the fundamental causes of the bias by identifying the knowledge
boundaries of LLMs in strategy planning. Then, we propose an approach to
mitigate the bias by reinforcement learning with a dual reward function, which
optimizes strategy planning via both accuracy and entropy-based confidence for
each region according to the knowledge boundaries. Experiments on the ESCov and
ExTES datasets with multiple LLM backbones show that our approach outperforms
the baselines, confirming the effectiveness of our approach.

</details>


### [18] [Chat-Driven Text Generation and Interaction for Person Retrieval](https://arxiv.org/abs/2509.12662)
*Zequn Xie,Chuxin Wang,Sihang Cai,Yeqiang Wang,Shulei Wang,Tao Jin*

Main category: cs.CL

TL;DR: 通过多轮对话生成丰富的伪标签和动态查询精炼，实现无法务注释的文本基于人物搜索系统


<details>
  <summary>Details</summary>
Motivation: 解决文本基于人物搜索中高质量文本注释获取劳动密集的问题，提高系统的可扩展性和实际部署能力

Method: 提出两个互补模块：多轮文本生成(MTG)通过MLLM模拟对话生成丰富伪标签，多轮文本交互(MTI)在推理时通过动态对话精炼用户查询

Result: 方法在广泛评估中展现出竞争或更优的检索准确性，同时完全消除了对人工标注的需求

Conclusion: 该统一无注释框架显著提升了检索准确性、稳健性和易用性，为TBPS系统的可扩展和实际部署推平了道路

Abstract: Text-based person search (TBPS) enables the retrieval of person images from
large-scale databases using natural language descriptions, offering critical
value in surveillance applications. However, a major challenge lies in the
labor-intensive process of obtaining high-quality textual annotations, which
limits scalability and practical deployment. To address this, we introduce two
complementary modules: Multi-Turn Text Generation (MTG) and Multi-Turn Text
Interaction (MTI). MTG generates rich pseudo-labels through simulated dialogues
with MLLMs, producing fine-grained and diverse visual descriptions without
manual supervision. MTI refines user queries at inference time through dynamic,
dialogue-based reasoning, enabling the system to interpret and resolve vague,
incomplete, or ambiguous descriptions - characteristics often seen in
real-world search scenarios. Together, MTG and MTI form a unified and
annotation-free framework that significantly improves retrieval accuracy,
robustness, and usability. Extensive evaluations demonstrate that our method
achieves competitive or superior results while eliminating the need for manual
captions, paving the way for scalable and practical deployment of TBPS systems.

</details>


### [19] [Towards Inclusive Toxic Content Moderation: Addressing Vulnerabilities to Adversarial Attacks in Toxicity Classifiers Tackling LLM-generated Content](https://arxiv.org/abs/2509.12672)
*Shaz Furniturewala,Arkaitz Zubiaga*

Main category: cs.CL

TL;DR: 该论文提出基于机制可解释性技术的新策略，通过识别毒性分类器中易受攻击的组件并抑制这些脆弱电路，提高了对抗攻击的性能，同时揭示了不同人口群体间的脆弱性差异。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型生成的在线内容激增，传统基于人类文本训练的毒性分类器面临误分类问题，现有防御策略被动且效果有限，需要主动识别和修复模型脆弱性。

Method: 使用机制可解释性技术分析微调的BERT和RoBERTa分类器，通过对抗攻击技术识别脆弱电路，并在多样化数据集上进行测试，最后抑制这些脆弱电路。

Result: 发现模型存在对性能关键或易受攻击的特定注意力头，抑制脆弱头能提升对抗输入的性能，不同人口群体的脆弱性由不同头负责。

Conclusion: 该方法能有效提升毒性检测模型的鲁棒性，同时为开发更具包容性的模型提供了人口层面的洞察，有助于弥合公平性和鲁棒性差距。

Abstract: The volume of machine-generated content online has grown dramatically due to
the widespread use of Large Language Models (LLMs), leading to new challenges
for content moderation systems. Conventional content moderation classifiers,
which are usually trained on text produced by humans, suffer from
misclassifications due to LLM-generated text deviating from their training data
and adversarial attacks that aim to avoid detection. Present-day defence
tactics are reactive rather than proactive, since they rely on adversarial
training or external detection models to identify attacks. In this work, we aim
to identify the vulnerable components of toxicity classifiers that contribute
to misclassification, proposing a novel strategy based on mechanistic
interpretability techniques. Our study focuses on fine-tuned BERT and RoBERTa
classifiers, testing on diverse datasets spanning a variety of minority groups.
We use adversarial attacking techniques to identify vulnerable circuits.
Finally, we suppress these vulnerable circuits, improving performance against
adversarial attacks. We also provide demographic-level insights into these
vulnerable circuits, exposing fairness and robustness gaps in model training.
We find that models have distinct heads that are either crucial for performance
or vulnerable to attack and suppressing the vulnerable heads improves
performance on adversarial input. We also find that different heads are
responsible for vulnerability across different demographic groups, which can
inform more inclusive development of toxicity detection models.

</details>


### [20] [Case-Based Decision-Theoretic Decoding with Quality Memories](https://arxiv.org/abs/2509.12677)
*Hiroyuki Deguchi,Masaaki Nagata*

Main category: cs.CL

TL;DR: 提出CBDT解码方法，结合案例决策理论来估计期望效用，在机器翻译和图像描述任务中优于传统MBR和MAP解码方法


<details>
  <summary>Details</summary>
Motivation: 解决MBR解码依赖模型采样文本、难以捕获域外知识的问题，需要一种能够利用领域数据示例来更好估计期望效用的方法

Method: 提出基于案例的决策理论(CBDT)解码，使用领域数据示例来估计期望效用，并与MBR解码相结合

Result: 在7个领域De-En和Ja↔En翻译任务以及MSCOCO和nocaps图像描述任务中，CBDT与MBR结合的方法优于单独使用MBR解码

Conclusion: CBDT解码能够有效利用领域知识，提高文本生成质量，特别是在处理域外信息时表现优异

Abstract: Minimum Bayes risk (MBR) decoding is a decision rule of text generation,
which selects the hypothesis that maximizes the expected utility and robustly
generates higher-quality texts than maximum a posteriori (MAP) decoding.
However, it depends on sample texts drawn from the text generation model; thus,
it is difficult to find a hypothesis that correctly captures the knowledge or
information of out-of-domain. To tackle this issue, we propose case-based
decision-theoretic (CBDT) decoding, another method to estimate the expected
utility using examples of domain data. CBDT decoding not only generates
higher-quality texts than MAP decoding, but also the combination of MBR and
CBDT decoding outperformed MBR decoding in seven domain De--En and
Ja$\leftrightarrow$En translation tasks and image captioning tasks on MSCOCO
and nocaps datasets.

</details>


### [21] [HistoryBankQA: Multilingual Temporal Question Answering on Historical Events](https://arxiv.org/abs/2509.12720)
*Biswadip Mandal,Anant Khandelwal,Manish Gupta*

Main category: cs.CL

TL;DR: HistoryBank是一个多语言历史事件数据库，包含1000万+事件，覆盖10种语言，并构建了全面的时序推理问答基准来评估大语言模型的历史事件理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有时序推理数据集规模有限、缺乏多语言覆盖且更关注当代事件，需要构建更全面的历史事件数据库和评估基准来推动大语言模型在历史时序推理方面的发展。

Method: 从维基百科时间线页面和文章信息框中提取历史事件，构建包含10种语言的1000万+事件数据库，并设计6种时序问答任务来评估语言模型性能。

Result: GPT4o在所有任务和语言中表现最佳，Gemma-2在小型语言模型中表现最优，验证了基准的有效性和模型性能差异。

Conclusion: HistoryBank为推进多语言和历史感知的自然语言理解提供了全面资源，代码和数据集将在论文接受后公开以促进进一步研究。

Abstract: Temporal reasoning about historical events is a critical skill for NLP tasks
like event extraction, historical entity linking, temporal question answering,
timeline summarization, temporal event clustering and temporal natural language
inference. Yet efforts on benchmarking temporal reasoning capabilities of large
language models (LLMs) are rather limited. Existing temporal reasoning datasets
are limited in scale, lack multilingual coverage and focus more on contemporary
events. To address these limitations, we present HistoryBank, a multilingual
database of 10M+ historical events extracted from Wikipedia timeline pages and
article infoboxes. Our database provides unprecedented coverage in both
historical depth and linguistic breadth with 10 languages. Additionally, we
construct a comprehensive question answering benchmark for temporal reasoning
across all languages. This benchmark covers a diverse set of 6 temporal QA
reasoning tasks, and we evaluate a suite of popular language models
(LLaMA-3-8B, Mistral-7B, Gemma-2-9b, Qwen3-8B, GPT4o) to assess their
performance on these tasks. As expected GPT4o performs best across all answer
types and languages; Gemma-2 outperforms the other small language models. Our
work aims to provide a comprehensive resource for advancing multilingual and
temporally-aware natural language understanding of historical events. To
facilitate further research, we will make our code and datasets publicly
available upon acceptance of this paper.

</details>


### [22] [Contrastive Learning with Enhanced Abstract Representations using Grouped Loss of Abstract Semantic Supervision](https://arxiv.org/abs/2509.12771)
*Omri Suissa,Muhiim Ali,Shengmai Chen,Yinuo Cai,Shekhar Pradhan*

Main category: cs.CL

TL;DR: 这篇论文研究视觉语言模型的概念抽象能力，提出了一种基于组合对比损失的训练方法，使模型能够在不暴露高级概念的情况下学习抽象概念表征。


<details>
  <summary>Details</summary>
Motivation: 人类能够识别图片中的抽象概念，而不仅仅是对象和关系。研究考察现有VLM模型是否具备这种概念抽象能力，以及如何编码图片中的高级概念信息来提升模型的这种能力。

Method: 构建MAGIC数据集（包含图片描述组和高级概念标签），使用新颖的组合对比损失技术：外部对比损失（文本-图片对比）和内部损失（组内实例间距离测量），促使模型将每个图片-描述组的表征向高级概念语义空间接近。

Result: 训练出的CLEAR GLASS模型在抽象概念识别方面比现有SOTA模型有显著提升，并且这种概念抽象能力是作为出现性能力形成的。

Conclusion: 通过组合对比损失方法，VLM模型可以在不直接暴露高级概念的情况下学习到概念抽象能力，为提升模型的概念理解能力提供了有效方法。

Abstract: Humans can recognize an image as an instance of a general concept, beyond
simply identifying its objects and their relationships. In this paper, we
investigate 1. The extent to which VLMs have this concept abstraction capacity,
and 2. Strategies for encoding the sort of higher-concept information in images
that would enable the resulting VLM model (CLEAR GLASS model) to have this
capability to a greater degree. To this end, we introduce a grouped
image-caption dataset (MAGIC), which consists of several groups of image
captions and for each group a set of associated images and higher-level
conceptual labels. We use a novel contrastive loss technique to induce the
model to encode in the representation of each image (caption) in a group the
information that is common to all members of the image-caption group. Our main
contribution is a grouped contrastive loss function based on text-image
contrastive groups (outer contrastive loss) as well as an inner loss which
measures the distances between image-caption instances in the group. Our
training methodology results in the CLEAR GLASS model having the concept
abstraction capacity as an emergent capacity because the model is not exposed
to the higher-level concepts associated with each group. Instead, the training
forces the model to create for each image-caption group a semantic
representation that brings it closer to the semantic representation of the
higher-level concepts in the latent semantic space. Our experiments show that
this training methodology results in a model which shows improvement in
abstract concept recognition compared to SOTA models.

</details>


### [23] [ConvergeWriter: Data-Driven Bottom-Up Article Construction](https://arxiv.org/abs/2509.12811)
*Binquan Ji,Jiaqi Wang,Ruiting Li,Xingchen Han,Yiyang Qi,Shichao Wang,Yifei Lu,Yuantao Han,Feiliang Ren*

Main category: cs.CL

TL;DR: 这篇论文提出了一种基于"先检索后聚类"的自底向上框架，通过先确定知识边界再生成文档的方法，有效减少大语言模型在长文本生成中的虚构问题


<details>
  <summary>Details</summary>
Motivation: 现有的"自顶向下"方法先生成假设或大纲再检索证据，容易导致模型计划与可用知识脱节，产生内容碎片化和事实错误

Method: 采用"检索优先获知识，聚类构建结构"策略，先进行迭代检索确定知识边界，然后使用无监督聚类算法将检索文档组织成知识聚类，最后基于这些聚类生成层次结构和最终文档

Result: 在14B和32B参数模型上的实验结果显示，该方法达到或超过了最先进基线的性能，并预计在需要高保真度和结构一致性的知识约束场景中展现独特优势

Conclusion: 该研究提供了一种生成可靠、结构化长文档的有效范式，为在高风险、知识密集领域开发更稳健的大语言模型应用掘平了道路

Abstract: Large Language Models (LLMs) have shown remarkable prowess in text
generation, yet producing long-form, factual documents grounded in extensive
external knowledge bases remains a significant challenge. Existing "top-down"
methods, which first generate a hypothesis or outline and then retrieve
evidence, often suffer from a disconnect between the model's plan and the
available knowledge, leading to content fragmentation and factual inaccuracies.
To address these limitations, we propose a novel "bottom-up," data-driven
framework that inverts the conventional generation pipeline. Our approach is
predicated on a "Retrieval-First for Knowledge, Clustering for Structure"
strategy, which first establishes the "knowledge boundaries" of the source
corpus before any generative planning occurs. Specifically, we perform
exhaustive iterative retrieval from the knowledge base and then employ an
unsupervised clustering algorithm to organize the retrieved documents into
distinct "knowledge clusters." These clusters form an objective, data-driven
foundation that directly guides the subsequent generation of a hierarchical
outline and the final document content. This bottom-up process ensures that the
generated text is strictly constrained by and fully traceable to the source
material, proactively adapting to the finite scope of the knowledge base and
fundamentally mitigating the risk of hallucination. Experimental results on
both 14B and 32B parameter models demonstrate that our method achieves
performance comparable to or exceeding state-of-the-art baselines, and is
expected to demonstrate unique advantages in knowledge-constrained scenarios
that demand high fidelity and structural coherence. Our work presents an
effective paradigm for generating reliable, structured, long-form documents,
paving the way for more robust LLM applications in high-stakes,
knowledge-intensive domains.

</details>


### [24] [Data Augmentation for Maltese NLP using Transliterated and Machine Translated Arabic Data](https://arxiv.org/abs/2509.12853)
*Kurt Micallef,Nizar Habash,Claudia Borg*

Main category: cs.CL

TL;DR: 通过跨语言增帽技术，利用阿拉伯语资源支持马耳他语NLP任务，提出新的音调系统并证明阿语增帽的显著效果


<details>
  <summary>Details</summary>
Motivation: 马耳他语作为一种独特的闇米特语言，在缘文字正弓与阿拉伯语存在距离，需要探索如何利用其语言亲缘关系来支持NLP工作

Method: 研究多种对准策略，包括不同的音调方案和机器翻译方法，并提出了更好反映马耳他语正弓的新音调系统

Result: 阿拉伯语基础的数据增帽能够显著提升马耳他语NLP任务的性能

Conclusion: 跨语言增帽技术可以有效利用阿拉伯语资源来支持马耳他语的NLP工作，为语言资源较少的语言提供了有效解决方案

Abstract: Maltese is a unique Semitic language that has evolved under extensive
influence from Romance and Germanic languages, particularly Italian and
English. Despite its Semitic roots, its orthography is based on the Latin
script, creating a gap between it and its closest linguistic relatives in
Arabic. In this paper, we explore whether Arabic-language resources can support
Maltese natural language processing (NLP) through cross-lingual augmentation
techniques. We investigate multiple strategies for aligning Arabic textual data
with Maltese, including various transliteration schemes and machine translation
(MT) approaches. As part of this, we also introduce novel transliteration
systems that better represent Maltese orthography. We evaluate the impact of
these augmentations on monolingual and mutlilingual models and demonstrate that
Arabic-based augmentation can significantly benefit Maltese NLP tasks.

</details>


### [25] [Benchmarking and Improving LVLMs on Event Extraction from Multimedia Documents](https://arxiv.org/abs/2509.12876)
*Fuyu Xing,Zimu Wang,Wei Wang,Haiyang Zhang*

Main category: cs.CL

TL;DR: 本文首次系统评估了大型视觉语言模型（LVLMs）在多媒体事件抽取（M2E2）任务上的表现，发现few-shot模式下视觉任务表现较好但文本任务较差，LoRA微调能显著提升性能，多模态组合具有强协同效应。


<details>
  <summary>Details</summary>
Motivation: 多媒体内容的快速增长需要有效的多媒体事件抽取系统，但大型视觉语言模型在此任务上的应用潜力尚未得到充分探索。

Method: 在M2E2数据集上系统评估代表性LVLMs（DeepSeek-VL2和Qwen-VL系列），涵盖文本、图像和跨模态子任务，采用few-shot提示和微调两种设置进行评估。

Result: few-shot LVLMs在视觉任务表现良好但文本任务困难；LoRA微调显著提升性能；多模态组合展现强协同效应，在跨模态设置中达到最优性能。

Conclusion: LVLMs在M2E2任务中展现出潜力，但在语义精度、定位和跨模态基础等方面仍存在持续挑战，这些是推进M2E2能力的关键障碍。

Abstract: The proliferation of multimedia content necessitates the development of
effective Multimedia Event Extraction (M2E2) systems. Though Large
Vision-Language Models (LVLMs) have shown strong cross-modal capabilities,
their utility in the M2E2 task remains underexplored. In this paper, we present
the first systematic evaluation of representative LVLMs, including DeepSeek-VL2
and the Qwen-VL series, on the M2E2 dataset. Our evaluations cover text-only,
image-only, and cross-media subtasks, assessed under both few-shot prompting
and fine-tuning settings. Our key findings highlight the following valuable
insights: (1) Few-shot LVLMs perform notably better on visual tasks but
struggle significantly with textual tasks; (2) Fine-tuning LVLMs with LoRA
substantially enhances model performance; and (3) LVLMs exhibit strong synergy
when combining modalities, achieving superior performance in cross-modal
settings. We further provide a detailed error analysis to reveal persistent
challenges in areas such as semantic precision, localization, and cross-modal
grounding, which remain critical obstacles for advancing M2E2 capabilities.

</details>


### [26] [The LLM Already Knows: Estimating LLM-Perceived Question Difficulty via Hidden Representations](https://arxiv.org/abs/2509.12886)
*Yubo Zhu,Dongrui Liu,Zecheng Lin,Wei Tong,Sheng Zhong,Jing Shao*

Main category: cs.CL

TL;DR: 一种基于LLM隐藏表征的效率高、无需生成输出的问题难度估计方法，通过马尔可夫链模型预测输出质量，在多种任务上超过现有方法并提升适应性推理效率


<details>
  <summary>Details</summary>
Motivation: 现有问题难度估计方法需要重复采样、辅助模型或微调，计算成本高且影响模型通用性，需要一种更高效、无侵入的难度估计方法

Method: 利用LLM隐藏表征，将标记级生成过程模型为马尔可夫链，定义价值函数估计任意隐藏状态下的预期输出质量，仅依靠初始隐藏状态即可进行难度估计

Result: 在文本和多模态任务上经验验证，方法在难度估计上一贯超过现有基线方法，并能够指导适应性推理策略（如Self-Consistency、Best-of-N、Self-Refine），以更少的生成标记数量实现更高的推理效率

Conclusion: 该方法提供了一种高效、准确且无需生成输出的LLM问题难度估计方案，在保持模型通用性的同时昇强了性能评估和适应性推理的效率，为LLM的实际应用提供了重要技术支撑

Abstract: Estimating the difficulty of input questions as perceived by large language
models (LLMs) is essential for accurate performance evaluation and adaptive
inference. Existing methods typically rely on repeated response sampling,
auxiliary models, or fine-tuning the target model itself, which may incur
substantial computational costs or compromise generality. In this paper, we
propose a novel approach for difficulty estimation that leverages only the
hidden representations produced by the target LLM. We model the token-level
generation process as a Markov chain and define a value function to estimate
the expected output quality given any hidden state. This allows for efficient
and accurate difficulty estimation based solely on the initial hidden state,
without generating any output tokens. Extensive experiments across both textual
and multimodal tasks demonstrate that our method consistently outperforms
existing baselines in difficulty estimation. Moreover, we apply our difficulty
estimates to guide adaptive reasoning strategies, including Self-Consistency,
Best-of-N, and Self-Refine, achieving higher inference efficiency with fewer
generated tokens.

</details>


### [27] [Conan-Embedding-v2: Training an LLM from Scratch for Text Embeddings](https://arxiv.org/abs/2509.12892)
*Shiyu Li,Yang Tang,Ruijie Liu,Shi-Zhe Chen,Xi Chen*

Main category: cs.CL

TL;DR: Conan-embedding-v2是一个14亿参数的大语言模型，从头训练并微调作为文本嵌入器，在MTEB和中英文MTEB基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法使用LoRA微调LLMs时存在的数据和训练差距问题，包括LLMs与嵌入模型之间的数据差异以及因果掩码与双向掩码的训练差异。

Method: 1) 添加新闻数据和多语言对进行LLM预训练以弥合数据差距；2) 提出跨语言检索数据集；3) 引入软掩码机制在因果掩码和双向掩码之间平滑过渡；4) 提出动态硬负样本挖掘方法。

Result: 仅用约14亿参数就在Massive Text Embedding Benchmark (MTEB)和中文MTEB (2025年5月19日)上实现了最先进的性能。

Conclusion: 通过弥合数据和训练差距，Conan-embedding-v2证明了从头训练并专门针对嵌入任务优化的LLMs能够在小参数规模下实现卓越的嵌入性能。

Abstract: Large language models (LLMs) have recently demonstrated excellent performance
in text embedding tasks. Previous work usually use LoRA to fine-tune existing
LLMs, which are limited by the data and training gap between LLMs and embedding
models. In this work, we introduce Conan-embedding-v2, a new 1.4B-parameter LLM
trained from scratch and fine-tuned as a text embedder. First, we add news data
and multilingual pairs for LLM pretraining to bridge the data gap. Based on
this, we propose a cross-lingual retrieval dataset that enables the LLM to
better integrate embeddings across different languages. Second, whereas LLMs
use a causal mask with token-level loss, embedding models use a bidirectional
mask with sentence-level loss. This training gap makes full fine-tuning less
effective than LoRA. We introduce a soft-masking mechanism to gradually
transition between these two types of masks, enabling the model to learn more
comprehensive representations. Based on this, we propose a dynamic hard
negative mining method that exposes the model to more difficult negative
examples throughout the training process. Being intuitive and effective, with
only approximately 1.4B parameters, Conan-embedding-v2 achieves SOTA
performance on both the Massive Text Embedding Benchmark (MTEB) and Chinese
MTEB (May 19, 2025).

</details>


### [28] [All Roads Lead to Rome: Graph-Based Confidence Estimation for Large Language Model Reasoning](https://arxiv.org/abs/2509.12908)
*Caiqi Zhang,Chang Shu,Ehsan Shareghi,Nigel Collier*

Main category: cs.CL

TL;DR: 这篇论文提出了一种专门用于推理任务的图基信心估计方法，通过将推理路径模型为有向图并利用图论特性来提高信心估计的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的信心估计方法主要为事实问答任务设计，在推理任务上普遍效果不佳，需要专门的方法来填补这个空白。

Method: 提出了一系列无需训练的图基信心估计方法，将推理路径模型为有向图，利用图的中心性、路径收敛性和路径权重等特性来估计信心度。

Result: 在三个推理数据集上使用两种大型语言模型进行实验，结果显示信心估计性能得到显著提升，并在两个下游任务上也获得了改善。

Conclusion: 这种以图论为基础的方法能够有效地提高大型语言模型在推理任务上的信心估计准确性，为可靠部署提供了新的解决方案。

Abstract: Confidence estimation is essential for the reliable deployment of large
language models (LLMs). Existing methods are primarily designed for factual QA
tasks and often fail to generalize to reasoning tasks. To address this gap, we
propose a set of training-free, graph-based confidence estimation methods
tailored to reasoning tasks. Our approach models reasoning paths as directed
graphs and estimates confidence by exploiting graph properties such as
centrality, path convergence, and path weighting. Experiments with two LLMs on
three reasoning datasets demonstrate improved confidence estimation and
enhanced performance on two downstream tasks.

</details>


### [29] [Automated Generation of Research Workflows from Academic Papers: A Full-text Mining Framework](https://arxiv.org/abs/2509.12955)
*Heng Zhang,Chengzhi Zhang*

Main category: cs.CL

TL;DR: 提出端到端框架从学术论文全文挖掘完整结构化研究流程，在NLP领域实现高精度工作流识别和可视化生成


<details>
  <summary>Details</summary>
Motivation: 现有方法只能提取碎片化流程组件，无法捕捉完整研究流程，需要自动化生成研究流程以提高研究可重复性和推动AI for Science

Method: 段落中心方法：PU学习+SciBERT识别工作流描述段落，Flan-T5生成流程短语，ChatGPT少样本学习分类，最后生成可视化流程图

Result: 工作流段落识别F1=0.9772，流程短语生成ROUGE-1=0.4543/ROUGE-2=0.2877/ROUGE-L=0.4427，分类精度=0.958，成功分析NLP领域20年方法学演变

Conclusion: 提供了自动化工作流生成的技术框架和过程导向视角，揭示了从特征工程到消融研究的方法学转变趋势

Abstract: The automated generation of research workflows is essential for improving the
reproducibility of research and accelerating the paradigm of "AI for Science".
However, existing methods typically extract merely fragmented procedural
components and thus fail to capture complete research workflows. To address
this gap, we propose an end-to-end framework that generates comprehensive,
structured research workflows by mining full-text academic papers. As a case
study in the Natural Language Processing (NLP) domain, our paragraph-centric
approach first employs Positive-Unlabeled (PU) Learning with SciBERT to
identify workflow-descriptive paragraphs, achieving an F1-score of 0.9772.
Subsequently, we utilize Flan-T5 with prompt learning to generate workflow
phrases from these paragraphs, yielding ROUGE-1, ROUGE-2, and ROUGE-L scores of
0.4543, 0.2877, and 0.4427, respectively. These phrases are then systematically
categorized into data preparation, data processing, and data analysis stages
using ChatGPT with few-shot learning, achieving a classification precision of
0.958. By mapping categorized phrases to their document locations in the
documents, we finally generate readable visual flowcharts of the entire
research workflows. This approach facilitates the analysis of workflows derived
from an NLP corpus and reveals key methodological shifts over the past two
decades, including the increasing emphasis on data analysis and the transition
from feature engineering to ablation studies. Our work offers a validated
technical framework for automated workflow generation, along with a novel,
process-oriented perspective for the empirical investigation of evolving
scientific paradigms. Source code and data are available at:
https://github.com/ZH-heng/research_workflow.

</details>


### [30] [Investigating ReLoRA: Effects on the Learning Dynamics of Small Language Models](https://arxiv.org/abs/2509.12960)
*Yuval Weiss,David Demitri Africa,Paula Buttery,Richard Diehl Martinez*

Main category: cs.CL

TL;DR: ReLoRA在小型语言模型(11M-66M参数)的预训练中表现差于标准训练，性能差距随模型规模增大，并加剧了小模型的秩缺陷问题。


<details>
  <summary>Details</summary>
Motivation: 研究ReLoRA在小型语言模型(SLMs)预训练中的应用，评估其性能和学习动态，以降低计算成本和环境影响。

Method: 通过对11M-66M参数范围的SLMs进行系统性实验，测试ReLoRA在损失值、Paloma困惑度和BLiMP指标上的表现，并分析学习动态。

Result: ReLoRA在所有测试指标上都表现更差，特别是在更大的模型上差距更显著，且会加剧小模型的秩缺陷问题。

Conclusion: 低秩更新策略在SLM预训练中转移效果不佳，需要在低计算范围内进行更多研究。

Abstract: Parameter-efficient methods such as LoRA have revolutionised the fine-tuning
of LLMs. Still, their extension to pretraining via ReLoRA is less well
understood, especially for small language models (SLMs), which offer lower
computational and environmental costs. This work is the first systematic study
of ReLoRA in SLMs (11M-66M parameters), evaluating both performance and
learning dynamics. Through ablation experiments, we find that ReLoRA generally
performs worse than standard training on loss, Paloma perplexity and BLiMP,
with the gap widening for the larger models. Further analysis of the learning
dynamics of the models indicates that ReLoRA reinforces the rank deficiencies
found in smaller models. These results indicate that low-rank update strategies
may not transfer easily to SLM pretraining, highlighting the need for more
research in the low-compute regime.

</details>


### [31] [Do LLMs Understand Wine Descriptors Across Cultures? A Benchmark for Cultural Adaptations of Wine Reviews](https://arxiv.org/abs/2509.12961)
*Chenye Zou,Xingyue Wen,Tianyi Hu,Qian Janice Wang,Daniel Hershcovich*

Main category: cs.CL

TL;DR: 本文研究了跨文化葡萄酒评论适应问题，提出了文化导向的评估标准，发现当前模型在捕捉文化细微差别方面存在困难


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的发展为文化感知语言任务提供了可能，需要超越字面翻译来适应不同文化的口味偏好和文化特定的风味描述

Method: 构建首个8k中文和16k英文葡萄酒评论平行语料库，对比神经机器翻译基线和最先进的大语言模型，提出文化接近性、文化中立性和文化真实性三个评估标准

Result: 当前模型在捕捉文化细微差别方面表现不佳，特别是在跨文化翻译葡萄酒描述时存在明显困难

Conclusion: 翻译模型在处理文化内容方面存在挑战和局限性，需要进一步改进文化适应能力

Abstract: Recent advances in large language models (LLMs) have opened the door to
culture-aware language tasks. We introduce the novel problem of adapting wine
reviews across Chinese and English, which goes beyond literal translation by
incorporating regional taste preferences and culture-specific flavor
descriptors. In a case study on cross-cultural wine review adaptation, we
compile the first parallel corpus of professional reviews, containing 8k
Chinese and 16k Anglophone reviews. We benchmark both
neural-machine-translation baselines and state-of-the-art LLMs with automatic
metrics and human evaluation. For the latter, we propose three culture-oriented
criteria -- Cultural Proximity, Cultural Neutrality, and Cultural Genuineness
-- to assess how naturally a translated review resonates with target-culture
readers. Our analysis shows that current models struggle to capture cultural
nuances, especially in translating wine descriptions across different cultures.
This highlights the challenges and limitations of translation models in
handling cultural content.

</details>


### [32] [SitLLM: Large Language Models for Sitting Posture Health Understanding via Pressure Sensor Data](https://arxiv.org/abs/2509.12994)
*Jian Gao,Fufangchen Zhao,Yiyang Zhang,Danfeng Yan*

Main category: cs.CL

TL;DR: SitLLM是一个轻量级多模态框架，结合压力传感和大型语言模型，实现细粒度坐姿识别和个性化健康反馈


<details>
  <summary>Details</summary>
Motivation: 现有坐姿监测系统识别粒度粗糙，缺乏语义表达能力，无法提供个性化反馈

Method: 包含三个核心模块：高斯鲁棒传感器嵌入模块（处理压力图并注入噪声）、提示驱动的跨模态对齐模块（将传感器嵌入映射到LLM语义空间）、多上下文提示模块（融合多层级上下文信息）

Result: 未在摘要中明确说明具体实验结果

Conclusion: 该框架能够实现细粒度坐姿理解和个性化健康导向的响应生成

Abstract: Poor sitting posture is a critical yet often overlooked factor contributing
to long-term musculoskeletal disorders and physiological dysfunctions. Existing
sitting posture monitoring systems, although leveraging visual, IMU, or
pressure-based modalities, often suffer from coarse-grained recognition and
lack the semantic expressiveness necessary for personalized feedback. In this
paper, we propose \textbf{SitLLM}, a lightweight multimodal framework that
integrates flexible pressure sensing with large language models (LLMs) to
enable fine-grained posture understanding and personalized health-oriented
response generation. SitLLM comprises three key components: (1) a
\textit{Gaussian-Robust Sensor Embedding Module} that partitions pressure maps
into spatial patches and injects local noise perturbations for robust feature
extraction; (2) a \textit{Prompt-Driven Cross-Modal Alignment Module} that
reprograms sensor embeddings into the LLM's semantic space via multi-head
cross-attention using the pre-trained vocabulary embeddings; and (3) a
\textit{Multi-Context Prompt Module} that fuses feature-level, structure-level,
statistical-level, and semantic-level contextual information to guide
instruction comprehension.

</details>


### [33] [Multi-Model Synthetic Training for Mission-Critical Small Language Models](https://arxiv.org/abs/2509.13047)
*Nolan Platt,Pragyansmita Nayak*

Main category: cs.CL

TL;DR: 使用LLM作为一次性教师生成合成数据，而非直接推理，实现了261倍成本降低，使小型模型在专业领域达到与大模型相当的准确率


<details>
  <summary>Details</summary>
Motivation: 解决专业领域训练数据稀缺和复杂性问题，降低大语言模型在专业应用中的高昂推理成本

Method: 利用GPT-4o和o3-mini多模型生成方法，将32亿条船舶跟踪记录转换为21,543个合成问答对，然后对Qwen2.5-7B模型进行微调

Result: 微调后的模型在海事任务上达到75%准确率，成本大幅降低，比使用大模型进行推理便宜得多

Conclusion: 通过合成数据生成和适当微调，小型廉价模型可以在专业领域提供与昂贵大模型相似的准确性，为手动标注不可行的领域提供了可复现框架

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across
many domains, yet their application to specialized fields remains constrained
by the scarcity and complexity of domain-specific training data. We present a
novel approach that achieves a 261x cost reduction for maritime intelligence by
using LLMs as one-time teachers rather than using them directly for inference.
Our method transforms 3.2 billion Automatic Identification System (AIS) vessel
tracking records into 21,543 synthetic question and answer pairs through
multi-model generation (GPT-4o and o3-mini), preventing overfitting and
ensuring accurate reasoning. The resulting fine-tuned Qwen2.5-7B model achieves
75% accuracy on maritime tasks, while being substantially cheaper than using a
larger model for inference. We show that smaller, cheaper models -- when fine
tuned properly -- can provide similar accuracy compared to larger models that
are prohibitively expensive. Our work contributes to the growing field of
synthetic dataset generation for specialized AI applications and presents a
highly reproducible framework for domains where manual annotation is
infeasible. Beyond expanding research in the growing field of specialized small
language models, our approach has immediate applications in maritime safety,
security operations, and vessel traffic management systems in various
industries.

</details>


### [34] [Shaping Explanations: Semantic Reward Modeling with Encoder-Only Transformers for GRPO](https://arxiv.org/abs/2509.13081)
*Francesco Pappone,Ruggero Marino Lazzaroni,Federico Califano,Niccolò Gentile,Roberto Marras*

Main category: cs.CL

TL;DR: 通过使用轻量级编码器模型作为语义奖励模型，在GRPO框架中提高了大语言模型生成教学性解释的质量


<details>
  <summary>Details</summary>
Motivation: 对准大语言模型输出与复杂质性目标（如教学效果）的对齐，现有方法依赖慢速评估或老布的关键词指标

Method: 在GRPO框架下使用小型编码器transformer作为语义奖励模型，通过余弦相似度提供密集语义奖励信号

Result: 在意大利医学入学考试任务中，该方法显著提高了解释的准确性和清晰度，超越了紧凑微调基线

Conclusion: 轻量级编码器模型可以有效地为复杂生成任务提供细腻的奖励形式

Abstract: While Large Language Models (LLMs) excel at generating human-like text,
aligning their outputs with complex, qualitative goals like pedagogical
soundness remains a significant challenge. Standard reinforcement learning
techniques often rely on slow and expensive LLM-as-a-judge evaluations or on
brittle, keyword-based metrics like ROUGE, which fail to capture the semantic
essence of a high-quality explanation. In this work, we introduce a novel
approach to reward shaping within the Group Relative Policy Optimisation (GRPO)
framework. Our central contribution is the use of a small, efficient
encoder-only transformer as a semantic reward model. This model provides a
dense, semantically rich reward signal based on the cosine similarity between a
generated explanation and a ground-truth reference, guiding the policy towards
explanations that are not just factually correct but also structurally and
conceptually aligned with expert reasoning. We apply this method to the task of
training a model for the Italian medical-school entrance examinations,
following standard domain-adaptive continued pre-training (CPT) and supervised
fine-tuning (SFT). Our results demonstrate that GRPO with our proposed semantic
reward significantly improves explanation faithfulness and clarity over a
strong SFT baseline, showcasing the power of using lightweight encoder models
for nuanced reward shaping in complex generation tasks

</details>


### [35] [Empowering LLMs with Parameterized Skills for Adversarial Long-Horizon Planning](https://arxiv.org/abs/2509.13127)
*Sijia Cui,Shuai Xu,Aiyao He,Yanna Wang,Bo Xu*

Main category: cs.CL

TL;DR: PLAP框架通过语言规划和参数化执行解决LLM智能体在长时域环境中的落地问题，在MicroRTS游戏中表现出色，GPT-4o零样本超越80%基线，Qwen2-72B少样本超越顶级脚本智能体。


<details>
  <summary>Details</summary>
Motivation: 解决LLM智能体在复杂对抗性长时域环境中有效落地的挑战，现有方法要么生成不可靠的低级动作，要么依赖专家经验转换高级任务。

Method: 提出PLAP规划框架，包含三个核心组件：环境特定的参数化技能库、LLM驱动的技能规划器、将参数化技能转换为可执行动作序列的技能执行器。

Result: 在MicroRTS实时策略游戏中，GPT-4o驱动的PLAP零样本表现超越80%基线智能体，Qwen2-72B驱动的PLAP少样本表现超越顶级脚本智能体CoacAI。

Conclusion: PLAP框架有效解决了LLM智能体在长时域环境中的落地问题，并建立了LLM长时域技能规划能力的排行榜。

Abstract: Recent advancements in Large Language Models(LLMs) have led to the
development of LLM-based AI agents. A key challenge is the creation of agents
that can effectively ground themselves in complex, adversarial long-horizon
environments. Existing methods mainly focus on (1) using LLMs as policies to
interact with the environment through generating low-level feasible actions,
and (2) utilizing LLMs to generate high-level tasks or language guides to
stimulate action generation. However, the former struggles to generate reliable
actions, while the latter relies heavily on expert experience to translate
high-level tasks into specific action sequences. To address these challenges,
we introduce the Plan with Language, Act with Parameter (PLAP) planning
framework that facilitates the grounding of LLM-based agents in long-horizon
environments. The PLAP method comprises three key components: (1) a skill
library containing environment-specific parameterized skills, (2) a skill
planner powered by LLMs, and (3) a skill executor converting the parameterized
skills into executable action sequences. We implement PLAP in MicroRTS, a
long-horizon real-time strategy game that provides an unfamiliar and
challenging environment for LLMs. The experimental results demonstrate the
effectiveness of PLAP. In particular, GPT-4o-driven PLAP in a zero-shot setting
outperforms 80% of baseline agents, and Qwen2-72B-driven PLAP, with carefully
crafted few-shot examples, surpasses the top-tier scripted agent, CoacAI.
Additionally, we design comprehensive evaluation metrics and test 6
closed-source and 2 open-source LLMs within the PLAP framework, ultimately
releasing an LLM leaderboard ranking long-horizon skill planning ability. Our
code is available at https://github.com/AI-Research-TeamX/PLAP.

</details>


### [36] [LLM Hallucination Detection: A Fast Fourier Transform Method Based on Hidden Layer Temporal Signals](https://arxiv.org/abs/2509.13154)
*Jinxin Li,Gang Tu,ShengYu Cheng,Junjie Hu,Jinting Wang,Rui Chen,Zhilong Zhou,Dongbo Shan*

Main category: cs.CL

TL;DR: HSAD是一种基于隐藏信号分析的幻觉检测框架，通过分析自回归生成过程中隐藏表示的时间动态，在频域提取特征，在多个基准测试中比现有方法提升10个百分点以上。


<details>
  <summary>Details</summary>
Motivation: 现有幻觉检测方法存在局限性：事实性检查受外部知识覆盖范围限制，静态隐藏状态分析无法捕捉推理动态中的偏差，导致效果和鲁棒性有限。

Method: HSAD通过跨层采样激活构建隐藏层信号，应用快速傅里叶变换获得频域表示，提取最强非直流频率分量作为频谱特征，并利用自回归特性确定最佳观测点。

Result: 在包括TruthfulQA在内的多个基准测试中，HSAD相比之前的最先进方法实现了超过10个百分点的改进。

Conclusion: 通过将推理过程建模与频域分析相结合，HSAD为大语言模型中的鲁棒幻觉检测建立了新范式。

Abstract: Hallucination remains a critical barrier for deploying large language models
(LLMs) in reliability-sensitive applications. Existing detection methods
largely fall into two categories: factuality checking, which is fundamentally
constrained by external knowledge coverage, and static hidden-state analysis,
that fails to capture deviations in reasoning dynamics. As a result, their
effectiveness and robustness remain limited. We propose HSAD (Hidden Signal
Analysis-based Detection), a novel hallucination detection framework that
models the temporal dynamics of hidden representations during autoregressive
generation. HSAD constructs hidden-layer signals by sampling activations across
layers, applies Fast Fourier Transform (FFT) to obtain frequency-domain
representations, and extracts the strongest non-DC frequency component as
spectral features. Furthermore, by leveraging the autoregressive nature of
LLMs, HSAD identifies optimal observation points for effective and reliable
detection. Across multiple benchmarks, including TruthfulQA, HSAD achieves over
10 percentage points improvement compared to prior state-of-the-art methods. By
integrating reasoning-process modeling with frequency-domain analysis, HSAD
establishes a new paradigm for robust hallucination detection in LLMs.

</details>


### [37] [The Few-shot Dilemma: Over-prompting Large Language Models](https://arxiv.org/abs/2509.13196)
*Yongjian Tang,Doruk Tuncel,Christian Koerner,Thomas Runkler*

Main category: cs.CL

TL;DR: 研究发现过度提示（过多示例）会降低大语言模型性能，通过三种少样本选择方法确定了各模型的最佳示例数量，在需求分类任务中超越SOTA 1%


<details>
  <summary>Details</summary>
Motivation: 挑战传统少样本学习观念，研究过度提示现象对LLM性能的影响，特别是在软件工程和需求分析领域的应用

Method: 使用随机采样、语义嵌入和TF-IDF向量三种少样本选择方法，在多个LLM上评估，通过逐步增加TF-IDF选择和分层少样本示例数量来确定最优数量

Result: 实验显示过多领域特定示例会降低某些LLM性能，确定了各模型的最佳示例数量，在功能和非功能需求分类任务中性能提升1%

Conclusion: 过度提示确实存在，需要为不同LLM确定最优示例数量，TF-IDF结合分层选择的方法能以更少示例获得更好性能，避免过度提示问题

Abstract: Over-prompting, a phenomenon where excessive examples in prompts lead to
diminished performance in Large Language Models (LLMs), challenges the
conventional wisdom about in-context few-shot learning. To investigate this
few-shot dilemma, we outline a prompting framework that leverages three
standard few-shot selection methods - random sampling, semantic embedding, and
TF-IDF vectors - and evaluate these methods across multiple LLMs, including
GPT-4o, GPT-3.5-turbo, DeepSeek-V3, Gemma-3, LLaMA-3.1, LLaMA-3.2, and Mistral.
Our experimental results reveal that incorporating excessive domain-specific
examples into prompts can paradoxically degrade performance in certain LLMs,
which contradicts the prior empirical conclusion that more relevant few-shot
examples universally benefit LLMs. Given the trend of LLM-assisted software
engineering and requirement analysis, we experiment with two real-world
software requirement classification datasets. By gradually increasing the
number of TF-IDF-selected and stratified few-shot examples, we identify their
optimal quantity for each LLM. This combined approach achieves superior
performance with fewer examples, avoiding the over-prompting problem, thus
surpassing the state-of-the-art by 1% in classifying functional and
non-functional requirements.

</details>


### [38] [Evaluating LLM Alignment on Personality Inference from Real-World Interview Data](https://arxiv.org/abs/2509.13244)
*Jianfeng Zhu,Julina Maharjan,Xinyu Li,Karin G. Coifman,Ruoming Jin*

Main category: cs.CL

TL;DR: LLM在人格特质评估方面表现有限，所有模型预测与真实人格特质的Pearson相关系数均低于0.26，表明当前LLM与验证心理构念的对齐度不足


<details>
  <summary>Details</summary>
Motivation: 随着LLM在需要心理理解的角色中部署增加，如情感支持代理和决策助手，但其在生态有效的对话环境中解释人类人格特质的能力尚未被探索

Method: 引入包含半结构化访谈记录和验证性连续大五人格特质分数的新基准，系统评估三种范式：零样本和思维链提示、LoRA微调、预训练嵌入回归

Result: 所有模型预测与真实人格特质的相关系数均低于0.26，思维链提示相比零样本提示提升有限，表明人格推断更多依赖潜在语义表示而非显式推理

Conclusion: 研究结果强调了将LLM与复杂人类属性对齐的挑战，需要未来在特质特定提示、上下文感知建模和对齐导向微调方面的工作

Abstract: Large Language Models (LLMs) are increasingly deployed in roles requiring
nuanced psychological understanding, such as emotional support agents,
counselors, and decision-making assistants. However, their ability to interpret
human personality traits, a critical aspect of such applications, remains
unexplored, particularly in ecologically valid conversational settings. While
prior work has simulated LLM "personas" using discrete Big Five labels on
social media data, the alignment of LLMs with continuous, ground-truth
personality assessments derived from natural interactions is largely
unexamined. To address this gap, we introduce a novel benchmark comprising
semi-structured interview transcripts paired with validated continuous Big Five
trait scores. Using this dataset, we systematically evaluate LLM performance
across three paradigms: (1) zero-shot and chain-of-thought prompting with
GPT-4.1 Mini, (2) LoRA-based fine-tuning applied to both RoBERTa and Meta-LLaMA
architectures, and (3) regression using static embeddings from pretrained BERT
and OpenAI's text-embedding-3-small. Our results reveal that all Pearson
correlations between model predictions and ground-truth personality traits
remain below 0.26, highlighting the limited alignment of current LLMs with
validated psychological constructs. Chain-of-thought prompting offers minimal
gains over zero-shot, suggesting that personality inference relies more on
latent semantic representation than explicit reasoning. These findings
underscore the challenges of aligning LLMs with complex human attributes and
motivate future work on trait-specific prompting, context-aware modeling, and
alignment-oriented fine-tuning.

</details>


### [39] [ChartGaze: Enhancing Chart Understanding in LVLMs with Eye-Tracking Guided Attention Refinement](https://arxiv.org/abs/2509.13282)
*Ali Salamatian,Amirhossein Abaskohi,Wan-Cyuan Fan,Mir Rayat Imtiaz Hossain,Leonid Sigal,Giuseppe Carenini*

Main category: cs.CL

TL;DR: ChartGaze是一个新的眼动追踪数据集，通过比较人类和模型注意力模式，发现LVLMs在图表推理中注意力分布与人类存在差异，提出了基于人类注视的注意力优化方法，显著提升了模型准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在图表问答任务中表现不佳，主要问题是模型关注图表中不相关区域，与人类推理时的注意力模式存在差异，影响了模型的准确性和可解释性。

Method: 构建ChartGaze眼动追踪数据集记录人类图表推理时的注视模式，通过系统比较人类与模型注意力差异，提出基于人类注视的注意力优化方法，将图像-文本注意力与人类注视点对齐。

Result: 该方法在多个模型上实现了最高2.56个百分点的准确率提升，同时显著改善了注意力对齐效果。

Conclusion: 人类注视信息可以有效提升图表相关LVLMs的推理质量和可解释性，为模型优化提供了新的方向。

Abstract: Charts are a crucial visual medium for communicating and representing
information. While Large Vision-Language Models (LVLMs) have made progress on
chart question answering (CQA), the task remains challenging, particularly when
models attend to irrelevant regions of the chart. In this work, we present
ChartGaze, a new eye-tracking dataset that captures human gaze patterns during
chart reasoning tasks. Through a systematic comparison of human and model
attention, we find that LVLMs often diverge from human gaze, leading to reduced
interpretability and accuracy. To address this, we propose a gaze-guided
attention refinement that aligns image-text attention with human fixations. Our
approach improves both answer accuracy and attention alignment, yielding gains
of up to 2.56 percentage points across multiple models. These results
demonstrate the promise of incorporating human gaze to enhance both the
reasoning quality and interpretability of chart-focused LVLMs.

</details>


### [40] [WebResearcher: Unleashing unbounded reasoning capability in Long-Horizon Agents](https://arxiv.org/abs/2509.13309)
*Zile Qiao,Guoxin Chen,Xuanzhong Chen,Donglei Yu,Wenbiao Yin,Xinyu Wang,Zhen Zhang,Baixuan Li,Huifeng Yin,Kuan Li,Rui Min,Minpeng Liao,Yong Jiang,Pengjun Xie,Fei Huang,Jingren Zhou*

Main category: cs.CL

TL;DR: WebResearcher是一个创新的深度研究框架，通过迭代式研究范式和可扩展数据合成引擎，解决了现有单上下文方法的上下文窒息和噪声污染问题，在6个基准测试中达到最先进性能


<details>
  <summary>Details</summary>
Motivation: 现有AI代理在自主发现和合成外部知识时面临上下文窒息和噪声污染的问题，需要新的框架来克服这些限制

Method: 包含两个核心组件：(1) WebResearcher迭代深度研究范式，将深度研究建模为马尔可夫决策过程，定期整合发现到演进报告中；(2) WebFrontier可扩展数据合成引擎，通过工具增强的复杂性升级生成高质量训练数据

Result: 在6个具有挑战性的基准测试中实现了最先进的性能，甚至超越了前沿专有系统。训练数据显著提升了传统单上下文方法的工具使用能力

Conclusion: WebResearcher框架通过并行思维自然扩展，支持并发多代理探索，能够产生更全面的结论，为构建自主知识发现AI代理提供了有效解决方案

Abstract: Recent advances in deep-research systems have demonstrated the potential for
AI agents to autonomously discover and synthesize knowledge from external
sources. In this paper, we introduce WebResearcher, a novel framework for
building such agents through two key components: (1) WebResearcher, an
iterative deep-research paradigm that reformulates deep research as a Markov
Decision Process, where agents periodically consolidate findings into evolving
reports while maintaining focused workspaces, overcoming the context
suffocation and noise contamination that plague existing mono-contextual
approaches; and (2) WebFrontier, a scalable data synthesis engine that
generates high-quality training data through tool-augmented complexity
escalation, enabling systematic creation of research tasks that bridge the gap
between passive knowledge recall and active knowledge construction. Notably, we
find that the training data from our paradigm significantly enhances tool-use
capabilities even for traditional mono-contextual methods. Furthermore, our
paradigm naturally scales through parallel thinking, enabling concurrent
multi-agent exploration for more comprehensive conclusions. Extensive
experiments across 6 challenging benchmarks demonstrate that WebResearcher
achieves state-of-the-art performance, even surpassing frontier proprietary
systems.

</details>


### [41] [Scaling Agents via Continual Pre-training](https://arxiv.org/abs/2509.13310)
*Liangcai Su,Zhen Zhang,Guangyu Li,Zhuo Chen,Chenxi Wang,Maojia Song,Xinyu Wang,Kuan Li,Jialong Wu,Xuanzhong Chen,Zile Qiao,Zhongwang Zhang,Huifeng Yin,Shihao Cai,Runnan Fang,Zhengwei Tao,Wenbiao Yin,Chenxiong Qian,Yong Jiang,Pengjun Xie,Fei Huang,Jingren Zhou*

Main category: cs.CL

TL;DR: 该论文提出了一种新的Agentic Continual Pre-training方法，通过构建强大的代理基础模型AgentFounder，解决了现有后训练方法在代理任务上表现不佳的问题，并在10个标准测试中达到了最先进水平。


<details>
  <summary>Details</summary>
Motivation: 现有的通用基础模型通过后训练方法在代理任务上表现差强，根本原因是缺乏健壮的代理基础模型，导致模型需要同时学习多样化代理行为和对齐专家示范，产生了优化矛盾。

Method: 提出将Agentic Continual Pre-training结合到深度研究代理训练流程中，构建强大的代理基础模型，开发了深度研究代理模型AgentFounder。

Result: 在10个标准测试中达到了state-of-the-art性能，保持了强大的工具使用能力，特别是在BrowseComp-en上获39.9%，BrowseComp-zh上获43.3%，HLE上Pass@1获31.5%。

Conclusion: 通过Agentic Continual Pre-training方法构建的AgentFounder模型有效解决了代理基础模型缺失的问题，在多个代理任务上实现了最先进的性能表现。

Abstract: Large language models (LLMs) have evolved into agentic systems capable of
autonomous tool use and multi-step reasoning for complex problem-solving.
However, post-training approaches building upon general-purpose foundation
models consistently underperform in agentic tasks, particularly in open-source
implementations. We identify the root cause: the absence of robust agentic
foundation models forces models during post-training to simultaneously learn
diverse agentic behaviors while aligning them to expert demonstrations, thereby
creating fundamental optimization tensions. To this end, we are the first to
propose incorporating Agentic Continual Pre-training (Agentic CPT) into the
deep research agents training pipeline to build powerful agentic foundational
models. Based on this approach, we develop a deep research agent model named
AgentFounder. We evaluate our AgentFounder-30B on 10 benchmarks and achieve
state-of-the-art performance while retains strong tool-use ability, notably
39.9% on BrowseComp-en, 43.3% on BrowseComp-zh, and 31.5% Pass@1 on HLE.

</details>


### [42] [Towards General Agentic Intelligence via Environment Scaling](https://arxiv.org/abs/2509.13311)
*Runnan Fang,Shihao Cai,Baixuan Li,Jialong Wu,Guangyu Li,Wenbiao Yin,Xinyu Wang,Xiaobin Wang,Liangcai Su,Zhen Zhang,Shibin Wu,Zhengwei Tao,Yong Jiang,Pengjun Xie,Fei Huang,Jingren Zhou*

Main category: cs.CL

TL;DR: 通过规模化自动构建异构环境和两阶段细调策略，大幅提升大语言模型的函数调用能力


<details>
  <summary>Details</summary>
Motivation: 实际应用需要大语言模型具备准确稳健的函数调用智能，而这种能力的广度依赖于训练环境的多样性

Method: 设计可扩展框架自动构建异构模拟环境，采用两阶段细调策略：先培养基础代理能力，再专门化领域能力

Result: 在agentic benchmarks、tau-bench、tau2-Bench和ACEBench等测试集上，AgentScaler模型显著提升了函数调用能力

Conclusion: 通过环境扩展和系统化训练方法，可有效提升大语言模型的代理智能，为实际应用部署奠定基础

Abstract: Advanced agentic intelligence is a prerequisite for deploying Large Language
Models in practical, real-world applications. Diverse real-world APIs demand
precise, robust function-calling intelligence, which needs agents to develop
these capabilities through interaction in varied environments. The breadth of
function-calling competence is closely tied to the diversity of environments in
which agents are trained. In this work, we scale up environments as a step
towards advancing general agentic intelligence. This gives rise to two central
challenges: (i) how to scale environments in a principled manner, and (ii) how
to effectively train agentic capabilities from experiences derived through
interactions with these environments. To address these, we design a scalable
framework that automatically constructs heterogeneous environments that are
fully simulated, systematically broadening the space of function-calling
scenarios. We further adapt a two-phase agent fine-tuning strategy: first
endowing agents with fundamental agentic capabilities, then specializing them
for domain-specific contexts. Extensive experiments on agentic benchmarks,
tau-bench, tau2-Bench, and ACEBench, demonstrate that our trained model,
AgentScaler, significantly enhances the function-calling capability of models.

</details>


### [43] [WebWeaver: Structuring Web-Scale Evidence with Dynamic Outlines for Open-Ended Deep Research](https://arxiv.org/abs/2509.13312)
*Zijian Li,Xin Guan,Bo Zhang,Shen Huang,Houquan Zhou,Shaopeng Lai,Ming Yan,Yong Jiang,Pengjun Xie,Fei Huang,Jun Zhang,Jingren Zhou*

Main category: cs.CL

TL;DR: WebWeaver是一个双代理框架，通过动态规划和分层检索写作来解决开放深度研究中的长上下文问题和幻觉问题，在多个基准测试中达到最先进水平


<details>
  <summary>Details</summary>
Motivation: 解决现有开放深度研究(OEDR)方法中静态研究流程和一次性生成范式导致的长上下文失败问题和幻觉问题

Method: 提出双代理框架：规划器动态循环迭代证据获取和提纲优化，写作者执行分层检索和分段写作，针对性检索必要证据

Result: 在DeepResearch Bench、DeepConsult和DeepResearchGym等主要OEDR基准测试中建立了新的最先进水平

Conclusion: 验证了以人为中心的迭代方法学，证明自适应规划和聚焦合成对于产生高质量、可靠且结构良好的报告至关重要

Abstract: This paper tackles open-ended deep research (OEDR), a complex challenge where
AI agents must synthesize vast web-scale information into insightful reports.
Current approaches are plagued by dual-fold limitations: static research
pipelines that decouple planning from evidence acquisition and one-shot
generation paradigms that easily suffer from long-context failure issues like
"loss in the middle" and hallucinations. To address these challenges, we
introduce WebWeaver, a novel dual-agent framework that emulates the human
research process. The planner operates in a dynamic cycle, iteratively
interleaving evidence acquisition with outline optimization to produce a
comprehensive, source-grounded outline linking to a memory bank of evidence.
The writer then executes a hierarchical retrieval and writing process,
composing the report section by section. By performing targeted retrieval of
only the necessary evidence from the memory bank for each part, it effectively
mitigates long-context issues. Our framework establishes a new state-of-the-art
across major OEDR benchmarks, including DeepResearch Bench, DeepConsult, and
DeepResearchGym. These results validate our human-centric, iterative
methodology, demonstrating that adaptive planning and focused synthesis are
crucial for producing high-quality, reliable, and well-structured reports.

</details>


### [44] [ReSum: Unlocking Long-Horizon Search Intelligence via Context Summarization](https://arxiv.org/abs/2509.13313)
*Xixi Wu,Kuan Li,Yida Zhao,Liwen Zhang,Litu Ou,Huifeng Yin,Zhongwang Zhang,Yong Jiang,Pengjun Xie,Fei Huang,Minhao Cheng,Shuai Wang,Hong Cheng,Jingren Zhou*

Main category: cs.CL

TL;DR: ReSum是一种新的LLM网络代理范式，通过周期性上下文摘要实现无限探索，解决了ReAct等方法的上下文窗口限制问题。


<details>
  <summary>Details</summary>
Motivation: 基于LLM的网络代理在知识密集型任务上表现良好，但受到上下文窗口限制的阻碍。复杂查询涉及多个实体、相互关联的关系和高不确定性，需要大量搜索周期，在达到完整解决方案之前迅速耗尽上下文预算。

Method: 引入ReSum范式，通过定期上下文摘要将不断增长的交互历史转换为紧凑的推理状态，保持对先前发现的感知同时绕过上下文约束。提出ReSum-GRPO，将GRPO与分段轨迹训练和优势广播相结合，使代理熟悉基于摘要的推理。

Result: 在三个基准测试中，ReSum相比ReAct平均绝对提升4.5%，经过ReSum-GRPO训练后进一步提升至8.2%。WebResummer-30B在BrowseComp-zh上达到33.3% Pass@1，在BrowseComp-en上达到18.3%，超越了现有开源网络代理。

Conclusion: ReSum通过上下文摘要机制有效解决了LLM网络代理的上下文限制问题，结合ReSum-GRPO训练方法显著提升了代理性能，在仅使用1K训练样本的情况下就取得了优异结果。

Abstract: Large Language Model (LLM)-based web agents demonstrate strong performance on
knowledge-intensive tasks but are hindered by context window limitations in
paradigms like ReAct. Complex queries involving multiple entities, intertwined
relationships, and high uncertainty demand extensive search cycles that rapidly
exhaust context budgets before reaching complete solutions. To overcome this
challenge, we introduce ReSum, a novel paradigm that enables indefinite
exploration through periodic context summarization. ReSum converts growing
interaction histories into compact reasoning states, maintaining awareness of
prior discoveries while bypassing context constraints. For paradigm adaptation,
we propose ReSum-GRPO, integrating GRPO with segmented trajectory training and
advantage broadcasting to familiarize agents with summary-conditioned
reasoning. Extensive experiments on web agents of varying scales across three
benchmarks demonstrate that ReSum delivers an average absolute improvement of
4.5\% over ReAct, with further gains of up to 8.2\% following ReSum-GRPO
training. Notably, with only 1K training samples, our WebResummer-30B (a
ReSum-GRPO-trained version of WebSailor-30B) achieves 33.3\% Pass@1 on
BrowseComp-zh and 18.3\% on BrowseComp-en, surpassing existing open-source web
agents.

</details>


### [45] [Do Natural Language Descriptions of Model Activations Convey Privileged Information?](https://arxiv.org/abs/2509.13316)
*Millicent Li,Alberto Mario Ceballos Arroyo,Giordano Rogers,Naomi Saphra,Byron C. Wallace*

Main category: cs.CL

TL;DR: 近期的可解释性方法使用第二个语言模型将LLM内部表征转换为自然语言描述，但研究发现这些方法常常反映的是语言模型的参数知识而非目标模型的激活信息，需要更严格的评测标准和实验控制。


<details>
  <summary>Details</summary>
Motivation: 评估激活语言化方法是否真正揭示了目标LLM的内部运作机制，还是仅仅传递了输入信息或语言模型的参数知识。

Method: 在以往工作使用的数据集上评估流行的语言化方法，进行受控实验来分析语言化内容的来源。

Result: 发现语言化方法在无法访问目标模型内部状态的情况下仍能在基准测试中取得成功，语言化内容常常反映语言模型的参数知识而非目标LLM的激活信息。

Conclusion: 需要针对性的标准测试集和实验控制来严格评估语言化方法是否真正提供了对LLM运作机制的有效洞察。

Abstract: Recent interpretability methods have proposed to translate LLM internal
representations into natural language descriptions using a second verbalizer
LLM. This is intended to illuminate how the target model represents and
operates on inputs. But do such activation verbalization approaches actually
provide privileged knowledge about the internal workings of the target model,
or do they merely convey information about its inputs? We critically evaluate
popular verbalization methods across datasets used in prior work and find that
they succeed at benchmarks without any access to target model internals,
suggesting that these datasets are not ideal for evaluating verbalization
methods. We then run controlled experiments which reveal that verbalizations
often reflect the parametric knowledge of the verbalizer LLM which generated
them, rather than the activations of the target LLM being decoded. Taken
together, our results indicate a need for targeted benchmarks and experimental
controls to rigorously assess whether verbalization methods provide meaningful
insights into the operations of LLMs.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [46] [LLMAP: LLM-Assisted Multi-Objective Route Planning with User Preferences](https://arxiv.org/abs/2509.12273)
*Liangqi Yuan,Dong-Jun Han,Christopher G. Brinton,Sabine Brunswicker*

Main category: cs.AI

TL;DR: 提出LLMAP系统，结合LLM解析自然语言偏好和多步图搜索算法，解决多约束条件下的最优路径规划问题


<details>
  <summary>Details</summary>
Motivation: 现有LLM路径规划方法存在两大问题：直接使用LLM处理大规模地图数据困难，图搜索方法理解自然语言偏好能力有限，且全球用户时空分布高度异构不可预测

Method: 使用LLM-as-Parser解析自然语言、识别任务、提取用户偏好和任务依赖关系，结合多步图构建迭代搜索算法(MSGS)进行最优路径搜索，采用多目标优化自适应调整权重

Result: 在14个国家27个城市的1000个不同复杂度路由提示上进行实验，结果显示该方法在多重约束下实现优越性能且有保证

Conclusion: LLMAP系统成功解决了自然语言驱动路径规划中的关键挑战，在理解用户偏好和处理复杂约束方面表现出色

Abstract: The rise of large language models (LLMs) has made natural language-driven
route planning an emerging research area that encompasses rich user objectives.
Current research exhibits two distinct approaches: direct route planning using
LLM-as-Agent and graph-based searching strategies. However, LLMs in the former
approach struggle to handle extensive map data, while the latter shows limited
capability in understanding natural language preferences. Additionally, a more
critical challenge arises from the highly heterogeneous and unpredictable
spatio-temporal distribution of users across the globe. In this paper, we
introduce a novel LLM-Assisted route Planning (LLMAP) system that employs an
LLM-as-Parser to comprehend natural language, identify tasks, and extract user
preferences and recognize task dependencies, coupled with a Multi-Step Graph
construction with iterative Search (MSGS) algorithm as the underlying solver
for optimal route finding. Our multi-objective optimization approach adaptively
tunes objective weights to maximize points of interest (POI) quality and task
completion rate while minimizing route distance, subject to three key
constraints: user time limits, POI opening hours, and task dependencies. We
conduct extensive experiments using 1,000 routing prompts sampled with varying
complexity across 14 countries and 27 cities worldwide. The results demonstrate
that our approach achieves superior performance with guarantees across multiple
constraints.

</details>


### [47] [Small Models, Big Results: Achieving Superior Intent Extraction through Decomposition](https://arxiv.org/abs/2509.12423)
*Danielle Cohen,Yoni Halpern,Noam Kahlon,Joel Oren,Omri Berkovitch,Sapir Caduri,Ido Dagan,Anatoly Efros*

Main category: cs.AI

TL;DR: 通过分解的结构化交互摘要和意图提取方法，提升了质源受限模型在UI交互轨迹意图理解上的性能，甚至超越大型多模态语言模型


<details>
  <summary>Details</summary>
Motivation: 解决质源受限的设备端模型在UI交互轨迹意图推理上的困难，提供隐私保护、低成本、低延迟的用户体验

Method: 首先进行结构化交互摘要捕获每个用户动作的关键信息，然后使用细调模型在聚合摘要上进行意图提取

Result: 该方法提高了质源受限模型的意图理解能力，甚至超过了大型多模态语言模型的基础性能

Conclusion: 分解方法为质源受限环境下的智能代理意图理解提供了有效解决方案，在保持隐私和低延迟的同时提升了准确性

Abstract: Understanding user intents from UI interaction trajectories remains a
challenging, yet crucial, frontier in intelligent agent development. While
massive, datacenter-based, multi-modal large language models (MLLMs) possess
greater capacity to handle the complexities of such sequences, smaller models
which can run on-device to provide a privacy-preserving, low-cost, and
low-latency user experience, struggle with accurate intent inference. We
address these limitations by introducing a novel decomposed approach: first, we
perform structured interaction summarization, capturing key information from
each user action. Second, we perform intent extraction using a fine-tuned model
operating on the aggregated summaries. This method improves intent
understanding in resource-constrained models, even surpassing the base
performance of large MLLMs.

</details>


### [48] [Match Chat: Real Time Generative AI and Generative Computing for Tennis](https://arxiv.org/abs/2509.12592)
*Aaron Baughman,Gozde Akay,Eduardo Morales,Rahul Agarwal,Preetika Srivastava*

Main category: cs.AI

TL;DR: Match Chat是一个实时AI助手系统，通过结合GenAI和GenComp技术，为网球比赛观众提供即时准确的比赛相关信息查询服务，在温网和美网中成功服务约100万用户。


<details>
  <summary>Details</summary>
Motivation: 提升网球观众的观赛体验，通过自然语言查询提供实时比赛洞察，解决传统查询方式的复杂性和延迟问题。

Method: 采用面向代理架构(AOA)，结合规则引擎、预测模型和代理系统预处理和优化用户查询，再传递给GenAI组件处理，使用交互式提示设计引导96.08%的查询。

Result: 系统准确率达92.83%，平均响应时间6.25秒，支持120 RPS负载，100%正常运行时间，服务近100万独特用户。

Conclusion: 该系统展示了在动态环境中部署高性能代理系统的实用路径，为实时面向消费者的AI系统提供了关键设计模式，强调速度、精确性和可用性。

Abstract: We present Match Chat, a real-time, agent-driven assistant designed to
enhance the tennis fan experience by delivering instant, accurate responses to
match-related queries. Match Chat integrates Generative Artificial Intelligence
(GenAI) with Generative Computing (GenComp) techniques to synthesize key
insights during live tennis singles matches. The system debuted at the 2025
Wimbledon Championships and the 2025 US Open, where it provided about 1 million
users with seamless access to streaming and static data through natural
language queries. The architecture is grounded in an Agent-Oriented
Architecture (AOA) combining rule engines, predictive models, and agents to
pre-process and optimize user queries before passing them to GenAI components.
The Match Chat system had an answer accuracy of 92.83% with an average response
time of 6.25 seconds under loads of up to 120 requests per second (RPS). Over
96.08% of all queries were guided using interactive prompt design, contributing
to a user experience that prioritized clarity, responsiveness, and minimal
effort. The system was designed to mask architectural complexity, offering a
frictionless and intuitive interface that required no onboarding or technical
familiarity. Across both Grand Slam deployments, Match Chat maintained 100%
uptime and supported nearly 1 million unique users, underscoring the
scalability and reliability of the platform. This work introduces key design
patterns for real-time, consumer-facing AI systems that emphasize speed,
precision, and usability that highlights a practical path for deploying
performant agentic systems in dynamic environments.

</details>


### [49] [DaSAThco: Data-Aware SAT Heuristics Combinations Optimization via Large Language Models](https://arxiv.org/abs/2509.12602)
*Minyu Chen,Guoqiang Li*

Main category: cs.AI

TL;DR: DaSAThco是一个使用LLM生成多样化启发式集成并通过自适应选择机制实现从实例特征到定制化启发式集成通用映射的框架，解决了SAT求解器配置通用性问题。


<details>
  <summary>Details</summary>
Motivation: SAT问题的异构性使得单一最优配置不可行，现有方法缺乏泛化性且需要为新问题类型重新优化，需要一种可泛化的自适应配置方法。

Method: 使用大型语言模型在系统定义的问题原型指导下生成多样化专用启发式集成组合，然后学习自适应选择机制形成最终映射。

Result: 实验显示DaSAThco实现了优越性能，并在非自适应方法表现有限的情况下展现出强大的域外泛化能力。

Conclusion: 该工作为复杂可配置系统的自动化算法设计建立了更可扩展和实用的路径。

Abstract: The performance of Conflict-Driven Clause Learning solvers hinges on internal
heuristics, yet the heterogeneity of SAT problems makes a single, universally
optimal configuration unattainable. While prior automated methods can find
specialized configurations for specific problem families, this dataset-specific
approach lacks generalizability and requires costly re-optimization for new
problem types. We introduce DaSAThco, a framework that addresses this challenge
by learning a generalizable mapping from instance features to tailored
heuristic ensembles, enabling a train-once, adapt-broadly model. Our framework
uses a Large Language Model, guided by systematically defined Problem
Archetypes, to generate a diverse portfolio of specialized heuristic ensembles
and subsequently learns an adaptive selection mechanism to form the final
mapping. Experiments show that DaSAThco achieves superior performance and, most
notably, demonstrates robust out-of-domain generalization where non-adaptive
methods show limitations. Our work establishes a more scalable and practical
path toward automated algorithm design for complex, configurable systems.

</details>


### [50] [Zero-shot Graph Reasoning via Retrieval Augmented Framework with LLMs](https://arxiv.org/abs/2509.12743)
*Hanqing Li,Kiran Sheena Jyothi,Henry Liang,Sharika Mahadevan,Diego Klabjan*

Main category: cs.AI

TL;DR: GRRAF是一种无需训练的图推理方法，利用检索增强生成(RAG)和LLM的代码生成能力，通过生成可执行查询从图数据库中检索信息，在多种图推理任务上达到100%准确率，并能扩展到万节点大图。


<details>
  <summary>Details</summary>
Motivation: 现有图推理方法需要大量微调或依赖预定义算法，存在局限性。GRRAF旨在开发一种无需训练、灵活且可扩展的通用图推理框架。

Method: 将目标图存储在图形数据库中，提示LLM生成可执行代码查询来检索必要信息，包含错误反馈循环和超时机制确保正确性和效率。

Result: 在GraphInstruct数据集上，大多数图推理任务达到100%准确率（包括环检测、二分图检查、最短路径和最大流计算），子图匹配性能也很高，能有效扩展到10,000个节点的大图，且token成本与图大小无关。

Conclusion: GRRAF提供了一种高效、准确且可扩展的训练无关图推理解决方案，通过结合RAG和LLM代码生成能力，克服了传统方法的限制。

Abstract: We propose a new, training-free method, Graph Reasoning via Retrieval
Augmented Framework (GRRAF), that harnesses retrieval-augmented generation
(RAG) alongside the code-generation capabilities of large language models
(LLMs) to address a wide range of graph reasoning tasks. In GRRAF, the target
graph is stored in a graph database, and the LLM is prompted to generate
executable code queries that retrieve the necessary information. This approach
circumvents the limitations of existing methods that require extensive
finetuning or depend on predefined algorithms, and it incorporates an error
feedback loop with a time-out mechanism to ensure both correctness and
efficiency. Experimental evaluations on the GraphInstruct dataset reveal that
GRRAF achieves 100% accuracy on most graph reasoning tasks, including cycle
detection, bipartite graph checks, shortest path computation, and maximum flow,
while maintaining consistent token costs regardless of graph sizes. Imperfect
but still very high performance is observed on subgraph matching. Notably,
GRRAF scales effectively to large graphs with up to 10,000 nodes.

</details>


### [51] [RepIt: Representing Isolated Targets to Steer Language Models](https://arxiv.org/abs/2509.13281)
*Vincent Siu,Nathan W. Henry,Nicholas Crispino,Yang Liu,Dawn Song,Chenguang Wang*

Main category: cs.AI

TL;DR: RepIt是一个简单高效的概念表示分离框架，能够在大型语言模型中精确干预特定概念，仅需少量数据和计算即可实现针对性行为控制。


<details>
  <summary>Details</summary>
Motivation: 现有激活导向方法往往产生比预期更广泛的影响，需要更纯净的概念向量来实现针对性干预和更细粒度的模型行为理解。

Method: 提出RepIt框架，通过分离概念特定表示来精确干预模型行为，仅需100-200个神经元和少量示例数据即可实现有效控制。

Result: 在五个前沿LLM上，RepIt能够选择性抑制特定概念的拒绝行为，同时保持其他方面的拒绝能力，使模型既能回答WMD相关问题，又在标准基准测试中保持安全评分。

Conclusion: RepIt展示了针对性干预可以抵消过度泛化问题，为更细粒度的模型行为控制奠定了基础，但也引发了对低计算和数据需求可能被滥用的担忧。

Abstract: While activation steering in large language models (LLMs) is a growing area
of research, methods can often incur broader effects than desired. This
motivates isolation of purer concept vectors to enable targeted interventions
and understand LLM behavior at a more granular level. We present RepIt, a
simple and data-efficient framework for isolating concept-specific
representations. Across five frontier LLMs, RepIt enables precise
interventions: it selectively suppresses refusal on targeted concepts while
preserving refusal elsewhere, producing models that answer WMD-related
questions while still scoring as safe on standard benchmarks. We further show
that the corrective signal localizes to just 100-200 neurons and that robust
target representations can be extracted from as few as a dozen examples on a
single A6000. This efficiency raises a dual concern: manipulations can be
performed with modest compute and data to extend to underrepresented
data-scarce topics while evading existing benchmarks. By disentangling refusal
vectors with RepIt, this work demonstrates that targeted interventions can
counteract overgeneralization, laying the foundation for more granular control
of model behavior.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [52] [The Better You Learn, The Smarter You Prune: Towards Efficient Vision-language-action Models via Differentiable Token Pruning](https://arxiv.org/abs/2509.12594)
*Titong Jiang,Xuefeng Jiang,Yuan Ma,Xin Wen,Bailin Li,Kun Zhan,Peng Jia,Yahui Liu,Sheng Sun,Xianpeng Lang*

Main category: cs.RO

TL;DR: LightVLA是一个用于视觉-语言-动作模型的差异化token剪枝框架，通过自适应剪枝视觉token来减少计算开销，同时提升任务性能，在LIBERO基准测试中实现了59.1%的FLOPs减少和2.9%的成功率提升。


<details>
  <summary>Details</summary>
Motivation: 视觉-语言-动作模型在资源受限平台部署时，由于大量视觉token的注意力计算导致计算瓶颈，需要一种高效的token剪枝方法来平衡计算效率和任务性能。

Method: 使用动态查询评估视觉token重要性，采用Gumbel softmax实现差异化token选择，通过微调学习保留信息丰富的token，剪枝对任务执行无贡献的token，无需启发式参数和额外可训练参数。

Result: 在LIBERO基准测试中，LightVLA相比现有方法在多个任务上表现更优，FLOPs减少59.1%，延迟降低38.2%，任务成功率提升2.9%。LightVLA*变体也取得了满意性能。

Conclusion: LightVLA首次将自适应视觉token剪枝应用于VLA任务，从性能驱动角度自发学习剪枝策略，为实现更高效、强大和实用的实时机器人系统迈出了重要一步。

Abstract: We present LightVLA, a simple yet effective differentiable token pruning
framework for vision-language-action (VLA) models. While VLA models have shown
impressive capability in executing real-world robotic tasks, their deployment
on resource-constrained platforms is often bottlenecked by the heavy
attention-based computation over large sets of visual tokens. LightVLA
addresses this challenge through adaptive, performance-driven pruning of visual
tokens: It generates dynamic queries to evaluate visual token importance, and
adopts Gumbel softmax to enable differentiable token selection. Through
fine-tuning, LightVLA learns to preserve the most informative visual tokens
while pruning tokens which do not contribute to task execution, thereby
improving efficiency and performance simultaneously. Notably, LightVLA requires
no heuristic magic numbers and introduces no additional trainable parameters,
making it compatible with modern inference frameworks. Experimental results
demonstrate that LightVLA outperforms different VLA models and existing token
pruning methods across diverse tasks on the LIBERO benchmark, achieving higher
success rates with substantially reduced computational overhead. Specifically,
LightVLA reduces FLOPs and latency by 59.1% and 38.2% respectively, with a 2.9%
improvement in task success rate. Meanwhile, we also investigate the learnable
query-based token pruning method LightVLA* with additional trainable
parameters, which also achieves satisfactory performance. Our work reveals that
as VLA pursues optimal performance, LightVLA spontaneously learns to prune
tokens from a performance-driven perspective. To the best of our knowledge,
LightVLA is the first work to apply adaptive visual token pruning to VLA tasks
with the collateral goals of efficiency and performance, marking a significant
step toward more efficient, powerful and practical real-time robotic systems.

</details>


### [53] [HARMONIC: A Content-Centric Cognitive Robotic Architecture](https://arxiv.org/abs/2509.13279)
*Sanjay Oruganti,Sergei Nirenburg,Marjorie McShane,Jesse English,Michael K. Roberts,Christian Arndt,Carlos Gonzalez,Mingyo Seo,Luis Sentis*

Main category: cs.RO

TL;DR: HARMONIC是一个面向人机团队的认知机器人架构，支持语义感知解释、类人决策和意图语言通信，旨在解决数据稀缺、可解释性和安全性问题。


<details>
  <summary>Details</summary>
Motivation: 解决人机团队中的安全性、结果质量、数据稀缺、可解释性和透明度问题，促进人机信任。

Method: 开发HARMONIC认知机器人架构，包含语义感知解释、类人决策和意图语言通信功能，并在高保真仿真环境和物理机器人平台上实现两个概念验证系统。

Result: 成功实现了两个基于HARMONIC的机器人系统，分别在仿真和物理平台上进行了验证。

Conclusion: HARMONIC架构能够有效支持人机团队协作，提高系统的安全性、可解释性和透明度，促进人机信任关系建立。

Abstract: This paper introduces HARMONIC, a cognitive-robotic architecture designed for
robots in human-robotic teams. HARMONIC supports semantic perception
interpretation, human-like decision-making, and intentional language
communication. It addresses the issues of safety and quality of results; aims
to solve problems of data scarcity, explainability, and safety; and promotes
transparency and trust. Two proof-of-concept HARMONIC-based robotic systems are
demonstrated, each implemented in both a high-fidelity simulation environment
and on physical robotic platforms.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [54] [Yet Another Watermark for Large Language Models](https://arxiv.org/abs/2509.12574)
*Siyuan Bao,Ying Shi,Zhiguang Yang,Hanzhou Wu,Xinpeng Zhang*

Main category: cs.CR

TL;DR: 这篇论文提出了一种新的大语言模型水印框架，通过操控模型内部参数来嵌入水印，在黑盒场景下也能高效提取，更好地平衡了水印的稳健性和隐藏性。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM水印方法主要通过调整标记采样预测或后处理，缺乏与LLM的内在耦合，可能会显著降低生成标记文本的语义质量。而基于训练或微调的传统水印方法要么限于白盒场景，要么因LLM参数量大而非常耗时。

Method: 提出一种新的水印框架，通过操控LLM的内部参数来嵌入水印，并能够在不访问LLM的情况下从生成的文本中提取水印。该方法将水印与LLM的内在参数缠绕在一起。

Result: 实验结果验证了该方法的可行性、优势性和实用性。与相关方法相比，该方法更好地平衡了水印的稳健性和隐藏性，并能够在黑盒场景下高效地提取水印。

Conclusion: 这项工作提供了不同于主流工作的新视角，可能为未来的研究提供启发。通过将水印与LLM内部参数缠绕的方式，实现了更好的性能平衡和更广泛的应用场景。

Abstract: Existing watermarking methods for large language models (LLMs) mainly embed
watermark by adjusting the token sampling prediction or post-processing,
lacking intrinsic coupling with LLMs, which may significantly reduce the
semantic quality of the generated marked texts. Traditional watermarking
methods based on training or fine-tuning may be extendable to LLMs. However,
most of them are limited to the white-box scenario, or very time-consuming due
to the massive parameters of LLMs. In this paper, we present a new watermarking
framework for LLMs, where the watermark is embedded into the LLM by
manipulating the internal parameters of the LLM, and can be extracted from the
generated text without accessing the LLM. Comparing with related methods, the
proposed method entangles the watermark with the intrinsic parameters of the
LLM, which better balances the robustness and imperceptibility of the
watermark. Moreover, the proposed method enables us to extract the watermark
under the black-box scenario, which is computationally efficient for use.
Experimental results have also verified the feasibility, superiority and
practicality. This work provides a new perspective different from mainstream
works, which may shed light on future research.

</details>


### [55] [Jailbreaking Large Language Models Through Content Concretization](https://arxiv.org/abs/2509.12937)
*Johan Wahréus,Ahmed Hussain,Panos Papadimitratos*

Main category: cs.CR

TL;DR: 本文提出Content Concretization（内容具体化）技术，通过两阶段迭代过程将抽象恶意请求转化为具体可执行代码，显著提高了LLM越狱成功率


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的安全机制仍然容易通过各种越狱技术被绕过，需要研究新的攻击方法来揭示现有安全框架的漏洞

Method: 两阶段过程：首先使用低层级安全过滤模型生成初始响应，然后通过高层级模型处理初步输出和原始提示进行精炼

Result: 在350个网络安全特定提示上测试，越狱成功率从7%（无精炼）提升到62%（三次精炼迭代），每次提示成本仅7.5美分

Conclusion: 研究结果突显了当前LLM安全框架的关键漏洞，精炼后的输出被一致评为更具恶意和技术优越性

Abstract: Large Language Models (LLMs) are increasingly deployed for task automation
and content generation, yet their safety mechanisms remain vulnerable to
circumvention through different jailbreaking techniques. In this paper, we
introduce \textit{Content Concretization} (CC), a novel jailbreaking technique
that iteratively transforms abstract malicious requests into concrete,
executable implementations. CC is a two-stage process: first, generating
initial LLM responses using lower-tier, less constrained safety filters models,
then refining them through higher-tier models that process both the preliminary
output and original prompt. We evaluate our technique using 350
cybersecurity-specific prompts, demonstrating substantial improvements in
jailbreak Success Rates (SRs), increasing from 7\% (no refinements) to 62\%
after three refinement iterations, while maintaining a cost of 7.5\textcent~per
prompt. Comparative A/B testing across nine different LLM evaluators confirms
that outputs from additional refinement steps are consistently rated as more
malicious and technically superior. Moreover, manual code analysis reveals that
generated outputs execute with minimal modification, although optimal
deployment typically requires target-specific fine-tuning. With eventual
improved harmful code generation, these results highlight critical
vulnerabilities in current LLM safety frameworks.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [56] [The Adaptation Paradox: Agency vs. Mimicry in Companion Chatbots](https://arxiv.org/abs/2509.12525)
*T. James Brandt,Cecilia Xi Wang*

Main category: cs.HC

TL;DR: 研究发现用户生成头像能提升亲密感，但自适应语言风格匹配反而降低满意度和个性化感知，出现"适应悖论"现象


<details>
  <summary>Details</summary>
Motivation: 探索生成式AI伴侣聊天机器人中如何建立真正的情感连接，比较用户可见创作与隐蔽语言风格模仿两种途径的效果

Method: 采用3×2预注册实验设计（N=162），操纵用户控制头像生成（无、预制、用户生成）和语言风格匹配（静态vs自适应）

Result: 生成头像显著提升亲密感（ω²=0.040, p=0.013），自适应LSM在个性化和满意度上表现不如静态风格（d=0.35, p=0.009），且被判断为适应性更差

Conclusion: 设计应优先考虑清晰可辨的用户驱动个性化，限制风格变化，而非依赖不透明的模仿机制，以保持人格稳定性

Abstract: Generative AI powers a growing wave of companion chatbots, yet principles for
fostering genuine connection remain unsettled. We test two routes: visible user
authorship versus covert language-style mimicry. In a preregistered 3x2
experiment (N = 162), we manipulated user-controlled avatar generation (none,
premade, user-generated) and Language Style Matching (LSM) (static vs.
adaptive). Generating an avatar boosted rapport ($\omega^2$ = .040, p = .013),
whereas adaptive LSM underperformed static style on personalization and
satisfaction (d = 0.35, p = .009) and was paradoxically judged less adaptive (t
= 3.07, p = .003, d = 0.48). We term this an Adaptation Paradox: synchrony
erodes connection when perceived as incoherent, destabilizing persona. To
explain, we propose a stability-and-legibility account: visible authorship
fosters natural interaction, while covert mimicry risks incoherence. Our
findings suggest designers should prioritize legible, user-driven
personalization and limit stylistic shifts rather than rely on opaque mimicry.

</details>


### [57] [Textarium: Entangling Annotation, Abstraction and Argument](https://arxiv.org/abs/2509.13191)
*Philipp Proff,Marian Dörk*

Main category: cs.HC

TL;DR: Textarium是一个基于web的学术阅读写作环境，通过可视化界面连接文本标注、抽象和论证，结合人工分析和轻量计算处理，使解释过程透明且可共享。


<details>
  <summary>Details</summary>
Motivation: 弥合细读和远读实践之间的差距，创建一个能够将人类文本分析与计算处理相结合的环境，使学术阅读和写作的解释过程更加透明和可共享。

Method: 通过推测性设计过程和共同创造迭代原型开发，提供可视化界面让用户高亮文本、将关键词分组为概念，并将这些观察嵌入到论文中作为锚点。

Result: 开发出了一个能够将解释性操作呈现为参数化可视化状态的阅读写作方法，实现了数字叙事中解释过程的透明化和共享。

Conclusion: Textarium成功创建了一个连接标注、抽象和论证的web环境，通过结合人类分析和计算处理，为学术阅读写作提供了新的可视化界面和方法论。

Abstract: We present a web-based environment that connects annotation, abstraction, and
argumentation during the interpretation of text. As a visual interface for
scholarly reading and writing, Textarium combines human analysis with
lightweight computational processing to bridge close and distant reading
practices. Readers can highlight text, group keywords into concepts, and embed
these observations as anchors in essays. The interface renders these
interpretive actions as parameterized visualization states. Through a
speculative design process of co-creative and iterative prototyping, we
developed a reading-writing approach that makes interpretive processes
transparent and shareable within digital narratives.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [58] [Podcasts as a Medium for Participation in Collective Action: A Case Study of Black Lives Matter](https://arxiv.org/abs/2509.13197)
*Theodora Moldovan,Arianna Pera,Davide Vega,Luca Maria Aiello*

Main category: cs.SI

TL;DR: 这篇论文通过分析播客话语研究黑人命也是命运动中的集体行动参与，发现情感表达随着活动阶段而变化，与理论预期相反的是负面情感与集体行动呈负相关。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中在文本内容上，本研究尝试分析音频格式（播客）中的集体行动话语，以完善对数字话语中活动主义表达的理解。

Method: 使用SPoRC播客语料库，采用分层框架从2020年5-6月BLM相关事件的称身正义播客中提取参与性话语，并按问题-解决方案、号召行动、意向和执行进行分类，同时检测这些话语的8种关键情感维度。

Result: 发现不同活动阶段的情感体验存在差异，正面情感在号召行动、意向和执行阶段表现突出，而集体行动与负面情感呈现负相关关系，这与理论预期相反。

Conclusion: 研究揭示了口语数字话语中活动主义的表达方式，并指出情感框架可能受到讨论形式的影响，为理解数字平台上的社会运动提供了新视角。

Abstract: We study how participation in collective action is articulated in podcast
discussions, using the Black Lives Matter (BLM) movement as a case study. While
research on collective action discourse has primarily focused on text-based
content, this study takes a first step toward analyzing audio formats by using
podcast transcripts. Using the Structured Podcast Research Corpus (SPoRC), we
investigated spoken language expressions of participation in collective action,
categorized as problem-solution, call-to-action, intention, and execution. We
identified podcast episodes discussing racial justice after important
BLM-related events in May and June of 2020, and extracted participatory
statements using a layered framework adapted from prior work on social media.
We examined the emotional dimensions of these statements, detecting eight key
emotions and their association with varying stages of activism. We found that
emotional profiles vary by stage, with different positive emotions standing out
during calls-to-action, intention, and execution. We detected negative
associations between collective action and negative emotions, contrary to
theoretical expectations. Our work contributes to a better understanding of how
activism is expressed in spoken digital discourse and how emotional framing may
depend on the format of the discussion.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [59] [Context-Aware Language Models for Forecasting Market Impact from Sequences of Financial News](https://arxiv.org/abs/2509.12519)
*Ross Koval,Nicholas Andrews,Xifeng Yan*

Main category: cs.CE

TL;DR: 历史上下文信息显著提升大语言模型对金融新闻市场影响的理解能力，提出的高效上下文处理方法能改善投资表现


<details>
  <summary>Details</summary>
Motivation: 金融新闻对股票价格有重要影响，但单篇新闻往往需要历史背景信息才能准确解读，识别和整合最相关的上下文信息存在挑战

Method: 提出高效上下文处理方法：使用大语言模型处理主文章，同时用小语言模型将历史上下文编码为简洁的摘要嵌入，并与大模型表示空间对齐

Result: 历史上下文在所有方法和时间范围内都带来一致且显著的性能提升，模型预测的价值具有实际应用意义

Conclusion: 历史上下文对于理解金融新闻的市场影响至关重要，提出的上下文处理方法有效且能显著改善模拟投资表现

Abstract: Financial news plays a critical role in the information diffusion process in
financial markets and is a known driver of stock prices. However, the
information in each news article is not necessarily self-contained, often
requiring a broader understanding of the historical news coverage for accurate
interpretation. Further, identifying and incorporating the most relevant
contextual information presents significant challenges. In this work, we
explore the value of historical context in the ability of large language models
to understand the market impact of financial news. We find that historical
context provides a consistent and significant improvement in performance across
methods and time horizons. To this end, we propose an efficient and effective
contextualization method that uses a large LM to process the main article,
while a small LM encodes the historical context into concise summary embeddings
that are then aligned with the large model's representation space. We explore
the behavior of the model through multiple qualitative and quantitative
interpretability tests and reveal insights into the value of contextualization.
Finally, we demonstrate that the value of historical context in model
predictions has real-world applications, translating to substantial
improvements in simulated investment performance.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [60] [MEUV: Achieving Fine-Grained Capability Activation in Large Language Models via Mutually Exclusive Unlock Vectors](https://arxiv.org/abs/2509.12221)
*Xin Tong,Zhi Lin,Jingya Wang,Meng Han,Bo Jin*

Main category: cs.LG

TL;DR: MEUV框架通过主题对齐的解锁向量实现细粒度控制，在保持高攻击成功率的同时大幅减少跨主题泄漏，支持中英文跨语言迁移。


<details>
  <summary>Details</summary>
Motivation: 现有LLM安全对齐机制会同时拒绝恶意请求和合法的高风险场景使用，而现有的单一拒绝方向编辑方法缺乏语义控制，会无差别解锁所有危险主题。

Method: 提出相互排斥解锁向量(MEUV)框架，将单一拒绝方向分解为多个主题对齐、近乎正交的向量，通过多任务目标在单个epoch中学习，包含差分消融边际、跨主题和正交性惩罚等辅助项。

Result: 在双语恶意提示基准测试中，MEUV在多个模型上达到不低于87%的攻击成功率，同时将跨主题泄漏减少高达90%，中英文向量可几乎无损跨语言迁移。

Conclusion: MEUV证明了细粒度主题级能力激活的可行性，为安全敏感领域的受控LLM部署铺平了道路，且具有最小效用损失。

Abstract: Large language models (LLMs) enforce safety alignment to reliably refuse
malicious requests, yet the same blanket safeguards also block legitimate uses
in policing, defense, and other high-stakes settings. Earlier
"refusal-direction" edits can bypass those layers, but they rely on a single
vector that indiscriminately unlocks all hazardous topics, offering no semantic
control. We introduce Mutually Exclusive Unlock Vectors (MEUV), a lightweight
framework that factorizes the monolithic refusal direction into topic-aligned,
nearly orthogonal vectors, each dedicated to one sensitive capability. MEUV is
learned in a single epoch with a multi-task objective that blends a
differential-ablation margin, cross-topic and orthogonality penalties, and
several auxiliary terms. On bilingual malicious-prompt benchmarks, MEUV
achieves an attack success rate of no less than 87% on Gemma-2-2B, LLaMA-3-8B,
and Qwen-7B, yet cuts cross-topic leakage by up to 90% compared with the best
single-direction baseline. Vectors trained in Chinese transfer almost unchanged
to English (and vice versa), suggesting a language-agnostic refusal subspace.
The results show that fine-grained, topic-level capability activation is
achievable with minimal utility loss, paving the way for controlled LLMs
deployment in security-sensitive domains.

</details>


### [61] [A Novel Recurrent Neural Network Framework for Prediction and Treatment of Oncogenic Mutation Progression](https://arxiv.org/abs/2509.12732)
*Rishab Parthasarathy,Achintya Bhowmik*

Main category: cs.LG

TL;DR: 提出基于AI的端到端通路分析框架，结合时间序列机器学习预测癌症严重程度和突变进展，推荐治疗方案，准确率超60%


<details>
  <summary>Details</summary>
Motivation: 癌症是第二大死因，现有通路分析依赖耗时的人工湿实验数据，需要更高效的自动化分析方法

Method: 从TCGA数据库提取突变序列，通过预处理算法筛选关键突变，使用RNN预测癌症严重程度，结合药物靶点数据库预测突变和推荐治疗

Result: ROC曲线准确率超过60%，与现有癌症诊断相当；预处理成功识别出每个癌症阶段约数百个关键驱动突变

Conclusion: 首个高效、经济的端到端框架，无需湿实验即可预测癌症进展和提供治疗方案

Abstract: Despite significant medical advancements, cancer remains the second leading
cause of death, with over 600,000 deaths per year in the US. One emerging
field, pathway analysis, is promising but still relies on manually derived wet
lab data, which is time-consuming to acquire. This work proposes an efficient,
effective end-to-end framework for Artificial Intelligence (AI) based pathway
analysis that predicts both cancer severity and mutation progression, thus
recommending possible treatments. The proposed technique involves a novel
combination of time-series machine learning models and pathway analysis. First,
mutation sequences were isolated from The Cancer Genome Atlas (TCGA) Database.
Then, a novel preprocessing algorithm was used to filter key mutations by
mutation frequency. This data was fed into a Recurrent Neural Network (RNN)
that predicted cancer severity. Then, the model probabilistically used the RNN
predictions, information from the preprocessing algorithm, and multiple
drug-target databases to predict future mutations and recommend possible
treatments. This framework achieved robust results and Receiver Operating
Characteristic (ROC) curves (a key statistical metric) with accuracies greater
than 60%, similar to existing cancer diagnostics. In addition, preprocessing
played an instrumental role in isolating important mutations, demonstrating
that each cancer stage studied may contain on the order of a few-hundred key
driver mutations, consistent with current research. Heatmaps based on predicted
gene frequency were also generated, highlighting key mutations in each cancer.
Overall, this work is the first to propose an efficient, cost-effective
end-to-end framework for projecting cancer progression and providing possible
treatments without relying on expensive, time-consuming wet lab work.

</details>


### [62] [Similarity-Distance-Magnitude Activations](https://arxiv.org/abs/2509.12760)
*Allen Schmaltz*

Main category: cs.LG

TL;DR: 通过给标准softmax激活函数添加相似性和距离感知能力，提出SDM激活函数，在语言模型中实现更好的稳健性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决标准softmax在协变移动和分布外输入时缺乏稳健性的问题，提供更好的选择分类性能。

Method: 在现有输出强度感知基础上，添加相似性感知（正确预测深度匹配）和距离感知（距离训练分布），构建SDM激活函数。

Result: SDM激活函数在高概率区域对协变移动和分布外输入更稳健，通过密集匹配提供可解释性，并支持类别细分的选择分类。

Conclusion: SDM激活函数比软最大激活函数更适合选择分类任务，即使考虑后验检验方法也如此。

Abstract: We introduce a more robust and interpretable formulation of the standard
softmax activation function commonly used with neural networks by adding
Similarity (i.e., correctly predicted depth-matches into training) awareness
and Distance-to-training-distribution awareness to the existing output
Magnitude (i.e., decision-boundary) awareness. When used as the final-layer
activation with language models, the resulting Similarity-Distance-Magnitude
(SDM) activation function is more robust than the softmax function to
co-variate shifts and out-of-distribution inputs in high-probability regions,
and provides interpretability-by-exemplar via dense matching. Complementing the
prediction-conditional estimates, the SDM activation enables a partitioning of
the class-wise empirical CDFs to guard against low class-wise recall among
selective classifications. These properties make it preferable for selective
classification, even when considering post-hoc calibration methods over the
softmax.

</details>


### [63] [Rethinking the Evaluation of Alignment Methods: Insights into Diversity, Generalisation, and Safety](https://arxiv.org/abs/2509.12936)
*Denis Janiak,Julia Moska,Dawid Motyka,Karolina Seweryn,Paweł Walkowiak,Bartosz Żuk,Arkadiusz Janz*

Main category: cs.LG

TL;DR: 这篇论文提出了一个统一的评估框架，用于比较不同大语言模型对齐方法（PPO、DPO、ORPO、KTO）在准确性、安全性、简洁性、主动性和多样性五个维度上的表现，为开发更平衡可靠的LLM提供指导。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注单个技术或特定维度，缺乏对大语言模型对齐中各种相互军突目标（准确性、安全性、简洁性、主动性、多样性）的全面评估和权衡分析。

Method: 提出统一评估框架，使用分布内和分布外数据集比较PPO、DPO、ORPO、KTO等对齐方法，采用经人类验证的LLM-as-Judge提示进行评估。

Result: 发现DPO和KTO在事实准确性上表现最佳，PPO和DPO在安全性方面领先，PPO在简洁性与主动性的平衡上表现最好。

Conclusion: 研究结果揭示了常见对齐方法的权衡特性，为开发更平衡可靠的大语言模型提供了重要指导。

Abstract: Large language models (LLMs) require careful alignment to balance competing
objectives - factuality, safety, conciseness, proactivity, and diversity.
Existing studies focus on individual techniques or specific dimensions, lacking
a holistic assessment of the inherent trade-offs. We propose a unified
evaluation framework that compares LLM alignment methods (PPO, DPO, ORPO, KTO)
across these five axes, using both in-distribution and out-of-distribution
datasets. Leveraging a specialized LLM-as-Judge prompt, validated through human
studies, we reveal that DPO and KTO excel in factual accuracy, PPO and DPO lead
in safety, and PPO best balances conciseness with proactivity. Our findings
provide insights into trade-offs of common alignment methods, guiding the
development of more balanced and reliable LLMs.

</details>


### [64] [When Inverse Data Outperforms: Exploring the Pitfalls of Mixed Data in Multi-Stage Fine-Tuning](https://arxiv.org/abs/2509.13079)
*Mengyi Deng,Xin Li,Tingyu Zhu,Zhicheng Yang,Zhijiang Guo,Wei Wang*

Main category: cs.LG

TL;DR: 通过构建反向推理数据集r1k并研究双向推理对齐效果，发现SFT在反向数据上能提升性能，但混合数据会弱化方向性区别，DPO虽能部分恢复但也会压制次优推理路径


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注单向监督微调(SFT)，忽视了不同推理模式间的复杂交互作用，需要研究双向推理对模型对齐的影响

Method: 构建高质量反向推理数据集r1k（通过反转s1k数据集中的1000个前向示例），并分别采用SFT和DPO方法在双向推理目标下进行对齐实验

Result: SFT在r1k数据上比s1k在各测试标准上准确率提升1.6%-6.8%，但混合前向和反向数据会弱化方向性区别，DPO虽能部分恢复这种区别但会将概率质量向无关输出偏移，压制次优推理路径

Conclusion: 混合推理数据会引入冲突的监督信号，强调需要发展健壮且方向感知的对齐策略来处理不同推理模式间的复杂关系

Abstract: Existing work has shown that o1-level performance can be achieved with
limited data distillation, but most existing methods focus on unidirectional
supervised fine-tuning (SFT), overlooking the intricate interplay between
diverse reasoning patterns. In this paper, we construct r1k, a high-quality
reverse reasoning dataset derived by inverting 1,000 forward examples from s1k,
and examine how SFT and Direct Preference Optimization (DPO) affect alignment
under bidirectional reasoning objectives. SFT on r1k yields a 1.6%--6.8%
accuracy improvement over s1k across evaluated benchmarks. However, naively
mixing forward and reverse data during SFT weakens the directional distinction.
Although DPO can partially recover this distinction, it also suppresses less
preferred reasoning paths by shifting the probability mass toward irrelevant
outputs. These findings suggest that mixed reasoning data introduce conflicting
supervision signals, underscoring the need for robust and direction-aware
alignment strategies.

</details>


### [65] [WebSailor-V2: Bridging the Chasm to Proprietary Agents via Synthetic Data and Scalable Reinforcement Learning](https://arxiv.org/abs/2509.13305)
*Kuan Li,Zhongwang Zhang,Huifeng Yin,Rui Ye,Yida Zhao,Liwen Zhang,Litu Ou,Dingchu Zhang,Xixi Wu,Jialong Wu,Xinyu Wang,Zile Qiao,Zhen Zhang,Yong Jiang,Pengjun Xie,Fei Huang,Jingren Zhou*

Main category: cs.LG

TL;DR: WebSailor是一种后训练方法，通过生成高不确定性任务、RFT冷启动和DUPO算法，使开源LLM在复杂信息搜索任务中达到与专有代理相当的性能。


<details>
  <summary>Details</summary>
Motivation: 解决开源模型在极端不确定性信息搜索任务中的能力不足，缩小与专有代理系统（如DeepResearch）的性能差距。

Method: 采用结构化采样和信息模糊化生成高不确定性任务，使用RFT冷启动和Duplicating Sampling Policy Optimization (DUPO)算法进行高效的智能体强化学习训练。

Result: WebSailor在复杂信息搜索任务中显著超越所有开源智能体，性能与专有代理相匹配，成功缩小了能力差距。

Conclusion: 通过系统化的后训练方法，开源模型可以获得与专有系统相当的复杂信息搜索能力，验证了减少极端不确定性推理模式的重要性。

Abstract: Transcending human cognitive limitations represents a critical frontier in
LLM training. Proprietary agentic systems like DeepResearch have demonstrated
superhuman capabilities on extremely complex information-seeking benchmarks
such as BrowseComp, a feat previously unattainable. We posit that their success
hinges on a sophisticated reasoning pattern absent in open-source models: the
ability to systematically reduce extreme uncertainty when navigating vast
information landscapes. Based on this insight, we introduce WebSailor, a
complete post-training methodology designed to instill this crucial capability.
Our approach involves generating novel, high-uncertainty tasks through
structured sampling and information obfuscation, RFT cold start, and an
efficient agentic RL training algorithm, Duplicating Sampling Policy
Optimization (DUPO). With this integrated pipeline, WebSailor significantly
outperforms all open-source agents in complex information-seeking tasks,
matching proprietary agents' performance and closing the capability gap.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [66] [Exact Coset Sampling for Quantum Lattice Algorithms](https://arxiv.org/abs/2509.12341)
*Yifan Zhang*

Main category: quant-ph

TL;DR: 该文章提出了一种简单、完全正确且假设轻微的方法，用于替代最近窗口化QFT梯度算法中存在问题的域扩展步骤，通过连续对移构造消除未知偏移，生成准确的均匀CRT余式类状态。


<details>
  <summary>Details</summary>
Motivation: 最近的窗口化QFT梯度算法中的域扩展步骤（Step 9）存在周期性/支持区不匹配的问题，需要一种更为简单且完全正确的替代方案。

Method: 提出了一种连续对移差值构造方法，能够相干消除所有未知偏移，生成准确的均匀CRT余式类状态，然后利用QFT来强制模块线性关系。该单元操作是可逆的，使用poly(log M2)个门。

Result: 新方法完全替代了原有的有问题的域扩展步骤，保持了算法的弄期性性能，且计算复杂度低。

Conclusion: 该研究提供了一种有效的修正方案，解决了窗口化QFT梯度算法中的关键问题，为量子梯度算法的实现提供了更为简单和可靠的方法。

Abstract: We give a simple, fully correct, and assumption-light replacement for the
contested "domain-extension" in Step 9 of a recent windowed-QFT lattice
algorithm with complex-Gaussian windows~\citep{chen2024quantum}. The published
Step~9 suffers from a periodicity/support mismatch. We present a pair-shift
difference construction that coherently cancels all unknown offsets, produces
an exact uniform CRT-coset state over $\mathbb{Z}_{P}$, and then uses the QFT
to enforce the intended modular linear relation. The unitary is reversible,
uses $\mathrm{poly}(\log M_2)$ gates, and preserves the algorithm's
asymptotics. Project Page: https://github.com/yifanzhang-pro/quantum-lattice.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [67] [LEAF: Knowledge Distillation of Text Embedding Models with Teacher-Aligned Representations](https://arxiv.org/abs/2509.12539)
*Robin Vujanic,Thomas Rueckstiess*

Main category: cs.IR

TL;DR: LEAF是一个轻量级的嵌入对齐知识蒸馏框架，能够将小型学生模型与大型教师模型对齐，支持信息检索中的非对称架构，并在BEIR和MTEB基准测试中达到同规模模型的最先进性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决文本嵌入模型在信息检索中需要高效部署的问题，同时保持高性能，作者提出了一个知识蒸馏框架，使学生模型能够与教师模型对齐，实现非对称架构的灵活部署。

Method: 使用LEAF知识蒸馏框架，通过对齐教师模型和学生模型的嵌入表示，无需显式训练即可继承教师模型的MRL和输出量化鲁棒性特性，支持黑盒模型且不需要人工标注或困难负样本。

Result: LEAF框架训练的leaf-ir模型（2300万参数）在BEIR基准测试中排名第一，leaf-mt模型在MTEB v2（英语）排行榜中同样排名第一，非对称模式下检索性能进一步提升。

Conclusion: LEAF是一个高效、轻量的知识蒸馏框架，能够产生与教师模型对齐的高性能小型嵌入模型，在信息检索和多任务场景中都表现出色，且训练要求较低。

Abstract: We present LEAF ("Lightweight Embedding Alignment Framework"), a knowledge
distillation framework for text embedding models. A key distinguishing feature
is that our distilled leaf models are aligned to their teacher. In the context
of information retrieval, this allows for flexible asymmetric architectures
where documents are encoded with the larger teacher model, while queries can be
served with the smaller leaf models. We also show that leaf models
automatically inherit MRL and robustness to output quantization whenever these
properties are present in the teacher model, without explicitly training for
them. To demonstrate the capability of our framework we publish leaf-ir, a 23M
parameters information retrieval oriented text embedding model trained using
LEAF, which sets a new state-of-the-art (SOTA) on BEIR, ranking #1 on the
public leaderboard for this benchmark and for models of its size. When run in
asymmetric mode, its retrieval performance is further increased. Our scheme is
however not restricted to the information retrieval setting, and we demonstrate
its wider applicability by synthesizing the multi-task leaf-mt model. This also
sets a new SOTA, ranking #1 on the public MTEB v2 (English) leaderboard for its
size. LEAF is applicable to black-box models and in contrast to other embedding
model training frameworks, it does not require judgments nor hard negatives,
and training can be conducted using small batch sizes. Thus, dataset and
training infrastructure requirements for our framework are modest. We make our
models publicly available under a permissive Apache 2.0 license.

</details>


### [68] [InfoGain-RAG: Boosting Retrieval-Augmented Generation via Document Information Gain-based Reranking and Filtering](https://arxiv.org/abs/2509.12765)
*Zihan Wang,Zihan Liang,Zhou Shao,Yufei Ma,Huangyu Dai,Ben Chen,Lingtao Mao,Chenyi Lei,Yuqing Ding,Han Li*

Main category: cs.IR

TL;DR: 提出Document Information Gain (DIG)指标来量化检索文档对回答生成的贡献度，并基于此构建InfoGain-RAG框架，通过训练专门的重排器来筛选最有价值的文档，显著提升了RAG系统的性能。


<details>
  <summary>Details</summary>
Motivation: 解决当前RAG框架在识别检索文档是否对回答生成有意义贡献方面的不足，避免无关或误导内容对最终性能的负面影响。

Method: 设计DIG指标来量化文档价值（通过计算有无文档时LLM生成信心度的差值），并基于DIG分数训练专门的重排器，从准确区分和排序角度优先选择最有价值的文档。

Result: 在多个模型和测试集上显著超过现有方法，在NaturalQA上相比普通RAG、自反射RAG和现代排序基础RAG分别提升17.9%、4.5%、12.5%的准确匹配率，在GPT-4o上平均提升15.3%。

Conclusion: InfoGain-RAG为RAG提供了可靠的解决方案，能够在多种应用场景中有效筛选无关文档并选择最有价值的内容，显著提升回答生成质量。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a promising approach to
address key limitations of Large Language Models (LLMs), such as hallucination,
outdated knowledge, and lacking reference. However, current RAG frameworks
often struggle with identifying whether retrieved documents meaningfully
contribute to answer generation. This shortcoming makes it difficult to filter
out irrelevant or even misleading content, which notably impacts the final
performance. In this paper, we propose Document Information Gain (DIG), a novel
metric designed to quantify the contribution of retrieved documents to correct
answer generation. DIG measures a document's value by computing the difference
of LLM's generation confidence with and without the document augmented.
Further, we introduce InfoGain-RAG, a framework that leverages DIG scores to
train a specialized reranker, which prioritizes each retrieved document from
exact distinguishing and accurate sorting perspectives. This approach can
effectively filter out irrelevant documents and select the most valuable ones
for better answer generation. Extensive experiments across various models and
benchmarks demonstrate that InfoGain-RAG can significantly outperform existing
approaches, on both single and multiple retrievers paradigm. Specifically on
NaturalQA, it achieves the improvements of 17.9%, 4.5%, 12.5% in exact match
accuracy against naive RAG, self-reflective RAG and modern ranking-based RAG
respectively, and even an average of 15.3% increment on advanced proprietary
model GPT-4o across all datasets. These results demonstrate the feasibility of
InfoGain-RAG as it can offer a reliable solution for RAG in multiple
applications.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [69] [Humor in Pixels: Benchmarking Large Multimodal Models Understanding of Online Comics](https://arxiv.org/abs/2509.12248)
*Yuriel Ryan,Rui Yang Tan,Kenny Tsu Wei Choo,Roy Ka-Wei Lee*

Main category: cs.CV

TL;DR: PixelHumor是一个包含2800个标注多格漫画的基准数据集，用于评估大型多模态模型理解多模态幽默和识别叙事序列的能力。实验显示当前最先进模型在面板排序任务上仅达到61%准确率，远低于人类表现，揭示了模型在整合视觉和文本线索进行连贯叙事和幽默理解方面的重要局限性。


<details>
  <summary>Details</summary>
Motivation: 幽默理解是社交智能的核心方面，但对大型多模态模型(LMMs)仍是一个重大挑战。需要建立一个评估框架来衡量LMMs在多模态幽默理解和叙事推理方面的能力。

Method: 构建PixelHumor基准数据集，包含2800个标注的多格漫画，设计实验评估最先进LMMs在面板排序和幽默理解任务上的表现。

Result: 实验结果显示当前顶级模型在面板排序任务上仅达到61%准确率，远低于人类表现水平，表明模型在多模态上下文整合和叙事推理方面存在显著不足。

Conclusion: PixelHumor为评估多模态上下文和叙事推理提供了一个严谨框架，旨在推动开发能够更好参与自然、社交意识交互的LMMs，当前模型在幽默理解和叙事序列识别方面仍有很大改进空间。

Abstract: Understanding humor is a core aspect of social intelligence, yet it remains a
significant challenge for Large Multimodal Models (LMMs). We introduce
PixelHumor, a benchmark dataset of 2,800 annotated multi-panel comics designed
to evaluate LMMs' ability to interpret multimodal humor and recognize narrative
sequences. Experiments with state-of-the-art LMMs reveal substantial gaps: for
instance, top models achieve only 61% accuracy in panel sequencing, far below
human performance. This underscores critical limitations in current models'
integration of visual and textual cues for coherent narrative and humor
understanding. By providing a rigorous framework for evaluating multimodal
contextual and narrative reasoning, PixelHumor aims to drive the development of
LMMs that better engage in natural, socially aware interactions.

</details>
